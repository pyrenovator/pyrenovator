<html><h3>Pattern ID :7104
</h3><img src='23672641.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.batch_size = batch_size

        self.policy_t = copy.deepcopy(policy)
        self.optimizer<a id="change"> = </a><a id="change">optim.Adam(
            self.policy.parameters()</a><a id="change">, lr=self.learning_rate)</a>

    def _loss(self, data: ReplayBufferSamples) -&gt; torch.Tensor:
        global global_step
        with torch.no_grad():</code></pre><h3>After Change</h3><pre><code class='java'>
    def __init__(self, kwargs: Dict) -&gt; None:
        self.kwargs = kwargs

        <a id="change">self.kwargs["device"]</a> = <a id="change">torch.device(</a>"cuda"<a id="change"> if torch.cuda.is_available() and kwargs["cuda"]</a><a id="change"> else </a>"cpu"<a id="change">)</a>
        self.envs = <a id="change">gym.vector.SyncVectorEnv(
            [
                self._make_env(kwargs["env_id"], kwargs["seed"], i, kwargs["capture_video"],)
                for i in range(kwargs["num_envs"])
            ]</a><a id="change">
        )</a>
        self.eval_env = <a id="change">gym.vector.SyncVectorEnv([self</a><a id="change">._make_env(kwargs</a><a id="change">["env_id"]</a>, <a id="change">0</a>, <a id="change">0</a>, False<a id="change">)</a>]<a id="change">)</a>

        <a id="change">self.kwargs["envs_single_observation_space"]</a> = self.envs.single_observation_space
        <a id="change">self.kwargs["envs_single_action_space"]</a> = self.envs.single_action_space

        self.buffer = <a id="change">ReplayBuffer(
            self.kwargs["buffer_size"]</a>,
            <a id="change">self.kwargs["envs_single_observation_space"]</a>,
            <a id="change">self.kwargs["envs_single_action_space"]</a>,
            <a id="change">self.kwargs["device"],
            n_envs=self.kwargs["num_envs"],
            optimize_memory_usage=True,
            handle_timeout_termination=False,
        )</a>

        self.agent = Agent(self.kwargs)

    def run(self) -&gt; None:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 33</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/sdpkjc/abcdrl/commit/2acfb37dc607f3fb4dd6152eab1f060543049e7e#diff-cdddc13e4137b26670f39afc44af71d6aeab03c1b1921cc8b8d768eb3674d2adL209' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23672641</div><div id='project'> Project Name: sdpkjc/abcdrl</div><div id='commit'> Commit Name: 2acfb37dc607f3fb4dd6152eab1f060543049e7e</div><div id='time'> Time: 2022-10-01</div><div id='author'> Author: pazyx728@gmail.com</div><div id='file'> File Name: src/dqn.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/dqn.py</div><div id='n_file'> N File Name: src/dqn.py</div><div id='m_start'> M Start Line: 240</div><div id='m_end'> M End Line: 257</div><div id='n_start'> N Start Line: 209</div><div id='n_end'> N End Line: 234</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.double_dqn = double_dqn

        self.policy_t = copy.deepcopy(policy)
        self.optimizer<a id="change"> = </a><a id="change">optim.Adam(
            self.policy.parameters()</a><a id="change">, lr=self.learning_rate)</a>

    def _loss(self, data: ReplayBufferSamples) -&gt; torch.Tensor:
        global global_step
        with torch.no_grad():</code></pre><h3>After Change</h3><pre><code class='java'>
    def __init__(self, kwargs: Dict) -&gt; None:
        self.kwargs = kwargs

        <a id="change">self.kwargs["device"]</a> = <a id="change">torch.device(</a>"cuda"<a id="change"> if torch.cuda.is_available() and kwargs["cuda"]</a><a id="change"> else </a>"cpu"<a id="change">)</a>
        self.envs = <a id="change">gym.vector.SyncVectorEnv(
            [
                self._make_env(kwargs["env_id"], kwargs["seed"], i, kwargs["capture_video"],)
                for i in range(kwargs["num_envs"])
            ]</a><a id="change">
        )</a>
        self.eval_env = <a id="change">gym.vector.SyncVectorEnv([</a><a id="change">self._make_env(</a><a id="change">kwargs["env_id"]</a>, <a id="change">0</a>, <a id="change">0</a>, False<a id="change">)</a>]<a id="change">)</a>

        <a id="change">self.kwargs["envs_single_observation_space"]</a> = self.envs.single_observation_space
        <a id="change">self.kwargs["envs_single_action_space"]</a> = self.envs.single_action_space

        self.buffer = <a id="change">ReplayBuffer(
            </a><a id="change">self.kwargs["buffer_size"]</a>,
            <a id="change">self.kwargs["envs_single_observation_space"]</a>,
            <a id="change">self.kwargs["envs_single_action_space"]</a>,
            <a id="change">self.kwargs["device"],
            n_envs=self.kwargs["num_envs"],
            optimize_memory_usage=True,
            handle_timeout_termination=False,
        )</a>

        self.agent = Agent(self.kwargs)

    def run(self) -&gt; None:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sdpkjc/abcdrl/commit/2acfb37dc607f3fb4dd6152eab1f060543049e7e#diff-e7ccb47a4f603b523bf286fdaa57ebec8196fca5e2f53732f03cc2f24b0a6250L242' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23672617</div><div id='project'> Project Name: sdpkjc/abcdrl</div><div id='commit'> Commit Name: 2acfb37dc607f3fb4dd6152eab1f060543049e7e</div><div id='time'> Time: 2022-10-01</div><div id='author'> Author: pazyx728@gmail.com</div><div id='file'> File Name: src/ddqn.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/ddqn.py</div><div id='n_file'> N File Name: src/ddqn.py</div><div id='m_start'> M Start Line: 242</div><div id='m_end'> M End Line: 261</div><div id='n_start'> N Start Line: 211</div><div id='n_end'> N End Line: 236</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.batch_size = batch_size

        self.policy_t = copy.deepcopy(self.policy)
        self.optimizer_actor<a id="change"> = </a><a id="change">optim.Adam(
            self.policy.actor_nn.parameters()</a><a id="change">, lr=self.learning_rate)</a>
        self.optimizer_critic = optim.Adam(
            self.policy.critic_nn.parameters(), lr=self.learning_rate)

    def _loss(self, data: ReplayBufferSamples) -&gt; torch.Tensor:</code></pre><h3>After Change</h3><pre><code class='java'>
    def __init__(self, kwargs: Dict) -&gt; None:
        self.kwargs = kwargs

        <a id="change">self.kwargs["device"]</a> = <a id="change">torch.device(</a>"cuda"<a id="change"> if torch.cuda.is_available() and kwargs["cuda"]</a><a id="change"> else </a>"cpu"<a id="change">)</a>
        self.envs = <a id="change">gym.vector.SyncVectorEnv(
            [
                self._make_env(kwargs["env_id"], kwargs["seed"], i, kwargs["capture_video"],)
                for i in range(kwargs["num_envs"])
            ]</a><a id="change">
        )</a>
        self.envs.single_observation_space.dtype = np.float32
        self.eval_env = <a id="change">gym.vector.SyncVectorEnv([</a><a id="change">self._make_env(</a><a id="change">kwargs["env_id"]</a>, <a id="change">0</a>, <a id="change">0</a>, False<a id="change">)</a>]<a id="change">)</a>

        <a id="change">self.kwargs["envs_single_observation_space"]</a> = self.envs.single_observation_space
        <a id="change">self.kwargs["envs_single_action_space"]</a> = self.envs.single_action_space

        self.buffer = <a id="change">ReplayBuffer(
            </a><a id="change">self.kwargs["buffer_size"]</a>,
            <a id="change">self.kwargs["envs_single_observation_space"]</a>,
            <a id="change">self.kwargs["envs_single_action_space"]</a>,
            <a id="change">self.kwargs["device"],
            n_envs=self.kwargs["num_envs"],
            optimize_memory_usage=True,
            handle_timeout_termination=False,
        )</a>

        self.agent = Agent(self.kwargs)

    def run(self) -&gt; None:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sdpkjc/abcdrl/commit/2acfb37dc607f3fb4dd6152eab1f060543049e7e#diff-18c96ab5299efb62fcf535d797a2fa36c90179a85b9069561babcc6e71ced525L259' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23672619</div><div id='project'> Project Name: sdpkjc/abcdrl</div><div id='commit'> Commit Name: 2acfb37dc607f3fb4dd6152eab1f060543049e7e</div><div id='time'> Time: 2022-10-01</div><div id='author'> Author: pazyx728@gmail.com</div><div id='file'> File Name: src/ddpg.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/ddpg.py</div><div id='n_file'> N File Name: src/ddpg.py</div><div id='m_start'> M Start Line: 259</div><div id='m_end'> M End Line: 280</div><div id='n_start'> N Start Line: 246</div><div id='n_end'> N End Line: 270</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.batch_size = batch_size

        self.policy_t = copy.deepcopy(policy)
        self.optimizer<a id="change"> = </a><a id="change">optim.Adam(
            self.policy.parameters()</a><a id="change">, lr=self.learning_rate)</a>

    def _loss(self, data: ReplayBufferSamples) -&gt; torch.Tensor:
        global global_step
        with torch.no_grad():</code></pre><h3>After Change</h3><pre><code class='java'>
    def __init__(self, kwargs: Dict) -&gt; None:
        self.kwargs = kwargs

        <a id="change">self.kwargs["device"]</a> = <a id="change">torch.device(</a>"cuda"<a id="change"> if torch.cuda.is_available() and kwargs["cuda"]</a><a id="change"> else </a>"cpu"<a id="change">)</a>
        self.envs = <a id="change">gym.vector.SyncVectorEnv(
            [
                self._make_env(kwargs["env_id"], kwargs["seed"], i, kwargs["capture_video"],)
                for i in range(kwargs["num_envs"])
            ]</a><a id="change">
        )</a>
        self.eval_env = <a id="change">gym.vector.SyncVectorEnv([</a><a id="change">self._make_env(</a><a id="change">kwargs["env_id"]</a>, <a id="change">0</a>, <a id="change">0</a>, False<a id="change">)</a>]<a id="change">)</a>

        <a id="change">self.kwargs["envs_single_observation_space"]</a> = self.envs.single_observation_space
        <a id="change">self.kwargs["envs_single_action_space"]</a> = self.envs.single_action_space

        self.buffer = <a id="change">ReplayBuffer(
            </a><a id="change">self.kwargs["buffer_size"]</a>,
            <a id="change">self.kwargs["envs_single_observation_space"]</a>,
            <a id="change">self.kwargs["envs_single_action_space"]</a>,
            <a id="change">self.kwargs["device"],
            n_envs=self.kwargs["num_envs"],
            optimize_memory_usage=True,
            handle_timeout_termination=False,
        )</a>

        self.agent = Agent(self.kwargs)

    def run(self) -&gt; None:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sdpkjc/abcdrl/commit/2acfb37dc607f3fb4dd6152eab1f060543049e7e#diff-cdddc13e4137b26670f39afc44af71d6aeab03c1b1921cc8b8d768eb3674d2adL240' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23672640</div><div id='project'> Project Name: sdpkjc/abcdrl</div><div id='commit'> Commit Name: 2acfb37dc607f3fb4dd6152eab1f060543049e7e</div><div id='time'> Time: 2022-10-01</div><div id='author'> Author: pazyx728@gmail.com</div><div id='file'> File Name: src/dqn.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/dqn.py</div><div id='n_file'> N File Name: src/dqn.py</div><div id='m_start'> M Start Line: 240</div><div id='m_end'> M End Line: 257</div><div id='n_start'> N Start Line: 209</div><div id='n_end'> N End Line: 234</div><BR>