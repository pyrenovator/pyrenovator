<html><h3>Pattern ID :20455
</h3><img src='66205554.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        num_budgets = self._check_budget(
            num_budgets, max_perturbations=self.num_nodes)

        <a id="change">assert </a>num_edges_global is None, &quotNot implemented now!&quot

        if num_edges_local is None:
            num_edges_local = int(self._degree.mean().clamp(min=1))</code></pre><h3>After Change</h3><pre><code class='java'>
                &#47&#47 node indices
                self.targets = torch.LongTensor(targets).view(-1).tolist()

        <a id="change">if num_edges_local is not None</a><a id="change"> and num_edges_global is not None</a>:
            raise RuntimeError(
                "Both `num_edges_local` and `num_edges_global` cannot be used simultaneously.")

        if num_edges_global is not None:
            num_edges_local = num_edges_global // len(self.targets)
            if num_edges_local == 0:
                <a id="change">raise ValueError(
                    f"Too less edges allowed (num_edges_global={num_edges_global}) for injected nodes ({len(self.targets)}). "
                    "Maybe you could use the argument `num_edges_local` instead."</a><a id="change">)</a>

        if num_edges_local is None:
            num_edges_local = int(self._degree.mean().clamp(min=1))

        self.num_budgets = num_budgets
        self.num_edges_global = num_edges_global
        self.num_edges_local = num_edges_local

        &#47&#47 ============== get feature limitation of injected node ==============
        min_limits = max_limits = None

        <a id="change">if feat_limits is not None</a> and <a id="change">feat_budgets is not None</a>:
            <a id="change">raise </a>RuntimeError(
                "Both `feat_limits` and `feat_budgets` cannot be used simultaneously.")

        if feat_limits is not None:
            if isinstance(feat_limits, tuple):
                min_limits, max_limits = feat_limits
            elif isinstance(feat_limits, dict):
                min_limits = feat_limits.pop(&quotmin&quot, None)
                max_limits = feat_limits.pop(&quotmax&quot, None)
                if feat_limits:
                    raise ValueError(
                        f"Unrecognized key {next(iter(feat_limits.keys()))}.")
            else:
                raise TypeError(
                    f"`feat_limits` should be an instance of tuple and dict, but got {feat_limits}.")

        feat = self.feat
        assert feat is not None

        if min_limits is None and feat is not None:
            min_limits = feat.min()
        else:
            min_limits = 0.

        if max_limits is None and feat is not None:
            max_limits = feat.max()
        else:
            max_limits = 1.

        if feat_budgets is not None:
            assert feat_budgets &lt;= self.num_feats

        self.feat_budgets<a id="change"> = </a>feat_budgets

        &#47&#47 TODO
        self._mu = (max_limits - min_limits) / 2</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 12</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/edisonleeeee/greatx/commit/b9e4a3cd44c3e20b95d070cc4858660d029b1c2f#diff-3f5044cd75cfdf0dd56528488a76653df55e38af87de04c9a09f3309d31d5a5bL56' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66205554</div><div id='project'> Project Name: edisonleeeee/greatx</div><div id='commit'> Commit Name: b9e4a3cd44c3e20b95d070cc4858660d029b1c2f</div><div id='time'> Time: 2022-05-30</div><div id='author'> Author: cnljt@outlook.com</div><div id='file'> File Name: graphwar/attack/injection/injection_attacker.py</div><div id='m_class'> M Class Name: InjectionAttacker</div><div id='n_method'> N Class Name: InjectionAttacker</div><div id='m_method'> M Method Name: attack(2)</div><div id='n_method'> N Method Name: attack(2)</div><div id='m_parent_class'> M Parent Class: Attacker</div><div id='n_parent_class'> N Parent Class: Attacker</div><div id='m_file'> M File Name: graphwar/attack/injection/injection_attacker.py</div><div id='n_file'> N File Name: graphwar/attack/injection/injection_attacker.py</div><div id='m_start'> M Start Line: 56</div><div id='m_end'> M End Line: 102</div><div id='n_start'> N Start Line: 115</div><div id='n_end'> N End Line: 179</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        )
        embedding_output = self.embedding_hidden_mapping_in(embedding_output)

        <a id="change">assert </a>not output_attentions, "Not support attentions output currently."

        all_hidden_states = [] if output_hidden_states else None
        hidden_states = embedding_output</code></pre><h3>After Change</h3><pre><code class='java'>
        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions

        &#47&#47 check the variable of `input_ids` and `inputs_embeds`
        <a id="change">if input_ids is None</a><a id="change"> and inputs_embeds is None</a>:
            <a id="change">raise ValueError("You have to specify either input_ids or inputs_embeds"</a><a id="change">)</a>
        <a id="change">if input_ids is not None</a> and <a id="change">inputs_embeds is not None</a>:
            <a id="change">raise </a>ValueError("You cannot specify both input_ids and inputs_embeds at the same time")

        if attention_mask is None:
            attention_mask = paddle.unsqueeze(
                (input_ids == self.pad_token_id).astype(self.pooler.dense.weight.dtype) * -1e4, axis=[1, 2]
            )
        &#47&#47 For 2D attention_mask from tokenizer
        elif attention_mask.ndim == 2:
            attention_mask = paddle.unsqueeze(attention_mask, axis=[1, 2]).astype(paddle.get_default_dtype())
            attention_mask = (1.0 - attention_mask) * -1e4
        attention_mask.stop_gradient = True

        embedding_output = self.embeddings(
            input_ids=input_ids, position_ids=position_ids, token_type_ids=token_type_ids, inputs_embeds=inputs_embeds
        )
        embedding_output = self.embedding_hidden_mapping_in(embedding_output)

        hidden_states = embedding_output

        encoder_output<a id="change"> = </a>self.encoder(
            hidden_states,
            src_mask=attention_mask,
            output_attentions=output_attentions,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/5e4d789496b1ef7bf7d1fd3b09c198105cc29aea#diff-ee0b626dc221753cba50d81a16b8ff808f451ea0cb445da307395f4d8e3a214eL279' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66205555</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 5e4d789496b1ef7bf7d1fd3b09c198105cc29aea</div><div id='time'> Time: 2023-03-23</div><div id='author'> Author: 1435130236@qq.com</div><div id='file'> File Name: paddlenlp/transformers/ernie_ctm/modeling.py</div><div id='m_class'> M Class Name: ErnieCtmModel</div><div id='n_method'> N Class Name: ErnieCtmModel</div><div id='m_method'> M Method Name: forward(10)</div><div id='n_method'> N Method Name: forward(9)</div><div id='m_parent_class'> M Parent Class: ErnieCtmPretrainedModel</div><div id='n_parent_class'> N Parent Class: ErnieCtmPretrainedModel</div><div id='m_file'> M File Name: paddlenlp/transformers/ernie_ctm/modeling.py</div><div id='n_file'> N File Name: paddlenlp/transformers/ernie_ctm/modeling.py</div><div id='m_start'> M Start Line: 376</div><div id='m_end'> M End Line: 440</div><div id='n_start'> N Start Line: 291</div><div id='n_end'> N End Line: 461</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        num_budgets = self._check_budget(
            num_budgets, max_perturbations=self.num_nodes)

        <a id="change">assert </a>num_edges_global is None, &quotNot implemented now!&quot

        if num_edges_local is None:
            num_edges_local = int(self._degree.mean().clamp(min=1))</code></pre><h3>After Change</h3><pre><code class='java'>
                &#47&#47 node indices
                self.targets = torch.LongTensor(targets).view(-1).tolist()

        <a id="change">if num_edges_local is not None</a><a id="change"> and num_edges_global is not None</a>:
            raise RuntimeError(
                "Both `num_edges_local` and `num_edges_global` cannot be used simultaneously.")

        if num_edges_global is not None:
            num_edges_local = num_edges_global // len(self.targets)
            if num_edges_local == 0:
                <a id="change">raise ValueError(
                    f"Too less edges allowed (num_edges_global={num_edges_global}) for injected nodes ({len(self.targets)}). "
                    "Maybe you could use the argument `num_edges_local` instead."</a><a id="change">)</a>

        if num_edges_local is None:
            num_edges_local = int(self._degree.mean().clamp(min=1))

        self.num_budgets = num_budgets
        self.num_edges_global = num_edges_global
        self.num_edges_local = num_edges_local

        &#47&#47 ============== get feature limitation of injected node ==============
        min_limits = max_limits = None

        <a id="change">if feat_limits is not None</a> and <a id="change">feat_budgets is not None</a>:
            <a id="change">raise </a>RuntimeError(
                "Both `feat_limits` and `feat_budgets` cannot be used simultaneously.")

        if feat_limits is not None:
            if isinstance(feat_limits, tuple):
                min_limits, max_limits = feat_limits
            elif isinstance(feat_limits, dict):
                min_limits = feat_limits.pop(&quotmin&quot, None)
                max_limits = feat_limits.pop(&quotmax&quot, None)
                if feat_limits:
                    raise ValueError(
                        f"Unrecognized key {next(iter(feat_limits.keys()))}.")
            else:
                raise TypeError(
                    f"`feat_limits` should be an instance of tuple and dict, but got {feat_limits}.")

        feat = self.feat
        assert feat is not None

        if min_limits is None and feat is not None:
            min_limits = feat.min()
        else:
            min_limits = 0.

        if max_limits is None and feat is not None:
            max_limits = feat.max()
        else:
            max_limits = 1.

        if feat_budgets is not None:
            assert feat_budgets &lt;= self.num_feats

        self.feat_budgets<a id="change"> = </a>feat_budgets

        &#47&#47 TODO
        self._mu = (max_limits - min_limits) / 2</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/edisonleeeee/graphwar/commit/b9e4a3cd44c3e20b95d070cc4858660d029b1c2f#diff-3f5044cd75cfdf0dd56528488a76653df55e38af87de04c9a09f3309d31d5a5bL36' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66205523</div><div id='project'> Project Name: edisonleeeee/graphwar</div><div id='commit'> Commit Name: b9e4a3cd44c3e20b95d070cc4858660d029b1c2f</div><div id='time'> Time: 2022-05-30</div><div id='author'> Author: cnljt@outlook.com</div><div id='file'> File Name: graphwar/attack/injection/injection_attacker.py</div><div id='m_class'> M Class Name: InjectionAttacker</div><div id='n_method'> N Class Name: InjectionAttacker</div><div id='m_method'> M Method Name: attack(2)</div><div id='n_method'> N Method Name: attack(2)</div><div id='m_parent_class'> M Parent Class: Attacker</div><div id='n_parent_class'> N Parent Class: Attacker</div><div id='m_file'> M File Name: graphwar/attack/injection/injection_attacker.py</div><div id='n_file'> N File Name: graphwar/attack/injection/injection_attacker.py</div><div id='m_start'> M Start Line: 56</div><div id='m_end'> M End Line: 102</div><div id='n_start'> N Start Line: 115</div><div id='n_end'> N End Line: 179</div><BR>