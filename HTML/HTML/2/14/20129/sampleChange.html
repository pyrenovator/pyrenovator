<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    <a id="change">normalize</a> = <a id="change">T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])</a>
    train_transform = T.Compose(<a id="change">[
        </a>ResizeImage(256),
        T.RandomResizedCrop(224),
        T.RandomHorizontalFlip(),
        <a id="change">T.ToTensor()</a>,
        <a id="change">normalize</a>
    ])
    val_transform<a id="change"> = T</a><a id="change">.Compose([
        </a>ResizeImage(256),
        T.CenterCrop(224),
        <a id="change">T.ToTensor()</a>,
        <a id="change">normalize</a>
    ]<a id="change">)</a>

    dataset = datasets.__dict__[args.data]
    train_dataset = dataset(root=args.root, split=&quottrain&quot, sample_rate=args.sample_rate,
                            download=True, transform=train_transform)</code></pre><h3>After Change</h3><pre><code class='java'>
    print("train_transform: ", train_transform)
    print("val_transform: ", val_transform)

    train_dataset<a id="change">, val_dataset, num_classes</a> = utils.get_dataset(args.data, args.root, train_transform,
                                                                    val_transform, args.sample_rate, args.sample_size)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,
                              num_workers=args.workers, drop_last=True)
    train_iter = ForeverDataIterator(train_loader)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    print("training dataset size: {} test dataset size: {}".format(len(train_dataset), len(val_dataset)))

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = utils.get_model(args.arch, args.pretrained)
    pool_layer = nn.Identity() if args.no_pool else None
    classifier = <a id="change">Classifier(backbone, num_classes, pool_layer=pool_layer, finetune=args.finetune).to(</a>device<a id="change">)</a>
    bss_module = BatchSpectralShrinkage(k=args.k)

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(args.lr), momentum=args.momentum, weight_decay=args.wd, nesterov=True)
    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, args.lr_decay_epochs, gamma=args.lr_gamma)

    &#47&#47 resume from the best checkpoint
    if args.phase == &quottest&quot:
        checkpoint = torch.load(logger.get_checkpoint_path(&quotbest&quot), map_location=&quotcpu&quot)
        classifier.load_state_dict(checkpoint)
        acc1 = utils.validate(val_loader, classifier, args, device)
        print(acc1)
        return

    &#47&#47 start training
    best_acc1 = 0.0
    for epoch in range(args.epochs):
        print(lr_scheduler.get_lr())
        &#47&#47 train for one epoch
        train(train_iter, classifier, bss_module, optimizer, epoch, args)
        lr_scheduler.step()
        &#47&#47 evaluate on validation set
        acc1<a id="change"> = </a>utils.validate(val_loader, classifier, args, device)

        &#47&#47 remember best acc@1 and save checkpoint
        torch.save(classifier.state_dict(), logger.get_checkpoint_path(&quotlatest&quot))</code></pre>