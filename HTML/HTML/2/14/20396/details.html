<html><h3>Pattern ID :20396
</h3><img src='66043183.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def __init__(self, model, train_config, model_config, current_step):

        self._optimizer = torch.optim.Adam(
            <a id="change">model.parameters()</a>,
            betas=train_config["optimizer"]["betas"],
            eps=train_config["optimizer"]["eps"],
            weight_decay=train_config["optimizer"]["weight_decay"],</code></pre><h3>After Change</h3><pre><code class='java'>
    
    def __init__(self, model, train_config, model_config, current_step):
        self._optimizer = torch.optim.Adam(
            <a id="change">[param for name, param in model.named_parameters()
                        if not any([filtered_name in name for filtered_name in [&quotD_s&quot, &quotD_t&quot]])]</a>,
            betas=train_config["optimizer"]["betas"],
            eps=train_config["optimizer"]["eps"],
            weight_decay=train_config["optimizer"]["weight_decay"],</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/keonlee9420/stylespeech/commit/d6909651b207a8b59aa3bd38bbb499654f7f778a#diff-aab7ce99b397ee6a518da19e519dc93cabffdf40ea04040b8ab6f2f180eb1aceL10' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66043183</div><div id='project'> Project Name: keonlee9420/stylespeech</div><div id='commit'> Commit Name: d6909651b207a8b59aa3bd38bbb499654f7f778a</div><div id='time'> Time: 2021-07-24</div><div id='author'> Author: keonlee9420@gmail.com</div><div id='file'> File Name: model/optimizer.py</div><div id='m_class'> M Class Name: ScheduledOptimMain</div><div id='n_method'> N Class Name: ScheduledOptimMain</div><div id='m_method'> M Method Name: __init__(5)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model/optimizer.py</div><div id='n_file'> N File Name: model/optimizer.py</div><div id='m_start'> M Start Line: 11</div><div id='m_end'> M End Line: 21</div><div id='n_start'> N Start Line: 10</div><div id='n_end'> N End Line: 21</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def __init__(self, model, train_config, model_config, current_step):

        self._optimizer = torch.optim.Adam(
            <a id="change">model.parameters()</a>,
            betas=train_config["optimizer"]["betas"],
            eps=train_config["optimizer"]["eps"],
            weight_decay=train_config["optimizer"]["weight_decay"],</code></pre><h3>After Change</h3><pre><code class='java'>
    
    def __init__(self, model, train_config, model_config, current_step):
        self._optimizer = torch.optim.Adam(
            <a id="change">[param for name, param in model.named_parameters()
                        if not any([filtered_name in name for filtered_name in [&quotD_s&quot, &quotD_t&quot]])]</a>,
            betas=train_config["optimizer"]["betas"],
            eps=train_config["optimizer"]["eps"],
            weight_decay=train_config["optimizer"]["weight_decay"],</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/keonlee9420/stylespeech/commit/d6909651b207a8b59aa3bd38bbb499654f7f778a#diff-aab7ce99b397ee6a518da19e519dc93cabffdf40ea04040b8ab6f2f180eb1aceL8' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66043182</div><div id='project'> Project Name: keonlee9420/stylespeech</div><div id='commit'> Commit Name: d6909651b207a8b59aa3bd38bbb499654f7f778a</div><div id='time'> Time: 2021-07-24</div><div id='author'> Author: keonlee9420@gmail.com</div><div id='file'> File Name: model/optimizer.py</div><div id='m_class'> M Class Name: ScheduledOptimMain</div><div id='n_method'> N Class Name: ScheduledOptimMain</div><div id='m_method'> M Method Name: __init__(5)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model/optimizer.py</div><div id='n_file'> N File Name: model/optimizer.py</div><div id='m_start'> M Start Line: 11</div><div id='m_end'> M End Line: 21</div><div id='n_start'> N Start Line: 10</div><div id='n_end'> N End Line: 21</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    model.to(device)
    
    total_steps = len(traindataloader) * N_EPOCHS
    optimizer = AdamW(<a id="change">model.parameters()</a>, lr=LR)
    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(WARMUP_PROPORTION * total_steps), num_training_steps=total_steps)
    
    loss_vals = []</code></pre><h3>After Change</h3><pre><code class='java'>
    model = GPT2LMHeadModel(config=model_config)
    model.to(device)

    no_decay = <a id="change">[</a>&quotbias&quot, <a id="change">&quotLayerNorm.bias&quot</a>, <a id="change">&quotLayerNorm.weight&quot</a>]
    optimizer_grouped_parameters = [
        {&quotparams&quot: <a id="change">[p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)]</a>,
        &quotweight_decay&quot: 0.01},
        {&quotparams&quot: [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], &quotweight_decay&quot: 0.0}
    ]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jasoncao11/nlp-notebook/commit/89055898f991cbc653da9d069a03ec92ab07d41c#diff-294a953135f12d6986187a7a98b576193c46107da291cb9c98ab33e85560dcbaL40' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66043179</div><div id='project'> Project Name: jasoncao11/nlp-notebook</div><div id='commit'> Commit Name: 89055898f991cbc653da9d069a03ec92ab07d41c</div><div id='time'> Time: 2021-06-21</div><div id='author'> Author: tiekuncao@163.com</div><div id='file'> File Name: 4-4.GPT/train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: run(0)</div><div id='n_method'> N Method Name: run(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: 4-4.GPT/train.py</div><div id='n_file'> N File Name: 4-4.GPT/train.py</div><div id='m_start'> M Start Line: 43</div><div id='m_end'> M End Line: 47</div><div id='n_start'> N Start Line: 43</div><div id='n_end'> N End Line: 88</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def __init__(self, model, train_config):

        self._optimizer = torch.optim.Adam(
            <a id="change">model.parameters()</a>,
            betas=train_config["optimizer"]["betas"],
            eps=train_config["optimizer"]["eps"],
            weight_decay=train_config["optimizer"]["weight_decay"],</code></pre><h3>After Change</h3><pre><code class='java'>
    def __init__(self, model, train_config):

        self._optimizer = torch.optim.Adam(
            <a id="change">[param for name, param in model.named_parameters()
                        if any([filtered_name in name for filtered_name in [&quotD_s&quot, &quotD_t&quot]])]</a>,
            betas=train_config["optimizer"]["betas"],
            eps=train_config["optimizer"]["eps"],
            weight_decay=train_config["optimizer"]["weight_decay"],</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/keonlee9420/stylespeech/commit/e996d1549fc52935e17700b59d74482732353845#diff-aab7ce99b397ee6a518da19e519dc93cabffdf40ea04040b8ab6f2f180eb1aceL59' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66043211</div><div id='project'> Project Name: keonlee9420/stylespeech</div><div id='commit'> Commit Name: e996d1549fc52935e17700b59d74482732353845</div><div id='time'> Time: 2021-09-06</div><div id='author'> Author: keonlee9420@gmail.com</div><div id='file'> File Name: model/optimizer.py</div><div id='m_class'> M Class Name: ScheduledOptimDisc</div><div id='n_method'> N Class Name: ScheduledOptimDisc</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model/optimizer.py</div><div id='n_file'> N File Name: model/optimizer.py</div><div id='m_start'> M Start Line: 62</div><div id='m_end'> M End Line: 62</div><div id='n_start'> N Start Line: 62</div><div id='n_end'> N End Line: 63</div><BR>