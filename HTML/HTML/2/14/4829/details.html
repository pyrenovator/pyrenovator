<html><h3>Pattern ID :4829
</h3><img src='17048709.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                paddle.reshape(labels, [-1]),
            )

            <a id="change">return </a>lm_loss, prediction_scores, sequence_output

        return prediction_scores, sequence_output
</code></pre><h3>After Change</h3><pre><code class='java'>

        
        output_attentions = output_attentions if output_attentions is not None else False
        output_hidden_states = output_hidden_states<a id="change"> if </a><a id="change">output_hidden_states is not None else </a>False
        return_dict = return_dict if return_dict is not None else False

        outputs = self.bigbird(input_ids, attention_mask=attention_mask, rand_mask_idx_list=rand_mask_idx_list)
        sequence_output<a id="change"> = </a>outputs[0]
        prediction_scores = self.lm_head(sequence_output)

        lm_loss = None
        if labels is not None:
            &#47&#47 we are doing next-token prediction; shift prediction scores and input ids by one
            shifted_prediction_scores = prediction_scores[:, :-1, :]
            labels = labels[:, 1:]
            loss_fct = nn.CrossEntropyLoss()
            lm_loss = loss_fct(
                paddle.reshape(shifted_prediction_scores, [-1, self.bigbird.config["vocab_size"]]),
                paddle.reshape(labels, [-1]),
            )

        <a id="change">if not return_dict</a>:
            output = (prediction_scores,) + outputs[2:]
            <a id="change">return </a>((<a id="change">lm_loss</a>,)<a id="change"> + </a>output)<a id="change"> if lm_loss</a><a id="change"> is not None else </a>(output[0] if len(output) == 1 else output)

        return <a id="change">MaskedLMOutput(
            loss=lm_loss,
            logits=prediction_scores,
            hidden_states=outputs.hidden_states,
            attentions=outputs.attentions,
        )</a>
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 12</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/ea41f01c6fee751023d2ec53eed7fb543439ff4e#diff-7da51fd7e434b7611664c7f9ad16f1fce671a0664ae192aeba1d9fab94dbe1b2L1164' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17048709</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: ea41f01c6fee751023d2ec53eed7fb543439ff4e</div><div id='time'> Time: 2023-03-09</div><div id='author'> Author: 115528288+tsinghua-zhang@users.noreply.github.com</div><div id='file'> File Name: paddlenlp/transformers/bigbird/modeling.py</div><div id='m_class'> M Class Name: BigBirdForCausalLM</div><div id='n_method'> N Class Name: BigBirdForCausalLM</div><div id='m_method'> M Method Name: forward(8)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: BigBirdPretrainedModel</div><div id='n_parent_class'> N Parent Class: BigBirdPretrainedModel</div><div id='m_file'> M File Name: paddlenlp/transformers/bigbird/modeling.py</div><div id='n_file'> N File Name: paddlenlp/transformers/bigbird/modeling.py</div><div id='m_start'> M Start Line: 1164</div><div id='m_end'> M End Line: 1211</div><div id='n_start'> N Start Line: 1558</div><div id='n_end'> N End Line: 1623</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                paddle.reshape(labels, [-1]),
            )

            <a id="change">return </a>lm_loss, prediction_scores, sequence_output

        return prediction_scores, sequence_output
</code></pre><h3>After Change</h3><pre><code class='java'>
        
        output_attentions = output_attentions if output_attentions is not None else False
        output_hidden_states = output_hidden_states if output_hidden_states is not None else False
        return_dict = return_dict<a id="change"> if </a><a id="change">return_dict is not None else </a>False

        outputs = self.bigbird(input_ids, attention_mask=attention_mask, rand_mask_idx_list=rand_mask_idx_list)
        sequence_output<a id="change"> = </a>outputs[0]
        prediction_scores = self.lm_head(sequence_output)

        <a id="change">lm_loss</a> = None
        if labels is not None:
            &#47&#47 we are doing next-token prediction; shift prediction scores and input ids by one
            shifted_prediction_scores = prediction_scores[:, :-1, :]
            labels = labels[:, 1:]
            loss_fct = nn.CrossEntropyLoss()
            lm_loss = loss_fct(
                paddle.reshape(shifted_prediction_scores, [-1, self.bigbird.config["vocab_size"]]),
                paddle.reshape(labels, [-1]),
            )

        <a id="change">if not return_dict</a>:
            output = (prediction_scores,) + outputs[2:]
            <a id="change">return </a>((lm_loss<a id="change"></a>,)<a id="change"> + </a>output)<a id="change"> if </a><a id="change">lm_loss is not None else </a>(output[0] if len(output) == 1 else output)

        return <a id="change">MaskedLMOutput(
            loss=lm_loss,
            logits=prediction_scores,
            hidden_states=outputs.hidden_states,
            attentions=outputs.attentions,
        )</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/ea41f01c6fee751023d2ec53eed7fb543439ff4e#diff-7da51fd7e434b7611664c7f9ad16f1fce671a0664ae192aeba1d9fab94dbe1b2L1164' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17048711</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: ea41f01c6fee751023d2ec53eed7fb543439ff4e</div><div id='time'> Time: 2023-03-09</div><div id='author'> Author: 115528288+tsinghua-zhang@users.noreply.github.com</div><div id='file'> File Name: paddlenlp/transformers/bigbird/modeling.py</div><div id='m_class'> M Class Name: BigBirdForCausalLM</div><div id='n_method'> N Class Name: BigBirdForCausalLM</div><div id='m_method'> M Method Name: forward(8)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: BigBirdPretrainedModel</div><div id='n_parent_class'> N Parent Class: BigBirdPretrainedModel</div><div id='m_file'> M File Name: paddlenlp/transformers/bigbird/modeling.py</div><div id='n_file'> N File Name: paddlenlp/transformers/bigbird/modeling.py</div><div id='m_start'> M Start Line: 1164</div><div id='m_end'> M End Line: 1211</div><div id='n_start'> N Start Line: 1558</div><div id='n_end'> N End Line: 1623</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                prediction_scores.reshape(shape=(-1, self.bigbird.config["vocab_size"])),
                labels.reshape(shape=(-1,)),
            )
            <a id="change">return </a>masked_lm_loss, prediction_scores, sequence_output

        return prediction_scores, sequence_output
</code></pre><h3>After Change</h3><pre><code class='java'>


        
        output_attentions = output_attentions<a id="change"> if </a><a id="change">output_attentions is not None else </a>False
        output_hidden_states = output_hidden_states if output_hidden_states is not None else False
        return_dict = return_dict if return_dict is not None else False

        outputs = self.bigbird(input_ids, attention_mask=attention_mask, rand_mask_idx_list=rand_mask_idx_list)
        sequence_output<a id="change"> = </a>outputs[0]
        prediction_scores = self.lm_head(sequence_output)

        <a id="change">masked_lm_loss</a> = None
        if labels is not None:
            loss_fct = nn.CrossEntropyLoss()
            masked_lm_loss = loss_fct(
                prediction_scores.reshape(shape=(-1, self.bigbird.config["vocab_size"])),
                labels.reshape(shape=(-1,)),
            )
        <a id="change">if not return_dict</a>:
            output = (prediction_scores,) + outputs[2:]
            <a id="change">return </a>(
                ((masked_lm_loss<a id="change"></a>,)<a id="change"> + </a>output)<a id="change">
                if </a><a id="change">masked_lm_loss is not None
                else </a>(output[0] if len(output) == 1 else output)
            )

        return <a id="change">MaskedLMOutput(
            loss=masked_lm_loss,
            logits=prediction_scores,
            hidden_states=outputs.hidden_states,
            attentions=outputs.attentions,
        )</a>


class BigBirdForCausalLM(BigBirdPretrainedModel):
    </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/ea41f01c6fee751023d2ec53eed7fb543439ff4e#diff-7da51fd7e434b7611664c7f9ad16f1fce671a0664ae192aeba1d9fab94dbe1b2L1100' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17048705</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: ea41f01c6fee751023d2ec53eed7fb543439ff4e</div><div id='time'> Time: 2023-03-09</div><div id='author'> Author: 115528288+tsinghua-zhang@users.noreply.github.com</div><div id='file'> File Name: paddlenlp/transformers/bigbird/modeling.py</div><div id='m_class'> M Class Name: BigBirdForMaskedLM</div><div id='n_method'> N Class Name: BigBirdForMaskedLM</div><div id='m_method'> M Method Name: forward(8)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: BigBirdPretrainedModel</div><div id='n_parent_class'> N Parent Class: BigBirdPretrainedModel</div><div id='m_file'> M File Name: paddlenlp/transformers/bigbird/modeling.py</div><div id='n_file'> N File Name: paddlenlp/transformers/bigbird/modeling.py</div><div id='m_start'> M Start Line: 1100</div><div id='m_end'> M End Line: 1144</div><div id='n_start'> N Start Line: 1463</div><div id='n_end'> N End Line: 1537</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        assert masked_lm_labels is None
        assert lm_labels is None

        <a id="change">return </a>outputs  &#47&#47  prediction_scores, (hidden_states), (attentions)
</code></pre><h3>After Change</h3><pre><code class='java'>
        assert "lm_labels" not in kwargs, "Use `BertWithLMHead` for autoregressive language modeling task."
        assert kwargs == {}, f"Unexpected keyword arguments: {list(kwargs.keys())}."

        return_dict = return_dict<a id="change"> if </a><a id="change">return_dict is not None else </a>self.config.use_return_dict

        outputs = self.bert(
            input_ids,
            attention_mask=attention_mask,
            token_type_ids=token_type_ids,
            position_ids=position_ids,
            head_mask=head_mask,
            inputs_embeds=inputs_embeds,
            encoder_hidden_states=encoder_hidden_states,
            encoder_attention_mask=encoder_attention_mask,
            output_attentions=output_attentions,
            output_hidden_states=output_hidden_states,
            return_dict=return_dict,
        )

        sequence_output = outputs[0]

        &#47&#47&#47&#47&#47&#47 START MODIFICATION
        &#47&#47 Only apply MLM head to desired positions
        if select_positions is not None:
            sequence_output = sequence_output[[[i] for i in range(sequence_output.shape[0])],select_positions,:]
        &#47&#47&#47&#47&#47&#47 END MODIFICATION

        prediction_scores = self.cls(sequence_output)

        <a id="change">masked_lm_loss</a> = None
        if labels is not None:
            loss_fct = CrossEntropyLoss()  &#47&#47 -100 index = padding token
            masked_lm_loss<a id="change"> = </a>loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))

        <a id="change">if not return_dict</a>:
            output = (prediction_scores,) + outputs[2:]
            <a id="change">return </a>((masked_lm_loss<a id="change"></a>,)<a id="change"> + </a>output)<a id="change"> if </a><a id="change">masked_lm_loss is not None else </a>output

        return <a id="change">MaskedLMOutput(
            loss=masked_lm_loss,
            logits=prediction_scores,
            hidden_states=outputs.hidden_states,
            attentions=outputs.attentions,
        )</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/awslabs/mlm-scoring/commit/9cab61e6774bcc4983f7117f1a280c334f3e68b5#diff-4239f63e33687df5cf396efe44ed7f1d4324d56feaca545873a80dfaf1fbb351L143' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17048721</div><div id='project'> Project Name: awslabs/mlm-scoring</div><div id='commit'> Commit Name: 9cab61e6774bcc4983f7117f1a280c334f3e68b5</div><div id='time'> Time: 2020-10-10</div><div id='author'> Author: julsal@amazon.com</div><div id='file'> File Name: src/mlm/models/bert.py</div><div id='m_class'> M Class Name: BertForMaskedLMOptimized</div><div id='n_method'> N Class Name: BertForMaskedLMOptimized</div><div id='m_method'> M Method Name: forward(14)</div><div id='n_method'> N Method Name: forward(12)</div><div id='m_parent_class'> M Parent Class: BertForMaskedLM</div><div id='n_parent_class'> N Parent Class: transformers.BertForMaskedLM</div><div id='m_file'> M File Name: src/mlm/models/bert.py</div><div id='n_file'> N File Name: src/mlm/models/bert.py</div><div id='m_start'> M Start Line: 151</div><div id='m_end'> M End Line: 218</div><div id='n_start'> N Start Line: 156</div><div id='n_end'> N End Line: 222</div><BR>