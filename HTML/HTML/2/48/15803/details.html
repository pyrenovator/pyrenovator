<html><h3>Pattern ID :15803
</h3><img src='53509744.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        return {**out, "z": z}

    def training_step(self, batch, batch_idx):
        indexes<a id="change">, (X1, X2), target</a> = batch

        <a id="change">out1</a> = <a id="change">self(X1</a><a id="change">)</a>
        <a id="change">out2</a> = <a id="change">self(X2</a><a id="change">)</a>

        z1 = <a id="change">out1["z"]</a>
        z2 = <a id="change">out2["z"]</a>
        logits1<a id="change"> = out1["logits"]</a>
        logits2<a id="change"> = out2["logits"]</a>

        &#47&#47 ------- loss -------
        vicreg_loss = vicreg_loss_func(
            z1,
            z2,
            sim_loss_weight=self.sim_loss_weight,
            var_loss_weight=self.var_loss_weight,
            cov_loss_weight=self.cov_loss_weight,
        )

        &#47&#47 ------- classification loss -------
        <a id="change">logits = </a><a id="change">torch.cat(</a>(logits1<a id="change">, logits2</a>)<a id="change">)</a>
        <a id="change">target = </a><a id="change">target.repeat(2</a><a id="change">)</a>
        class_loss<a id="change"> = </a><a id="change">F.cross_entropy(logits</a>, <a id="change">target</a><a id="change">, ignore_index=-1)</a>

        &#47&#47 just add together the losses to do only one backward()
        &#47&#47 we have stop gradients on the output y of the model
        loss<a id="change"> = </a>vicreg_loss<a id="change"> + </a>class_loss

        &#47&#47 ------- metrics -------
        acc1<a id="change">, acc5 = </a><a id="change">accuracy_at_k(logits</a>, <a id="change">target</a><a id="change">, top_k=(1, 5))</a>

        metrics = {
            "train_vicreg_loss": vicreg_loss,
            "train_class_loss": class_loss,
            "train_acc1": acc1,
            "train_acc5": acc5,
        }
        self.log_dict(metrics, on_epoch=True, sync_dist=True)
        <a id="change">return </a>loss
</code></pre><h3>After Change</h3><pre><code class='java'>
        return {**out, "z": z}

    def training_step(self, batch, batch_idx):
        <a id="change">out</a> = <a id="change">super().training_step(</a>batch, batch_idx<a id="change">)</a>
        class_loss = <a id="change">out["loss"]</a>
        <a id="change">feats1</a><a id="change">, feats2</a> = <a id="change">out["feats"]</a>

        z1 = <a id="change">self.projector(feats1</a><a id="change">)</a>
        z2 = <a id="change">self.projector(feats2</a><a id="change">)</a>

        &#47&#47 ------- barlow twins loss -------
        vicreg_loss = vicreg_loss_func(
            z1,
            z2,
            sim_loss_weight=self.sim_loss_weight,
            var_loss_weight=self.var_loss_weight,
            cov_loss_weight=self.cov_loss_weight,
        )

        self.log("train_vicreg_loss", vicreg_loss, on_epoch=True, sync_dist=True)

        <a id="change">return </a>vicreg_loss<a id="change"> + </a>class_loss
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 33</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/vturrisi/contrastive-learning/commit/a47bb52eeeb836a919c105a9dcd27930c9124ec4#diff-d205e6feb463c552804d01782ab270db5e1bb3e716194fa9f26a1872b5b384e2L59' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 53509744</div><div id='project'> Project Name: vturrisi/contrastive-learning</div><div id='commit'> Commit Name: a47bb52eeeb836a919c105a9dcd27930c9124ec4</div><div id='time'> Time: 2021-06-14</div><div id='author'> Author: vt.turrisi@gmail.com</div><div id='file'> File Name: solo/methods/vicreg.py</div><div id='m_class'> M Class Name: VICReg</div><div id='n_method'> N Class Name: VICReg</div><div id='m_method'> M Method Name: training_step(3)</div><div id='n_method'> N Method Name: training_step(3)</div><div id='m_parent_class'> M Parent Class: BaseModel</div><div id='n_parent_class'> N Parent Class: BaseModel</div><div id='m_file'> M File Name: solo/methods/vicreg.py</div><div id='n_file'> N File Name: solo/methods/vicreg.py</div><div id='m_start'> M Start Line: 59</div><div id='m_end'> M End Line: 97</div><div id='n_start'> N Start Line: 59</div><div id='n_end'> N End Line: 77</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        return {**out, "z": z}

    def training_step(self, batch, batch_idx):
        indexes<a id="change">, (X1, X2), target</a> = batch

        <a id="change">out1</a> = <a id="change">self(</a>X1<a id="change">)</a>
        <a id="change">out2</a> = <a id="change">self(</a>X2<a id="change">)</a>

        z1 = <a id="change">out1["z"]</a>
        z2 = <a id="change">out2["z"]</a>
        logits1<a id="change"> = out1["logits"]</a>
        logits2<a id="change"> = out2["logits"]</a>

        &#47&#47 ------- contrastive loss -------
        barlow_loss = barlow_loss_func(z1, z2, lamb=self.lamb, scale_loss=self.scale_loss)

        &#47&#47 ------- classification loss -------
        <a id="change">logits = </a><a id="change">torch.cat(</a>(logits1<a id="change">, logits2</a>)<a id="change">)</a>
        <a id="change">target = </a><a id="change">target.repeat(2</a><a id="change">)</a>
        class_loss<a id="change"> = </a><a id="change">F.cross_entropy(</a>logits, target<a id="change">, ignore_index=-1)</a>

        &#47&#47 just add together the losses to do only one backward()
        &#47&#47 we have stop gradients on the output y of the model
        loss<a id="change"> = </a>barlow_loss<a id="change"> + </a>class_loss

        &#47&#47 ------- metrics -------
        acc1<a id="change">, acc5 = </a><a id="change">accuracy_at_k(</a>logits, target<a id="change">, top_k=(1, 5))</a>

        metrics = {
            "train_barlow_loss": barlow_loss,
            "train_class_loss": class_loss,
            "train_acc1": acc1,
            "train_acc5": acc5,
        }
        self.log_dict(metrics, on_epoch=True, sync_dist=True)
        <a id="change">return </a>loss
</code></pre><h3>After Change</h3><pre><code class='java'>
        return {**out, "z": z}

    def training_step(self, batch, batch_idx):
        <a id="change">out</a> = <a id="change">super().training_step(</a>batch, batch_idx<a id="change">)</a>
        class_loss = <a id="change">out["loss"]</a>
        feats1<a id="change">, feats2</a> = <a id="change">out["feats"]</a>

        z1 = <a id="change">self.projector(</a>feats1<a id="change">)</a>
        z2 = <a id="change">self.projector(</a>feats2<a id="change">)</a>

        &#47&#47 ------- barlow twins loss -------
        barlow_loss = barlow_loss_func(z1, z2, lamb=self.lamb, scale_loss=self.scale_loss)

        self.log("train_barlow_loss", barlow_loss, on_epoch=True, sync_dist=True)

        <a id="change">return </a>barlow_loss<a id="change"> + </a>class_loss
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/vturrisi/contrastive-learning/commit/a47bb52eeeb836a919c105a9dcd27930c9124ec4#diff-2194e93583f830d73685bc44051ad0c55241b07d4882a10f22f40caad74a053dL48' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 53509745</div><div id='project'> Project Name: vturrisi/contrastive-learning</div><div id='commit'> Commit Name: a47bb52eeeb836a919c105a9dcd27930c9124ec4</div><div id='time'> Time: 2021-06-14</div><div id='author'> Author: vt.turrisi@gmail.com</div><div id='file'> File Name: solo/methods/barlow_twins.py</div><div id='m_class'> M Class Name: BarlowTwins</div><div id='n_method'> N Class Name: BarlowTwins</div><div id='m_method'> M Method Name: training_step(3)</div><div id='n_method'> N Method Name: training_step(3)</div><div id='m_parent_class'> M Parent Class: BaseModel</div><div id='n_parent_class'> N Parent Class: BaseModel</div><div id='m_file'> M File Name: solo/methods/barlow_twins.py</div><div id='n_file'> N File Name: solo/methods/barlow_twins.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 81</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 61</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        return assignments

    def training_step(self, batch, batch_idx):
        indexes<a id="change">, (X1, X2), target</a> = batch

        <a id="change">out1</a> = <a id="change">self(</a>X1<a id="change">)</a>
        <a id="change">out2</a> = <a id="change">self(</a>X2<a id="change">)</a>

        z1 = out1["z"]
        z2 = <a id="change">out2["z"]</a>
        p1 = <a id="change">out1["p"]</a>
        p2 = out2["p"]
        logits1<a id="change"> = out1["logits"]</a>
        logits2<a id="change"> = out2["logits"]</a>

        &#47&#47 ------- swav loss -------
        preds = [p1, p2]
        assignments = self.get_assignments(preds)
        swav_loss = swav_loss_func(preds, assignments, self.temperature)

        &#47&#47 ------- classification loss -------
        <a id="change">logits = </a><a id="change">torch.cat(</a>(logits1<a id="change">, logits2</a>)<a id="change">)</a>
        <a id="change">target = </a><a id="change">target.repeat(2</a><a id="change">)</a>
        class_loss<a id="change"> = </a><a id="change">F.cross_entropy(</a>logits, target<a id="change">, ignore_index=-1)</a>

        &#47&#47 just add together the losses to do only one backward()
        &#47&#47 we have stop gradients on the output y of the model
        loss<a id="change"> = </a>swav_loss<a id="change"> + </a>class_loss

        &#47&#47 ------- update queue -------
        if self.queue_size &gt; 0:
            z = torch.stack((z1, z2))
            self.queue[:, z.size(1) :] = self.queue[:, : -z.size(1)].clone()
            self.queue[:, : z.size(1)] = z.detach()

        &#47&#47 ------- metrics -------
        acc1<a id="change">, acc5 = </a><a id="change">accuracy_at_k(</a>logits, target<a id="change">, top_k=(1, 5))</a>

        metrics = {
            "train_ce_loss": swav_loss,
            "train_class_loss": class_loss,
            "train_acc1": acc1,
            "train_acc5": acc5,
        }
        self.log_dict(metrics, on_epoch=True, sync_dist=True)
        <a id="change">return </a>loss

    def on_after_backward(self):
        if self.current_epoch &lt; self.freeze_prototypes_epochs:</code></pre><h3>After Change</h3><pre><code class='java'>
        return assignments

    def training_step(self, batch, batch_idx):
        <a id="change">out</a> = <a id="change">super().training_step(</a>batch, batch_idx<a id="change">)</a>
        class_loss = <a id="change">out["loss"]</a>
        feats1<a id="change">, feats2</a> = <a id="change">out["feats"]</a>

        z1 = <a id="change">self.projector(</a>feats1<a id="change">)</a>
        z2 = <a id="change">self.projector(</a>feats2<a id="change">)</a>

        p1 = self.prototypes(z1)
        p2 = self.prototypes(z2)

        &#47&#47 ------- swav loss -------
        preds = [p1, p2]
        assignments = self.get_assignments(preds)
        swav_loss = swav_loss_func(preds, assignments, self.temperature)

        &#47&#47 ------- update queue -------
        if self.queue_size &gt; 0:
            z = torch.stack((z1, z2))
            self.queue[:, z.size(1) :] = self.queue[:, : -z.size(1)].clone()
            self.queue[:, : z.size(1)] = z.detach()

        self.log("train_swav_loss", swav_loss, on_epoch=True, sync_dist=True)

        <a id="change">return </a>swav_loss<a id="change"> + </a>class_loss

    def on_after_backward(self):
        if self.current_epoch &lt; self.freeze_prototypes_epochs:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/vturrisi/contrastive-learning/commit/a47bb52eeeb836a919c105a9dcd27930c9124ec4#diff-bb8445b4ca8fa0a6b43e693fd3f434309f694da66a1bbd5e4773270586552023L110' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 53509743</div><div id='project'> Project Name: vturrisi/contrastive-learning</div><div id='commit'> Commit Name: a47bb52eeeb836a919c105a9dcd27930c9124ec4</div><div id='time'> Time: 2021-06-14</div><div id='author'> Author: vt.turrisi@gmail.com</div><div id='file'> File Name: solo/methods/swav.py</div><div id='m_class'> M Class Name: SwAV</div><div id='n_method'> N Class Name: SwAV</div><div id='m_method'> M Method Name: training_step(3)</div><div id='n_method'> N Method Name: training_step(3)</div><div id='m_parent_class'> M Parent Class: BaseModel</div><div id='n_parent_class'> N Parent Class: BaseModel</div><div id='m_file'> M File Name: solo/methods/swav.py</div><div id='n_file'> N File Name: solo/methods/swav.py</div><div id='m_start'> M Start Line: 111</div><div id='m_end'> M End Line: 153</div><div id='n_start'> N Start Line: 116</div><div id='n_end'> N End Line: 139</div><BR>