<html><h3>Pattern ID :14705
</h3><img src='48472627.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                out, l1 = self.model(elements_to_predict, last=True)
                
                &#47&#47 Insert the calculated batch of probabilities into the tensor to return
                <a id="change">embedding[element_idxs]</a> = l1

        return embedding
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Create a dataloader object to load the dataset
        to_predict_dataloader = DataLoader(to_predict_dataset, batch_size = self.args[&quotbatch_size&quot], shuffle = False)
        
        evaluated_instances<a id="change"> = 0</a>
        
        with torch.no_grad():

            for batch_idx, <a id="change">elements_to_predict</a> in enumerate(to_predict_dataloader):
                
                &#47&#47 Calculate softmax (probabilities) of predictions
                elements_to_predict = elements_to_predict.to(self.device)
                out, l1 = self.model(elements_to_predict, last=True)
                
                &#47&#47 Insert the calculated batch of probabilities into the tensor to return
                <a id="change">start_slice</a> = evaluated_instances
                <a id="change">end_slice = start_slice</a><a id="change"> + elements_to_predict.shape[0]</a>
                <a id="change">embedding[start_slice:end_slice] = </a>l1
                evaluated_instances<a id="change"> = end_slice</a>

        return embedding

    &#47&#47 gradient embedding (assumes cross-entropy loss)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/decile-team/distil/commit/78643fe4ad3a4a4967d5dbc15b4bdc1bc9d2d0df#diff-3470b89e58cfe62c9cd50e1c274adc927700bbab6aa4b09ec19696ef44fad9d2L141' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 48472627</div><div id='project'> Project Name: decile-team/distil</div><div id='commit'> Commit Name: 78643fe4ad3a4a4967d5dbc15b4bdc1bc9d2d0df</div><div id='time'> Time: 2021-06-21</div><div id='author'> Author: nab170130@utdallas.edu</div><div id='file'> File Name: distil/scalable_active_learning_strategies/strategy.py</div><div id='m_class'> M Class Name: Strategy</div><div id='n_method'> N Class Name: Strategy</div><div id='m_method'> M Method Name: get_embedding(2)</div><div id='n_method'> N Method Name: get_embedding(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: distil/scalable_active_learning_strategies/strategy.py</div><div id='n_file'> N File Name: distil/scalable_active_learning_strategies/strategy.py</div><div id='m_start'> M Start Line: 141</div><div id='m_end'> M End Line: 152</div><div id='n_start'> N Start Line: 173</div><div id='n_end'> N End Line: 192</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.model = self.model.to(self.device)
        
        &#47&#47 Create a tensor to hold embeddings
        <a id="change">embedding</a> = torch.zeros([len(to_predict_dataloader.dataset), self.model.get_embedding_dim()]).to(self.device)
        
        with torch.no_grad():

            for batch_idx, (elements_to_predict, element_idxs) in enumerate(to_predict_dataloader):
                
                &#47&#47 Calculate softmax (probabilities) of predictions
                elements_to_predict = elements_to_predict.to(self.device)
                out, l1 = self.model(elements_to_predict, last=True)
                
                &#47&#47 Insert the calculated batch of probabilities into the tensor to return
                <a id="change">embedding[element_idxs]</a> = l1

        return embedding
</code></pre><h3>After Change</h3><pre><code class='java'>
        self.model = self.model.to(self.device)
        
        &#47&#47 Create a tensor to hold embeddings
        <a id="change">embedding</a> = torch.zeros([len(to_predict_dataset), self.model.get_embedding_dim()]).to(self.device)
        
        &#47&#47 Create a dataloader object to load the dataset
        to_predict_dataloader = DataLoader(to_predict_dataset, batch_size = self.args[&quotbatch_size&quot], shuffle = False)
        
        evaluated_instances<a id="change"> = 0</a>
        
        with torch.no_grad():

            for batch_idx, <a id="change">elements_to_predict</a> in enumerate(to_predict_dataloader):
                
                &#47&#47 Calculate softmax (probabilities) of predictions
                elements_to_predict = elements_to_predict.to(self.device)
                out, l1 = self.model(elements_to_predict, last=True)
                
                &#47&#47 Insert the calculated batch of probabilities into the tensor to return
                <a id="change">start_slice</a> = evaluated_instances
                <a id="change">end_slice = </a>start_slice<a id="change"> + elements_to_predict.shape[0]</a>
                <a id="change">embedding[start_slice:end_slice] = </a>l1
                evaluated_instances<a id="change"> = </a>end_slice

        return embedding
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/decile-team/distil/commit/78643fe4ad3a4a4967d5dbc15b4bdc1bc9d2d0df#diff-3470b89e58cfe62c9cd50e1c274adc927700bbab6aa4b09ec19696ef44fad9d2L134' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 48472631</div><div id='project'> Project Name: decile-team/distil</div><div id='commit'> Commit Name: 78643fe4ad3a4a4967d5dbc15b4bdc1bc9d2d0df</div><div id='time'> Time: 2021-06-21</div><div id='author'> Author: nab170130@utdallas.edu</div><div id='file'> File Name: distil/scalable_active_learning_strategies/strategy.py</div><div id='m_class'> M Class Name: Strategy</div><div id='n_method'> N Class Name: Strategy</div><div id='m_method'> M Method Name: get_embedding(2)</div><div id='n_method'> N Method Name: get_embedding(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: distil/scalable_active_learning_strategies/strategy.py</div><div id='n_file'> N File Name: distil/scalable_active_learning_strategies/strategy.py</div><div id='m_start'> M Start Line: 141</div><div id='m_end'> M End Line: 152</div><div id='n_start'> N Start Line: 173</div><div id='n_end'> N End Line: 192</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.model = self.model.to(self.device)
        
        &#47&#47 Create a tensor to hold probabilities
        <a id="change">probs</a> = torch.zeros([len(to_predict_dataloader.dataset), self.target_classes]).to(self.device)
        
        with torch.no_grad():
            for batch_idx, (elements_to_predict, element_idxs) in enumerate(to_predict_dataloader):
                
                &#47&#47 Calculate softmax (probabilities) of predictions
                elements_to_predict = elements_to_predict.to(self.device)
                out = self.model(elements_to_predict)
                pred = F.softmax(out, dim=1)
                
                &#47&#47 Insert the calculated batch of probabilities into the tensor to return
                <a id="change">probs[element_idxs]</a> = pred

        return probs        
</code></pre><h3>After Change</h3><pre><code class='java'>
        self.model = self.model.to(self.device)
        
        &#47&#47 Create a tensor to hold probabilities
        <a id="change">probs</a> = torch.zeros([len(to_predict_dataset), self.target_classes]).to(self.device)
        
        &#47&#47 Create a dataloader object to load the dataset
        to_predict_dataloader = DataLoader(to_predict_dataset, batch_size = self.args[&quotbatch_size&quot], shuffle = False)
        
        evaluated_instances<a id="change"> = 0</a>
        
        with torch.no_grad():
            for batch_idx, <a id="change">elements_to_predict</a> in enumerate(to_predict_dataloader):
                
                &#47&#47 Calculate softmax (probabilities) of predictions
                elements_to_predict = elements_to_predict.to(self.device)
                out = self.model(elements_to_predict)
                pred = F.softmax(out, dim=1)
                
                &#47&#47 Insert the calculated batch of probabilities into the tensor to return
                <a id="change">start_slice</a> = evaluated_instances
                <a id="change">end_slice = </a>start_slice<a id="change"> + elements_to_predict.shape[0]</a>
                <a id="change">probs[start_slice:end_slice] = </a>pred
                evaluated_instances<a id="change"> = </a>end_slice

        return probs        
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/decile-team/distil/commit/78643fe4ad3a4a4967d5dbc15b4bdc1bc9d2d0df#diff-3470b89e58cfe62c9cd50e1c274adc927700bbab6aa4b09ec19696ef44fad9d2L57' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 48472629</div><div id='project'> Project Name: decile-team/distil</div><div id='commit'> Commit Name: 78643fe4ad3a4a4967d5dbc15b4bdc1bc9d2d0df</div><div id='time'> Time: 2021-06-21</div><div id='author'> Author: nab170130@utdallas.edu</div><div id='file'> File Name: distil/scalable_active_learning_strategies/strategy.py</div><div id='m_class'> M Class Name: Strategy</div><div id='n_method'> N Class Name: Strategy</div><div id='m_method'> M Method Name: predict_prob(2)</div><div id='n_method'> N Method Name: predict_prob(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: distil/scalable_active_learning_strategies/strategy.py</div><div id='n_file'> N File Name: distil/scalable_active_learning_strategies/strategy.py</div><div id='m_start'> M Start Line: 64</div><div id='m_end'> M End Line: 75</div><div id='n_start'> N Start Line: 74</div><div id='n_end'> N End Line: 93</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.model = self.model.to(self.device)
        
        &#47&#47 Create a tensor to hold class predictions
        <a id="change">P</a> = torch.zeros(len(to_predict_dataloader.dataset)).long().to(self.device)
        
        with torch.no_grad():
            for batch_idx, (elements_to_predict, element_idxs) in enumerate(to_predict_dataloader):
                
                &#47&#47 Predict the most likely class
                elements_to_predict = elements_to_predict.to(self.device)
                out = self.model(elements_to_predict)
                pred = out.max(1)[1]
                
                &#47&#47 Insert the calculated batch of predictions into the tensor to return
                <a id="change">P[element_idxs]</a> = pred
                
        return P
</code></pre><h3>After Change</h3><pre><code class='java'>
        self.model = self.model.to(self.device)
        
        &#47&#47 Create a tensor to hold class predictions
        <a id="change">P</a> = torch.zeros(len(to_predict_dataset)).long().to(self.device)
        
        &#47&#47 Create a dataloader object to load the dataset
        to_predict_dataloader = DataLoader(to_predict_dataset, batch_size = self.args[&quotbatch_size&quot], shuffle = False)
        
        evaluated_instances<a id="change"> = 0</a>
        
        with torch.no_grad():
            for batch_idx, <a id="change">elements_to_predict</a> in enumerate(to_predict_dataloader):
                
                &#47&#47 Predict the most likely class
                elements_to_predict = elements_to_predict.to(self.device)
                out = self.model(elements_to_predict)
                pred = out.max(1)[1]
                
                &#47&#47 Insert the calculated batch of predictions into the tensor to return
                <a id="change">start_slice</a> = evaluated_instances
                <a id="change">end_slice = </a>start_slice<a id="change"> + elements_to_predict.shape[0]</a>
                <a id="change">P[start_slice:end_slice] = </a>pred
                evaluated_instances<a id="change"> = </a>end_slice
                
        return P
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/decile-team/distil/commit/78643fe4ad3a4a4967d5dbc15b4bdc1bc9d2d0df#diff-3470b89e58cfe62c9cd50e1c274adc927700bbab6aa4b09ec19696ef44fad9d2L35' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 48472638</div><div id='project'> Project Name: decile-team/distil</div><div id='commit'> Commit Name: 78643fe4ad3a4a4967d5dbc15b4bdc1bc9d2d0df</div><div id='time'> Time: 2021-06-21</div><div id='author'> Author: nab170130@utdallas.edu</div><div id='file'> File Name: distil/scalable_active_learning_strategies/strategy.py</div><div id='m_class'> M Class Name: Strategy</div><div id='n_method'> N Class Name: Strategy</div><div id='m_method'> M Method Name: predict(2)</div><div id='n_method'> N Method Name: predict(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: distil/scalable_active_learning_strategies/strategy.py</div><div id='n_file'> N File Name: distil/scalable_active_learning_strategies/strategy.py</div><div id='m_start'> M Start Line: 42</div><div id='m_end'> M End Line: 53</div><div id='n_start'> N Start Line: 44</div><div id='n_end'> N End Line: 63</div><BR>