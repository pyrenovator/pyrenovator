<html><h3>Pattern ID :21663
</h3><img src='69165214.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
class MultiStepDecay(LRScheduler):

    def __init__(self, learning_rate, milestones, gamma=0.1, last_epoch=-1, verbose=False):
        <a id="change">pass</a>

    def get_lr(self):
        raise NotImplementedError
</code></pre><h3>After Change</h3><pre><code class='java'>
class MultiStepDecay(LRScheduler):

    def __init__(self, learning_rate, milestones, gamma=0.1, last_epoch=-1, verbose=False):
        <a id="change">if not isinstance(milestones, (tuple, list))</a>:
            <a id="change">raise TypeError(
                "The type of &quotmilestones&quot in &quotMultiStepDecay&quot must be &quottuple, list&quot, but received %s."</a><a id="change"> %
                type(milestones</a><a id="change">)</a><a id="change">
            )</a>

        if not all([milestones[i] &lt; milestones[i + 1] for i in range(len(milestones) - 1)]):
            raise ValueError(&quotThe elements of milestones must be incremented&quot)
        <a id="change">if </a>gamma &gt;= 1.0:
            <a id="change">raise </a>ValueError(&quotgamma should be &lt; 1.0.&quot)

        self.milestones<a id="change"> = milestones</a>
        self.gamma<a id="change"> = </a>gamma
        <a id="change">super(MultiStepDecay, self).__init__(</a>learning_rate, last_epoch, verbose<a id="change">)</a>

    def get_lr(self):
        for i in range(len(self.milestones)):
            if self.last_epoch &lt; self.milestones[i]:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 14</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayerx/commit/cbef9e40fbc27064050f8fbadc064427b7729213#diff-4c2860296a3ecee6057b4fdb6135c346e3d472a96bb8bb9b1c0ce1f599bd4719L118' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69165214</div><div id='project'> Project Name: tensorlayer/tensorlayerx</div><div id='commit'> Commit Name: cbef9e40fbc27064050f8fbadc064427b7729213</div><div id='time'> Time: 2022-04-11</div><div id='author'> Author: jiaronghan@outlook.com</div><div id='file'> File Name: tensorlayerx/optimizers/lr/torch_lr.py</div><div id='m_class'> M Class Name: MultiStepDecay</div><div id='n_method'> N Class Name: MultiStepDecay</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: LRScheduler</div><div id='n_parent_class'> N Parent Class: LRScheduler</div><div id='m_file'> M File Name: tensorlayerx/optimizers/lr/torch_lr.py</div><div id='n_file'> N File Name: tensorlayerx/optimizers/lr/torch_lr.py</div><div id='m_start'> M Start Line: 118</div><div id='m_end'> M End Line: 118</div><div id='n_start'> N Start Line: 256</div><div id='n_end'> N End Line: 269</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
class MultiStepDecay(LRScheduler):

    def __init__(self, learning_rate, milestones, gamma=0.1, last_epoch=-1, verbose=False):
        <a id="change">pass</a>

    def get_lr(self):
        raise NotImplementedError
</code></pre><h3>After Change</h3><pre><code class='java'>
class MultiStepDecay(LRScheduler):

    def __init__(self, learning_rate, milestones, gamma=0.1, last_epoch=-1, verbose=False):
        <a id="change">if not isinstance(milestones, (tuple, list))</a>:
            <a id="change">raise TypeError(
                "The type of &quotmilestones&quot in &quotMultiStepDecay&quot must be &quottuple, list&quot, but received %s."</a><a id="change"> %
                type(</a>milestones<a id="change">)</a><a id="change">
            )</a>

        <a id="change">if </a>not all([milestones[i] &lt; milestones[i + 1] for i in range(len(milestones) - 1)]):
            raise ValueError(&quotThe elements of milestones must be incremented&quot)
        if gamma &gt;= 1.0:
            <a id="change">raise </a>ValueError(&quotgamma should be &lt; 1.0.&quot)

        self.milestones<a id="change"> = </a>milestones
        self.gamma<a id="change"> = </a>gamma
        <a id="change">super(MultiStepDecay, self).__init__(</a>learning_rate, last_epoch, verbose<a id="change">)</a>

    def get_lr(self):
        for i in range(len(self.milestones)):
            if self.last_epoch &lt; self.milestones[i]:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayerx/commit/cbef9e40fbc27064050f8fbadc064427b7729213#diff-4c2860296a3ecee6057b4fdb6135c346e3d472a96bb8bb9b1c0ce1f599bd4719L117' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69165212</div><div id='project'> Project Name: tensorlayer/tensorlayerx</div><div id='commit'> Commit Name: cbef9e40fbc27064050f8fbadc064427b7729213</div><div id='time'> Time: 2022-04-11</div><div id='author'> Author: jiaronghan@outlook.com</div><div id='file'> File Name: tensorlayerx/optimizers/lr/torch_lr.py</div><div id='m_class'> M Class Name: MultiStepDecay</div><div id='n_method'> N Class Name: MultiStepDecay</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: LRScheduler</div><div id='n_parent_class'> N Parent Class: LRScheduler</div><div id='m_file'> M File Name: tensorlayerx/optimizers/lr/torch_lr.py</div><div id='n_file'> N File Name: tensorlayerx/optimizers/lr/torch_lr.py</div><div id='m_start'> M Start Line: 118</div><div id='m_end'> M End Line: 118</div><div id='n_start'> N Start Line: 256</div><div id='n_end'> N End Line: 269</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
class CosineAnnealingDecay(LRScheduler):

    def __init__(self, learning_rate, T_max, eta_min=0, last_epoch=-1, verbose=False):
        <a id="change">pass</a>

    def get_lr(self):
        raise NotImplementedError
</code></pre><h3>After Change</h3><pre><code class='java'>
class CosineAnnealingDecay(LRScheduler):

    def __init__(self, learning_rate, T_max, eta_min=0, last_epoch=-1, verbose=False):
        <a id="change">if not isinstance(T_max, int)</a>:
            <a id="change">raise TypeError(
                "The type of &quotT_max&quot in &quotCosineAnnealingDecay&quot must be &quotint&quot, but received %s."</a><a id="change"> % type(</a>T_max<a id="change">)</a><a id="change">
            )</a>
        <a id="change">if </a>not isinstance(eta_min, (float, int)):
            <a id="change">raise </a>TypeError(
                "The type of &quoteta_min&quot in &quotCosineAnnealingDecay&quot must be &quotfloat, int&quot, but received %s." %
                type(eta_min)
            )
        self.T_max<a id="change"> = </a>T_max
        self.eta_min<a id="change"> = </a>float(eta_min)
        <a id="change">super(CosineAnnealingDecay, self).__init__(</a>learning_rate, last_epoch, verbose<a id="change">)</a>

    def get_lr(self):
        if self.last_epoch == 0:
            return self.base_lr</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayerx/commit/cbef9e40fbc27064050f8fbadc064427b7729213#diff-4c2860296a3ecee6057b4fdb6135c346e3d472a96bb8bb9b1c0ce1f599bd4719L42' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69165208</div><div id='project'> Project Name: tensorlayer/tensorlayerx</div><div id='commit'> Commit Name: cbef9e40fbc27064050f8fbadc064427b7729213</div><div id='time'> Time: 2022-04-11</div><div id='author'> Author: jiaronghan@outlook.com</div><div id='file'> File Name: tensorlayerx/optimizers/lr/torch_lr.py</div><div id='m_class'> M Class Name: CosineAnnealingDecay</div><div id='n_method'> N Class Name: CosineAnnealingDecay</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: LRScheduler</div><div id='n_parent_class'> N Parent Class: LRScheduler</div><div id='m_file'> M File Name: tensorlayerx/optimizers/lr/torch_lr.py</div><div id='n_file'> N File Name: tensorlayerx/optimizers/lr/torch_lr.py</div><div id='m_start'> M Start Line: 43</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 113</div><div id='n_end'> N End Line: 124</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
class StepDecay(LRScheduler):

    def __init__(self, learning_rate, step_size, gamma=0.1, last_epoch=-1, verbose=False):
        <a id="change">pass</a>

    def get_lr(self):
        raise NotImplementedError
</code></pre><h3>After Change</h3><pre><code class='java'>
class StepDecay(LRScheduler):

    def __init__(self, learning_rate, step_size, gamma=0.1, last_epoch=-1, verbose=False):
        <a id="change">if not isinstance(step_size, int)</a>:
            <a id="change">raise TypeError("The type of &quotstep_size&quot must be &quotint&quot, but received %s."</a><a id="change"> % type(</a>step_size<a id="change">)</a><a id="change">)</a>
        <a id="change">if </a>gamma &gt;= 1.0:
            <a id="change">raise </a>ValueError(&quotgamma should be &lt; 1.0.&quot)
        self.step_size<a id="change"> = </a>step_size
        self.gamma<a id="change"> = </a>gamma
        <a id="change">super(StepDecay, self).__init__(</a>learning_rate, last_epoch, verbose<a id="change">)</a>

    def get_lr(self):
        i = self.last_epoch // self.step_size
        return self.base_lr * (self.gamma**i)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayerx/commit/cbef9e40fbc27064050f8fbadc064427b7729213#diff-4c2860296a3ecee6057b4fdb6135c346e3d472a96bb8bb9b1c0ce1f599bd4719L33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69165207</div><div id='project'> Project Name: tensorlayer/tensorlayerx</div><div id='commit'> Commit Name: cbef9e40fbc27064050f8fbadc064427b7729213</div><div id='time'> Time: 2022-04-11</div><div id='author'> Author: jiaronghan@outlook.com</div><div id='file'> File Name: tensorlayerx/optimizers/lr/torch_lr.py</div><div id='m_class'> M Class Name: StepDecay</div><div id='n_method'> N Class Name: StepDecay</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: LRScheduler</div><div id='n_parent_class'> N Parent Class: LRScheduler</div><div id='m_file'> M File Name: tensorlayerx/optimizers/lr/torch_lr.py</div><div id='n_file'> N File Name: tensorlayerx/optimizers/lr/torch_lr.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 34</div><div id='n_start'> N Start Line: 97</div><div id='n_end'> N End Line: 103</div><BR>