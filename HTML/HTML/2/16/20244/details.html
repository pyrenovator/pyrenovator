<html><h3>Pattern ID :20244
</h3><img src='65938254.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        init_zero = False
    ):
        super().__init__()
        self.scale = dim_head<a id="change"> ** -0.5</a><a id="change"> if not cosine_sim_attn</a><a id="change"> else </a>1.
        self.causal = causal

        self.cosine_sim_attn<a id="change"> = cosine_sim_attn</a>
        self.cosine_sim_scale = 16<a id="change"> if cosine_sim_attn</a><a id="change"> else </a>1

        self.rel_pos_bias = DynamicPositionBias(dim = dim, heads = heads, depth = rel_pos_bias_mlp_depth) if rel_pos_bias else None
</code></pre><h3>After Change</h3><pre><code class='java'>
        self.to_q = nn.Linear(dim, inner_dim, bias = False)
        self.to_kv = nn.Linear(dim, dim_head * 2, bias = False)

        self.q_scale<a id="change"> = nn</a><a id="change">.Parameter(torch</a><a id="change">.ones(dim_head</a><a id="change">))</a>
        self.k_scale<a id="change"> = nn</a><a id="change">.Parameter(torch.ones(dim_head</a><a id="change">)</a><a id="change">)</a>

        self.to_context = nn.Sequential(nn.LayerNorm(context_dim), nn.Linear(context_dim, dim_head * 2)) if exists(context_dim) else None

        self.to_out = nn.Sequential(</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 6</div><BR><div id='size'>Non-data size: 11</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/e021548bc31a5132c3f99c1a9ac041f81e6d8b69#diff-87b27a2606d89bf8c64b738a6a3fcfdb0699b7a362ada843cfa9dc9feeaf6eb4L447' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 65938254</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: e021548bc31a5132c3f99c1a9ac041f81e6d8b69</div><div id='time'> Time: 2023-02-13</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/imagen_video.py</div><div id='m_class'> M Class Name: Attention</div><div id='n_method'> N Class Name: Attention</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imagen_pytorch/imagen_video.py</div><div id='n_file'> N File Name: imagen_pytorch/imagen_video.py</div><div id='m_start'> M Start Line: 448</div><div id='m_end'> M End Line: 452</div><div id='n_start'> N Start Line: 447</div><div id='n_end'> N End Line: 464</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        cosine_sim_attn = False
    ):
        super().__init__()
        self.scale = dim_head<a id="change"> ** -0.5</a><a id="change"> if not cosine_sim_attn</a><a id="change"> else </a>1.
        self.cosine_sim_attn<a id="change"> = </a>cosine_sim_attn
        self.cosine_sim_scale = 16<a id="change"> if </a>cosine_sim_attn<a id="change"> else </a>1

        self.heads = heads
        inner_dim = dim_head * heads</code></pre><h3>After Change</h3><pre><code class='java'>
        self.to_q = nn.Linear(dim, inner_dim, bias = False)
        self.to_kv = nn.Linear(context_dim, inner_dim * 2, bias = False)

        self.q_scale<a id="change"> = </a><a id="change">nn.Parameter(</a><a id="change">torch.ones(</a>dim_head<a id="change">))</a>
        self.k_scale<a id="change"> = </a><a id="change">nn.Parameter(torch.ones(</a>dim_head<a id="change">)</a><a id="change">)</a>

        self.to_out = nn.Sequential(
            nn.Linear(inner_dim, dim, bias = False),
            LayerNorm(dim)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/e021548bc31a5132c3f99c1a9ac041f81e6d8b69#diff-edef3c5fe92797a22c0b8fc6cca1d57b4b84ef03dfdfe802ed9147e21fc88109L756' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 65938270</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: e021548bc31a5132c3f99c1a9ac041f81e6d8b69</div><div id='time'> Time: 2023-02-13</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_class'> M Class Name: CrossAttention</div><div id='n_method'> N Class Name: CrossAttention</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imagen_pytorch/imagen_pytorch.py</div><div id='n_file'> N File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_start'> M Start Line: 767</div><div id='m_end'> M End Line: 769</div><div id='n_start'> N Start Line: 767</div><div id='n_end'> N End Line: 782</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        init_zero = False
    ):
        super().__init__()
        self.scale = dim_head<a id="change"> ** -0.5</a><a id="change"> if not cosine_sim_attn</a><a id="change"> else </a>1.
        self.causal = causal

        self.cosine_sim_attn<a id="change"> = </a>cosine_sim_attn
        self.cosine_sim_scale = 16<a id="change"> if </a>cosine_sim_attn<a id="change"> else </a>1

        self.rel_pos_bias = DynamicPositionBias(dim = dim, heads = heads, depth = rel_pos_bias_mlp_depth) if rel_pos_bias else None
</code></pre><h3>After Change</h3><pre><code class='java'>
        self.to_q = nn.Linear(dim, inner_dim, bias = False)
        self.to_kv = nn.Linear(dim, dim_head * 2, bias = False)

        self.q_scale<a id="change"> = </a><a id="change">nn.Parameter(</a><a id="change">torch.ones(</a>dim_head<a id="change">))</a>
        self.k_scale<a id="change"> = </a><a id="change">nn.Parameter(torch.ones(</a>dim_head<a id="change">)</a><a id="change">)</a>

        self.to_context = nn.Sequential(nn.LayerNorm(context_dim), nn.Linear(context_dim, dim_head * 2)) if exists(context_dim) else None

        self.to_out = nn.Sequential(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/e021548bc31a5132c3f99c1a9ac041f81e6d8b69#diff-87b27a2606d89bf8c64b738a6a3fcfdb0699b7a362ada843cfa9dc9feeaf6eb4L434' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 65938255</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: e021548bc31a5132c3f99c1a9ac041f81e6d8b69</div><div id='time'> Time: 2023-02-13</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/imagen_video.py</div><div id='m_class'> M Class Name: Attention</div><div id='n_method'> N Class Name: Attention</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imagen_pytorch/imagen_video.py</div><div id='n_file'> N File Name: imagen_pytorch/imagen_video.py</div><div id='m_start'> M Start Line: 448</div><div id='m_end'> M End Line: 452</div><div id='n_start'> N Start Line: 447</div><div id='n_end'> N End Line: 464</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        cosine_sim_attn = False
    ):
        super().__init__()
        self.scale = dim_head<a id="change"> ** -0.5</a><a id="change"> if not cosine_sim_attn</a><a id="change"> else </a>1
        self.cosine_sim_attn<a id="change"> = </a>cosine_sim_attn
        self.cosine_sim_scale = 16<a id="change"> if </a>cosine_sim_attn<a id="change"> else </a>1

        self.heads = heads
        inner_dim = dim_head * heads</code></pre><h3>After Change</h3><pre><code class='java'>
        self.to_q = nn.Linear(dim, inner_dim, bias = False)
        self.to_kv = nn.Linear(dim, inner_dim * 2, bias = False)

        self.q_scale<a id="change"> = </a><a id="change">nn.Parameter(torch.ones(</a>dim_head<a id="change">)</a><a id="change">)</a>
        self.k_scale<a id="change"> = </a><a id="change">nn.Parameter(</a><a id="change">torch.ones(</a>dim_head<a id="change">))</a>

        self.to_out = nn.Sequential(
            nn.Linear(inner_dim, dim, bias = False),
            nn.LayerNorm(dim)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/e021548bc31a5132c3f99c1a9ac041f81e6d8b69#diff-edef3c5fe92797a22c0b8fc6cca1d57b4b84ef03dfdfe802ed9147e21fc88109L374' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 65938252</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: e021548bc31a5132c3f99c1a9ac041f81e6d8b69</div><div id='time'> Time: 2023-02-13</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_class'> M Class Name: PerceiverAttention</div><div id='n_method'> N Class Name: PerceiverAttention</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imagen_pytorch/imagen_pytorch.py</div><div id='n_file'> N File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_start'> M Start Line: 383</div><div id='m_end'> M End Line: 385</div><div id='n_start'> N Start Line: 383</div><div id='n_end'> N End Line: 395</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        cosine_sim_attn = False
    ):
        super().__init__()
        self.scale = dim_head<a id="change"> ** -0.5</a><a id="change"> if not cosine_sim_attn</a><a id="change"> else </a>1.
        self.cosine_sim_attn<a id="change"> = </a>cosine_sim_attn
        self.cosine_sim_scale = 16<a id="change"> if </a>cosine_sim_attn<a id="change"> else </a>1

        self.heads = heads
        inner_dim = dim_head * heads</code></pre><h3>After Change</h3><pre><code class='java'>
        self.to_q = nn.Linear(dim, inner_dim, bias = False)
        self.to_kv = nn.Linear(context_dim, inner_dim * 2, bias = False)

        self.q_scale<a id="change"> = </a><a id="change">nn.Parameter(torch.ones(</a>dim_head<a id="change">)</a><a id="change">)</a>
        self.k_scale<a id="change"> = </a><a id="change">nn.Parameter(</a><a id="change">torch.ones(</a>dim_head<a id="change">))</a>

        self.to_out = nn.Sequential(
            nn.Linear(inner_dim, dim, bias = False),
            LayerNorm(dim)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/e021548bc31a5132c3f99c1a9ac041f81e6d8b69#diff-87b27a2606d89bf8c64b738a6a3fcfdb0699b7a362ada843cfa9dc9feeaf6eb4L796' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 65938266</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: e021548bc31a5132c3f99c1a9ac041f81e6d8b69</div><div id='time'> Time: 2023-02-13</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/imagen_video.py</div><div id='m_class'> M Class Name: CrossAttention</div><div id='n_method'> N Class Name: CrossAttention</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imagen_pytorch/imagen_video.py</div><div id='n_file'> N File Name: imagen_pytorch/imagen_video.py</div><div id='m_start'> M Start Line: 807</div><div id='m_end'> M End Line: 809</div><div id='n_start'> N Start Line: 806</div><div id='n_end'> N End Line: 821</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        cosine_sim_attn = False
    ):
        super().__init__()
        self.scale = dim_head<a id="change"> ** -0.5</a><a id="change"> if not cosine_sim_attn</a><a id="change"> else </a>1.
        self.cosine_sim_attn<a id="change"> = </a>cosine_sim_attn
        self.cosine_sim_scale = 16<a id="change"> if </a>cosine_sim_attn<a id="change"> else </a>1

        self.heads = heads
        inner_dim = dim_head * heads</code></pre><h3>After Change</h3><pre><code class='java'>
        self.to_q = nn.Linear(dim, inner_dim, bias = False)
        self.to_kv = nn.Linear(dim, dim_head * 2, bias = False)

        self.q_scale<a id="change"> = </a><a id="change">nn.Parameter(torch.ones(</a>dim_head<a id="change">)</a><a id="change">)</a>
        self.k_scale<a id="change"> = </a><a id="change">nn.Parameter(</a><a id="change">torch.ones(</a>dim_head<a id="change">))</a>

        self.to_context = nn.Sequential(nn.LayerNorm(context_dim), nn.Linear(context_dim, dim_head * 2)) if exists(context_dim) else None

        self.to_out = nn.Sequential(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/e021548bc31a5132c3f99c1a9ac041f81e6d8b69#diff-edef3c5fe92797a22c0b8fc6cca1d57b4b84ef03dfdfe802ed9147e21fc88109L498' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 65938262</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: e021548bc31a5132c3f99c1a9ac041f81e6d8b69</div><div id='time'> Time: 2023-02-13</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_class'> M Class Name: Attention</div><div id='n_method'> N Class Name: Attention</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imagen_pytorch/imagen_pytorch.py</div><div id='n_file'> N File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_start'> M Start Line: 508</div><div id='m_end'> M End Line: 510</div><div id='n_start'> N Start Line: 507</div><div id='n_end'> N End Line: 519</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        cosine_sim_attn = False
    ):
        super().__init__()
        self.scale = dim_head<a id="change"> ** -0.5</a><a id="change"> if not cosine_sim_attn</a><a id="change"> else </a>1
        self.cosine_sim_attn<a id="change"> = </a>cosine_sim_attn
        self.cosine_sim_scale = 16<a id="change"> if </a>cosine_sim_attn<a id="change"> else </a>1

        self.heads = heads
        inner_dim = dim_head * heads</code></pre><h3>After Change</h3><pre><code class='java'>
        self.to_q = nn.Linear(dim, inner_dim, bias = False)
        self.to_kv = nn.Linear(dim, inner_dim * 2, bias = False)

        self.q_scale<a id="change"> = </a><a id="change">nn.Parameter(torch.ones(</a>dim_head<a id="change">)</a><a id="change">)</a>
        self.k_scale<a id="change"> = </a><a id="change">nn.Parameter(</a><a id="change">torch.ones(</a>dim_head<a id="change">))</a>

        self.to_out = nn.Sequential(
            nn.Linear(inner_dim, dim, bias = False),
            nn.LayerNorm(dim)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/e021548bc31a5132c3f99c1a9ac041f81e6d8b69#diff-87b27a2606d89bf8c64b738a6a3fcfdb0699b7a362ada843cfa9dc9feeaf6eb4L252' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 65938272</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: e021548bc31a5132c3f99c1a9ac041f81e6d8b69</div><div id='time'> Time: 2023-02-13</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/imagen_video.py</div><div id='m_class'> M Class Name: PerceiverAttention</div><div id='n_method'> N Class Name: PerceiverAttention</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imagen_pytorch/imagen_video.py</div><div id='n_file'> N File Name: imagen_pytorch/imagen_video.py</div><div id='m_start'> M Start Line: 261</div><div id='m_end'> M End Line: 263</div><div id='n_start'> N Start Line: 261</div><div id='n_end'> N End Line: 273</div><BR>