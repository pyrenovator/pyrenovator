<html><h3>Pattern ID :19352
</h3><img src='63118595.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            raise ValueError(f&quotInvalid beta parameter at index 0: {betas[0]}&quot)
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            <a id="change">raise </a><a id="change">ValueError(f&quotInvalid beta parameter at index 1: {betas[1]}&quot</a><a id="change">)</a>
        if weight_decay &lt; 0:
            raise ValueError(f&quotInvalid weight_decay value: {weight_decay}&quot)
        if clamp_value &lt; 0.0:
            raise ValueError(f&quotInvalid clamp value: {clamp_value}&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
        if eps &lt; 0.0:
            raise ValueError(&quotInvalid epsilon value: {}&quot.format(eps))
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 0: {}&quot.format(betas[0]</a><a id="change">)
            )</a>
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 1: {}&quot.format(betas</a><a id="change">[1])
            )</a>
        if weight_decay &lt; 0:
            raise ValueError(
                &quotInvalid weight_decay value: {}&quot.format(weight_decay)
            )</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 7</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/jettify/pytorch-optimizer/commit/71e9bb453a840825743df84f6c5dedfd8bbb8429#diff-fbfe617fbb19b468f8d84fa739523e3ee80954ae89bd01ca97dc9fa9c6a4e6bbL53' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63118595</div><div id='project'> Project Name: jettify/pytorch-optimizer</div><div id='commit'> Commit Name: 71e9bb453a840825743df84f6c5dedfd8bbb8429</div><div id='time'> Time: 2020-03-15</div><div id='author'> Author: chris.j.seymour@hotmail.com</div><div id='file'> File Name: torch_optimizer/lamb.py</div><div id='m_class'> M Class Name: Lamb</div><div id='n_method'> N Class Name: Lamb</div><div id='m_method'> M Method Name: __init__(9)</div><div id='n_method'> N Method Name: __init__(9)</div><div id='m_parent_class'> M Parent Class: Optimizer</div><div id='n_parent_class'> N Parent Class: Optimizer</div><div id='m_file'> M File Name: torch_optimizer/lamb.py</div><div id='n_file'> N File Name: torch_optimizer/lamb.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 63</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 69</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if eps &lt; 0.0:
            raise ValueError(f&quotInvalid epsilon value: {eps}&quot)
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            <a id="change">raise </a><a id="change">ValueError(f&quotInvalid beta parameter at index 0: {betas[0]}&quot</a><a id="change">)</a>
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            raise ValueError(f&quotInvalid beta parameter at index 1: {betas[1]}&quot)
        if weight_decay &lt; 0:
            raise ValueError(f&quotInvalid weight_decay value: {weight_decay}&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
        if eps &lt; 0.0:
            raise ValueError(&quotInvalid epsilon value: {}&quot.format(eps))
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 0: {}&quot.format(</a><a id="change">betas[0])
            )</a>
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 1: {}&quot.format(betas[1]</a><a id="change">)
            )</a>
        if weight_decay &lt; 0:
            raise ValueError(
                &quotInvalid weight_decay value: {}&quot.format(weight_decay)
            )</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jettify/pytorch-optimizer/commit/71e9bb453a840825743df84f6c5dedfd8bbb8429#diff-fbfe617fbb19b468f8d84fa739523e3ee80954ae89bd01ca97dc9fa9c6a4e6bbL41' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63118594</div><div id='project'> Project Name: jettify/pytorch-optimizer</div><div id='commit'> Commit Name: 71e9bb453a840825743df84f6c5dedfd8bbb8429</div><div id='time'> Time: 2020-03-15</div><div id='author'> Author: chris.j.seymour@hotmail.com</div><div id='file'> File Name: torch_optimizer/lamb.py</div><div id='m_class'> M Class Name: Lamb</div><div id='n_method'> N Class Name: Lamb</div><div id='m_method'> M Method Name: __init__(9)</div><div id='n_method'> N Method Name: __init__(9)</div><div id='m_parent_class'> M Parent Class: Optimizer</div><div id='n_parent_class'> N Parent Class: Optimizer</div><div id='m_file'> M File Name: torch_optimizer/lamb.py</div><div id='n_file'> N File Name: torch_optimizer/lamb.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 63</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 69</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            raise ValueError(f&quotInvalid beta parameter at index 0: {betas[0]}&quot)
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            <a id="change">raise </a><a id="change">ValueError(f&quotInvalid beta parameter at index 1: {betas[1]}&quot</a><a id="change">)</a>
        if final_lr &lt; 0.0:
            raise ValueError(f&quotInvalid final learning rate: {final_lr}&quot)
        if not 0.0 &lt;= gamma &lt; 1.0:
            raise ValueError(f&quotInvalid gamma parameter: {gamma}&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
        if eps &lt; 0.0:
            raise ValueError(&quotInvalid epsilon value: {}&quot.format(eps))
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 0: {}&quot.format(</a><a id="change">betas[0])
            )</a>
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 1: {}&quot.format(betas[1]</a><a id="change">)
            )</a>
        if final_lr &lt; 0.0:
            raise ValueError(
                &quotInvalid final learning rate: {}&quot.format(final_lr)
            )</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jettify/pytorch-optimizer/commit/71e9bb453a840825743df84f6c5dedfd8bbb8429#diff-41353da6f0280ea0aae58afe1a63fc1b4a5741282306983c5bae2839e33373b0L41' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63118593</div><div id='project'> Project Name: jettify/pytorch-optimizer</div><div id='commit'> Commit Name: 71e9bb453a840825743df84f6c5dedfd8bbb8429</div><div id='time'> Time: 2020-03-15</div><div id='author'> Author: chris.j.seymour@hotmail.com</div><div id='file'> File Name: torch_optimizer/adabound.py</div><div id='m_class'> M Class Name: AdaBound</div><div id='n_method'> N Class Name: AdaBound</div><div id='m_method'> M Method Name: __init__(9)</div><div id='n_method'> N Method Name: __init__(9)</div><div id='m_parent_class'> M Parent Class: Optimizer</div><div id='n_parent_class'> N Parent Class: Optimizer</div><div id='m_file'> M File Name: torch_optimizer/adabound.py</div><div id='n_file'> N File Name: torch_optimizer/adabound.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 65</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 72</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            raise ValueError(f&quotInvalid beta parameter at index 0: {betas[0]}&quot)
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            <a id="change">raise </a><a id="change">ValueError(f&quotInvalid beta parameter at index 1: {betas[1]}&quot</a><a id="change">)</a>
        if weight_decay &lt; 0.0:
            raise ValueError(f&quotInvalid weight_decay value: {weight_decay}&quot)

        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)</code></pre><h3>After Change</h3><pre><code class='java'>
        if eps &lt; 0.0:
            raise ValueError(&quotInvalid epsilon value: {}&quot.format(eps))
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 0: {}&quot.format(betas[0]</a><a id="change">)
            )</a>
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 1: {}&quot.format(</a><a id="change">betas[1])
            )</a>
        if weight_decay &lt; 0.0:
            raise ValueError(
                &quotInvalid weight_decay value: {}&quot.format(weight_decay)
            )</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jettify/pytorch-optimizer/commit/71e9bb453a840825743df84f6c5dedfd8bbb8429#diff-3f42353c6e94c330878a94555f94193ca15cff3cbb947c91f94499538c6dcb79L37' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63118592</div><div id='project'> Project Name: jettify/pytorch-optimizer</div><div id='commit'> Commit Name: 71e9bb453a840825743df84f6c5dedfd8bbb8429</div><div id='time'> Time: 2020-03-15</div><div id='author'> Author: chris.j.seymour@hotmail.com</div><div id='file'> File Name: torch_optimizer/diffgrad.py</div><div id='m_class'> M Class Name: DiffGrad</div><div id='n_method'> N Class Name: DiffGrad</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: Optimizer</div><div id='n_parent_class'> N Parent Class: Optimizer</div><div id='m_file'> M File Name: torch_optimizer/diffgrad.py</div><div id='n_file'> N File Name: torch_optimizer/diffgrad.py</div><div id='m_start'> M Start Line: 46</div><div id='m_end'> M End Line: 54</div><div id='n_start'> N Start Line: 46</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if eps &lt; 0.0:
            raise ValueError(f&quotInvalid epsilon value: {eps}&quot)
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            <a id="change">raise </a><a id="change">ValueError(f&quotInvalid beta parameter at index 0: {betas[0]}&quot</a><a id="change">)</a>
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            raise ValueError(f&quotInvalid beta parameter at index 1: {betas[1]}&quot)
        if not 0.0 &lt;= beta3 &lt; 1.0:
            raise ValueError(f&quotInvalid beta3 parameter: {beta3}&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
        if eps &lt; 0.0:
            raise ValueError(&quotInvalid epsilon value: {}&quot.format(eps))
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 0: {}&quot.format(</a><a id="change">betas[0])
            )</a>
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 1: {}&quot.format(betas[1]</a><a id="change">)
            )</a>
        if not 0.0 &lt;= beta3 &lt; 1.0:
            raise ValueError(&quotInvalid beta3 parameter: {}&quot.format(beta3))
        if weight_decay &lt; 0.0:
            raise ValueError(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jettify/pytorch-optimizer/commit/71e9bb453a840825743df84f6c5dedfd8bbb8429#diff-6dc5a0ba1d1fec8eaaf9ac315044d52f67bd7ac751321747bd0c0c4a3887963eL39' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63118599</div><div id='project'> Project Name: jettify/pytorch-optimizer</div><div id='commit'> Commit Name: 71e9bb453a840825743df84f6c5dedfd8bbb8429</div><div id='time'> Time: 2020-03-15</div><div id='author'> Author: chris.j.seymour@hotmail.com</div><div id='file'> File Name: torch_optimizer/adamod.py</div><div id='m_class'> M Class Name: AdaMod</div><div id='n_method'> N Class Name: AdaMod</div><div id='m_method'> M Method Name: __init__(7)</div><div id='n_method'> N Method Name: __init__(7)</div><div id='m_parent_class'> M Parent Class: Optimizer</div><div id='n_parent_class'> N Parent Class: Optimizer</div><div id='m_file'> M File Name: torch_optimizer/adamod.py</div><div id='n_file'> N File Name: torch_optimizer/adamod.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 59</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 64</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if eps &lt; 0.0:
            raise ValueError(f&quotInvalid epsilon value: {eps}&quot)
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            <a id="change">raise </a><a id="change">ValueError(f&quotInvalid beta parameter at index 0: {betas[0]}&quot</a><a id="change">)</a>
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            raise ValueError(f&quotInvalid beta parameter at index 1: {betas[1]}&quot)
        if weight_decay &lt; 0:
            raise ValueError(f&quotInvalid weight_decay value: {weight_decay}&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
        if eps &lt; 0.0:
            raise ValueError(&quotInvalid epsilon value: {}&quot.format(eps))
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 0: {}&quot.format(</a><a id="change">betas[0])
            )</a>
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 1: {}&quot.format(betas[1]</a><a id="change">)
            )</a>
        if weight_decay &lt; 0:
            raise ValueError(
                &quotInvalid weight_decay value: {}&quot.format(weight_decay)
            )</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jettify/pytorch-optimizer/commit/71e9bb453a840825743df84f6c5dedfd8bbb8429#diff-bd88cc4d365762e5d366d3e7566a84086f566af95d37539d3195fbc95896a977L38' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63118598</div><div id='project'> Project Name: jettify/pytorch-optimizer</div><div id='commit'> Commit Name: 71e9bb453a840825743df84f6c5dedfd8bbb8429</div><div id='time'> Time: 2020-03-15</div><div id='author'> Author: chris.j.seymour@hotmail.com</div><div id='file'> File Name: torch_optimizer/yogi.py</div><div id='m_class'> M Class Name: Yogi</div><div id='n_method'> N Class Name: Yogi</div><div id='m_method'> M Method Name: __init__(7)</div><div id='n_method'> N Method Name: __init__(7)</div><div id='m_parent_class'> M Parent Class: Optimizer</div><div id='n_parent_class'> N Parent Class: Optimizer</div><div id='m_file'> M File Name: torch_optimizer/yogi.py</div><div id='n_file'> N File Name: torch_optimizer/yogi.py</div><div id='m_start'> M Start Line: 48</div><div id='m_end'> M End Line: 56</div><div id='n_start'> N Start Line: 48</div><div id='n_end'> N End Line: 61</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            raise ValueError(f&quotInvalid beta parameter at index 0: {betas[0]}&quot)
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            <a id="change">raise </a><a id="change">ValueError(f&quotInvalid beta parameter at index 1: {betas[1]}&quot</a><a id="change">)</a>
        if weight_decay &lt; 0:
            raise ValueError(f&quotInvalid weight_decay value: {weight_decay}&quot)
        defaults = dict(
            lr=lr,</code></pre><h3>After Change</h3><pre><code class='java'>
        if eps &lt; 0.0:
            raise ValueError(&quotInvalid epsilon value: {}&quot.format(eps))
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 0: {}&quot.format(</a><a id="change">betas[0])
            )</a>
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 1: {}&quot.format(betas[1]</a><a id="change">)
            )</a>
        if weight_decay &lt; 0:
            raise ValueError(
                &quotInvalid weight_decay value: {}&quot.format(weight_decay)
            )</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jettify/pytorch-optimizer/commit/71e9bb453a840825743df84f6c5dedfd8bbb8429#diff-1a75eaec6e1c2a55a6dcfa91060155be2505b32a6b68adc057004a31b216cd19L42' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63118596</div><div id='project'> Project Name: jettify/pytorch-optimizer</div><div id='commit'> Commit Name: 71e9bb453a840825743df84f6c5dedfd8bbb8429</div><div id='time'> Time: 2020-03-15</div><div id='author'> Author: chris.j.seymour@hotmail.com</div><div id='file'> File Name: torch_optimizer/novograd.py</div><div id='m_class'> M Class Name: NovoGrad</div><div id='n_method'> N Class Name: NovoGrad</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(8)</div><div id='m_parent_class'> M Parent Class: Optimizer</div><div id='n_parent_class'> N Parent Class: Optimizer</div><div id='m_file'> M File Name: torch_optimizer/novograd.py</div><div id='n_file'> N File Name: torch_optimizer/novograd.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 61</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 66</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if eps &lt; 0.0:
            raise ValueError(f&quotInvalid epsilon value: {eps}&quot)
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            <a id="change">raise </a><a id="change">ValueError(f&quotInvalid beta parameter at index 0: {betas[0]}&quot</a><a id="change">)</a>
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            raise ValueError(f&quotInvalid beta parameter at index 1: {betas[1]}&quot)
        if weight_decay &lt; 0:
            raise ValueError(f&quotInvalid weight_decay value: {weight_decay}&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
        if eps &lt; 0.0:
            raise ValueError(&quotInvalid epsilon value: {}&quot.format(eps))
        if not 0.0 &lt;= betas[0] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 0: {}&quot.format(</a><a id="change">betas[0])
            )</a>
        if not 0.0 &lt;= betas[1] &lt; 1.0:
            <a id="change">raise ValueError(
                </a><a id="change">&quotInvalid beta parameter at index 1: {}&quot.format(betas[1]</a><a id="change">)
            )</a>
        if weight_decay &lt; 0:
            raise ValueError(
                &quotInvalid weight_decay value: {}&quot.format(weight_decay)
            )</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jettify/pytorch-optimizer/commit/71e9bb453a840825743df84f6c5dedfd8bbb8429#diff-41a3e9860970b06730608acdd49f57ced1ccc2c0717805c35a782440ff6ef1d4L37' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63118607</div><div id='project'> Project Name: jettify/pytorch-optimizer</div><div id='commit'> Commit Name: 71e9bb453a840825743df84f6c5dedfd8bbb8429</div><div id='time'> Time: 2020-03-15</div><div id='author'> Author: chris.j.seymour@hotmail.com</div><div id='file'> File Name: torch_optimizer/radam.py</div><div id='m_class'> M Class Name: RAdam</div><div id='n_method'> N Class Name: RAdam</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: Optimizer</div><div id='n_parent_class'> N Parent Class: Optimizer</div><div id='m_file'> M File Name: torch_optimizer/radam.py</div><div id='n_file'> N File Name: torch_optimizer/radam.py</div><div id='m_start'> M Start Line: 46</div><div id='m_end'> M End Line: 54</div><div id='n_start'> N Start Line: 46</div><div id='n_end'> N End Line: 59</div><BR>