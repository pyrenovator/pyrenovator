<html><h3>Pattern ID :41128
</h3><img src='115909519.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        effective_vocab_size = self.generative_vocab_size + len(oov_to_limited_idx)
        if self.generative_vocab_size &lt; effective_vocab_size:
            size[-1] = effective_vocab_size - self.generative_vocab_size
            buff = <a id="change">Variable(scaled_p_vocab.data.new(*size).fill_(EPSILON</a><a id="change">)</a><a id="change">)</a>
            <a id="change">scaled_p_vocab</a> = torch.cat([scaled_p_vocab, buff], dim=buff.dim()-1)

        p_context_ptr = <a id="change">Variable(scaled_p_vocab.data.new(*scaled_p_vocab.size()).fill_(EPSILON</a><a id="change">)</a><a id="change">)</a>
        p_context_ptr.scatter_add_(p_context_ptr.dim()-1, context_indices.unsqueeze(1).expand_as(context_attention), context_attention)
        scaled_p_context_ptr = (1 - vocab_pointer_switches).expand_as(p_context_ptr) * p_context_ptr

        probs = scaled_p_vocab + scaled_p_context_ptr</code></pre><h3>After Change</h3><pre><code class='java'>
        effective_vocab_size = self.generative_vocab_size + len(oov_to_limited_idx)
        if self.generative_vocab_size &lt; effective_vocab_size:
            size[-1] = effective_vocab_size - self.generative_vocab_size
            buff = <a id="change">scaled_p_vocab.new_full(</a>size, <a id="change">EPSILON</a><a id="change">)</a>
            <a id="change">scaled_p_vocab</a> = torch.cat([scaled_p_vocab, buff], dim=buff.dim()-1)

        p_context_ptr = <a id="change">scaled_p_vocab.new_full(</a><a id="change">scaled_p_vocab.size()</a>, <a id="change">EPSILON</a><a id="change">)</a>
        p_context_ptr.scatter_add_(p_context_ptr.dim()-1, context_indices.unsqueeze(1).expand_as(context_attention), context_attention)
        scaled_p_context_ptr = (1 - vocab_pointer_switches).expand_as(p_context_ptr) * p_context_ptr

        probs = scaled_p_vocab + scaled_p_context_ptr</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/4a962fa2bc3a99d5b5b177453210699f75472cbc#diff-ed5b3c3850653ac07b17b1db126163f7a6d160ffc06c6186a8b293fc0297d985L113' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 115909519</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: 4a962fa2bc3a99d5b5b177453210699f75472cbc</div><div id='time'> Time: 2018-10-25</div><div id='author'> Author: bryan.mccann.is@gmail.com</div><div id='file'> File Name: models/self_attentive_pointer_generator.py</div><div id='m_class'> M Class Name: SelfAttentivePointerGenerator</div><div id='n_method'> N Class Name: SelfAttentivePointerGenerator</div><div id='m_method'> M Method Name: probs(7)</div><div id='n_method'> N Method Name: probs(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/self_attentive_pointer_generator.py</div><div id='n_file'> N File Name: models/self_attentive_pointer_generator.py</div><div id='m_start'> M Start Line: 114</div><div id='m_end'> M End Line: 127</div><div id='n_start'> N Start Line: 113</div><div id='n_end'> N End Line: 126</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        size[-1] = self.generative_vocab_size
        scores = generator(outputs.view(-1, outputs.size(-1))).view(size)
        p_vocab = F.softmax(scores, dim=scores.dim()-1)
        <a id="change">scaled_p_vocab</a> = vocab_pointer_switches.expand_as(p_vocab) * p_vocab

        effective_vocab_size = self.generative_vocab_size + len(oov_to_limited_idx)
        if self.generative_vocab_size &lt; effective_vocab_size:
            size[-1] = effective_vocab_size - self.generative_vocab_size
            buff = <a id="change">Variable(scaled_p_vocab.data.new(*size).fill_(</a>EPSILON<a id="change">)</a><a id="change">)</a>
            <a id="change">scaled_p_vocab</a> = torch.cat([scaled_p_vocab, buff], dim=buff.dim()-1)

        p_context_ptr = <a id="change">Variable(scaled_p_vocab.data.new(*scaled_p_vocab.size()).fill_(</a>EPSILON<a id="change">)</a><a id="change">)</a>
        p_context_ptr.scatter_add_(p_context_ptr.dim()-1, context_indices.unsqueeze(1).expand_as(context_attention), context_attention)
        scaled_p_context_ptr = (1 - vocab_pointer_switches).expand_as(p_context_ptr) * p_context_ptr

        probs = scaled_p_vocab + scaled_p_context_ptr &#47&#47+ scaled_p_question_ptr</code></pre><h3>After Change</h3><pre><code class='java'>
        size[-1] = self.generative_vocab_size
        scores = generator(outputs.view(-1, outputs.size(-1))).view(size)
        p_vocab = F.softmax(scores, dim=scores.dim()-1)
        <a id="change">scaled_p_vocab</a> = vocab_pointer_switches.expand_as(p_vocab) * p_vocab

        effective_vocab_size = self.generative_vocab_size + len(oov_to_limited_idx)
        if self.generative_vocab_size &lt; effective_vocab_size:
            size[-1] = effective_vocab_size - self.generative_vocab_size
            buff = <a id="change">scaled_p_vocab.new_full(</a>size, EPSILON<a id="change">)</a>
            <a id="change">scaled_p_vocab</a> = torch.cat([scaled_p_vocab, buff], dim=buff.dim()-1)

        p_context_ptr = <a id="change">scaled_p_vocab.new_full(</a><a id="change">scaled_p_vocab.size()</a>, EPSILON<a id="change">)</a>
        p_context_ptr.scatter_add_(p_context_ptr.dim()-1, context_indices.unsqueeze(1).expand_as(context_attention), context_attention)
        scaled_p_context_ptr = (1 - vocab_pointer_switches).expand_as(p_context_ptr) * p_context_ptr
        probs = scaled_p_vocab + scaled_p_context_ptr
        return probs</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/ee3ba6c1b53857e88f9fc323844e26f96ca5607a#diff-a666c526632b1cdc0ae405d34627213445247898ae8c3f2c372a473428f4574cL88' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 115909520</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: ee3ba6c1b53857e88f9fc323844e26f96ca5607a</div><div id='time'> Time: 2018-10-25</div><div id='author'> Author: bryan.mccann.is@gmail.com</div><div id='file'> File Name: models/pointer_generator.py</div><div id='m_class'> M Class Name: PointerGenerator</div><div id='n_method'> N Class Name: PointerGenerator</div><div id='m_method'> M Method Name: probs(7)</div><div id='n_method'> N Method Name: probs(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/pointer_generator.py</div><div id='n_file'> N File Name: models/pointer_generator.py</div><div id='m_start'> M Start Line: 94</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 93</div><div id='n_end'> N End Line: 106</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        size[-1] = self.generative_vocab_size
        scores = generator(outputs.view(-1, outputs.size(-1))).view(size)
        p_vocab = F.softmax(scores, dim=scores.dim()-1)
        <a id="change">scaled_p_vocab</a> = vocab_pointer_switches.expand_as(p_vocab) * p_vocab

        effective_vocab_size = self.generative_vocab_size + len(oov_to_limited_idx)
        if self.generative_vocab_size &lt; effective_vocab_size:
            size[-1] = effective_vocab_size - self.generative_vocab_size
            buff = <a id="change">Variable(scaled_p_vocab.data.new(*size).fill_(</a>EPSILON<a id="change">)</a><a id="change">)</a>
            <a id="change">scaled_p_vocab</a> = torch.cat([scaled_p_vocab, buff], dim=buff.dim()-1)

        p_context_ptr = <a id="change">Variable(scaled_p_vocab.data.new(*scaled_p_vocab.size()).fill_(</a>EPSILON<a id="change">)</a><a id="change">)</a>
        p_context_ptr.scatter_add_(p_context_ptr.dim()-1, context_indices.unsqueeze(1).expand_as(context_attention), context_attention)
        scaled_p_context_ptr = (1 - vocab_pointer_switches).expand_as(p_context_ptr) * p_context_ptr

        probs = scaled_p_vocab + scaled_p_context_ptr</code></pre><h3>After Change</h3><pre><code class='java'>
        size[-1] = self.generative_vocab_size
        scores = generator(outputs.view(-1, outputs.size(-1))).view(size)
        p_vocab = F.softmax(scores, dim=scores.dim()-1)
        <a id="change">scaled_p_vocab</a> = vocab_pointer_switches.expand_as(p_vocab) * p_vocab

        effective_vocab_size = self.generative_vocab_size + len(oov_to_limited_idx)
        if self.generative_vocab_size &lt; effective_vocab_size:
            size[-1] = effective_vocab_size - self.generative_vocab_size
            buff = <a id="change">scaled_p_vocab.new_full(</a>size, EPSILON<a id="change">)</a>
            <a id="change">scaled_p_vocab</a> = torch.cat([scaled_p_vocab, buff], dim=buff.dim()-1)

        p_context_ptr = <a id="change">scaled_p_vocab.new_full(</a><a id="change">scaled_p_vocab.size()</a>, EPSILON<a id="change">)</a>
        p_context_ptr.scatter_add_(p_context_ptr.dim()-1, context_indices.unsqueeze(1).expand_as(context_attention), context_attention)
        scaled_p_context_ptr = (1 - vocab_pointer_switches).expand_as(p_context_ptr) * p_context_ptr

        probs = scaled_p_vocab + scaled_p_context_ptr</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/59a1dcd47dda8c0cd19248b3a119ee6125795fdc#diff-132fc63ce5affe92920aa4dc16792a1932aa59397084f8e47fcb4e2b203475a9L115' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 115909521</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: 59a1dcd47dda8c0cd19248b3a119ee6125795fdc</div><div id='time'> Time: 2018-10-25</div><div id='author'> Author: bryan.mccann.is@gmail.com</div><div id='file'> File Name: models/coattentive_pointer_generator.py</div><div id='m_class'> M Class Name: CoattentivePointerGenerator</div><div id='n_method'> N Class Name: CoattentivePointerGenerator</div><div id='m_method'> M Method Name: probs(7)</div><div id='n_method'> N Method Name: probs(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/coattentive_pointer_generator.py</div><div id='n_file'> N File Name: models/coattentive_pointer_generator.py</div><div id='m_start'> M Start Line: 121</div><div id='m_end'> M End Line: 134</div><div id='n_start'> N Start Line: 120</div><div id='n_end'> N End Line: 133</div><BR>