<html><h3>Pattern ID :12687
</h3><img src='42988430.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def forward(self, input):
        if not self.coord_conv:
            return input
        b<a id="change"> = input.shape[0]</a>
        h = input.shape[2]
        w = input.shape[3]
        x_range = <a id="change">T.arange(0, w, dtype=T.float32, device=input.device) / (w - 1) * 2.0</a> - 1
        y_range = <a id="change">T.arange(0, h, dtype=T.float32, device=input.device) / (h - 1) * 2.0</a> - 1
        x_range<a id="change"> = </a>x_range[np.newaxis, np.newaxis, np.newaxis, :].repeat((b<a id="change">, 1, h, 1</a>))
        y_range<a id="change"> = </a>y_range[np.newaxis, np.newaxis, :, np.newaxis].repeat((b, 1, 1, w))
        offset = T.cat([input, x_range, y_range], dim=1)
        return offset
</code></pre><h3>After Change</h3><pre><code class='java'>

    def forward(self, x):
        gx, gy = add_coord(x, self.data_format)
        <a id="change">if self.data_format == &quotNCHW&quot</a>:
            y<a id="change"> = </a>torch.cat([x, gx, gy], 1)
        else:
            y = torch.cat([x, gx, gy], -1)
        y = self.conv(y)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 12</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/miemie2013/miemiedetection/commit/aabe1f2d364493c30179de6cf7d5c2d0c6ee7258#diff-a8b191246b197a19b67f7091a6ab58484cff81cdb9be1d770800a043a751c910L498' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 42988430</div><div id='project'> Project Name: miemie2013/miemiedetection</div><div id='commit'> Commit Name: aabe1f2d364493c30179de6cf7d5c2d0c6ee7258</div><div id='time'> Time: 2021-12-30</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmdet/models/custom_layers.py</div><div id='m_class'> M Class Name: CoordConv</div><div id='n_method'> N Class Name: CoordConv</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: mmdet/models/custom_layers.py</div><div id='n_file'> N File Name: mmdet/models/custom_layers.py</div><div id='m_start'> M Start Line: 498</div><div id='m_end'> M End Line: 508</div><div id='n_start'> N Start Line: 574</div><div id='n_end'> N End Line: 580</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def forward(self, input):
        if not self.coord_conv:
            return input
        b<a id="change"> = input.shape[0]</a>
        h = input.shape[2]
        w = input.shape[3]
        x_range = <a id="change">T.arange(</a>0, w<a id="change">, dtype=T.float32, device=input.device)</a> / (w - 1) *<a id="change"> 2.0 - 1</a>
        y_range = <a id="change">T.arange(0, h, dtype=T.float32, device=input.device) / (h - 1) * 2.0</a> - 1
        x_range<a id="change"> = </a>x_range[np.newaxis, np.newaxis, np.newaxis, :].repeat((b<a id="change">, 1, h, 1</a>))
        y_range<a id="change"> = </a>y_range[np.newaxis, np.newaxis, :, np.newaxis].repeat((b, 1, 1, w))
        offset = T.cat([input, x_range, y_range], dim=1)
        return offset
</code></pre><h3>After Change</h3><pre><code class='java'>

    def forward(self, x):
        gx, gy = add_coord(x, self.data_format)
        <a id="change">if self.data_format == &quotNCHW&quot</a>:
            y = torch.cat([x, gx, gy], 1)
        else:
            y<a id="change"> = </a>torch.cat([x, gx, gy], -1)
        y = self.conv(y)
        return y
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/miemie2013/miemiedetection/commit/aabe1f2d364493c30179de6cf7d5c2d0c6ee7258#diff-a8b191246b197a19b67f7091a6ab58484cff81cdb9be1d770800a043a751c910L497' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 42988302</div><div id='project'> Project Name: miemie2013/miemiedetection</div><div id='commit'> Commit Name: aabe1f2d364493c30179de6cf7d5c2d0c6ee7258</div><div id='time'> Time: 2021-12-30</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmdet/models/custom_layers.py</div><div id='m_class'> M Class Name: CoordConv</div><div id='n_method'> N Class Name: CoordConv</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: mmdet/models/custom_layers.py</div><div id='n_file'> N File Name: mmdet/models/custom_layers.py</div><div id='m_start'> M Start Line: 498</div><div id='m_end'> M End Line: 508</div><div id='n_start'> N Start Line: 574</div><div id='n_end'> N End Line: 580</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        dim_counts = Counter(self.observation_shape)
        spatial_dimension = dim_counts.most_common()[0][0]
        assert dim_counts[spatial_dimension] == 2, "This code assumes a square image, implying at least one dimension size repeated"
        channel_dimension<a id="change"> = dim_counts.most_common()[-1][0]</a>
        assert dim_counts[channel_dimension] == 1, "This code assumes two spatial dimensions and one channels dimension"
        spatial_indicies = <a id="change">np.arange(</a>len(self.observation_shape)<a id="change">)</a>[np.array(self.observation_shape) == spatial_dimension]
        channel_index = <a id="change">np.arange(</a>len(self.observation_shape)<a id="change">)</a>[np.array(self.observation_shape) == channel_dimension].item()

        new_shape = (channel_dimension<a id="change">, spatial_dimension, spatial_dimension</a>)
        required_permutation = (0, channel_index+1, spatial_indicies[0]<a id="change">+1</a>, spatial_indicies[1]<a id="change">+1</a>) &#47&#47 +1 to account for batch
        self.observation_shape<a id="change"> = </a>new_shape
        self.observation_space = Box(shape=self.observation_shape, low=0, high=255, dtype=np.uint8)
        self.permutation_tuple<a id="change"> = </a>required_permutation

    def _tensorize(self, arr):
        </code></pre><h3>After Change</h3><pre><code class='java'>
    def _make_channels_first(self):
        &#47&#47 Assumes an image in form (C, H, W) or (H, W, C) with H = W != C
        x, y, z = self.observation_shape
        <a id="change">if </a>x != y and <a id="change">y == z</a>:
            self.permutation_tuple<a id="change"> = </a>None
        else:
            assert x == y and x != z, "Can only handle square images in format (C, H, W) or (H, W, C)"
            self.observation_shape = (z, x, y)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/f5cbb3623fa01457a4ce34acd05c35f1535ece6c#diff-11bd63b8ace5530605783f45e027231fff8e98dafa1dbb5675fe0c042e1f07dbL92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 42988445</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: f5cbb3623fa01457a4ce34acd05c35f1535ece6c</div><div id='time'> Time: 2020-07-27</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: _make_channels_first(1)</div><div id='n_method'> N Method Name: _make_channels_first(1)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: algos/representation_learner.py</div><div id='n_file'> N File Name: algos/representation_learner.py</div><div id='m_start'> M Start Line: 95</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 103</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        dim_counts = Counter(self.observation_shape)
        spatial_dimension = dim_counts.most_common()[0][0]
        assert dim_counts[spatial_dimension] == 2, "This code assumes a square image, implying at least one dimension size repeated"
        channel_dimension<a id="change"> = dim_counts.most_common()[-1][0]</a>
        assert dim_counts[channel_dimension] == 1, "This code assumes two spatial dimensions and one channels dimension"
        spatial_indicies = <a id="change">np.arange(</a>len(self.observation_shape)<a id="change">)</a>[np.array(self.observation_shape) == spatial_dimension]
        channel_index = <a id="change">np.arange(</a>len(self.observation_shape)<a id="change">)</a>[np.array(self.observation_shape) == channel_dimension].item()

        new_shape = (channel_dimension<a id="change">, spatial_dimension, spatial_dimension</a>)
        required_permutation = (0, channel_index+1, spatial_indicies[0]<a id="change">+1</a>, spatial_indicies[1]<a id="change">+1</a>) &#47&#47 +1 to account for batch
        self.observation_shape<a id="change"> = </a>new_shape
        self.observation_space = Box(shape=self.observation_shape, low=0, high=255, dtype=np.uint8)
        self.permutation_tuple<a id="change"> = </a>required_permutation

    def _tensorize(self, arr):
        </code></pre><h3>After Change</h3><pre><code class='java'>
    def _make_channels_first(self):
        &#47&#47 Assumes an image in form (C, H, W) or (H, W, C) with H = W != C
        x, y, z = self.observation_shape
        <a id="change">if </a>x != y and <a id="change">y == z</a>:
            self.permutation_tuple<a id="change"> = </a>None
        else:
            assert x == y and x != z, "Can only handle square images in format (C, H, W) or (H, W, C)"
            self.observation_shape = (z, x, y)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/d1ad577e009bce6e87e589755c40d71337a0e2cd#diff-11bd63b8ace5530605783f45e027231fff8e98dafa1dbb5675fe0c042e1f07dbL92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 42988423</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: d1ad577e009bce6e87e589755c40d71337a0e2cd</div><div id='time'> Time: 2020-07-27</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: _make_channels_first(1)</div><div id='n_method'> N Method Name: _make_channels_first(1)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: algos/representation_learner.py</div><div id='n_file'> N File Name: algos/representation_learner.py</div><div id='m_start'> M Start Line: 95</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 103</div><BR>