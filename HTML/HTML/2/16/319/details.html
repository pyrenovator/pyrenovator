<html><h3>Pattern ID :319
</h3><img src='2143776.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        return self.model(**input_)

    def training_step(self, batch: TransformerTokenClassificationModelStepBatchEncoding, batch_idx):  &#47&#47 type: ignore
        <a id="change">input_</a><a id="change">, target</a> = batch
        assert target is not None, "target has to be available for training"

        <a id="change">input_["labels"]</a> = target
        output<a id="change"> = self(input_</a><a id="change">)</a>

        <a id="change">loss</a><a id="change"> = </a>output.loss
        <a id="change">self.log("train/loss"</a>, <a id="change">loss</a><a id="change">, on_step=True, on_epoch=True, prog_bar=True)</a>

        target_flat = target.view(-1)

        valid_indices = target_flat != self.label_pad_token_id
        &#47&#47 ignore typing because hparams is Union
        num_classes: int = self.hparams.num_classes  &#47&#47 type: ignore
        valid_logits = output.logits.view(-1, num_classes)[valid_indices]
        valid_target = target_flat[valid_indices]

        self.train_f1(valid_logits, valid_target)
        <a id="change">self.log("train/f1"</a>, self.train_f1<a id="change">, on_step=False, on_epoch=True, prog_bar=True)</a>

        <a id="change">return loss</a>

    def validation_step(self, batch: TransformerTokenClassificationModelStepBatchEncoding, batch_idx):  &#47&#47 type: ignore
        input_, target = batch
        assert target is not None, "target has to be available for validation"</code></pre><h3>After Change</h3><pre><code class='java'>
        return loss

    def training_step(self, batch: TransformerTokenClassificationModelStepBatchEncoding, batch_idx: int):  &#47&#47 type: ignore
        <a id="change">return self.step(stage=TRAINING, batch=batch)</a>

    def validation_step(self, batch: TransformerTokenClassificationModelStepBatchEncoding, batch_idx: int):  &#47&#47 type: ignore
        return self.step(stage=VALIDATION, batch=batch)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/christophalt/pytorch-ie/commit/b614ef74d4488df2fb51ff945d95709e3d9436ed#diff-0e5755f9b1c90521b8aa742c154ff6198f4808698a677d44b3833079308924cdL45' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2143776</div><div id='project'> Project Name: christophalt/pytorch-ie</div><div id='commit'> Commit Name: b614ef74d4488df2fb51ff945d95709e3d9436ed</div><div id='time'> Time: 2022-04-15</div><div id='author'> Author: ArneBinder@users.noreply.github.com</div><div id='file'> File Name: src/pytorch_ie/models/transformer_token_classification.py</div><div id='m_class'> M Class Name: TransformerTokenClassificationModel</div><div id='n_method'> N Class Name: TransformerTokenClassificationModel</div><div id='m_method'> M Method Name: training_step(3)</div><div id='n_method'> N Method Name: training_step(3)</div><div id='m_parent_class'> M Parent Class: PyTorchIEModel</div><div id='n_parent_class'> N Parent Class: PyTorchIEModel</div><div id='m_file'> M File Name: src/pytorch_ie/models/transformer_token_classification.py</div><div id='n_file'> N File Name: src/pytorch_ie/models/transformer_token_classification.py</div><div id='m_start'> M Start Line: 45</div><div id='m_end'> M End Line: 66</div><div id='n_start'> N Start Line: 85</div><div id='n_end'> N End Line: 86</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        return self.model(**input_)

    def training_step(self, batch: TransformerTokenClassificationModelStepBatchEncoding, batch_idx):  &#47&#47 type: ignore
        input_<a id="change">, target</a> = batch
        assert target is not None, "target has to be available for training"

        <a id="change">input_["labels"]</a> = target
        output<a id="change"> = self(</a>input_<a id="change">)</a>

        <a id="change">loss</a><a id="change"> = </a>output.loss
        <a id="change">self.log("train/loss"</a>, loss<a id="change">, on_step=True, on_epoch=True, prog_bar=True)</a>

        target_flat = target.view(-1)

        valid_indices = target_flat != self.label_pad_token_id
        &#47&#47 ignore typing because hparams is Union
        num_classes: int = self.hparams.num_classes  &#47&#47 type: ignore
        valid_logits = output.logits.view(-1, num_classes)[valid_indices]
        valid_target = target_flat[valid_indices]

        self.train_f1(valid_logits, valid_target)
        <a id="change">self.log("train/f1"</a>, self.train_f1<a id="change">, on_step=False, on_epoch=True, prog_bar=True)</a>

        <a id="change">return </a>loss

    def validation_step(self, batch: TransformerTokenClassificationModelStepBatchEncoding, batch_idx):  &#47&#47 type: ignore
        input_, target = batch</code></pre><h3>After Change</h3><pre><code class='java'>
        return loss

    def training_step(self, batch: TransformerTokenClassificationModelStepBatchEncoding, batch_idx: int):  &#47&#47 type: ignore
        <a id="change">return self.step(stage=TRAINING, batch=batch)</a>

    def validation_step(self, batch: TransformerTokenClassificationModelStepBatchEncoding, batch_idx: int):  &#47&#47 type: ignore
        return self.step(stage=VALIDATION, batch=batch)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/christophalt/pytorch-ie/commit/b614ef74d4488df2fb51ff945d95709e3d9436ed#diff-0e5755f9b1c90521b8aa742c154ff6198f4808698a677d44b3833079308924cdL45' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2143777</div><div id='project'> Project Name: christophalt/pytorch-ie</div><div id='commit'> Commit Name: b614ef74d4488df2fb51ff945d95709e3d9436ed</div><div id='time'> Time: 2022-04-15</div><div id='author'> Author: ArneBinder@users.noreply.github.com</div><div id='file'> File Name: src/pytorch_ie/models/transformer_token_classification.py</div><div id='m_class'> M Class Name: TransformerTokenClassificationModel</div><div id='n_method'> N Class Name: TransformerTokenClassificationModel</div><div id='m_method'> M Method Name: training_step(3)</div><div id='n_method'> N Method Name: training_step(3)</div><div id='m_parent_class'> M Parent Class: PyTorchIEModel</div><div id='n_parent_class'> N Parent Class: PyTorchIEModel</div><div id='m_file'> M File Name: src/pytorch_ie/models/transformer_token_classification.py</div><div id='n_file'> N File Name: src/pytorch_ie/models/transformer_token_classification.py</div><div id='m_start'> M Start Line: 45</div><div id='m_end'> M End Line: 66</div><div id='n_start'> N Start Line: 85</div><div id='n_end'> N End Line: 86</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        }

    def training_step(self, batch: TransformerSpanClassificationModelStepBatchEncoding, batch_idx):  &#47&#47 type: ignore
        input_<a id="change">, target_tuples</a> = batch
        assert target_tuples is not None, "target has to be available for training"

        output<a id="change"> = self(</a>input_<a id="change">)</a>

        logits = output["logits"]

        batch_size, seq_length = input_["input_ids"].shape
        seq_lengths = None
        if "attention_mask" in input_:
            seq_lengths = torch.sum(<a id="change">input_["attention_mask"]</a>, dim=-1)
        &#47&#47 TODO: Why is this not happening in TransformerSpanClassificationTaskModule.collate?
        target = self._expand_target_tuples(
            target_tuples=target_tuples,
            batch_size=batch_size,
            max_seq_length=seq_length,
            seq_lengths=seq_lengths,
        )
        target = target.to(logits.device)

        <a id="change">loss</a><a id="change"> = </a>self.loss_fct(logits, target)

        <a id="change">self.log("train/loss"</a>, loss<a id="change">, on_step=True, on_epoch=True, prog_bar=True)</a>

        self.train_f1(logits, target)
        <a id="change">self.log("train/f1"</a>, self.train_f1<a id="change">, on_step=False, on_epoch=True, prog_bar=True)</a>

        <a id="change">return </a>loss

    def validation_step(self, batch: TransformerSpanClassificationModelStepBatchEncoding, batch_idx):  &#47&#47 type: ignore
        input_, target_tuples = batch</code></pre><h3>After Change</h3><pre><code class='java'>
        return loss

    def training_step(self, batch: TransformerSpanClassificationModelStepBatchEncoding, batch_idx: int):  &#47&#47 type: ignore
        <a id="change">return self.step(stage=TRAINING, batch=batch, batch_idx=batch_idx)</a>

    def validation_step(self, batch: TransformerSpanClassificationModelStepBatchEncoding, batch_idx: int):  &#47&#47 type: ignore
        return self.step(stage=VALIDATION, batch=batch, batch_idx=batch_idx)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/christophalt/pytorch-ie/commit/11157646f07bcfe6e6e46f1a6ea56c1d4d1ca860#diff-4eee2b3f2e7abaf8b7619d611102ecf17a10455950240ed1eec04adac390e0f6L170' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2143778</div><div id='project'> Project Name: christophalt/pytorch-ie</div><div id='commit'> Commit Name: 11157646f07bcfe6e6e46f1a6ea56c1d4d1ca860</div><div id='time'> Time: 2022-05-05</div><div id='author'> Author: ArneBinder@users.noreply.github.com</div><div id='file'> File Name: src/pytorch_ie/models/transformer_span_classification.py</div><div id='m_class'> M Class Name: TransformerSpanClassificationModel</div><div id='n_method'> N Class Name: TransformerSpanClassificationModel</div><div id='m_method'> M Method Name: training_step(3)</div><div id='n_method'> N Method Name: training_step(3)</div><div id='m_parent_class'> M Parent Class: PyTorchIEModel</div><div id='n_parent_class'> N Parent Class: PyTorchIEModel</div><div id='m_file'> M File Name: src/pytorch_ie/models/transformer_span_classification.py</div><div id='n_file'> N File Name: src/pytorch_ie/models/transformer_span_classification.py</div><div id='m_start'> M Start Line: 170</div><div id='m_end'> M End Line: 198</div><div id='n_start'> N Start Line: 213</div><div id='n_end'> N End Line: 214</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        return loss

    def validation_step(self, batch: TransformerSpanClassificationModelStepBatchEncoding, batch_idx):  &#47&#47 type: ignore
        input_<a id="change">, target_tuples</a> = batch
        assert target_tuples is not None, "target has to be available for validation"

        output = <a id="change">self(</a>input_<a id="change">)</a>

        logits<a id="change"> = </a>output["logits"]

        batch_size, seq_length = input_["input_ids"].shape
        seq_lengths = None
        if "attention_mask" in input_:
            seq_lengths = torch.sum(<a id="change">input_["attention_mask"]</a>, dim=-1)

        &#47&#47 TODO: Why is this not happening in TransformerSpanClassificationTaskModule.collate?
        target = self._expand_target_tuples(
            target_tuples=target_tuples,
            batch_size=batch_size,
            max_seq_length=seq_length,
            seq_lengths=seq_lengths,
        )
        target = target.to(logits.device)

        <a id="change">loss</a><a id="change"> = </a>self.loss_fct(logits, target)

        <a id="change">self.log("val/loss"</a>, loss<a id="change">, on_step=False, on_epoch=True, prog_bar=True)</a>

        self.val_f1(logits, target)
        <a id="change">self.log("val/f1"</a>, self.val_f1<a id="change">, on_step=False, on_epoch=True, prog_bar=True)</a>

        <a id="change">return </a>loss

    def configure_optimizers(self):
        param_optimizer = list(self.named_parameters())</code></pre><h3>After Change</h3><pre><code class='java'>
        return self.step(stage=TRAINING, batch=batch, batch_idx=batch_idx)

    def validation_step(self, batch: TransformerSpanClassificationModelStepBatchEncoding, batch_idx: int):  &#47&#47 type: ignore
        <a id="change">return self.step(stage=VALIDATION, batch=batch, batch_idx=batch_idx)</a>

    def test_step(self, batch: TransformerSpanClassificationModelStepBatchEncoding, batch_idx: int):  &#47&#47 type: ignore
        return self.step(stage=TEST, batch=batch, batch_idx=batch_idx)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/christophalt/pytorch-ie/commit/11157646f07bcfe6e6e46f1a6ea56c1d4d1ca860#diff-4eee2b3f2e7abaf8b7619d611102ecf17a10455950240ed1eec04adac390e0f6L200' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2143794</div><div id='project'> Project Name: christophalt/pytorch-ie</div><div id='commit'> Commit Name: 11157646f07bcfe6e6e46f1a6ea56c1d4d1ca860</div><div id='time'> Time: 2022-05-05</div><div id='author'> Author: ArneBinder@users.noreply.github.com</div><div id='file'> File Name: src/pytorch_ie/models/transformer_span_classification.py</div><div id='m_class'> M Class Name: TransformerSpanClassificationModel</div><div id='n_method'> N Class Name: TransformerSpanClassificationModel</div><div id='m_method'> M Method Name: validation_step(3)</div><div id='n_method'> N Method Name: validation_step(3)</div><div id='m_parent_class'> M Parent Class: PyTorchIEModel</div><div id='n_parent_class'> N Parent Class: PyTorchIEModel</div><div id='m_file'> M File Name: src/pytorch_ie/models/transformer_span_classification.py</div><div id='n_file'> N File Name: src/pytorch_ie/models/transformer_span_classification.py</div><div id='m_start'> M Start Line: 200</div><div id='m_end'> M End Line: 229</div><div id='n_start'> N Start Line: 216</div><div id='n_end'> N End Line: 217</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        return loss

    def validation_step(self, batch: TransformerTokenClassificationModelStepBatchEncoding, batch_idx):  &#47&#47 type: ignore
        input_<a id="change">, target</a> = batch
        assert target is not None, "target has to be available for validation"

        <a id="change">input_["labels"]</a> = target
        output<a id="change"> = self(</a>input_<a id="change">)</a>

        <a id="change">loss</a><a id="change"> = </a>output.loss
        <a id="change">self.log("val/loss"</a>, loss<a id="change">, on_step=False, on_epoch=True, prog_bar=True)</a>

        target_flat = target.view(-1)

        valid_indices = target_flat != self.label_pad_token_id
        &#47&#47 ignore typing because hparams is Union
        num_classes: int = self.hparams.num_classes  &#47&#47 type: ignore
        valid_logits = output.logits.view(-1, num_classes)[valid_indices]
        valid_target = target_flat[valid_indices]

        self.val_f1(valid_logits, valid_target)
        <a id="change">self.log("val/f1"</a>, self.val_f1<a id="change">, on_step=False, on_epoch=True, prog_bar=True)</a>

        <a id="change">return </a>loss

    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)</code></pre><h3>After Change</h3><pre><code class='java'>
        return self.step(stage=TRAINING, batch=batch)

    def validation_step(self, batch: TransformerTokenClassificationModelStepBatchEncoding, batch_idx: int):  &#47&#47 type: ignore
        <a id="change">return self.step(stage=VALIDATION, batch=batch)</a>

    def test_step(self, batch: TransformerTokenClassificationModelStepBatchEncoding, batch_idx: int):  &#47&#47 type: ignore
        return self.step(stage=TEST, batch=batch)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/christophalt/pytorch-ie/commit/b614ef74d4488df2fb51ff945d95709e3d9436ed#diff-0e5755f9b1c90521b8aa742c154ff6198f4808698a677d44b3833079308924cdL68' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2143784</div><div id='project'> Project Name: christophalt/pytorch-ie</div><div id='commit'> Commit Name: b614ef74d4488df2fb51ff945d95709e3d9436ed</div><div id='time'> Time: 2022-04-15</div><div id='author'> Author: ArneBinder@users.noreply.github.com</div><div id='file'> File Name: src/pytorch_ie/models/transformer_token_classification.py</div><div id='m_class'> M Class Name: TransformerTokenClassificationModel</div><div id='n_method'> N Class Name: TransformerTokenClassificationModel</div><div id='m_method'> M Method Name: validation_step(3)</div><div id='n_method'> N Method Name: validation_step(3)</div><div id='m_parent_class'> M Parent Class: PyTorchIEModel</div><div id='n_parent_class'> N Parent Class: PyTorchIEModel</div><div id='m_file'> M File Name: src/pytorch_ie/models/transformer_token_classification.py</div><div id='n_file'> N File Name: src/pytorch_ie/models/transformer_token_classification.py</div><div id='m_start'> M Start Line: 68</div><div id='m_end'> M End Line: 89</div><div id='n_start'> N Start Line: 88</div><div id='n_end'> N End Line: 89</div><BR>