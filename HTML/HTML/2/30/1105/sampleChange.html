<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 2. shape [B Len] means the item has single-feature, i.e. one store could only in one city.

        pos_features = <a id="change">pos_features.to(</a>item_list.device<a id="change">)</a>
        <a id="change">feature_emb</a> = <a id="change">self.feature_embedding(</a>pos_features<a id="change">)</a>
        &#47&#47 get feature_trm_input
        if <a id="change">pos_features.dim() == 3</a>:
            feature_mask<a id="change"> = </a><a id="change">(pos_features != 0).float()</a>
            feature_mask<a id="change"> = </a><a id="change">feature_mask.unsqueeze(-1).expand_as(feature_emb</a><a id="change">)</a>
            feature_emb<a id="change"> = </a><a id="change">(feature_emb * feature_mask).sum(dim=-2)</a>  &#47&#47 [B Len H]
        &#47&#47 feature position add position embedding

        feature_emb = feature_emb + position_embedding</code></pre><h3>After Change</h3><pre><code class='java'>
        item_emb = self.LayerNorm(item_emb)
        item_trm_input = self.dropout(item_emb)

        <a id="change">sparse_embedding</a><a id="change">, dense_embedding</a> = self.embed_input_fields(item_seq)
        &#47&#47 concat the sparse embedding and float embedding
        feature_table = <a id="change">[]</a>
        <a id="change">if sparse_embedding is not None</a>:
            <a id="change">feature_table.append(sparse_embedding</a><a id="change">)</a>
        if <a id="change">dense_embedding is not None</a>:
            <a id="change">feature_table.append(dense_embedding</a><a id="change">)</a>

        &#47&#47 [batch len num_features hidden_size]
        feature_table<a id="change"> = </a><a id="change">torch.cat(</a>feature_table<a id="change">, dim=1)</a>

        &#47&#47 feature_emb [batch len hidden]
        &#47&#47 weight [batch len num_features]
        &#47&#47 if only one feature, the weight would be 1.0

        feature_emb<a id="change">, attn_weight = </a>self.feature_att_layer(feature_table)
        &#47&#47 feature position add position embedding
        feature_emb = feature_emb + position_embedding
        feature_emb = self.LayerNorm(feature_emb)</code></pre>