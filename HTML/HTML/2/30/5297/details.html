<html><h3>Pattern ID :5297
</h3><img src='18993441.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    <a id="change">normalize</a> = <a id="change">T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])</a>
    train_transform = <a id="change">T.Compose(</a><a id="change">[
        T.RandomResizedCrop(224</a><a id="change">, scale=(0.7, 1.0))</a>,
        <a id="change">T.RandomHorizontalFlip()</a>,
        <a id="change">T.ColorJitter(0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a><a id="change">)</a>,
        <a id="change">T.RandomGrayscale()</a>,
        <a id="change">T.ToTensor()</a>,
        <a id="change">normalize</a>
    ]<a id="change">)</a>
    val_transform<a id="change"> = T</a><a id="change">.Compose(</a><a id="change">[
        ResizeImage(224</a><a id="change">)</a>,
        <a id="change">T.ToTensor()</a>,
        <a id="change">normalize</a>
    ]<a id="change">)</a>

    train_dataset, num_classes = get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                             split=&quottrain&quot, download=True, transform=train_transform,
                                             seed=args.seed)</code></pre><h3>After Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    train_transform = <a id="change">utils.get_train_transform(</a>args.train_resizing<a id="change">, random_horizontal_flip=True,
                                                random_color_jitter=True, random_gray_scale=True)</a>
    val_transform = <a id="change">utils.get_val_transform(</a>args.val_resizing<a id="change">)</a>
    <a id="change">print("train_transform: "</a>, train_transform<a id="change">)</a>
    <a id="change">print("val_transform: "</a>, val_transform<a id="change">)</a>

    train_dataset, num_classes = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                                   split=&quottrain&quot, download=True, transform=train_transform,
                                                   seed=args.seed)
    sampler = RandomDomainSampler(train_dataset, args.batch_size, num_select_domains=2)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=args.workers,
                              sampler=sampler, drop_last=True)
    val_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources, split=&quotval&quot,
                                       download=True, transform=val_transform, seed=args.seed)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    test_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.targets, split=&quotall&quot,
                                        download=True, transform=val_transform, seed=args.seed)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)

    print("Source Train:", len(train_dataset))
    print(&quotSource Val:&quot, len(val_dataset))
    print("Target:", len(test_dataset))
    train_iter = ForeverDataIterator(train_loader)

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = models.__dict__[args.arch](mix_layers=args.mix_layers, mix_p=args.mix_p, mix_alpha=args.mix_alpha,
                                          pretrained=True)
    pool_layer = nn.Identity() if args.no_pool else None
    classifier = Classifier(backbone, num_classes, freeze_bn=args.freeze_bn, dropout_p=args.dropout_p,
                            finetune=args.finetune, pool_layer=pool_layer).to(device)

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(base_lr=args.lr), args.lr, momentum=args.momentum, weight_decay=args.wd,
                    nesterov=True)
    lr_scheduler = CosineAnnealingLR(optimizer, args.epochs * args.iters_per_epoch)

    if args.phase == &quottest&quot:
        checkpoint = torch.load(logger.get_checkpoint_path(&quotbest&quot), map_location=&quotcpu&quot)
        classifier.load_state_dict(checkpoint)
        acc1 = utils.validate(test_loader, classifier, args, device)
        print(acc1)
        return

    &#47&#47 start training
    best_val_acc1 = 0.
    best_test_acc1 = 0.
    for epoch in range(args.epochs):
        print(lr_scheduler.get_lr())
        &#47&#47 train for one epoch
        train(train_iter, classifier, optimizer, lr_scheduler, epoch, args)

        &#47&#47 evaluate on validation set
        print("Validation on source domain...")
        acc1 = utils.validate(val_loader, classifier, args, device)

        &#47&#47 remember best acc@1 and save checkpoint
        torch.save(classifier.state_dict(), logger.get_checkpoint_path(&quotlatest&quot))
        if acc1 &gt; best_val_acc1:
            shutil.copy(logger.get_checkpoint_path(&quotlatest&quot), logger.get_checkpoint_path(&quotbest&quot))
        best_val_acc1 = max(acc1, best_val_acc1)

        &#47&#47 evaluate on test set
        print("Test on target domain...")
        best_test_acc1 = max(best_test_acc1, utils.validate(test_loader, classifier, args, device))

    &#47&#47 evaluate on test set
    classifier.load_state_dict(torch.load(logger.get_checkpoint_path(&quotbest&quot)))
    acc1<a id="change"> = utils</a><a id="change">.validate(</a>test_loader, classifier, args, device<a id="change">)</a>
    print("test acc on target = {}".format(acc1))
    print("oracle acc on target = {}".format(best_test_acc1))
    logger.close()
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 7</div><BR><div id='size'>Non-data size: 19</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/53b9f6e20d72d01f46d9d293f8f3781881052ca1#diff-73c227cfeeb353f8347da76ef5c373f0584126b28ed5354830423ec3c3418660L48' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 18993441</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 53b9f6e20d72d01f46d9d293f8f3781881052ca1</div><div id='time'> Time: 2021-08-08</div><div id='author'> Author: chenbx18@mails.tsinghua.edu.cn</div><div id='file'> File Name: examples/domain_generalization/classification/mixstyle.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/domain_generalization/classification/mixstyle.py</div><div id='n_file'> N File Name: examples/domain_generalization/classification/mixstyle.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 124</div><div id='n_start'> N Start Line: 48</div><div id='n_end'> N End Line: 116</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    <a id="change">normalize</a> = <a id="change">T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])</a>
    train_transform = <a id="change">T.Compose(</a><a id="change">[
        T.RandomResizedCrop(224</a><a id="change">, scale=(0.7, 1.0))</a>,
        <a id="change">T.RandomHorizontalFlip()</a>,
        <a id="change">T.ColorJitter(0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a><a id="change">)</a>,
        <a id="change">T.RandomGrayscale()</a>,
        <a id="change">T.ToTensor()</a>,
        normalize<a id="change"></a>
    ]<a id="change">)</a>
    val_transform<a id="change"> = </a><a id="change">T.Compose(</a><a id="change">[
        ResizeImage(224</a><a id="change">)</a>,
        <a id="change">T.ToTensor()</a>,
        normalize<a id="change"></a>
    ]<a id="change">)</a>

    train_dataset, num_classes = get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                             split=&quottrain&quot, download=True, transform=train_transform,
                                             seed=args.seed)</code></pre><h3>After Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    train_transform = <a id="change">utils.get_train_transform(</a>args.train_resizing<a id="change">, random_horizontal_flip=True,
                                                random_color_jitter=True, random_gray_scale=True)</a>
    val_transform = <a id="change">utils.get_val_transform(</a>args.val_resizing<a id="change">)</a>
    <a id="change">print("train_transform: "</a>, train_transform<a id="change">)</a>
    <a id="change">print("val_transform: "</a>, val_transform<a id="change">)</a>

    train_dataset, num_classes = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                                   split=&quottrain&quot, download=True, transform=train_transform,
                                                   seed=args.seed)
    sampler = DefaultSampler(train_dataset, args.batch_size)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=args.workers,
                              sampler=sampler, drop_last=True)
    val_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources, split=&quotval&quot,
                                       download=True, transform=val_transform, seed=args.seed)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    test_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.targets, split=&quotall&quot,
                                        download=True, transform=val_transform, seed=args.seed)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    print("Source Train:", len(train_dataset))
    print(&quotSource Val:&quot, len(val_dataset))
    print("Target:", len(test_dataset))
    train_iter = ForeverDataIterator(train_loader)

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = utils.get_model(args.arch)
    pool_layer = nn.Identity() if args.no_pool else None
    classifier = Classifier(backbone, num_classes, freeze_bn=args.freeze_bn, dropout_p=args.dropout_p,
                            finetune=args.finetune, pool_layer=pool_layer).to(device)
    num_domains = len(args.sources)

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(base_lr=args.lr), args.lr, momentum=args.momentum, weight_decay=args.wd,
                    nesterov=True)
    lr_scheduler = CosineAnnealingLR(optimizer, args.epochs * args.iters_per_epoch)

    &#47&#47 define loss function
    correlation_alignment_loss = CorrelationAlignmentLoss().to(device)

    if args.phase == &quottest&quot:
        checkpoint = torch.load(logger.get_checkpoint_path(&quotbest&quot), map_location=&quotcpu&quot)
        classifier.load_state_dict(checkpoint)
        acc1 = utils.validate(test_loader, classifier, args, device)
        print(acc1)
        return

    &#47&#47 start training
    best_val_acc1 = 0.
    best_test_acc1 = 0.
    for epoch in range(args.epochs):

        print(lr_scheduler.get_lr())
        &#47&#47 train for one epoch
        train(train_iter, classifier, optimizer, lr_scheduler, correlation_alignment_loss, num_domains, epoch, args)

        &#47&#47 evaluate on validation set
        print("Validation on source domain...")
        acc1 = utils.validate(val_loader, classifier, args, device)

        &#47&#47 remember best acc@1 and save checkpoint
        torch.save(classifier.state_dict(), logger.get_checkpoint_path(&quotlatest&quot))
        if acc1 &gt; best_val_acc1:
            shutil.copy(logger.get_checkpoint_path(&quotlatest&quot), logger.get_checkpoint_path(&quotbest&quot))
        best_val_acc1 = max(acc1, best_val_acc1)

        &#47&#47 evaluate on test set
        print("Test on target domain...")
        best_test_acc1 = max(best_test_acc1, utils.validate(test_loader, classifier, args, device))

    &#47&#47 evaluate on test set
    classifier.load_state_dict(torch.load(logger.get_checkpoint_path(&quotbest&quot)))
    acc1<a id="change"> = </a><a id="change">utils.validate(</a>test_loader, classifier, args, device<a id="change">)</a>
    print("test acc on target = {}".format(acc1))
    print("oracle acc on target = {}".format(best_test_acc1))
    logger.close()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/53b9f6e20d72d01f46d9d293f8f3781881052ca1#diff-e79b6d2963b4227ee192d8eeed89eba5543d45929f7717a5a9d21d7b23162bf1L33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 18993409</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 53b9f6e20d72d01f46d9d293f8f3781881052ca1</div><div id='time'> Time: 2021-08-08</div><div id='author'> Author: chenbx18@mails.tsinghua.edu.cn</div><div id='file'> File Name: examples/domain_generalization/classification/coral.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/domain_generalization/classification/coral.py</div><div id='n_file'> N File Name: examples/domain_generalization/classification/coral.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 129</div><div id='n_start'> N Start Line: 48</div><div id='n_end'> N End Line: 119</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    <a id="change">normalize</a> = <a id="change">T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])</a>
    train_transform = <a id="change">T.Compose(</a><a id="change">[
        T.RandomResizedCrop(224</a><a id="change">, scale=(0.7, 1.0))</a>,
        <a id="change">T.RandomHorizontalFlip()</a>,
        <a id="change">T.ColorJitter(0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a><a id="change">)</a>,
        <a id="change">T.RandomGrayscale()</a>,
        <a id="change">T.ToTensor()</a>,
        normalize<a id="change"></a>
    ]<a id="change">)</a>
    val_transform<a id="change"> = </a><a id="change">T.Compose(</a><a id="change">[
        ResizeImage(224</a><a id="change">)</a>,
        <a id="change">T.ToTensor()</a>,
        normalize<a id="change"></a>
    ]<a id="change">)</a>

    train_dataset, num_classes = get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                             split=&quottrain&quot, download=True, transform=train_transform,
                                             seed=args.seed)</code></pre><h3>After Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    train_transform = <a id="change">utils.get_train_transform(</a>args.train_resizing<a id="change">, random_horizontal_flip=True,
                                                random_color_jitter=True, random_gray_scale=True)</a>
    val_transform = <a id="change">utils.get_val_transform(</a>args.val_resizing<a id="change">)</a>
    <a id="change">print("train_transform: "</a>, train_transform<a id="change">)</a>
    <a id="change">print("val_transform: "</a>, val_transform<a id="change">)</a>

    train_dataset, num_classes = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                                   split=&quottrain&quot, download=True, transform=train_transform,
                                                   seed=args.seed)
    sampler = RandomDomainSampler(train_dataset, args.batch_size, num_select_domains=2)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=args.workers,
                              sampler=sampler, drop_last=True)
    val_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources, split=&quotval&quot,
                                       download=True, transform=val_transform, seed=args.seed)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    test_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.targets, split=&quotall&quot,
                                        download=True, transform=val_transform, seed=args.seed)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)

    print("Source Train:", len(train_dataset))
    print(&quotSource Val:&quot, len(val_dataset))
    print("Target:", len(test_dataset))
    train_iter = ForeverDataIterator(train_loader)

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = models.__dict__[args.arch](mix_layers=args.mix_layers, mix_p=args.mix_p, mix_alpha=args.mix_alpha,
                                          pretrained=True)
    pool_layer = nn.Identity() if args.no_pool else None
    classifier = Classifier(backbone, num_classes, freeze_bn=args.freeze_bn, dropout_p=args.dropout_p,
                            finetune=args.finetune, pool_layer=pool_layer).to(device)

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(base_lr=args.lr), args.lr, momentum=args.momentum, weight_decay=args.wd,
                    nesterov=True)
    lr_scheduler = CosineAnnealingLR(optimizer, args.epochs * args.iters_per_epoch)

    if args.phase == &quottest&quot:
        checkpoint = torch.load(logger.get_checkpoint_path(&quotbest&quot), map_location=&quotcpu&quot)
        classifier.load_state_dict(checkpoint)
        acc1 = utils.validate(test_loader, classifier, args, device)
        print(acc1)
        return

    &#47&#47 start training
    best_val_acc1 = 0.
    best_test_acc1 = 0.
    for epoch in range(args.epochs):
        print(lr_scheduler.get_lr())
        &#47&#47 train for one epoch
        train(train_iter, classifier, optimizer, lr_scheduler, epoch, args)

        &#47&#47 evaluate on validation set
        print("Validation on source domain...")
        acc1 = utils.validate(val_loader, classifier, args, device)

        &#47&#47 remember best acc@1 and save checkpoint
        torch.save(classifier.state_dict(), logger.get_checkpoint_path(&quotlatest&quot))
        if acc1 &gt; best_val_acc1:
            shutil.copy(logger.get_checkpoint_path(&quotlatest&quot), logger.get_checkpoint_path(&quotbest&quot))
        best_val_acc1 = max(acc1, best_val_acc1)

        &#47&#47 evaluate on test set
        print("Test on target domain...")
        best_test_acc1 = max(best_test_acc1, utils.validate(test_loader, classifier, args, device))

    &#47&#47 evaluate on test set
    classifier.load_state_dict(torch.load(logger.get_checkpoint_path(&quotbest&quot)))
    acc1<a id="change"> = </a><a id="change">utils.validate(</a>test_loader, classifier, args, device<a id="change">)</a>
    print("test acc on target = {}".format(acc1))
    print("oracle acc on target = {}".format(best_test_acc1))
    logger.close()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/53b9f6e20d72d01f46d9d293f8f3781881052ca1#diff-73c227cfeeb353f8347da76ef5c373f0584126b28ed5354830423ec3c3418660L32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 18993440</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 53b9f6e20d72d01f46d9d293f8f3781881052ca1</div><div id='time'> Time: 2021-08-08</div><div id='author'> Author: chenbx18@mails.tsinghua.edu.cn</div><div id='file'> File Name: examples/domain_generalization/classification/mixstyle.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/domain_generalization/classification/mixstyle.py</div><div id='n_file'> N File Name: examples/domain_generalization/classification/mixstyle.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 124</div><div id='n_start'> N Start Line: 48</div><div id='n_end'> N End Line: 116</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    <a id="change">normalize</a> = <a id="change">T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])</a>
    train_transform = <a id="change">T.Compose(</a><a id="change">[
        T.RandomResizedCrop(224</a><a id="change">, scale=(0.7, 1.0))</a>,
        <a id="change">T.RandomHorizontalFlip()</a>,
        <a id="change">T.ColorJitter(0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a><a id="change">)</a>,
        <a id="change">T.RandomGrayscale()</a>,
        <a id="change">T.ToTensor()</a>,
        normalize<a id="change"></a>
    ]<a id="change">)</a>
    val_transform<a id="change"> = </a><a id="change">T.Compose(</a><a id="change">[
        ResizeImage(224</a><a id="change">)</a>,
        <a id="change">T.ToTensor()</a>,
        normalize<a id="change"></a>
    ]<a id="change">)</a>

    train_dataset, num_classes = get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                             split=&quottrain&quot, download=True, transform=train_transform,
                                             seed=args.seed)</code></pre><h3>After Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    train_transform = <a id="change">utils.get_train_transform(</a>args.train_resizing<a id="change">, random_horizontal_flip=True,
                                                random_color_jitter=True, random_gray_scale=True)</a>
    val_transform = <a id="change">utils.get_val_transform(</a>args.val_resizing<a id="change">)</a>
    <a id="change">print("train_transform: "</a>, train_transform<a id="change">)</a>
    <a id="change">print("val_transform: "</a>, val_transform<a id="change">)</a>

    train_dataset, num_classes = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                                   split=&quottrain&quot, download=True, transform=train_transform,
                                                   seed=args.seed)
    num_select_domains = args.num_support_domains + args.num_query_domains
    sampler = RandomDomainSampler(train_dataset, args.batch_size, num_select_domains=num_select_domains)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=args.workers,
                              sampler=sampler, drop_last=True)
    val_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources, split=&quotval&quot,
                                       download=True, transform=val_transform, seed=args.seed)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    test_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.targets, split=&quotall&quot,
                                        download=True, transform=val_transform, seed=args.seed)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    print("Source Train:", len(train_dataset))
    print(&quotSource Val:&quot, len(val_dataset))
    print("Target:", len(test_dataset))
    train_iter = ForeverDataIterator(train_loader)

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = utils.get_model(args.arch)
    pool_layer = nn.Identity() if args.no_pool else None
    classifier = Classifier(backbone, num_classes, freeze_bn=args.freeze_bn, dropout_p=args.dropout_p,
                            finetune=args.finetune, pool_layer=pool_layer).to(device)

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(base_lr=args.lr), args.lr, momentum=args.momentum, weight_decay=args.wd,
                    nesterov=True)
    lr_scheduler = CosineAnnealingLR(optimizer, args.epochs * args.iters_per_epoch)

    if args.phase == &quottest&quot:
        checkpoint = torch.load(logger.get_checkpoint_path(&quotbest&quot), map_location=&quotcpu&quot)
        classifier.load_state_dict(checkpoint)
        acc1 = utils.validate(test_loader, classifier, args, device)
        print(acc1)
        return

    &#47&#47 start training
    best_val_acc1 = 0.
    best_test_acc1 = 0.
    for epoch in range(args.epochs):
        print(lr_scheduler.get_lr())
        &#47&#47 train for one epoch
        train(train_iter, classifier, optimizer, lr_scheduler, epoch, num_select_domains, args)

        &#47&#47 evaluate on validation set
        print("Validation on source domain...")
        acc1 = utils.validate(val_loader, classifier, args, device)

        &#47&#47 remember best acc@1 and save checkpoint
        torch.save(classifier.state_dict(), logger.get_checkpoint_path(&quotlatest&quot))
        if acc1 &gt; best_val_acc1:
            shutil.copy(logger.get_checkpoint_path(&quotlatest&quot), logger.get_checkpoint_path(&quotbest&quot))
        best_val_acc1 = max(acc1, best_val_acc1)

        &#47&#47 evaluate on test set
        print("Test on target domain...")
        best_test_acc1 = max(best_test_acc1, utils.validate(test_loader, classifier, args, device))

    &#47&#47 evaluate on test set
    classifier.load_state_dict(torch.load(logger.get_checkpoint_path(&quotbest&quot)))
    acc1<a id="change"> = </a><a id="change">utils.validate(</a>test_loader, classifier, args, device<a id="change">)</a>
    print("test acc on target = {}".format(acc1))
    print("oracle acc on target = {}".format(best_test_acc1))
    logger.close()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/53b9f6e20d72d01f46d9d293f8f3781881052ca1#diff-4dfec7e74afd5b19ad22667d6819badf4de835a858df15ee5d2da71b271ce7ecL33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 18993443</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 53b9f6e20d72d01f46d9d293f8f3781881052ca1</div><div id='time'> Time: 2021-08-08</div><div id='author'> Author: chenbx18@mails.tsinghua.edu.cn</div><div id='file'> File Name: examples/domain_generalization/classification/mldg.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/domain_generalization/classification/mldg.py</div><div id='n_file'> N File Name: examples/domain_generalization/classification/mldg.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 124</div><div id='n_start'> N Start Line: 48</div><div id='n_end'> N End Line: 115</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    <a id="change">normalize</a> = <a id="change">T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])</a>
    train_transform = <a id="change">T.Compose(</a><a id="change">[
        T.RandomResizedCrop(224</a><a id="change">, scale=(0.7, 1.0))</a>,
        <a id="change">T.RandomHorizontalFlip()</a>,
        <a id="change">T.ColorJitter(0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a><a id="change">)</a>,
        <a id="change">T.RandomGrayscale()</a>,
        <a id="change">T.ToTensor()</a>,
        normalize<a id="change"></a>
    ]<a id="change">)</a>
    val_transform<a id="change"> = </a><a id="change">T.Compose(</a><a id="change">[
        ResizeImage(224</a><a id="change">)</a>,
        <a id="change">T.ToTensor()</a>,
        normalize<a id="change"></a>
    ]<a id="change">)</a>

    train_dataset, num_classes = get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                             split=&quottrain&quot, download=True, transform=train_transform,
                                             seed=args.seed)</code></pre><h3>After Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    train_transform = <a id="change">utils.get_train_transform(</a>args.train_resizing<a id="change">, random_horizontal_flip=True,
                                                random_color_jitter=True, random_gray_scale=True)</a>
    val_transform = <a id="change">utils.get_val_transform(</a>args.val_resizing<a id="change">)</a>
    <a id="change">print("train_transform: "</a>, train_transform<a id="change">)</a>
    <a id="change">print("val_transform: "</a>, val_transform<a id="change">)</a>

    train_dataset, num_classes = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                                   split=&quottrain&quot, download=True, transform=train_transform,
                                                   seed=args.seed)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size,
                              shuffle=True, num_workers=args.workers, drop_last=True)
    val_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources, split=&quotval&quot,
                                       download=True, transform=val_transform, seed=args.seed)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    test_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.targets, split=&quotall&quot,
                                        download=True, transform=val_transform, seed=args.seed)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)

    print("Source Train:", len(train_dataset))
    print(&quotSource Val:&quot, len(val_dataset))
    print("Target:", len(test_dataset))
    train_iter = ForeverDataIterator(train_loader)

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = utils.get_model(args.arch)
    pool_layer = nn.Identity() if args.no_pool else None
    classifier = Classifier(backbone, num_classes, freeze_bn=args.freeze_bn, dropout_p=args.dropout_p,
                            finetune=args.finetune, pool_layer=pool_layer).to(device)

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(base_lr=args.lr), args.lr, momentum=args.momentum, weight_decay=args.wd,
                    nesterov=True)
    lr_scheduler = CosineAnnealingLR(optimizer, args.epochs * args.iters_per_epoch)

    if args.phase == &quottest&quot:
        checkpoint = torch.load(logger.get_checkpoint_path(&quotbest&quot), map_location=&quotcpu&quot)
        classifier.load_state_dict(checkpoint)
        acc1 = utils.validate(test_loader, classifier, args, device)
        print(acc1)
        return

    &#47&#47 start training
    best_val_acc1 = 0.
    best_test_acc1 = 0.
    for epoch in range(args.epochs):
        print(lr_scheduler.get_lr())
        &#47&#47 train for one epoch
        train(train_iter, classifier, optimizer, lr_scheduler, epoch, args)

        &#47&#47 evaluate on validation set
        print("Validation on source domain...")
        acc1 = utils.validate(val_loader, classifier, args, device)

        &#47&#47 remember best acc@1 and save checkpoint
        torch.save(classifier.state_dict(), logger.get_checkpoint_path(&quotlatest&quot))
        if acc1 &gt; best_val_acc1:
            shutil.copy(logger.get_checkpoint_path(&quotlatest&quot), logger.get_checkpoint_path(&quotbest&quot))
        best_val_acc1 = max(acc1, best_val_acc1)

        &#47&#47 evaluate on test set
        print("Test on target domain...")
        best_test_acc1 = max(best_test_acc1, utils.validate(test_loader, classifier, args, device))

    &#47&#47 evaluate on test set
    classifier.load_state_dict(torch.load(logger.get_checkpoint_path(&quotbest&quot)))
    acc1<a id="change"> = </a><a id="change">utils.validate(</a>test_loader, classifier, args, device<a id="change">)</a>
    print("test acc on target = {}".format(acc1))
    print("oracle acc on target = {}".format(best_test_acc1))
    logger.close()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/53b9f6e20d72d01f46d9d293f8f3781881052ca1#diff-a7ecd800de571a9301c4e503b6d71a3bbdde71d89b25a618f977064c2498346eL31' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 18993411</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 53b9f6e20d72d01f46d9d293f8f3781881052ca1</div><div id='time'> Time: 2021-08-08</div><div id='author'> Author: chenbx18@mails.tsinghua.edu.cn</div><div id='file'> File Name: examples/domain_generalization/classification/baseline.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/domain_generalization/classification/baseline.py</div><div id='n_file'> N File Name: examples/domain_generalization/classification/baseline.py</div><div id='m_start'> M Start Line: 48</div><div id='m_end'> M End Line: 122</div><div id='n_start'> N Start Line: 46</div><div id='n_end'> N End Line: 112</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    <a id="change">normalize</a> = <a id="change">T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])</a>
    train_transform = <a id="change">T.Compose(</a><a id="change">[
        T.RandomResizedCrop(224</a><a id="change">, scale=(0.7, 1.0))</a>,
        <a id="change">T.RandomHorizontalFlip()</a>,
        <a id="change">T.ColorJitter(0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a><a id="change">)</a>,
        <a id="change">T.RandomGrayscale()</a>,
        <a id="change">T.ToTensor()</a>,
        normalize<a id="change"></a>
    ]<a id="change">)</a>
    val_transform<a id="change"> = </a><a id="change">T.Compose(</a><a id="change">[
        ResizeImage(224</a><a id="change">)</a>,
        <a id="change">T.ToTensor()</a>,
        normalize<a id="change"></a>
    ]<a id="change">)</a>

    train_dataset, num_classes = get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                             split=&quottrain&quot, download=True, transform=train_transform,
                                             seed=args.seed)</code></pre><h3>After Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    train_transform = <a id="change">utils.get_train_transform(</a>args.train_resizing<a id="change">, random_horizontal_flip=True,
                                                random_color_jitter=True, random_gray_scale=True)</a>
    val_transform = <a id="change">utils.get_val_transform(</a>args.val_resizing<a id="change">)</a>
    <a id="change">print("train_transform: "</a>, train_transform<a id="change">)</a>
    <a id="change">print("val_transform: "</a>, val_transform<a id="change">)</a>

    train_dataset, num_classes = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                                   split=&quottrain&quot, download=True, transform=train_transform,
                                                   seed=args.seed)
    sampler = DefaultSampler(train_dataset, args.batch_size)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=args.workers,
                              sampler=sampler, drop_last=True)
    val_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources, split=&quotval&quot,
                                       download=True, transform=val_transform, seed=args.seed)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    test_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.targets, split=&quotall&quot,
                                        download=True, transform=val_transform, seed=args.seed)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    print("Source Train:", len(train_dataset))
    print(&quotSource Val:&quot, len(val_dataset))
    print("Target:", len(test_dataset))
    train_iter = ForeverDataIterator(train_loader)

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = utils.get_model(args.arch)
    pool_layer = nn.Identity() if args.no_pool else None
    classifier = Classifier(backbone, num_classes, freeze_bn=args.freeze_bn, dropout_p=args.dropout_p,
                            finetune=args.finetune, pool_layer=pool_layer).to(device)
    num_domains = len(args.sources)

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(base_lr=args.lr), args.lr, momentum=args.momentum, weight_decay=args.wd,
                    nesterov=True)
    lr_scheduler = CosineAnnealingLR(optimizer, args.epochs * args.iters_per_epoch)
    domain_weight_module = AutomaticUpdateDomainWeightModule(num_domains, args.eta, device)

    if args.phase == &quottest&quot:
        checkpoint = torch.load(logger.get_checkpoint_path(&quotbest&quot), map_location=&quotcpu&quot)
        classifier.load_state_dict(checkpoint)
        acc1 = utils.validate(test_loader, classifier, args, device)
        print(acc1)
        return

    &#47&#47 start training
    best_val_acc1 = 0.
    best_test_acc1 = 0.
    for epoch in range(args.epochs):
        print(lr_scheduler.get_lr())
        &#47&#47 train for one epoch
        train(train_iter, classifier, optimizer, lr_scheduler, domain_weight_module, num_domains, epoch, args)

        &#47&#47 evaluate on validation set
        print("Validation on source domain...")
        acc1 = utils.validate(val_loader, classifier, args, device)

        &#47&#47 remember best acc@1 and save checkpoint
        torch.save(classifier.state_dict(), logger.get_checkpoint_path(&quotlatest&quot))
        if acc1 &gt; best_val_acc1:
            shutil.copy(logger.get_checkpoint_path(&quotlatest&quot), logger.get_checkpoint_path(&quotbest&quot))
        best_val_acc1 = max(acc1, best_val_acc1)

        &#47&#47 evaluate on test set
        print("Test on target domain...")
        best_test_acc1 = max(best_test_acc1, utils.validate(test_loader, classifier, args, device))

    &#47&#47 evaluate on test set
    classifier.load_state_dict(torch.load(logger.get_checkpoint_path(&quotbest&quot)))
    acc1<a id="change"> = </a><a id="change">utils.validate(</a>test_loader, classifier, args, device<a id="change">)</a>
    print("test acc on target = {}".format(acc1))
    print("oracle acc on target = {}".format(best_test_acc1))
    logger.close()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/53b9f6e20d72d01f46d9d293f8f3781881052ca1#diff-17fb24ce184ac2e11fcd9ac3a422dd507a7058ad4d065bcb54e89733d91f8ff8L33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 18993419</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 53b9f6e20d72d01f46d9d293f8f3781881052ca1</div><div id='time'> Time: 2021-08-08</div><div id='author'> Author: chenbx18@mails.tsinghua.edu.cn</div><div id='file'> File Name: examples/domain_generalization/classification/groupdro.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/domain_generalization/classification/groupdro.py</div><div id='n_file'> N File Name: examples/domain_generalization/classification/groupdro.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 126</div><div id='n_start'> N Start Line: 48</div><div id='n_end'> N End Line: 116</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    <a id="change">normalize</a> = <a id="change">T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])</a>
    train_transform = <a id="change">T.Compose(</a><a id="change">[
        T.RandomResizedCrop(224</a><a id="change">, scale=(0.7, 1.0))</a>,
        <a id="change">T.RandomHorizontalFlip()</a>,
        <a id="change">T.ColorJitter(0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a><a id="change">)</a>,
        <a id="change">T.RandomGrayscale()</a>,
        <a id="change">T.ToTensor()</a>,
        normalize<a id="change"></a>
    ]<a id="change">)</a>
    val_transform<a id="change"> = </a><a id="change">T.Compose(</a><a id="change">[
        ResizeImage(224</a><a id="change">)</a>,
        <a id="change">T.ToTensor()</a>,
        normalize<a id="change"></a>
    ]<a id="change">)</a>

    train_dataset, num_classes = get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                             split=&quottrain&quot, download=True, transform=train_transform,
                                             seed=args.seed)</code></pre><h3>After Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    train_transform = <a id="change">utils.get_train_transform(</a>args.train_resizing<a id="change">, random_horizontal_flip=True,
                                                random_color_jitter=True, random_gray_scale=True)</a>
    val_transform = <a id="change">utils.get_val_transform(</a>args.val_resizing<a id="change">)</a>
    <a id="change">print("train_transform: "</a>, train_transform<a id="change">)</a>
    <a id="change">print("val_transform: "</a>, val_transform<a id="change">)</a>

    train_dataset, num_classes = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                                   split=&quottrain&quot, download=True, transform=train_transform,
                                                   seed=args.seed)
    sampler = DefaultSampler(train_dataset, args.batch_size)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=args.workers,
                              sampler=sampler, drop_last=True)
    val_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources, split=&quotval&quot,
                                       download=True, transform=val_transform, seed=args.seed)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    test_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.targets, split=&quotall&quot,
                                        download=True, transform=val_transform, seed=args.seed)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    print("Source Train:", len(train_dataset))
    print(&quotSource Val:&quot, len(val_dataset))
    print("Target:", len(test_dataset))
    train_iter = ForeverDataIterator(train_loader)

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = utils.get_model(args.arch)
    pool_layer = nn.Identity() if args.no_pool else None
    classifier = Classifier(backbone, num_classes, freeze_bn=args.freeze_bn, dropout_p=args.dropout_p,
                            finetune=args.finetune, pool_layer=pool_layer).to(device)
    num_domains = len(args.sources)

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(base_lr=args.lr), args.lr, momentum=args.momentum, weight_decay=args.wd,
                    nesterov=True)
    lr_scheduler = CosineAnnealingLR(optimizer, args.epochs * args.iters_per_epoch)

    &#47&#47 define loss function
    invariance_penalty_loss = InvariancePenaltyLoss().to(device)

    &#47&#47 for simplicity
    assert args.anneal_iters % args.iters_per_epoch == 0

    if args.phase == &quottest&quot:
        checkpoint = torch.load(logger.get_checkpoint_path(&quotbest&quot), map_location=&quotcpu&quot)
        classifier.load_state_dict(checkpoint)
        acc1 = utils.validate(test_loader, classifier, args, device)
        print(acc1)
        return

    &#47&#47 start training
    best_val_acc1 = 0.
    best_test_acc1 = 0.
    for epoch in range(args.epochs):
        if epoch * args.iters_per_epoch == args.anneal_iters:
            &#47&#47 reset optimizer to avoid sharp jump in gradient magnitudes
            optimizer = SGD(classifier.get_parameters(base_lr=args.lr), args.lr, momentum=args.momentum,
                            weight_decay=args.wd, nesterov=True)
            lr_scheduler = CosineAnnealingLR(optimizer, args.epochs * args.iters_per_epoch - args.anneal_iters)

        print(lr_scheduler.get_lr())
        &#47&#47 train for one epoch
        train(train_iter, classifier, optimizer, lr_scheduler, invariance_penalty_loss, num_domains, epoch, args)

        &#47&#47 evaluate on validation set
        print("Validation on source domain...")
        acc1 = utils.validate(val_loader, classifier, args, device)

        &#47&#47 remember best acc@1 and save checkpoint
        torch.save(classifier.state_dict(), logger.get_checkpoint_path(&quotlatest&quot))
        if acc1 &gt; best_val_acc1:
            shutil.copy(logger.get_checkpoint_path(&quotlatest&quot), logger.get_checkpoint_path(&quotbest&quot))
        best_val_acc1 = max(acc1, best_val_acc1)

        &#47&#47 evaluate on test set
        print("Test on target domain...")
        best_test_acc1 = max(best_test_acc1, utils.validate(test_loader, classifier, args, device))

    &#47&#47 evaluate on test set
    classifier.load_state_dict(torch.load(logger.get_checkpoint_path(&quotbest&quot)))
    acc1<a id="change"> = </a><a id="change">utils.validate(</a>test_loader, classifier, args, device<a id="change">)</a>
    print("test acc on target = {}".format(acc1))
    print("oracle acc on target = {}".format(best_test_acc1))
    logger.close()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/53b9f6e20d72d01f46d9d293f8f3781881052ca1#diff-3abb95a42fdff1b755a8a483b24bdfbde48bdac56f271e3288a6ea6c0a5e48b3L33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 18993469</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 53b9f6e20d72d01f46d9d293f8f3781881052ca1</div><div id='time'> Time: 2021-08-08</div><div id='author'> Author: chenbx18@mails.tsinghua.edu.cn</div><div id='file'> File Name: examples/domain_generalization/classification/irm.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/domain_generalization/classification/irm.py</div><div id='n_file'> N File Name: examples/domain_generalization/classification/irm.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 137</div><div id='n_start'> N Start Line: 48</div><div id='n_end'> N End Line: 127</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    <a id="change">normalize</a> = <a id="change">T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])</a>
    train_transform = <a id="change">T.Compose(</a><a id="change">[
        T.RandomResizedCrop(224</a><a id="change">, scale=(0.7, 1.0))</a>,
        <a id="change">T.RandomHorizontalFlip()</a>,
        <a id="change">T.ColorJitter(0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a>, <a id="change">0.3</a><a id="change">)</a>,
        <a id="change">T.RandomGrayscale()</a>,
        <a id="change">T.ToTensor()</a>,
        normalize<a id="change"></a>
    ]<a id="change">)</a>
    val_transform<a id="change"> = </a><a id="change">T.Compose(</a><a id="change">[
        ResizeImage(224</a><a id="change">)</a>,
        <a id="change">T.ToTensor()</a>,
        normalize<a id="change"></a>
    ]<a id="change">)</a>

    train_dataset, num_classes = get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                             split=&quottrain&quot, download=True, transform=train_transform,
                                             seed=args.seed)</code></pre><h3>After Change</h3><pre><code class='java'>
    cudnn.benchmark = True

    &#47&#47 Data loading code
    train_transform = <a id="change">utils.get_train_transform(</a>args.train_resizing<a id="change">, random_horizontal_flip=True,
                                                random_color_jitter=True, random_gray_scale=True)</a>
    val_transform = <a id="change">utils.get_val_transform(</a>args.val_resizing<a id="change">)</a>
    <a id="change">print("train_transform: "</a>, train_transform<a id="change">)</a>
    <a id="change">print("val_transform: "</a>, val_transform<a id="change">)</a>

    train_dataset, num_classes = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources,
                                                   split=&quottrain&quot, download=True, transform=train_transform,
                                                   seed=args.seed)
    sampler = DefaultSampler(train_dataset, args.batch_size)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=args.workers,
                              sampler=sampler, drop_last=True)
    val_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.sources, split=&quotval&quot,
                                       download=True, transform=val_transform, seed=args.seed)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    test_dataset, _ = utils.get_dataset(dataset_name=args.data, root=args.root, task_list=args.targets, split=&quotall&quot,
                                        download=True, transform=val_transform, seed=args.seed)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    print("Source Train:", len(train_dataset))
    print(&quotSource Val:&quot, len(val_dataset))
    print("Target:", len(test_dataset))
    train_iter = ForeverDataIterator(train_loader)

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = utils.get_model(args.arch)
    pool_layer = nn.Identity() if args.no_pool else None
    classifier = Classifier(backbone, num_classes, freeze_bn=args.freeze_bn, dropout_p=args.dropout_p,
                            finetune=args.finetune, pool_layer=pool_layer).to(device)
    num_domains = len(args.sources)

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(base_lr=args.lr), args.lr, momentum=args.momentum, weight_decay=args.wd,
                    nesterov=True)
    lr_scheduler = CosineAnnealingLR(optimizer, args.epochs * args.iters_per_epoch)

    &#47&#47 for simplicity
    assert args.anneal_iters % args.iters_per_epoch == 0

    if args.phase == &quottest&quot:
        checkpoint = torch.load(logger.get_checkpoint_path(&quotbest&quot), map_location=&quotcpu&quot)
        classifier.load_state_dict(checkpoint)
        acc1 = utils.validate(test_loader, classifier, args, device)
        print(acc1)
        return

    &#47&#47 start training
    best_val_acc1 = 0.
    best_test_acc1 = 0.
    for epoch in range(args.epochs):
        if epoch * args.iters_per_epoch == args.anneal_iters:
            &#47&#47 reset optimizer to avoid sharp jump in gradient magnitudes
            optimizer = SGD(classifier.get_parameters(base_lr=args.lr), args.lr, momentum=args.momentum,
                            weight_decay=args.wd, nesterov=True)
            lr_scheduler = CosineAnnealingLR(optimizer, args.epochs * args.iters_per_epoch - args.anneal_iters)

        print(lr_scheduler.get_lr())
        &#47&#47 train for one epoch
        train(train_iter, classifier, optimizer, lr_scheduler, num_domains, epoch, args)

        &#47&#47 evaluate on validation set
        print("Validation on source domain...")
        acc1 = utils.validate(val_loader, classifier, args, device)

        &#47&#47 remember best acc@1 and save checkpoint
        torch.save(classifier.state_dict(), logger.get_checkpoint_path(&quotlatest&quot))
        if acc1 &gt; best_val_acc1:
            shutil.copy(logger.get_checkpoint_path(&quotlatest&quot), logger.get_checkpoint_path(&quotbest&quot))
        best_val_acc1 = max(acc1, best_val_acc1)

        &#47&#47 evaluate on test set
        print("Test on target domain...")
        best_test_acc1 = max(best_test_acc1, utils.validate(test_loader, classifier, args, device))

    &#47&#47 evaluate on test set
    classifier.load_state_dict(torch.load(logger.get_checkpoint_path(&quotbest&quot)))
    acc1<a id="change"> = </a><a id="change">utils.validate(</a>test_loader, classifier, args, device<a id="change">)</a>
    print("test acc on target = {}".format(acc1))
    print("oracle acc on target = {}".format(best_test_acc1))
    logger.close()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/53b9f6e20d72d01f46d9d293f8f3781881052ca1#diff-36b89e4449e8cd427d4b3b190a293227d91d88e28f05541d8409ae5c536a3949L32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 18993471</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 53b9f6e20d72d01f46d9d293f8f3781881052ca1</div><div id='time'> Time: 2021-08-08</div><div id='author'> Author: chenbx18@mails.tsinghua.edu.cn</div><div id='file'> File Name: examples/domain_generalization/classification/vrex.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/domain_generalization/classification/vrex.py</div><div id='n_file'> N File Name: examples/domain_generalization/classification/vrex.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 133</div><div id='n_start'> N Start Line: 47</div><div id='n_end'> N End Line: 123</div><BR>