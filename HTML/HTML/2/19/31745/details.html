<html><h3>Pattern ID :31745
</h3><img src='92724694.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        self._is_weighted: bool = module.is_weighted()
        self._device = device
        self._input_dists = <a id="change">nn.ModuleList()</a>
        self._lookups<a id="change">: nn.ModuleList = nn</a><a id="change">.ModuleList()</a>
        self._create_lookups()
        self._output_dists: nn.ModuleList = <a id="change">nn.ModuleList()</a>
        self._embedding_names: List[str] = []
        self._embedding_dims: List[int] = []
        self._feature_splits: List[int] = []
        self._features_order: List[int] = []</code></pre><h3>After Change</h3><pre><code class='java'>
        qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None,
    ) -&gt; None:
        super().__init__(qcomm_codecs_registry=qcomm_codecs_registry)
        self._embedding_bag_configs<a id="change">: List[
            EmbeddingBagConfig
        ] = </a>module.embedding_bag_configs()
        self._table_names<a id="change">: List[str] = </a><a id="change">[
            config.name for config in self._embedding_bag_configs
        ]</a>

        self.module_sharding_plan<a id="change">: ModuleShardingPlan = </a><a id="change">{
            table_name: parameter_sharding
            for table_name, parameter_sharding in table_name_to_parameter_sharding.items()
            if table_name in self._table_names
        }</a>
        self._env = env

        sharding_type_to_sharding_infos = create_sharding_infos_by_sharding(
            module,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 14</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/torchrec/commit/c4f251b90040bffc6c6fbd3b8076205287140dc2#diff-fd51ff8537ea74d205ade3b58e7acd1832ae6fc5d8f549719407f53f6ccdfa9cL305' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 92724694</div><div id='project'> Project Name: pytorch/torchrec</div><div id='commit'> Commit Name: c4f251b90040bffc6c6fbd3b8076205287140dc2</div><div id='time'> Time: 2022-12-16</div><div id='author'> Author: colin2328@meta.com</div><div id='file'> File Name: torchrec/distributed/embeddingbag.py</div><div id='m_class'> M Class Name: ShardedEmbeddingBagCollection</div><div id='n_method'> N Class Name: ShardedEmbeddingBagCollection</div><div id='m_method'> M Method Name: __init__(7)</div><div id='n_method'> N Method Name: __init__(7)</div><div id='m_parent_class'> M Parent Class: FusedOptimizerModule,Subscript</div><div id='n_parent_class'> N Parent Class: FusedOptimizerModule,Subscript</div><div id='m_file'> M File Name: torchrec/distributed/embeddingbag.py</div><div id='n_file'> N File Name: torchrec/distributed/embeddingbag.py</div><div id='m_start'> M Start Line: 330</div><div id='m_end'> M End Line: 333</div><div id='n_start'> N Start Line: 305</div><div id='n_end'> N End Line: 396</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        }

        self._device = device
        self._input_dists: nn.ModuleList = <a id="change">nn.ModuleList()</a>
        self._lookups<a id="change">: nn.ModuleList = </a><a id="change">nn.ModuleList()</a>
        self._create_lookups()
        self._output_dists: nn.ModuleList = <a id="change">nn.ModuleList()</a>
        self._create_output_dist()

        self._feature_splits: List[int] = []
        self._features_order: List[int] = []</code></pre><h3>After Change</h3><pre><code class='java'>
        qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None,
    ) -&gt; None:
        super().__init__(qcomm_codecs_registry=qcomm_codecs_registry)
        self._embedding_configs<a id="change">: List[EmbeddingConfig] = </a>module.embedding_configs()
        self._table_names<a id="change">: List[str] = </a><a id="change">[
            config.name for config in self._embedding_configs
        ]</a>
        self.module_sharding_plan<a id="change">: ModuleShardingPlan = </a><a id="change">{
            table_name: parameter_sharding
            for table_name, parameter_sharding in table_name_to_parameter_sharding.items()
            if table_name in self._table_names
        }</a>
        self._env = env
        sharding_type_to_sharding_infos = create_sharding_infos_by_sharding(
            module,
            table_name_to_parameter_sharding,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/facebookresearch/torchrec/commit/0ffa1c7616403c416c73118107bec307baa3abfb#diff-ef14f956164adafc139f5a6d4554edaf589f8e92ac501cad851bb9db40d0e315L304' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 92724695</div><div id='project'> Project Name: facebookresearch/torchrec</div><div id='commit'> Commit Name: 0ffa1c7616403c416c73118107bec307baa3abfb</div><div id='time'> Time: 2022-12-21</div><div id='author'> Author: colin2328@meta.com</div><div id='file'> File Name: torchrec/distributed/embedding.py</div><div id='m_class'> M Class Name: ShardedEmbeddingCollection</div><div id='n_method'> N Class Name: ShardedEmbeddingCollection</div><div id='m_method'> M Method Name: __init__(7)</div><div id='n_method'> N Method Name: __init__(7)</div><div id='m_parent_class'> M Parent Class: FusedOptimizerModule,Subscript</div><div id='n_parent_class'> N Parent Class: FusedOptimizerModule,Subscript</div><div id='m_file'> M File Name: torchrec/distributed/embedding.py</div><div id='n_file'> N File Name: torchrec/distributed/embedding.py</div><div id='m_start'> M Start Line: 336</div><div id='m_end'> M End Line: 339</div><div id='n_start'> N Start Line: 315</div><div id='n_end'> N End Line: 405</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        self._is_weighted: bool = module.is_weighted()
        self._device = device
        self._input_dists = <a id="change">nn.ModuleList()</a>
        self._lookups<a id="change">: nn.ModuleList = </a><a id="change">nn.ModuleList()</a>
        self._create_lookups()
        self._output_dists: nn.ModuleList = <a id="change">nn.ModuleList()</a>
        self._embedding_names: List[str] = []
        self._embedding_dims: List[int] = []
        self._feature_splits: List[int] = []
        self._features_order: List[int] = []</code></pre><h3>After Change</h3><pre><code class='java'>
        qcomm_codecs_registry: Optional[Dict[str, QuantizedCommCodecs]] = None,
    ) -&gt; None:
        super().__init__(qcomm_codecs_registry=qcomm_codecs_registry)
        self._embedding_bag_configs<a id="change">: List[
            EmbeddingBagConfig
        ] = </a>module.embedding_bag_configs()
        self._table_names<a id="change">: List[str] = </a><a id="change">[
            config.name for config in self._embedding_bag_configs
        ]</a>

        self.module_sharding_plan<a id="change">: ModuleShardingPlan = </a><a id="change">{
            table_name: parameter_sharding
            for table_name, parameter_sharding in table_name_to_parameter_sharding.items()
            if table_name in self._table_names
        }</a>
        self._env = env

        sharding_type_to_sharding_infos = create_sharding_infos_by_sharding(
            module,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/torchrec/commit/c4f251b90040bffc6c6fbd3b8076205287140dc2#diff-fd51ff8537ea74d205ade3b58e7acd1832ae6fc5d8f549719407f53f6ccdfa9cL290' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 92724701</div><div id='project'> Project Name: pytorch/torchrec</div><div id='commit'> Commit Name: c4f251b90040bffc6c6fbd3b8076205287140dc2</div><div id='time'> Time: 2022-12-16</div><div id='author'> Author: colin2328@meta.com</div><div id='file'> File Name: torchrec/distributed/embeddingbag.py</div><div id='m_class'> M Class Name: ShardedEmbeddingBagCollection</div><div id='n_method'> N Class Name: ShardedEmbeddingBagCollection</div><div id='m_method'> M Method Name: __init__(7)</div><div id='n_method'> N Method Name: __init__(7)</div><div id='m_parent_class'> M Parent Class: FusedOptimizerModule,Subscript</div><div id='n_parent_class'> N Parent Class: FusedOptimizerModule,Subscript</div><div id='m_file'> M File Name: torchrec/distributed/embeddingbag.py</div><div id='n_file'> N File Name: torchrec/distributed/embeddingbag.py</div><div id='m_start'> M Start Line: 330</div><div id='m_end'> M End Line: 333</div><div id='n_start'> N Start Line: 305</div><div id='n_end'> N End Line: 396</div><BR>