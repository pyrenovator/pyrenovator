<html><h3>Pattern ID :6244
</h3><img src='21662250.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = <a id="change">models.__dict__[args.arch](pretrained=True)</a>
    <a id="change">if </a>args.pretrained:
        <a id="change">print("=&gt; loading pre-trained model from &quot{}&quot".format(</a>args.pretrained<a id="change">)</a><a id="change">)</a>
        pretrained_dict<a id="change"> = </a><a id="change">torch.load(</a>args.pretrained<a id="change">)</a>
        <a id="change">backbone.load_state_dict(</a>pretrained_dict<a id="change">, strict=False)</a>
    num_classes = train_dataset.num_classes
    classifier = Classifier(backbone, num_classes).to(device)
    bss_module = BatchSpectralShrinkage(k=args.k)
</code></pre><h3>After Change</h3><pre><code class='java'>
    print("train_transform: ", train_transform)
    print("val_transform: ", val_transform)

    <a id="change">train_dataset</a><a id="change">, val_dataset, num_classes</a> = utils.get_dataset(args.data, args.root, train_transform,
                                                                    val_transform, args.sample_rate, args.sample_size)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,
                              num_workers=args.workers, drop_last=True)
    train_iter = ForeverDataIterator(train_loader)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    <a id="change">print(</a><a id="change">"training dataset size: {} test dataset size: {}".format(len(train_dataset</a><a id="change">)</a>, <a id="change">len(val_dataset</a><a id="change">)</a><a id="change">))</a>

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = utils.get_model(args.arch, args.pretrained)
    pool_layer = nn.Identity() if args.no_pool else None
    classifier = <a id="change">Classifier(backbone, num_classes, pool_layer=pool_layer, finetune=args.finetune).to(</a>device<a id="change">)</a>
    bss_module = BatchSpectralShrinkage(k=args.k)

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(args.lr), momentum=args.momentum, weight_decay=args.wd, nesterov=True)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 14</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/052625393790ff6b5ffcffb9f29a68670054ea93#diff-28b7d12f40c0e0363e65e17af84a0ae6b4ad95f260156802c18714e0289e34d0L46' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21662250</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 052625393790ff6b5ffcffb9f29a68670054ea93</div><div id='time'> Time: 2021-08-01</div><div id='author'> Author: 13126830206@163.com</div><div id='file'> File Name: examples/finetune/image_classification/bss.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/finetune/image_classification/bss.py</div><div id='n_file'> N File Name: examples/finetune/image_classification/bss.py</div><div id='m_start'> M Start Line: 46</div><div id='m_end'> M End Line: 100</div><div id='n_start'> N Start Line: 46</div><div id='n_end'> N End Line: 86</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = <a id="change">models.__dict__[args.arch](pretrained=True)</a>
    <a id="change">if </a>args.pretrained:
        <a id="change">print("=&gt; loading pre-trained model from &quot{}&quot".format(</a>args.pretrained<a id="change">)</a><a id="change">)</a>
        pretrained_dict<a id="change"> = </a><a id="change">torch.load(</a>args.pretrained<a id="change">)</a>
        <a id="change">backbone.load_state_dict(</a>pretrained_dict<a id="change">, strict=False)</a>
    num_classes = train_dataset.num_classes
    classifier = Classifier(backbone, num_classes).to(device)
    classifier = convert_model(classifier, p=args.prob)
</code></pre><h3>After Change</h3><pre><code class='java'>
    print("train_transform: ", train_transform)
    print("val_transform: ", val_transform)

    train_dataset<a id="change">, val_dataset, num_classes</a> = utils.get_dataset(args.data, args.root, train_transform,
                                                                    val_transform, args.sample_rate, args.sample_size)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,
                              num_workers=args.workers, drop_last=True)
    train_iter = ForeverDataIterator(train_loader)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    <a id="change">print(</a><a id="change">"training dataset size: {} test dataset size: {}".format(len(</a>train_dataset<a id="change">)</a>, <a id="change">len(</a>val_dataset<a id="change">)</a><a id="change">))</a>

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = utils.get_model(args.arch, args.pretrained)
    pool_layer = nn.Identity() if args.no_pool else None
    classifier = <a id="change">Classifier(backbone, num_classes, pool_layer=pool_layer, finetune=args.finetune).to(</a>device<a id="change">)</a>
    classifier = convert_model(classifier, p=args.prob)

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(args.lr), lr=args.lr, momentum=args.momentum, weight_decay=args.wd, nesterov=True)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/052625393790ff6b5ffcffb9f29a68670054ea93#diff-54b1bff3f14a188ba8efbe4ea6b6bd3851fdbb4266d30cfdfc8d10b5e1a179b1L29' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21662254</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 052625393790ff6b5ffcffb9f29a68670054ea93</div><div id='time'> Time: 2021-08-01</div><div id='author'> Author: 13126830206@163.com</div><div id='file'> File Name: examples/finetune/image_classification/stochnorm.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/finetune/image_classification/stochnorm.py</div><div id='n_file'> N File Name: examples/finetune/image_classification/stochnorm.py</div><div id='m_start'> M Start Line: 46</div><div id='m_end'> M End Line: 78</div><div id='n_start'> N Start Line: 46</div><div id='n_end'> N End Line: 87</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = <a id="change">models.__dict__[args.arch](pretrained=True)</a>
    <a id="change">if </a>args.pretrained:
        <a id="change">print("=&gt; loading pre-trained model from &quot{}&quot".format(</a>args.pretrained<a id="change">)</a><a id="change">)</a>
        pretrained_dict<a id="change"> = </a><a id="change">torch.load(</a>args.pretrained<a id="change">)</a>
        <a id="change">backbone.load_state_dict(</a>pretrained_dict<a id="change">, strict=False)</a>
    num_classes = train_dataset.num_classes
    classifier = Classifier(backbone, num_classes).to(device)
    bss_module = BatchSpectralShrinkage(k=args.k)
</code></pre><h3>After Change</h3><pre><code class='java'>
    print("train_transform: ", train_transform)
    print("val_transform: ", val_transform)

    train_dataset<a id="change">, val_dataset, num_classes</a> = utils.get_dataset(args.data, args.root, train_transform,
                                                                    val_transform, args.sample_rate, args.sample_size)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,
                              num_workers=args.workers, drop_last=True)
    train_iter = ForeverDataIterator(train_loader)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    <a id="change">print(</a><a id="change">"training dataset size: {} test dataset size: {}".format(len(</a>train_dataset<a id="change">)</a>, <a id="change">len(</a>val_dataset<a id="change">)</a><a id="change">))</a>

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = utils.get_model(args.arch, args.pretrained)
    pool_layer = nn.Identity() if args.no_pool else None
    classifier = <a id="change">Classifier(backbone, num_classes, pool_layer=pool_layer, finetune=args.finetune).to(</a>device<a id="change">)</a>
    bss_module = BatchSpectralShrinkage(k=args.k)

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(args.lr), momentum=args.momentum, weight_decay=args.wd, nesterov=True)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/052625393790ff6b5ffcffb9f29a68670054ea93#diff-28b7d12f40c0e0363e65e17af84a0ae6b4ad95f260156802c18714e0289e34d0L29' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21662252</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 052625393790ff6b5ffcffb9f29a68670054ea93</div><div id='time'> Time: 2021-08-01</div><div id='author'> Author: 13126830206@163.com</div><div id='file'> File Name: examples/finetune/image_classification/bss.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/finetune/image_classification/bss.py</div><div id='n_file'> N File Name: examples/finetune/image_classification/bss.py</div><div id='m_start'> M Start Line: 46</div><div id='m_end'> M End Line: 100</div><div id='n_start'> N Start Line: 46</div><div id='n_end'> N End Line: 86</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    num_classes = train_dataset.num_classes
    backbone_q = <a id="change">models.__dict__[args.arch](pretrained=True)</a>
    <a id="change">if </a>args.pretrained:
        <a id="change">print("=&gt; loading pre-trained backbone from &quot{}&quot".format(</a>args.pretrained<a id="change">)</a><a id="change">)</a>
        pretrained_dict<a id="change"> = </a><a id="change">torch.load(</a>args.pretrained<a id="change">)</a>
        <a id="change">backbone_q.load_state_dict(</a>pretrained_dict<a id="change">, strict=False)</a>
    classifier_q = Classifier(backbone_q, num_classes, projection_dim=args.projection_dim)
    if args.pretrained_fc:
        print("=&gt; loading pre-trained fc from &quot{}&quot".format(args.pretrained_fc))
        pretrained_fc_dict = torch.load(args.pretrained_fc)</code></pre><h3>After Change</h3><pre><code class='java'>
    print("train_transform: ", train_transform)
    print("val_transform: ", val_transform)

    train_dataset<a id="change">, val_dataset, num_classes</a> = utils.get_dataset(args.data, args.root, train_transform,
                                                                val_transform, args.sample_rate, args.sample_size)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,
                              num_workers=args.workers, drop_last=True)
    train_iter = ForeverDataIterator(train_loader)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)
    <a id="change">print(</a><a id="change">"training dataset size: {} test dataset size: {}".format(len(</a>train_dataset<a id="change">)</a>, <a id="change">len(</a>val_dataset<a id="change">)</a><a id="change">))</a>

    &#47&#47 create model
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone_q = utils.get_model(args.arch, args.pretrained)
    pool_layer = nn.Identity() if args.no_pool else None
    classifier_q = Classifier(backbone_q, num_classes, pool_layer=pool_layer, projection_dim=args.projection_dim, finetune=args.finetune)
    if args.pretrained_fc:
        print("=&gt; loading pre-trained fc from &quot{}&quot".format(args.pretrained_fc))
        pretrained_fc_dict = torch.load(args.pretrained_fc)
        classifier_q.projector.load_state_dict(pretrained_fc_dict, strict=False)
    classifier_q = classifier_q.to(device)
    backbone_k = utils.get_model(args.arch)
    classifier_k = <a id="change">Classifier(backbone_k, num_classes, pool_layer=pool_layer).to(</a>device<a id="change">)</a>

    bituning = Bituning(classifier_q, classifier_k, num_classes, K=args.K, m=args.m, T=args.T)

    &#47&#47 define optimizer and lr scheduler</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/052625393790ff6b5ffcffb9f29a68670054ea93#diff-8c5c5b3600e42580065fc93ec76aaca26a3f9349717e61f761d9ebfd327cfb9bL28' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21662258</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 052625393790ff6b5ffcffb9f29a68670054ea93</div><div id='time'> Time: 2021-08-01</div><div id='author'> Author: 13126830206@163.com</div><div id='file'> File Name: examples/finetune/image_classification/bi_tuning.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/finetune/image_classification/bi_tuning.py</div><div id='n_file'> N File Name: examples/finetune/image_classification/bi_tuning.py</div><div id='m_start'> M Start Line: 45</div><div id='m_end'> M End Line: 84</div><div id='n_start'> N Start Line: 45</div><div id='n_end'> N End Line: 95</div><BR>