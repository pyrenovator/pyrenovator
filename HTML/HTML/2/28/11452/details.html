<html><h3>Pattern ID :11452
</h3><img src='39056801.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.weight_read = torch.matmul(past_normalized, state_normalized.transpose(0,1)).transpose(0,1)
        self.index_max = torch.sort(self.weight_read, descending=True)[1].cpu()[:,:self.num_prediction]

        <a id="change">for i_track</a> in <a id="change">range(</a>self.num_prediction<a id="change">):
            </a>present<a id="change"> = </a>present_temp
            prediction_single = <a id="change">torch.Tensor().cuda()</a>
            ind<a id="change"> = self.index_max[:, i_track]</a>
            info_future<a id="change"> = </a>self.memory_fut[ind]
            info_total<a id="change"> = </a>torch.cat((state_past, info_future.unsqueeze(0)), 2)
            input_dec<a id="change"> = </a>info_total
            state_dec = zero_padding
            for i in range(self.future_len):
                output_decoder, state_dec = self.decoder(input_dec, state_dec)
                displacement_next = self.FC_output(output_decoder)
                coords_next = present + displacement_next.squeeze(0).unsqueeze(1)
                prediction_single = torch.cat((prediction_single, coords_next), 1)
                present = coords_next
                input_dec = zero_padding

            &#47&#47 Iteratively refine predictions using context
            for i_refine in range(1):
                pred_map = prediction_single + 90
                pred_map = pred_map.unsqueeze(2)
                indices = pred_map.permute(0, 2, 1, 3)

                &#47&#47 rescale between -1 and 1
                indices = 2 * (indices / 180) - 1
                output = F.grid_sample(scene_2, indices, mode=&quotnearest&quot)
                output = output.squeeze(2).permute(0, 2, 1)

                state_rnn = state_past
                output_rnn, state_rnn = self.RNN_scene(output, state_rnn)
                prediction_refine = self.fc_refine(state_rnn).view(dim_batch, 40, 2)
                prediction_single = prediction_single + prediction_refine

            prediction<a id="change"> = torch.cat(</a>(prediction<a id="change">, prediction_single.unsqueeze(1)</a>), <a id="change">1</a><a id="change">)</a>

        return prediction

    def write_in_memory(self, past, future):</code></pre><h3>After Change</h3><pre><code class='java'>
        past_normalized = F.normalize(self.memory_past, p=2, dim=1)
        state_normalized = F.normalize(state_past.squeeze(), p=2, dim=1)
        self.weight_read = torch.matmul(past_normalized, state_normalized.transpose(0,1)).transpose(0,1)
        <a id="change">self.index_max</a> = torch.sort(self.weight_read, descending=True)[1].cpu()[:, :self.num_prediction]

        present = present_temp.repeat_interleave(self.num_prediction, dim=0)
        state_past<a id="change"> = </a><a id="change">state_past.repeat_interleave(</a>self.num_prediction<a id="change">, dim=1)</a>
        scene_2 = scene_2.repeat_interleave(self.num_prediction, dim=0)
        ind<a id="change"> = self.index_max</a><a id="change">.flatten()</a>

        &#47&#47ablation study
        &#47&#47 &#47&#47pdb.set_trace()
        &#47&#47 prediction = self.memory_count[ind]
        &#47&#47 &#47&#47prediction = temp.view(dim_batch, self.num_prediction, self.future_len, 2)

        info_future<a id="change"> = </a>self.memory_fut[ind]
        info_total<a id="change"> = </a>torch.cat((state_past, info_future.unsqueeze(0)), 2)
        input_dec<a id="change"> = </a>info_total
        state_dec = zero_padding
        for i in range(self.future_len):
            output_decoder, state_dec = self.decoder(input_dec, state_dec)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 23</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/marchetz/mantra-cvpr20/commit/04d7a063354c991d5aaa36f28a63df2ebbee9f78#diff-a0e6c75d4dc7945a3f8930d0c81236b81a0c8affd90ac0db921386274cf16e5cL123' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39056801</div><div id='project'> Project Name: marchetz/mantra-cvpr20</div><div id='commit'> Commit Name: 04d7a063354c991d5aaa36f28a63df2ebbee9f78</div><div id='time'> Time: 2020-01-18</div><div id='author'> Author: francescom394@gmail.com</div><div id='file'> File Name: models/model_memory_IRM.py</div><div id='m_class'> M Class Name: model_memory_IRM</div><div id='n_method'> N Class Name: model_memory_IRM</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/model_memory_IRM.py</div><div id='n_file'> N File Name: models/model_memory_IRM.py</div><div id='m_start'> M Start Line: 123</div><div id='m_end'> M End Line: 179</div><div id='n_start'> N Start Line: 129</div><div id='n_end'> N End Line: 190</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        past_normalized = F.normalize(self.memory_past, p=2, dim=1)
        state_normalized = F.normalize(state_past.squeeze(), p=2, dim=1)
        self.weight_read = torch.matmul(past_normalized, state_normalized.transpose(0,1)).transpose(0,1)
        <a id="change">self.index_max</a> = torch.sort(self.weight_read, descending=True)[1].cpu()[:,:self.num_prediction]

        <a id="change">for i_track</a> in <a id="change">range(</a>self.num_prediction<a id="change">):
            </a>present<a id="change"> = </a>present_temp
            prediction_single = <a id="change">torch.Tensor().cuda()</a>
            ind<a id="change"> = </a><a id="change">self.index_max[:, i_track]</a>
            info_future<a id="change"> = </a>self.memory_fut[ind]
            info_total<a id="change"> = </a>torch.cat((state_past, info_future.unsqueeze(0)), 2)
            input_dec<a id="change"> = </a>info_total
            state_dec = zero_padding
            for i in range(self.future_len):
                output_decoder, state_dec = self.decoder(input_dec, state_dec)
                displacement_next = self.FC_output(output_decoder)
                coords_next = present + displacement_next.squeeze(0).unsqueeze(1)
                prediction_single = torch.cat((prediction_single, coords_next), 1)
                present = coords_next
                input_dec = zero_padding

            &#47&#47 Iteratively refine predictions using context
            for i_refine in range(1):
                pred_map = prediction_single + 90
                pred_map = pred_map.unsqueeze(2)
                indices = pred_map.permute(0, 2, 1, 3)

                &#47&#47 rescale between -1 and 1
                indices = 2 * (indices / 180) - 1
                output = F.grid_sample(scene_2, indices, mode=&quotnearest&quot)
                output = output.squeeze(2).permute(0, 2, 1)

                state_rnn = state_past
                output_rnn, state_rnn = self.RNN_scene(output, state_rnn)
                prediction_refine = self.fc_refine(state_rnn).view(dim_batch, 40, 2)
                prediction_single = prediction_single + prediction_refine

            prediction<a id="change"> = torch.cat(</a>(prediction<a id="change">, prediction_single.unsqueeze(1)</a>), <a id="change">1</a><a id="change">)</a>

        return prediction

    def write_in_memory(self, past, future):</code></pre><h3>After Change</h3><pre><code class='java'>
        past_normalized = F.normalize(self.memory_past, p=2, dim=1)
        state_normalized = F.normalize(state_past.squeeze(), p=2, dim=1)
        self.weight_read = torch.matmul(past_normalized, state_normalized.transpose(0,1)).transpose(0,1)
        <a id="change">self.index_max</a> = torch.sort(self.weight_read, descending=True)[1].cpu()[:,:self.num_prediction]

        present = present_temp.repeat_interleave(self.num_prediction, dim=0)
        state_past<a id="change"> = </a><a id="change">state_past.repeat_interleave(</a>self.num_prediction<a id="change">, dim=1)</a>
        scene_2 = scene_2.repeat_interleave(self.num_prediction, dim=0)
        ind<a id="change"> = </a><a id="change">self.index_max.flatten()</a>
        info_future<a id="change"> = </a>self.memory_fut[ind]
        info_total<a id="change"> = </a>torch.cat((state_past, info_future.unsqueeze(0)), 2)
        input_dec<a id="change"> = </a>info_total
        state_dec = zero_padding
        for i in range(self.future_len):
            output_decoder, state_dec = self.decoder(input_dec, state_dec)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/marchetz/mantra-cvpr20/commit/e6e7645276ab144231ed2d4e85dada5171a54205#diff-a0e6c75d4dc7945a3f8930d0c81236b81a0c8affd90ac0db921386274cf16e5cL116' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39056800</div><div id='project'> Project Name: marchetz/mantra-cvpr20</div><div id='commit'> Commit Name: e6e7645276ab144231ed2d4e85dada5171a54205</div><div id='time'> Time: 2019-11-03</div><div id='author'> Author: francescom394@gmail.com</div><div id='file'> File Name: models/model_memory_IRM.py</div><div id='m_class'> M Class Name: model_memory_IRM</div><div id='n_method'> N Class Name: model_memory_IRM</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/model_memory_IRM.py</div><div id='n_file'> N File Name: models/model_memory_IRM.py</div><div id='m_start'> M Start Line: 123</div><div id='m_end'> M End Line: 179</div><div id='n_start'> N Start Line: 123</div><div id='n_end'> N End Line: 176</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        past_normalized = F.normalize(self.memory_past, p=2, dim=1)
        state_normalized = F.normalize(state_past.squeeze(), p=2, dim=1)
        self.weight_read = torch.matmul(past_normalized, state_normalized.transpose(0, 1)).transpose(0, 1)
        <a id="change">self.index_max</a> = torch.sort(self.weight_read, descending=True)[1].cpu()

        <a id="change">for i_track</a> in <a id="change">range(</a>self.num_prediction<a id="change">):
            </a>present<a id="change"> = </a>present_temp
            prediction_single = <a id="change">torch.Tensor().cuda()</a>
            ind<a id="change"> = </a><a id="change">self.index_max [:, i_track]</a>

            &#47&#47ablation study
            &#47&#47 prediction_single = self.memory_count[ind]
            &#47&#47 prediction = torch.cat((prediction, prediction_single.unsqueeze(1)), 1)

            info_future<a id="change"> = </a>self.memory_fut[ind]
            info_total<a id="change"> = </a>torch.cat((state_past, info_future.unsqueeze(0)), 2)
            input_dec<a id="change"> = </a>info_total
            state_dec = zero_padding
            for i in range(self.future_len):
                output_decoder, state_dec = self.decoder(input_dec, state_dec)
                displacement_next = self.FC_output(output_decoder)
                coords_next = present + displacement_next.squeeze(0).unsqueeze(1)
                prediction_single = torch.cat((prediction_single, coords_next), 1)
                present = coords_next
                input_dec = zero_padding
            prediction<a id="change"> = torch.cat(</a>(prediction<a id="change">, prediction_single.unsqueeze(1)</a>), <a id="change">1</a><a id="change">)</a>
        return prediction

    def write_in_memory(self, past, future):
        </code></pre><h3>After Change</h3><pre><code class='java'>
        past_normalized = F.normalize(self.memory_past, p=2, dim=1)
        state_normalized = F.normalize(state_past.squeeze(), p=2, dim=1)
        self.weight_read = torch.matmul(past_normalized, state_normalized.transpose(0, 1)).transpose(0, 1)
        <a id="change">self.index_max</a> = torch.sort(self.weight_read, descending=True)[1].cpu()[:,:self.num_prediction]
        present = present_temp.repeat_interleave(self.num_prediction, dim=0)
        state_past<a id="change"> = </a><a id="change">state_past.repeat_interleave(</a>self.num_prediction<a id="change">, dim=1)</a>
        ind<a id="change"> = </a><a id="change">self.index_max.flatten()</a>

        &#47&#47ablation study
        &#47&#47pdb.set_trace()
        &#47&#47 temp = self.memory_count[ind]
        &#47&#47 prediction = temp.view(dim_batch, self.num_prediction, self.future_len, 2)


        info_future<a id="change"> = </a>self.memory_fut[ind]
        info_total<a id="change"> = </a>torch.cat((state_past, info_future.unsqueeze(0)), 2)
        input_dec<a id="change"> = </a>info_total
        state_dec = zero_padding
        for i in range(self.future_len):
            output_decoder, state_dec = self.decoder(input_dec, state_dec)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/marchetz/mantra-cvpr20/commit/04d7a063354c991d5aaa36f28a63df2ebbee9f78#diff-6ffca9b13cf6255ad4de971b4259c7aec5c8be0e8498858880e49c2bec255ddfL120' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39056799</div><div id='project'> Project Name: marchetz/mantra-cvpr20</div><div id='commit'> Commit Name: 04d7a063354c991d5aaa36f28a63df2ebbee9f78</div><div id='time'> Time: 2020-01-18</div><div id='author'> Author: francescom394@gmail.com</div><div id='file'> File Name: models/model_decoder.py</div><div id='m_class'> M Class Name: model_decoder</div><div id='n_method'> N Class Name: model_decoder</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/model_decoder.py</div><div id='n_file'> N File Name: models/model_decoder.py</div><div id='m_start'> M Start Line: 128</div><div id='m_end'> M End Line: 166</div><div id='n_start'> N Start Line: 125</div><div id='n_end'> N End Line: 162</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        past_normalized = F.normalize(self.memory_past, p=2, dim=1)
        state_normalized = F.normalize(state_past.squeeze(), p=2, dim=1)
        self.weight_read = torch.matmul(past_normalized, state_normalized.transpose(0,1)).transpose(0,1)
        <a id="change">self.index_max</a> = torch.sort(self.weight_read, descending=True)[1].cpu()[:,:self.num_prediction]

        <a id="change">for i_track</a> in <a id="change">range(</a>self.num_prediction<a id="change">):
            </a>present<a id="change"> = </a>present_temp
            prediction_single = <a id="change">torch.Tensor().cuda()</a>
            ind<a id="change"> = </a><a id="change">self.index_max[:, i_track]</a>
            info_future<a id="change"> = </a>self.memory_fut[ind]
            info_total<a id="change"> = </a>torch.cat((state_past, info_future.unsqueeze(0)), 2)
            input_dec<a id="change"> = </a>info_total
            state_dec = zero_padding
            for i in range(self.future_len):
                output_decoder, state_dec = self.decoder(input_dec, state_dec)
                displacement_next = self.FC_output(output_decoder)
                coords_next = present + displacement_next.squeeze(0).unsqueeze(1)
                prediction_single = torch.cat((prediction_single, coords_next), 1)
                present = coords_next
                input_dec = zero_padding

            &#47&#47 Iteratively refine predictions using context
            for i_refine in range(1):
                pred_map = prediction_single + 90
                pred_map = pred_map.unsqueeze(2)
                indices = pred_map.permute(0, 2, 1, 3)

                &#47&#47 rescale between -1 and 1
                indices = 2 * (indices / 180) - 1
                output = F.grid_sample(scene_2, indices, mode=&quotnearest&quot)
                output = output.squeeze(2).permute(0, 2, 1)

                state_rnn = state_past
                output_rnn, state_rnn = self.RNN_scene(output, state_rnn)
                prediction_refine = self.fc_refine(state_rnn).view(dim_batch, 40, 2)
                prediction_single = prediction_single + prediction_refine

            prediction<a id="change"> = torch.cat(</a>(prediction<a id="change">, prediction_single.unsqueeze(1)</a>), <a id="change">1</a><a id="change">)</a>

        return prediction

    def write_in_memory(self, past, future):</code></pre><h3>After Change</h3><pre><code class='java'>
        past_normalized = F.normalize(self.memory_past, p=2, dim=1)
        state_normalized = F.normalize(state_past.squeeze(), p=2, dim=1)
        self.weight_read = torch.matmul(past_normalized, state_normalized.transpose(0,1)).transpose(0,1)
        <a id="change">self.index_max</a> = torch.sort(self.weight_read, descending=True)[1].cpu()[:, :self.num_prediction]

        present = present_temp.repeat_interleave(self.num_prediction, dim=0)
        state_past<a id="change"> = </a><a id="change">state_past.repeat_interleave(</a>self.num_prediction<a id="change">, dim=1)</a>
        scene_2 = scene_2.repeat_interleave(self.num_prediction, dim=0)
        ind<a id="change"> = </a><a id="change">self.index_max.flatten()</a>

        &#47&#47ablation study
        &#47&#47 &#47&#47pdb.set_trace()
        &#47&#47 prediction = self.memory_count[ind]
        &#47&#47 &#47&#47prediction = temp.view(dim_batch, self.num_prediction, self.future_len, 2)

        info_future<a id="change"> = </a>self.memory_fut[ind]
        info_total<a id="change"> = </a>torch.cat((state_past, info_future.unsqueeze(0)), 2)
        input_dec<a id="change"> = </a>info_total
        state_dec = zero_padding
        for i in range(self.future_len):
            output_decoder, state_dec = self.decoder(input_dec, state_dec)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/marchetz/mantra-cvpr20/commit/04d7a063354c991d5aaa36f28a63df2ebbee9f78#diff-a0e6c75d4dc7945a3f8930d0c81236b81a0c8affd90ac0db921386274cf16e5cL116' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39056797</div><div id='project'> Project Name: marchetz/mantra-cvpr20</div><div id='commit'> Commit Name: 04d7a063354c991d5aaa36f28a63df2ebbee9f78</div><div id='time'> Time: 2020-01-18</div><div id='author'> Author: francescom394@gmail.com</div><div id='file'> File Name: models/model_memory_IRM.py</div><div id='m_class'> M Class Name: model_memory_IRM</div><div id='n_method'> N Class Name: model_memory_IRM</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/model_memory_IRM.py</div><div id='n_file'> N File Name: models/model_memory_IRM.py</div><div id='m_start'> M Start Line: 123</div><div id='m_end'> M End Line: 179</div><div id='n_start'> N Start Line: 129</div><div id='n_end'> N End Line: 190</div><BR>