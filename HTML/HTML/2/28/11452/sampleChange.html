<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.weight_read = torch.matmul(past_normalized, state_normalized.transpose(0,1)).transpose(0,1)
        self.index_max = torch.sort(self.weight_read, descending=True)[1].cpu()[:,:self.num_prediction]

        <a id="change">for i_track</a> in <a id="change">range(</a>self.num_prediction<a id="change">):
            </a>present<a id="change"> = </a>present_temp
            prediction_single = <a id="change">torch.Tensor().cuda()</a>
            ind<a id="change"> = self.index_max[:, i_track]</a>
            info_future<a id="change"> = </a>self.memory_fut[ind]
            info_total<a id="change"> = </a>torch.cat((state_past, info_future.unsqueeze(0)), 2)
            input_dec<a id="change"> = </a>info_total
            state_dec = zero_padding
            for i in range(self.future_len):
                output_decoder, state_dec = self.decoder(input_dec, state_dec)
                displacement_next = self.FC_output(output_decoder)
                coords_next = present + displacement_next.squeeze(0).unsqueeze(1)
                prediction_single = torch.cat((prediction_single, coords_next), 1)
                present = coords_next
                input_dec = zero_padding

            &#47&#47 Iteratively refine predictions using context
            for i_refine in range(1):
                pred_map = prediction_single + 90
                pred_map = pred_map.unsqueeze(2)
                indices = pred_map.permute(0, 2, 1, 3)

                &#47&#47 rescale between -1 and 1
                indices = 2 * (indices / 180) - 1
                output = F.grid_sample(scene_2, indices, mode=&quotnearest&quot)
                output = output.squeeze(2).permute(0, 2, 1)

                state_rnn = state_past
                output_rnn, state_rnn = self.RNN_scene(output, state_rnn)
                prediction_refine = self.fc_refine(state_rnn).view(dim_batch, 40, 2)
                prediction_single = prediction_single + prediction_refine

            prediction<a id="change"> = torch.cat(</a>(prediction<a id="change">, prediction_single.unsqueeze(1)</a>), <a id="change">1</a><a id="change">)</a>

        return prediction

    def write_in_memory(self, past, future):</code></pre><h3>After Change</h3><pre><code class='java'>
        past_normalized = F.normalize(self.memory_past, p=2, dim=1)
        state_normalized = F.normalize(state_past.squeeze(), p=2, dim=1)
        self.weight_read = torch.matmul(past_normalized, state_normalized.transpose(0,1)).transpose(0,1)
        <a id="change">self.index_max</a> = torch.sort(self.weight_read, descending=True)[1].cpu()[:, :self.num_prediction]

        present = present_temp.repeat_interleave(self.num_prediction, dim=0)
        state_past<a id="change"> = </a><a id="change">state_past.repeat_interleave(</a>self.num_prediction<a id="change">, dim=1)</a>
        scene_2 = scene_2.repeat_interleave(self.num_prediction, dim=0)
        ind<a id="change"> = self.index_max</a><a id="change">.flatten()</a>

        &#47&#47ablation study
        &#47&#47 &#47&#47pdb.set_trace()
        &#47&#47 prediction = self.memory_count[ind]
        &#47&#47 &#47&#47prediction = temp.view(dim_batch, self.num_prediction, self.future_len, 2)

        info_future<a id="change"> = </a>self.memory_fut[ind]
        info_total<a id="change"> = </a>torch.cat((state_past, info_future.unsqueeze(0)), 2)
        input_dec<a id="change"> = </a>info_total
        state_dec = zero_padding
        for i in range(self.future_len):
            output_decoder, state_dec = self.decoder(input_dec, state_dec)</code></pre>