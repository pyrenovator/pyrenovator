<html><h3>Pattern ID :2355
</h3><img src='9985752.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                if type(criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:
                    loss = criterion(out, j[-1].float().cuda())
                else:
                    loss<a id="change"> = </a><a id="change">criterion(</a>out, <a id="change">j[-1].cuda()</a><a id="change">)</a>
                totalloss += loss * len(j[-1])
                if task == "classification":
                    pred.append(torch.argmax(out, 1))
                elif task == "multilabel":</code></pre><h3>After Change</h3><pre><code class='java'>
                if type(criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:
                    loss1=criterion(out, j[-1].float().cuda())
                else:
                    <a id="change">if len(j[-1].size())&gt;1</a>:
                        <a id="change">j[-1] = j</a><a id="change">[-1].squeeze()</a>
                    loss1=<a id="change">criterion(</a>out, <a id="change">j[-1].long().cuda()</a><a id="change">)</a>
                loss2=regularize(out, [i.float().cuda() for i in j[:-1]]) if regularization else 0
                loss = loss1+loss2
            &#47&#47 print(loss)
            totalloss += loss * len(j[-1])
            totals += len(j[-1])
            if regularization:
                totalloss1 += loss1 * len(j[-1])
                totalloss2 += loss2 * len(j[-1])
                loss.backward(retain_graph=True)
            else:
                loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 8)
            op.step()
        if regularization:
            print("Epoch " + str(epoch) + " train loss: " + str(totalloss1 / totals) + " reg loss: " + str(
                totalloss2 / totals))
        else:
            print("Epoch " + str(epoch) + " train loss: " + str(totalloss / totals))

        model.eval()
        with torch.no_grad():
            totalloss = 0.0
            pred = []
            true = []
            pts = []
            for j in valid_dataloader:
                if is_packed:
                    out = model([[i.cuda() for i in j[0]], j[1]], training=False)
                else:
                    out = model([i.float().cuda() for i in j[:-1]], training=False)
                if type(criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:
                    loss = criterion(out, j[-1].float().cuda())
                else:
                    <a id="change">if len(j[-1].size())&gt;1</a>:
                        <a id="change">j[-1] = j[-1].squeeze()</a>
                    loss<a id="change">=</a><a id="change">criterion(</a>out, <a id="change">j[-1].long().cuda())</a>
                totalloss += loss * len(j[-1])
                if task == "classification":
                    pred.append(torch.argmax(out, 1))
                elif task == "multilabel":</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 33</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pliang279/multibench/commit/ad6f250adaddd084749a47bcb9bc54236badc5ea#diff-54a630d453211fa554eea2d6a4949a8df7b95378a181765b7b2590885b8daad6L42' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9985752</div><div id='project'> Project Name: pliang279/multibench</div><div id='commit'> Commit Name: ad6f250adaddd084749a47bcb9bc54236badc5ea</div><div id='time'> Time: 2021-06-01</div><div id='author'> Author: ztwu_nil@zju.edu.cn</div><div id='file'> File Name: training_structures/Simple_Early_Fusion.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(16)</div><div id='n_method'> N Method Name: train(16)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: training_structures/Simple_Early_Fusion.py</div><div id='n_file'> N File Name: training_structures/Simple_Early_Fusion.py</div><div id='m_start'> M Start Line: 45</div><div id='m_end'> M End Line: 159</div><div id='n_start'> N Start Line: 42</div><div id='n_end'> N End Line: 164</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            pred = []
            true = []
            pts = []
            for <a id="change">j</a> in valid_dataloader:
                if is_packed:
                    out = model([[i.cuda() for i in j[0]], j[1]], training=False)
                else:
                    out = model([i.float().cuda() for i in j[:-1]], training=False)
                if type(criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:
                    loss = criterion(out, j[-1].float().cuda())
                else:
                    loss<a id="change"> = </a><a id="change">criterion(</a>out, <a id="change">j[-1].cuda()</a><a id="change">)</a>
                totalloss += loss * len(j[-1])
                if task == "classification":
                    pred.append(torch.argmax(out, 1))
                elif task == "multilabel":</code></pre><h3>After Change</h3><pre><code class='java'>
        totalloss2 = 0.0
        totals = 0
        model.train()
        for <a id="change">j</a> in train_dataloader:
            &#47&#47 print([i for i in j[:-1]])
            op.zero_grad()
            if is_packed:
                with torch.backends.cudnn.flags(enabled=False):
                    out = model([[i.cuda() for i in j[0]], j[1]], training=True)
                    &#47&#47 print(j[-1])
                    &#47&#47 print(out)
                    loss1 = criterion(out, j[-1].cuda())
                    loss2 = regularize(out, [[i.cuda() for i in j[0]], j[1]]) if regularization else 0
                    loss = loss1 + loss2
            else:
                out=model([i.float().cuda() for i in j[:-1]],training=True)
                &#47&#47print(out, j[-1])
                if type(criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:
                    loss1=criterion(out, j[-1].float().cuda())
                else:
                    <a id="change">if len(j[-1].size())&gt;1</a>:
                        <a id="change">j[-1] = </a><a id="change">j[-1].squeeze()</a>
                    loss1=<a id="change">criterion(</a>out, <a id="change">j[-1].long().cuda()</a><a id="change">)</a>
                loss2=regularize(out, [i.float().cuda() for i in j[:-1]]) if regularization else 0
                loss = loss1+loss2
            &#47&#47 print(loss)
            totalloss += loss * len(j[-1])
            totals += len(j[-1])
            if regularization:
                totalloss1 += loss1 * len(j[-1])
                totalloss2 += loss2 * len(j[-1])
                loss.backward(retain_graph=True)
            else:
                loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 8)
            op.step()
        if regularization:
            print("Epoch " + str(epoch) + " train loss: " + str(totalloss1 / totals) + " reg loss: " + str(
                totalloss2 / totals))
        else:
            print("Epoch " + str(epoch) + " train loss: " + str(totalloss / totals))

        model.eval()
        with torch.no_grad():
            totalloss = 0.0
            pred = []
            true = []
            pts = []
            for <a id="change">j</a> in valid_dataloader:
                if is_packed:
                    out = model([[i.cuda() for i in j[0]], j[1]], training=False)
                else:
                    out = model([i.float().cuda() for i in j[:-1]], training=False)
                if type(criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:
                    loss = criterion(out, j[-1].float().cuda())
                else:
                    <a id="change">if len(j[-1].size())&gt;1</a>:
                        <a id="change">j[-1] = j[-1].squeeze()</a>
                    loss<a id="change">=</a><a id="change">criterion(</a>out, <a id="change">j[-1].long().cuda())</a>
                totalloss += loss * len(j[-1])
                if task == "classification":
                    pred.append(torch.argmax(out, 1))
                elif task == "multilabel":</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pliang279/multibench/commit/76a20ce2589f8280042a0ff0b97f31bded5c8c0c#diff-54a630d453211fa554eea2d6a4949a8df7b95378a181765b7b2590885b8daad6L35' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9985753</div><div id='project'> Project Name: pliang279/multibench</div><div id='commit'> Commit Name: 76a20ce2589f8280042a0ff0b97f31bded5c8c0c</div><div id='time'> Time: 2021-06-01</div><div id='author'> Author: ztwu_nil@zju.edu.cn</div><div id='file'> File Name: training_structures/Simple_Early_Fusion.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(16)</div><div id='n_method'> N Method Name: train(16)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: training_structures/Simple_Early_Fusion.py</div><div id='n_file'> N File Name: training_structures/Simple_Early_Fusion.py</div><div id='m_start'> M Start Line: 45</div><div id='m_end'> M End Line: 159</div><div id='n_start'> N Start Line: 42</div><div id='n_end'> N End Line: 164</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            pred = []
            true = []
            pts = []
            for <a id="change">j</a> in valid_dataloader:
                if is_packed:
                    out = model([[i.cuda() for i in j[0]], j[1]], training=False)
                else:
                    out = model([i.float().cuda() for i in j[:-1]], training=False)
                if type(criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:
                    loss = criterion(out, j[-1].float().cuda())
                else:
                    loss<a id="change"> = </a><a id="change">criterion(</a>out, <a id="change">j[-1].cuda()</a><a id="change">)</a>
                totalloss += loss * len(j[-1])
                if task == "classification":
                    pred.append(torch.argmax(out, 1))
                elif task == "multilabel":</code></pre><h3>After Change</h3><pre><code class='java'>
        totalloss2 = 0.0
        totals = 0
        model.train()
        for <a id="change">j</a> in train_dataloader:
            &#47&#47 print([i for i in j[:-1]])
            op.zero_grad()
            if is_packed:
                with torch.backends.cudnn.flags(enabled=False):
                    out = model([[i.cuda() for i in j[0]], j[1]], training=True)
                    &#47&#47 print(j[-1])
                    &#47&#47 print(out)
                    loss1 = criterion(out, j[-1].cuda())
                    loss2 = regularize(out, [[i.cuda() for i in j[0]], j[1]]) if regularization else 0
                    loss = loss1 + loss2
            else:
                out=model([i.float().cuda() for i in j[:-1]],training=True)
                &#47&#47print(out, j[-1])
                if type(criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:
                    loss1=criterion(out, j[-1].float().cuda())
                else:
                    <a id="change">if len(j[-1].size())&gt;1</a>:
                        <a id="change">j[-1] = </a><a id="change">j[-1].squeeze()</a>
                    loss1=<a id="change">criterion(</a>out, <a id="change">j[-1].long().cuda()</a><a id="change">)</a>
                loss2=regularize(out, [i.float().cuda() for i in j[:-1]]) if regularization else 0
                loss = loss1+loss2
            &#47&#47 print(loss)
            totalloss += loss * len(j[-1])
            totals += len(j[-1])
            if regularization:
                totalloss1 += loss1 * len(j[-1])
                totalloss2 += loss2 * len(j[-1])
                loss.backward(retain_graph=True)
            else:
                loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 8)
            op.step()
        if regularization:
            print("Epoch " + str(epoch) + " train loss: " + str(totalloss1 / totals) + " reg loss: " + str(
                totalloss2 / totals))
        else:
            print("Epoch " + str(epoch) + " train loss: " + str(totalloss / totals))

        model.eval()
        with torch.no_grad():
            totalloss = 0.0
            pred = []
            true = []
            pts = []
            for <a id="change">j</a> in valid_dataloader:
                if is_packed:
                    out = model([[i.cuda() for i in j[0]], j[1]], training=False)
                else:
                    out = model([i.float().cuda() for i in j[:-1]], training=False)
                if type(criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:
                    loss = criterion(out, j[-1].float().cuda())
                else:
                    <a id="change">if len(j[-1].size())&gt;1</a>:
                        <a id="change">j[-1] = j[-1].squeeze()</a>
                    loss<a id="change">=</a><a id="change">criterion(</a>out, <a id="change">j[-1].long().cuda())</a>
                totalloss += loss * len(j[-1])
                if task == "classification":
                    pred.append(torch.argmax(out, 1))
                elif task == "multilabel":</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pliang279/multibench/commit/ad6f250adaddd084749a47bcb9bc54236badc5ea#diff-54a630d453211fa554eea2d6a4949a8df7b95378a181765b7b2590885b8daad6L35' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9985747</div><div id='project'> Project Name: pliang279/multibench</div><div id='commit'> Commit Name: ad6f250adaddd084749a47bcb9bc54236badc5ea</div><div id='time'> Time: 2021-06-01</div><div id='author'> Author: ztwu_nil@zju.edu.cn</div><div id='file'> File Name: training_structures/Simple_Early_Fusion.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(16)</div><div id='n_method'> N Method Name: train(16)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: training_structures/Simple_Early_Fusion.py</div><div id='n_file'> N File Name: training_structures/Simple_Early_Fusion.py</div><div id='m_start'> M Start Line: 45</div><div id='m_end'> M End Line: 159</div><div id='n_start'> N Start Line: 42</div><div id='n_end'> N End Line: 164</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            pred = []
            true = []
            pts = []
            for <a id="change">j</a> in valid_dataloader:
                if is_packed:
                    out=model([[i.cuda() for i in j[0]], j[1]],training=False)
                else:
                    out = model([i.float().cuda() for i in j[:-1]],training=False)
                if type(criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:
                    loss=criterion(out, j[-1].float().cuda())
                else:
                    loss<a id="change">=</a><a id="change">criterion(</a>out, <a id="change">j[-1].cuda()</a><a id="change">)</a>
                totalloss += loss*len(j[-1])
                print(totalloss)
                if task == "classification":
                    pred.append(torch.argmax(out, 1))</code></pre><h3>After Change</h3><pre><code class='java'>
        totalloss2 = 0.0
        totals = 0
        model.train()
        for <a id="change">j</a> in train_dataloader:
            &#47&#47print([i for i in j[:-1]])
            op.zero_grad()
            if is_packed:
                with torch.backends.cudnn.flags(enabled=False):
                    out=model([[i.cuda() for i in j[0]], j[1]],training=True)
                    &#47&#47print(j[-1])
                    &#47&#47print(out)
                    loss1=criterion(out,j[-1].cuda())
                    loss2=regularize(out, [[i.cuda() for i in j[0]], j[1]]) if regularization else 0
                    loss = loss1+loss2
            else:
                out=model([i.float().cuda() for i in j[:-1]],training=True)
                &#47&#47print(out, j[-1])
                if type(criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:
                    loss=criterion(out, j[-1].float().cuda())
                else:
                    <a id="change">if len(j[-1].size())&gt;1</a>:
                        <a id="change">j[-1] = </a><a id="change">j[-1].squeeze()</a>
                    loss=<a id="change">criterion(</a>out, <a id="change">j[-1].long().cuda()</a><a id="change">)</a>
            &#47&#47print(loss)
            totalloss += loss * len(j[-1])
            totals+=len(j[-1])
            if regularization:
                totalloss1 += loss1 * len(j[-1])
                totalloss2 += loss2 * len(j[-1])
                loss.backward(retain_graph=True)
            else:
                loss.backward()
            &#47&#47torch.nn.utils.clip_grad_norm_(model.parameters(), 1)
            op.step()
        if regularization:
            print("Epoch "+str(epoch)+" train loss: "+str(totalloss1/totals)+" reg loss: "+str(totalloss2/totals))
        else:
            print("Epoch "+str(epoch)+" train loss: "+str(totalloss/totals))
        
        model.eval()
        with torch.no_grad():
            totalloss = 0.0
            pred = []
            true = []
            pts = []
            for <a id="change">j</a> in valid_dataloader:
                if is_packed:
                    out=model([[i.cuda() for i in j[0]], j[1]],training=False)
                else:
                    out = model([i.float().cuda() for i in j[:-1]],training=False)
                if type(criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:
                    loss=criterion(out, j[-1].float().cuda())
                else:
                    <a id="change">if len(j[-1].size())&gt;1</a>:
                        <a id="change">j[-1] = j[-1].squeeze()</a>
                    loss<a id="change">=</a><a id="change">criterion(</a>out, <a id="change">j[-1].long().cuda())</a>
                totalloss += loss*len(j[-1])
                &#47&#47print(totalloss)
                if task == "classification":
                    pred.append(torch.argmax(out, 1))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pliang279/multibench/commit/1c128af16e3b49797aee4b1097382015f746c920#diff-d3849819d29a68870215319efee82c37d9369ee66a16c6d341a3d7442791395eL33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9985748</div><div id='project'> Project Name: pliang279/multibench</div><div id='commit'> Commit Name: 1c128af16e3b49797aee4b1097382015f746c920</div><div id='time'> Time: 2021-05-23</div><div id='author'> Author: blairc@andrew.cmu.edu</div><div id='file'> File Name: training_structures/Simple_Late_Fusion.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(16)</div><div id='n_method'> N Method Name: train(16)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: training_structures/Simple_Late_Fusion.py</div><div id='n_file'> N File Name: training_structures/Simple_Late_Fusion.py</div><div id='m_start'> M Start Line: 67</div><div id='m_end'> M End Line: 105</div><div id='n_start'> N Start Line: 55</div><div id='n_end'> N End Line: 107</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            pred = []
            true = []
            pts = []
            for <a id="change">j</a> in valid_dataloader:
                if is_packed:
                    out=model([[i.cuda() for i in j[0]], j[1]],training=False)
                else:
                    out = model([i.float().cuda() for i in j[:-1]],training=False)
                if type(criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:
                    loss=criterion(out, j[-1].float().cuda())
                else:
                    loss<a id="change">=</a><a id="change">criterion(</a>out, <a id="change">j[-1].cuda()</a><a id="change">)</a>
                totalloss += loss*len(j[-1])
                print(totalloss)
                if task == "classification":
                    pred.append(torch.argmax(out, 1))</code></pre><h3>After Change</h3><pre><code class='java'>
        totalloss2 = 0.0
        totals = 0
        model.train()
        for <a id="change">j</a> in train_dataloader:
            &#47&#47print([i for i in j[:-1]])
            op.zero_grad()
            if is_packed:
                with torch.backends.cudnn.flags(enabled=False):
                    out=model([[i.cuda() for i in j[0]], j[1]],training=True)
                    &#47&#47print(j[-1])
                    &#47&#47print(out)
                    loss1=criterion(out,j[-1].cuda())
                    loss2=regularize(out, [[i.cuda() for i in j[0]], j[1]]) if regularization else 0
                    loss = loss1+loss2
            else:
                out=model([i.float().cuda() for i in j[:-1]],training=True)
                &#47&#47print(out, j[-1])
                if type(criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:
                    loss=criterion(out, j[-1].float().cuda())
                else:
                    <a id="change">if len(j[-1].size())&gt;1</a>:
                        <a id="change">j[-1] = </a><a id="change">j[-1].squeeze()</a>
                    loss=<a id="change">criterion(</a>out, <a id="change">j[-1].long().cuda()</a><a id="change">)</a>
            &#47&#47print(loss)
            totalloss += loss * len(j[-1])
            totals+=len(j[-1])
            if regularization:
                totalloss1 += loss1 * len(j[-1])
                totalloss2 += loss2 * len(j[-1])
                loss.backward(retain_graph=True)
            else:
                loss.backward()
            &#47&#47torch.nn.utils.clip_grad_norm_(model.parameters(), 1)
            op.step()
        if regularization:
            print("Epoch "+str(epoch)+" train loss: "+str(totalloss1/totals)+" reg loss: "+str(totalloss2/totals))
        else:
            print("Epoch "+str(epoch)+" train loss: "+str(totalloss/totals))
        
        model.eval()
        with torch.no_grad():
            totalloss = 0.0
            pred = []
            true = []
            pts = []
            for <a id="change">j</a> in valid_dataloader:
                if is_packed:
                    out=model([[i.cuda() for i in j[0]], j[1]],training=False)
                else:
                    out = model([i.float().cuda() for i in j[:-1]],training=False)
                if type(criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:
                    loss=criterion(out, j[-1].float().cuda())
                else:
                    <a id="change">if len(j[-1].size())&gt;1</a>:
                        <a id="change">j[-1] = j[-1].squeeze()</a>
                    loss<a id="change">=</a><a id="change">criterion(</a>out, <a id="change">j[-1].long().cuda())</a>
                totalloss += loss*len(j[-1])
                &#47&#47print(totalloss)
                if task == "classification":
                    pred.append(torch.argmax(out, 1))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pliang279/multibench/commit/e854effb566a45ddcf8788685b859e545feb70c0#diff-d3849819d29a68870215319efee82c37d9369ee66a16c6d341a3d7442791395eL33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9985750</div><div id='project'> Project Name: pliang279/multibench</div><div id='commit'> Commit Name: e854effb566a45ddcf8788685b859e545feb70c0</div><div id='time'> Time: 2021-05-23</div><div id='author'> Author: blairc@andrew.cmu.edu</div><div id='file'> File Name: training_structures/Simple_Late_Fusion.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(16)</div><div id='n_method'> N Method Name: train(16)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: training_structures/Simple_Late_Fusion.py</div><div id='n_file'> N File Name: training_structures/Simple_Late_Fusion.py</div><div id='m_start'> M Start Line: 67</div><div id='m_end'> M End Line: 105</div><div id='n_start'> N Start Line: 55</div><div id='n_end'> N End Line: 107</div><BR>