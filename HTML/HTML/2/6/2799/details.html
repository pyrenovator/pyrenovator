<html><h3>Pattern ID :2799
</h3><img src='11146223.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
def inverse_rotation_warp(img, rot, intrinsics, padding_mode=&quotzeros&quot):

    b, _, h, w = img.size()
    cam_coords = pixel2cam(<a id="change">torch.ones(</a>b, h, w<a id="change">)</a>.type_as(
        img), intrinsics.inverse())  &#47&#47 [B,3,H,W]

    rot_mat = euler2mat(rot)  &#47&#47 [B, 3, 3]</code></pre><h3>After Change</h3><pre><code class='java'>
    world_points = depth_to_3d(torch.ones(B, 1, H, W).type_as(img), intrinsics) &#47&#47 B 3 H W
    cam_points = torch.matmul(P, world_points.view(B, 3, -1))

    pix_coords = cam_points[:, :2, :]<a id="change"> / </a>(<a id="change">cam_points[:, 2, :].unsqueeze(1</a><a id="change">) + </a>1e-7)
    pix_coords<a id="change"> = </a>pix_coords.view(B, 2, H, W)
    pix_coords = pix_coords.permute(0, 2, 3, 1)
    pix_coords[..., 0] /= W - 1
    pix_coords[..., 1] /= H - 1</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/jiawangbian/sc_depth_pl/commit/6a50fb9e99035b26acd8d44a2965c6a5b8eaa4da#diff-12ed95b9590ddbd0f5c333ed7040c3d303665bcf30f4e792d00566aaa13eb00cL129' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11146223</div><div id='project'> Project Name: jiawangbian/sc_depth_pl</div><div id='commit'> Commit Name: 6a50fb9e99035b26acd8d44a2965c6a5b8eaa4da</div><div id='time'> Time: 2022-08-18</div><div id='author'> Author: jiawang.bian@gmail.com</div><div id='file'> File Name: losses/inverse_warp.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: inverse_rotation_warp(4)</div><div id='n_method'> N Method Name: inverse_rotation_warp(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: losses/inverse_warp.py</div><div id='n_file'> N File Name: losses/inverse_warp.py</div><div id='m_start'> M Start Line: 275</div><div id='m_end'> M End Line: 284</div><div id='n_start'> N Start Line: 129</div><div id='n_end'> N End Line: 140</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

                    if "whamr" in self.hparams.data_folder:
                        targets = self.hparams.reverb(
                            targets[0].t(), <a id="change">torch.ones(</a>targets.size(-1)<a id="change">)</a>
                        )
                        targets = targets.t().unsqueeze(0)
                        mix = targets.sum(-1)
</code></pre><h3>After Change</h3><pre><code class='java'>
                        mix = 0
                        for mic in rirs:
                            &#47&#47 rir_cat = torch.flip(torch.stack(mic), [1]).unsqueeze(0)
                            rir_cat = <a id="change">(torch.stack(mic)).unsqueeze(0</a><a id="change">)</a>

                            rir_cat = rir_cat.to(self.device)

                            mix = mix + F.conv1d(
                                targets.permute(0, 2, 1), rir_cat
                            )
                        mix = mix.squeeze(1)

                        &#47&#47 fix the levels
                        coef = (
                            targets.abs().max().item()<a id="change"> / </a>mix.abs().max().item()
                        )
                        mix<a id="change"> = </a>mix<a id="change"> * </a>coef

                        &#47&#47 torchaudio.save(&quotreverbtest.wav&quot, mix.cpu(), 8000)
                        &#47&#47 torchaudio.save(&quottarget.wav&quot, targets[:, :, 0].cpu(), 8000)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/59bc3bf412dc5c1c2e9baf687ede623cc1c4c588#diff-eb60f0baa9cae2dfcac548ade392e883ffc7b89290c90c680e1c9d6200f1c1a5L42' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11146266</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 59bc3bf412dc5c1c2e9baf687ede623cc1c4c588</div><div id='time'> Time: 2021-03-19</div><div id='author'> Author: csubakan@gmail.com</div><div id='file'> File Name: recipes/WSJ0Mix/separation/train.py</div><div id='m_class'> M Class Name: Separation</div><div id='n_method'> N Class Name: Separation</div><div id='m_method'> M Method Name: compute_forward(6)</div><div id='n_method'> N Method Name: compute_forward(5)</div><div id='m_parent_class'> M Parent Class: sb.Brain</div><div id='n_parent_class'> N Parent Class: sb.Brain</div><div id='m_file'> M File Name: recipes/WSJ0Mix/separation/train.py</div><div id='n_file'> N File Name: recipes/WSJ0Mix/separation/train.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 65</div><div id='n_start'> N Start Line: 42</div><div id='n_end'> N End Line: 79</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        device = rays_o.device

        if bg_color is None:
            bg_color = <a id="change">torch.ones(</a>3<a id="change">, dtype=rays_o.dtype, device=device)</a>

        if self.training:
            &#47&#47 setup counter
            counter = self.step_counter[self.local_step % 64]</code></pre><h3>After Change</h3><pre><code class='java'>
            weights_sum, image = raymarching.composite_rays_train(sigmas, rgbs, deltas, rays, bound)

            &#47&#47 composite bg (shade_kernel_nerf)
            image<a id="change"> = </a>image<a id="change"> + </a><a id="change">(1 - weights_sum).unsqueeze(-1</a><a id="change">) * </a>bg_color
            depth = None &#47&#47 currently training do not requires depth

        else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ashawkey/torch-ngp/commit/70f4c365d38080d4ca08cfab4b8f9d01e7e560b0#diff-96330057ed34864879e5c07ca3b71aa0415cc9281c388c0ec9d3d6892d48343aL222' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11146272</div><div id='project'> Project Name: ashawkey/torch-ngp</div><div id='commit'> Commit Name: 70f4c365d38080d4ca08cfab4b8f9d01e7e560b0</div><div id='time'> Time: 2022-03-10</div><div id='author'> Author: ashawkey1999@gmail.com</div><div id='file'> File Name: nerf/renderer.py</div><div id='m_class'> M Class Name: NeRFRenderer</div><div id='n_method'> N Class Name: NeRFRenderer</div><div id='m_method'> M Method Name: run_cuda(8)</div><div id='n_method'> N Method Name: run_cuda(8)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: nerf/renderer.py</div><div id='n_file'> N File Name: nerf/renderer.py</div><div id='m_start'> M Start Line: 230</div><div id='m_end'> M End Line: 303</div><div id='n_start'> N Start Line: 230</div><div id='n_end'> N End Line: 311</div><BR>