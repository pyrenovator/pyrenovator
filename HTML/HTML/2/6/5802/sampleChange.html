<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    if args.lora_rank &gt; 0:
        torch.save({&quotmodel_state_dict&quot: lora.lora_state_dict(trainer.model)}, args.save_path)
    else:
        <a id="change">torch.save(</a>trainer.model, args.save_path<a id="change">)</a>


if __name__ == &quot__main__&quot:
    parser = argparse.ArgumentParser()</code></pre><h3>After Change</h3><pre><code class='java'>
            raise ValueError(f&quotUnsupported model "{args.model}"&quot)

    &#47&#47 configure tokenizer
    <a id="change">if args.model == &quotgpt2&quot</a>:
        tokenizer = GPT2Tokenizer.from_pretrained(&quotgpt2&quot)
        tokenizer.pad_token = tokenizer.eos_token
    elif args.model == &quotbloom&quot:
        tokenizer = BloomTokenizerFast.from_pretrained(args.pretrain)
        tokenizer.pad_token<a id="change"> = </a>tokenizer.eos_token
    elif args.model == &quotopt&quot:
        tokenizer<a id="change"> = </a>AutoTokenizer.from_pretrained("facebook/opt-350m")
    else:
        raise ValueError(f&quotUnsupported model "{args.model}"&quot)
    tokenizer.pad_token = tokenizer.eos_token</code></pre>