<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 - eta -&gt; Î·
        &#47&#47 - pred_image_direction -&gt; "direction pointingc to x_t"
        &#47&#47 - pred_prev_image -&gt; "x_t-1"
        <a id="change">for </a>t in tqdm.tqdm(<a id="change">reversed(</a>range(num_inference_steps)<a id="change">)</a>, total=num_inference_steps)<a id="change">:
            &#47&#47 1. predict noise residual
            </a>timesteps = torch.tensor([inference_step_times[t]] * image.shape[0], device=torch_device)
            pred_noise_t = self.unet(image, timesteps)

            if isinstance(pred_noise_t, dict):
                pred_noise_t = pred_noise_t["sample"]

            &#47&#47 2. predict previous mean of image x_t-1
            pred_prev_image = self.noise_scheduler.step(pred_noise_t, image, t, num_inference_steps, eta)

            &#47&#47 3. optionally sample variance
            variance = 0
            if eta &gt; 0:
                noise = torch.randn(image.shape, generator=generator).to(image.device)
                variance<a id="change"> = </a>self<a id="change">.noise_scheduler.get_variance(t, num_inference_steps).sqrt() * eta * </a>noise

            &#47&#47 4. set current image to prev_image: x_t -&gt; x_t-1
            image = pred_prev_image + variance

        &#47&#47 decode image with vae
        image = self.vqvae.decode(image)
        <a id="change">return </a>image
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 decode image with vae
        image = self.vqvae.decode(image)
        <a id="change">return </a>{"sample": image}
</code></pre>