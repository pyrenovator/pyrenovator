<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
  inputs = tf.keras.Input(
      shape=[len_seqs], batch_size=batch_size, dtype=tf.int32)

  <a id="change">if one_hot</a>:
    x = tf.one_hot(inputs, depth=VOCAB_SIZE)
    embed_size = VOCAB_SIZE
  else:
    x<a id="change"> = </a><a id="change">tf.keras.layers.Embedding(
        VOCAB_SIZE, embed_size, name=&quotembedding&quot)(
            </a>inputs<a id="change">)</a>
  &#47&#47 filter-wise dropout before conv, x.shape=[batch_size, len_seqs, embed_size]
  if before_conv_dropout:
    x = models_util.apply_dropout(
        x, dropout_rate, use_mc_dropout, filter_wise_dropout=True)</code></pre><h3>After Change</h3><pre><code class='java'>
  if gp_layer_hparams and gp_layer_hparams[&quotgp_input_dim&quot] &gt; 0:
    &#47&#47 Uses random projection to reduce the input dimension of the GP layer.
    x = tf.keras.layers.Dense(
        <a id="change">gp_layer_hparams[&quotgp_input_dim&quot]</a>,
        kernel_initializer=&quotrandom_normal&quot,
        use_bias=False,
        trainable=False,</code></pre>