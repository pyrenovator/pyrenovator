<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                  M[0:2, :], (input_res * 2, input_res * 2),
                                  flags=cv2.INTER_CUBIC)

    <a id="change">if </a>det is not None:

        &#47&#47 detection for bbox
        bbox<a id="change"> = </a>get_bbox(img_for_crop, det)

        width = bbox[2] - bbox[0]
        height = bbox[3] - bbox[1]
        center = np.array([(bbox[0] + bbox[2]) / 2.0,
                           (bbox[1] + bbox[3]) / 2.0])

    else:
        &#47&#47 Assume that the person is centerered in the image
        height = img_for_crop.shape[0]
        width<a id="change"> = </a>img_for_crop.shape[1]
        center<a id="change"> = </a>np.array([width // 2, height // 2])

    scale = max(height, width) / 180
</code></pre><h3>After Change</h3><pre><code class='java'>
    detector = detection.maskrcnn_resnet50_fpn(pretrained=True)
    detector.eval()
    predictions = detector(
        [<a id="change">torch.from_numpy(</a>img_for_crop<a id="change">)</a>.permute(2, 0, 1) / 255.])[0]
    human_ids = torch.logical_and(
        predictions["labels"] == 1,
        predictions["scores"] == predictions["scores"].max()).nonzero().squeeze(1)
    bbox<a id="change"> = </a>predictions["boxes"][human_ids, :].flatten().detach().cpu().numpy()
    
    width = bbox[2] - bbox[0]
    height = bbox[3] - bbox[1]</code></pre>