<html><h3>Pattern ID :2997
</h3><img src='11555776.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        ds.map(lambda example: example[&quotsubgroup_label&quot]).batch(
            batch_size).as_numpy_iterator())
    subgroup_labels = np.concatenate(subgroup_labels).tolist()
    df_a = <a id="change">pd.DataFrame(</a>{&quotexample_id&quot: ids, &quotsubgroup_label&quot: subgroup_labels}<a id="change">)</a>
    bias_table<a id="change"> = </a>bias_table[bias_table[&quotexample_id&quot].isin(ids)]
    predictions_merge<a id="change"> = </a>pd.merge(bias_table, df_a, on=[&quotexample_id&quot])
    prob_one = (predictions_merge[&quotsubgroup_label&quot]
                == 1).sum() / len(predictions_merge)
    num_samples.append(len(predictions_merge))</code></pre><h3>After Change</h3><pre><code class='java'>
  round_idx = []
  subgroup_ids = []
  num_samples = []
  prob_representation<a id="change"> = []</a>
  for idx in range(num_rounds):
    ds = dataloader.train_ds
    bias_table = pd.read_csv(
        os.path.join(
            os.path.join(output_dir, f&quotround_{idx}&quot), &quotbias_table.csv&quot))
    predictions_merge = merge_subgroup_labels(ds, bias_table, batch_size)
    for subgroup_id in range(num_subgroups):
      prob_i = (predictions_merge[&quotsubgroup_label&quot]
                == subgroup_id).sum() / len(predictions_merge)
      round_idx.append(idx)
      subgroup_ids.append(subgroup_id)
      num_samples.append(len(predictions_merge))
      <a id="change">prob_representation.append(</a>prob_i<a id="change">)</a>
  return pd.DataFrame({
      &quotnum_samples&quot: num_samples,
      &quotprob_representation&quot: prob_representation,
      &quotround_idx&quot: round_idx,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/google/uncertainty-baselines/commit/f5b53459d654b40668528e806a24776b53864278#diff-898a1ff69c9d70117cfb7c75da053a4e8649b705ffef48bf652f1c38fc3a5858L34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11555776</div><div id='project'> Project Name: google/uncertainty-baselines</div><div id='commit'> Commit Name: f5b53459d654b40668528e806a24776b53864278</div><div id='time'> Time: 2022-11-03</div><div id='author'> Author: no-reply@google.com</div><div id='file'> File Name: experimental/shoshin/evaluate_model_lib.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate_active_sampling(5)</div><div id='n_method'> N Method Name: evaluate_active_sampling(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: experimental/shoshin/evaluate_model_lib.py</div><div id='n_file'> N File Name: experimental/shoshin/evaluate_model_lib.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 59</div><div id='n_start'> N Start Line: 68</div><div id='n_end'> N End Line: 92</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 create the regressor features
    if regressor_config is not None:
        regressors = <a id="change">pd.DataFrame()</a>
        for reg in df.columns:
            if reg in regressor_config:
                regressors[reg]<a id="change"> = </a>df[reg]

        &#47&#47 Make sure column order is consistent
        regressors = regressors[sorted(regressors.columns.tolist())]
        regressors<a id="change"> = </a>regressors.values

        if n_lags == 0:
            regressors = np.expand_dims(regressors, axis=1)</code></pre><h3>After Change</h3><pre><code class='java'>
                regressors["additive"] = additive_regressors

            if multiplicative_regressors is not None:
                multiplicative_regressor_feature_windows<a id="change"> = []</a>
                for i in range(0, multiplicative_regressors.shape[1]):
                    &#47&#47 stride into num_forecast at dim=1 for each sample, just like we did with time
                    <a id="change">multiplicative_regressor_feature_windows.append(
                        </a>_stride_time_features_for_forecasts(multiplicative_regressors[:, i])<a id="change">)</a>
                multiplicative_regressors = np.dstack(multiplicative_regressor_feature_windows)
                regressors["multiplicative"] = multiplicative_regressors

        inputs["regressors"] = regressors</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ourownstory/neural_prophet/commit/71ff07c9baa8002f2611b7f6d3f8f94825e59b1b#diff-19e8b8bb76c45be0b19f9651c6c08d9e4641f5f993cdbaa581338cc45aff7516L99' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11555779</div><div id='project'> Project Name: ourownstory/neural_prophet</div><div id='commit'> Commit Name: 71ff07c9baa8002f2611b7f6d3f8f94825e59b1b</div><div id='time'> Time: 2020-09-14</div><div id='author'> Author: hansika.hewamalage@monash.edu</div><div id='file'> File Name: neuralprophet/time_dataset.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: tabularize_univariate_datetime(10)</div><div id='n_method'> N Method Name: tabularize_univariate_datetime(10)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: neuralprophet/time_dataset.py</div><div id='n_file'> N File Name: neuralprophet/time_dataset.py</div><div id='m_start'> M Start Line: 195</div><div id='m_end'> M End Line: 213</div><div id='n_start'> N Start Line: 201</div><div id='n_end'> N End Line: 267</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        num_ambiguous = 0
        ambiguous_label_name = &quotObserved Labels&quot
        display = <a id="change">pd.DataFrame(columns=[ambiguous_label_name, *dataset.features])</a>

        for num_labels, group_data in sorted(zip(group_unique_labels, group_unique_data),
                                             key=lambda x: x[0], reverse=True):
            if num_labels == 1:
                break

            group_df = group_data[1]
            sample_values = dict(group_df[dataset.features].iloc[0])
            labels = tuple(sorted(group_df[label_name].unique()))
            sample<a id="change"> = </a>pd.DataFrame.from_dict({&quotindex&quot: [labels] + list(sample_values.values())},
                                            columns=[ambiguous_label_name] + list(sample_values.keys()),
                                            orient=&quotindex&quot)
            n_data_sample = group_df.shape[0]
            num_ambiguous += n_data_sample
            if context.with_display:
                display<a id="change"> = </a>pd.concat([display, sample])

        display = display.set_index(ambiguous_label_name)
</code></pre><h3>After Change</h3><pre><code class='java'>

        num_ambiguous = 0
        ambiguous_label_name = &quotObserved Labels&quot
        samples<a id="change"> = []</a>
        display_samples = []

        data = sorted(
            zip(group_unique_labels, group_unique_data),
            key=lambda x: x[0],
            reverse=True
        )

        for num_labels, group_data in data:
            if num_labels == 1:
                continue

            group_df = group_data[1]

            n_data_sample = group_df.shape[0]
            num_ambiguous += n_data_sample
            <a id="change">samples.append(</a>group_df.loc[:, [label_name, *features]].copy()<a id="change">)</a>

            if context.with_display is True:
                display_sample = dict(group_df[features].iloc[0])
                ambiguous_labels = tuple(sorted(group_df[label_name].unique()))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/deepchecks/deepchecks/commit/b0bf20b9abb8067eac01dfc710851aac05ca4564#diff-f12b3d23a1ed0bbbd12a91115b30111a34beba1883c76c196032eb3cdd77a83fL51' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11555771</div><div id='project'> Project Name: deepchecks/deepchecks</div><div id='commit'> Commit Name: b0bf20b9abb8067eac01dfc710851aac05ca4564</div><div id='time'> Time: 2022-06-29</div><div id='author'> Author: 71635444+yromanyshyn@users.noreply.github.com</div><div id='file'> File Name: deepchecks/tabular/checks/data_integrity/conflicting_labels.py</div><div id='m_class'> M Class Name: ConflictingLabels</div><div id='n_method'> N Class Name: ConflictingLabels</div><div id='m_method'> M Method Name: run_logic(3)</div><div id='n_method'> N Method Name: run_logic(3)</div><div id='m_parent_class'> M Parent Class: SingleDatasetCheck</div><div id='n_parent_class'> N Parent Class: SingleDatasetCheck</div><div id='m_file'> M File Name: deepchecks/tabular/checks/data_integrity/conflicting_labels.py</div><div id='n_file'> N File Name: deepchecks/tabular/checks/data_integrity/conflicting_labels.py</div><div id='m_start'> M Start Line: 64</div><div id='m_end'> M End Line: 103</div><div id='n_start'> N Start Line: 71</div><div id='n_end'> N End Line: 123</div><BR>