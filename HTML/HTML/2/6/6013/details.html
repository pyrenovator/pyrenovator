<html><h3>Pattern ID :6013
</h3><img src='21007536.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    

    <a id="change">if </a>not isinstance(dist, rv_frozen):
        <a id="change">raise </a><a id="change">ValueError(</a>"`dist` must be a frozen continuous distribution."<a id="change">)</a>

    tol = float(tol)  &#47&#47 if there&quots an exception, raise it now

    if int(max_intervals) != max_intervals or max_intervals &lt;= 1:</code></pre><h3>After Change</h3><pre><code class='java'>

    has_pdf = hasattr(dist, &quotpdf&quot) and callable(dist.pdf)
    has_cdf = hasattr(dist, &quotcdf&quot) and callable(dist.cdf)
    has_ppf = <a id="change">hasattr(</a>dist, <a id="change">&quotppf&quot</a><a id="change">)</a> and callable(dist.ppf)
    has_isf = hasattr(dist, &quotisf&quot) and callable(dist.isf)

    <a id="change">if </a>not (has_pdf and has_cdf and has_ppf):
        raise ValueError("`dist` must have methods `pdf`, `cdf`, and `ppf`.")

    if not has_isf:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/scipy/scipy/commit/ca0fd50c13634b7caf3803efd1898addecee3000#diff-6c98eba2dc6ffb987521f690b388ff1be0da104b76df2da825a91e47432da652L459' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21007536</div><div id='project'> Project Name: scipy/scipy</div><div id='commit'> Commit Name: ca0fd50c13634b7caf3803efd1898addecee3000</div><div id='time'> Time: 2021-05-24</div><div id='author'> Author: mhaberla@calpoly.edu</div><div id='file'> File Name: scipy/stats/_rvs_sampling.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _fni_input_validation(3)</div><div id='n_method'> N Method Name: _fni_input_validation(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scipy/stats/_rvs_sampling.py</div><div id='n_file'> N File Name: scipy/stats/_rvs_sampling.py</div><div id='m_start'> M Start Line: 459</div><div id='m_end'> M End Line: 462</div><div id='n_start'> N Start Line: 504</div><div id='n_end'> N End Line: 517</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if self.hparams.optim is None:
            optimizer = torch.optim.Adam(parameters, lr=1e-4)
        else:
            <a id="change">if </a>&quot_target_&quot not in to_DictConfig(self.hparams.optim).keys():
                <a id="change">raise </a><a id="change">ValueError(</a>"Please provide a _target_ class for model.optim arg!"<a id="change">)</a>
            optimizer = hydra.utils.instantiate(to_DictConfig(self.hparams.optim), params=self.parameters())
        self._init_lr = optimizer.param_groups[0][&quotlr&quot]

        if self.hparams.scheduler is None:</code></pre><h3>After Change</h3><pre><code class='java'>
            self.log_text.info(" No optimizer was specified, defaulting to AdamW with 1e-4 lr.")
            self.hparams.optimizer.name = &quotadamw&quot

        <a id="change">if </a><a id="change">hasattr(</a>self, <a id="change">&quotno_weight_decay&quot</a><a id="change">)</a>:
            self.log_text.info(f"Model has method no_weight_decay, which will be used.")
        optim_kwargs = {k: v for k, v in self.hparams.optimizer.items() if k not in [&quotname&quot, &quot_target_&quot]}
        optimizer = create_optimizer_v2(model_or_params=self, opt=self.hparams.optimizer.name, **optim_kwargs)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rolnicklab/climart/commit/d4a8bf41fb5dda3d04a45e31cd930fd10964e0a5#diff-dca6b8fd81d3b9ed48032bdf44c4c4abc9d74ab04f63bb89b348809f4e8fb4a2L291' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21007538</div><div id='project'> Project Name: rolnicklab/climart</div><div id='commit'> Commit Name: d4a8bf41fb5dda3d04a45e31cd930fd10964e0a5</div><div id='time'> Time: 2022-06-06</div><div id='author'> Author: salvaruehling@gmail.com</div><div id='file'> File Name: climart/models/base_model.py</div><div id='m_class'> M Class Name: BaseModel</div><div id='n_method'> N Class Name: BaseModel</div><div id='m_method'> M Method Name: configure_optimizers(1)</div><div id='n_method'> N Method Name: configure_optimizers(1)</div><div id='m_parent_class'> M Parent Class: LightningModule</div><div id='n_parent_class'> N Parent Class: LightningModule</div><div id='m_file'> M File Name: climart/models/base_model.py</div><div id='n_file'> N File Name: climart/models/base_model.py</div><div id='m_start'> M Start Line: 292</div><div id='m_end'> M End Line: 298</div><div id='n_start'> N Start Line: 320</div><div id='n_end'> N End Line: 329</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 If the information isn&quott contained in the checkpoint IT HAS TO BE GIVEN
        &#47&#47 BY THE USER.
        if input_norm is None:
            <a id="change">if </a>hasattr(cfg, "normalize"):
                self.normalize = cfg.normalize
            else:
                msg = "The normalize flag is not set in the loaded fairseq checkpoint. "
                msg += (
                    "Please set it to True or False. True = waveform will be "
                )
                msg += "normalized. False, it won&quott. This is dependent on the model."
                msg += " !!! it has to match the pretraining of the wav2vec 2.0 !!!"
                <a id="change">raise </a><a id="change">ValueError(</a>msg<a id="change">)</a>
        else:
            self.normalize = input_norm

        model = model[0]</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Hence, we check if the model has be trained with or without it.
        &#47&#47 If the information isn&quott contained in the checkpoint it is set to False.
        if input_norm is None:
            <a id="change">if </a>not <a id="change">hasattr(</a>cfg["task"], <a id="change">"normalize"</a><a id="change">)</a>:
                self.normalize = cfg["task"].normalize
            else:
                self.normalize = False</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/df91c9ab63144069bb3c53b389b4e1d997c644a0#diff-f154e5df4be06d0debd3139de826910c14071a9c496b593aa9b96f0ef37db90cL67' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21007539</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: df91c9ab63144069bb3c53b389b4e1d997c644a0</div><div id='time'> Time: 2021-04-30</div><div id='author'> Author: parcollet.titouan@gmail.com</div><div id='file'> File Name: speechbrain/lobes/models/fairseq_wav2vec.py</div><div id='m_class'> M Class Name: FairseqWav2Vec2</div><div id='n_method'> N Class Name: FairseqWav2Vec2</div><div id='m_method'> M Method Name: __init__(7)</div><div id='n_method'> N Method Name: __init__(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: speechbrain/lobes/models/fairseq_wav2vec.py</div><div id='n_file'> N File Name: speechbrain/lobes/models/fairseq_wav2vec.py</div><div id='m_start'> M Start Line: 92</div><div id='m_end'> M End Line: 102</div><div id='n_start'> N Start Line: 91</div><div id='n_end'> N End Line: 95</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Feature extractor definition
        if self.config[&quotfeature_extractor&quot] == &quotPointNetPlusPlus&quot:
            self.feature_extractor = blocks.PointNetPlusPlus(self.config[&quotpattern_encoding_size&quot], self.config)  &#47&#47 pass cofiguration from upper layer
        elif <a id="change"></a>self.config[&quotfeature_extractor&quot] == &quotEdgeConvFeatures&quot:
            self.feature_extractor = blocks.EdgeConvFeatures(self.config[&quotpattern_encoding_size&quot])
        else: 
            <a id="change">raise </a><a id="change">ValueError(</a>&quotGarmentPattern3D::Error::Unsupported feature extractor {} requested in config&quot.format(self.config[&quotfeature_extractor&quot])<a id="change">)</a>


        &#47&#47 Decode into pattern definition
        panel_decoder_module = getattr(blocks, self.config[&quotpanel_decoder&quot])</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Feature extractor definition
        feature_extractor_module = getattr(blocks, self.config[&quotfeature_extractor&quot])
        self.feature_extractor = feature_extractor_module(self.config[&quotpattern_encoding_size&quot], self.config)
        <a id="change">if </a><a id="change">hasattr(</a>self.feature_extractor, <a id="change">&quotconfig&quot</a><a id="change">)</a>:
            self.config.update(self.feature_extractor.config)   &#47&#47 save extractor&quots additional configuration

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/maria-korosteleva/garment-pattern-estimation/commit/fd5c692b41060b14597a002bbdb644aa33c2c7f4#diff-44aa79d991dcaba91e0f5234ac001d7d8377d456b3c65b011a4c46d29bef187dL262' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21007533</div><div id='project'> Project Name: maria-korosteleva/garment-pattern-estimation</div><div id='commit'> Commit Name: fd5c692b41060b14597a002bbdb644aa33c2c7f4</div><div id='time'> Time: 2020-09-17</div><div id='author'> Author: mariako@kaist.ac.kr</div><div id='file'> File Name: nn/nets.py</div><div id='m_class'> M Class Name: GarmentPattern3D</div><div id='n_method'> N Class Name: GarmentPattern3D</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: BaseModule</div><div id='n_parent_class'> N Parent Class: BaseModule</div><div id='m_file'> M File Name: nn/nets.py</div><div id='n_file'> N File Name: nn/nets.py</div><div id='m_start'> M Start Line: 290</div><div id='m_end'> M End Line: 299</div><div id='n_start'> N Start Line: 290</div><div id='n_end'> N End Line: 297</div><BR>