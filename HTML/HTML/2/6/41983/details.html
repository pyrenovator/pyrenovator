<html><h3>Pattern ID :41983
</h3><img src='117680355.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        rnn_output, context_alignment = None, None
        for t in range(T):
            if t == 0:
                embedding<a id="change"> = </a>self.decoder_embeddings(<a id="change">Variable(
                    </a>self_attended_context[-1].data.new(B).long().fill_(
                        self.field.vocab.stoi[&quot&lt;init&gt;&quot])<a id="change">, volatile=True)</a>.unsqueeze(1), [1]*B)
            else:
                embedding = self.decoder_embeddings(outs[:, t - 1].unsqueeze(1), [1]*B)
            hiddens[0][:, t] = hiddens[0][:, t] + (math.sqrt(self.self_attentive_decoder.d_model) * embedding).squeeze(1)</code></pre><h3>After Change</h3><pre><code class='java'>
        rnn_output, context_alignment = None, None
        for t in range(T):
            if t == 0:
                <a id="change">with torch</a><a id="change">.no_grad():
                    </a>outs_0<a id="change"> = </a>Variable(self_attended_context[-1].data.new(B).long().fill_(self.field.vocab.stoi[&quot&lt;init&gt;&quot]))
                embedding = self.decoder_embeddings(outs_0.unsqueeze(1), [1]*B)
            else:
                embedding = self.decoder_embeddings(outs[:, t - 1].unsqueeze(1), [1]*B)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/9f19cfb09b47ff69b458788a00383ac6d3b071e1#diff-132fc63ce5affe92920aa4dc16792a1932aa59397084f8e47fcb4e2b203475a9L143' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117680355</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: 9f19cfb09b47ff69b458788a00383ac6d3b071e1</div><div id='time'> Time: 2018-08-13</div><div id='author'> Author: mehrad@stanford.edu</div><div id='file'> File Name: models/coattentive_pointer_generator.py</div><div id='m_class'> M Class Name: CoattentivePointerGenerator</div><div id='n_method'> N Class Name: CoattentivePointerGenerator</div><div id='m_method'> M Method Name: greedy(6)</div><div id='n_method'> N Method Name: greedy(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/coattentive_pointer_generator.py</div><div id='n_file'> N File Name: models/coattentive_pointer_generator.py</div><div id='m_start'> M Start Line: 145</div><div id='m_end'> M End Line: 178</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 180</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        T = self.args.max_output_length
        outs = Variable(context.data.new(B, T).long().fill_(
            self.field.decoder_stoi[&quot&lt;pad&gt;&quot]), volatile=True)
        hiddens<a id="change"> = </a>[<a id="change">Variable(</a>self_attended_context[0].data.new(B, T, C).zero_()<a id="change">, volatile=True)</a>
                   for l in range(len(self.self_attentive_decoder.layers) + 1)]
        hiddens[0] = hiddens[0] + positional_encodings_like(hiddens[0])
        eos_yet = context.data.new(B).byte().zero_()
</code></pre><h3>After Change</h3><pre><code class='java'>


    def greedy(self, self_attended_context, context, question, context_indices, question_indices, oov_to_limited_idx, rnn_state=None):
        <a id="change">with torch</a><a id="change">.no_grad():
            </a>B, TC, C = context.size()
            T = self.args.max_output_length
            outs = context.new_full((B, T), self.field.decoder_stoi[&quot&lt;pad&gt;&quot], dtype=torch.long)
            hiddens<a id="change"> = </a>[self_attended_context[0].new_zeros((B, T, C))
                       for l in range(len(self.self_attentive_decoder.layers) + 1)]
            hiddens[0] = hiddens[0] + positional_encodings_like(hiddens[0])
            eos_yet = context.new_zeros((B, )).byte()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/76304734b69186932db4b58d16dd077b1426c074#diff-d068f20368b9e24ab81f7be561e5b946ca2a0fcb2267e6f1a46ec25745b1389cL177' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117680353</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: 76304734b69186932db4b58d16dd077b1426c074</div><div id='time'> Time: 2018-10-25</div><div id='author'> Author: bryan.mccann.is@gmail.com</div><div id='file'> File Name: models/multitask_question_answering_network.py</div><div id='m_class'> M Class Name: MultitaskQuestionAnsweringNetwork</div><div id='n_method'> N Class Name: MultitaskQuestionAnsweringNetwork</div><div id='m_method'> M Method Name: greedy(8)</div><div id='n_method'> N Method Name: greedy(8)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/multitask_question_answering_network.py</div><div id='n_file'> N File Name: models/multitask_question_answering_network.py</div><div id='m_start'> M Start Line: 178</div><div id='m_end'> M End Line: 215</div><div id='n_start'> N Start Line: 175</div><div id='n_end'> N End Line: 213</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        rnn_output, context_alignment = None, None
        for t in range(T):
            if t == 0:
                embedding<a id="change"> = </a>self.decoder_embeddings(<a id="change">Variable(
                    </a>context[-1].data.new(B).long().fill_(
                        self.field.vocab.stoi[&quot&lt;init&gt;&quot])<a id="change">, volatile=True)</a>.unsqueeze(1), [1]*B)
            else:
                embedding = self.decoder_embeddings(outs[:, t - 1].unsqueeze(1), [1]*B)
            decoder_outputs = self.dual_ptr_rnn_decoder(embedding, &#47&#47hiddens[-1][:, t].unsqueeze(1),</code></pre><h3>After Change</h3><pre><code class='java'>
        rnn_output, context_alignment = None, None
        for t in range(T):
            if t == 0:
                <a id="change">with torch</a><a id="change">.no_grad():
                    </a>outs_0<a id="change"> = </a>Variable(context[-1].data.new(B).long().fill_(self.field.vocab.stoi[&quot&lt;init&gt;&quot]))
                embedding = self.decoder_embeddings(outs_0.unsqueeze(1), [1]*B)
            else:
                embedding = self.decoder_embeddings(outs[:, t - 1].unsqueeze(1), [1]*B)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/9f19cfb09b47ff69b458788a00383ac6d3b071e1#diff-a666c526632b1cdc0ae405d34627213445247898ae8c3f2c372a473428f4574cL115' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117680346</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: 9f19cfb09b47ff69b458788a00383ac6d3b071e1</div><div id='time'> Time: 2018-08-13</div><div id='author'> Author: mehrad@stanford.edu</div><div id='file'> File Name: models/pointer_generator.py</div><div id='m_class'> M Class Name: PointerGenerator</div><div id='n_method'> N Class Name: PointerGenerator</div><div id='m_method'> M Method Name: greedy(5)</div><div id='n_method'> N Method Name: greedy(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/pointer_generator.py</div><div id='n_file'> N File Name: models/pointer_generator.py</div><div id='m_start'> M Start Line: 118</div><div id='m_end'> M End Line: 142</div><div id='n_start'> N Start Line: 114</div><div id='n_end'> N End Line: 141</div><BR>