<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            inter_inputs.append(inputs)

        &#47&#47 Run a chain of requested backends
        <a id="change">for </a>inp, backend in zip(inter_inputs[::-1], requested_backends[::-1])<a id="change">:
            </a>inputs_and_grads<a id="change"> = </a>[inp, grads]
            grads<a id="change"> = </a>await backend.backward_pool.submit_task(*inputs_and_grads)
            assert isinstance(grads, (list, tuple)) and len(grads) == 1
            grads<a id="change"> = </a>grads[0]

        &#47&#47 Serialize the overall grad_input and respond
        return runtime_pb2.ExpertResponse(</code></pre><h3>After Change</h3><pre><code class='java'>
        requested_uids = self._check_uids(request.uid)
        requested_backends = tuple(self.module_backends[uid] for uid in requested_uids)

        grads = <a id="change">await </a>_rpc_backward(*flat_tensors, requested_backends=requested_backends)

        &#47&#47 Modify grad_inputs_schema to support grad_prompts
        assert len(requested_backends[0].args_schema) == 1 and len(grads) in (1, 2)  &#47&#47 TODO generalize</code></pre>