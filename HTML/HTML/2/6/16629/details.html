<html><h3>Pattern ID :16629
</h3><img src='55832850.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            inter_inputs.append(inputs)

        &#47&#47 Run a chain of requested backends
        <a id="change">for </a>inp, backend in zip(inter_inputs[::-1], requested_backends[::-1])<a id="change">:
            </a>inputs_and_grads<a id="change"> = </a>[inp, grads]
            grads<a id="change"> = </a>await backend.backward_pool.submit_task(*inputs_and_grads)
            assert isinstance(grads, (list, tuple)) and len(grads) == 1
            grads<a id="change"> = </a>grads[0]

        &#47&#47 Serialize the overall grad_input and respond
        return runtime_pb2.ExpertResponse(</code></pre><h3>After Change</h3><pre><code class='java'>
        requested_uids = self._check_uids(request.uid)
        requested_backends = tuple(self.module_backends[uid] for uid in requested_uids)

        grads = <a id="change">await </a>_rpc_backward(*flat_tensors, requested_backends=requested_backends)

        &#47&#47 Modify grad_inputs_schema to support grad_prompts
        assert len(requested_backends[0].args_schema) == 1 and len(grads) in (1, 2)  &#47&#47 TODO generalize</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/bigscience-workshop/distributed-bloom/commit/6095f58681bde14962c5023b75a2219c525cbe4c#diff-65ada620fb21ff82c2b88abea8bc2cf7fdd27241f03553f7e7d076339dbaab55L133' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55832850</div><div id='project'> Project Name: bigscience-workshop/distributed-bloom</div><div id='commit'> Commit Name: 6095f58681bde14962c5023b75a2219c525cbe4c</div><div id='time'> Time: 2022-08-12</div><div id='author'> Author: dmitrybaranchuk@gmail.com</div><div id='file'> File Name: src/server/handler.py</div><div id='m_class'> M Class Name: TransformerConnectionHandler</div><div id='n_method'> N Class Name: TransformerConnectionHandler</div><div id='m_method'> M Method Name: rpc_backward(3)</div><div id='n_method'> N Method Name: rpc_backward(3)</div><div id='m_parent_class'> M Parent Class: ConnectionHandler</div><div id='n_parent_class'> N Parent Class: ConnectionHandler</div><div id='m_file'> M File Name: src/server/handler.py</div><div id='n_file'> N File Name: src/server/handler.py</div><div id='m_start'> M Start Line: 142</div><div id='m_end'> M End Line: 168</div><div id='n_start'> N Start Line: 133</div><div id='n_end'> N End Line: 145</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            inter_inputs.append(inputs)

        &#47&#47 Run a backward chain for requested backends
        <a id="change">for </a>inp, <a id="change">backend</a> in zip(inter_inputs[::-1], requested_backends[::-1])<a id="change">:
            </a>inputs_and_grads<a id="change"> = </a>[inp, grads]
            grads<a id="change"> = </a>await backend.backward_pool.submit_task(*inputs_and_grads)
            assert isinstance(grads, (list, tuple)) and len(grads) == 1
            grads<a id="change"> = </a>grads[0]

        &#47&#47 Serialize the overall grad_inputs
        serialized_grad_inputs = [</code></pre><h3>After Change</h3><pre><code class='java'>
        requested_uids = self._check_uids(uids_header)
        requested_backends = tuple(self.module_backends[uid] for uid in requested_uids)

        grads = <a id="change">await </a>_rpc_backward(*flat_tensors, requested_backends=requested_backends)

        &#47&#47 Modify grad_inputs_schema to support grad_prompts
        assert len(requested_backends[0].args_schema) == 1 and len(grads) in (1, 2)  &#47&#47 TODO generalize</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bigscience-workshop/distributed-bloom/commit/6095f58681bde14962c5023b75a2219c525cbe4c#diff-65ada620fb21ff82c2b88abea8bc2cf7fdd27241f03553f7e7d076339dbaab55L175' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55832912</div><div id='project'> Project Name: bigscience-workshop/distributed-bloom</div><div id='commit'> Commit Name: 6095f58681bde14962c5023b75a2219c525cbe4c</div><div id='time'> Time: 2022-08-12</div><div id='author'> Author: dmitrybaranchuk@gmail.com</div><div id='file'> File Name: src/server/handler.py</div><div id='m_class'> M Class Name: TransformerConnectionHandler</div><div id='n_method'> N Class Name: TransformerConnectionHandler</div><div id='m_method'> M Method Name: rpc_backward_stream(3)</div><div id='n_method'> N Method Name: rpc_backward_stream(3)</div><div id='m_parent_class'> M Parent Class: ConnectionHandler</div><div id='n_parent_class'> N Parent Class: ConnectionHandler</div><div id='m_file'> M File Name: src/server/handler.py</div><div id='n_file'> N File Name: src/server/handler.py</div><div id='m_start'> M Start Line: 179</div><div id='m_end'> M End Line: 208</div><div id='n_start'> N Start Line: 159</div><div id='n_end'> N End Line: 175</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                uses_with = {&quotdump_path&quot: dump_path}
        try:
            pea_args_idx = 0
            <a id="change">for i</a> in range(len(self.peas))<a id="change">:
                </a>pea = self.peas[i]
                if pea.role == PeaRoleType.PARALLEL:
                    pea.close()
                    _args = self.peas_args[&quotpeas&quot][pea_args_idx]
                    _args.noblock_on_start = True
                    &#47&#47&#47&#47&#47&#47 BACKWARDS COMPATIBILITY, so THAT DUMP_PATH is in runtime_args
                    _args.dump_path = dump_path
                    &#47&#47&#47&#47&#47&#47
                    _args.uses_with<a id="change"> = </a>uses_with
                    new_pea<a id="change"> = </a>BasePea(_args)
                    self.enter_context(new_pea)
                    await new_pea.async_wait_start_success()
                    new_pea.activate_runtime()
                    self.peas[i]<a id="change"> = </a>new_pea
                    pea_args_idx += 1
        except:
            raise</code></pre><h3>After Change</h3><pre><code class='java'>
            else:
                uses_with = {&quotdump_path&quot: dump_path}
        try:
            <a id="change">await </a>self.replica_set.rolling_update(
                dump_path=dump_path, uses_with=uses_with
            )
        except:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jina-ai/jina/commit/d7f57cd1b3ef4a56517dfae3d99d39ba16cd5d43#diff-835bc1cd3c6f383278831a1eae34edcb26abb646fe00e719bbdb28614271c267L569' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55832855</div><div id='project'> Project Name: jina-ai/jina</div><div id='commit'> Commit Name: d7f57cd1b3ef4a56517dfae3d99d39ba16cd5d43</div><div id='time'> Time: 2021-10-21</div><div id='author'> Author: joan.martinez@jina.ai</div><div id='file'> File Name: jina/peapods/pods/__init__.py</div><div id='m_class'> M Class Name: Pod</div><div id='n_method'> N Class Name: Pod</div><div id='m_method'> M Method Name: rolling_update(2)</div><div id='n_method'> N Method Name: rolling_update(2)</div><div id='m_parent_class'> M Parent Class: BasePod</div><div id='n_parent_class'> N Parent Class: BasePod</div><div id='m_file'> M File Name: jina/peapods/pods/__init__.py</div><div id='n_file'> N File Name: jina/peapods/pods/__init__.py</div><div id='m_start'> M Start Line: 584</div><div id='m_end'> M End Line: 601</div><div id='n_start'> N Start Line: 645</div><div id='n_end'> N End Line: 647</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            inter_inputs.append(inputs)

        &#47&#47 Run a chain of requested backends
        <a id="change">for </a>inp, <a id="change">backend</a> in zip(inter_inputs[::-1], requested_backends[::-1])<a id="change">:
            </a>inputs_and_grads<a id="change"> = </a>[inp, grads]
            grads<a id="change"> = </a>await backend.backward_pool.submit_task(*inputs_and_grads)
            assert isinstance(grads, (list, tuple)) and len(grads) == 1
            grads<a id="change"> = </a>grads[0]

        &#47&#47 Serialize the overall grad_input and respond
        return runtime_pb2.ExpertResponse(</code></pre><h3>After Change</h3><pre><code class='java'>
        requested_uids = self._check_uids(request.uid)
        requested_backends = tuple(self.module_backends[uid] for uid in requested_uids)

        grads = <a id="change">await </a>_rpc_backward(*flat_tensors, requested_backends=requested_backends)

        &#47&#47 Modify grad_inputs_schema to support grad_prompts
        assert len(requested_backends[0].args_schema) == 1 and len(grads) in (1, 2)  &#47&#47 TODO generalize</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bigscience-workshop/distributed-bloom/commit/6095f58681bde14962c5023b75a2219c525cbe4c#diff-65ada620fb21ff82c2b88abea8bc2cf7fdd27241f03553f7e7d076339dbaab55L140' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55832813</div><div id='project'> Project Name: bigscience-workshop/distributed-bloom</div><div id='commit'> Commit Name: 6095f58681bde14962c5023b75a2219c525cbe4c</div><div id='time'> Time: 2022-08-12</div><div id='author'> Author: dmitrybaranchuk@gmail.com</div><div id='file'> File Name: src/server/handler.py</div><div id='m_class'> M Class Name: TransformerConnectionHandler</div><div id='n_method'> N Class Name: TransformerConnectionHandler</div><div id='m_method'> M Method Name: rpc_backward(3)</div><div id='n_method'> N Method Name: rpc_backward(3)</div><div id='m_parent_class'> M Parent Class: ConnectionHandler</div><div id='n_parent_class'> N Parent Class: ConnectionHandler</div><div id='m_file'> M File Name: src/server/handler.py</div><div id='n_file'> N File Name: src/server/handler.py</div><div id='m_start'> M Start Line: 142</div><div id='m_end'> M End Line: 168</div><div id='n_start'> N Start Line: 133</div><div id='n_end'> N End Line: 145</div><BR>