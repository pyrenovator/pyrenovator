<html><h3>Pattern ID :382
</h3><img src='2271606.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 We don&quott allow an empty split by virtue of the parameter declaration,
    &#47&#47 so we always have a split.
    read_config = dataclasses.replace(
        <a id="change">kwargs.pop(&quotread_config&quot</a>, tfds.ReadConfig()<a id="change">)</a>)
    &#47&#47 Add the &quottfds_id&quot key to the samples which we can then parse.
    &#47&#47 From: https://www.tensorflow.org/datasets/api_docs/python/tfds/ReadConfig
    read_config.add_tfds_id = True

    dataset = self.base_dataset_builder.as_dataset(
        split=split, shuffle_files=False, read_config=read_config, **kwargs)

    element_spec = dataset.element_spec.copy()
    element_spec[&quotid&quot] = tf.TensorSpec(shape=(), dtype=tf.int64, name=None)
    logging.info(msg=f&quotelement_spec = {element_spec}; &quot
                 f&quottype = {jax.tree_map(type, element_spec)}&quot)

    dataset = tf.data.Dataset.from_generator(
        _subset_generator(
            dataset=dataset,
            dataset_info=self.base_dataset_builder.info,
            subset_ids=self.subset_ids,
            splitwise_id=True),
        output_signature=element_spec,
    )

    &#47&#47 This is a bit more complex: potentially cache before or after calling
    &#47&#47 .shuffle. BUT don&quott cache for the pool set as it will be much larger than
    &#47&#47 the training set.
    reshuffle_each_iteration<a id="change"> = </a>shuffle_files and read_config.shuffle_reshuffle_each_iteration
    cache_data = self.subset_ids is not None

    if reshuffle_each_iteration and cache_data:
      dataset = dataset.cache()
    if shuffle_files:
      if self.subset_ids is not None:
        buffer_size = len(self.subset_ids)
      else:
        &#47&#47 TODO(andreas): what buffer size do we want actually for shuffling?
        &#47&#47   10k seems like a safe thing.
        buffer_size = 10000
      dataset = dataset.shuffle(
          buffer_size=buffer_size,
          seed=read_config.shuffle_seed,
          reshuffle_each_iteration=read_config.shuffle_reshuffle_each_iteration)
    if <a id="change">not reshuffle_each_iteration and cache_data</a>:
      dataset = dataset.cache()
    return dataset
</code></pre><h3>After Change</h3><pre><code class='java'>
    Constructs a dataset containing a subset of the original dataset.
    &#47&#47 Add the &quottfds_id&quot key to the samples which we can then parse.
    &#47&#47 From: https://www.tensorflow.org/datasets/api_docs/python/tfds/ReadConfig
    <a id="change">if read_config is None</a>:
      logging.info(&quotUsing an empty ReadConfig!&quot)
      read_config = tfds.ReadConfig()
    read_config = dataclasses.replace(read_config, add_tfds_id=True)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/google/uncertainty-baselines/commit/9a26d7d634c28e0417378cd77432f08c00254f2f#diff-3f47e20cf1c8e2b81ee3f064457e40c4b0fc07c8cea0a63a1c872cfbcbe8ce6aL109' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2271606</div><div id='project'> Project Name: google/uncertainty-baselines</div><div id='commit'> Commit Name: 9a26d7d634c28e0417378cd77432f08c00254f2f</div><div id='time'> Time: 2022-04-19</div><div id='author'> Author: dusenberrymw@google.com</div><div id='file'> File Name: baselines/jft/al_utils.py</div><div id='m_class'> M Class Name: SubsetDatasetBuilder</div><div id='n_method'> N Class Name: SubsetDatasetBuilder</div><div id='m_method'> M Method Name: as_dataset(2)</div><div id='n_method'> N Method Name: as_dataset(2)</div><div id='m_parent_class'> M Parent Class: DatasetBuilder</div><div id='n_parent_class'> N Parent Class: DatasetBuilder</div><div id='m_file'> M File Name: baselines/jft/al_utils.py</div><div id='n_file'> N File Name: baselines/jft/al_utils.py</div><div id='m_start'> M Start Line: 109</div><div id='m_end'> M End Line: 153</div><div id='n_start'> N Start Line: 110</div><div id='n_end'> N End Line: 113</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            input_mask = torch.full_like(out, True, dtype=torch.bool, device=out.device)
        
        &#47&#47 in case of conditional generation, if enc_mask is not provided use the correct context_mask
        context<a id="change"> = </a><a id="change">kwargs.pop(&quotcontext&quot</a>, None<a id="change">)</a>
        context_mask = kwargs.pop(&quotcontext_mask&quot, None)
        if <a id="change">context is not None and context_mask is None</a>:
            context_mask = torch.full(context.shape[:2], True, dtype=torch.bool, device=out.device)

        for _ in range(seq_len):</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 in case of conditional generation, if enc_mask is not provided use the correct context_mask
        context_mask = kwargs.pop(&quotcontext_mask&quot, None)

        <a id="change">if &quotcontext&quot in kwargs</a> and not exists(context_mask):
            context = kwargs[&quotcontext&quot]
            context_mask = torch.full(context.shape[:2], True, dtype=torch.bool, device=out.device)
            kwargs.update(context_mask = context_mask)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/performer-pytorch/commit/e10ec182c2aba2eba66b59a175ed767251aa3889#diff-192164ea998deaff038129dced1fc9dbccf034f70eaf2ffa88b31af860963378L35' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2271610</div><div id='project'> Project Name: lucidrains/performer-pytorch</div><div id='commit'> Commit Name: e10ec182c2aba2eba66b59a175ed767251aa3889</div><div id='time'> Time: 2020-12-08</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: performer_pytorch/autoregressive_wrapper.py</div><div id='m_class'> M Class Name: AutoregressiveWrapper</div><div id='n_method'> N Class Name: AutoregressiveWrapper</div><div id='m_method'> M Method Name: generate(7)</div><div id='n_method'> N Method Name: generate(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: performer_pytorch/autoregressive_wrapper.py</div><div id='n_file'> N File Name: performer_pytorch/autoregressive_wrapper.py</div><div id='m_start'> M Start Line: 52</div><div id='m_end'> M End Line: 57</div><div id='n_start'> N Start Line: 55</div><div id='n_end'> N End Line: 62</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            executor = self.executor
        else:
            &#47&#47 use passed in executor
            executor<a id="change"> = </a><a id="change">kwargs.pop("executor"</a><a id="change">)</a>

        return (
            executor.submit(self._run, *args, **kwargs)  &#47&#47 Non-Blocking call
            if <a id="change">executor and not self.use_dynamic_batch()</a>
            else self._run(*args, **kwargs)  &#47&#47 Blocking call
        )

    @staticmethod</code></pre><h3>After Change</h3><pre><code class='java'>
        self._batch_size = self._batch_size or 1

    def __call__(self, *args, **kwargs) -&gt; BaseModel:
        <a id="change">if "engine_inputs" in kwargs</a>:
            raise ValueError(
                "invalid kwarg engine_inputs. engine inputs determined "
                f"by {self.__class__.__qualname__}.parse_inputs"</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neuralmagic/deepsparse/commit/51a99e18329a82cfff93b9cda06eb4f6983c64e2#diff-bab8a867c64069e2efe49cfb9a3ada579e3058fa48bdafcc743f1cca24bcd147L179' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2271608</div><div id='project'> Project Name: neuralmagic/deepsparse</div><div id='commit'> Commit Name: 51a99e18329a82cfff93b9cda06eb4f6983c64e2</div><div id='time'> Time: 2022-08-30</div><div id='author'> Author: 109536191+corey-nm@users.noreply.github.com</div><div id='file'> File Name: src/deepsparse/pipeline.py</div><div id='m_class'> M Class Name: Pipeline</div><div id='n_method'> N Class Name: Pipeline</div><div id='m_method'> M Method Name: __call__(1)</div><div id='n_method'> N Method Name: __call__(1)</div><div id='m_parent_class'> M Parent Class: ABC</div><div id='n_parent_class'> N Parent Class: ABC</div><div id='m_file'> M File Name: src/deepsparse/pipeline.py</div><div id='n_file'> N File Name: src/deepsparse/pipeline.py</div><div id='m_start'> M Start Line: 180</div><div id='m_end'> M End Line: 194</div><div id='n_start'> N Start Line: 180</div><div id='n_end'> N End Line: 224</div><BR>