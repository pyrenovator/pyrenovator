<html><h3>Pattern ID :19061
</h3><img src='62139052.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            padded_position_ids = position_ids.unsqueeze(0).expand(shape=[input_shape[0], padding_length])
            position_ids = paddle.concat([position_ids, padded_position_ids], axis=-1)

        <a id="change">return </a>input_ids<a id="change">, attention_mask, position_ids, input_shape</a>


class ReformerModelWithLMHead(ReformerPretrainedModel):
    </code></pre><h3>After Change</h3><pre><code class='java'>
                position_ids = paddle.concat([position_ids, padded_position_ids], axis=-1)

        &#47&#47 Extend `inputs_embeds` with padding to match least common multiple chunk_length
        <a id="change">if </a>inputs_embeds is not None:
            padded_inputs_embeds = self.embeddings(padded_input_ids, position_ids)
            inputs_embeds<a id="change"> = </a><a id="change">paddle.concat([</a>inputs_embeds, padded_inputs_embeds<a id="change"></a>]<a id="change">, axis=-2)</a>
            input_shape = inputs_embeds.shape
        return input_ids, inputs_embeds, attention_mask, position_ids, input_shape

</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/7c75f5983d9a09617f1492345c65cfe1087338b5#diff-2b88f6901da7b46addcc8593f924d2f5b35bbf3fe795de42918a8d350b6af03eL2368' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 62139052</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 7c75f5983d9a09617f1492345c65cfe1087338b5</div><div id='time'> Time: 2023-03-13</div><div id='author'> Author: 115528288+tsinghua-zhang@users.noreply.github.com</div><div id='file'> File Name: paddlenlp/transformers/reformer/modeling.py</div><div id='m_class'> M Class Name: ReformerModel</div><div id='n_method'> N Class Name: ReformerModel</div><div id='m_method'> M Method Name: _pad_to_mult_of_chunk_length(8)</div><div id='n_method'> N Method Name: _pad_to_mult_of_chunk_length(7)</div><div id='m_parent_class'> M Parent Class: ReformerPretrainedModel</div><div id='n_parent_class'> N Parent Class: ReformerPretrainedModel</div><div id='m_file'> M File Name: paddlenlp/transformers/reformer/modeling.py</div><div id='n_file'> N File Name: paddlenlp/transformers/reformer/modeling.py</div><div id='m_start'> M Start Line: 2368</div><div id='m_end'> M End Line: 2395</div><div id='n_start'> N Start Line: 2379</div><div id='n_end'> N End Line: 2427</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            pred_scores.append(self.cls_score(self.cls_net(feat)))
            pred_boxes.append(self.bbox_pred(self.reg_net(feat)))

        <a id="change">return </a>pred_scores<a id="change">, pred_boxes</a>

    def losses(self, anchors, preds, inputs):
        anchors = paddle.concat(anchors)
</code></pre><h3>After Change</h3><pre><code class='java'>
            transpose_to_bs_hwa_k(s, 4) for s in pred_boxes
        ]

        <a id="change">if </a>self.training:
            anchors = paddle.concat(anchors)
            loss_dict = self.get_loss(anchors, [pred_scores_list, pred_boxes_list], inputs)

            return loss_dict
        
        else:
            img_whwh<a id="change"> = </a><a id="change">paddle.concat([</a>inputs["imgs_shape"][:, 1:2],
                                      inputs["imgs_shape"][:, 0:1]<a id="change"></a>]<a id="change">, axis=-1)</a>
            pred_result, bbox_num = self.postprocess(
                pred_scores_list, 
                pred_boxes_list, 
                anchors,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/br-idl/paddlevit/commit/d508b9b4d72fd64e8a8ab019a4a6ed3bab660203#diff-3a5e9f44bd8cc2f7794c16f86abd693aa2079bc45939f1b2016c4b5beb843246L92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 62139053</div><div id='project'> Project Name: br-idl/paddlevit</div><div id='commit'> Commit Name: d508b9b4d72fd64e8a8ab019a4a6ed3bab660203</div><div id='time'> Time: 2021-08-19</div><div id='author'> Author: feizzhang@163.com</div><div id='file'> File Name: object_detection/ODHead/retinaNet_head/retinanet_head.py</div><div id='m_class'> M Class Name: RetinaNetHead</div><div id='n_method'> N Class Name: RetinaNetHead</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Layer</div><div id='n_parent_class'> N Parent Class: nn.Layer</div><div id='m_file'> M File Name: object_detection/ODHead/retinaNet_head/retinanet_head.py</div><div id='n_file'> N File Name: object_detection/ODHead/retinaNet_head/retinanet_head.py</div><div id='m_start'> M Start Line: 93</div><div id='m_end'> M End Line: 100</div><div id='n_start'> N Start Line: 113</div><div id='n_end'> N End Line: 158</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        mix_layer = paddle.reshape_(mix_layer, [0, 0, self.num_heads, 3 * self.head_dim])
        mix_layer = paddle.transpose(mix_layer, [0, 2, 1, 3])
        q, k, v = paddle.split(mix_layer, num_or_sections=3, axis=-1)
        <a id="change">return </a>q<a id="change">, k, v</a>

    def _prepare_qkv(self, query, key, value, use_cache=False, cache=None):
        r
        Prapares linear projected queries, keys and values for usage of subsequnt</code></pre><h3>After Change</h3><pre><code class='java'>

        assert not isinstance(cache, self.StaticCache), "cache currently does not support the StaticCache type"

        <a id="change">if </a>isinstance(cache, self.Cache):
            &#47&#47 for decoder self-attention in inference
            k = tensor.concat([cache.k, k], axis=2)
            v<a id="change"> = </a><a id="change">tensor.concat([</a>cache.v, v<a id="change"></a>]<a id="change">, axis=2)</a>
        if use_cache is True:
            cache = self.Cache(k, v)

        return (q, k, v, cache) if use_cache else (q, k, v, None)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/d71b03754a7e5dbab880cb14d12717e2298045d1#diff-9bb9f18c3e14727084b01bf188121da9afb4893fdfb8b323f8c3fc98d0c4a22bL102' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 62139054</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: d71b03754a7e5dbab880cb14d12717e2298045d1</div><div id='time'> Time: 2023-03-12</div><div id='author'> Author: zhonghui.net@gmail.com</div><div id='file'> File Name: paddlenlp/transformers/gpt/modeling.py</div><div id='m_class'> M Class Name: MultiHeadAttention</div><div id='n_method'> N Class Name: MultiHeadAttention</div><div id='m_method'> M Method Name: _fuse_prepare_qkv(4)</div><div id='n_method'> N Method Name: _fuse_prepare_qkv(2)</div><div id='m_parent_class'> M Parent Class: nn.Layer</div><div id='n_parent_class'> N Parent Class: nn.Layer</div><div id='m_file'> M File Name: paddlenlp/transformers/gpt/modeling.py</div><div id='n_file'> N File Name: paddlenlp/transformers/gpt/modeling.py</div><div id='m_start'> M Start Line: 102</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 100</div><div id='n_end'> N End Line: 115</div><BR>