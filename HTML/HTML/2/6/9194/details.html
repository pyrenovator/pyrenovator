<html><h3>Pattern ID :9194
</h3><img src='33288698.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    elif n_dims != 3:
        raise ValueError("mixture.dim() is expected 3 or 4, but given {}.".format(mixture.dim()))

    <a id="change">assert </a>estimated_sources_amplitude.dim() == 4, "estimated_sources_amplitude.dim() is expected 4, but given {}.".format(estimated_sources_amplitude.dim())

    ratio = estimated_sources_amplitude / estimated_sources_amplitude.sum(dim=0)
    estimated_sources = ratio * mixture</code></pre><h3>After Change</h3><pre><code class='java'>
    estimated_amplitude = estimated_amplitude.detach().cpu().numpy()

    mixture = mixture.transpose(2, 1, 0)
    estimated_amplitude<a id="change"> = </a><a id="change">estimated_amplitude.transpose(3</a>, 2, 1, <a id="change">0</a><a id="change">)</a>
    estimated_sources = norbert.wiener(estimated_amplitude, mixture, eps=eps)
    estimated_sources = estimated_sources.transpose(3, 2, 1, 0)
    estimated_sources<a id="change"> = </a>torch.from_numpy(estimated_sources).to(device, dtype)

    return estimated_sources</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tky823/dnn-based_source_separation/commit/11a2e82888f76547df72eff58c6a592e3473e65c#diff-7c5b1018ab6bf19cc2f7c1fc385abd4adb493c178cdd1548dcae8770f80fb8fdL383' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33288698</div><div id='project'> Project Name: tky823/dnn-based_source_separation</div><div id='commit'> Commit Name: 11a2e82888f76547df72eff58c6a592e3473e65c</div><div id='time'> Time: 2021-08-20</div><div id='author'> Author: 40362510+tky823@users.noreply.github.com</div><div id='file'> File Name: egs/musdb18/d3net/src/adhoc_driver.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: apply_multichannel_wiener_filter(4)</div><div id='n_method'> N Method Name: apply_multichannel_wiener_filter(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: egs/musdb18/d3net/src/adhoc_driver.py</div><div id='n_file'> N File Name: egs/musdb18/d3net/src/adhoc_driver.py</div><div id='m_start'> M Start Line: 383</div><div id='m_end'> M End Line: 401</div><div id='n_start'> N Start Line: 397</div><div id='n_end'> N End Line: 413</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.final_merge.weight.data = clf_weights

    def forward(self, x, **kwargs):
        <a id="change">assert </a>x.shape[2] == self.temporal_dim, "invalid number of frames given"
        last_frame = x[:, :, -1]  &#47&#47 [b, c, h, w]
        big_branch = self.big_branch(x).squeeze(2)  &#47&#47 [b, c, h, w]
        out = self.final_merge(torch.cat([big_branch, last_frame], dim=1))</code></pre><h3>After Change</h3><pre><code class='java'>
        return out

    def forward(self, x, pred_length=1, **kwargs):
        x<a id="change"> = </a><a id="change">x.transpose(1</a>, <a id="change">2</a><a id="change">)</a>  &#47&#47 shape: [b, c, t, h, w]
        output_frames = []
        for t in range(pred_length):
            input<a id="change"> = </a>x[:, :, -self.temporal_dim:]
            output_frames.append(self.pred_1(input))
        return torch.stack(output_frames, dim=1), None
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ais-bonn/vp-suite/commit/b1ebac921dc35dcaf5e5c3f9fe803c4c9e2d78f8#diff-fbd71ad5a29af730394535b97e62a8cce64cb44421b70aafd01ff726385abfd5L78' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33288589</div><div id='project'> Project Name: ais-bonn/vp-suite</div><div id='commit'> Commit Name: b1ebac921dc35dcaf5e5c3f9fe803c4c9e2d78f8</div><div id='time'> Time: 2022-01-14</div><div id='author'> Author: boltres@ais.uni-bonn.de</div><div id='file'> File Name: vp_suite/models/simple.py</div><div id='m_class'> M Class Name: SimpleV2</div><div id='n_method'> N Class Name: SimpleV2</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: VideoPredictionModel</div><div id='n_parent_class'> N Parent Class: VideoPredictionModel</div><div id='m_file'> M File Name: vp_suite/models/simple.py</div><div id='n_file'> N File Name: vp_suite/models/simple.py</div><div id='m_start'> M Start Line: 79</div><div id='m_end'> M End Line: 83</div><div id='n_start'> N Start Line: 86</div><div id='n_end'> N End Line: 92</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.cnn.weight.data = clf_weights

    def forward(self, x, **kwargs):
        <a id="change">assert </a>x.shape[2] == self.temporal_dim, "invalid number of frames given"
        return self.cnn(x)

    def pred_n(self, x, pred_length=1, **kwargs):</code></pre><h3>After Change</h3><pre><code class='java'>
        return self.cnn(x)

    def forward(self, x, pred_length=1, **kwargs):
        x<a id="change"> = </a><a id="change">x.transpose(1</a>, <a id="change">2</a><a id="change">)</a>  &#47&#47 shape: [b, c, t, h, w]
        output_frames = []
        for t in range(pred_length):
            input<a id="change"> = </a>x[:, :, -self.temporal_dim:]
            output_frames.append(self.pred_1(input))
        return torch.cat(output_frames, dim=2).transpose(1, 2), None
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ais-bonn/vp-suite/commit/b1ebac921dc35dcaf5e5c3f9fe803c4c9e2d78f8#diff-fbd71ad5a29af730394535b97e62a8cce64cb44421b70aafd01ff726385abfd5L31' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33288534</div><div id='project'> Project Name: ais-bonn/vp-suite</div><div id='commit'> Commit Name: b1ebac921dc35dcaf5e5c3f9fe803c4c9e2d78f8</div><div id='time'> Time: 2022-01-14</div><div id='author'> Author: boltres@ais.uni-bonn.de</div><div id='file'> File Name: vp_suite/models/simple.py</div><div id='m_class'> M Class Name: SimpleV1</div><div id='n_method'> N Class Name: SimpleV1</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: VideoPredictionModel</div><div id='n_parent_class'> N Parent Class: VideoPredictionModel</div><div id='m_file'> M File Name: vp_suite/models/simple.py</div><div id='n_file'> N File Name: vp_suite/models/simple.py</div><div id='m_start'> M Start Line: 32</div><div id='m_end'> M End Line: 33</div><div id='n_start'> N Start Line: 35</div><div id='n_end'> N End Line: 41</div><BR>