<html><h3>Pattern ID :29926
</h3><img src='88800746.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    Returns:
        A tuple of cropped image, cropped boxes, where the image is not resized.
    
    xmin<a id="change">, ymin, xmax, ymax</a> = crop_box
    croped_img = F.crop(
        img, ymin, xmin, ymax - ymin, xmax - xmin
    )</code></pre><h3>After Change</h3><pre><code class='java'>
    Returns:
        A tuple of cropped image, cropped boxes, where the image is not resized.
    
    <a id="change">if </a>any(<a id="change">val &lt; 0</a> or val &gt; 1 for val in crop_box):
        <a id="change">raise </a><a id="change">AssertionError("coordinates of arg `crop_box` should be relative"</a><a id="change">)</a>
    h, w = img.shape[-2:]
    xmin, ymin = int(round(crop_box[0] * (w - 1))), int(round(crop_box[1] * (h - 1)))
    xmax, ymax = int(round(crop_box[2] * (w - 1))), int(round(crop_box[3] * (h - 1)))
    croped_img = F.crop(</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/mindee/doctr/commit/f5b6375507ace7ec9f5666cde4e3fb2b938373ed#diff-d26a232e6a24ee5ba725dd35e4b320e7c3dbf12c90e5995bba08248ae6515396L83' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 88800746</div><div id='project'> Project Name: mindee/doctr</div><div id='commit'> Commit Name: f5b6375507ace7ec9f5666cde4e3fb2b938373ed</div><div id='time'> Time: 2021-12-29</div><div id='author'> Author: 76527547+fg-mindee@users.noreply.github.com</div><div id='file'> File Name: doctr/transforms/functional/pytorch.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: crop_detection(3)</div><div id='n_method'> N Method Name: crop_detection(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: doctr/transforms/functional/pytorch.py</div><div id='n_file'> N File Name: doctr/transforms/functional/pytorch.py</div><div id='m_start'> M Start Line: 83</div><div id='m_end'> M End Line: 83</div><div id='n_start'> N Start Line: 83</div><div id='n_end'> N End Line: 87</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                if self.q_is_k:
                    query = key = value = query.swapaxes(1, 0)
                else:
                    query, key = [x.swapaxes(1, 0) for x in (query<a id="change">, key</a>)]
                    value = key
            else:
                query = query.swapaxes(1, 0)</code></pre><h3>After Change</h3><pre><code class='java'>
        is_batched = query.ndim == 3
        if key_padding_mask is not None:
            _kpm_dtype = key_padding_mask.dtype
            <a id="change">if _kpm_dtype != mindspore.bool_</a> and not ops.is_floating_point(key_padding_mask):
                <a id="change">raise </a><a id="change">AssertionError(
                    "only bool and floating types of key_padding_mask are supported"</a><a id="change">)</a>

        if self.batch_first and is_batched:
            &#47&#47 k_is_v and q_is_k preprocess in __call__ since Graph mode do not support `is`
            if self.k_is_v:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mindlab-ai/mindnlp/commit/4bbd19237d96b2609f86ff06e0d7ee45ed01eed5#diff-6a67d261f15deb7334c11c5e1253f697a90a0c18e009fcd2e7c89762dd15b3ffL127' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 88800747</div><div id='project'> Project Name: mindlab-ai/mindnlp</div><div id='commit'> Commit Name: 4bbd19237d96b2609f86ff06e0d7ee45ed01eed5</div><div id='time'> Time: 2023-02-28</div><div id='author'> Author: lvyufeng@cqu.edu.cn</div><div id='file'> File Name: mindnlp/common/nn/transformer.py</div><div id='m_class'> M Class Name: MultiheadAttention</div><div id='n_method'> N Class Name: MultiheadAttention</div><div id='m_method'> M Method Name: construct(8)</div><div id='n_method'> N Method Name: construct(8)</div><div id='m_parent_class'> M Parent Class: nn.Cell</div><div id='n_parent_class'> N Parent Class: nn.Cell</div><div id='m_file'> M File Name: mindnlp/common/nn/transformer.py</div><div id='n_file'> N File Name: mindnlp/common/nn/transformer.py</div><div id='m_start'> M Start Line: 127</div><div id='m_end'> M End Line: 144</div><div id='n_start'> N Start Line: 156</div><div id='n_end'> N End Line: 172</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    Returns:
        A tuple of cropped image, cropped boxes, where the image is not resized.
    
    xmin<a id="change">, ymin, xmax, ymax</a> = crop_box
    croped_img = tf.image.crop_to_bounding_box(
        img, ymin, xmin, ymax - ymin, xmax - xmin
    )</code></pre><h3>After Change</h3><pre><code class='java'>
    Returns:
        A tuple of cropped image, cropped boxes, where the image is not resized.
    
    <a id="change">if </a>any(<a id="change">val &lt; 0</a> or val &gt; 1 for val in crop_box):
        <a id="change">raise </a><a id="change">AssertionError("coordinates of arg `crop_box` should be relative"</a><a id="change">)</a>
    h, w = img.shape[:2]
    xmin, ymin = int(round(crop_box[0] * (w - 1))), int(round(crop_box[1] * (h - 1)))
    xmax, ymax = int(round(crop_box[2] * (w - 1))), int(round(crop_box[3] * (h - 1)))
    croped_img = tf.image.crop_to_bounding_box(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mindee/doctr/commit/f5b6375507ace7ec9f5666cde4e3fb2b938373ed#diff-f71e7cf69ea60bc9fec67835b1bccabbf8f233d7de424bd9bf3315ec4a7058d5L79' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 88800750</div><div id='project'> Project Name: mindee/doctr</div><div id='commit'> Commit Name: f5b6375507ace7ec9f5666cde4e3fb2b938373ed</div><div id='time'> Time: 2021-12-29</div><div id='author'> Author: 76527547+fg-mindee@users.noreply.github.com</div><div id='file'> File Name: doctr/transforms/functional/tensorflow.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: crop_detection(3)</div><div id='n_method'> N Method Name: crop_detection(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: doctr/transforms/functional/tensorflow.py</div><div id='n_file'> N File Name: doctr/transforms/functional/tensorflow.py</div><div id='m_start'> M Start Line: 94</div><div id='m_end'> M End Line: 94</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 98</div><BR>