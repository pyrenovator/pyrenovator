<html><h3>Pattern ID :33219
</h3><img src='95898583.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        :return: a sample, i.e. an input image and a target
        

        if <a id="change">index == 0</a>:

            img = torch.cat((
                self.frames[0, :, :, :],
                self.frames[0, :, :, :],
                self.frames[1, :, :, :]), dim=0)

        elif index == (self.__len__() - 1):

            img = torch.cat((
                <a id="change">self.frames[-2, :, :, :]</a>,
                self.frames[-1, :, :, :],
                self.frames[-1, :, :, :]), dim=0)
</code></pre><h3>After Change</h3><pre><code class='java'>

        Get adjacent frames. Pad borders with &quotsame&quot. Therefore we use the max(0, ix-1) and min(lastix, index+1).
        img = torch.cat((
            self.frames[<a id="change">max(0</a>, index - 1<a id="change">)</a>, :, :, :],
            self.frames[index, :, :, :],
            self.frames[min(self.__len__() - 1, index + 1), :, :, :]), dim=0)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/turagalab/decode/commit/a562faf6bd644c73162bb580e70bb738e7a7a2e6#diff-ada64902b98e0ef5b5ac72d023e6b46f4921556f320a298897923a817b5eb9d2L57' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 95898583</div><div id='project'> Project Name: turagalab/decode</div><div id='commit'> Commit Name: a562faf6bd644c73162bb580e70bb738e7a7a2e6</div><div id='time'> Time: 2019-02-20</div><div id='author'> Author: gitdev@LRM.photo</div><div id='file'> File Name: deepsmlm/neuralfitter/dataset.py</div><div id='m_class'> M Class Name: SMLMDataset</div><div id='n_method'> N Class Name: SMLMDataset</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: deepsmlm/neuralfitter/dataset.py</div><div id='n_file'> N File Name: deepsmlm/neuralfitter/dataset.py</div><div id='m_start'> M Start Line: 57</div><div id='m_end'> M End Line: 78</div><div id='n_start'> N Start Line: 58</div><div id='n_end'> N End Line: 61</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        :return: a sample, i.e. an input image and a target
        

        if <a id="change">index == 0</a>:

            img = torch.cat((
                <a id="change">self.frames[0, :, :, :]</a>,
                self.frames[0, :, :, :],
                self.frames[1, :, :, :]), dim=0)
</code></pre><h3>After Change</h3><pre><code class='java'>
        if self.multi_frame_output:
            Get adjacent frames. Pad borders with &quotsame&quot. Therefore we use the max(0, ix-1) and min(lastix, index+1).
            img = torch.cat((
                self.frames[<a id="change">max(0</a>, index - 1<a id="change">)</a>, :, :, :],
                self.frames[index, :, :, :],
                self.frames[min(self.__len__() - 1, index + 1), :, :, :]), dim=0)
        else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/turagalab/decode/commit/defa569ae04e129cadab2011848376f7682ccd48#diff-ada64902b98e0ef5b5ac72d023e6b46f4921556f320a298897923a817b5eb9d2L92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 95898581</div><div id='project'> Project Name: turagalab/decode</div><div id='commit'> Commit Name: defa569ae04e129cadab2011848376f7682ccd48</div><div id='time'> Time: 2019-03-01</div><div id='author'> Author: gitdev@LRM.photo</div><div id='file'> File Name: deepsmlm/neuralfitter/dataset.py</div><div id='m_class'> M Class Name: UnsupervisedDataset</div><div id='n_method'> N Class Name: UnsupervisedDataset</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: deepsmlm/neuralfitter/dataset.py</div><div id='n_file'> N File Name: deepsmlm/neuralfitter/dataset.py</div><div id='m_start'> M Start Line: 100</div><div id='m_end'> M End Line: 121</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 152</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        assert phase in [&quotGmain&quot, &quotGreg&quot, &quotGboth&quot, &quotDmain&quot, &quotDreg&quot, &quotDboth&quot]
        do_Gmain = (phase in [&quotGmain&quot, &quotGboth&quot])
        do_Dmain = (phase in [&quotDmain&quot, &quotDboth&quot])
        do_Gpl   = <a id="change">(phase in [&quotGreg&quot, &quotGboth&quot])</a> and (self.pl_weight != 0)
        do_Dr1   = (phase in [&quotDreg&quot, &quotDboth&quot]) and (self.r1_gamma != 0)

        loss_numpy = {}

        &#47&#47 Gmain: Maximize logits for generated images.
        if do_Gmain:
            gen_img, _gen_ws = self.run_G(gen_z, gen_c, sync=(sync and not do_Gpl)) &#47&#47 May get synced by Gpl.
            &#47&#47 d_gen_ws_dgen_z = torch.autograd.grad(outputs=[_gen_ws.sum()], inputs=[gen_z], create_graph=True, only_inputs=True)[0]
            &#47&#47 aaaaaaaaaa0 = dic2[phase + &quotd_gen_ws_dgen_z&quot]
            &#47&#47 aaaaaaaaaa1 = d_gen_ws_dgen_z.cpu().detach().numpy()
            &#47&#47 ddd = np.mean((dic2[phase + &quotd_gen_ws_dgen_z&quot] - d_gen_ws_dgen_z.cpu().detach().numpy()) ** 2)
            &#47&#47 print(&quotddd=%.6f&quot % ddd)
            &#47&#47 aaaaaaaaa1 = dic2[phase + &quotgen_img&quot]
            &#47&#47 aaaaaaaaa2 = gen_img.cpu().detach().numpy()
            &#47&#47 ddd = np.mean((dic2[phase + &quotgen_img&quot] - gen_img.cpu().detach().numpy()) ** 2)
            &#47&#47 print(&quotddd=%.6f&quot % ddd)
            &#47&#47 ddd = np.mean((dic2[phase + &quot_gen_ws&quot] - _gen_ws.cpu().detach().numpy()) ** 2)
            &#47&#47 print(&quotddd=%.6f&quot % ddd)

            gen_logits = self.run_D(gen_img, gen_c, sync=False)
            &#47&#47 ddd = np.mean((dic2[phase + &quotgen_logits&quot] - gen_logits.cpu().detach().numpy()) ** 2)
            &#47&#47 print(&quotddd=%.6f&quot % ddd)

            loss_Gmain = torch.nn.functional.softplus(-gen_logits)  &#47&#47 -log(sigmoid(gen_logits))
            loss_Gmain = loss_Gmain.mean()
            loss_numpy[&quotloss_Gmain&quot] = loss_Gmain.cpu().detach().numpy()

            loss_G = loss_Gmain
            loss_G = loss_G * float(gain)
            loss_G.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。

        &#47&#47 Gpl: Apply path length regularization.
        if do_Gpl:
            &#47&#47 print(&quot----------------- do_Gpl -----------------&quot)
            batch_size = gen_z.shape[0] // self.pl_batch_shrink
            batch_size = max(batch_size, 1)
            &#47&#47 with misc.ddp_sync(self.G_flownet, sync):
            &#47&#47     flow = self.G_flownet(torch.cat((cloth[:batch_size], aff_pose[:batch_size]), dim=1))
            &#47&#47 warp_cloth = F.grid_sample(cloth[:batch_size, :3, :, :], flow)

            gen_c_ = None
            if gen_c is not None:
                gen_c_ = gen_c[:batch_size]

            gen_img, gen_ws = self.run_G(gen_z[:batch_size], gen_c_, sync=sync)
            &#47&#47 ddd = np.mean((dic2[phase + &quotgen_img&quot] - gen_img.cpu().detach().numpy()) ** 2)
            &#47&#47 print(&quotddd=%.6f&quot % ddd)
            &#47&#47 ddd = np.mean((dic2[phase + &quotgen_ws&quot] - gen_ws.cpu().detach().numpy()) ** 2)
            &#47&#47 print(&quotddd=%.6f&quot % ddd)
            pl_noise = torch.randn_like(gen_img) / np.sqrt(gen_img.shape[2] * gen_img.shape[3])
            &#47&#47 pl_noise = torch.ones_like(gen_img) / np.sqrt(gen_img.shape[2] * gen_img.shape[3])
            pl_grads = torch.autograd.grad(outputs=[(gen_img * pl_noise).sum()], inputs=[gen_ws], create_graph=True, only_inputs=True)[0]

            pl_lengths = pl_grads.square().sum(2).mean(1).sqrt()
            &#47&#47 ddd = np.mean((dic2[phase + &quotpl_grads&quot] - pl_grads.cpu().detach().numpy()) ** 2)
            &#47&#47 print(&quotddd=%.6f&quot % ddd)
            &#47&#47 ddd = np.mean((dic2[phase + &quotpl_lengths&quot] - pl_lengths.cpu().detach().numpy()) ** 2)
            &#47&#47 print(&quotddd=%.6f&quot % ddd)
            if self.pl_mean is None:
                self.pl_mean = torch.zeros([1, ], dtype=torch.float32, device=pl_lengths.device)
            pl_mean = self.pl_mean.lerp(pl_lengths.mean(), self.pl_decay)
            self.pl_mean.copy_(pl_mean.detach())

            pl_penalty = (pl_lengths - pl_mean).square()
            loss_Gpl = pl_penalty * self.pl_weight

            loss_Gpl = (<a id="change">gen_img[:, 0, 0, 0]</a> * 0 + loss_Gpl).mean() * float(gain)
            loss_numpy[&quotloss_Gpl&quot] = loss_Gpl.cpu().detach().numpy()
            loss_Gpl.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。
</code></pre><h3>After Change</h3><pre><code class='java'>
            phase = {&quotGreg&quot: &quotnone&quot, &quotGboth&quot: &quotGmain&quot}.get(phase, phase)
        if self.r1_gamma == 0:
            phase = {&quotDreg&quot: &quotnone&quot, &quotDboth&quot: &quotDmain&quot}.get(phase, phase)
        blur_sigma = <a id="change">max(</a>1 - cur_nimg / (self.blur_fade_kimg * 1e3), <a id="change">0</a><a id="change">)</a> * self.blur_init_sigma if self.blur_fade_kimg &gt; 0 else 0

        loss_numpy = {}
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/miemie2013/miemiegan/commit/c5e7ecffe23cf2fc2613ee06ec8fd94c8d7230ac#diff-4a5f5fcbb93c9b5e973214dc967c292a612eba7ff7a63f6841cac2829b7b8afdL138' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 95898590</div><div id='project'> Project Name: miemie2013/miemiegan</div><div id='commit'> Commit Name: c5e7ecffe23cf2fc2613ee06ec8fd94c8d7230ac</div><div id='time'> Time: 2022-03-24</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmgan/models/architectures/styleganv3_model.py</div><div id='m_class'> M Class Name: StyleGANv3Model</div><div id='n_method'> N Class Name: StyleGANv3Model</div><div id='m_method'> M Method Name: accumulate_gradients(9)</div><div id='n_method'> N Method Name: accumulate_gradients(9)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: mmgan/models/architectures/styleganv3_model.py</div><div id='n_file'> N File Name: mmgan/models/architectures/styleganv3_model.py</div><div id='m_start'> M Start Line: 140</div><div id='m_end'> M End Line: 251</div><div id='n_start'> N Start Line: 140</div><div id='n_end'> N End Line: 251</div><BR>