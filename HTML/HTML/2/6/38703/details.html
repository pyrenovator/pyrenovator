<html><h3>Pattern ID :38703
</h3><img src='110665368.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def calc_metrics(self, model_id, model_name, end_point_id, inference_output_url):
        total_latency, avg_latency, total_request_num, current_qps, timestamp = 0, 0, 0, 0, 0
        metrics_item = <a id="change">FedMLModelCache</a>.get_instance().get_latest_monitor_metrics(end_point_id)
        if metrics_item is not None:
            total_latency, avg_latency, total_request_num, current_qps, avg_qps, timestamp = \
                <a id="change">FedMLModelCache.get_instance()</a>.get_metrics_item_info(metrics_item)
        cost_time = (time.time_ns() - self.start_time) / self.ns_per_ms
        total_latency += cost_time
        total_request_num += 1
        current_qps = 1 / (cost_time / self.ms_per_sec)
        current_qps = format(current_qps, &quot.0f&quot)
        avg_qps = total_request_num / (total_latency / self.ms_per_sec)
        avg_qps = format(avg_qps, &quot.0f&quot)
        avg_latency = format(total_latency / total_request_num / self.ms_per_sec, &quot.6f&quot)

        <a id="change">FedMLModelCache.get_instance()</a>.set_monitor_metrics(end_point_id, total_latency, avg_latency,
                                                           total_request_num, current_qps,
                                                           avg_qps, int(format(time.time(), &quot.0f&quot)))
</code></pre><h3>After Change</h3><pre><code class='java'>

    def calc_metrics(self, model_id, model_name, end_point_id, inference_output_url):
        total_latency, avg_latency, total_request_num, current_qps, timestamp = 0, 0, 0, 0, 0
        metrics_item = <a id="change">FedMLModelCache.get_instance(</a>self.redis_addr, self.redis_port<a id="change">)</a>.get_latest_monitor_metrics(
                                                                                    end_point_id)
        if metrics_item is not None:
            total_latency, avg_latency, total_request_num, current_qps, avg_qps, timestamp = \
                FedMLModelCache.get_instance(self.redis_addr, self.redis_port).get_metrics_item_info(metrics_item)
        cost_time = (time.time_ns() - self.start_time) / self.ns_per_ms
        total_latency += cost_time
        total_request_num += 1
        current_qps = 1 / (cost_time / self.ms_per_sec)
        current_qps = format(current_qps, &quot.0f&quot)
        avg_qps = total_request_num / (total_latency / self.ms_per_sec)
        avg_qps = format(avg_qps, &quot.0f&quot)
        avg_latency = format(total_latency / total_request_num / self.ms_per_sec, &quot.6f&quot)

        timestamp = int(format(time.time(), &quot.0f&quot))
        <a id="change">FedMLModelCache.get_instance(</a>self.redis_addr, self.redis_port<a id="change">)</a>.set_monitor_metrics(end_point_id, total_latency,
                                                                                           avg_latency,
                                                                                           total_request_num,
                                                                                           current_qps, avg_qps,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/fedml-ai/fedml/commit/1410aa43fc65d9988f660925e8c44e747dc91e99#diff-9ec8fbd65dc14859a2bd23f9b75eccbeaa95f9538d5081ecd7527078acc941d7L28' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110665368</div><div id='project'> Project Name: fedml-ai/fedml</div><div id='commit'> Commit Name: 1410aa43fc65d9988f660925e8c44e747dc91e99</div><div id='time'> Time: 2023-01-05</div><div id='author'> Author: alex.gpt.llm@gmail.com</div><div id='file'> File Name: python/fedml/cli/model_deployment/device_model_monitor.py</div><div id='m_class'> M Class Name: FedMLModelMetrics</div><div id='n_method'> N Class Name: FedMLModelMetrics</div><div id='m_method'> M Method Name: calc_metrics(5)</div><div id='n_method'> N Method Name: calc_metrics(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: python/fedml/cli/model_deployment/device_model_monitor.py</div><div id='n_file'> N File Name: python/fedml/cli/model_deployment/device_model_monitor.py</div><div id='m_start'> M Start Line: 28</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 49</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def calc_metrics(self, model_id, model_name, end_point_id, inference_output_url):
        total_latency, avg_latency, total_request_num, current_qps, timestamp = 0, 0, 0, 0, 0
        metrics_item = <a id="change">FedMLModelCache.get_instance()</a>.get_latest_monitor_metrics(end_point_id)
        if metrics_item is not None:
            total_latency, avg_latency, total_request_num, current_qps, avg_qps, timestamp = \
                FedMLModelCache.get_instance().get_metrics_item_info(metrics_item)
        cost_time = (time.time_ns() - self.start_time) / self.ns_per_ms
        total_latency += cost_time
        total_request_num += 1
        current_qps = 1 / (cost_time / self.ms_per_sec)
        current_qps = format(current_qps, &quot.0f&quot)
        avg_qps = total_request_num / (total_latency / self.ms_per_sec)
        avg_qps = format(avg_qps, &quot.0f&quot)
        avg_latency = format(total_latency / total_request_num / self.ms_per_sec, &quot.6f&quot)

        <a id="change">FedMLModelCache.get_instance()</a>.set_monitor_metrics(end_point_id, total_latency, avg_latency,
                                                           total_request_num, current_qps,
                                                           avg_qps, int(format(time.time(), &quot.0f&quot)))
</code></pre><h3>After Change</h3><pre><code class='java'>
                                                                                    end_point_id)
        if metrics_item is not None:
            total_latency, avg_latency, total_request_num, current_qps, avg_qps, timestamp = \
                <a id="change">FedMLModelCache.get_instance(</a>self.redis_addr, self.redis_port<a id="change">)</a>.get_metrics_item_info(metrics_item)
        cost_time = (time.time_ns() - self.start_time) / self.ns_per_ms
        total_latency += cost_time
        total_request_num += 1
        current_qps = 1 / (cost_time / self.ms_per_sec)
        current_qps = format(current_qps, &quot.0f&quot)
        avg_qps = total_request_num / (total_latency / self.ms_per_sec)
        avg_qps = format(avg_qps, &quot.0f&quot)
        avg_latency = format(total_latency / total_request_num / self.ms_per_sec, &quot.6f&quot)

        timestamp = int(format(time.time(), &quot.0f&quot))
        <a id="change">FedMLModelCache.get_instance(</a>self.redis_addr, self.redis_port<a id="change">)</a>.set_monitor_metrics(end_point_id, total_latency,
                                                                                           avg_latency,
                                                                                           total_request_num,
                                                                                           current_qps, avg_qps,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/fedml-ai/fedml/commit/1410aa43fc65d9988f660925e8c44e747dc91e99#diff-9ec8fbd65dc14859a2bd23f9b75eccbeaa95f9538d5081ecd7527078acc941d7L26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110665369</div><div id='project'> Project Name: fedml-ai/fedml</div><div id='commit'> Commit Name: 1410aa43fc65d9988f660925e8c44e747dc91e99</div><div id='time'> Time: 2023-01-05</div><div id='author'> Author: alex.gpt.llm@gmail.com</div><div id='file'> File Name: python/fedml/cli/model_deployment/device_model_monitor.py</div><div id='m_class'> M Class Name: FedMLModelMetrics</div><div id='n_method'> N Class Name: FedMLModelMetrics</div><div id='m_method'> M Method Name: calc_metrics(5)</div><div id='n_method'> N Method Name: calc_metrics(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: python/fedml/cli/model_deployment/device_model_monitor.py</div><div id='n_file'> N File Name: python/fedml/cli/model_deployment/device_model_monitor.py</div><div id='m_start'> M Start Line: 28</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 49</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.monitor_mqtt_mgr.loop_stop()

    def send_monitoring_metrics(self, index):
        metrics_item, inc_index = <a id="change">FedMLModelCache.get_instance()</a>.get_monitor_metrics_item(self.current_end_point_id,
                                                                                          index)
        if metrics_item is None:
            return index
        total_latency, avg_latency, total_request_num, current_qps, avg_qps, timestamp = \
            <a id="change">FedMLModelCache.get_instance()</a>.get_metrics_item_info(metrics_item)
        deployment_monitoring_topic_prefix = "/model_ops/model_device/return_inference_monitoring"
        deployment_monitoring_topic = "{}/{}".format(deployment_monitoring_topic_prefix, self.current_end_point_id)
        deployment_monitoring_payload = {"model_name": self.current_model_name,</code></pre><h3>After Change</h3><pre><code class='java'>
        self.monitor_mqtt_mgr.loop_stop()

    def send_monitoring_metrics(self, index):
        metrics_item, inc_index = <a id="change">FedMLModelCache.get_instance(</a>self.redis_addr,
                                                               self.redis_port<a id="change">)</a>.get_monitor_metrics_item(
                                                               self.current_end_point_id, index)
        if metrics_item is None:
            return index
        total_latency, avg_latency, total_request_num, current_qps, avg_qps, timestamp = \
            <a id="change">FedMLModelCache.get_instance(</a>self.redis_addr, self.redis_port<a id="change">)</a>.get_metrics_item_info(metrics_item)
        deployment_monitoring_topic_prefix = "/model_ops/model_device/return_inference_monitoring"
        deployment_monitoring_topic = "{}/{}".format(deployment_monitoring_topic_prefix, self.current_end_point_id)
        deployment_monitoring_payload = {"model_name": self.current_model_name,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/fedml-ai/fedml/commit/1410aa43fc65d9988f660925e8c44e747dc91e99#diff-9ec8fbd65dc14859a2bd23f9b75eccbeaa95f9538d5081ecd7527078acc941d7L72' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110665371</div><div id='project'> Project Name: fedml-ai/fedml</div><div id='commit'> Commit Name: 1410aa43fc65d9988f660925e8c44e747dc91e99</div><div id='time'> Time: 2023-01-05</div><div id='author'> Author: alex.gpt.llm@gmail.com</div><div id='file'> File Name: python/fedml/cli/model_deployment/device_model_monitor.py</div><div id='m_class'> M Class Name: FedMLModelMetrics</div><div id='n_method'> N Class Name: FedMLModelMetrics</div><div id='m_method'> M Method Name: send_monitoring_metrics(2)</div><div id='n_method'> N Method Name: send_monitoring_metrics(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: python/fedml/cli/model_deployment/device_model_monitor.py</div><div id='n_file'> N File Name: python/fedml/cli/model_deployment/device_model_monitor.py</div><div id='m_start'> M Start Line: 73</div><div id='m_end'> M End Line: 78</div><div id='n_start'> N Start Line: 79</div><div id='n_end'> N End Line: 85</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def calc_metrics(self, model_id, model_name, end_point_id, inference_output_url):
        total_latency, avg_latency, total_request_num, current_qps, timestamp = 0, 0, 0, 0, 0
        metrics_item = <a id="change">FedMLModelCache.get_instance()</a>.get_latest_monitor_metrics(end_point_id)
        if metrics_item is not None:
            total_latency, avg_latency, total_request_num, current_qps, avg_qps, timestamp = \
                FedMLModelCache.get_instance().get_metrics_item_info(metrics_item)
        cost_time = (time.time_ns() - self.start_time) / self.ns_per_ms
        total_latency += cost_time
        total_request_num += 1
        current_qps = 1 / (cost_time / self.ms_per_sec)
        current_qps = format(current_qps, &quot.0f&quot)
        avg_qps = total_request_num / (total_latency / self.ms_per_sec)
        avg_qps = format(avg_qps, &quot.0f&quot)
        avg_latency = format(total_latency / total_request_num / self.ms_per_sec, &quot.6f&quot)

        <a id="change">FedMLModelCache.get_instance()</a>.set_monitor_metrics(end_point_id, total_latency, avg_latency,
                                                           total_request_num, current_qps,
                                                           avg_qps, int(format(time.time(), &quot.0f&quot)))
</code></pre><h3>After Change</h3><pre><code class='java'>

    def calc_metrics(self, model_id, model_name, end_point_id, inference_output_url):
        total_latency, avg_latency, total_request_num, current_qps, timestamp = 0, 0, 0, 0, 0
        metrics_item = <a id="change">FedMLModelCache.get_instance(</a>self.redis_addr, self.redis_port<a id="change">)</a>.get_latest_monitor_metrics(
                                                                                    end_point_id)
        if metrics_item is not None:
            total_latency, avg_latency, total_request_num, current_qps, avg_qps, timestamp = \
                FedMLModelCache.get_instance(self.redis_addr, self.redis_port).get_metrics_item_info(metrics_item)
        cost_time = (time.time_ns() - self.start_time) / self.ns_per_ms
        total_latency += cost_time
        total_request_num += 1
        current_qps = 1 / (cost_time / self.ms_per_sec)
        current_qps = format(current_qps, &quot.0f&quot)
        avg_qps = total_request_num / (total_latency / self.ms_per_sec)
        avg_qps = format(avg_qps, &quot.0f&quot)
        avg_latency = format(total_latency / total_request_num / self.ms_per_sec, &quot.6f&quot)

        timestamp = int(format(time.time(), &quot.0f&quot))
        <a id="change">FedMLModelCache.get_instance(</a>self.redis_addr, self.redis_port<a id="change">)</a>.set_monitor_metrics(end_point_id, total_latency,
                                                                                           avg_latency,
                                                                                           total_request_num,
                                                                                           current_qps, avg_qps,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/fedml-ai/fedml/commit/65a5c793ca24b5793907564b085a537564a7bf30#diff-9ec8fbd65dc14859a2bd23f9b75eccbeaa95f9538d5081ecd7527078acc941d7L26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110665355</div><div id='project'> Project Name: fedml-ai/fedml</div><div id='commit'> Commit Name: 65a5c793ca24b5793907564b085a537564a7bf30</div><div id='time'> Time: 2023-01-05</div><div id='author'> Author: alexliang.kh@gmail.com</div><div id='file'> File Name: python/fedml/cli/model_deployment/device_model_monitor.py</div><div id='m_class'> M Class Name: FedMLModelMetrics</div><div id='n_method'> N Class Name: FedMLModelMetrics</div><div id='m_method'> M Method Name: calc_metrics(5)</div><div id='n_method'> N Method Name: calc_metrics(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: python/fedml/cli/model_deployment/device_model_monitor.py</div><div id='n_file'> N File Name: python/fedml/cli/model_deployment/device_model_monitor.py</div><div id='m_start'> M Start Line: 28</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 49</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.monitor_mqtt_mgr.loop_stop()

    def send_monitoring_metrics(self, index):
        metrics_item, inc_index = <a id="change">FedMLModelCache.get_instance()</a>.get_monitor_metrics_item(self.current_end_point_id,
                                                                                          index)
        if metrics_item is None:
            return index
        total_latency, avg_latency, total_request_num, current_qps, avg_qps, timestamp = \
            <a id="change">FedMLModelCache.get_instance()</a>.get_metrics_item_info(metrics_item)
        deployment_monitoring_topic_prefix = "/model_ops/model_device/return_inference_monitoring"
        deployment_monitoring_topic = "{}/{}".format(deployment_monitoring_topic_prefix, self.current_end_point_id)
        deployment_monitoring_payload = {"model_name": self.current_model_name,</code></pre><h3>After Change</h3><pre><code class='java'>
        self.monitor_mqtt_mgr.loop_stop()

    def send_monitoring_metrics(self, index):
        metrics_item, inc_index = <a id="change">FedMLModelCache.get_instance(</a>self.redis_addr,
                                                               self.redis_port<a id="change">)</a>.get_monitor_metrics_item(
                                                               self.current_end_point_id, index)
        if metrics_item is None:
            return index
        total_latency, avg_latency, total_request_num, current_qps, avg_qps, timestamp = \
            <a id="change">FedMLModelCache.get_instance(</a>self.redis_addr, self.redis_port<a id="change">)</a>.get_metrics_item_info(metrics_item)
        deployment_monitoring_topic_prefix = "/model_ops/model_device/return_inference_monitoring"
        deployment_monitoring_topic = "{}/{}".format(deployment_monitoring_topic_prefix, self.current_end_point_id)
        deployment_monitoring_payload = {"model_name": self.current_model_name,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/fedml-ai/fedml/commit/65a5c793ca24b5793907564b085a537564a7bf30#diff-9ec8fbd65dc14859a2bd23f9b75eccbeaa95f9538d5081ecd7527078acc941d7L72' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110665379</div><div id='project'> Project Name: fedml-ai/fedml</div><div id='commit'> Commit Name: 65a5c793ca24b5793907564b085a537564a7bf30</div><div id='time'> Time: 2023-01-05</div><div id='author'> Author: alexliang.kh@gmail.com</div><div id='file'> File Name: python/fedml/cli/model_deployment/device_model_monitor.py</div><div id='m_class'> M Class Name: FedMLModelMetrics</div><div id='n_method'> N Class Name: FedMLModelMetrics</div><div id='m_method'> M Method Name: send_monitoring_metrics(2)</div><div id='n_method'> N Method Name: send_monitoring_metrics(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: python/fedml/cli/model_deployment/device_model_monitor.py</div><div id='n_file'> N File Name: python/fedml/cli/model_deployment/device_model_monitor.py</div><div id='m_start'> M Start Line: 73</div><div id='m_end'> M End Line: 78</div><div id='n_start'> N Start Line: 79</div><div id='n_end'> N End Line: 85</div><BR>