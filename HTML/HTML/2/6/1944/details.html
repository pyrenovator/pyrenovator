<html><h3>Pattern ID :1944
</h3><img src='8643395.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            generator.zero_grad()

            &#47&#47 Train fake sample with generator.
            sr<a id="change"> = </a>generator(lr)
            sr_output = discriminator(sr)
            pixel_loss<a id="change">       = </a>pixel_weight       * pixel_criterion(sr, <a id="change">hr.detach()</a>)
            perceptual_loss  = perceptual_weight  * perceptual_criterion(sr, hr.detach())
            adversarial_loss = adversarial_weight * adversarial_criterion(sr_output, real_label)
            d_sr2 = sr_output.mean().item()</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 (1) Update D network.
            &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
            &#47&#47 Fix the generator and update the discriminator.
            <a id="change">for </a>parameters in discriminator.parameters()<a id="change">:
                </a>parameters.requires_grad<a id="change"> = </a>True
            for parameters in generator.parameters():
                parameters.requires_grad = False
            &#47&#47 Set the discriminator gradient to 0.</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lornatang/srgan-pytorch/commit/a5cdcb9952756e19bdb383cf541d392ed6b08236#diff-ed183d67207df065a11e1289f19d34cc2abbc5448dea952683cfe9728c342b95L44' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8643395</div><div id='project'> Project Name: lornatang/srgan-pytorch</div><div id='commit'> Commit Name: a5cdcb9952756e19bdb383cf541d392ed6b08236</div><div id='time'> Time: 2021-08-12</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train.py</div><div id='n_file'> N File Name: train.py</div><div id='m_start'> M Start Line: 44</div><div id='m_end'> M End Line: 121</div><div id='n_start'> N Start Line: 44</div><div id='n_end'> N End Line: 143</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    default_psnrs = 10 * torch.log10(factor**2 / mse_per_example)
    &#47&#47 Align by homography:
    breakpoint()
    registrator<a id="change"> = </a>ImageRegistrator(&quotsimilarity&quot).to(ref_batch.device)
    homography = registrator.register(ref_batch.detach(), <a id="change">img_batch.detach()</a>).to(ref_batch.device)
    breakpoint()
    warped_imgs = homography_warp(img_batch, homography, ref_batch.shape[-2:])
    &#47&#47 Compute new PSNR:
    mse_per_example = ((warped_imgs.detach() - ref_batch)**2).view(B, -1).mean(dim=1)
    registered_psnrs<a id="change"> = </a>10 * torch.log10(factor**2 / mse_per_example)

    &#47&#47 Return best of default and warped PSNR:
    return torch.stack([default_psnrs, registered_psnrs]).max(dim=0)[0].mean()</code></pre><h3>After Change</h3><pre><code class='java'>
    default_psnrs = []
    registered_psnrs = []
    &#47&#47 If only this was parallelized, todo ...
    <a id="change">for </a>img, <a id="change">ref</a> in zip(img_batch.detach(), ref_batch.detach())<a id="change">:
        </a>img, ref = img[None, ...], ref[None, ...]
        mse = ((img - ref)**2).mean()
        default_psnrs<a id="change"> += </a>[10 * torch.log10(factor**2 / mse)]
        &#47&#47 Align by homography:
        registrator = ImageRegistrator(&quotsimilarity&quot, num_iterations=2500)
        registrator.warper = partial(HomographyWarper,  padding_mode=&quotreflection&quot)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jonasgeiping/breaching/commit/6b4ffc1d9faebf9b2f809f69b0ed4a9af670db47#diff-ebc0bcd56264211e0b77afc333a7225f3ad39387d291ae274dfd47a4b9044823L77' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8643778</div><div id='project'> Project Name: jonasgeiping/breaching</div><div id='commit'> Commit Name: 6b4ffc1d9faebf9b2f809f69b0ed4a9af670db47</div><div id='time'> Time: 2021-11-29</div><div id='author'> Author: jonas.geiping@googlemail.com</div><div id='file'> File Name: breaching/analysis/metrics.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _registered_psnr_compute_kornia(3)</div><div id='n_method'> N Method Name: _registered_psnr_compute_kornia(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: breaching/analysis/metrics.py</div><div id='n_file'> N File Name: breaching/analysis/metrics.py</div><div id='m_start'> M Start Line: 80</div><div id='m_end'> M End Line: 94</div><div id='n_start'> N Start Line: 81</div><div id='n_end'> N End Line: 99</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            generator.zero_grad()

            &#47&#47 Train fake sample with generator.
            sr<a id="change"> = </a>generator(lr)
            sr_output = discriminator(sr)
            pixel_loss       = pixel_weight       * pixel_criterion(sr, <a id="change">hr.detach()</a>)
            perceptual_loss  = perceptual_weight  * perceptual_criterion(sr, hr.detach())
            adversarial_loss = adversarial_weight * adversarial_criterion(sr_output, real_label)
            d_sr2 = sr_output.mean().item()
            g_loss<a id="change"> = </a>pixel_loss + perceptual_loss + adversarial_loss
            g_loss.backward()
            g_optimizer.step()
            &#47&#47 Print Loss.</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 (2) Update G network.
            &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
            &#47&#47 Fix the discriminator and update the generator.
            <a id="change">for parameters</a> in discriminator.parameters()<a id="change">:
                </a>parameters.requires_grad<a id="change"> = </a>False
            for parameters in generator.parameters():
                parameters.requires_grad = True
            &#47&#47 Set the generator gradient to 0.</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/srgan-pytorch/commit/a5cdcb9952756e19bdb383cf541d392ed6b08236#diff-ed183d67207df065a11e1289f19d34cc2abbc5448dea952683cfe9728c342b95L25' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8643666</div><div id='project'> Project Name: lornatang/srgan-pytorch</div><div id='commit'> Commit Name: a5cdcb9952756e19bdb383cf541d392ed6b08236</div><div id='time'> Time: 2021-08-12</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train.py</div><div id='n_file'> N File Name: train.py</div><div id='m_start'> M Start Line: 44</div><div id='m_end'> M End Line: 121</div><div id='n_start'> N Start Line: 44</div><div id='n_end'> N End Line: 143</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        original_predictions = self._original_predictions

        &#47&#47 handle only first image (batch=1)
        predictions_in_xyxy_format<a id="change"> = </a><a id="change">original_predictions.xyxy[0].cpu().detach()</a>.numpy()

        object_prediction_list = []
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 compatilibty for sahi v0.8.15
        if isinstance(shift_amount_list[0], int):
            shift_amount_list<a id="change"> = </a>[shift_amount_list]
        if full_shape_list is not None and isinstance(full_shape_list[0], int):
            full_shape_list = [full_shape_list]

        &#47&#47 handle all predictions
        object_prediction_list_per_image = []
        <a id="change">for </a>image_ind, <a id="change">image_predictions_in_xyxy_format</a> in enumerate(original_predictions.xyxy)<a id="change">:
            </a>shift_amount<a id="change"> = </a>shift_amount_list[image_ind]
            full_shape = None if full_shape_list is None else full_shape_list[image_ind]
            object_prediction_list = []
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/obss/sahi/commit/248cd2df7d3450eea48c0f03b75d1b7d0111dcf4#diff-34fb6fd3619110ee74df2d3aafa1b22f7cf122b36a43ec080f4dde16059022a3L455' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8643958</div><div id='project'> Project Name: obss/sahi</div><div id='commit'> Commit Name: 248cd2df7d3450eea48c0f03b75d1b7d0111dcf4</div><div id='time'> Time: 2021-12-19</div><div id='author'> Author: 34196005+fcakyon@users.noreply.github.com</div><div id='file'> File Name: sahi/model.py</div><div id='m_class'> M Class Name: Yolov5DetectionModel</div><div id='n_method'> N Class Name: Yolov5DetectionModel</div><div id='m_method'> M Method Name: _create_object_prediction_list_from_original_predictions(3)</div><div id='n_method'> N Method Name: _create_object_prediction_list_from_original_predictions(3)</div><div id='m_parent_class'> M Parent Class: DetectionModel</div><div id='n_parent_class'> N Parent Class: DetectionModel</div><div id='m_file'> M File Name: sahi/model.py</div><div id='n_file'> N File Name: sahi/model.py</div><div id='m_start'> M Start Line: 470</div><div id='m_end'> M End Line: 509</div><div id='n_start'> N Start Line: 433</div><div id='n_end'> N End Line: 484</div><BR>