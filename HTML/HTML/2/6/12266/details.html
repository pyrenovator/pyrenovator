<html><h3>Pattern ID :12266
</h3><img src='41613498.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            grad_scaler.unscale_(optimizer)
            if step_counter &gt; postnet_start_steps:
                grad_scaler_postflow.scale(glow_loss).backward()
                <a id="change">grad_scaler_postflow.unscale_(optimizer_postflow</a><a id="change">)</a>
            torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0, error_if_nonfinite=False)

            grad_scaler.step(optimizer)
            grad_scaler.update()

            if step_counter &gt; postnet_start_steps:
                <a id="change">grad_scaler_postflow.step(optimizer_postflow</a><a id="change">)</a>
                grad_scaler_postflow.update()

            scheduler.step()
            if step_counter &gt; postnet_start_steps:</code></pre><h3>After Change</h3><pre><code class='java'>
            torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0, error_if_nonfinite=False)

            grad_scaler.step(optimizer)
            <a id="change">optimizer_postflow.step()</a>
            grad_scaler.update()

            scheduler.step()
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/f602045d362a5da3119066ffc47b09771ed11b7e#diff-241ea0a4da614fa4b0dbd748ea10aae1c34265d57f46001c62ec2994245ee0f7L88' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41613498</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: f602045d362a5da3119066ffc47b09771ed11b7e</div><div id='time'> Time: 2023-02-05</div><div id='author'> Author: lux.florian@gmail.com</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/PortaSpeech/portaspeech_train_loop.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train_loop(16)</div><div id='n_method'> N Method Name: train_loop(16)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/PortaSpeech/portaspeech_train_loop.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/PortaSpeech/portaspeech_train_loop.py</div><div id='m_start'> M Start Line: 88</div><div id='m_end'> M End Line: 232</div><div id='n_start'> N Start Line: 88</div><div id='n_end'> N End Line: 219</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        index = unet_number - 1
        unet = self.decoder.unets[index]

        <a id="change">optimizer</a> = getattr(self, f&quotoptim{index}&quot)
        <a id="change">scaler</a> = getattr(self, f&quotscaler{index}&quot)

        if exists(self.max_grad_norm):
            <a id="change">scaler.unscale_(</a>optimizer<a id="change">)</a>
            nn.utils.clip_grad_norm_(unet.parameters(), self.max_grad_norm)

        <a id="change">scaler.step(</a>optimizer<a id="change">)</a>
        scaler.update()
        optimizer.zero_grad()

        if self.use_ema:</code></pre><h3>After Change</h3><pre><code class='java'>
        assert exists(unet_number) and 1 &lt;= unet_number &lt;= self.num_unets
        index = unet_number - 1

        <a id="change">optimizer</a> = getattr(self, f&quotoptim{index}&quot)

        if exists(self.max_grad_norm):
            self.accelerator.clip_grad_norm_(self.decoder.parameters(), self.max_grad_norm)  &#47&#47 Automatically unscales gradients
        <a id="change">optimizer.step()</a>
        optimizer.zero_grad()

        if self.use_ema:
            ema_unet = self.ema_unets[index]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/58892135d9bcf117921c885dda161c0b67452096#diff-617450527162fa367141dbf45e8b201673573479820af0ffc56ba93b7f70947fL692' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41613496</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: 58892135d9bcf117921c885dda161c0b67452096</div><div id='time'> Time: 2022-06-19</div><div id='author'> Author: aidan.dempster@gmail.com</div><div id='file'> File Name: dalle2_pytorch/trainer.py</div><div id='m_class'> M Class Name: DecoderTrainer</div><div id='n_method'> N Class Name: DecoderTrainer</div><div id='m_method'> M Method Name: update(2)</div><div id='n_method'> N Method Name: update(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dalle2_pytorch/trainer.py</div><div id='n_file'> N File Name: dalle2_pytorch/trainer.py</div><div id='m_start'> M Start Line: 697</div><div id='m_end'> M End Line: 708</div><div id='n_start'> N Start Line: 693</div><div id='n_end'> N End Line: 697</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                              collate_fn=collate_and_pad,
                              persistent_workers=True)
    step_counter = 0
    <a id="change">optimizer</a> = torch.optim.Adam(net.parameters(), lr=lr)
    scheduler = WarmupScheduler(optimizer, peak_lr=lr, warmup_steps=warmup_steps,
                                max_steps=phase_1_steps + phase_2_steps)
    <a id="change">grad_scaler</a> = GradScaler()
    epoch = 0
    if resume:
        path_to_checkpoint = get_most_recent_checkpoint(checkpoint_dir=save_directory)
    if path_to_checkpoint is not None:
        check_dict = torch.load(path_to_checkpoint, map_location=device)
        net.load_state_dict(check_dict["model"])
        if not fine_tune:
            optimizer.load_state_dict(check_dict["optimizer"])
            scheduler.load_state_dict(check_dict["scheduler"])
            step_counter = check_dict["step_counter"]
            grad_scaler.load_state_dict(check_dict["scaler"])
    start_time = time.time()
    while True:
        net.train()
        epoch += 1
        optimizer.zero_grad()
        train_losses_this_epoch = list()
        cycle_losses_this_epoch = list()
        l1_losses_total = list()
        duration_losses_discr_total = list()
        pitch_losses_discr_total = list()
        energy_losses_discr_total = list()
        duration_losses_adv_total = list()
        pitch_losses_adv_total = list()
        energy_losses_adv_total = list()
        glow_losses_total = list()
        for batch in tqdm(train_loader):
            train_loss = 0.0
            with autocast():
                if step_counter &lt;= phase_1_steps:
                    &#47&#47 ===============================================
                    &#47&#47 =        PHASE 1: no cycle objective          =
                    &#47&#47 ===============================================
                    style_embedding = style_embedding_function(batch_of_spectrograms=batch[2].to(device),
                                                               batch_of_spectrogram_lengths=batch[3].to(device))

                    for _ in range(100):
                        pitch_critic_loss, energy_critic_loss, duration_critic_loss = net.calculate_discriminator_loss(
                            text_tensors=batch[0].to(device),
                            text_lens=batch[1].to(device),
                            gold_durations=batch[4].to(device),
                            gold_pitch=batch[6].to(device),  &#47&#47 mind the switched order
                            gold_energy=batch[5].to(device),  &#47&#47 mind the switched order
                            utterance_embedding=style_embedding,
                            lang_ids=batch[8].to(device),
                        )
                        loss = pitch_critic_loss + energy_critic_loss + duration_critic_loss
                        if use_wandb:
                            wandb.log({
                                "pitch_critic_loss"   : pitch_critic_loss.item(),
                                "energy_critic_loss"  : energy_critic_loss.item(),
                                "duration_critic_loss": duration_critic_loss.item(),
                            })

                        optimizer.zero_grad()
                        grad_scaler.scale(loss).backward()
                        <a id="change">grad_scaler.unscale_(</a>optimizer<a id="change">)</a>
                        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0, error_if_nonfinite=False)
                        <a id="change">grad_scaler.step(</a>optimizer<a id="change">)</a>

                    l1_loss, duration_losses, pitch_losses, energy_losses, glow_loss, kl_loss = net(
                        text_tensors=batch[0].to(device),
                        text_lengths=batch[1].to(device),</code></pre><h3>After Change</h3><pre><code class='java'>
                              collate_fn=collate_and_pad,
                              persistent_workers=True)
    step_counter = 0
    <a id="change">optimizer</a> = torch.optim.Adam(net.parameters(), lr=lr)
    scheduler = WarmupScheduler(optimizer, peak_lr=lr, warmup_steps=warmup_steps,
                                max_steps=phase_1_steps + phase_2_steps)
    grad_scaler = GradScaler()
    epoch = 0
    if resume:
        path_to_checkpoint = get_most_recent_checkpoint(checkpoint_dir=save_directory)
    if path_to_checkpoint is not None:
        check_dict = torch.load(path_to_checkpoint, map_location=device)
        net.load_state_dict(check_dict["model"])
        if not fine_tune:
            optimizer.load_state_dict(check_dict["optimizer"])
            scheduler.load_state_dict(check_dict["scheduler"])
            step_counter = check_dict["step_counter"]
            grad_scaler.load_state_dict(check_dict["scaler"])
    start_time = time.time()
    while True:
        net.train()
        epoch += 1
        optimizer.zero_grad()
        train_losses_this_epoch = list()
        cycle_losses_this_epoch = list()
        l1_losses_total = list()
        duration_losses_discr_total = list()
        pitch_losses_discr_total = list()
        energy_losses_discr_total = list()
        duration_losses_adv_total = list()
        pitch_losses_adv_total = list()
        energy_losses_adv_total = list()
        glow_losses_total = list()
        for batch in tqdm(train_loader):
            style_embedding = style_embedding_function(batch_of_spectrograms=batch[2].to(device),
                                                       batch_of_spectrogram_lengths=batch[3].to(device))
            for _ in range(100):
                pitch_critic_loss, energy_critic_loss, duration_critic_loss = net.calculate_discriminator_loss(
                    text_tensors=batch[0].to(device),
                    text_lens=batch[1].to(device),
                    gold_durations=batch[4].to(device),
                    gold_pitch=batch[6].to(device),  &#47&#47 mind the switched order
                    gold_energy=batch[5].to(device),  &#47&#47 mind the switched order
                    utterance_embedding=style_embedding,
                    lang_ids=batch[8].to(device),
                )
                loss = pitch_critic_loss + energy_critic_loss + duration_critic_loss
                if use_wandb:
                    wandb.log({
                        "pitch_critic_loss"   : pitch_critic_loss.item(),
                        "energy_critic_loss"  : energy_critic_loss.item(),
                        "duration_critic_loss": duration_critic_loss.item(),
                    })
                optimizer.zero_grad()
                loss.backward()
                torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0, error_if_nonfinite=False)
                <a id="change">optimizer.step()</a>
            train_loss = 0.0
            with autocast():
                if step_counter &lt;= phase_1_steps:
                    &#47&#47 ===============================================</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/96bb0b4beccd98dc9c762b915a8508508d645b1a#diff-558f242c6346687e14b6867d8bf52c1487e81ba3710f925457ba3a3aef85dbb0L34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41613497</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 96bb0b4beccd98dc9c762b915a8508508d645b1a</div><div id='time'> Time: 2023-03-02</div><div id='author'> Author: lux.florian@gmail.com</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/ToucanTTS/toucantts_train_loop.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train_loop(15)</div><div id='n_method'> N Method Name: train_loop(15)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/ToucanTTS/toucantts_train_loop.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/ToucanTTS/toucantts_train_loop.py</div><div id='m_start'> M Start Line: 89</div><div id='m_end'> M End Line: 153</div><div id='n_start'> N Start Line: 89</div><div id='n_end'> N End Line: 143</div><BR>