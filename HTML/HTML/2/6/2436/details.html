<html><h3>Pattern ID :2436
</h3><img src='10285644.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    for embt, embi in zip(text_reader(batch_size=NUM_TEST_EMBEDDINGS, start=tstart, end=tend), 
            image_reader(batch_size=NUM_TEST_EMBEDDINGS, start=tstart, end=tend)):
       &#47&#47 make a copy of the text embeddings for shuffling
       text_embed<a id="change"> = </a><a id="change">torch.tensor(</a>embt[0]<a id="change">)</a>.to(device)
       text_embed_shuffled = text_embed.clone()
        &#47&#47 roll the text embeddings to simulate "unrelated" captions
       rolled_idx = torch.roll(torch.arange(NUM_TEST_EMBEDDINGS), 1)
       text_embed_shuffled = text_embed_shuffled[rolled_idx]
       text_embed_shuffled = text_embed_shuffled / \
           text_embed_shuffled.norm(dim=1, keepdim=True)
       test_text_shuffled_cond = dict(text_embed=text_embed_shuffled)
        &#47&#47 prepare the text embedding
       text_embed = text_embed / text_embed.norm(dim=1, keepdim=True)
       test_text_cond<a id="change"> = </a>dict(text_embed=text_embed)
        &#47&#47 prepare image embeddings
       test_image_embeddings = torch.tensor(embi[0]).to(device)
       test_image_embeddings = test_image_embeddings / \
           test_image_embeddings.norm(dim=1, keepdim=True)
        &#47&#47 predict on the unshuffled text embeddings
       predicted_image_embeddings = diffusion_prior.p_sample_loop(
           (NUM_TEST_EMBEDDINGS<a id="change">, 768</a>), text_cond=test_text_cond)
       predicted_image_embeddings = predicted_image_embeddings / \
           predicted_image_embeddings.norm(dim=1, keepdim=True)
        &#47&#47 predict on the shuffled embeddings</code></pre><h3>After Change</h3><pre><code class='java'>

    cos = nn.CosineSimilarity(dim=1, eps=1e-6)

    for test_image_embeddings, text_data in <a id="change">tqdm(</a>dataloader<a id="change">)</a>:

        &#47&#47 we are text conditioned, we produce an embedding from the tokenized text
        if text_conditioned:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/4a59dea4cfad72176f35700296adfbc28e205598#diff-283456789c9565d0a8ad235fc41b44188f310b3043c3bcdeb6678f1958a57b51L63' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 10285644</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: 4a59dea4cfad72176f35700296adfbc28e205598</div><div id='time'> Time: 2022-05-15</div><div id='author'> Author: 51308183+nousr@users.noreply.github.com</div><div id='file'> File Name: train_diffusion_prior.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: report_cosine_sims(3)</div><div id='n_method'> N Method Name: report_cosine_sims(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_diffusion_prior.py</div><div id='n_file'> N File Name: train_diffusion_prior.py</div><div id='m_start'> M Start Line: 63</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 73</div><div id='n_end'> N End Line: 119</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 add noise
    wavaug = WavAug(sample_rate=out_sample_rate, mode="test")
    for <a id="change">wav_file</a> in tqdm(wav_files):
        output_path<a id="change"> = </a>wav_file.replace(str(data_dir), str(save_dir))
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)

        wav<a id="change">, sr</a> = librosa.load(wav_file, sr=out_sample_rate)
        noisy_wav<a id="change"> = </a>wavaug.add_noise(<a id="change">torch.tensor(</a>wav<a id="change">)</a>)
        torchaudio.save(output_path, noisy_wav, sample_rate=out_sample_rate)

    &#47&#47 copy text files</code></pre><h3>After Change</h3><pre><code class='java'>
    N_processes = cpu_count()
    print(f"[INFO] Start multiprocessing with {N_processes} processes")
    with Pool(processes=N_processes) as pool:
        for _ in <a id="change">tqdm(</a>pool.imap(file_to_noisy_file, wav_files)<a id="change">, total=len(wav_files))</a>:
            pass

    &#47&#47 copy text files</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ga642381/robustvc/commit/b126baaf7f3ce43577adb438842d1c6c4904b722#diff-5b54711dd6b5dcab5729c760588f01daaa854df533804b325965013633add281L20' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 10285646</div><div id='project'> Project Name: ga642381/robustvc</div><div id='commit'> Commit Name: b126baaf7f3ce43577adb438842d1c6c4904b722</div><div id='time'> Time: 2021-08-28</div><div id='author'> Author: ga642381@gmail.com</div><div id='file'> File Name: assets/script/dataset_noise.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(3)</div><div id='n_method'> N Method Name: main(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: assets/script/dataset_noise.py</div><div id='n_file'> N File Name: assets/script/dataset_noise.py</div><div id='m_start'> M Start Line: 22</div><div id='m_end'> M End Line: 46</div><div id='n_start'> N Start Line: 37</div><div id='n_end'> N End Line: 64</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    tstart = train_set_size
    tend = train_set_size+NUM_TEST_EMBEDDINGS

    for embt, <a id="change">embi</a> in zip(text_reader(batch_size=NUM_TEST_EMBEDDINGS, start=tstart, end=tend), 
            image_reader(batch_size=NUM_TEST_EMBEDDINGS, start=tstart, end=tend)):
       &#47&#47 make a copy of the text embeddings for shuffling
       text_embed<a id="change"> = </a>torch.tensor(embt[0]).to(device)
       text_embed_shuffled = text_embed.clone()
        &#47&#47 roll the text embeddings to simulate "unrelated" captions
       rolled_idx = torch.roll(torch.arange(NUM_TEST_EMBEDDINGS), 1)
       text_embed_shuffled = text_embed_shuffled[rolled_idx]
       text_embed_shuffled = text_embed_shuffled / \
           text_embed_shuffled.norm(dim=1, keepdim=True)
       test_text_shuffled_cond = dict(text_embed=text_embed_shuffled)
        &#47&#47 prepare the text embedding
       text_embed = text_embed / text_embed.norm(dim=1, keepdim=True)
       test_text_cond = dict(text_embed=text_embed)
        &#47&#47 prepare image embeddings
       test_image_embeddings<a id="change"> = </a><a id="change">torch.tensor(</a>embi[0]<a id="change">)</a>.to(device)
       test_image_embeddings = test_image_embeddings / \
           test_image_embeddings.norm(dim=1, keepdim=True)
        &#47&#47 predict on the unshuffled text embeddings
       predicted_image_embeddings = diffusion_prior.p_sample_loop(
           (NUM_TEST_EMBEDDINGS<a id="change">, 768</a>), text_cond=test_text_cond)
       predicted_image_embeddings = predicted_image_embeddings / \
           predicted_image_embeddings.norm(dim=1, keepdim=True)
        &#47&#47 predict on the shuffled embeddings</code></pre><h3>After Change</h3><pre><code class='java'>

    cos = nn.CosineSimilarity(dim=1, eps=1e-6)

    for test_image_embeddings, text_data in <a id="change">tqdm(</a>dataloader<a id="change">)</a>:

        &#47&#47 we are text conditioned, we produce an embedding from the tokenized text
        if text_conditioned:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/4a59dea4cfad72176f35700296adfbc28e205598#diff-283456789c9565d0a8ad235fc41b44188f310b3043c3bcdeb6678f1958a57b51L63' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 10285640</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: 4a59dea4cfad72176f35700296adfbc28e205598</div><div id='time'> Time: 2022-05-15</div><div id='author'> Author: 51308183+nousr@users.noreply.github.com</div><div id='file'> File Name: train_diffusion_prior.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: report_cosine_sims(3)</div><div id='n_method'> N Method Name: report_cosine_sims(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_diffusion_prior.py</div><div id='n_file'> N File Name: train_diffusion_prior.py</div><div id='m_start'> M Start Line: 63</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 73</div><div id='n_end'> N End Line: 119</div><BR>