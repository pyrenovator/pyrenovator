<html><h3>Pattern ID :42103
</h3><img src='117882855.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 TODO the num_targets in the below expression used to be batch size. Changed it to num_targets but this might be wrong
        &#47&#47 (don&quott 100% understand the logic of the normalization term here)
        sim_ik = (<a id="change">torch.einsum(&quotnc,mc-&gt;n&quot, [z_i, z_all]).unsqueeze(-1</a><a id="change">)</a> - 1) / (2 * num_targets - 1)

        logits = torch.cat((sim_ij, sim_ik), 1)
        logits /= self.temp</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 I think if we include z_i here, we should use a mask (as in SymmetricContrastiveLoss) to subtract the column
        &#47&#47 on which the similarity is calculated with an image itself?
        mask<a id="change"> = </a><a id="change">torch.eye(num_contexts).to(</a>self.device<a id="change">)</a>

        &#47&#47 Simplify the code
        z_all = torch.cat([z_i, z_j], 0)
        if num_targets &gt; num_contexts:
            z_j = z_j[:num_contexts]

        &#47&#47 zi and zj are both matrices of dim (n x c), since they are z vectors of dim c for every element in the batch
        &#47&#47 This einsum is constructing a vector of size n, where the nth element is a sum over C of the NCth elements
        &#47&#47 That is to say, the nth element is a dot product between the Nth C-dim vector of each matrix
        sim_ij = torch.einsum(&quotnc,nc-&gt;n&quot, [z_i, z_j]).unsqueeze(-1)  &#47&#47 Nx1

        &#47&#47 Calculate similarity of current batch&quots images and other images.
        sim_ik = torch.einsum(&quotnc,ck-&gt;nk&quot, [z_i, z_all.T])
        sim_ik<a id="change"> = </a>sim_ik<a id="change"> - </a>mask  &#47&#47 TODO: Check if the diagonal line are all 1s.

        logits = torch.cat((sim_ij, sim_ik), 1)
        logits /= self.temp</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/77be42e07c4a5f10559685813b6d0d778577eb1a#diff-094460a9fbb96d5a5e5e0ff351a3d7aaa4cc4fae9d4c22cbb890b6d29832d85eL42' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117882855</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: 77be42e07c4a5f10559685813b6d0d778577eb1a</div><div id='time'> Time: 2020-08-05</div><div id='author'> Author: RPC2@users.noreply.github.com</div><div id='file'> File Name: algos/losses.py</div><div id='m_class'> M Class Name: AsymmetricContrastiveLoss</div><div id='n_method'> N Class Name: AsymmetricContrastiveLoss</div><div id='m_method'> M Method Name: __call__(4)</div><div id='n_method'> N Method Name: __call__(4)</div><div id='m_parent_class'> M Parent Class: RepresentationLoss</div><div id='n_parent_class'> N Parent Class: RepresentationLoss</div><div id='m_file'> M File Name: algos/losses.py</div><div id='n_file'> N File Name: algos/losses.py</div><div id='m_start'> M Start Line: 42</div><div id='m_end'> M End Line: 61</div><div id='n_start'> N Start Line: 46</div><div id='n_end'> N End Line: 65</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 TODO the num_targets in the below expression used to be batch size. Changed it to num_targets but this might be wrong
        &#47&#47 (don&quott 100% understand the logic of the normalization term here)
        sim_ik = (<a id="change">torch.einsum(&quotnc,mc-&gt;n&quot, [z_i, z_all]).unsqueeze(-1</a><a id="change">)</a> - 1) / (2 * num_targets - 1)

        logits = torch.cat((sim_ij, sim_ik), 1)
        logits /= self.temp</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 I think if we include z_i here, we should use a mask (as in SymmetricContrastiveLoss) to subtract the column
        &#47&#47 on which the similarity is calculated with an image itself?
        mask<a id="change"> = </a><a id="change">torch.eye(num_contexts).to(</a>self.device<a id="change">)</a>

        &#47&#47 Simplify the code
        z_all = torch.cat([z_i, z_j], 0)
        if num_targets &gt; num_contexts:
            z_j = z_j[:num_contexts]

        &#47&#47 zi and zj are both matrices of dim (n x c), since they are z vectors of dim c for every element in the batch
        &#47&#47 This einsum is constructing a vector of size n, where the nth element is a sum over C of the NCth elements
        &#47&#47 That is to say, the nth element is a dot product between the Nth C-dim vector of each matrix
        sim_ij = torch.einsum(&quotnc,nc-&gt;n&quot, [z_i, z_j]).unsqueeze(-1)  &#47&#47 Nx1

        &#47&#47 Calculate similarity of current batch&quots images and other images.
        sim_ik = torch.einsum(&quotnc,ck-&gt;nk&quot, [z_i, z_all.T])
        sim_ik<a id="change"> = </a>sim_ik<a id="change"> - </a>mask  &#47&#47 TODO: Check if the diagonal line are all 1s.

        logits = torch.cat((sim_ij, sim_ik), 1)
        logits /= self.temp</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/bf00e1e7db5d222ce7aa4e79f95a499b0c235cfa#diff-094460a9fbb96d5a5e5e0ff351a3d7aaa4cc4fae9d4c22cbb890b6d29832d85eL33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117882846</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: bf00e1e7db5d222ce7aa4e79f95a499b0c235cfa</div><div id='time'> Time: 2020-08-05</div><div id='author'> Author: RPC2@users.noreply.github.com</div><div id='file'> File Name: algos/losses.py</div><div id='m_class'> M Class Name: AsymmetricContrastiveLoss</div><div id='n_method'> N Class Name: AsymmetricContrastiveLoss</div><div id='m_method'> M Method Name: __call__(4)</div><div id='n_method'> N Method Name: __call__(4)</div><div id='m_parent_class'> M Parent Class: RepresentationLoss</div><div id='n_parent_class'> N Parent Class: RepresentationLoss</div><div id='m_file'> M File Name: algos/losses.py</div><div id='n_file'> N File Name: algos/losses.py</div><div id='m_start'> M Start Line: 42</div><div id='m_end'> M End Line: 61</div><div id='n_start'> N Start Line: 46</div><div id='n_end'> N End Line: 65</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            l1_loss = l1_loss + self.l1_criterion(after_outs, ys)

        &#47&#47 make weighted mask and apply it
        out_masks = <a id="change">make_non_pad_mask(olens).unsqueeze(-1</a><a id="change">)</a>.to(ys.device)
        out_masks = torch.nn.functional.pad(out_masks.transpose(1, 2), [0, ys.size(1) - out_masks.size(1), 0, 0, 0, 0], value=False).transpose(1, 2)
        out_weights = out_masks.float() / out_masks.sum(dim=1, keepdim=True).float()
        out_weights /= ys.size(0) * ys.size(2)</code></pre><h3>After Change</h3><pre><code class='java'>
        out_masks = torch.nn.functional.pad(out_masks.transpose(1, 2), [0, gold_spectrograms.size(1) - out_masks.size(1), 0, 0, 0, 0], value=False).transpose(1, 2)
        out_weights = out_masks.float() / out_masks.sum(dim=1, keepdim=True).float()
        out_weights /= gold_spectrograms.size(0) * gold_spectrograms.size(2)
        duration_masks<a id="change"> = </a><a id="change">make_non_pad_mask(text_lengths).to(</a>gold_spectrograms.device<a id="change">)</a>
        duration_weights = (duration_masks.float()<a id="change"> / </a>duration_masks.sum(dim=1, keepdim=True).float())

        &#47&#47 apply weight
        l1_loss = l1_loss.mul(out_weights).masked_select(out_masks).sum()
        duration_loss<a id="change"> = </a>(duration_loss.mul(duration_weights).masked_select(duration_masks).sum())

        return l1_loss, duration_loss
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/b8532b46fafdc2f07c5ce57d6b7711db0682be18#diff-d7f9aee10ac5450baf13668ce069a9ea393323a61e8217b09a70a6ecc1e72757L17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117882842</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: b8532b46fafdc2f07c5ce57d6b7711db0682be18</div><div id='time'> Time: 2023-03-09</div><div id='author'> Author: lux.florian@gmail.com</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/ToucanTTS/ToucanTTSLoss.py</div><div id='m_class'> M Class Name: ToucanTTSLoss</div><div id='n_method'> N Class Name: ToucanTTSLoss</div><div id='m_method'> M Method Name: forward(8)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/ToucanTTS/ToucanTTSLoss.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/ToucanTTS/ToucanTTSLoss.py</div><div id='m_start'> M Start Line: 35</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 19</div><div id='n_end'> N End Line: 53</div><BR>