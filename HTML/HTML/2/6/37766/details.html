<html><h3>Pattern ID :37766
</h3><img src='108396292.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 it will be returned early.
        &#47&#47 Note: during inference batch_size needs to be 1
        if inference:
            uncertain_infos<a id="change"> = </a>[]
            for i, (layer_module, (k, layer_classifier_module)) in enumerate(
                    zip(self.layer, self.layer_classifiers.items())):
                hidden_states = layer_module(hidden_states[0], attention_mask)
                logits = layer_classifier_module(hidden_states[0])
                prob = F.softmax(logits, dim=-1)
                log_prob = F.log_softmax(logits, dim=-1)
                uncertain = torch.sum(prob * log_prob, 1) / (-torch.log(self.num_class))
                uncertain_infos.append([uncertain, prob])

                &#47&#47 return early results
                if uncertain &lt; inference_speed:
                    <a id="change">return </a>prob, i, uncertain_infos
            return prob, i, uncertain_infos

        &#47&#47 Training phase: the first phase corresponds to the backbone training</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 positions will keep track of the original position of each element in the
            &#47&#47 batch when elements will be removed
            final_probs = torch.zeros((hidden_states[0].shape[0], 2), device=device)
            positions = <a id="change">torch.arange(start=0, end=hidden_states[0].shape[0], device=device).long()</a>

            for i, (layer_module, (k, layer_classifier_module)) in enumerate(
                    zip(self.layer, self.layer_classifiers.items())):

                hidden_states = layer_module(hidden_states[0], attention_mask)
                logits = layer_classifier_module(hidden_states[0])
                prob = F.softmax(logits, dim=-1)
                log_prob = F.log_softmax(logits, dim=-1)
                uncertain = torch.sum(prob * log_prob, 1) / (-torch.log(self.num_class))

                &#47&#47 checking if there&quots enough information
                enough_info = uncertain &lt; inference_speed

                right_pos<a id="change"> = </a>positions[enough_info]
                final_probs[right_pos] = prob[enough_info]

                hidden_states = (hidden_states[0][~enough_info],)
                attention_mask = attention_mask[~enough_info]

                &#47&#47 if we have processed all the samples
                if hidden_states[0].shape[0] == 0:
                    <a id="change">return </a>final_probs<a id="change">, i</a>

                positions = positions[~enough_info]  &#47&#47 updating the positions to fit the new batch

            return final_probs, i</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/julesbelveze/bert-squeeze/commit/3cb14b8f1e742b86fe609843f2779e3bb36de4aa#diff-aac748de92a29499c39463320f41c1eaeb283dae0ed8ead9584db8318265a4acL49' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 108396292</div><div id='project'> Project Name: julesbelveze/bert-squeeze</div><div id='commit'> Commit Name: 3cb14b8f1e742b86fe609843f2779e3bb36de4aa</div><div id='time'> Time: 2021-12-11</div><div id='author'> Author: 32683010+JulesBelveze@users.noreply.github.com</div><div id='file'> File Name: bert-squeeze/models/custom_transformers/fastbert.py</div><div id='m_class'> M Class Name: FastBertGraph</div><div id='n_method'> N Class Name: FastBertGraph</div><div id='m_method'> M Method Name: forward(7)</div><div id='n_method'> N Method Name: forward(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: bert-squeeze/models/custom_transformers/fastbert.py</div><div id='n_file'> N File Name: bert-squeeze/models/custom_transformers/fastbert.py</div><div id='m_start'> M Start Line: 57</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 87</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        mrr.append(1 / rank)
        hits.append(int(rank &lt;= k))

    <a id="change">return </a>mrr, hits


def main():</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 get the scores of the true target subjects/objects
    idx = 0 if direction == "s" else 2
    targets<a id="change"> = </a><a id="change">test_spo[:, idx].long()</a>
    arange = torch.arange(len(targets), dtype=torch.long, device="cpu")
    true_scores<a id="change"> = </a>scores[arange, targets].view(-1, 1)

    &#47&#47 remove the true subjects/objects from the scores so they don&quott factor in rankings
    scores = scores.clone()
    scores[arange<a id="change">, targets</a>] = float("-Inf")

    &#47&#47 follow LibKGE protocol by taking the mean rank among all entities with same score
    ranks = torch.sum(scores &gt; true_scores, dim=1, dtype=torch.double)
    num_ties = torch.sum(scores == true_scores, dim=1, dtype=torch.double)
    ranks = ranks + num_ties // 2 + 1  &#47&#47 ranks are one-indexed

    mrr = (1 / ranks).numpy()
    hits = (ranks &lt;= k).numpy()
    <a id="change">return </a>list(mrr), list(hits)


@torch.no_grad()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tsafavi/codex/commit/3dddca246e4fb616cef251bafb32dac648e8eedb#diff-7473d3c6ae8fdca415f05877da582b17af17f591a0a1312717bb10fd4da4b992L119' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 108396272</div><div id='project'> Project Name: tsafavi/codex</div><div id='commit'> Commit Name: 3dddca246e4fb616cef251bafb32dac648e8eedb</div><div id='time'> Time: 2020-07-08</div><div id='author'> Author: tsafavi@umich.edu</div><div id='file'> File Name: scripts/baseline.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate_rankings(5)</div><div id='n_method'> N Method Name: evaluate_rankings(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/baseline.py</div><div id='n_file'> N File Name: scripts/baseline.py</div><div id='m_start'> M Start Line: 129</div><div id='m_end'> M End Line: 151</div><div id='n_start'> N Start Line: 129</div><div id='n_end'> N End Line: 148</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    config = set_evasion_model(query, victim_input_shape, victim_input_targets)
    x_adv, y_adv = init_hopskipjump(config, data)
    x = torch.cat((x, x_adv))
    y<a id="change"> = </a>torch.cat((y, y_adv))
    <a id="change">return </a>x, y


@register_synth</code></pre><h3>After Change</h3><pre><code class='java'>
    result = result.clone().detach()
    print(result.shape)
    y = torch.Tensor([query(x) for x in result])
    y<a id="change"> = </a><a id="change">y.long()</a>
    <a id="change">return </a>result<a id="change">, y</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/trailofbits/privacyraven/commit/ce663f3b0895905a2731bf1907af06f1f99fbb12#diff-e399b6ad8d6d6523e65ad0d433b80f161b2fbc814e46ade00bbbb9b5d997c1aaL150' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 108396274</div><div id='project'> Project Name: trailofbits/privacyraven</div><div id='commit'> Commit Name: ce663f3b0895905a2731bf1907af06f1f99fbb12</div><div id='time'> Time: 2020-10-21</div><div id='author'> Author: suhashussain1@gmail.com</div><div id='file'> File Name: src/privacyraven/extraction/synthesis.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: hopskipjump(6)</div><div id='n_method'> N Method Name: hopskipjump(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/privacyraven/extraction/synthesis.py</div><div id='n_file'> N File Name: src/privacyraven/extraction/synthesis.py</div><div id='m_start'> M Start Line: 159</div><div id='m_end'> M End Line: 175</div><div id='n_start'> N Start Line: 118</div><div id='n_end'> N End Line: 144</div><BR>