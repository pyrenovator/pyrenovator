<html><h3>Pattern ID :21733
</h3><img src='69389858.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            model.zero_grad()

            pred = model(
                <a id="change">torch.autograd.Variable(batch).to(</a>device<a id="change">)</a>, lengths.cpu().numpy()
            )  &#47&#47&#47&#47 perform forward pass
            pred = torch.squeeze(pred)
            loss = criterion(
                pred.to(device), torch.autograd.Variable(targets.float()).to(device)
            )  &#47&#47&#47&#47 compute loss

            loss.backward()  &#47&#47&#47&#47 perform backward pass
            optimizer.step()  &#47&#47&#47&#47 update weights

            pred_val = pred &gt;= 0.5  &#47&#47&#47&#47 get predictions
            y_true += list(targets.int().numpy())  &#47&#47&#47&#47 accumulate targets from batch
            y_pred<a id="change"> += </a>list(
                pred_val.data.int().detach().cpu().numpy()
            )  &#47&#47&#47&#47 accumulate preds from batch
            total_loss += loss  &#47&#47&#47&#47 accumulate train loss</code></pre><h3>After Change</h3><pre><code class='java'>

            model.zero_grad()
            &#47&#47&#47&#47 perform forward pass
            pred<a id="change"> = </a>model(
                sent1.to(device),
                sent2.to(device),
                <a id="change">sents1_len.to(</a>device<a id="change">)</a>,
                sents2_len.to(device),
            )

            &#47&#47&#47&#47 compute loss
            loss = criterion(
                pred.to(device), torch.autograd.Variable(targets.float()).to(device)
            )

            &#47&#47&#47&#47 perform backward pass
            loss.backward()

            &#47&#47&#47&#47 update weights
            optimizer.step()

            &#47&#47&#47&#47 accumulate targets from batch
            y_true += list(targets.float().numpy())

            &#47&#47&#47&#47 accumulate preds from batch
            y_pred<a id="change"> += </a>list(<a id="change">pred.data.float()</a>.detach().cpu().numpy())

            &#47&#47&#47&#47 accumulate train loss
            total_loss += loss</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/shahrukhx01/siamese-nn-semantic-text-similarity/commit/f3d054dd14ef532c408b1306c3341115777ac22f#diff-be822a1f9a4a693be118629ef529ccaecde36733327973c865b9d50a0c7bb839L16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69389858</div><div id='project'> Project Name: shahrukhx01/siamese-nn-semantic-text-similarity</div><div id='commit'> Commit Name: f3d054dd14ef532c408b1306c3341115777ac22f</div><div id='time'> Time: 2021-12-30</div><div id='author'> Author: sk28671@gmail.com</div><div id='file'> File Name: siamese_sts/trainer/train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train_model(6)</div><div id='n_method'> N Method Name: train_model(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: siamese_sts/trainer/train.py</div><div id='n_file'> N File Name: siamese_sts/trainer/train.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 47</div><div id='n_start'> N Start Line: 16</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        if i &gt;= 10: break

        frames<a id="change"> = </a><a id="change">frames.to(</a>DEVICE<a id="change">)</a>  &#47&#47 [1, T, 3, h, w]
        frames_vis = postprocess_img(frames.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
        input = frames[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 3, h, w]
</code></pre><h3>After Change</h3><pre><code class='java'>
    with torch.no_grad():
        for i in tqdm(range(10)):

            frames<a id="change"> = </a><a id="change">next(iter_loader).to(</a>DEVICE<a id="change">)</a>  &#47&#47 [1, T, 3, h, w]
            frames_vis = postprocess_img(frames.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
            input = frames[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 3, h, w]

            pred_rgb = pred_rgb_model.pred_n(input, pred_length=VIDEO_PRED_LENGTH)
            pred_rgb = torch.cat([input, pred_rgb], dim=1)  &#47&#47 [1, T, 3, h, w]
            pred_rgb_vis = postprocess_img(pred_rgb.squeeze(dim=0))  &#47&#47 [T, 3, h, w]

            pred_rgb = torch.stack([seg_model(pred_rgb[:, i]) for i in range(pred_rgb.shape[1])], dim=1)
            pred_rgb = pred_rgb.argmax(dim=2).squeeze()  &#47&#47 [T, h, w]
            pred_then_colorized_vis = colorize_semseg(postprocess_mask(pred_rgb), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2) &#47&#47 [T, 3, h, w]

            frames_seg = torch.stack([seg_model(frames[:, i]) for i in range(frames.shape[1])], dim=1).argmax(dim=2)  &#47&#47 [1, T, 1, h, w]
            frames_seg_in<a id="change"> = </a><a id="change">torch.stack([(frames_seg == i) for i in range(SYNPICK_CLASSES)], dim=2).float()</a>  &#47&#47 [1, T, c, h, w] one-hot float
            input_seg = frames_seg_in[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, c, h, w]
            pred_mask = pred_mask_model.pred_n(input_seg, pred_length=VIDEO_PRED_LENGTH).argmax(dim=2)  &#47&#47 [1, n, 1, h, w]
            pred_mask = torch.cat([input_seg.argmax(dim=2), pred_mask], dim=1).squeeze()  &#47&#47 [T, h, w]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ais-bonn/vp-suite/commit/13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3#diff-e07d70acfca9139cbf2c37b7a0074bdfbb966d41dc6c7edcc2cef05e78c00af0L13' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69389891</div><div id='project'> Project Name: ais-bonn/vp-suite</div><div id='commit'> Commit Name: 13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3</div><div id='time'> Time: 2021-08-02</div><div id='author'> Author: boltres@ais.uni-bonn.de</div><div id='file'> File Name: scripts/visualize_4_way.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: visualize_4_way(1)</div><div id='n_method'> N Method Name: visualize_4_way(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/visualize_4_way.py</div><div id='n_file'> N File Name: scripts/visualize_4_way.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 73</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 74</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            l1_loss = l1_loss + self.l1_criterion(after_outs, ys)

        &#47&#47 make weighted mask and apply it
        out_masks = <a id="change">make_non_pad_mask(olens).unsqueeze(-1).to(</a>ys.device<a id="change">)</a>
        out_masks = torch.nn.functional.pad(out_masks.transpose(1, 2), [0, ys.size(1) - out_masks.size(1), 0, 0, 0, 0], value=False).transpose(1, 2)
        out_weights = out_masks.float() / out_masks.sum(dim=1, keepdim=True).float()
        out_weights<a id="change"> /= </a>ys.size(0) * ys.size(2)

        &#47&#47 apply weight
        l1_loss = l1_loss.mul(out_weights).masked_select(out_masks).sum()</code></pre><h3>After Change</h3><pre><code class='java'>
        out_masks = torch.nn.functional.pad(out_masks.transpose(1, 2), [0, gold_spectrograms.size(1) - out_masks.size(1), 0, 0, 0, 0], value=False).transpose(1, 2)
        out_weights = out_masks.float() / out_masks.sum(dim=1, keepdim=True).float()
        out_weights /= gold_spectrograms.size(0) * gold_spectrograms.size(2)
        duration_masks<a id="change"> = </a><a id="change">make_non_pad_mask(text_lengths).to(</a>gold_spectrograms.device<a id="change">)</a>
        duration_weights<a id="change"> = </a>(duration_masks.float() / <a id="change">duration_masks.sum(dim=1, keepdim=True).float()</a>)

        &#47&#47 apply weight
        l1_loss = l1_loss.mul(out_weights).masked_select(out_masks).sum()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/b8532b46fafdc2f07c5ce57d6b7711db0682be18#diff-d7f9aee10ac5450baf13668ce069a9ea393323a61e8217b09a70a6ecc1e72757L17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69389806</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: b8532b46fafdc2f07c5ce57d6b7711db0682be18</div><div id='time'> Time: 2023-03-09</div><div id='author'> Author: lux.florian@gmail.com</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/ToucanTTS/ToucanTTSLoss.py</div><div id='m_class'> M Class Name: ToucanTTSLoss</div><div id='n_method'> N Class Name: ToucanTTSLoss</div><div id='m_method'> M Method Name: forward(8)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/ToucanTTS/ToucanTTSLoss.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/ToucanTTS/ToucanTTSLoss.py</div><div id='m_start'> M Start Line: 35</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 19</div><div id='n_end'> N End Line: 53</div><BR>