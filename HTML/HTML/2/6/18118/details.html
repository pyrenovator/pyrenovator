<html><h3>Pattern ID :18118
</h3><img src='59399282.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        hr_image_path = os.path.join(config.hr_dir, file_names[index])

        print(f"Processing `{os.path.abspath(lr_image_path)}`...")
        lr_image = <a id="change">Image.open(</a>lr_image_path<a id="change">)</a>.convert("RGB")
        hr_image = <a id="change">Image.open(</a>hr_image_path<a id="change">)</a>.convert("RGB")

        &#47&#47 Extract RGB channel image data
        lr_tensor = imgproc.image2tensor(lr_image, range_norm=False, half=True).to(config.device).unsqueeze_(0)
        hr_tensor = imgproc.image2tensor(hr_image, range_norm=False, half=True).to(config.device).unsqueeze_(0)

        &#47&#47 Only reconstruct the Y channel image data.
        with torch.no_grad():
            sr_tensor = model(lr_tensor).clamp_(0, 1)

        &#47&#47 Cal PSNR
        sr_y_tensor = imgproc.convert_rgb_to_y(sr_tensor)
        hr_y_tensor<a id="change"> = </a>imgproc.convert_rgb_to_y(hr_tensor)
        total_psnr += 10. * torch.log10(1. / torch.mean((sr_y_tensor - hr_y_tensor) ** 2))

        sr_image = imgproc.tensor2image(sr_tensor, range_norm=False, half=True)</code></pre><h3>After Change</h3><pre><code class='java'>
def main() -&gt; None:
    &#47&#47 Initialize the super-resolution model
    model = Generator().to(config.device)
    <a id="change">print("Build ESRGAN model successfully."</a><a id="change">)</a>

    &#47&#47 Load the super-resolution model weights
    checkpoint = torch.load(config.model_path, map_location=lambda storage, loc: storage)
    model.load_state_dict(checkpoint["state_dict"])</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lornatang/esrgan-pytorch/commit/087e0c9bc621989889918b52b7c0dba9485c5fd6#diff-58b7fc05c0526d9a9b3c0b50dda416fcbf0a654e696da4b6df82cbb5a6b2dcfcL28' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59399282</div><div id='project'> Project Name: lornatang/esrgan-pytorch</div><div id='commit'> Commit Name: 087e0c9bc621989889918b52b7c0dba9485c5fd6</div><div id='time'> Time: 2022-03-06</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: validate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: validate.py</div><div id='n_file'> N File Name: validate.py</div><div id='m_start'> M Start Line: 28</div><div id='m_end'> M End Line: 82</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 91</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        hr_image_path = os.path.join(config.hr_dir, file_names[index])

        print(f"Processing `{os.path.abspath(lr_image_path)}`...")
        lr_image = <a id="change">Image.open(</a>lr_image_path<a id="change">)</a>.convert("RGB")
        hr_image = <a id="change">Image.open(</a>hr_image_path<a id="change">)</a>.convert("RGB")

        &#47&#47 Extract RGB channel image data
        lr_tensor = imgproc.image2tensor(lr_image, range_norm=False, half=True).to(config.device).unsqueeze_(0)
        hr_tensor = imgproc.image2tensor(hr_image, range_norm=False, half=True).to(config.device).unsqueeze_(0)

        &#47&#47 Only reconstruct the Y channel image data.
        with torch.no_grad():
            sr_tensor = model(lr_tensor).clamp_(0, 1)

        &#47&#47 Cal PSNR
        sr_y_tensor = imgproc.convert_rgb_to_y(sr_tensor)
        hr_y_tensor<a id="change"> = </a>imgproc.convert_rgb_to_y(hr_tensor)
        total_psnr += 10. * torch.log10(1. / torch.mean((sr_y_tensor - hr_y_tensor) ** 2))

        sr_image = imgproc.tensor2image(sr_tensor, range_norm=False, half=True)</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 Load the super-resolution model weights
    checkpoint = torch.load(config.model_path, map_location=lambda storage, loc: storage)
    model.load_state_dict(checkpoint["state_dict"])
    <a id="change">print(f"Load ESRGAN model weights `{os.path.abspath(config.model_path)}` successfully."</a><a id="change">)</a>

    &#47&#47 Create a folder of super-resolution experiment results
    results_dir = os.path.join("results", "test", config.exp_name)
    if not os.path.exists(results_dir):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/esrgan-pytorch/commit/087e0c9bc621989889918b52b7c0dba9485c5fd6#diff-58b7fc05c0526d9a9b3c0b50dda416fcbf0a654e696da4b6df82cbb5a6b2dcfcL26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59399283</div><div id='project'> Project Name: lornatang/esrgan-pytorch</div><div id='commit'> Commit Name: 087e0c9bc621989889918b52b7c0dba9485c5fd6</div><div id='time'> Time: 2022-03-06</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: validate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: validate.py</div><div id='n_file'> N File Name: validate.py</div><div id='m_start'> M Start Line: 28</div><div id='m_end'> M End Line: 82</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 91</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        hr_image_path = os.path.join(config.hr_dir, file_names[index])

        print(f"Processing `{os.path.abspath(lr_image_path)}`...")
        lr_image = <a id="change">Image.open(</a>lr_image_path<a id="change">)</a>.convert("RGB")
        hr_image = <a id="change">Image.open(</a>hr_image_path<a id="change">)</a>.convert("RGB")

        &#47&#47 Extract RGB channel image data
        lr_tensor = imgproc.image2tensor(lr_image, range_norm=False, half=True).to(config.device).unsqueeze_(0)
        hr_tensor = imgproc.image2tensor(hr_image, range_norm=False, half=True).to(config.device).unsqueeze_(0)

        &#47&#47 Only reconstruct the Y channel image data.
        with torch.no_grad():
            sr_tensor = model(lr_tensor).clamp_(0, 1)

        &#47&#47 Cal PSNR
        sr_y_tensor = imgproc.convert_rgb_to_y(sr_tensor)
        hr_y_tensor<a id="change"> = </a>imgproc.convert_rgb_to_y(hr_tensor)
        total_psnr += 10. * torch.log10(1. / torch.mean((sr_y_tensor - hr_y_tensor) ** 2))

        sr_image = imgproc.tensor2image(sr_tensor, range_norm=False, half=True)</code></pre><h3>After Change</h3><pre><code class='java'>

        total_psnr += 10. * torch.log10(1. / torch.mean((sr_y_tensor - hr_y_tensor) ** 2))

    <a id="change">print(f"PSNR: {total_psnr / total_files:4.2f}dB.\n"</a><a id="change">)</a>


if __name__ == "__main__":
    main()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/srgan-pytorch/commit/231bd74d21d7f532fd746f4a1cb8fb3bc008c933#diff-58b7fc05c0526d9a9b3c0b50dda416fcbf0a654e696da4b6df82cbb5a6b2dcfcL26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59399286</div><div id='project'> Project Name: lornatang/srgan-pytorch</div><div id='commit'> Commit Name: 231bd74d21d7f532fd746f4a1cb8fb3bc008c933</div><div id='time'> Time: 2022-03-03</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: validate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: validate.py</div><div id='n_file'> N File Name: validate.py</div><div id='m_start'> M Start Line: 28</div><div id='m_end'> M End Line: 82</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 91</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    outfile = f&quot{audio_super}{dir}/{dir}.wav&quot
    data= []
    for infile in audioFiles:
        w<a id="change"> = </a><a id="change">wave.open(</a>infile, &quotrb&quot<a id="change">)</a>
        data.append( [w.getparams(), w.readframes(w.getnframes())] )
        w.close()
    output = <a id="change">wave.open(</a>outfile, &quotwb&quot<a id="change">)</a>
    output.setparams(data[0][0])
    for i in range(len(data)):
        output.writeframes(data[i][1])
    output.close()</code></pre><h3>After Change</h3><pre><code class='java'>
    os.rename(audio_files[0], str(os.path.dirname(audio_files[0]))+ &quot/&quot + str(os.path.basename(os.path.dirname(audio_files[0]))) + audio_files[0][-4:])
    
  if len(audio_files) == 0:
    <a id="change">print(&quotMissing audio in your audio folder.&quot</a><a id="change">)</a>
    sys.exit()

&#47&#47 converts video to frames; outpouts in 0000x.png to framesOutPath location
def vid2frames(vid_path, frames_out_path):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/johngettings/lihq/commit/5c02df6c1bfeb357a3c7a3c073a349eb534a983f#diff-1500446ac71873acb52abfc30bf317cfba356a29f0eab48f2446d3c4c5dc529eL23' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59399284</div><div id='project'> Project Name: johngettings/lihq</div><div id='commit'> Commit Name: 5c02df6c1bfeb357a3c7a3c073a349eb534a983f</div><div id='time'> Time: 2022-05-24</div><div id='author'> Author: johngettingsai@gmail.com</div><div id='file'> File Name: procedures/av_scripts.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: combine_audiofiles(2)</div><div id='n_method'> N Method Name: combine_audiofiles(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: procedures/av_scripts.py</div><div id='n_file'> N File Name: procedures/av_scripts.py</div><div id='m_start'> M Start Line: 24</div><div id='m_end'> M End Line: 37</div><div id='n_start'> N Start Line: 24</div><div id='n_end'> N End Line: 47</div><BR>