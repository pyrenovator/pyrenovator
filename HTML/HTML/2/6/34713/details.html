<html><h3>Pattern ID :34713
</h3><img src='99589743.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def _merge_results(self, current_state: List[Tensor]) -&gt; Tensor:
        mb_feats = torch.stack(current_state, dim=1)
        (batch_size, num_f, num_steps, num_feats) = mb_feats.size()
        mb_feats = <a id="change">mb_feats.permute(</a>0, <a id="change">2</a>, <a id="change">1</a>, <a id="change">3</a><a id="change">)</a>
        mb_feats = mb_feats.reshape(batch_size, num_steps * num_f, num_feats)
        return mb_feats

    def _run_regressor(self, mb_feats: Tensor) -&gt; Tensor:</code></pre><h3>After Change</h3><pre><code class='java'>
        f_even = f_even.permute(1, 0, 2)
        f_odd = f_odd.permute(1, 0, 2)
        mlen = min((f_even.shape[0], f_odd.shape[0]))
        _ = <a id="change">[]</a>
        for i in range(mlen):
            _.append(f_even[i].unsqueeze(0))
            _.append(f_odd[i].unsqueeze(0))
        if f_even.shape[0] &gt; f_odd.shape[0]:
            <a id="change">_.append(</a>f_even[-1].unsqueeze(0)<a id="change">)</a>
        return torch.cat(_, 0).permute(1, 0, 2)

    def _run_regressor(self, mb_feats: Tensor) -&gt; Tensor:
        mb_feats = mb_feats.permute(0, 2, 1)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/takuyashintate/tsts/commit/b03ce0665b1764d80b4f1f5ef041af8375521f50#diff-a5ccf9b326b0a93905e9f104b2a6705531bc58a54f652fa7c74d49ae9bc9eb8fL209' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 99589743</div><div id='project'> Project Name: takuyashintate/tsts</div><div id='commit'> Commit Name: b03ce0665b1764d80b4f1f5ef041af8375521f50</div><div id='time'> Time: 2022-03-29</div><div id='author'> Author: kmdbn2hs@gmail.com</div><div id='file'> File Name: tsts/models/scinet.py</div><div id='m_class'> M Class Name: SCINet</div><div id='n_method'> N Class Name: SCINet</div><div id='m_method'> M Method Name: _merge_results(3)</div><div id='n_method'> N Method Name: _merge_results(2)</div><div id='m_parent_class'> M Parent Class: Module</div><div id='n_parent_class'> N Parent Class: Module</div><div id='m_file'> M File Name: tsts/models/scinet.py</div><div id='n_file'> N File Name: tsts/models/scinet.py</div><div id='m_start'> M Start Line: 209</div><div id='m_end'> M End Line: 214</div><div id='n_start'> N Start Line: 210</div><div id='n_end'> N End Line: 224</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        reproTool = reproTools[dataset_name]
        num_cameras = imgs_orig.shape[0]

        imgs = <a id="change">torch.from_numpy(imgs_orig).cuda().float().permute(0</a>,<a id="change">3</a>,<a id="change">1</a>,2<a id="change">)</a>

        points3D_net = jarvisPredictor(imgs, reproTool.cameraMatrices.cuda(), reproTool.intrinsicMatrices.cuda(), reproTool.distortionCoefficients.cuda())

        if points3D_net != None:</code></pre><h3>After Change</h3><pre><code class='java'>

    pointsNet = []
    pointsGT = []
    filenames = <a id="change">[]</a>
    data_generator = DataLoader(
                dataset,
                batch_size = 1,
                shuffle = False,
                num_workers =  cfg.DATALOADER_NUM_WORKERS,
                pin_memory = True)


    for item, sample in enumerate(tqdm(data_generator)):
        if progress_bar != None:
            progress_bar.progress(float(item+1)/len(dataset.image_ids))

        keypoints3D = sample[1][0].numpy()
        imgs_orig = sample[0][0]
        img_size = imgs_orig[0].shape
        num_cameras = imgs_orig.shape[0]
        dataset_name = sample[-2][0]
        reproTool = reproTools[dataset_name]
        file_name = sample[-1][0]

        imgs = imgs_orig.cuda().float().permute(0,3,1,2)

        points3D_net = jarvisPredictor(imgs,
                    reproTool.cameraMatrices.cuda(),
                    reproTool.intrinsicMatrices.cuda(),
                    reproTool.distortionCoefficients.cuda())

        if points3D_net != None:
            points3D_net = points3D_net[0].cpu().detach().numpy()
            pointsNet.append(points3D_net)
            pointsGT.append(keypoints3D)
            <a id="change">filenames.append(</a>file_name<a id="change">)</a>

    print (f&quot{CLIColors.OKGREEN}Successfully analysed all validation &quot
                f&quotframes!{CLIColors.ENDC}&quot)
    if len(pointsNet) != len(dataset.image_ids):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jarvis-mocap/jarvis-hybridnet/commit/327b43a36cc8aa4995c6e50842b02f3577a1e241#diff-769b6466744cecdc87ace0d46622975c1c612d93b95416dd15345c5193a92404L16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 99589739</div><div id='project'> Project Name: jarvis-mocap/jarvis-hybridnet</div><div id='commit'> Commit Name: 327b43a36cc8aa4995c6e50842b02f3577a1e241</div><div id='time'> Time: 2022-04-28</div><div id='author'> Author: jarvismocap@gmail.com</div><div id='file'> File Name: jarvis/analysis/analyze.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: analyze_validation_data(5)</div><div id='n_method'> N Method Name: analyze_validation_data(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: jarvis/analysis/analyze.py</div><div id='n_file'> N File Name: jarvis/analysis/analyze.py</div><div id='m_start'> M Start Line: 28</div><div id='m_end'> M End Line: 52</div><div id='n_start'> N Start Line: 22</div><div id='n_end'> N End Line: 82</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        inpainted_image = self.model(image, mask)

        cur_res = <a id="change">inpainted_image[0].permute(1</a>, <a id="change">2</a>, <a id="change">0</a><a id="change">)</a>.detach().cpu().numpy()
        cur_res = cur_res[0:origin_height, 0:origin_width, :]
        cur_res = np.clip(cur_res * 255, 0, 255).astype("uint8")
        cur_res = cv2.cvtColor(cur_res, cv2.COLOR_BGR2RGB)</code></pre><h3>After Change</h3><pre><code class='java'>

        print("Trigger crop image")
        boxes = boxes_from_mask(mask)
        crop_result = <a id="change">[]</a>
        for box in boxes:
            crop_image, crop_box = self._run_box(image, mask, box)
            <a id="change">crop_result.append(</a>(crop_image, crop_box)<a id="change">)</a>

        image = (image.transpose(1, 2, 0) * 255).astype(np.uint8)[:, :, ::-1]
        for crop_image, crop_box in crop_result:
            x1, y1, x2, y2 = crop_box</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sanster/lama-cleaner/commit/43c9c22c7312dd39feac4e3783e9ec080fd64243#diff-c64397576661152777123ab1a485c53dbfa8de21c16999da23c3b18cb8993606L34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 99589696</div><div id='project'> Project Name: sanster/lama-cleaner</div><div id='commit'> Commit Name: 43c9c22c7312dd39feac4e3783e9ec080fd64243</div><div id='time'> Time: 2022-03-22</div><div id='author'> Author: cwq1913@gmail.com</div><div id='file'> File Name: lama_cleaner/lama/__init__.py</div><div id='m_class'> M Class Name: LaMa</div><div id='n_method'> N Class Name: LaMa</div><div id='m_method'> M Method Name: __call__(3)</div><div id='n_method'> N Method Name: __call__(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: lama_cleaner/lama/__init__.py</div><div id='n_file'> N File Name: lama_cleaner/lama/__init__.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 55</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 65</div><BR>