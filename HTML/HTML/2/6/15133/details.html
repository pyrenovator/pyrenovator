<html><h3>Pattern ID :15133
</h3><img src='51327020.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        with self.memory_cache.use_cache(attention_cache_handle) as cache:
            print(&quotMETADATA:&quot, cache_metadata, "CACHE", cache.mean(), "CACHE ENTRIES:", len(self.memory_cache._allocated_tensors))
            cache[...] += 1
            <a id="change">return </a>(inputs[0] + cache.flatten()[0]<a id="change"></a>,)

    def get_pools(self) -&gt; Sequence[TaskPool]:
        return self.forward_pool, self.backward_pool, self.inference_pool</code></pre><h3>After Change</h3><pre><code class='java'>
            assert isinstance(self.module, BloomBlock) and cache.shape[0] == 2 and cache.ndim == 5
            layer_past = past_k, past_v = cache[0, :, :prefix_length], cache[1, :, :prefix_length]
            print(past_k.shape, past_v.shape)
            hidden_states<a id="change">, (new_k, new_v) = </a><a id="change">self.module.forward(hidden_states</a><a id="change">, layer_past=layer_past, use_cache=True)</a>


            &#47&#47 todo remove these debugprints
            new_length = new_v.shape[1]
            assert new_length &gt; prefix_length
            assert new_k.shape[0] == past_k.shape[0] and new_v.shape[0] == past_v.shape[0]
            assert new_k.shape[1] == new_length and new_v.shape[1] == new_length
            assert new_k.shape[2:] == past_k.shape[2:] and new_v.shape[2:] == past_v.shape[2:]
            assert torch.allclose(new_v[:, :past_v.shape[1]], past_v)
            assert torch.allclose(new_k[:, :past_k.shape[1]], past_k)
            cache[0, :, prefix_length: new_length, :] = new_k[:, prefix_length : new_length]
            cache[1, :, prefix_length: new_length, :] = new_v[:, prefix_length: new_length]
            return (<a id="change">hidden_states</a>,)

    def get_pools(self) -&gt; Sequence[TaskPool]:
        return self.forward_pool, self.backward_pool, self.inference_pool</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/bigscience-workshop/distributed-bloom/commit/33358bc52b91b452f26e87a653aae8fec88787ab#diff-2e1d320aa2c8e999003e1c5d13022ac3c54664133b82d112204c59dc2b6ed053L30' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 51327020</div><div id='project'> Project Name: bigscience-workshop/distributed-bloom</div><div id='commit'> Commit Name: 33358bc52b91b452f26e87a653aae8fec88787ab</div><div id='time'> Time: 2022-06-19</div><div id='author'> Author: justheuristic@gmail.com</div><div id='file'> File Name: src/server/backend.py</div><div id='m_class'> M Class Name: TransformerBackend</div><div id='n_method'> N Class Name: TransformerBackend</div><div id='m_method'> M Method Name: inference_step(2)</div><div id='n_method'> N Method Name: inference_step(2)</div><div id='m_parent_class'> M Parent Class: ModuleBackend</div><div id='n_parent_class'> N Parent Class: ModuleBackend</div><div id='m_file'> M File Name: src/server/backend.py</div><div id='n_file'> N File Name: src/server/backend.py</div><div id='m_start'> M Start Line: 32</div><div id='m_end'> M End Line: 37</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 54</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        with self.memory_cache.use_cache(attention_cache_handle) as cache:
            print(&quotMETADATA:&quot, cache_metadata, "CACHE", cache.mean(), "CACHE ENTRIES:", len(self.memory_cache._allocated_tensors))
            cache[...] += 1
            <a id="change">return </a>(inputs[0] + cache.flatten()[0]<a id="change"></a>,)

    def get_pools(self) -&gt; Sequence[TaskPool]:
        return self.forward_pool, self.backward_pool, self.inference_pool</code></pre><h3>After Change</h3><pre><code class='java'>
            assert isinstance(self.module, BloomBlock) and cache.shape[0] == 2 and cache.ndim == 5
            layer_past = past_k, past_v = cache[0, :, :prefix_length], cache[1, :, :prefix_length]
            print(past_k.shape, past_v.shape)
            hidden_states<a id="change">, (new_k, new_v) = </a><a id="change">self.module.forward(</a>hidden_states<a id="change">, layer_past=layer_past, use_cache=True)</a>


            &#47&#47 todo remove these debugprints
            new_length = new_v.shape[1]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bigscience-workshop/distributed-bloom/commit/33358bc52b91b452f26e87a653aae8fec88787ab#diff-2e1d320aa2c8e999003e1c5d13022ac3c54664133b82d112204c59dc2b6ed053L29' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 51327019</div><div id='project'> Project Name: bigscience-workshop/distributed-bloom</div><div id='commit'> Commit Name: 33358bc52b91b452f26e87a653aae8fec88787ab</div><div id='time'> Time: 2022-06-19</div><div id='author'> Author: justheuristic@gmail.com</div><div id='file'> File Name: src/server/backend.py</div><div id='m_class'> M Class Name: TransformerBackend</div><div id='n_method'> N Class Name: TransformerBackend</div><div id='m_method'> M Method Name: inference_step(2)</div><div id='n_method'> N Method Name: inference_step(2)</div><div id='m_parent_class'> M Parent Class: ModuleBackend</div><div id='n_parent_class'> N Parent Class: ModuleBackend</div><div id='m_file'> M File Name: src/server/backend.py</div><div id='n_file'> N File Name: src/server/backend.py</div><div id='m_start'> M Start Line: 32</div><div id='m_end'> M End Line: 37</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 54</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            target = self.target[index]

        self.check_completeness(False)
        <a id="change">return </a>frame<a id="change">, target, index</a>


class UnsupervisedDataset(Dataset):
    def __init__(self, extent, frames, multi_frame_output=True):</code></pre><h3>After Change</h3><pre><code class='java'>
            em_tar = self.em_tar[index]

        self.check_completeness(False)
        em_tar<a id="change">, _ = </a><a id="change">self.target_generator_gt.forward(</a>em_tar<a id="change">)</a>
        return frame, target, em_tar, index


class UnsupervisedDataset(Dataset):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/turagalab/decode/commit/76fdb7cb7b6d0955b7276439dac11d03e271e104#diff-ada64902b98e0ef5b5ac72d023e6b46f4921556f320a298897923a817b5eb9d2L147' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 51327017</div><div id='project'> Project Name: turagalab/decode</div><div id='commit'> Commit Name: 76fdb7cb7b6d0955b7276439dac11d03e271e104</div><div id='time'> Time: 2019-04-03</div><div id='author'> Author: gitdev@LRM.photo</div><div id='file'> File Name: deepsmlm/neuralfitter/dataset.py</div><div id='m_class'> M Class Name: SMLMDatasetOnFly</div><div id='n_method'> N Class Name: SMLMDatasetOnFly</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: deepsmlm/neuralfitter/dataset.py</div><div id='n_file'> N File Name: deepsmlm/neuralfitter/dataset.py</div><div id='m_start'> M Start Line: 158</div><div id='m_end'> M End Line: 158</div><div id='n_start'> N Start Line: 157</div><div id='n_end'> N End Line: 168</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            self.correlated_mask
            ].view(2 * batch_size, -1)

        logits = torch.cat((positives<a id="change">, negatives</a>), dim=1)
        logits /= self.temperature

        labels = torch.zeros(2 * batch_size).long()

        loss = self.cross_entropy(logits, labels.to(device))
        <a id="change">return </a>loss / (2 * batch_size)
</code></pre><h3>After Change</h3><pre><code class='java'>
        batch_size = batch_size // 2

        &#47&#47 ask memory bank for negative samples
        output<a id="change">, negatives = </a><a id="change">super(NTXentLoss, self).forward(</a>output<a id="change">)</a>
        &#47&#47 normalize the output to length 1
        output = torch.nn.functional.normalize(output, dim=1)

        if negatives is not None:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lightly-ai/lightly/commit/1157f1a371bc4f7d17ef2795e4410004e9261005#diff-19edf044f7ec91383832f752a1cf86e0c59614eab625991ff93d9bb297d2ed13L79' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 51327015</div><div id='project'> Project Name: lightly-ai/lightly</div><div id='commit'> Commit Name: 1157f1a371bc4f7d17ef2795e4410004e9261005</div><div id='time'> Time: 2020-10-20</div><div id='author'> Author: philipp.m.wirth@gmail.com</div><div id='file'> File Name: lightly/loss/ntx_ent_loss.py</div><div id='m_class'> M Class Name: NTXentLoss</div><div id='n_method'> N Class Name: NTXentLoss</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: MemoryBankModule</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: lightly/loss/ntx_ent_loss.py</div><div id='n_file'> N File Name: lightly/loss/ntx_ent_loss.py</div><div id='m_start'> M Start Line: 95</div><div id='m_end'> M End Line: 127</div><div id='n_start'> N Start Line: 100</div><div id='n_end'> N End Line: 144</div><BR>