<html><h3>Pattern ID :11728
</h3><img src='39548765.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        print(f"Processing `{os.path.abspath(hr_image_path)}`...")
        &#47&#47 Make low-resolution images.
        lr_image = <a id="change">Image.open(</a>lr_image_path<a id="change">)</a>.convert("RGB")
        hr_image = Image.open(hr_image_path).convert("RGB")
        bic_image = lr_image.resize([hr_image.width, hr_image.height], Image.BICUBIC)

        &#47&#47 Extract Y channel lr image data.
        lr_image = np.array(lr_image).astype(np.float32)
        lr_ycbcr = imgproc.convert_rgb_to_ycbcr(lr_image)
        lr_image_y = lr_ycbcr[..., 0]
        lr_image_y /= 255.
        lr_tensor_y = torch.from_numpy(lr_image_y).to(config.device).unsqueeze(0).unsqueeze(0)
        lr_tensor_y<a id="change"> = </a>lr_tensor_y.half()

        &#47&#47 Extract Y channel bicubic image data.
        bic_image = np.array(bic_image).astype(np.float32)
        bic_ycbcr = imgproc.convert_rgb_to_ycbcr(bic_image)

        &#47&#47 Extract Y channel hr image data.
        hr_image = np.array(hr_image).astype(np.float32)
        hr_ycbcr = imgproc.convert_rgb_to_ycbcr(hr_image)
        hr_image_y = hr_ycbcr[..., 0]
        hr_image_y /= 255.
        hr_tensor_y = torch.from_numpy(hr_image_y).to(config.device).unsqueeze(0).unsqueeze(0)
        hr_tensor_y<a id="change"> = </a>hr_tensor_y.half()

        &#47&#47 Only reconstruct the Y channel image data.
        with torch.no_grad():</code></pre><h3>After Change</h3><pre><code class='java'>
        hr_image = Image.open(hr_image_path).convert("RGB")
        hr_image_width = hr_image.width // config.upscale_factor * config.upscale_factor
        hr_image_height = hr_image.height // config.upscale_factor * config.upscale_factor
        hr_image<a id="change"> = </a>hr_image.resize(<a id="change">[</a>hr_image_width, hr_image_height<a id="change"></a>], Image.BICUBIC)

        lr_image = hr_image.resize([hr_image.width // config.upscale_factor, hr_image.height // config.upscale_factor], Image.BICUBIC)
        bic_image = lr_image.resize([hr_image.width, hr_image.height], Image.BICUBIC)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lornatang/fsrcnn-pytorch/commit/5a0ecdd432cc264e98e446689348e5565a84ac1f#diff-58b7fc05c0526d9a9b3c0b50dda416fcbf0a654e696da4b6df82cbb5a6b2dcfcL53' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39548765</div><div id='project'> Project Name: lornatang/fsrcnn-pytorch</div><div id='commit'> Commit Name: 5a0ecdd432cc264e98e446689348e5565a84ac1f</div><div id='time'> Time: 2021-11-19</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: validate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: validate.py</div><div id='n_file'> N File Name: validate.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 95</div><div id='n_start'> N Start Line: 63</div><div id='n_end'> N End Line: 98</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

def load_velo_scan(basepath, file, binary=True):
    Load and parse a kitti point cloud file. Accept path or file object as basepath
    if <a id="change">binary</a>:
        if isinstance(basepath, (str, Path)):
            scan = np.fromfile(Path(basepath, file), dtype=np.float32)
        else:
            with basepath.open(str(file)) as fin:
                buffer = fin.read()
            scan = np.frombuffer(buffer, dtype=np.float32)
    else:
        if isinstance(basepath, (str, Path)):
            scan<a id="change"> = </a>np.loadtxt(Path(basepath, file), dtype=np.float32)
        else:
            scan<a id="change"> = </a>np.loadtxt(<a id="change">basepath.open(</a>str(file)<a id="change">)</a>, dtype=np.float32)
    return scan.reshape((-1, 4))

&#47&#47 ===== Raw data tracklets =====</code></pre><h3>After Change</h3><pre><code class='java'>

    if not formatted:
        return scan
    columns<a id="change"> = </a><a id="change">[</a>&quotx&quot, &quoty&quot, &quotz&quot, &quotintensity&quot<a id="change"></a>]
    return scan.view([(c, &quotf4&quot) for c in columns])

&#47&#47 ===== Raw data tracklets =====</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/cmpute/d3d/commit/38b8e060f76ecd1c9a479b3bfe2d91a76c5b86dd#diff-65d4024f6981a49b3b905c76bc74ae8aef84c743c60a375ec3ee6bc2a3210faeL333' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39548875</div><div id='project'> Project Name: cmpute/d3d</div><div id='commit'> Commit Name: 38b8e060f76ecd1c9a479b3bfe2d91a76c5b86dd</div><div id='time'> Time: 2021-08-26</div><div id='author'> Author: cmpute@gmail.com</div><div id='file'> File Name: d3d/dataset/kitti/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: load_velo_scan(3)</div><div id='n_method'> N Method Name: load_velo_scan(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: d3d/dataset/kitti/utils.py</div><div id='n_file'> N File Name: d3d/dataset/kitti/utils.py</div><div id='m_start'> M Start Line: 335</div><div id='m_end'> M End Line: 347</div><div id='n_start'> N Start Line: 335</div><div id='n_end'> N End Line: 346</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 Get the number of test image files.
    total_files = len(file_names)

    for <a id="change">index</a> in range(total_files):
        lr_image_path = os.path.join(config.lr_dir, file_names[index])
        sr_image_path = os.path.join(config.sr_dir, file_names[index])
        hr_image_path = os.path.join(config.hr_dir, file_names[index])

        print(f"Processing `{os.path.abspath(hr_image_path)}`...")
        &#47&#47 Make low-resolution images.
        lr_image = <a id="change">Image.open(</a>lr_image_path<a id="change">)</a>.convert("RGB")
        hr_image = Image.open(hr_image_path).convert("RGB")
        bic_image = lr_image.resize([hr_image.width, hr_image.height], Image.BICUBIC)

        &#47&#47 Extract Y channel lr image data.
        lr_image = np.array(lr_image).astype(np.float32)
        lr_ycbcr = imgproc.convert_rgb_to_ycbcr(lr_image)
        lr_image_y = lr_ycbcr[..., 0]
        lr_image_y /= 255.
        lr_tensor_y = torch.from_numpy(lr_image_y).to(config.device).unsqueeze(0).unsqueeze(0)
        lr_tensor_y = lr_tensor_y.half()

        &#47&#47 Extract Y channel bicubic image data.
        bic_image<a id="change"> = </a>np.array(bic_image).astype(np.float32)
        bic_ycbcr = imgproc.convert_rgb_to_ycbcr(bic_image)

        &#47&#47 Extract Y channel hr image data.
        hr_image = np.array(hr_image).astype(np.float32)
        hr_ycbcr = imgproc.convert_rgb_to_ycbcr(hr_image)
        hr_image_y = hr_ycbcr[..., 0]
        hr_image_y<a id="change"> /= </a>255.
        hr_tensor_y = torch.from_numpy(hr_image_y).to(config.device).unsqueeze(0).unsqueeze(0)
        hr_tensor_y = hr_tensor_y.half()
</code></pre><h3>After Change</h3><pre><code class='java'>
        image = Image.open(hr_image_path).convert("RGB")
        image_width = (image.width // config.upscale_factor) * config.upscale_factor
        image_height = (image.height // config.upscale_factor) * config.upscale_factor
        image<a id="change"> = </a>image.resize(<a id="change">[</a>image_width, image_height<a id="change"></a>], Image.BICUBIC)
        image = image.resize([image.width // config.upscale_factor, image.height // config.upscale_factor], Image.BICUBIC)
        image = image.resize([image.width * config.upscale_factor, image.height * config.upscale_factor], Image.BICUBIC)
        &#47&#47 Extract Y channel image data.</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/vdsr-pytorch/commit/a74f59d38f5d880febe1040548b5865af385e8db#diff-58b7fc05c0526d9a9b3c0b50dda416fcbf0a654e696da4b6df82cbb5a6b2dcfcL27' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39548793</div><div id='project'> Project Name: lornatang/vdsr-pytorch</div><div id='commit'> Commit Name: a74f59d38f5d880febe1040548b5865af385e8db</div><div id='time'> Time: 2021-11-17</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: validate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: validate.py</div><div id='n_file'> N File Name: validate.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 63</div><div id='n_end'> N End Line: 84</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 Get the number of test image files.
    total_files = len(file_names)

    for <a id="change">index</a> in range(total_files):
        lr_image_path = os.path.join(config.lr_dir, file_names[index])
        sr_image_path = os.path.join(config.sr_dir, file_names[index])
        hr_image_path = os.path.join(config.hr_dir, file_names[index])

        print(f"Processing `{os.path.abspath(hr_image_path)}`...")
        &#47&#47 Make low-resolution images.
        lr_image = <a id="change">Image.open(</a>lr_image_path<a id="change">)</a>.convert("RGB")
        hr_image = Image.open(hr_image_path).convert("RGB")
        bic_image = lr_image.resize([hr_image.width, hr_image.height], Image.BICUBIC)

        &#47&#47 Extract Y channel lr image data.
        lr_image = np.array(lr_image).astype(np.float32)
        lr_ycbcr = imgproc.convert_rgb_to_ycbcr(lr_image)
        lr_image_y = lr_ycbcr[..., 0]
        lr_image_y /= 255.
        lr_tensor_y = torch.from_numpy(lr_image_y).to(config.device).unsqueeze(0).unsqueeze(0)
        lr_tensor_y<a id="change"> = </a>lr_tensor_y.half()

        &#47&#47 Extract Y channel bicubic image data.
        bic_image = np.array(bic_image).astype(np.float32)
        bic_ycbcr = imgproc.convert_rgb_to_ycbcr(bic_image)

        &#47&#47 Extract Y channel hr image data.
        hr_image = np.array(hr_image).astype(np.float32)
        hr_ycbcr = imgproc.convert_rgb_to_ycbcr(hr_image)
        hr_image_y = hr_ycbcr[..., 0]
        hr_image_y /= 255.
        hr_tensor_y = torch.from_numpy(hr_image_y).to(config.device).unsqueeze(0).unsqueeze(0)
        hr_tensor_y = hr_tensor_y.half()

        &#47&#47 Only reconstruct the Y channel image data.
        with torch.no_grad():
            sr_tensor_y = model(lr_tensor_y)

        &#47&#47 Cal PSNR
        total_psnr += 10. * torch.log10(1. / torch.mean((sr_tensor_y - hr_tensor_y) ** 2))

        sr_image_y<a id="change"> = </a>sr_tensor_y.mul_(255.0).cpu().squeeze_(0).squeeze_(0).numpy()
        sr_image = np.array([sr_image_y, bic_ycbcr[..., 1], bic_ycbcr[..., 2]]).transpose([1, 2, 0])
        sr_image = np.clip(imgproc.convert_ycbcr_to_rgb(sr_image), 0.0, 255.0).astype(np.uint8)
        sr_image = Image.fromarray(sr_image)</code></pre><h3>After Change</h3><pre><code class='java'>
        hr_image = Image.open(hr_image_path).convert("RGB")
        hr_image_width = hr_image.width // config.upscale_factor * config.upscale_factor
        hr_image_height = hr_image.height // config.upscale_factor * config.upscale_factor
        hr_image<a id="change"> = </a>hr_image.resize(<a id="change">[</a>hr_image_width, hr_image_height<a id="change"></a>], Image.BICUBIC)

        lr_image = hr_image.resize([hr_image.width // config.upscale_factor, hr_image.height // config.upscale_factor], Image.BICUBIC)
        bic_image = lr_image.resize([hr_image.width, hr_image.height], Image.BICUBIC)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/fsrcnn-pytorch/commit/5a0ecdd432cc264e98e446689348e5565a84ac1f#diff-58b7fc05c0526d9a9b3c0b50dda416fcbf0a654e696da4b6df82cbb5a6b2dcfcL27' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39548764</div><div id='project'> Project Name: lornatang/fsrcnn-pytorch</div><div id='commit'> Commit Name: 5a0ecdd432cc264e98e446689348e5565a84ac1f</div><div id='time'> Time: 2021-11-19</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: validate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: validate.py</div><div id='n_file'> N File Name: validate.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 95</div><div id='n_start'> N Start Line: 63</div><div id='n_end'> N End Line: 98</div><BR>