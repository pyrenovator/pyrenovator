<html><h3>Pattern ID :28329
</h3><img src='83613071.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                    out.log_softmax(dim=-1).view(-1), k=beam, dim=-1
                )
                best_logp = (
                    logp_targets[0]<a id="change">
                    if positions[0] != blank_id</a><a id="change">
                    else </a>logp_targets[1]
                )
                &#47&#47 Extend hyp by  selection
                for j in range(logp_targets.size(0)):</code></pre><h3>After Change</h3><pre><code class='java'>
                best_logp = logp_targets[0]

                &#47&#47 concat blank_id
                logp_targets<a id="change"> = </a>torch.cat((logp_targets, <a id="change">out.view(-1)[0:1]</a>))
                positions = torch.cat(
                    (
                        positions + 1,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/4f184ec4401d29785bf25a773f29facf0a108f82#diff-30ec10b39e03a0e388bd2214e87ed0a72e7187210492b3bfa13bbe5279d8d6c8L449' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83613071</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 4f184ec4401d29785bf25a773f29facf0a108f82</div><div id='time'> Time: 2020-11-03</div><div id='author'> Author: ff936tw@gmail.com</div><div id='file'> File Name: speechbrain/decoders/transducer.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: transducer_beam_search_decode(11)</div><div id='n_method'> N Method Name: transducer_beam_search_decode(11)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: speechbrain/decoders/transducer.py</div><div id='n_file'> N File Name: speechbrain/decoders/transducer.py</div><div id='m_start'> M Start Line: 476</div><div id='m_end'> M End Line: 526</div><div id='n_start'> N Start Line: 449</div><div id='n_end'> N End Line: 534</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if use_anchor_free_mode:
        bbox_process = lambda bb: to_one_hot_with_class_mark(tf.concat([bb[0], tf.cast(tf.expand_dims(bb[1], -1), bb[0].dtype)], axis=-1), num_classes)
    else:
        grid_zero_start = True<a id="change"> if anchor_grid_zero_start == "auto"</a><a id="change"> else </a>anchor_grid_zero_start
        anchors = anchors_func.get_anchors(input_shape[:2], anchor_pyramid_levels, anchor_aspect_ratios, anchor_num_scales, anchor_scale, grid_zero_start)
        num_anchors = anchors.shape[0]
        empty_label = tf.zeros([num_anchors, 4 + num_classes + 1])  &#47&#47 All 0</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Don&quott need anchors here, anchor assigning is after getting model predictions.
        bbox_process = lambda bb: to_one_hot_with_class_mark(tf.concat([bb[0], tf.cast(tf.expand_dims(bb[1], -1), bb[0].dtype)], axis=-1), num_classes)
    elif use_yolor_anchors_mode:
        anchor_ratios<a id="change">, feature_sizes = </a>anchors_func.get_yolor_anchors(<a id="change">input_shape[:2]</a>, anchor_pyramid_levels, is_for_training=True)
        total_anchors = tf.cast(anchor_ratios.shape[1] * tf.reduce_sum(feature_sizes[:, 0] * feature_sizes[:, 1]), tf.int32)
        empty_label = tf.zeros([total_anchors, 4 + num_classes + 1])  &#47&#47 All 0
        bbox_process = lambda bb: __yolor_bboxes_labels_batch_func__(bb[0], bb[1], anchor_ratios, feature_sizes, empty_label, num_classes)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/df3cf1ce0ac4b02a9c73496b1a583b9a892c7b0a#diff-8597d4831067d0150f00219789f341cc39bbce8c375f4b38d9eb20365c723e18L354' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83613068</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: df3cf1ce0ac4b02a9c73496b1a583b9a892c7b0a</div><div id='time'> Time: 2022-03-25</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/coco/data.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: init_dataset(18)</div><div id='n_method'> N Method Name: init_dataset(19)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/coco/data.py</div><div id='n_file'> N File Name: keras_cv_attention_models/coco/data.py</div><div id='m_start'> M Start Line: 363</div><div id='m_end'> M End Line: 425</div><div id='n_start'> N Start Line: 376</div><div id='n_end'> N End Line: 447</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
class UNet3D:
  def __init__(self):
    ups = [16,32,64,128,256]
    self.encoders = [BasicModule(ups[i]<a id="change"> if i != 0</a><a id="change"> else </a>1, ups[i], ups[i+1]) for i in range(4)]
    self.decoders = [BasicModule(ups[-1-i] + ups[-2-i], ups[-2-i], ups[-2-i]) for i in range(3)]
    self.final_conv = nn.Conv2d(32, 1, (1,1,1))
</code></pre><h3>After Change</h3><pre><code class='java'>
    self.input_block = DownsampleBlock(in_channels, filters[0], stride=1)
    self.downsample = [DownsampleBlock(i, o) for i, o in zip(inp, out)]
    self.bottleneck = DownsampleBlock(filters[-1], filters[-1])
    self.upsample<a id="change"> = </a>[UpsampleBlock(filters[-1], filters[-1])] + [UpsampleBlock(i, o) for i, o in zip(out[::-1], <a id="change">inp[::-1]</a>)] 
    self.output = {"conv": nn.Conv2d(filters[0], n_class, kernel_size=(1, 1, 1))}

  def __call__(self, x):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/geohot/tinygrad/commit/5d212864b5d00e537c43c6124bd57cb68284f94e#diff-78a84d6d54d8fb2c4ba59c35d33627d0873217aed7ed836ac667c1d9a6d00271L21' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83613072</div><div id='project'> Project Name: geohot/tinygrad</div><div id='commit'> Commit Name: 5d212864b5d00e537c43c6124bd57cb68284f94e</div><div id='time'> Time: 2023-05-28</div><div id='author'> Author: 39754370+jla524@users.noreply.github.com</div><div id='file'> File Name: models/unet3d.py</div><div id='m_class'> M Class Name: UNet3D</div><div id='n_method'> N Class Name: UNet3D</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: models/unet3d.py</div><div id='n_file'> N File Name: models/unet3d.py</div><div id='m_start'> M Start Line: 21</div><div id='m_end'> M End Line: 25</div><div id='n_start'> N Start Line: 27</div><div id='n_end'> N End Line: 34</div><BR>