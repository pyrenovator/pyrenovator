<html><h3>Pattern ID :1223
</h3><img src='6240191.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.layers = nn.ModuleList([
            GCN(in_dim, hidden_dim, F.relu),
            GCN(hidden_dim, hidden_dim, F.relu)])
        self.classify = <a id="change">nn.Linear(</a>hidden_dim, n_classes<a id="change">)</a>

    def forward(self, g):
        &#47&#47 For undirected graphs, in_degree is the same as
        &#47&#47 out_degree.</code></pre><h3>After Change</h3><pre><code class='java'>

        for i, (name, param) in enumerate(self.config):
            if name is &quotlinear&quot:
                w<a id="change"> = nn</a><a id="change">.Parameter(</a>torch.ones(*param)<a id="change">)</a>
                &#47&#47 gain=1 according to cbfinn&quots implementation
                init.kaiming_normal_(w)
                self.vars.append(w)
                &#47&#47 [ch_out]
                self.vars.append(nn.Parameter(torch.zeros(param[0])))
            if name is &quotGraphConv&quot:
                &#47&#47 param: in_dim, hidden_dim
                w<a id="change"> = nn</a><a id="change">.Parameter(</a>torch.Tensor(param[0], param[1])<a id="change">)</a>
                init.xavier_uniform_(w)
                self.vars.append(w)
                self.vars.append(nn.Parameter(torch.zeros(param[1])))
                self.graph_conv.append(GraphConv(param[0], param[1], activation = F.relu))</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/mims-harvard/g-meta/commit/aed3468b5f71c857f788169b34b97a411628930b#diff-bfc53d3f42fcfc13f05953bcea57cd8efdca40eea6586556bb44b5bda0745717L42' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6240191</div><div id='project'> Project Name: mims-harvard/g-meta</div><div id='commit'> Commit Name: aed3468b5f71c857f788169b34b97a411628930b</div><div id='time'> Time: 2020-03-02</div><div id='author'> Author: cosamhkx@gmail.com</div><div id='file'> File Name: src/learner.py</div><div id='m_class'> M Class Name: Classifier</div><div id='n_method'> N Class Name: Classifier</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/learner.py</div><div id='n_file'> N File Name: src/learner.py</div><div id='m_start'> M Start Line: 42</div><div id='m_end'> M End Line: 48</div><div id='n_start'> N Start Line: 75</div><div id='n_end'> N End Line: 94</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.layers = nn.ModuleList([
            GCN(in_dim, hidden_dim, F.relu),
            GCN(hidden_dim, hidden_dim, F.relu)])
        self.classify = <a id="change">nn.Linear(</a>hidden_dim, n_classes<a id="change">)</a>

    def forward(self, g):
        &#47&#47 For undirected graphs, in_degree is the same as
        &#47&#47 out_degree.</code></pre><h3>After Change</h3><pre><code class='java'>

        for i, (name, param) in enumerate(self.config):
            if name is &quotlinear&quot:
                w<a id="change"> = </a><a id="change">nn.Parameter(</a>torch.ones(*param)<a id="change">)</a>
                &#47&#47 gain=1 according to cbfinn&quots implementation
                init.kaiming_normal_(w)
                self.vars.append(w)
                &#47&#47 [ch_out]
                self.vars.append(nn.Parameter(torch.zeros(param[0])))
            if name is &quotGraphConv&quot:
                &#47&#47 param: in_dim, hidden_dim
                w<a id="change"> = </a><a id="change">nn.Parameter(</a>torch.Tensor(param[0], param[1])<a id="change">)</a>
                init.xavier_uniform_(w)
                self.vars.append(w)
                self.vars.append(nn.Parameter(torch.zeros(param[1])))
                self.graph_conv.append(GraphConv(param[0], param[1], activation = F.relu))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mims-harvard/g-meta/commit/aed3468b5f71c857f788169b34b97a411628930b#diff-bfc53d3f42fcfc13f05953bcea57cd8efdca40eea6586556bb44b5bda0745717L42' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6240190</div><div id='project'> Project Name: mims-harvard/g-meta</div><div id='commit'> Commit Name: aed3468b5f71c857f788169b34b97a411628930b</div><div id='time'> Time: 2020-03-02</div><div id='author'> Author: cosamhkx@gmail.com</div><div id='file'> File Name: src/learner.py</div><div id='m_class'> M Class Name: Classifier</div><div id='n_method'> N Class Name: Classifier</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/learner.py</div><div id='n_file'> N File Name: src/learner.py</div><div id='m_start'> M Start Line: 42</div><div id='m_end'> M End Line: 48</div><div id='n_start'> N Start Line: 75</div><div id='n_end'> N End Line: 94</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.norm_gamma = nn.Parameter(torch.zeros(dim))
        self.norm_beta = nn.Parameter(torch.ones(dim))

        self.proj_in = <a id="change">nn.Linear(</a>dim, dim * mult<a id="change">)</a>
        self.proj_out = nn.Linear(dim * mult, dim)

    def forward(self, x, use_triton = None):
        use_triton = default(use_triton, self.use_triton)</code></pre><h3>After Change</h3><pre><code class='java'>
        self.norm_gamma = nn.Parameter(torch.zeros(dim))
        self.norm_beta = nn.Parameter(torch.ones(dim))

        self.proj_in_weight<a id="change"> = </a><a id="change">nn.Parameter(</a>torch.randn(dim, inner_dim)<a id="change">)</a>
        self.proj_in_bias<a id="change"> = </a><a id="change">nn.Parameter(</a>torch.randn(inner_dim)<a id="change">)</a>
        self.proj_out = nn.Linear(inner_dim, dim)

    def forward(self, x, use_triton = None):
        use_triton = default(use_triton, self.use_triton)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/triton-transformer/commit/72efae6cb8b3c62b501dd5bcf1ab8cfbf684e0cb#diff-efb464e8953d3171bdd3355d448443781f005f551f7281446030316b4157bb28L302' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6240189</div><div id='project'> Project Name: lucidrains/triton-transformer</div><div id='commit'> Commit Name: 72efae6cb8b3c62b501dd5bcf1ab8cfbf684e0cb</div><div id='time'> Time: 2021-09-21</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: triton_transformer/triton_transformer.py</div><div id='m_class'> M Class Name: FeedForward</div><div id='n_method'> N Class Name: FeedForward</div><div id='m_method'> M Method Name: __init__(4)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: triton_transformer/triton_transformer.py</div><div id='n_file'> N File Name: triton_transformer/triton_transformer.py</div><div id='m_start'> M Start Line: 313</div><div id='m_end'> M End Line: 314</div><div id='n_start'> N Start Line: 318</div><div id='n_end'> N End Line: 324</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.transformer = Transformer(dim = dim, **kwargs)

        self.coarse_logits = nn.Linear(dim, codebook_size)
        self.fine_logits = <a id="change">nn.Linear(</a>dim, codebook_size<a id="change">)</a>

    def forward(
        self,
        coarse_token_ids,</code></pre><h3>After Change</h3><pre><code class='java'>
        self.num_coarse_quantizers = num_coarse_quantizers
        self.num_fine_quantizers = num_fine_quantizers

        self.coarse_logit_weights<a id="change"> = </a><a id="change">nn.Parameter(</a>torch.randn(num_coarse_quantizers, codebook_size, dim)<a id="change">)</a>
        self.fine_logit_weights<a id="change"> = </a><a id="change">nn.Parameter(</a>torch.randn(num_fine_quantizers, codebook_size, dim)<a id="change">)</a>

    def forward(
        self,
        coarse_token_ids,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/audiolm-pytorch/commit/0ec7667bed37ddc7955241fbbdbfdc4644b73f07#diff-96a5ee045c1df07f3125d9b4189130620f229785b36cebb86c95b0646f0d744dL578' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6240187</div><div id='project'> Project Name: lucidrains/audiolm-pytorch</div><div id='commit'> Commit Name: 0ec7667bed37ddc7955241fbbdbfdc4644b73f07</div><div id='time'> Time: 2022-11-04</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: audiolm_pytorch/audiolm_pytorch.py</div><div id='m_class'> M Class Name: FineTransformer</div><div id='n_method'> N Class Name: FineTransformer</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: audiolm_pytorch/audiolm_pytorch.py</div><div id='n_file'> N File Name: audiolm_pytorch/audiolm_pytorch.py</div><div id='m_start'> M Start Line: 596</div><div id='m_end'> M End Line: 597</div><div id='n_start'> N Start Line: 599</div><div id='n_end'> N End Line: 603</div><BR>