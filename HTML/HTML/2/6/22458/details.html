<html><h3>Pattern ID :22458
</h3><img src='71023423.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 Need cv2.DMatches
    valid = matches &gt; -1
    zipped = zip(valid, matches[valid])  &#47&#47 zipped indices for img and map kps
    matches = np.array(<a id="change">map(</a>_make_match, zipped<a id="change">)</a>)
    if logger is not None:
        logger.debug(&quotzipped=\n{},\nmatches=\n{}.&quot.format(zipped, matches))  &#47&#47 TODO: remove this
</code></pre><h3>After Change</h3><pre><code class='java'>
    h, w = img.shape

    &#47&#47 Make a list of matches
    matches<a id="change"> = </a><a id="change">[]</a>
    <a id="change">for </a>i in range(0, len(kp_img))<a id="change">:
        </a><a id="change">matches.append(</a>cv2.DMatch(i, i, 0)<a id="change">)</a>  &#47&#47 TODO: implement better, e.g. use _make_match helper
    matches = np.array(matches)

    &#47&#47 Need cv2.KeyPoints for kps (assumed to be numpy arrays)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/hmakelin/gisnav/commit/285469b7fb52791ba46a92841b36bbb5543b2212#diff-ed2d848d4c939e8139b5f64803732c50c8aca3c2d58f9ad11b84cf31377f68bcL102' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 71023423</div><div id='project'> Project Name: hmakelin/gisnav</div><div id='commit'> Commit Name: 285469b7fb52791ba46a92841b36bbb5543b2212</div><div id='time'> Time: 2021-10-07</div><div id='author'> Author: hmakelin@protonmail.com</div><div id='file'> File Name: wms_map_matching/util.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: visualize_homography(8)</div><div id='n_method'> N Method Name: visualize_homography(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: wms_map_matching/util.py</div><div id='n_file'> N File Name: wms_map_matching/util.py</div><div id='m_start'> M Start Line: 105</div><div id='m_end'> M End Line: 118</div><div id='n_start'> N Start Line: 102</div><div id='n_end'> N End Line: 132</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for index, vocab in list(zip(range(0, len(self.vocab)), self.vocab)):
            self.vocab_dict[vocab] = index

        self.index_dd = np.array(list(<a id="change">map(</a>lambda y: np.array(list(map(lambda x:
                                                                      self.vocab_dict[x], y.split()))), data<a id="change">)</a>))
        self.idx2token = {v: k for (k, v) in self.vocab_dict.items()}
        self.bow = get_bag_of_words(self.index_dd, len(self.vocab))
</code></pre><h3>After Change</h3><pre><code class='java'>
    def prepare(self):
        indptr = [0]
        indices = []
        data<a id="change"> = </a><a id="change">[]</a>
        vocabulary = {}
        with open(self.file_name, "r") as filino:
            docs = filino.readlines()

        for d in docs:
            <a id="change">for term</a> in d.split()<a id="change">:
                </a>index = vocabulary.setdefault(term, len(vocabulary))
                indices.append(index)
                <a id="change">data.append(</a>1<a id="change">)</a>
            indptr.append(len(indices))

        self.vocab_dict = vocabulary
        self.vocab = list(vocabulary.keys())</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/milanlproc/contextualized-topic-models/commit/06e8fbee8e3be72841f4aac15b1f43bd6821ffee#diff-813e19406d3b9c72a61d20ce9f3f2ed01d03dc520c0be9128b082189bd2fc617L47' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 71023422</div><div id='project'> Project Name: milanlproc/contextualized-topic-models</div><div id='commit'> Commit Name: 06e8fbee8e3be72841f4aac15b1f43bd6821ffee</div><div id='time'> Time: 2020-07-30</div><div id='author'> Author: s.terragni4@campus.unimib.it</div><div id='file'> File Name: contextualized_topic_models/utils/data_preparation.py</div><div id='m_class'> M Class Name: TextHandler</div><div id='n_method'> N Class Name: TextHandler</div><div id='m_method'> M Method Name: prepare(1)</div><div id='n_method'> N Method Name: prepare(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: contextualized_topic_models/utils/data_preparation.py</div><div id='n_file'> N File Name: contextualized_topic_models/utils/data_preparation.py</div><div id='m_start'> M Start Line: 48</div><div id='m_end'> M End Line: 64</div><div id='n_start'> N Start Line: 51</div><div id='n_end'> N End Line: 68</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

def shift_tokens(x, amt):
    *x, x_pass = x.chunk(amt + 1, dim = -1)
    x = tuple(<a id="change">map(</a>lambda args: shift(*args), zip(x, range(0, amt + 1))<a id="change">)</a>)
    return torch.cat((*x, x_pass), dim = -1)

&#47&#47 helper classes</code></pre><h3>After Change</h3><pre><code class='java'>
    amts = 2 ** torch.arange(amt)
    amts = amts.tolist()

    shifts<a id="change"> = </a><a id="change">[]</a>
    denom = torch.arange(n, device = device)

    <a id="change">for </a>x_chunk, x_cumsum_chunk, <a id="change">amt</a> in zip(x, x_cumsum, amts)<a id="change">:
        </a>shifted_chunk = shift(x_cumsum_chunk, amt, dim = -2) - shift(x_cumsum_chunk, 2 * amt, dim = -2)
        shifted_denom = shift(denom, amt, dim = -1) - shift(denom, 2 * amt, dim = -1)
        shifted_denom = rearrange(shifted_denom, &quotn -&gt; () n ()&quot)
        normed_shifted_x = shifted_chunk /  (shifted_denom + eps)
        <a id="change">shifts.append(</a>normed_shifted_x<a id="change">)</a>

    return torch.cat((*shifts, x_pass), dim = -1)

&#47&#47 helper classes</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/token-shift-gpt/commit/ee7f1bcc4e0dae69d1cccb5154cbff1020571b9c#diff-9d28469a12c1c7dd01676c75a29143d1072db0101c18effa867e68aae8543075L15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 71023426</div><div id='project'> Project Name: lucidrains/token-shift-gpt</div><div id='commit'> Commit Name: ee7f1bcc4e0dae69d1cccb5154cbff1020571b9c</div><div id='time'> Time: 2021-08-17</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: token_shift_gpt/token_shift_gpt.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: shift_tokens(3)</div><div id='n_method'> N Method Name: shift_tokens(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: token_shift_gpt/token_shift_gpt.py</div><div id='n_file'> N File Name: token_shift_gpt/token_shift_gpt.py</div><div id='m_start'> M Start Line: 17</div><div id='m_end'> M End Line: 18</div><div id='n_start'> N Start Line: 16</div><div id='n_end'> N End Line: 36</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    ids = np.concatenate(list(
        ds.map(lambda example: example[&quotexample_id&quot]).batch(
            batch_size).as_numpy_iterator())).tolist()
    ids = list(<a id="change">map(</a>lambda x: x.decode(&quotUTF-8&quot), ids<a id="change">)</a>)
    subgroup_labels = list(
        ds.map(lambda example: example[&quotsubgroup_label&quot]).batch(
            batch_size).as_numpy_iterator())</code></pre><h3>After Change</h3><pre><code class='java'>
    num_subgroups: int,
    ) -&gt; pd.DataFrame:
  Evaluates model for subgroup representation vs number of rounds.
  round_idx<a id="change"> = </a><a id="change">[]</a>
  subgroup_ids = []
  num_samples = []
  prob_representation = []
  for idx in range(num_rounds):
    ds = dataloader.train_ds
    bias_table = pd.read_csv(
        os.path.join(
            os.path.join(output_dir, f&quotround_{idx}&quot), &quotbias_table.csv&quot))
    predictions_merge = merge_subgroup_labels(ds, bias_table, batch_size)
    <a id="change">for subgroup_id</a> in range(num_subgroups)<a id="change">:
      </a>prob_i = (predictions_merge[&quotsubgroup_label&quot]
                == subgroup_id).sum() / len(predictions_merge)
      <a id="change">round_idx.append(</a>idx<a id="change">)</a>
      subgroup_ids.append(subgroup_id)
      num_samples.append(len(predictions_merge))
      prob_representation.append(prob_i)
  return pd.DataFrame({</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/google/uncertainty-baselines/commit/f5b53459d654b40668528e806a24776b53864278#diff-898a1ff69c9d70117cfb7c75da053a4e8649b705ffef48bf652f1c38fc3a5858L26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 71023425</div><div id='project'> Project Name: google/uncertainty-baselines</div><div id='commit'> Commit Name: f5b53459d654b40668528e806a24776b53864278</div><div id='time'> Time: 2022-11-03</div><div id='author'> Author: no-reply@google.com</div><div id='file'> File Name: experimental/shoshin/evaluate_model_lib.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate_active_sampling(5)</div><div id='n_method'> N Method Name: evaluate_active_sampling(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: experimental/shoshin/evaluate_model_lib.py</div><div id='n_file'> N File Name: experimental/shoshin/evaluate_model_lib.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 59</div><div id='n_start'> N Start Line: 68</div><div id='n_end'> N End Line: 92</div><BR>