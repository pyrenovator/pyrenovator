<html><h3>Pattern ID :18715
</h3><img src='60915457.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        :param batch_idx: the index of the batch
        :return loss: (1,); the train_loss for this batch
        
        <a id="change">raise </a>NotImplementedError

    def forward(self, X: torch.Tensor) -&gt; torch.Tensor:
        </code></pre><h3>After Change</h3><pre><code class='java'>

    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -&gt; dict:
        X, y = batch
        H_all<a id="change"> = </a><a id="change">self.forward(</a>X<a id="change">)</a>  &#47&#47 (N, 3, L) -&gt; (N, L, H)
        S_wisdom<a id="change"> = </a>self.S_wisdom(H_all)  &#47&#47 (N, L, H) -&gt; (N, |W|)
        loss<a id="change"> = </a>F.cross_entropy(S_wisdom, y)  &#47&#47 (N, |W|), (N,) -&gt; (N,)
        loss<a id="change"> = </a>loss.sum()  &#47&#47 (N,) -&gt; (1,)
        P_wisdom = F.softmax(S_wisdom, dim=1)  &#47&#47 (N, |W|) -&gt; (N, |W|)
        self.rd_metric.update(preds=P_wisdom, targets=y)
        median, var, top1, top10, top100 = self.rd_metric.compute()</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/eubinecto/wisdomify/commit/bb66a843111e861b36bb8b32127c63054566f542#diff-86d43b8e4dab7b553061ad3ccb15d2a9d27256d76cad0e3028e375d8bcd64883L51' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60915457</div><div id='project'> Project Name: eubinecto/wisdomify</div><div id='commit'> Commit Name: bb66a843111e861b36bb8b32127c63054566f542</div><div id='time'> Time: 2021-10-02</div><div id='author'> Author: eubinecto</div><div id='file'> File Name: wisdomify/rds.py</div><div id='m_class'> M Class Name: RD</div><div id='n_method'> N Class Name: RD</div><div id='m_method'> M Method Name: training_step(3)</div><div id='n_method'> N Method Name: training_step(3)</div><div id='m_parent_class'> M Parent Class: pl.LightningModule</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: wisdomify/rds.py</div><div id='n_file'> N File Name: wisdomify/rds.py</div><div id='m_start'> M Start Line: 51</div><div id='m_end'> M End Line: 51</div><div id='n_start'> N Start Line: 51</div><div id='n_end'> N End Line: 66</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        :return: H_all_t: (N, L, H)
        
        &#47&#47 TODO - residual connection, layer norm.
        <a id="change">raise </a>NotImplementedError


class Decoder(torch.nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>
        :param attention_mask: (L,)
        :return: H_x (as-is), H_y (updated), attention_mask (as-is)
        
        Out_<a id="change"> = </a><a id="change">self.masked_multi_head_self_attention_layer\
                   .forward(H_q=H_y, H_k=H_y, H_v=H_y)</a> + H_y
        Out_ = self.norm_1(Out_)
        Out_<a id="change"> = </a>self.multi_head_encoder_decoder_attention_layer.forward(H_q=Out_, H_k=H_x, H_v=H_x) + Out_
        Out_<a id="change"> = </a>self.norm_2(Out_)
        Out_ = self.ffn(Out_)
        Out<a id="change"> = </a>self.norm_3(Out_)  &#47&#47 H_y updated
        return H_x, Out, attention_mask

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/eubinecto/dekorde/commit/6cd311d7d3499fce627b620b64629ef7734776b0#diff-2dba6761c765170d196f72191f7ac0a5df2f5edef503ab286d1f6a35d7e8405bL21' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60915379</div><div id='project'> Project Name: eubinecto/dekorde</div><div id='commit'> Commit Name: 6cd311d7d3499fce627b620b64629ef7734776b0</div><div id='time'> Time: 2021-10-08</div><div id='author'> Author: eubinecto</div><div id='file'> File Name: dekorde/components/decoder.py</div><div id='m_class'> M Class Name: DecoderLayer</div><div id='n_method'> N Class Name: DecoderLayer</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: dekorde/components/decoder.py</div><div id='n_file'> N File Name: dekorde/components/decoder.py</div><div id='m_start'> M Start Line: 21</div><div id='m_end'> M End Line: 29</div><div id='n_start'> N Start Line: 19</div><div id='n_end'> N End Line: 34</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        :return: H_all_x: (N, L, H)
        
        &#47&#47 TODO - residual connection, layer norm.
        <a id="change">raise </a>NotImplementedError


class Encoder(torch.nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>
        :param H_x: (N, L, H), or (N, L, E) if this layer is the first layer.
        :return: H_x: (N, L, H)
        
        Out_<a id="change"> = </a><a id="change">self.multi_head_self_attention_layer.forward(H_q=H_x, H_k=H_x, H_v=H_x)</a> + H_x
        Out_<a id="change"> = </a>self.norm_1(Out_)
        Out_<a id="change"> = </a>self.ffn(Out_) + Out_
        Out<a id="change"> = </a>self.norm_2(Out_)  &#47&#47 this is the new H_x
        return Out  &#47&#47 updated

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/eubinecto/dekorde/commit/6cd311d7d3499fce627b620b64629ef7734776b0#diff-37dd3c88622f0e3474ccb0fa0321052706cd6691ccf00f6ed86a8ccc24840d9fL17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60915125</div><div id='project'> Project Name: eubinecto/dekorde</div><div id='commit'> Commit Name: 6cd311d7d3499fce627b620b64629ef7734776b0</div><div id='time'> Time: 2021-10-08</div><div id='author'> Author: eubinecto</div><div id='file'> File Name: dekorde/components/encoder.py</div><div id='m_class'> M Class Name: EncoderLayer</div><div id='n_method'> N Class Name: EncoderLayer</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: dekorde/components/encoder.py</div><div id='n_file'> N File Name: dekorde/components/encoder.py</div><div id='m_start'> M Start Line: 23</div><div id='m_end'> M End Line: 23</div><div id='n_start'> N Start Line: 20</div><div id='n_end'> N End Line: 24</div><BR>