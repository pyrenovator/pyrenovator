<html><h3>Pattern ID :24434
</h3><img src='75899254.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        sr_image_path = os.path.join(config.sr_dir, file_names[index])
        hr_image_path = os.path.join(config.hr_dir, file_names[index])

        <a id="change">print(f"Processing `{os.path.abspath(hr_image_path)}`..."</a><a id="change">)</a>
        &#47&#47 Make high-resolution image
        hr_image = cv2.imread(hr_image_path).astype(np.float32) / 255.0
        hr_image_height, hr_image_width = hr_image.shape[:2]
        hr_image_height_remainder = hr_image_height % 12</code></pre><h3>After Change</h3><pre><code class='java'>
        lr_image_height, lr_image_width = lr_image.shape[:2]
        lr_image_height_remainder = lr_image_height % config.upscale_factor
        lr_image_width_remainder = lr_image_width % config.upscale_factor
        lr_image<a id="change"> = lr_image[:lr_image_height - lr_image_height_remainder, :lr_image_width - lr_image_width_remainder, ...]</a>
        lr_image = imgproc.imresize(lr_image, 1 / config.upscale_factor)
        lr_image = imgproc.imresize(lr_image, config.upscale_factor)

        &#47&#47 Make high-resolution image</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lornatang/srcnn-pytorch/commit/919c5e6f1c9d9f4b355873199e155b50b2f04104#diff-58b7fc05c0526d9a9b3c0b50dda416fcbf0a654e696da4b6df82cbb5a6b2dcfcL29' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75899254</div><div id='project'> Project Name: lornatang/srcnn-pytorch</div><div id='commit'> Commit Name: 919c5e6f1c9d9f4b355873199e155b50b2f04104</div><div id='time'> Time: 2022-03-17</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: validate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: validate.py</div><div id='n_file'> N File Name: validate.py</div><div id='m_start'> M Start Line: 29</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 51</div><div id='n_end'> N End Line: 75</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

def main() -&gt; None:
    &#47&#47 Initialize the super-resolution model
    <a id="change">print("Build SRCNN model..."</a><a id="change">)</a>
    model = SRCNN().to(config.device)
    print("Build SRCNN model successfully.")

    &#47&#47 Load the super-resolution model weights</code></pre><h3>After Change</h3><pre><code class='java'>

        print(f"Processing `{os.path.abspath(lr_image_path)}`...")
        &#47&#47 Make low-resolution image
        <a id="change">lr_image</a> = cv2.imread(lr_image_path).astype(np.float32) / 255.0
        lr_image_height, lr_image_width = lr_image.shape[:2]
        lr_image_height_remainder = lr_image_height % config.upscale_factor
        lr_image_width_remainder = lr_image_width % config.upscale_factor
        lr_image<a id="change"> = </a><a id="change">lr_image[:lr_image_height - lr_image_height_remainder, :lr_image_width - lr_image_width_remainder, ...]</a>
        lr_image = imgproc.imresize(lr_image, 1 / config.upscale_factor)
        lr_image = imgproc.imresize(lr_image, config.upscale_factor)

        &#47&#47 Make high-resolution image</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/srcnn-pytorch/commit/919c5e6f1c9d9f4b355873199e155b50b2f04104#diff-58b7fc05c0526d9a9b3c0b50dda416fcbf0a654e696da4b6df82cbb5a6b2dcfcL27' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75899252</div><div id='project'> Project Name: lornatang/srcnn-pytorch</div><div id='commit'> Commit Name: 919c5e6f1c9d9f4b355873199e155b50b2f04104</div><div id='time'> Time: 2022-03-17</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: validate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: validate.py</div><div id='n_file'> N File Name: validate.py</div><div id='m_start'> M Start Line: 29</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 51</div><div id='n_end'> N End Line: 75</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>


def sweep_n(ntensor, niter, dtype):
    <a id="change">print("n, dtype, ntensor, gflop, runtime, tflop/s"</a><a id="change">)</a>
    for n in [16, 32, 64, 128, 256, 512, 1024, 2048, 4096]:
        nt_a = torch.nested_tensor(
            [torch.randn(n, n).to(dtype).cuda() for t in range(ntensor)]
        )</code></pre><h3>After Change</h3><pre><code class='java'>
            device="cuda",
        )
        runtime = bench(nt_a, nt_b, niter)
        <a id="change">nt_a_size</a> = torch.ops.aten._nested_tensor_size(nt_a)
        lengths<a id="change"> = </a><a id="change">nt_a_size[:, 1]</a>
        print(",".join(map(str, [ntensor, dtype, lengths.min().item(),
              lengths.float().mean().item(), lengths.max().item(), runtime])))

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/943b20e7ae290d8e71f877eb700f197a9df56cbe#diff-1a0c7c4824948dc09f17a85687fcb71774f4b0084b825189bb69aa3d87804a03L22' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75899250</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 943b20e7ae290d8e71f877eb700f197a9df56cbe</div><div id='time'> Time: 2022-11-02</div><div id='author'> Author: cpuhrsch@fb.com</div><div id='file'> File Name: benchmarks/nested/nested_bmm_bench.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: sweep_n(2)</div><div id='n_method'> N Method Name: sweep_n(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: benchmarks/nested/nested_bmm_bench.py</div><div id='n_file'> N File Name: benchmarks/nested/nested_bmm_bench.py</div><div id='m_start'> M Start Line: 22</div><div id='m_end'> M End Line: 33</div><div id='n_start'> N Start Line: 24</div><div id='n_end'> N End Line: 40</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        img = cv2.resize(img, (32,32))
        img = np.moveaxis(img, -1, 0)
        img = img.astype(&quotfloat32&quot) / 255.0 - 0.5  &#47&#47 normalized and centered
        <a id="change">print(f"DEBUG: Env: captured speed:{speed}"</a><a id="change">)</a>
        speed = speed / 1000.0  &#47&#47 normalized, but not centered
        self.img = img  &#47&#47 for render()
        return img, speed
    </code></pre><h3>After Change</h3><pre><code class='java'>
        apply_control(actions)  &#47&#47 TODO: format this
    
    def grab_img_and_speed(self):
        <a id="change">img</a> = np.asarray(self.sct.grab(self.monitor))[:,:,:3]
        speed = np.array([get_speed(img, self.digits), ], dtype=&quotfloat32&quot)
        img<a id="change"> = </a><a id="change">img[100:-150, :]</a>
        img = cv2.resize(img, (50, 190))
        img = np.moveaxis(img, -1, 0)
        img = img.astype(&quotfloat32&quot) / 255.0 - 0.5  &#47&#47 normalized and centered
        &#47&#47print(f"DEBUG: Env: captured speed:{speed}")</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/trackmania-rl/tmrl/commit/c4118d9f35c2c541c79fe5817adea1e060452fe1#diff-5e27b4719032b9b6e9d192291154df0e3df345d70933f70dfc9dc50c4c07032bL56' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75899251</div><div id='project'> Project Name: trackmania-rl/tmrl</div><div id='commit'> Commit Name: c4118d9f35c2c541c79fe5817adea1e060452fe1</div><div id='time'> Time: 2020-08-01</div><div id='author'> Author: edouard.geze@hotmail.fr</div><div id='file'> File Name: gym-tmrl/gym_tmrl/envs/tmrl_env.py</div><div id='m_class'> M Class Name: TMInterface</div><div id='n_method'> N Class Name: TMInterface</div><div id='m_method'> M Method Name: grab_img_and_speed(1)</div><div id='n_method'> N Method Name: grab_img_and_speed(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: gym-tmrl/gym_tmrl/envs/tmrl_env.py</div><div id='n_file'> N File Name: gym-tmrl/gym_tmrl/envs/tmrl_env.py</div><div id='m_start'> M Start Line: 62</div><div id='m_end'> M End Line: 62</div><div id='n_start'> N Start Line: 57</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    imgs = [imread(file)[..., :3] / 255.0 for file in img_files]
    imgs = np.stack(imgs, axis=-1)

    <a id="change">print("Loaded camera poses, scene bounds, and image data."</a><a id="change">)</a>
    return imgs, poses, z_bounds


def imread(img_file: str) -&gt; np.ndarray:</code></pre><h3>After Change</h3><pre><code class='java'>
    
    &#47&#47 load the camera parameters and scene z-bounds
    poses_raw = np.load(os.path.join(base_dir, "poses_bounds.npy"))
    <a id="change">camera_params</a> = (
        poses_raw[:, :-2].reshape([-1, 3, 5]).transpose([1, 2, 0])
    )  &#47&#47 (N, 15) -&gt; (3, 5, N)
    z_bounds = poses_raw[:, -2:].transpose([1, 0])  &#47&#47 (N, 2) -&gt; (2, N)

    &#47&#47 parse extrinsics and intrinsics
    extrinsics<a id="change"> = </a><a id="change">camera_params[:, :-1, :]</a>  &#47&#47 (3, 4, N)
    intrinsics = camera_params[:, -1, :]  &#47&#47 (3, N)

    img0 = [</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/dvelopery0115/torch-nerf/commit/7880d3f3120e36d298df8cde8c346a8cf69a974b#diff-85d4d56eca066ca08d764c672c1a1920d20cad538ca3c85fe45aba1c7968c5b0L67' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75899248</div><div id='project'> Project Name: dvelopery0115/torch-nerf</div><div id='commit'> Commit Name: 7880d3f3120e36d298df8cde8c346a8cf69a974b</div><div id='time'> Time: 2022-06-30</div><div id='author'> Author: dreamy1534@kaist.ac.kr</div><div id='file'> File Name: torch_nerf/src/utils/data/load_llff.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _load_data(4)</div><div id='n_method'> N Method Name: _load_data(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torch_nerf/src/utils/data/load_llff.py</div><div id='n_file'> N File Name: torch_nerf/src/utils/data/load_llff.py</div><div id='m_start'> M Start Line: 69</div><div id='m_end'> M End Line: 140</div><div id='n_start'> N Start Line: 69</div><div id='n_end'> N End Line: 170</div><BR>