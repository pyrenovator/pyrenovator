<html><h3>Pattern ID :12196
</h3><img src='41333570.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    print("Initializing model: {}".format(args.arch))
    model = models.init_model(name=args.arch, num_classes=dataset.num_train_pids, loss={&quotxent&quot}, use_gpu=use_gpu)
    print("Model size: {:.5f}M".format(sum(p.numel() for p in <a id="change">model.parameters()</a>)/1000000.0))

    criterion = CrossEntropyLabelSmooth(num_classes=dataset.num_train_pids, use_gpu=use_gpu)
    optimizer = init_optim(args.optim, model.parameters(), args.lr, args.weight_decay)</code></pre><h3>After Change</h3><pre><code class='java'>
        print("Train classifier for {} epochs while keeping base network frozen".format(args.fixbase_epoch))

        for epoch in range(args.fixbase_epoch):
            start_train_time<a id="change"> = time</a><a id="change">.time()</a>
            train(epoch, model, criterion, optimizer_tmp, trainloader, use_gpu, freeze_bn=True)
            train_time += round(<a id="change">time.time()</a> - start_train_time)

        del optimizer_tmp
        print("Now open all layers for training")</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/vlsomers/bpbreid/commit/b88d36cd9c8056e15607a40f5d10a9072ab84b22#diff-da7ad75a94e9cad37a1620619fb9b62dc9ca1760acdab2b811be171463c78966L105' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41333570</div><div id='project'> Project Name: vlsomers/bpbreid</div><div id='commit'> Commit Name: b88d36cd9c8056e15607a40f5d10a9072ab84b22</div><div id='time'> Time: 2018-07-06</div><div id='author'> Author: k.zhou@qmul.ac.uk</div><div id='file'> File Name: train_imgreid_xent.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_imgreid_xent.py</div><div id='n_file'> N File Name: train_imgreid_xent.py</div><div id='m_start'> M Start Line: 158</div><div id='m_end'> M End Line: 159</div><div id='n_start'> N Start Line: 105</div><div id='n_end'> N End Line: 207</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    print("Initializing model: {}".format(args.arch))
    model = models.init_model(name=args.arch, num_classes=dataset.num_train_pids, loss={&quotxent&quot})
    print("Model size: {:.5f}M".format(sum(p.numel() for p in <a id="change">model.parameters()</a>)/1000000.0))

    criterion = CrossEntropyLabelSmooth(num_classes=dataset.num_train_pids, use_gpu=use_gpu)
    optimizer = init_optim(args.optim, model.parameters(), args.lr, args.weight_decay)</code></pre><h3>After Change</h3><pre><code class='java'>
    if args.fixbase_epoch &gt; 0:
        print("Train classifier for {} epochs while keeping base network frozen".format(args.fixbase_epoch))

        for <a id="change">epoch</a> in range(args.fixbase_epoch):
            start_train_time<a id="change"> = </a><a id="change">time.time()</a>
            train(epoch, model, criterion, optimizer_tmp, trainloader, use_gpu, freeze_bn=True)
            train_time += round(<a id="change">time.time()</a> - start_train_time)

        del optimizer_tmp
        print("Now open all layers for training")</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/vlsomers/bpbreid/commit/b88d36cd9c8056e15607a40f5d10a9072ab84b22#diff-e6c0c833279ad43f0c76b2e4799c36ce85c9cbbcd1aeb2f6e0af3401a600792eL87' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41333571</div><div id='project'> Project Name: vlsomers/bpbreid</div><div id='commit'> Commit Name: b88d36cd9c8056e15607a40f5d10a9072ab84b22</div><div id='time'> Time: 2018-07-06</div><div id='author'> Author: k.zhou@qmul.ac.uk</div><div id='file'> File Name: train_vidreid_xent.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_vidreid_xent.py</div><div id='n_file'> N File Name: train_vidreid_xent.py</div><div id='m_start'> M Start Line: 149</div><div id='m_end'> M End Line: 150</div><div id='n_start'> N Start Line: 97</div><div id='n_end'> N End Line: 198</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        scaler.scale(loss).backward()
        &#47&#47 Gradient clipping
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(<a id="change">model.parameters()</a>, 1.0)
        &#47&#47 Update generator weight
        scaler.step(optimizer)
        scaler.update()</code></pre><h3>After Change</h3><pre><code class='java'>
    model.train()

    end = time.time()
    for <a id="change">index</a>, (lr, hr) in enumerate(train_dataloader):
        &#47&#47 measure data loading time
        data_time.update(<a id="change">time.time()</a> - end)

        lr = lr.to(config.device, non_blocking=True)
        hr = hr.to(config.device, non_blocking=True)

        &#47&#47 Initialize the generator gradient
        model.zero_grad()

        &#47&#47 Mixed precision training
        with amp.autocast():
            sr = model(lr)
            loss = criterion(sr, hr)
        &#47&#47 Gradient zoom
        scaler.scale(loss).backward()
        &#47&#47 Update generator weight
        scaler.step(optimizer)
        scaler.update()

        &#47&#47 measure accuracy and record loss
        psnr = 10. * torch.log10(1. / torch.mean((sr - hr) ** 2))
        losses.update(loss.item(), lr.size(0))
        psnres.update(psnr.item(), lr.size(0))

        &#47&#47 measure elapsed time
        batch_time.update(time.time() - end)
        end<a id="change"> = </a><a id="change">time.time()</a>

        if index % config.print_frequency == 0:
            progress.display(index)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/espcn-pytorch/commit/3d7da32ace2da2b908bad2a32243b464f206e72a#diff-ed183d67207df065a11e1289f19d34cc2abbc5448dea952683cfe9728c342b95L83' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41333568</div><div id='project'> Project Name: lornatang/espcn-pytorch</div><div id='commit'> Commit Name: 3d7da32ace2da2b908bad2a32243b464f206e72a</div><div id='time'> Time: 2021-11-30</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(7)</div><div id='n_method'> N Method Name: train(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train.py</div><div id='n_file'> N File Name: train.py</div><div id='m_start'> M Start Line: 83</div><div id='m_end'> M End Line: 117</div><div id='n_start'> N Start Line: 156</div><div id='n_end'> N End Line: 203</div><BR>