<html><h3>Pattern ID :18125
</h3><img src='59403914.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        layer_params<a id="change"> = </a><a id="change">[</a>num_resnet_blocks, resnet_groups, layer_attns, layer_attns_depth, layer_cross_attns<a id="change"></a>]
        reversed_layer_params = list(map(reversed, layer_params))

        &#47&#47 downsampling layers</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 temporal downsample config

        temporal_strides<a id="change"> = </a><a id="change">cast_tuple(</a>temporal_strides, num_layers<a id="change">)</a>
        self.total_temporal_divisor = functools.reduce(operator.mul, temporal_strides, 1)

        &#47&#47 downsample klass

        downsample_klass = Downsample

        if cross_embed_downsample:
            downsample_klass = partial(CrossEmbedLayer, kernel_sizes = cross_embed_downsample_kernel_sizes)

        &#47&#47 initial resnet block (for memory efficient unet)

        self.init_resnet_block = resnet_klass(init_dim, init_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[0], use_gca = use_global_context_attn) if memory_efficient else None

        self.init_temporal_peg = temporal_peg(init_dim)
        self.init_temporal_attn = temporal_attn(init_dim)

        &#47&#47 scale for resnet skip connections

        self.skip_connect_scale = 1. if not scale_skip_connection else (2 ** -0.5)

        &#47&#47 layers

        self.downs = nn.ModuleList([])
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        layer_params<a id="change"> = </a><a id="change">[</a>num_resnet_blocks, resnet_groups, layer_attns, layer_attns_depth, layer_cross_attns, temporal_strides<a id="change"></a>]
        reversed_layer_params = list(map(reversed, layer_params))

        &#47&#47 downsampling layers</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/35409652fdd230f2ceb79fcefebf6c2a8e18f5f4#diff-87b27a2606d89bf8c64b738a6a3fcfdb0699b7a362ada843cfa9dc9feeaf6eb4L1302' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59403914</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: 35409652fdd230f2ceb79fcefebf6c2a8e18f5f4</div><div id='time'> Time: 2023-01-24</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/imagen_video.py</div><div id='m_class'> M Class Name: Unet3D</div><div id='n_method'> N Class Name: Unet3D</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imagen_pytorch/imagen_video.py</div><div id='n_file'> N File Name: imagen_pytorch/imagen_video.py</div><div id='m_start'> M Start Line: 1302</div><div id='m_end'> M End Line: 1341</div><div id='n_start'> N Start Line: 1347</div><div id='n_end'> N End Line: 1476</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        layer_params<a id="change"> = </a><a id="change">[</a>num_resnet_blocks, resnet_groups, layer_attns, layer_attns_depth, layer_cross_attns<a id="change"></a>]
        reversed_layer_params = list(map(reversed, layer_params))

        &#47&#47 downsampling layers</code></pre><h3>After Change</h3><pre><code class='java'>
        layer_attns_depth = cast_tuple(layer_attns_depth, num_layers)
        layer_cross_attns = cast_tuple(layer_cross_attns, num_layers)

        use_linear_attn<a id="change"> = </a><a id="change">cast_tuple(</a>use_linear_attn, num_layers<a id="change">)</a>
        use_linear_cross_attn = cast_tuple(use_linear_cross_attn, num_layers)

        assert all([layers == num_layers for layers in list(map(len, (resnet_groups, layer_attns, layer_cross_attns)))])

        &#47&#47 downsample klass

        downsample_klass = Downsample

        if cross_embed_downsample:
            downsample_klass = partial(CrossEmbedLayer, kernel_sizes = cross_embed_downsample_kernel_sizes)

        &#47&#47 initial resnet block (for memory efficient unet)

        self.init_resnet_block = resnet_klass(init_dim, init_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[0], use_gca = use_global_context_attn) if memory_efficient else None

        &#47&#47 scale for resnet skip connections

        self.skip_connect_scale = 1. if not scale_skip_connection else (2 ** -0.5)

        &#47&#47 layers

        self.downs = nn.ModuleList([])
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        layer_params<a id="change"> = </a><a id="change">[</a>num_resnet_blocks, resnet_groups, layer_attns, layer_attns_depth, layer_cross_attns, use_linear_attn, use_linear_cross_attn<a id="change"></a>]
        reversed_layer_params = list(map(reversed, layer_params))

        &#47&#47 downsampling layers</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/d4c45ab1c8380de71e5dd1044dc4100ef9ac76ce#diff-edef3c5fe92797a22c0b8fc6cca1d57b4b84ef03dfdfe802ed9147e21fc88109L1065' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59403918</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: d4c45ab1c8380de71e5dd1044dc4100ef9ac76ce</div><div id='time'> Time: 2022-08-30</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_class'> M Class Name: Unet</div><div id='n_method'> N Class Name: Unet</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imagen_pytorch/imagen_pytorch.py</div><div id='n_file'> N File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_start'> M Start Line: 1250</div><div id='m_end'> M End Line: 1343</div><div id='n_start'> N Start Line: 1246</div><div id='n_end'> N End Line: 1358</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        layer_params<a id="change"> = </a><a id="change">[</a>num_resnet_blocks, resnet_groups, layer_attns, layer_cross_attns<a id="change"></a>]
        reversed_layer_params = list(map(reversed, layer_params))

        &#47&#47 downsampling layers</code></pre><h3>After Change</h3><pre><code class='java'>
        resnet_groups = cast_tuple(resnet_groups, num_layers)

        layer_attns = cast_tuple(layer_attns, num_layers)
        layer_attns_depth<a id="change"> = </a><a id="change">cast_tuple(</a>layer_attns_depth, num_layers<a id="change">)</a>
        layer_cross_attns = cast_tuple(layer_cross_attns, num_layers)

        assert all([layers == num_layers for layers in list(map(len, (resnet_groups, layer_attns, layer_cross_attns)))])

        &#47&#47 downsample klass

        downsample_klass = Downsample

        if cross_embed_downsample:
            downsample_klass = partial(CrossEmbedLayer, kernel_sizes = cross_embed_downsample_kernel_sizes)

        &#47&#47 initial resnet block (for memory efficient unet)

        self.init_resnet_block = ResnetBlock(init_dim, init_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[0], use_gca = use_global_context_attn) if memory_efficient else None

        &#47&#47 scale for resnet skip connections

        self.skip_connect_scale = 1. if not scale_skip_connection else (2 ** -0.5)

        &#47&#47 layers

        self.downs = nn.ModuleList([])
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        layer_params<a id="change"> = </a><a id="change">[</a>num_resnet_blocks, resnet_groups, layer_attns, layer_attns_depth, layer_cross_attns<a id="change"></a>]
        reversed_layer_params = list(map(reversed, layer_params))

        &#47&#47 downsampling layers</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/31f5eb5e12618f9b83f24d1dc486d3fe9e07403e#diff-edef3c5fe92797a22c0b8fc6cca1d57b4b84ef03dfdfe802ed9147e21fc88109L1028' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59403916</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: 31f5eb5e12618f9b83f24d1dc486d3fe9e07403e</div><div id='time'> Time: 2022-07-14</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_class'> M Class Name: Unet</div><div id='n_method'> N Class Name: Unet</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imagen_pytorch/imagen_pytorch.py</div><div id='n_file'> N File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_start'> M Start Line: 1211</div><div id='m_end'> M End Line: 1240</div><div id='n_start'> N Start Line: 1222</div><div id='n_end'> N End Line: 1256</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        skip_dims = []

        down_stage_parameters<a id="change"> = </a><a id="change">[
            </a>in_out,
            nested_unet_depths,
            num_blocks_per_stage<a id="change"></a>
        ]

        up_stage_parameters = [reversed(params[:-1]) for params in down_stage_parameters]
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 number of self attention blocks per stage

        num_self_attn_per_stage<a id="change"> = </a><a id="change">cast_tuple(</a>num_self_attn_per_stage, num_resolutions<a id="change">)</a>
        assert all([num_self_attn_blocks &gt;= 0 for num_self_attn_blocks in num_self_attn_per_stage])

        &#47&#47 attn kwargs

        attn_kwargs = dict(
            heads = attn_heads,
            dim_head = attn_dim_head
        )

        &#47&#47 modules for all layers

        skip_dims = []

        down_stage_parameters<a id="change"> = </a><a id="change">[
            </a>in_out,
            nested_unet_depths,
            num_blocks_per_stage,
            num_self_attn_per_stage<a id="change"></a>
        ]

        up_stage_parameters = [reversed(params[:-1]) for params in down_stage_parameters]
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/x-unet/commit/f95f833eade55222c51aa137f446b0fdc9669ed2#diff-6e9e7a6d8d7a8c116b8bdae64f3e845f516adfec59d0379fc01849d294784966L255' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59403917</div><div id='project'> Project Name: lucidrains/x-unet</div><div id='commit'> Commit Name: f95f833eade55222c51aa137f446b0fdc9669ed2</div><div id='time'> Time: 2022-08-19</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: x_unet/x_unet.py</div><div id='m_class'> M Class Name: XUnet</div><div id='n_method'> N Class Name: XUnet</div><div id='m_method'> M Method Name: __init__(18)</div><div id='n_method'> N Method Name: __init__(15)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: x_unet/x_unet.py</div><div id='n_file'> N File Name: x_unet/x_unet.py</div><div id='m_start'> M Start Line: 283</div><div id='m_end'> M End Line: 311</div><div id='n_start'> N Start Line: 300</div><div id='n_end'> N End Line: 400</div><BR>