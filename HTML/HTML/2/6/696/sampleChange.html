<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    cotrans.eval()

    &#47&#47 Forward through models
    target<a id="change"> = </a>trans(example_clip)

    outputs = <a id="change">[]</a>
    &#47&#47 Manual zero pad (due to padding=1 in trans.b Conv3d)
    zeros = torch.zeros_like(example_clip[:, :, 0])
    outputs.append(cotrans.forward(zeros))
    for i in range(example_clip.shape[2]):
        outputs.append(cotrans.forward(example_clip[:, :, i]))
    outputs.append(cotrans.forward(zeros))
    outputs.append(cotrans.forward(zeros))
    outputs.append(cotrans.forward(zeros))

    &#47&#47 For debugging:
    &#47&#47 close = []
    &#47&#47 for t in range(target.shape[2]):
    &#47&#47     for i in range(len(outputs)):
    &#47&#47         if torch.allclose(target[:, :, t], outputs[i], atol=5e-2):
    &#47&#47             close.append(f"t = {t}, o = {i}")

    shift = example_clip.shape[2] - 1  &#47&#47 From SE

    &#47&#47 Not very precise because SE block still initializes
    for t in range(1, target.shape[2]):
        assert torch.allclose(target[:, :, t], outputs[t + shift], atol=5e-2)

    &#47&#47 After temporal_window_size inputs it also produces precise computation
    <a id="change">torch.allclose(</a>target[:, :, 3], outputs[3 + shift]<a id="change">, atol=1e-9)</a>

    &#47&#47 forward_steps also works as expected
    outputs2 = cotrans.forward_steps(example_clip)
    assert torch.allclose(target, outputs2)</code></pre><h3>After Change</h3><pre><code class='java'>


def test_ResBlock():
    sample = torch.randn((<a id="change">1</a><a id="change">, 2, 4, 4, 4</a>))

    &#47&#47 Regular block
    trans = ResBlock(</code></pre>