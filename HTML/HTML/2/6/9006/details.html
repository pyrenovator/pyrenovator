<html><h3>Pattern ID :9006
</h3><img src='32868093.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        output=&quotscreen&quot,
    )

    <a id="change">return </a><a id="change">LaunchDescription(</a>[
        rclcpp_container,
        Node(name=&quotcenterpose_decoder_node&quot, package=&quotisaac_ros_centerpose&quot,
             executable=&quotCenterPoseDecoder&quot, parameters=[config], output=&quotscreen&quot)]<a id="change">)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
        output=&quotscreen&quot
    )

    final_launch_container<a id="change"> = </a>launch_args<a id="change"> + \
        [rclcpp_container] + </a><a id="change">[</a>dope_decoder_node<a id="change"></a>]
    <a id="change">return </a>LaunchDescription(final_launch_container)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/nvidia-isaac-ros/isaac_ros_pose_estimation/commit/a6ad6e5eae07bc176a918da89e0d4088102f06ee#diff-3cf8a416b551b345252607ae41dcfff1aa9b2456ae474718de209d29ad863f3eL19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 32868093</div><div id='project'> Project Name: nvidia-isaac-ros/isaac_ros_pose_estimation</div><div id='commit'> Commit Name: a6ad6e5eae07bc176a918da89e0d4088102f06ee</div><div id='time'> Time: 2022-06-30</div><div id='author'> Author: jaiveers@nvidia.com</div><div id='file'> File Name: isaac_ros_centerpose/launch/isaac_ros_centerpose.launch.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: generate_launch_description(0)</div><div id='n_method'> N Method Name: generate_launch_description(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: isaac_ros_centerpose/launch/isaac_ros_centerpose.launch.py</div><div id='n_file'> N File Name: isaac_ros_centerpose/launch/isaac_ros_centerpose.launch.py</div><div id='m_start'> M Start Line: 19</div><div id='m_end'> M End Line: 69</div><div id='n_start'> N Start Line: 21</div><div id='n_end'> N End Line: 147</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        output=&quotscreen&quot,
    )

    <a id="change">return </a><a id="change">LaunchDescription(</a>[container]<a id="change">)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>

def generate_launch_description():
    Generate launch description for DOPE encoder-&gt;Triton-&gt;DOPE decoder.
    launch_args = <a id="change">[
        </a>DeclareLaunchArgument(
            &quotnetwork_image_width&quot,
            default_value=&quot640&quot,
            description=&quotThe input image width that the network expects&quot),
        DeclareLaunchArgument(
            &quotnetwork_image_height&quot,
            default_value=&quot480&quot,
            description=&quotThe input image height that the network expects&quot),
        DeclareLaunchArgument(
            &quotencoder_image_mean&quot,
            default_value=&quot[0.5, 0.5, 0.5]&quot,
            description=&quotThe mean for image normalization&quot),
        DeclareLaunchArgument(
            &quotencoder_image_stddev&quot,
            default_value=&quot[0.5, 0.5, 0.5]&quot,
            description=&quotThe standard deviation for image normalization&quot),
        DeclareLaunchArgument(
            &quotmodel_name&quot,
            default_value=&quot&quot,
            description=&quotThe name of the model&quot),
        DeclareLaunchArgument(
            &quotmodel_repository_paths&quot,
            default_value=&quot&quot,
            description=&quotThe absolute path to the repository of models&quot),
        DeclareLaunchArgument(
            &quotmax_batch_size&quot,
            default_value=&quot0&quot,
            description=&quotThe maximum allowed batch size of the model&quot),
        DeclareLaunchArgument(
            &quotinput_tensor_names&quot,
            default_value=&quot["input_tensor"]&quot,
            description=&quotA list of tensor names to bound to the specified input binding names&quot),
        DeclareLaunchArgument(
            &quotinput_binding_names&quot,
            default_value=&quot["input_1"]&quot,
            description=&quotA list of input tensor binding names (specified by model)&quot),
        DeclareLaunchArgument(
            &quotinput_tensor_formats&quot,
            default_value=&quot["nitros_tensor_list_nchw_rgb_f32"]&quot,
            description=&quotThe nitros format of the input tensors&quot),
        DeclareLaunchArgument(
            &quotoutput_tensor_names&quot,
            default_value=&quot["output_tensor"]&quot,
            description=&quotA list of tensor names to bound to the specified output binding names&quot),
        DeclareLaunchArgument(
            &quotoutput_binding_names&quot,
            default_value=&quot["softmax_1"]&quot,
            description=&quotA  list of output tensor binding names (specified by model)&quot),
        DeclareLaunchArgument(
            &quotoutput_tensor_formats&quot,
            default_value=&quot["nitros_tensor_list_nhwc_rgb_f32"]&quot,
            description=&quotThe nitros format of the output tensors&quot),
        DeclareLaunchArgument(
            &quotobject_name&quot,
            default_value=&quotKetchup&quot,
            description=&quotThe object class that the DOPE network is detecting&quot)<a id="change"></a>,
    ]

    &#47&#47 DNN Image Encoder parameters
    network_image_width = LaunchConfiguration(&quotnetwork_image_width&quot)
    network_image_height = LaunchConfiguration(&quotnetwork_image_height&quot)
    encoder_image_mean = LaunchConfiguration(&quotencoder_image_mean&quot)
    encoder_image_stddev = LaunchConfiguration(&quotencoder_image_stddev&quot)

    &#47&#47 Triton parameters
    model_name = LaunchConfiguration(&quotmodel_name&quot)
    model_repository_paths = LaunchConfiguration(&quotmodel_repository_paths&quot)
    max_batch_size = LaunchConfiguration(&quotmax_batch_size&quot)
    input_tensor_names = LaunchConfiguration(&quotinput_tensor_names&quot)
    input_binding_names = LaunchConfiguration(&quotinput_binding_names&quot)
    input_tensor_formats = LaunchConfiguration(&quotinput_tensor_formats&quot)
    output_tensor_names = LaunchConfiguration(&quotoutput_tensor_names&quot)
    output_binding_names = LaunchConfiguration(&quotoutput_binding_names&quot)
    output_tensor_formats = LaunchConfiguration(&quotoutput_tensor_formats&quot)

    &#47&#47 DOPE Decoder parameters
    object_name = LaunchConfiguration(&quotobject_name&quot)

    dope_encoder_node = ComposableNode(
        name=&quotdope_encoder&quot,
        package=&quotisaac_ros_dnn_encoders&quot,
        plugin=&quotnvidia::isaac_ros::dnn_inference::DnnImageEncoderNode&quot,
        parameters=[{
            &quotnetwork_image_width&quot: network_image_width,
            &quotnetwork_image_height&quot: network_image_height,
            &quotimage_mean&quot: encoder_image_mean,
            &quotimage_stddev&quot: encoder_image_stddev,
        }],
        remappings=[(&quotencoded_tensor&quot, &quottensor_pub&quot)])

    dope_inference_node = ComposableNode(
        name=&quotdope_inference&quot,
        package=&quotisaac_ros_triton&quot,
        plugin=&quotnvidia::isaac_ros::dnn_inference::TritonNode&quot,
        parameters=[{
            &quotmodel_name&quot: model_name,
            &quotmodel_repository_paths&quot: model_repository_paths,
            &quotmax_batch_size&quot: max_batch_size,
            &quotinput_tensor_names&quot: input_tensor_names,
            &quotinput_binding_names&quot: input_binding_names,
            &quotinput_tensor_formats&quot: input_tensor_formats,
            &quotoutput_tensor_names&quot: output_tensor_names,
            &quotoutput_binding_names&quot: output_binding_names,
            &quotoutput_tensor_formats&quot: output_tensor_formats,
        }])

    dope_decoder_node = ComposableNode(
        name=&quotdope_decoder&quot,
        package=&quotisaac_ros_dope&quot,
        plugin=&quotnvidia::isaac_ros::dope::DopeDecoderNode&quot,
        parameters=[{
            &quotobject_name&quot: object_name,
        }],
        remappings=[(&quotbelief_map_array&quot, &quottensor_sub&quot),
                    (&quotdope/pose_array&quot, &quotposes&quot)])

    container = ComposableNodeContainer(
        name=&quotdope_container&quot,
        namespace=&quot&quot,
        package=&quotrclcpp_components&quot,
        executable=&quotcomponent_container_mt&quot,
        composable_node_descriptions=[dope_encoder_node, dope_inference_node, dope_decoder_node],
        output=&quotscreen&quot,
    )

    final_launch_description<a id="change"> = </a>launch_args<a id="change"> + </a>[container]
    <a id="change">return </a>launch.LaunchDescription(final_launch_description)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nvidia-isaac-ros/isaac_ros_pose_estimation/commit/a6ad6e5eae07bc176a918da89e0d4088102f06ee#diff-faf8d9ae706429d443c1da4cab0e79584c3c3552b0a7f120985bd0ef5e9a3450L16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 32868091</div><div id='project'> Project Name: nvidia-isaac-ros/isaac_ros_pose_estimation</div><div id='commit'> Commit Name: a6ad6e5eae07bc176a918da89e0d4088102f06ee</div><div id='time'> Time: 2022-06-30</div><div id='author'> Author: jaiveers@nvidia.com</div><div id='file'> File Name: isaac_ros_dope/launch/isaac_ros_dope_triton.launch.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: generate_launch_description(0)</div><div id='n_method'> N Method Name: generate_launch_description(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: isaac_ros_dope/launch/isaac_ros_dope_triton.launch.py</div><div id='n_file'> N File Name: isaac_ros_dope/launch/isaac_ros_dope_triton.launch.py</div><div id='m_start'> M Start Line: 18</div><div id='m_end'> M End Line: 68</div><div id='n_start'> N Start Line: 18</div><div id='n_end'> N End Line: 145</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        output=&quotscreen&quot,
    )

    <a id="change">return </a><a id="change">LaunchDescription(</a>[container]<a id="change">)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
    DEFAULT_MODEL_FILE_NAME = &quotdope_ketchup_pol.onnx&quot
    default_model_file_path = os.path.dirname(os.path.abspath(
        __file__)) + &quot/../../test/models/&quot + DEFAULT_MODEL_FILE_NAME
    launch_args = <a id="change">[
        </a>DeclareLaunchArgument(
            &quotnetwork_image_width&quot,
            default_value=&quot640&quot,
            description=&quotThe input image width that the network expects&quot),
        DeclareLaunchArgument(
            &quotnetwork_image_height&quot,
            default_value=&quot480&quot,
            description=&quotThe input image height that the network expects&quot),
        DeclareLaunchArgument(
            &quotmodel_file_path&quot,
            default_value=f&quot{default_model_file_path}&quot,
            description=&quotThe absolute file path to the ONNX file&quot),
        DeclareLaunchArgument(
            &quotengine_file_path&quot,
            default_value=&quot/tmp/trt_engine.plan&quot,
            description=&quotThe absolute file path to the TensorRT engine file&quot),
        DeclareLaunchArgument(
            &quotinput_tensor_names&quot,
            default_value=&quot["input_tensor"]&quot,
            description=&quotA list of tensor names to bound to the specified input binding names&quot),
        DeclareLaunchArgument(
            &quotinput_binding_names&quot,
            default_value=&quot["input"]&quot,
            description=&quotA list of input tensor binding names (specified by model)&quot),
        DeclareLaunchArgument(
            &quotinput_tensor_formats&quot,
            default_value=&quot["nitros_tensor_list_nchw_rgb_f32"]&quot,
            description=&quotThe nitros format of the input tensors&quot),
        DeclareLaunchArgument(
            &quotoutput_tensor_names&quot,
            default_value=&quot["output"]&quot,
            description=&quotA list of tensor names to bound to the specified output binding names&quot),
        DeclareLaunchArgument(
            &quotoutput_binding_names&quot,
            default_value=&quot["output"]&quot,
            description=&quotA  list of output tensor binding names (specified by model)&quot),
        DeclareLaunchArgument(
            &quotoutput_tensor_formats&quot,
            default_value=&quot["nitros_tensor_list_nhwc_rgb_f32"]&quot,
            description=&quotThe nitros format of the output tensors&quot),
        DeclareLaunchArgument(
            &quottensorrt_verbose&quot,
            default_value=&quotFalse&quot,
            description=&quotWhether TensorRT should verbosely log or not&quot),
        DeclareLaunchArgument(
            &quotobject_name&quot,
            default_value=&quotKetchup&quot,
            description=&quotThe object class that the DOPE network is detecting&quot),
        DeclareLaunchArgument(
            &quotforce_engine_update&quot,
            default_value=&quotFalse&quot,
            description=&quotWhether TensorRT should update the TensorRT engine file or not&quot)<a id="change"></a>,
    ]

    &#47&#47 DNN Image Encoder parameters
    network_image_width = LaunchConfiguration(&quotnetwork_image_width&quot)
    network_image_height = LaunchConfiguration(&quotnetwork_image_height&quot)

    &#47&#47 Tensor RT parameters
    model_file_path = LaunchConfiguration(&quotmodel_file_path&quot)
    engine_file_path = LaunchConfiguration(&quotengine_file_path&quot)
    input_tensor_names = LaunchConfiguration(&quotinput_tensor_names&quot)
    input_binding_names = LaunchConfiguration(&quotinput_binding_names&quot)
    input_tensor_formats = LaunchConfiguration(&quotinput_tensor_formats&quot)
    output_tensor_names = LaunchConfiguration(&quotoutput_tensor_names&quot)
    output_binding_names = LaunchConfiguration(&quotoutput_binding_names&quot)
    output_tensor_formats = LaunchConfiguration(&quotoutput_tensor_formats&quot)
    tensorrt_verbose = LaunchConfiguration(&quottensorrt_verbose&quot)
    force_engine_update = LaunchConfiguration(&quotforce_engine_update&quot)

    &#47&#47 DOPE Decoder parameters
    object_name = LaunchConfiguration(&quotobject_name&quot)

    dope_encoder_node = ComposableNode(
        name=&quotdope_encoder&quot,
        package=&quotisaac_ros_dnn_encoders&quot,
        plugin=&quotnvidia::isaac_ros::dnn_inference::DnnImageEncoderNode&quot,
        parameters=[{
            &quotnetwork_image_width&quot: network_image_width,
            &quotnetwork_image_height&quot: network_image_height,
        }],
        remappings=[(&quotencoded_tensor&quot, &quottensor_pub&quot)])

    dope_inference_node = ComposableNode(
        name=&quotdope_inference&quot,
        package=&quotisaac_ros_tensor_rt&quot,
        plugin=&quotnvidia::isaac_ros::dnn_inference::TensorRTNode&quot,
        parameters=[{
            &quotmodel_file_path&quot: model_file_path,
            &quotengine_file_path&quot: engine_file_path,
            &quotinput_tensor_names&quot: input_tensor_names,
            &quotinput_binding_names&quot: input_binding_names,
            &quotinput_tensor_formats&quot: input_tensor_formats,
            &quotoutput_tensor_names&quot: output_tensor_names,
            &quotoutput_binding_names&quot: output_binding_names,
            &quotoutput_tensor_formats&quot: output_tensor_formats,
            &quotverbose&quot: tensorrt_verbose,
            &quotforce_engine_update&quot: force_engine_update
        }])

    dope_decoder_node = ComposableNode(
        name=&quotdope_decoder&quot,
        package=&quotisaac_ros_dope&quot,
        plugin=&quotnvidia::isaac_ros::dope::DopeDecoderNode&quot,
        parameters=[{
            &quotobject_name&quot: object_name,
        }],
        remappings=[(&quotbelief_map_array&quot, &quottensor_sub&quot),
                    (&quotdope/pose_array&quot, &quotposes&quot)])

    container = ComposableNodeContainer(
        name=&quotdope_container&quot,
        namespace=&quot&quot,
        package=&quotrclcpp_components&quot,
        executable=&quotcomponent_container_mt&quot,
        composable_node_descriptions=[dope_encoder_node, dope_inference_node, dope_decoder_node],
        output=&quotscreen&quot,
    )

    final_launch_description<a id="change"> = </a>launch_args<a id="change"> + </a>[container]
    <a id="change">return </a>launch.LaunchDescription(final_launch_description)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nvidia-isaac-ros/isaac_ros_pose_estimation/commit/a6ad6e5eae07bc176a918da89e0d4088102f06ee#diff-0b7a7563b78f77aaceadaa54af5cbb3fe543825c417195f478826e0ec436302aL16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 32868090</div><div id='project'> Project Name: nvidia-isaac-ros/isaac_ros_pose_estimation</div><div id='commit'> Commit Name: a6ad6e5eae07bc176a918da89e0d4088102f06ee</div><div id='time'> Time: 2022-06-30</div><div id='author'> Author: jaiveers@nvidia.com</div><div id='file'> File Name: isaac_ros_dope/launch/isaac_ros_dope_tensor_rt.launch.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: generate_launch_description(0)</div><div id='n_method'> N Method Name: generate_launch_description(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: isaac_ros_dope/launch/isaac_ros_dope_tensor_rt.launch.py</div><div id='n_file'> N File Name: isaac_ros_dope/launch/isaac_ros_dope_tensor_rt.launch.py</div><div id='m_start'> M Start Line: 32</div><div id='m_end'> M End Line: 67</div><div id='n_start'> N Start Line: 20</div><div id='n_end'> N End Line: 144</div><BR>