<html><h3>Pattern ID :11562
</h3><img src='39238391.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        padded input
    
    _max = inputs.shape[dim] - 2
    x = torch.index_select(inputs, dim, <a id="change">torch.arange(</a>pad, <a id="change">0</a>, <a id="change">-1</a><a id="change">, device=inputs.device)</a>)
    y = torch.index_select(inputs, dim, torch.arange(_max, _max - pad, -1, device=inputs.device))
    return torch.cat((x, inputs, y), dim)
</code></pre><h3>After Change</h3><pre><code class='java'>
        Image padded over a single dimension
    
    _max = inputs.shape[dim]
    x = torch.index_select(inputs, dim, <a id="change">torch.arange(</a>pad - 1, <a id="change">-1</a>, <a id="change">-1</a><a id="change">)</a>.to(inputs.device))
    y = torch.index_select(inputs, dim, torch.arange(_max - 1, _max - pad - outer_pad, -1).to(inputs.device))
    return torch.cat((x, inputs, y), dim)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 11</div><BR><div id='size'>Non-data size: 2</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorchlightning/metrics/commit/704ddebf908d9870efd2ebcaf4d2dbe579fe0b2b#diff-419b43f945511b260db1aceb0ce2986b65882223b98ea71601404075c079dbefL76' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39238391</div><div id='project'> Project Name: pytorchlightning/metrics</div><div id='commit'> Commit Name: 704ddebf908d9870efd2ebcaf4d2dbe579fe0b2b</div><div id='time'> Time: 2023-02-28</div><div id='author'> Author: 63279364+Piyush-97@users.noreply.github.com</div><div id='file'> File Name: src/torchmetrics/functional/image/helper.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _single_dimension_pad(4)</div><div id='n_method'> N Method Name: _single_dimension_pad(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/torchmetrics/functional/image/helper.py</div><div id='n_file'> N File Name: src/torchmetrics/functional/image/helper.py</div><div id='m_start'> M Start Line: 94</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 76</div><div id='n_end'> N End Line: 90</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    
    pe = torch.zeros(position, d_model)
    pos = torch.arange(0, position, dtype=torch.float).unsqueeze(1)
    div_term = torch.exp(<a id="change">torch.arange(0</a>, d_model, <a id="change">2</a><a id="change">)</a>.float() * (-math.log(10000.0) / d_model))
    pe[:, 0::2] = torch.sin(pos * div_term)
    pe[:, 1::2] = torch.cos(pos * div_term)
    return pe.unsqueeze(0)</code></pre><h3>After Change</h3><pre><code class='java'>
    
    pe = torch.zeros(position, d_model)
    pos = torch.arange(0, position, dtype=dtype).unsqueeze(1)
    div_term = torch.exp(<a id="change">torch.arange(0</a>, d_model, <a id="change">2</a><a id="change">, dtype=dtype)</a> * (-math.log(10000.0) / d_model))
    pe[:, 0::2] = torch.sin(pos * div_term)
    pe[:, 1::2] = torch.cos(pos * div_term)
    return pe.unsqueeze(0)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mindee/doctr/commit/6edceda7d2d3d84a41b3ee21c45079c97ecff7d6#diff-5eb4b6b7a215017ac91351a0c5e665af04fa644ddf1ecd5037545ba096ec1337L14' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39238374</div><div id='project'> Project Name: mindee/doctr</div><div id='commit'> Commit Name: 6edceda7d2d3d84a41b3ee21c45079c97ecff7d6</div><div id='time'> Time: 2021-07-19</div><div id='author'> Author: 76527547+fg-mindee@users.noreply.github.com</div><div id='file'> File Name: doctr/models/recognition/transformer/pytorch.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: positional_encoding(3)</div><div id='n_method'> N Method Name: positional_encoding(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: doctr/models/recognition/transformer/pytorch.py</div><div id='n_file'> N File Name: doctr/models/recognition/transformer/pytorch.py</div><div id='m_start'> M Start Line: 27</div><div id='m_end'> M End Line: 27</div><div id='n_start'> N Start Line: 14</div><div id='n_end'> N End Line: 27</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if exists(custom_freqs):
            freqs = custom_freqs
        elif freqs_for == &quotlang&quot:
            freqs = 1. / (theta ** (<a id="change">torch.arange(0</a>, dim, <a id="change">2</a><a id="change">)</a>.float() / dim))
        elif freqs_for == &quotpixel&quot:
            freqs = torch.logspace(0., log(max_freq / 2) / log(2), dim // 2, base = 2) * pi
        elif freqs_for == &quotconstant&quot:</code></pre><h3>After Change</h3><pre><code class='java'>
        if exists(custom_freqs):
            freqs = custom_freqs
        elif freqs_for == &quotlang&quot:
            freqs = 1. / (theta ** (<a id="change">torch.arange(0</a>, dim, <a id="change">2</a><a id="change">)</a>[:(dim // 2)].float() / dim))
        elif freqs_for == &quotpixel&quot:
            freqs = torch.logspace(0., log(max_freq / 2) / log(2), dim // 2, base = 2) * pi
        elif freqs_for == &quotconstant&quot:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/rotary-embedding-torch/commit/f3bc83c5338d7129f073cb180134452a82243722#diff-cd5f83ec0dcf1b7afed2336003bd72708c531a84a4fb8ee8b5289e91cc97ee3cL61' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39238372</div><div id='project'> Project Name: lucidrains/rotary-embedding-torch</div><div id='commit'> Commit Name: f3bc83c5338d7129f073cb180134452a82243722</div><div id='time'> Time: 2021-08-16</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: rotary_embedding_torch/rotary_embedding_torch.py</div><div id='m_class'> M Class Name: RotaryEmbedding</div><div id='n_method'> N Class Name: RotaryEmbedding</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(8)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: rotary_embedding_torch/rotary_embedding_torch.py</div><div id='n_file'> N File Name: rotary_embedding_torch/rotary_embedding_torch.py</div><div id='m_start'> M Start Line: 75</div><div id='m_end'> M End Line: 75</div><div id='n_start'> N Start Line: 75</div><div id='n_end'> N End Line: 75</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>


def test_sharding_spec():
    physical_mesh_id = <a id="change">torch.arange(0</a>, <a id="change">16</a><a id="change">)</a>.reshape(2, 8)
    mesh_shape = (4, 4)
    &#47&#47 [[0, 1, 2, 3],
    &#47&#47  [4, 5, 6, 7],</code></pre><h3>After Change</h3><pre><code class='java'>


def test_sharding_spec():
    physical_mesh_id = <a id="change">torch.arange(0</a>, <a id="change">16</a><a id="change">)</a>
    mesh_shape = (4, 4)
    &#47&#47 [[0, 1, 2, 3],
    &#47&#47  [4, 5, 6, 7],
    &#47&#47  [8, 9, 10,11],</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hpcaitech/colossalai/commit/eb39154d4082601bf8c39b64317fecd28a526205#diff-3f86a99c6ba401bc8b5765a5b04ca755cf2ba9858a1ebdb3921a5494bccafc76L7' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39238402</div><div id='project'> Project Name: hpcaitech/colossalai</div><div id='commit'> Commit Name: eb39154d4082601bf8c39b64317fecd28a526205</div><div id='time'> Time: 2023-06-07</div><div id='author'> Author: somerlee.9@gmail.com</div><div id='file'> File Name: tests/test_tensor/test_sharding_spec.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_sharding_spec(0)</div><div id='n_method'> N Method Name: test_sharding_spec(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/test_tensor/test_sharding_spec.py</div><div id='n_file'> N File Name: tests/test_tensor/test_sharding_spec.py</div><div id='m_start'> M Start Line: 8</div><div id='m_end'> M End Line: 8</div><div id='n_start'> N Start Line: 8</div><div id='n_end'> N End Line: 8</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(
            <a id="change">torch.arange(0</a>, d_model, <a id="change">2</a><a id="change">)</a>.float() * (-math.log(TEMPERATURE) / d_model)
        )
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)</code></pre><h3>After Change</h3><pre><code class='java'>
        pe = torch.zeros(max_len, d_model)

        position = torch.arange(0, max_len, dtype=torch.float)
        dim_t = <a id="change">torch.arange(0</a>, d_model, <a id="change">2</a><a id="change">, dtype=torch.float)</a>
        div_term = 1.0 / (temperature ** (dim_t / d_model))

        inv_freq = torch.einsum("i, j -&gt; i j", position, div_term)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/green-wood/bttr/commit/ed6072e37a991c138f4197fce71b68ee4e1fc529#diff-07d28c3a77ca52c5c7f69922e4113566385015a423017083355cb5c85428dca4L10' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39238384</div><div id='project'> Project Name: green-wood/bttr</div><div id='commit'> Commit Name: ed6072e37a991c138f4197fce71b68ee4e1fc529</div><div id='time'> Time: 2021-06-09</div><div id='author'> Author: 1027572886a@gmail.ccom</div><div id='file'> File Name: bttr/model/pos_enc.py</div><div id='m_class'> M Class Name: WordPosEnc</div><div id='n_method'> N Class Name: WordPosEnc</div><div id='m_method'> M Method Name: __init__(4)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: pl.LightningModule</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: bttr/model/pos_enc.py</div><div id='n_file'> N File Name: bttr/model/pos_enc.py</div><div id='m_start'> M Start Line: 12</div><div id='m_end'> M End Line: 20</div><div id='n_start'> N Start Line: 11</div><div id='n_end'> N End Line: 22</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
def _arange_like(x, reverse=False):
    Returns arange with len of x of the same dtype and device
    if reverse:
        return <a id="change">torch.arange(</a>x.shape[0] - 1, <a id="change">-1</a>, <a id="change">-1</a><a id="change">, dtype=x.dtype, device=x.device)</a>
    return torch.arange(x.shape[0], dtype=x.dtype, device=x.device)


def _inv_permutation(permutation):</code></pre><h3>After Change</h3><pre><code class='java'>
def _arange_like(x, reverse=False):
    &#47&#47 returns arange with len of x of the same dtype and device (assumes 2d, first dim batch)
    if reverse:
        ar = <a id="change">torch.arange(</a>x.shape[1] - 1, <a id="change">-1</a>, <a id="change">-1</a><a id="change">, dtype=x.dtype, device=x.device)</a>
    else:
        ar = torch.arange(x.shape[1], dtype=x.dtype, device=x.device)
    return ar.expand(x.shape[0], -1)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/teddykoker/torchsort/commit/e47780fac5f81b6b80ba431c58593bea596392ed#diff-6cfcf9d2a83ff3ad8d3e7dbd9b0ab5e6184109cd09839661ed2bc52cbaf2f5c0L48' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39238366</div><div id='project'> Project Name: teddykoker/torchsort</div><div id='commit'> Commit Name: e47780fac5f81b6b80ba431c58593bea596392ed</div><div id='time'> Time: 2021-03-21</div><div id='author'> Author: teddy.koker@gmail.com</div><div id='file'> File Name: torchsort/ops.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _arange_like(2)</div><div id='n_method'> N Method Name: _arange_like(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchsort/ops.py</div><div id='n_file'> N File Name: torchsort/ops.py</div><div id='m_start'> M Start Line: 51</div><div id='m_end'> M End Line: 52</div><div id='n_start'> N Start Line: 45</div><div id='n_end'> N End Line: 48</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>


def test_device_mesh():
    physical_mesh_id = <a id="change">torch.arange(0</a>, <a id="change">16</a><a id="change">)</a>.reshape(2, 8)
    mesh_shape = (4, 4)
    &#47&#47 [[0, 1, 2, 3],
    &#47&#47  [4, 5, 6, 7],</code></pre><h3>After Change</h3><pre><code class='java'>


def test_device_mesh():
    physical_mesh_id = <a id="change">torch.arange(0</a>, <a id="change">16</a><a id="change">)</a>
    mesh_shape = (4, 4)
    &#47&#47 [[0, 1, 2, 3],
    &#47&#47  [4, 5, 6, 7],
    &#47&#47  [8, 9, 10,11],</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hpcaitech/colossalai/commit/eb39154d4082601bf8c39b64317fecd28a526205#diff-37ce6b6965df6b5f5c123970d79fc6134066bf29f6be4508f5f52054abd7272eL5' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39238397</div><div id='project'> Project Name: hpcaitech/colossalai</div><div id='commit'> Commit Name: eb39154d4082601bf8c39b64317fecd28a526205</div><div id='time'> Time: 2023-06-07</div><div id='author'> Author: somerlee.9@gmail.com</div><div id='file'> File Name: tests/test_device/test_device_mesh.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_device_mesh(0)</div><div id='n_method'> N Method Name: test_device_mesh(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/test_device/test_device_mesh.py</div><div id='n_file'> N File Name: tests/test_device/test_device_mesh.py</div><div id='m_start'> M Start Line: 6</div><div id='m_end'> M End Line: 16</div><div id='n_start'> N Start Line: 7</div><div id='n_end'> N End Line: 7</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
class FixedPositionalEmbedding(nn.Module):
    def __init__(self, dim):
        super().__init__()
        inv_freq = 1 / (10000 ** (<a id="change">torch.arange(0</a>, dim, <a id="change">2</a><a id="change">)</a> / dim))
        self.register_buffer(&quotinv_freq&quot, inv_freq)

    def forward(self, x):</code></pre><h3>After Change</h3><pre><code class='java'>
class FixedPositionalEmbedding(nn.Module):
    def __init__(self, dim):
        super().__init__()
        inv_freq = 1. / (10000 ** (<a id="change">torch.arange(0</a>, dim, <a id="change">2</a><a id="change">)</a>.float() / dim))
        self.register_buffer(&quotinv_freq&quot, inv_freq)

    def forward(self, x):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/reformer-pytorch/commit/13a73ee73fc2406f63ae709230f1666def648c0a#diff-7e740488ff2ce47996cfdd5356981ed3e6ac2bb38739a71b400275ac91d1c3bfL531' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39238363</div><div id='project'> Project Name: lucidrains/reformer-pytorch</div><div id='commit'> Commit Name: 13a73ee73fc2406f63ae709230f1666def648c0a</div><div id='time'> Time: 2020-03-10</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: reformer_pytorch/reformer_pytorch.py</div><div id='m_class'> M Class Name: FixedPositionalEmbedding</div><div id='n_method'> N Class Name: FixedPositionalEmbedding</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: reformer_pytorch/reformer_pytorch.py</div><div id='n_file'> N File Name: reformer_pytorch/reformer_pytorch.py</div><div id='m_start'> M Start Line: 533</div><div id='m_end'> M End Line: 533</div><div id='n_start'> N Start Line: 533</div><div id='n_end'> N End Line: 533</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        super(RelTemporalEncoding, self).__init__()
        self.drop = nn.Dropout(dropout)
        position = torch.arange(0., max_len).unsqueeze(1)
        div_term = 1 / (10000 ** (<a id="change">torch.arange(0.</a>, n_hid * 2, <a id="change">2.</a><a id="change">))</a> / n_hid / 2)
        self.emb = nn.Embedding(max_len, n_hid * 2)
        self.emb.weight.data[:, 0::2] = torch.sin(position * div_term) / math.sqrt(n_hid)
        self.emb.weight.data[:, 1::2] = torch.cos(position * div_term) / math.sqrt(n_hid)</code></pre><h3>After Change</h3><pre><code class='java'>
    def __init__(self, n_hid, max_len = 240, dropout = 0.2):
        super(RelTemporalEncoding, self).__init__()
        position = torch.arange(0., max_len).unsqueeze(1)
        div_term = torch.exp(<a id="change">torch.arange(0</a>, n_hid, <a id="change">2</a><a id="change">)</a> *
                             -(math.log(10000.0) / n_hid))
        emb = nn.Embedding(max_len, n_hid)
        emb.weight.data[:, 0::2] = torch.sin(position * div_term) / math.sqrt(n_hid)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/acbull/pyhgt/commit/67b3ec0c6632f5eb542a9ec9092674975fedc714#diff-cc81d93adc64949c18117aa9a98f5e72e0c1ac0825b1a6552ce6221a34bbba37L137' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39238361</div><div id='project'> Project Name: acbull/pyhgt</div><div id='commit'> Commit Name: 67b3ec0c6632f5eb542a9ec9092674975fedc714</div><div id='time'> Time: 2020-07-06</div><div id='author'> Author: 31607751+acbull@users.noreply.github.com</div><div id='file'> File Name: conv.py</div><div id='m_class'> M Class Name: RelTemporalEncoding</div><div id='n_method'> N Class Name: RelTemporalEncoding</div><div id='m_method'> M Method Name: __init__(4)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: conv.py</div><div id='n_file'> N File Name: conv.py</div><div id='m_start'> M Start Line: 139</div><div id='m_end'> M End Line: 146</div><div id='n_start'> N Start Line: 284</div><div id='n_end'> N End Line: 291</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
class LlamaRotaryEmbedding(nn.Layer):
    def __init__(self, dim, max_position_embeddings=2048, base=10000):
        super().__init__()
        inv_freq = 1.0 / (base ** (<a id="change">paddle.arange(0</a>, dim, <a id="change">2</a><a id="change">, dtype=paddle.get_default_dtype())</a> / dim))
        self.register_buffer("inv_freq", inv_freq)

        t = paddle.arange(max_position_embeddings, dtype=self.inv_freq.dtype)</code></pre><h3>After Change</h3><pre><code class='java'>
class LlamaRotaryEmbedding(nn.Layer):
    def __init__(self, dim, max_position_embeddings=2048, base=10000):
        super().__init__()
        inv_freq = 1.0 / (base ** (paddle.cast(<a id="change">paddle.arange(0</a>, dim, <a id="change">2</a><a id="change">)</a>, "float32") / dim))
        self.register_buffer("inv_freq", inv_freq)

        t = paddle.arange(max_position_embeddings, dtype=self.inv_freq.dtype)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/1bff13e1ca265316b34cbac280d596ce02f9063c#diff-99e104eff4c095428aa1cd5d186107ae22737297e8ec3b5c12cd138e69a79cb5L215' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39238393</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 1bff13e1ca265316b34cbac280d596ce02f9063c</div><div id='time'> Time: 2023-04-22</div><div id='author'> Author: 40840292+linjieccc@users.noreply.github.com</div><div id='file'> File Name: paddlenlp/transformers/llama/modeling.py</div><div id='m_class'> M Class Name: LlamaRotaryEmbedding</div><div id='n_method'> N Class Name: LlamaRotaryEmbedding</div><div id='m_method'> M Method Name: __init__(4)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Layer</div><div id='n_parent_class'> N Parent Class: nn.Layer</div><div id='m_file'> M File Name: paddlenlp/transformers/llama/modeling.py</div><div id='n_file'> N File Name: paddlenlp/transformers/llama/modeling.py</div><div id='m_start'> M Start Line: 217</div><div id='m_end'> M End Line: 217</div><div id='n_start'> N Start Line: 222</div><div id='n_end'> N End Line: 222</div><BR>