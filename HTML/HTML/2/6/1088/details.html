<html><h3>Pattern ID :1088
</h3><img src='5544902.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        if self.args.feature_based:
            pre_pooled_outputs = []
            for pre_t in order:
                <a id="change">with torch</a><a id="change">.no_grad():
                    </a>_<a id="change">,pre_pooled_output = \
                        </a>self.bert(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask,t=pre_t,s=smax)
                pre_pooled_outputs.append(pre_pooled_output.unsqueeze(1).clone())

            pre_pooled_outputs = torch.cat(pre_pooled_outputs, 1)</code></pre><h3>After Change</h3><pre><code class='java'>

    def self_attention_feature(self,t,input_ids,segment_ids,input_mask,pooled_output):
        pre_pooled_outputs = []
        for pre_t in [x for x in <a id="change">range(</a>t<a id="change">)</a>]:
            with torch.no_grad():
                _<a id="change">,pre_pooled_output = \
                    </a>self.bert(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask,t=pre_t,s=self.args.smax)
            pre_pooled_outputs.append(pre_pooled_output.unsqueeze(-1).clone())

</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/zixuanke/pycontinual/commit/833f2f1e90085a86b7c0788324ed13bd72bed021#diff-e55d641584e5258311c89bd5dfd8aae20e3de910f5773c114a9a704366600947L116' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5544902</div><div id='project'> Project Name: zixuanke/pycontinual</div><div id='commit'> Commit Name: 833f2f1e90085a86b7c0788324ed13bd72bed021</div><div id='time'> Time: 2021-11-12</div><div id='author'> Author: iscauzixuanke@gmail.com</div><div id='file'> File Name: src/networks/classification/bert_adapter_mask.py</div><div id='m_class'> M Class Name: Net</div><div id='n_method'> N Class Name: Net</div><div id='m_method'> M Method Name: self_attention_feature(6)</div><div id='n_method'> N Method Name: self_attention_feature(9)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: src/networks/classification/bert_adapter_mask.py</div><div id='n_file'> N File Name: src/networks/classification/bert_adapter_mask.py</div><div id='m_start'> M Start Line: 124</div><div id='m_end'> M End Line: 156</div><div id='n_start'> N Start Line: 116</div><div id='n_end'> N End Line: 130</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        count = torch.zeros_like(self.density_grid)
        poses = poses.to(count.device)

        <a id="change">with torch</a><a id="change">.no_grad():
            </a>for xi, xs in enumerate(X):
                for yi, ys in enumerate(Y):
                    for zi, zs in enumerate(Z):
                        lx, ly, lz = len(xs), len(ys), len(zs)
                        &#47&#47 construct points
                        xx, yy, zz = custom_meshgrid(xs, ys, zs)
                        world_xyzs = torch.cat([xx.reshape(-1, 1), yy.reshape(-1, 1), zz.reshape(-1, 1)], dim=-1).unsqueeze(0).to(count.device) &#47&#47 [1, N, 3]

                        &#47&#47 split batch to avoid OOM
                        head<a id="change"> = </a>0
                        while head &lt; B:
                            tail = min(head + S, B)
</code></pre><h3>After Change</h3><pre><code class='java'>
                    world_xyzs = torch.cat([xx.reshape(-1, 1), yy.reshape(-1, 1), zz.reshape(-1, 1)], dim=-1).unsqueeze(0).to(count.device) &#47&#47 [1, N, 3]

                    &#47&#47 cascading
                    for cas in <a id="change">range(</a>self.cascade<a id="change">)</a>:
                        bound = min(2 ** cas, self.bound)
                        half_grid_size = bound / resolution
                        &#47&#47 scale to current cascade&quots resolution
                        cas_world_xyzs = world_xyzs * (bound - half_grid_size)

                        &#47&#47 split batch to avoid OOM
                        head<a id="change"> = </a>0
                        while head &lt; B:
                            tail = min(head + S, B)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ashawkey/torch-ngp/commit/96af393225fdd443478a79e5b4dd8fe95e4e27b3#diff-96330057ed34864879e5c07ca3b71aa0415cc9281c388c0ec9d3d6892d48343aL327' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5544898</div><div id='project'> Project Name: ashawkey/torch-ngp</div><div id='commit'> Commit Name: 96af393225fdd443478a79e5b4dd8fe95e4e27b3</div><div id='time'> Time: 2022-04-08</div><div id='author'> Author: ashawkey1999@gmail.com</div><div id='file'> File Name: nerf/renderer.py</div><div id='m_class'> M Class Name: NeRFRenderer</div><div id='n_method'> N Class Name: NeRFRenderer</div><div id='m_method'> M Method Name: mark_untrained_grid(4)</div><div id='n_method'> N Method Name: mark_untrained_grid(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: nerf/renderer.py</div><div id='n_file'> N File Name: nerf/renderer.py</div><div id='m_start'> M Start Line: 344</div><div id='m_end'> M End Line: 384</div><div id='n_start'> N Start Line: 345</div><div id='n_end'> N End Line: 390</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            &#47&#47     x_adv, perturb = pgd_attack.perturb(x_real, x_real, c_trg_list[0])

            for c_trg in c_trg_list:
                <a id="change">with torch</a><a id="change">.no_grad():
                    </a>gen_noattack<a id="change">, gen_noattack_feats = </a>self.G(x_real, c_trg)
                &#47&#47 Attack
                x_adv, perturb = pgd_attack.perturb(x_real, black, c_trg)
                &#47&#47 x_adv = x_real + perturb</code></pre><h3>After Change</h3><pre><code class='java'>

        layer_dict = {0: 2, 1: 5, 2: 8, 3: 9, 4: 10, 5: 11, 6: 12, 7: 13, 8: 14, 9: 17, 10: 20, 11: None}

        for layer_num_orig in <a id="change">range(</a>12<a id="change">)</a>:
            &#47&#47 Load the trained generator.
            self.restore_model(self.test_iters)
            
            &#47&#47 Set data loader.
            if self.dataset == &quotCelebA&quot:
                data_loader = self.celeba_loader
            elif self.dataset == &quotRaFD&quot:
                data_loader = self.rafd_loader

            &#47&#47 Initialize Metrics
            l1_error = 0.0
            l2_error = 0.0
            min_dist = 0.0
            l0_error = 0.0
            perceptual_error = 0.0
            n_samples = 0

            &#47&#47 11 layers + output
            &#47&#47 layer_num_orig = 11

            print(&quotLayer&quot, layer_num_orig)
            for i, (x_real, c_org) in enumerate(data_loader):
                &#47&#47 Black image
                black = np.zeros((1,3,256,256))
                black = torch.FloatTensor(black).to(self.device)

                &#47&#47 Prepare input images and target domain labels.
                x_real = x_real.to(self.device)
                c_trg_list = self.create_labels(c_org, self.c_dim, self.dataset, self.selected_attrs)

                layer_num = layer_dict[layer_num_orig]
                pgd_attack = attacks.LinfPGDAttack(model=self.G, device=self.device, feat=layer_num)

                &#47&#47 Translate images.
                x_fake_list = [x_real]

                &#47&#47 if i == 0:
                &#47&#47     x_adv, perturb = pgd_attack.perturb(x_real, x_real, c_trg_list[0])

                for c_trg in c_trg_list:
                    &#47&#47 Attack
                    x_adv, perturb = pgd_attack.perturb(x_real, black, c_trg)
                    &#47&#47 x_adv = x_real + perturb
                    &#47&#47 x_adv = self.blur_tensor(x_adv)

                    &#47&#47 Metrics
                    with torch.no_grad():
                        &#47&#47 gen, preproc_x = self.G(x_adv, c_trg)
                        gen, gen_feats = self.G(x_adv, c_trg)

                        &#47&#47 Add to lists
                        &#47&#47 x_fake_list.append(preproc_x)
                        x_fake_list.append(x_adv)
                        x_fake_list.append(gen)

                        &#47&#47 No Attack
                        &#47&#47 gen_noattack, _ = self.G(x_real, c_trg)
                        gen_noattack<a id="change">, gen_noattack_feats = </a>self.G(x_real, c_trg)

                        l1_error += F.l1_loss(gen, gen_noattack)
                        l2_error += F.mse_loss(gen, gen_noattack)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/natanielruiz/disrupting-deepfakes/commit/572a2bff955b18f76e8ba2cbc181036fed2f7b18#diff-b700ed60ba32817f1933c49049485378be754d9c9f56fc1fd510f39fe9ce0ee0L572' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5544899</div><div id='project'> Project Name: natanielruiz/disrupting-deepfakes</div><div id='commit'> Commit Name: 572a2bff955b18f76e8ba2cbc181036fed2f7b18</div><div id='time'> Time: 2019-12-24</div><div id='author'> Author: nruiz@Nataniels-MacBook-Pro.local</div><div id='file'> File Name: stargan/solver.py</div><div id='m_class'> M Class Name: Solver</div><div id='n_method'> N Class Name: Solver</div><div id='m_method'> M Method Name: test_attack(1)</div><div id='n_method'> N Method Name: test_attack(1)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: stargan/solver.py</div><div id='n_file'> N File Name: stargan/solver.py</div><div id='m_start'> M Start Line: 576</div><div id='m_end'> M End Line: 655</div><div id='n_start'> N Start Line: 660</div><div id='n_end'> N End Line: 743</div><BR>