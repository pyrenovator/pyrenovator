<html><h3>Pattern ID :20580
</h3><img src='66387013.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        dx = self.l_relu(self.linear1(dx))
        dx = self.linear2(dx)
        
        <a id="change">return </a>x_pos<a id="change"> + </a>dx

class NormalNet(nn.Module):
    def __init__(self, device):</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, data):

        z1, x_pos, edge_index = data.z1.to(self.device), data.x_pos.to(self.device), data.edge_index.to(self.device)
        n1<a id="change"> = </a><a id="change">torch.randn(</a>x_pos.shape[0], x_pos.shape[1]<a id="change">)</a>.to(self.device)<a id="change"> * </a>1e-5
        dx = self.l_relu(self.bn1(self.conv1(z1, edge_index)))
        dx = self.l_relu(self.bn2(self.conv2(dx, edge_index)))
        dx = self.l_relu(self.bn3(self.conv3(dx, edge_index)))
        dx = self.l_relu(self.bn4(self.conv4(dx, edge_index)))
        dx = self.l_relu(self.bn5(self.conv5(dx, edge_index)))
        dx = self.l_relu(self.bn6(self.conv6(dx, edge_index)))
        dx = self.l_relu(self.bn7(self.conv7(dx, edge_index)))
        dx = self.l_relu(self.bn8(self.conv8(dx, edge_index)))
        dx = self.l_relu(self.bn9(self.conv9(dx, edge_index)))
        dx = self.l_relu(self.bn10(self.conv10(dx, edge_index)))
        dx = self.l_relu(self.bn11(self.conv11(dx, edge_index)))
        dx = self.l_relu(self.bn12(self.conv12(dx, edge_index)))
        
        dx = self.l_relu(self.linear1(dx))
        dx = self.linear2(dx)
        
        <a id="change">return </a>x_pos + n1 + dx

class NormalNet(nn.Module):
    def __init__(self, device):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/astaka-pe/dual-dmp/commit/00d263b6537e68750d84971a1c4923b7647cafac#diff-1124bd0154af388226a7828f8f3855c9878cb762814f023d5b171f245a7f513aL50' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66387013</div><div id='project'> Project Name: astaka-pe/dual-dmp</div><div id='commit'> Commit Name: 00d263b6537e68750d84971a1c4923b7647cafac</div><div id='time'> Time: 2021-08-20</div><div id='author'> Author: astaka1119@g.ecc.u-tokyo.ac.jp</div><div id='file'> File Name: util/networks.py</div><div id='m_class'> M Class Name: PosNet</div><div id='n_method'> N Class Name: PosNet</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: util/networks.py</div><div id='n_file'> N File Name: util/networks.py</div><div id='m_start'> M Start Line: 65</div><div id='m_end'> M End Line: 67</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 67</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        return predictions

    def masked_mse_loss(self, input, target, mask, background_mask):
        <a id="change">return </a>(background_mask<a id="change"> * </a>(mask * (input - target) ** 2)).mean()

    def general_step(self, batch, batch_idx, mode):
        </code></pre><h3>After Change</h3><pre><code class='java'>
    def masked_mse_loss(self, input, target, mask, background_mask):
        &#47&#47return (background_mask * (input - target) ** 2).mean()
        input = torch.randn(2, 100, 3)
        target = <a id="change">torch.randn(</a>2, 100, 3<a id="change">)</a>
        mask = (input &gt; 0).float()
        background_mask = torch.randn(2, 100, 1)
        value = background_mask * (input - target) ** 2
        mask_sum = torch.sum(mask, dim=1)
        mask_sum_modified = torch.clamp(mask_sum, min=1.0)
        loss<a id="change"> = </a>torch.sum(value<a id="change"> * </a>mask) / mask_sum_modified
        <a id="change">return </a>loss

    &#47&#47 TODO -&gt; do not take into account -1 flow information (or filter them in WaymoDataset?)
    def compute_metrics(self, y, y_hat, mask, labels, background_weight):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jabb0/fastflow3d/commit/bea207737f9d35e204c73ecfcde3de582a10956d#diff-779d8a81f150236174636a6a0444855ba8e0fdbe8cb48dab33acc69be86a699cL117' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66387024</div><div id='project'> Project Name: jabb0/fastflow3d</div><div id='commit'> Commit Name: bea207737f9d35e204c73ecfcde3de582a10956d</div><div id='time'> Time: 2021-06-28</div><div id='author'> Author: carlosmn1997@gmail.com</div><div id='file'> File Name: models/FastFlow3DModelScatter.py</div><div id='m_class'> M Class Name: FastFlow3DModelScatter</div><div id='n_method'> N Class Name: FastFlow3DModelScatter</div><div id='m_method'> M Method Name: masked_mse_loss(5)</div><div id='n_method'> N Method Name: masked_mse_loss(5)</div><div id='m_parent_class'> M Parent Class: pl.LightningModule</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: models/FastFlow3DModelScatter.py</div><div id='n_file'> N File Name: models/FastFlow3DModelScatter.py</div><div id='m_start'> M Start Line: 118</div><div id='m_end'> M End Line: 118</div><div id='n_start'> N Start Line: 120</div><div id='n_end'> N End Line: 128</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            keypoints_list.append(keypoints)

        keypoints = torch.cat(keypoints_list, dim=0)  &#47&#47 (B, M, 3)
        <a id="change">return </a>keypoints

    def forward(self, batch_dict):
        </code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 src_points = src_points[mask]
        &#47&#47 batch_indices = batch_indices[mask]
        &#47&#47 sample points
        keypoints_batch = <a id="change">torch.randn(</a>(batch_size, self.model_cfg[&quotnum_keypoints&quot], 4)<a id="change">, device=src_points.device)</a>
        keypoints_batch[..., 0]<a id="change"> = </a>keypoints_batch[..., 0]<a id="change"> * </a>140
        keypoints_batch[..., 1] = keypoints_batch[..., 0] * 40
        keypoints_batch[..., 2] = 10.0 &#47&#47 points with height flag 10 are padding/invalid, for later filtering
        for bs_idx in range(batch_size):
            bs_mask = (batch_indices == bs_idx)
            sampled_points = src_points[bs_mask].unsqueeze(dim=0)  &#47&#47 (1, N, 3)
            &#47&#47 sample points with FPS
            &#47&#47 some cropped pcd may have very few points, select various number of points to ensure similar sample density
            num_kpts = int(self<a id="change">.model_cfg[&quotnum_keypoints&quot] * sampled_points.shape[1] / </a>50000) + 1 &#47&#47 50000 is approximately the number of points in one full pcd
            num_kpts = min(num_kpts, self.model_cfg[&quotnum_keypoints&quot])
            cur_pt_idxs = pointnet2_stack_utils.furthest_point_sample(
                sampled_points[:, :, 0:3].contiguous(), num_kpts
            ).long()

            if sampled_points.shape[1] &lt; num_kpts:
                empty_num = num_kpts - sampled_points.shape[1]
                cur_pt_idxs[0, -empty_num:] = cur_pt_idxs[0, :empty_num]

            keypoints = sampled_points[0][cur_pt_idxs[0]].unsqueeze(dim=0)

            keypoints_batch[bs_idx, :len(keypoints[0]), :] = keypoints

        &#47&#47 keypoints = torch.cat(keypoints_list, dim=0)  &#47&#47 (B, M, 3)
        <a id="change">return </a>keypoints_batch

    def forward(self, batch_dict):
        </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/derrickxunu/opencood/commit/c7ecf237666697c93ad84b5d271c16e133ac8ccb#diff-a84def6fa3625c35214bd9725c52096ea919f8fed9c4e78a48624b4dc52e6bfeL123' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66386994</div><div id='project'> Project Name: derrickxunu/opencood</div><div id='commit'> Commit Name: c7ecf237666697c93ad84b5d271c16e133ac8ccb</div><div id='time'> Time: 2022-04-01</div><div id='author'> Author: yunshuang.yuan@ikg.uni-hannover.de</div><div id='file'> File Name: opencood/models/sub_modules/vsa.py</div><div id='m_class'> M Class Name: VoxelSetAbstraction</div><div id='n_method'> N Class Name: VoxelSetAbstraction</div><div id='m_method'> M Method Name: get_sampled_points(2)</div><div id='n_method'> N Method Name: get_sampled_points(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: opencood/models/sub_modules/vsa.py</div><div id='n_file'> N File Name: opencood/models/sub_modules/vsa.py</div><div id='m_start'> M Start Line: 143</div><div id='m_end'> M End Line: 161</div><div id='n_start'> N Start Line: 124</div><div id='n_end'> N End Line: 167</div><BR>