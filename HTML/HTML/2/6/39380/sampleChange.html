<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                     bias=bias)
        layers.append(layer)
        &#47&#47 do not use weight_decay in the final layer
        <a id="change">paras.append(</a><a id="change">dict(params=layer.parameters(), weight_decay=0.))</a>

        self.layers = layers
        self.dropout = nn.Dropout(dropout)
        self.compile(loss=torch.nn.CrossEntropyLoss(),</code></pre><h3>After Change</h3><pre><code class='java'>
        conv = []
        conv.append(nn.Dropout(dropout))
        for hid, num_head, act in zip(hids, num_heads, acts):
            <a id="change">conv.append(</a>SparseGraphAttention(in_channels * head,
                                             hid,
                                             attn_heads=num_head,
                                             reduction=&quotconcat&quot,
                                             bias=bias)<a id="change">)</a>
            conv.append(<a id="change">activations.get(act</a><a id="change">)</a>)
            conv.append(<a id="change">nn.Dropout(</a>dropout<a id="change">)</a>)
            in_channels = hid
            head = num_head
        conv.append(SparseGraphAttention(in_channels * head,</code></pre>