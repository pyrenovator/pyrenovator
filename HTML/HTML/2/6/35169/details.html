<html><h3>Pattern ID :35169
</h3><img src='100235931.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def forward(self, input: torch.Tensor) -&gt; torch.Tensor:
        indices = functional.value_to_index(
            input, self.low_value, self.high_value, self.num_embeddings
        ).clamp(0, self.num_embeddings<a id="change"> - 1</a>)

        <a id="change">return </a>super(Thermometer, self).forward(indices).as_subclass(MAP)


class Circular(nn.Embedding):</code></pre><h3>After Change</h3><pre><code class='java'>
            self.weight.copy_(embeddings)

    def forward(self, input: Tensor) -&gt; Tensor:
        index<a id="change"> = </a>functional.value_to_index(
            input, self.low, self.high, self.num_embeddings
        )
        index = index.clamp(min=0, max=self.num_embeddings - 1)
        <a id="change">return </a><a id="change">super().forward(index).as_subclass(</a>self.vsa_model<a id="change">)</a>


class Circular(nn.Embedding):
    Embedding wrapper around :func:`~torchhd.circular_hv`.</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/hyperdimensional-computing/torchhd/commit/90c6926d8c62c42ec5f2726007c581213fb41322#diff-d7f17cefd7a9cec7e1df84bbc00adfc7e0d840fd12a7e7b2fa0859efbfb54530L228' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 100235931</div><div id='project'> Project Name: hyperdimensional-computing/torchhd</div><div id='commit'> Commit Name: 90c6926d8c62c42ec5f2726007c581213fb41322</div><div id='time'> Time: 2023-01-22</div><div id='author'> Author: mikeheddes@gmail.com</div><div id='file'> File Name: torchhd/embeddings.py</div><div id='m_class'> M Class Name: Thermometer</div><div id='n_method'> N Class Name: Thermometer</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Embedding</div><div id='n_parent_class'> N Parent Class: nn.Embedding</div><div id='m_file'> M File Name: torchhd/embeddings.py</div><div id='n_file'> N File Name: torchhd/embeddings.py</div><div id='m_start'> M Start Line: 228</div><div id='m_end'> M End Line: 232</div><div id='n_start'> N Start Line: 613</div><div id='n_end'> N End Line: 617</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def forward(self, input: torch.Tensor) -&gt; torch.Tensor:
        indices = functional.value_to_index(
            input, self.low_value, self.high_value, self.num_embeddings
        ).clamp(0, self.num_embeddings<a id="change"> - 1</a>)

        <a id="change">return </a>super(Level, self).forward(indices).as_subclass(MAP)


class Thermometer(nn.Embedding):</code></pre><h3>After Change</h3><pre><code class='java'>
            self.weight.copy_(embeddings)

    def forward(self, input: Tensor) -&gt; Tensor:
        index<a id="change"> = </a>functional.value_to_index(
            input, self.low, self.high, self.num_embeddings
        )
        index = index.clamp(min=0, max=self.num_embeddings - 1)
        <a id="change">return </a><a id="change">super().forward(index).as_subclass(</a>self.vsa_model<a id="change">)</a>


class Thermometer(nn.Embedding):
    Embedding wrapper around :func:`~torchhd.thermometer_hv`.</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hyperdimensional-computing/torchhd/commit/90c6926d8c62c42ec5f2726007c581213fb41322#diff-d7f17cefd7a9cec7e1df84bbc00adfc7e0d840fd12a7e7b2fa0859efbfb54530L167' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 100235930</div><div id='project'> Project Name: hyperdimensional-computing/torchhd</div><div id='commit'> Commit Name: 90c6926d8c62c42ec5f2726007c581213fb41322</div><div id='time'> Time: 2023-01-22</div><div id='author'> Author: mikeheddes@gmail.com</div><div id='file'> File Name: torchhd/embeddings.py</div><div id='m_class'> M Class Name: Level</div><div id='n_method'> N Class Name: Level</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Embedding</div><div id='n_parent_class'> N Parent Class: nn.Embedding</div><div id='m_file'> M File Name: torchhd/embeddings.py</div><div id='n_file'> N File Name: torchhd/embeddings.py</div><div id='m_start'> M Start Line: 168</div><div id='m_end'> M End Line: 172</div><div id='n_start'> N Start Line: 496</div><div id='n_end'> N End Line: 500</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    levels_per_span = (1 - randomness) * (num_embeddings - 1) + randomness * 1
    &#47&#47 must be at least one to deal with the case that num_embeddings is less than 2
    levels_per_span = max(levels_per_span, 1)
    span = (num_embeddings<a id="change"> - 1</a>) / levels_per_span

    hv = torch.empty(
        num_embeddings,
        embedding_dim,
        dtype=dtype,
        device=device,
    )

    &#47&#47 generate the set of orthogonal vectors within the level vector set
    span_hv = random_hv(
        int(math.ceil(span + 1)),
        embedding_dim,
        generator=generator,
        sparsity=sparsity,
        dtype=dtype,
        device=device,
    )
    &#47&#47 for each span within the set create a threshold vector
    &#47&#47 the threshold vector is used to interpolate between the
    &#47&#47 two random vector bounds of each span.
    threshold_v = torch.rand(
        int(math.ceil(span)),
        embedding_dim,
        generator=generator,
        dtype=torch.float,
        device=device,
    )

    for i in range(num_embeddings):
        span_idx = int(i // levels_per_span)

        &#47&#47 special case: if we are on a span border (e.g. on the first or last levels)
        &#47&#47 then set the orthogonal vector directly.
        &#47&#47 This also prevents an index out of bounds error for the last level
        &#47&#47 when threshold_v[span_idx], and span_hv[span_idx + 1] are not available.
        if abs(i % levels_per_span) &lt; 1e-12:
            hv[i] = span_hv[span_idx]
        else:
            level_within_span = i % levels_per_span
            &#47&#47 the threshold value from the start hv&quots perspective
            t = 1 - (level_within_span / levels_per_span)

            span_start_hv = span_hv[span_idx]
            span_end_hv = span_hv[span_idx + 1]
            hv[i] = torch.where(threshold_v[span_idx] &lt; t, span_start_hv, span_end_hv)

    hv.requires_grad = requires_grad
    <a id="change">return </a>hv


def circular_hv(</code></pre><h3>After Change</h3><pre><code class='java'>
    levels_per_span = (1 - randomness) * (num_vectors - 1) + randomness * 1
    &#47&#47 must be at least one to deal with the case that num_vectors is less than 2
    levels_per_span = max(levels_per_span, 1)
    span<a id="change"> = </a>(num_vectors - 1) / levels_per_span

    &#47&#47 generate the set of orthogonal vectors within the level vector set
    span_hv = model.random_hv(
        int(math.ceil(span + 1)),
        dimensions,
        **kwargs,
    )

    &#47&#47 for each span within the set create a threshold vector
    &#47&#47 the threshold vector is used to interpolate between the
    &#47&#47 two random vector bounds of each span.
    threshold_v = torch.rand(
        int(math.ceil(span)),
        dimensions,
        dtype=torch.float,
        device=kwargs.get("device", None),
        generator=kwargs.get("generator", None),
    )

    hv = torch.empty(
        num_vectors,
        dimensions,
        dtype=span_hv.dtype,
        device=span_hv.device,
    )

    for i in range(num_vectors):
        span_idx = int(i // levels_per_span)

        &#47&#47 special case: if we are on a span border (e.g. on the first or last levels)
        &#47&#47 then set the orthogonal vector directly.
        &#47&#47 This also prevents an index out of bounds error for the last level
        &#47&#47 when threshold_v[span_idx], and span_hv[span_idx + 1] are not available.
        if abs(i % levels_per_span) &lt; 1e-12:
            hv[i] = span_hv[span_idx]
        else:
            level_within_span = i % levels_per_span
            &#47&#47 the threshold value from the start hv&quots perspective
            t = 1 - (level_within_span / levels_per_span)

            span_start_hv = span_hv[span_idx]
            span_end_hv = span_hv[span_idx + 1]
            hv[i] = torch.where(threshold_v[span_idx] &lt; t, span_start_hv, span_end_hv)

    hv.requires_grad = requires_grad
    <a id="change">return </a><a id="change">hv.as_subclass(</a>model<a id="change">)</a>


def circular_hv(
    num_vectors: int,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hyperdimensional-computing/torchhd/commit/b8f0460fe826ce47ff268cb9c2b15048f5d188d1#diff-2eec1c18711dc8b77e517b45771208f50de1693b062b658d75343e8e081d67cdL204' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 100235932</div><div id='project'> Project Name: hyperdimensional-computing/torchhd</div><div id='commit'> Commit Name: b8f0460fe826ce47ff268cb9c2b15048f5d188d1</div><div id='time'> Time: 2022-11-09</div><div id='author'> Author: mikeheddes@gmail.com</div><div id='file'> File Name: torchhd/functional.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: level_hv(3)</div><div id='n_method'> N Method Name: level_hv(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchhd/functional.py</div><div id='n_file'> N File Name: torchhd/functional.py</div><div id='m_start'> M Start Line: 255</div><div id='m_end'> M End Line: 313</div><div id='n_start'> N Start Line: 229</div><div id='n_end'> N End Line: 326</div><BR>