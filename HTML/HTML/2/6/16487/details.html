<html><h3>Pattern ID :16487
</h3><img src='55417276.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    if fixed_size is not None:
        size = [fixed_size[1], fixed_size[0]]
    else:
        min_size<a id="change"> = torch</a><a id="change">.min(</a>im_shape<a id="change">)</a>.to(dtype=torch.float32)
        max_size<a id="change"> = torch</a><a id="change">.max(</a>im_shape<a id="change">)</a>.to(dtype=torch.float32)
        scale = torch.min(self_min_size / min_size, self_max_size / max_size)

        if torchvision._is_tracing():</code></pre><h3>After Change</h3><pre><code class='java'>
    ratio = torch.min(new_shape[0] / im_shape[0], new_shape[1] / im_shape[1])

    ratio_h = torch.round(im_shape[0] * ratio).to(dtype=torch.int32)
    ratio_w = torch.round(<a id="change">im_shape[1]</a> * ratio).to(dtype=torch.int32)

    if torchvision._is_tracing():
        new_unpad = _tracing_item_onnx(ratio_h), _tracing_item_onnx(ratio_w)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/zhiqwang/yolov5-rt-stack/commit/cd1a6ec7cda09de0dc92962a37ecb4f723a8dfeb#diff-60b40f8280cc07f4b1f5ff27c62b172cf2350df49462357850d9ccb60554c3c8L67' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55417276</div><div id='project'> Project Name: zhiqwang/yolov5-rt-stack</div><div id='commit'> Commit Name: cd1a6ec7cda09de0dc92962a37ecb4f723a8dfeb</div><div id='time'> Time: 2022-02-03</div><div id='author'> Author: 92794867+q3394101@users.noreply.github.com</div><div id='file'> File Name: yolort/models/transform.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _resize_image_and_masks(3)</div><div id='n_method'> N Method Name: _resize_image_and_masks(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: yolort/models/transform.py</div><div id='n_file'> N File Name: yolort/models/transform.py</div><div id='m_start'> M Start Line: 257</div><div id='m_end'> M End Line: 286</div><div id='n_start'> N Start Line: 67</div><div id='n_end'> N End Line: 77</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        )

        B, C, H, W = gcam.shape
        <a id="change">gcam</a> = gcam.view(B, -1)
        gcam<a id="change"> -= </a><a id="change">gcam.min(dim=1, keepdim=True)</a>[0]
        gcam<a id="change"> /= </a><a id="change">gcam.max(dim=1, keepdim=True)</a>[0]
        gcam = gcam.view(B, C, H, W)

        return gcam</code></pre><h3>After Change</h3><pre><code class='java'>
            fmaps, weights = self.select_highest_layer()
            gcam = []
            for i in range(self.logits.shape[0]):
                gcam.append(self.generate_helper(<a id="change">fmaps[i]</a>.unsqueeze(0), weights[i].unsqueeze(0)))
        else:
            fmaps = self._find(self.fmap_pool, target_layer)
            grads = self._find(self.grad_pool, target_layer)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/karol-g/gcam/commit/4d3673129f7f35d0b6ea05944a037268b4da45b2#diff-978485ec7cfb0b80eb5a414e89c1afc3b49e03fb985bcad877ce02e5af9cfe59L207' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55417263</div><div id='project'> Project Name: karol-g/gcam</div><div id='commit'> Commit Name: 4d3673129f7f35d0b6ea05944a037268b4da45b2</div><div id='time'> Time: 2020-01-02</div><div id='author'> Author: KarolGotkowski@gmx.de</div><div id='file'> File Name: evaluation_models/grad_cam/grad_cam.py</div><div id='m_class'> M Class Name: GradCAM</div><div id='n_method'> N Class Name: GradCAM</div><div id='m_method'> M Method Name: generate(2)</div><div id='n_method'> N Method Name: generate(2)</div><div id='m_parent_class'> M Parent Class: _BaseWrapper</div><div id='n_parent_class'> N Parent Class: _BaseWrapper</div><div id='m_file'> M File Name: evaluation_models/grad_cam/grad_cam.py</div><div id='n_file'> N File Name: evaluation_models/grad_cam/grad_cam.py</div><div id='m_start'> M Start Line: 209</div><div id='m_end'> M End Line: 228</div><div id='n_start'> N Start Line: 231</div><div id='n_end'> N End Line: 244</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if fixed_size is not None:
        size = [fixed_size[1], fixed_size[0]]
    else:
        min_size<a id="change"> = </a><a id="change">torch.min(</a>im_shape<a id="change">)</a>.to(dtype=torch.float32)
        max_size<a id="change"> = </a><a id="change">torch.max(</a>im_shape<a id="change">)</a>.to(dtype=torch.float32)
        scale = torch.min(self_min_size / min_size, self_max_size / max_size)

        if torchvision._is_tracing():</code></pre><h3>After Change</h3><pre><code class='java'>
    else:
        im_shape = torch.tensor(image.shape[-2:])

    ratio = torch.min(new_shape[0] / <a id="change">im_shape[0]</a>, new_shape[1] / im_shape[1])

    ratio_h = torch.round(im_shape[0] * ratio).to(dtype=torch.int32)
    ratio_w = torch.round(im_shape[1] * ratio).to(dtype=torch.int32)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/zhiqwang/yolov5-rt-stack/commit/cd1a6ec7cda09de0dc92962a37ecb4f723a8dfeb#diff-60b40f8280cc07f4b1f5ff27c62b172cf2350df49462357850d9ccb60554c3c8L255' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55417256</div><div id='project'> Project Name: zhiqwang/yolov5-rt-stack</div><div id='commit'> Commit Name: cd1a6ec7cda09de0dc92962a37ecb4f723a8dfeb</div><div id='time'> Time: 2022-02-03</div><div id='author'> Author: 92794867+q3394101@users.noreply.github.com</div><div id='file'> File Name: yolort/models/transform.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _resize_image_and_masks(3)</div><div id='n_method'> N Method Name: _resize_image_and_masks(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: yolort/models/transform.py</div><div id='n_file'> N File Name: yolort/models/transform.py</div><div id='m_start'> M Start Line: 257</div><div id='m_end'> M End Line: 286</div><div id='n_start'> N Start Line: 67</div><div id='n_end'> N End Line: 77</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    avg_last_hidden_test)

                &#47&#47 Scale Data
                domain<a id="change"> = </a><a id="change">np.max(</a>avg_test_var<a id="change">)</a> - np.min(avg_test_var)
                &#47&#47 Shift.
                avg_test_var<a id="change"> = </a>avg_test_var - <a id="change">np.min(</a>avg_test_var<a id="change">)</a>
                &#47&#47 Scale domain to 1.
                avg_test_var = avg_test_var / domain
                &#47&#47 Apply log scale and flip.
                avg_test_var = np.maximum(</code></pre><h3>After Change</h3><pre><code class='java'>
                &#47&#47     0, -np.log(avg_test_var + np.exp(-10)))

                predictions[:, task:task + 1] = avg_test_preds
                <a id="change">confidence[:, task:task + 1]</a> = avg_test_var

            predictions = self.scaler.inverse_transform(predictions)
            confidence = (self.scaler.inverse_transform(predictions +</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/aamini/chemprop/commit/63fcc59dcdf5c1b632996f3d2a1119051ab17761#diff-924093af4f0b2f23d513401ba28883251a8f99c68b3c14268d44a9dc4be67f5bL100' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55417271</div><div id='project'> Project Name: aamini/chemprop</div><div id='commit'> Commit Name: 63fcc59dcdf5c1b632996f3d2a1119051ab17761</div><div id='time'> Time: 2019-09-30</div><div id='author'> Author: liortulip@gmail.com</div><div id='file'> File Name: chemprop/train/confidence_estimator.py</div><div id='m_class'> M Class Name: GaussianProcessEstimator</div><div id='n_method'> N Class Name: GaussianProcessEstimator</div><div id='m_method'> M Method Name: compute_confidence(2)</div><div id='n_method'> N Method Name: compute_confidence(2)</div><div id='m_parent_class'> M Parent Class: DroppingEstimator</div><div id='n_parent_class'> N Parent Class: DroppingEstimator</div><div id='m_file'> M File Name: chemprop/train/confidence_estimator.py</div><div id='n_file'> N File Name: chemprop/train/confidence_estimator.py</div><div id='m_start'> M Start Line: 121</div><div id='m_end'> M End Line: 128</div><div id='n_start'> N Start Line: 133</div><div id='n_end'> N End Line: 139</div><BR>