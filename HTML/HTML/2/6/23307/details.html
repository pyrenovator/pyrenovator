<html><h3>Pattern ID :23307
</h3><img src='73470129.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                self.backprop_count += 1

    def collect_rollout_step(self, rollouts):
        <a id="change">print("new rollout step"</a><a id="change">)</a>
        &#47&#47 sample actions
        with torch.no_grad():
            step_observation = {
                k: v[rollouts.step].to(self.device)</code></pre><h3>After Change</h3><pre><code class='java'>
            and self.teacher_forcing(self.rollout_count) &gt; 0
        ):
            tf_mask_shape = step_observation["expert_action"].shape[:-1] + (1,)
            expert_actions<a id="change"> = </a>(
                step_observation["expert_action"].view(-1, 2)[:, 0].view(*tf_mask_shape)
            )
            expert_action_exists_mask<a id="change"> = </a>(
                step_observation["expert_action"].view(-1, 2)[:, 1].view(*tf_mask_shape)
            )
            teacher_forcing_mask = (
                torch.distributions.bernoulli.Bernoulli(
                    <a id="change">torch.tensor(</a>self.teacher_forcing(self.rollout_count)<a id="change">)</a>
                )
                .sample(tf_mask_shape)
                .long()
                .to(self.device)
            ) * expert_action_exists_mask
            actions<a id="change"> = </a>(
                teacher_forcing_mask * expert_actions
                + (1 - teacher_forcing_mask) * actions
            )</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/allenai/allenact/commit/8e313465b05e6546339b02ea73bc1ded059bab14#diff-8f5bf720a80a4913f8c876005730914b873c5b458dba881a99dcb04b54de373fL168' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73470129</div><div id='project'> Project Name: allenai/allenact</div><div id='commit'> Commit Name: 8e313465b05e6546339b02ea73bc1ded059bab14</div><div id='time'> Time: 2020-01-20</div><div id='author'> Author: lucaw@allenai.org</div><div id='file'> File Name: onpolicy_sync/trainer.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: collect_rollout_step(2)</div><div id='n_method'> N Method Name: collect_rollout_step(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: onpolicy_sync/trainer.py</div><div id='n_file'> N File Name: onpolicy_sync/trainer.py</div><div id='m_start'> M Start Line: 168</div><div id='m_end'> M End Line: 194</div><div id='n_start'> N Start Line: 184</div><div id='n_end'> N End Line: 213</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        optimizer = optim.Adam(train_params, lr=self.poison_lr)
        criterion = nn.CrossEntropyLoss()

        <a id="change">print("fine-tuning"</a><a id="change">)</a>
        self.model.cuda()
        loss, n_sample = 0.0, 0

        self.model.train()</code></pre><h3>After Change</h3><pre><code class='java'>
            param.requires_grad = True

        yt_num = len(self.yt_labels)
        ynt_num<a id="change"> = </a>len(self.ynt_labels)
        all_num = yt_num + ynt_num
        fine_tune_inds = np.random.choice(list(range(all_num)), 
                         int(all_num*self.fine_tune_set_ratio), 
                         replace=False)

        fine_tune_imgs<a id="change"> = </a>torch.tensor(self.yt_imgs.tolist()+self.ynt_imgs.tolist())[fine_tune_inds]
        fine_tune_labels<a id="change"> = </a><a id="change">torch.tensor(</a>self.yt_labels.tolist()+self.ynt_labels.tolist()<a id="change">)</a>[fine_tune_inds]

        &#47&#47 only update last layer parameters
        optimizer = optim.Adam(train_params, lr=self.poison_lr)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ain-soph/trojanzoo/commit/e1fa2f5536d966e225a2d40eddb80b9725daca34#diff-1e9f08cdcf107dac703ba6ade89c7699ee84615bf2b5cdd4e776168a691df4dfL218' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73470121</div><div id='project'> Project Name: ain-soph/trojanzoo</div><div id='commit'> Commit Name: e1fa2f5536d966e225a2d40eddb80b9725daca34</div><div id='time'> Time: 2020-06-27</div><div id='author'> Author: zxx5113@lrs-twang01.ist.psu.edu</div><div id='file'> File Name: trojanzoo/attack/backdoor/latent_backdoor.py</div><div id='m_class'> M Class Name: Latent_Backdoor</div><div id='n_method'> N Class Name: Latent_Backdoor</div><div id='m_method'> M Method Name: student_fine_tuning(1)</div><div id='n_method'> N Method Name: student_fine_tuning(1)</div><div id='m_parent_class'> M Parent Class: BadNet</div><div id='n_parent_class'> N Parent Class: BadNet</div><div id='m_file'> M File Name: trojanzoo/attack/backdoor/latent_backdoor.py</div><div id='n_file'> N File Name: trojanzoo/attack/backdoor/latent_backdoor.py</div><div id='m_start'> M Start Line: 231</div><div id='m_end'> M End Line: 249</div><div id='n_start'> N Start Line: 248</div><div id='n_end'> N End Line: 269</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        optimizer.step()
        losses.append(loss.item())
        print(&quotstep:&quot, step, &quotloss:&quot, loss.item())
    <a id="change">print(&quotfinished training&quot</a><a id="change">)</a>
    return losses


def main():</code></pre><h3>After Change</h3><pre><code class='java'>
        optimizer.zero_grad()

        &#47&#47 Build batched input.
        input_arrays<a id="change"> = </a>[]
        for _ in range(myconfig.BATCH_SIZE):
            anchor, pos, neg = feature_extraction.get_triplet_features_trimmed(
                spk_to_utts)
            input_arrays<a id="change"> += </a>[anchor.transpose(), pos.transpose(),
                             neg.transpose()]
        batch_input = torch.from_numpy(np.stack(input_arrays)).float()

        &#47&#47 Compute loss.
        batch_output = encoder(batch_input)[:, -1, :]
        loss = <a id="change">torch.tensor(</a>0.0<a id="change">)</a>
        for batch in range(myconfig.BATCH_SIZE):
            loss<a id="change"> += </a>my_triplet(
                batch_output[batch * 3, :],
                batch_output[batch * 3 + 1, :],
                batch_output[batch * 3 + 2, :])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/wq2012/speakerrecognitionfromscratch/commit/5851b0d7a32e7c84558b0f09be2ab28c0552f9e6#diff-3f06ab74d880d0cd6059092134ddab037fe075b5c00c3200779d5724334b0298L35' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73470120</div><div id='project'> Project Name: wq2012/speakerrecognitionfromscratch</div><div id='commit'> Commit Name: 5851b0d7a32e7c84558b0f09be2ab28c0552f9e6</div><div id='time'> Time: 2022-05-07</div><div id='author'> Author: quanw@google.com</div><div id='file'> File Name: neural_net.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train_network(2)</div><div id='n_method'> N Method Name: train_network(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: neural_net.py</div><div id='n_file'> N File Name: neural_net.py</div><div id='m_start'> M Start Line: 37</div><div id='m_end'> M End Line: 63</div><div id='n_start'> N Start Line: 40</div><div id='n_end'> N End Line: 81</div><BR>