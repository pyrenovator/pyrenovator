<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                self.backprop_count += 1

    def collect_rollout_step(self, rollouts):
        <a id="change">print("new rollout step"</a><a id="change">)</a>
        &#47&#47 sample actions
        with torch.no_grad():
            step_observation = {
                k: v[rollouts.step].to(self.device)</code></pre><h3>After Change</h3><pre><code class='java'>
            and self.teacher_forcing(self.rollout_count) &gt; 0
        ):
            tf_mask_shape = step_observation["expert_action"].shape[:-1] + (1,)
            expert_actions<a id="change"> = </a>(
                step_observation["expert_action"].view(-1, 2)[:, 0].view(*tf_mask_shape)
            )
            expert_action_exists_mask<a id="change"> = </a>(
                step_observation["expert_action"].view(-1, 2)[:, 1].view(*tf_mask_shape)
            )
            teacher_forcing_mask = (
                torch.distributions.bernoulli.Bernoulli(
                    <a id="change">torch.tensor(</a>self.teacher_forcing(self.rollout_count)<a id="change">)</a>
                )
                .sample(tf_mask_shape)
                .long()
                .to(self.device)
            ) * expert_action_exists_mask
            actions<a id="change"> = </a>(
                teacher_forcing_mask * expert_actions
                + (1 - teacher_forcing_mask) * actions
            )</code></pre>