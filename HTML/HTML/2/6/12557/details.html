<html><h3>Pattern ID :12557
</h3><img src='42666443.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                has_annotations = True
                break

        <a id="change">if </a>not has_annotations:
            return datasets.Dataset.from_dict({})

        class_tags = ["O"]
        class_tags.extend(
            [
                f"{pre}-{label}"
                for label in sorted(self.__all_labels__())
                for pre in <a id="change">[</a>"B", "I"<a id="change"></a>]
            ]
        )
        class_tags = datasets.ClassLabel(names=class_tags)

        def spans2iob(example):
            r = TokenClassificationRecord(
                text=example["text"],
                tokens=example["tokens"],
                annotation=self.__entities_to_tuple__(example["annotation"]),
            )
            return class_tags.str2int(r.spans2iob(r.annotation))

        ds<a id="change"> = </a>(
            <a id="change">self.to_datasets()
            .filter(self.__only_annotations__)
            .map(</a>lambda example: {"ner_tags": spans2iob(example)}<a id="change">)
        )</a>
        new_features = ds.features.copy()
        new_features["ner_tags"] = [class_tags]

        return ds.cast(new_features)</code></pre><h3>After Change</h3><pre><code class='java'>
        

        &#47&#47 turn the string into a Framework instance and trigger error if str is not valid
        <a id="change">if </a>isinstance(framework, str):
            framework<a id="change"> = </a>Framework(framework)

        if framework is Framework.TRANSFORMERS:
            return self._prepare_for_training_with_transformers()</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/recognai/rubrix/commit/85878087144723695568ebde0d04e16fc9de3c1c#diff-a61b31bccfa74d94f686dc19d055112f419a2a0c535a55891361b7e1cf030b11L766' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 42666443</div><div id='project'> Project Name: recognai/rubrix</div><div id='commit'> Commit Name: 85878087144723695568ebde0d04e16fc9de3c1c</div><div id='time'> Time: 2022-08-22</div><div id='author'> Author: francisco@recogn.ai</div><div id='file'> File Name: src/rubrix/client/datasets.py</div><div id='m_class'> M Class Name: DatasetForTokenClassification</div><div id='n_method'> N Class Name: DatasetForTokenClassification</div><div id='m_method'> M Method Name: prepare_for_training(3)</div><div id='n_method'> N Method Name: prepare_for_training(1)</div><div id='m_parent_class'> M Parent Class: DatasetBase</div><div id='n_parent_class'> N Parent Class: DatasetBase</div><div id='m_file'> M File Name: src/rubrix/client/datasets.py</div><div id='n_file'> N File Name: src/rubrix/client/datasets.py</div><div id='m_start'> M Start Line: 766</div><div id='m_end'> M End Line: 842</div><div id='n_start'> N Start Line: 793</div><div id='n_end'> N End Line: 854</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            
        df_stamp = df_raw[[&quotdate&quot]][border1:border2]
        df_stamp[&quotdate&quot] = pd.to_datetime(df_stamp.date)
        <a id="change">if </a>self.timeenc==0:
            df_stamp[&quotmonth&quot] = df_stamp.date.apply(lambda row:row.month,1)
            df_stamp[&quotday&quot] = df_stamp.date.apply(lambda row:row.day,1)
            df_stamp[&quotweekday&quot] = df_stamp.date.apply(lambda row:row.weekday(),1)
            df_stamp[&quothour&quot] = df_stamp.date.apply(lambda row:row.hour,1)
            df_stamp[&quotminute&quot] = df_stamp.date.apply(lambda row:row.minute,1)
            df_stamp[&quotminute&quot]<a id="change"> = </a><a id="change">df_stamp.minute.map(</a>lambda x:x//15<a id="change">)</a>
            data_stamp = df_stamp.drop(<a id="change">[</a>&quotdate&quot<a id="change"></a>],1).values
        elif self.timeenc==1:
            data_stamp = time_features(pd.to_datetime(df_stamp[&quotdate&quot].values), freq=self.freq)
            data_stamp = data_stamp.transpose(1,0)</code></pre><h3>After Change</h3><pre><code class='java'>
        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)
        
        self.data_x = data[border1:border2]
        <a id="change">if </a>self.inverse:
            self.data_y<a id="change"> = </a>df_data.values[border1:border2]
        else:
            self.data_y = data[border1:border2]
        self.data_stamp = data_stamp</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/zhouhaoyi/informer2020/commit/416f8c1a181b94b50b8837849dd9408bd7e5327b#diff-c4fd4034971cc4beee09e41ff3d4eb43e20a5fb5cd311886b5ee00dda674e0b7L130' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 42666427</div><div id='project'> Project Name: zhouhaoyi/informer2020</div><div id='commit'> Commit Name: 416f8c1a181b94b50b8837849dd9408bd7e5327b</div><div id='time'> Time: 2021-03-29</div><div id='author'> Author: 1095715895@qq.com</div><div id='file'> File Name: data/data_loader.py</div><div id='m_class'> M Class Name: Dataset_ETT_minute</div><div id='n_method'> N Class Name: Dataset_ETT_minute</div><div id='m_method'> M Method Name: __read_data__(1)</div><div id='n_method'> N Method Name: __read_data__(1)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: data/data_loader.py</div><div id='n_file'> N File Name: data/data_loader.py</div><div id='m_start'> M Start Line: 154</div><div id='m_end'> M End Line: 168</div><div id='n_start'> N Start Line: 135</div><div id='n_end'> N End Line: 160</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

  &#47&#47 Batch and reshape to [num_devices, batch_size_per_device] with padding.
  num_devices = jax.local_device_count()
  <a id="change">if </a>drop_remainder:
    &#47&#47 If we&quotre dropping the remainder, we can take the fast path of double
    &#47&#47 batching to [num_devices, batch_size_per_device] and then adding a mask of
    &#47&#47 ones for the two batch dimensions.
    batch_size_per_device = process_batch_size // num_devices
    batch_dims = [num_devices, batch_size_per_device]
    for batch_size in reversed(batch_dims):
      ds = ds.batch(batch_size, drop_remainder=True)

    ds = ds.map(
        lambda xs: _add_mask(xs, 2), num_parallel_calls=tf.data.AUTOTUNE)
  else:
    &#47&#47 If we&quotre not dropping the remainder, then we define a flattened batch size
    &#47&#47 that would divide evenly across devices, and then batch to that size with
    &#47&#47 drop_remainder=False. Then we add a mask of ones for the examples given,
    &#47&#47 pad each flattened batch with zeros (including the mask) to ensure all
    &#47&#47 batches have the same number of examples, and then reshape to
    &#47&#47 [num_devices, batch_size_per_device].
    batch_size_per_device = math.ceil(process_batch_size / num_devices)
    flat_batch_size = batch_size_per_device * num_devices
    ds = ds.batch(flat_batch_size, drop_remainder=drop_remainder)

    def f(xs):
      return _pad_reshape_batch(_add_mask(xs, 1), flat_batch_size, num_devices)

    ds<a id="change"> = </a><a id="change">ds.map(</a>f<a id="change">, num_parallel_calls=tf.data.AUTOTUNE)</a>

  if cache == "batched":
    ds = ds.cache()
</code></pre><h3>After Change</h3><pre><code class='java'>
  num_devices = jax.local_device_count()
  batch_size_per_device = process_batch_size // num_devices

  <a id="change">if </a>not drop_remainder:
    &#47&#47 If we&quotre not dropping the remainder, then we append additional zero-valued
    &#47&#47 examples with zero-valued masks to the dataset such that batching with
    &#47&#47 drop_remainder=True will yield a dataset whose final batch is padded as
    &#47&#47 needed.
    &#47&#47 NOTE: We&quotre batching the dataset over two dimensions,
    &#47&#47 `batch_size_per_device` and `num_devices`. Therefore, adding
    &#47&#47 `batch_size_per_device*num_devices - 1` padding examples covers the worst
    &#47&#47 case of 1 example left over after the first batching application with
    &#47&#47 batch size `batch_size_per_device` (since we&quotd need
    &#47&#47 `batch_size_per_device*num_devices - 1` additional examples).
    padding_example<a id="change"> = </a>tf.nest.map_structure(
        lambda spec: tf.zeros(spec.shape, spec.dtype)[None], ds.element_spec)
    padding_example["mask"] = <a id="change">[</a>0.<a id="change"></a>]
    padding_dataset = tf.data.Dataset.from_tensor_slices(padding_example)
    ds = ds.concatenate(
        padding_dataset.repeat(batch_size_per_device * num_devices - 1))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/google/uncertainty-baselines/commit/5ef136b370a87f81dc0d0f1f57757d0432b2bc6a#diff-e4b4b686345ec38b48dee362ed9131cd71626908a9b2dce0a6ad0ebb71cd4a83L217' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 42666428</div><div id='project'> Project Name: google/uncertainty-baselines</div><div id='commit'> Commit Name: 5ef136b370a87f81dc0d0f1f57757d0432b2bc6a</div><div id='time'> Time: 2022-05-17</div><div id='author'> Author: dusenberrymw@google.com</div><div id='file'> File Name: baselines/jft/input_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: get_data(15)</div><div id='n_method'> N Method Name: get_data(15)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: baselines/jft/input_utils.py</div><div id='n_file'> N File Name: baselines/jft/input_utils.py</div><div id='m_start'> M Start Line: 291</div><div id='m_end'> M End Line: 344</div><div id='n_start'> N Start Line: 267</div><div id='n_end'> N End Line: 324</div><BR>