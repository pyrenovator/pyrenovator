<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

def main() -&gt; None:
    Run example.
    <a id="change">logger.info(f"features: {features}"</a><a id="change">)</a>
    logger.info(f"truth: {truth}")

    &#47&#47 single integer definition of class
    &#47&#47class_options = 3
    &#47&#47 list of classes
    &#47&#47class_options = [0,1,2]
    &#47&#47 transformation of target to a given class integer
    class_options = {
    1:0,-1:0,
    13:1,-13:1,
    12:2,-12:2,14:2,-14:2,16:2,-16:2
    }

    &#47&#47 Configuration
    config = {
        "db": "/groups/icecube/petersen/GraphNetDatabaseRepository/Leon_MC_data/last_one_lvl3MC.db",
        "pulsemap": "SplitInIcePulses",
        "batch_size": 32,
        "num_workers": 5,
        "accelerator": "cpu", &#47&#47gpu
        "devices": 1,&#47&#47[0],
        "target": "pid",
        "classification": class_options,
        "n_epochs": 5,
        "patience": 5,
    }
    archive = "/groups/icecube/asogaard/gnn/results/"
    run_name = "dynedge_{}_example".format(config["target"])

    &#47&#47 Log configuration to W&B
    wandb_logger.experiment.config.update(config)

    &#47&#47 Common variables
    train_selection = get_desired_event_numbers(
    database = cast(str, config["db"]),
    desired_size = 1000,
    fraction_noise = float(1/3),
    fraction_muon = float(1/3),
    fraction_nu_e = float(1/9),
    fraction_nu_mu = float(1/9),
    fraction_nu_tau = float(1/9),
    )

    (
        training_dataloader,
        validation_dataloader,
    ) = make_train_validation_dataloader(
        cast(str, config["db"]),
        train_selection,
        cast(str, config["pulsemap"]),
        features,
        truth,
        batch_size=cast(int, config["batch_size"]),
        num_workers=cast(int, config["num_workers"]),
    )

    &#47&#47 Building model
    detector = IceCubeDeepCore(
        graph_builder=KNNGraphBuilder(nb_nearest_neighbours=8),
    )
    gnn = DynEdge(
        nb_inputs=detector.nb_outputs,
        global_pooling_schemes=["min", "max", "mean", "sum"],
    )
    task = ClassificationTask(
        nb_classes=len(np.unique(list(class_options.values()))),
        hidden_size=gnn.nb_outputs,
        target_labels=config["target"],
        loss_function=NLLLoss(
            options=config["classification"]
            ),
    )
    model = StandardModel(
        detector=detector,
        gnn=gnn,
        tasks=[task],
        optimizer_class=Adam,
        optimizer_kwargs={"lr": 1e-03, "eps": 1e-03},
        scheduler_class=PiecewiseLinearLR,
        scheduler_kwargs={
            "milestones": [
                0,
                len(training_dataloader) / 2,
                len(training_dataloader) * cast(int, config["n_epochs"]),
            ],
            "factors": [1e-2, 1, 1e-02],
        },
        scheduler_config={
            "interval": "step",
        },
    )

    &#47&#47 Training model
    callbacks = [
        EarlyStopping(
            monitor="val_loss",
            patience=config["patience"],
        ),
        ProgressBar(),
    ]

    trainer = Trainer(
        accelerator=config["accelerator"],
        devices=config["devices"],
        max_epochs=config["n_epochs"],
        callbacks=callbacks,
        log_every_n_steps=1,
        logger=wandb_logger,
    )

    try:
        trainer.fit(model, training_dataloader, validation_dataloader)
    except KeyboardInterrupt:
        <a id="change">logger.warning("[ctrl+c] Exiting gracefully."</a><a id="change">)</a>
        pass

    &#47&#47 Saving predictions to file
    results = get_predictions(</code></pre><h3>After Change</h3><pre><code class='java'>
        trainer.fit(model, training_dataloader, validation_dataloader)
    except KeyboardInterrupt:
        &#47&#47 logger.warning("[ctrl+c] Exiting gracefully.")
        <a id="change">pass</a>

    &#47&#47 Saving predictions to file
    results = get_predictions(
        trainer,</code></pre>