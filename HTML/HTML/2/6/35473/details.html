<html><h3>Pattern ID :35473
</h3><img src='101382952.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        base_optimizer_group_states = []
        for i in range(len(self.optimizer.param_groups)):
            partition_states = {}
            all_partition_group_states = <a id="change">[
                sd[&quotbase_optimizer_state&quot][i] for sd in all_state_dict
            ]</a>

            if self.is_moe_group(self.optimizer.param_groups[i]):
                ranks = self.get_ep_ranks()
                all_partition_group_states = [</code></pre><h3>After Change</h3><pre><code class='java'>
            return all_partition_states[0]

    def _restore_base_optimizer_state(self, base_optimizer_group_states):
        <a id="change">if type(base_optimizer_group_states) == dict</a>:
            base_optimizer_group_states<a id="change"> = </a>base_optimizer_group_states[&quotstate&quot]
        for i, group in enumerate(self.optimizer.param_groups):
            p = group[&quotparams&quot][0]
            for key, saved in base_optimizer_group_states[i].items():</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/3293cf72a0abd5cf77a831996bd054bc908476a6#diff-99dcf26ea2876ff5bbf05b5165c4133eaa0d0f36b170685643c2f7e2eb566addL2066' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 101382952</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: 3293cf72a0abd5cf77a831996bd054bc908476a6</div><div id='time'> Time: 2022-01-14</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/runtime/zero/stage_1_and_2.py</div><div id='m_class'> M Class Name: DeepSpeedZeroOptimizer</div><div id='n_method'> N Class Name: DeepSpeedZeroOptimizer</div><div id='m_method'> M Method Name: _restore_base_optimizer_state(2)</div><div id='n_method'> N Method Name: _restore_base_optimizer_state(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: deepspeed/runtime/zero/stage_1_and_2.py</div><div id='n_file'> N File Name: deepspeed/runtime/zero/stage_1_and_2.py</div><div id='m_start'> M Start Line: 2070</div><div id='m_end'> M End Line: 2097</div><div id='n_start'> N Start Line: 2066</div><div id='n_end'> N End Line: 2074</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            if isinstance(self._student_inputs, Tensor)
            else self._student_inputs[0].device
            if isinstance(self._student_inputs, Iterable)
            else <a id="change">[
                tens.device
                for tens in self._student_inputs.values()
                if isinstance(tens, Tensor)
            ]</a>[0]
        )
        self._teacher.to(target_device)
</code></pre><h3>After Change</h3><pre><code class='java'>
                teacher_inputs, self._teacher, check_feat_lab_inp=False
            )

        <a id="change">if type(student_outputs) != type(teacher_outputs)</a>:
            raise ValueError(
                "Student and teacher models must have the same output type"
            )

        distill_losses = []
        if isinstance(student_outputs, Tensor):
            distill_losses.append(
                self._calc_distill_loss(student_outputs, teacher_outputs)
            )
        elif isinstance(student_outputs, Dict):
            for key in self._distill_output_keys or student_outputs:
                distill_losses.append(
                    self._calc_distill_loss(student_outputs[key], teacher_outputs[key])
                )
        elif isinstance(student_outputs, Iterable):
            for idx in self._distill_output_keys or range(len(student_outputs)):
                distill_losses.append(
                    self._calc_distill_loss(student_outputs[idx], teacher_outputs[idx])
                )

        &#47&#47 get distillation loss as average of individual output distillation loss values
        teacher_loss = sum(distill_losses) / len(distill_losses)
        distillation_loss = ((1.0 - self._hardness) * loss) + (
            self._hardness * teacher_loss
        )
        global_step<a id="change"> = </a>kwargs.get("global_step")
        global_step = epoch * steps_per_epoch if global_step is None else global_step
        _log_losses(self.loggers, global_step, loss, teacher_loss, distillation_loss)
        return distillation_loss</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neuralmagic/sparseml/commit/6a4767337b993070bc55cc0bac99c076ab84cb47#diff-37a1d70c58e00289a182955989f1d34a7b14be0cae1ced43409e44cb36926904L217' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 101382943</div><div id='project'> Project Name: neuralmagic/sparseml</div><div id='commit'> Commit Name: 6a4767337b993070bc55cc0bac99c076ab84cb47</div><div id='time'> Time: 2021-10-07</div><div id='author'> Author: tuan@neuralmagic.com</div><div id='file'> File Name: src/sparseml/pytorch/optim/modifier_distillation.py</div><div id='m_class'> M Class Name: DistillationModifier</div><div id='n_method'> N Class Name: DistillationModifier</div><div id='m_method'> M Method Name: loss_update(8)</div><div id='n_method'> N Method Name: loss_update(6)</div><div id='m_parent_class'> M Parent Class: ScheduledModifier</div><div id='n_parent_class'> N Parent Class: ScheduledModifier</div><div id='m_file'> M File Name: src/sparseml/pytorch/optim/modifier_distillation.py</div><div id='n_file'> N File Name: src/sparseml/pytorch/optim/modifier_distillation.py</div><div id='m_start'> M Start Line: 241</div><div id='m_end'> M End Line: 297</div><div id='n_start'> N Start Line: 225</div><div id='n_end'> N End Line: 290</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            pred = self.model(X)
            [fn(pred, y) for fn in self.metric_fns]
        result = {type(fn).__name__: fn.compute().item() for fn in self.metric_fns}
        <a id="change">[fn.reset() for fn in self.metric_fns]</a>
        return result
</code></pre><h3>After Change</h3><pre><code class='java'>
                    if get_package_name(fn) == "torchmetrics":
                        fn(pred, y.int())
                    elif get_package_name(fn) == "sklearn":
                        <a id="change">if type(fn).__name__ not in sklearn_intermediates</a>:
                            sklearn_intermediates[fn.__name__]<a id="change"> = </a>0
                        sklearn_intermediates[fn.__name__] += fn(
                            y.cpu().data.numpy(), pred.cpu().data.numpy())
        &#47&#47 torchmetrics compute and reset</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ryantd/veloce/commit/aca7bbb15fbcbae885dd418e7ff969ad4828703e#diff-10a63a56f6f260c3a8cc88a30331e16de36e33f42ccd316cb27d96f83f790d53L125' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 101382956</div><div id='project'> Project Name: ryantd/veloce</div><div id='commit'> Commit Name: aca7bbb15fbcbae885dd418e7ff969ad4828703e</div><div id='time'> Time: 2022-01-04</div><div id='author'> Author: xiaoyu.zhai@hotmail.com</div><div id='file'> File Name: phetware/epochvisor.py</div><div id='m_class'> M Class Name: Epochvisor</div><div id='n_method'> N Class Name: Epochvisor</div><div id='m_method'> M Method Name: test_epoch(2)</div><div id='n_method'> N Method Name: test_epoch(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: phetware/epochvisor.py</div><div id='n_file'> N File Name: phetware/epochvisor.py</div><div id='m_start'> M Start Line: 126</div><div id='m_end'> M End Line: 133</div><div id='n_start'> N Start Line: 128</div><div id='n_end'> N End Line: 154</div><BR>