<html><h3>Pattern ID :16635
</h3><img src='55834683.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        neg_idxs = torch.randint(low=0, high=high, size=(bsz, self.n_negatives * tsz))

        if self.sample_distance is not None and self.sample_distance &lt; tsz:
            neg_idxs<a id="change"> += </a><a id="change">torch.cat(
                [</a>torch.arange(start=1, end=tsz - self.sample_distance, device=neg_idxs.device, dtype=neg_idxs.dtype),
                 torch.arange(start=tsz - self.sample_distance, end=tsz - self.sample_distance * 2 - 1, step=-1,
                              device=neg_idxs.device, dtype=neg_idxs.dtype)<a id="change"></a>]<a id="change">)</a>

        if not self.cross_sample_negatives:
            for i in range(1, bsz):
                neg_idxs[i] += i * high</code></pre><h3>After Change</h3><pre><code class='java'>

        neg_idxs = torch.randint(low=0, high=high, size=(bsz, self.n_negatives * tsz))

        <a id="change">with torch</a><a id="change">.no_grad():
            </a>if self.n_negatives &gt; 0:
                tszs = (
                    buffered_arange(tsz)
                    .unsqueeze(-1)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/mohammadkhalifa/fairseq-tagging/commit/3335de5f441ee1b3824e16dcd98db620e40beaba#diff-9b4dd2bdb515c86c631253c805af3041e9bbf4ce7f68af6a1900ef5b4ffa5c5aL385' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55834683</div><div id='project'> Project Name: mohammadkhalifa/fairseq-tagging</div><div id='commit'> Commit Name: 3335de5f441ee1b3824e16dcd98db620e40beaba</div><div id='time'> Time: 2020-02-29</div><div id='author'> Author: alexei.b@gmail.com</div><div id='file'> File Name: fairseq/models/wav2vec.py</div><div id='m_class'> M Class Name: Wav2VecPredictionsModel</div><div id='n_method'> N Class Name: Wav2VecPredictionsModel</div><div id='m_method'> M Method Name: sample_negatives(2)</div><div id='n_method'> N Method Name: sample_negatives(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: fairseq/models/wav2vec.py</div><div id='n_file'> N File Name: fairseq/models/wav2vec.py</div><div id='m_start'> M Start Line: 385</div><div id='m_end'> M End Line: 404</div><div id='n_start'> N Start Line: 583</div><div id='n_end'> N End Line: 629</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        vutils.save_image(tensor_to_plot, basename + "_construct.png")
        self.set_input(torch.randn(1, self.embedding_dim).repeat(batch[0].shape[0], 1), batch[2], batch[1])
        self.forward()
        tensor_to_plot<a id="change"> = </a><a id="change">torch.cat([</a>self.fake_B, self.real_A<a id="change"></a>], 3<a id="change">)</a>
        vutils.save_image(tensor_to_plot, basename + "_generate.png")

</code></pre><h3>After Change</h3><pre><code class='java'>
                &#47&#47 net.eval()

    def sample(self, batch, basename):
        <a id="change">with torch</a><a id="change">.no_grad():
            </a>self.set_input(batch[0], batch[2], batch[1])
            self.forward()
            tensor_to_plot = torch.cat([self.fake_B, self.real_B], 3)
            img = vutils.make_grid(tensor_to_plot)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/euphoriayan/zi2zi-pytorch/commit/d18cdce2416d812c3944db8aef913e06879b022b#diff-62e0d959e50d9f4003df8124a1c19d98c77320268642d433b1cc28c58cf73a85L203' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55834686</div><div id='project'> Project Name: euphoriayan/zi2zi-pytorch</div><div id='commit'> Commit Name: d18cdce2416d812c3944db8aef913e06879b022b</div><div id='time'> Time: 2020-06-29</div><div id='author'> Author: ysq58000@foxmail.com</div><div id='file'> File Name: model/model.py</div><div id='m_class'> M Class Name: Zi2ZiModel</div><div id='n_method'> N Class Name: Zi2ZiModel</div><div id='m_method'> M Method Name: sample(3)</div><div id='n_method'> N Method Name: sample(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model/model.py</div><div id='n_file'> N File Name: model/model.py</div><div id='m_start'> M Start Line: 204</div><div id='m_end'> M End Line: 212</div><div id='n_start'> N Start Line: 215</div><div id='n_end'> N End Line: 227</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    apool = torch.mean(conv_features, dim = 1) &#47&#47 (N, block_num, embed_dim * 0.5)
    mpool, _ = torch.max(conv_features, dim = 1) &#47&#47 (N, block_num, embed_dim * 0.5)

    imgs_embed<a id="change"> = </a><a id="change">torch.cat([</a>apool, mpool<a id="change"></a>]<a id="change">, dim = 2)</a> &#47&#47 (N, block_num, embed_dim)

    words_embed = self.__content_embed__(input_ids) &#47&#47 (N, seq_len, embed_dim)
    indices  = torch.arange(self.seq_len + self.block_num).expand(batch, -1).to(device)</code></pre><h3>After Change</h3><pre><code class='java'>
    batch = images.shape[0] &#47&#47 (N)

    
    <a id="change">with torch</a><a id="change">.no_grad():
      </a>batch_features = self.__clip__.encode_image(images)
      
    &#47&#47text_input = self.__get_text_input__(tag_ids)
    &#47&#47batch_texts = self.__clip__.encode_text(text_input)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/siwooyong/codalab-microsoft-coco-image-captioning-challenge/commit/d24b22ec9f0be1acd2f307be20ec85f84f8d8795#diff-7c1ece53a18959b293126dd93f3cf0f768220f50d2c1201e1601681873e6f6e4L54' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55834684</div><div id='project'> Project Name: siwooyong/codalab-microsoft-coco-image-captioning-challenge</div><div id='commit'> Commit Name: d24b22ec9f0be1acd2f307be20ec85f84f8d8795</div><div id='time'> Time: 2021-07-08</div><div id='author'> Author: 68500343+yongsiwoo@users.noreply.github.com</div><div id='file'> File Name: models/base_model.py</div><div id='m_class'> M Class Name: decoder</div><div id='n_method'> N Class Name: decoder</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/base_model.py</div><div id='n_file'> N File Name: models/base_model.py</div><div id='m_start'> M Start Line: 57</div><div id='m_end'> M End Line: 74</div><div id='n_start'> N Start Line: 75</div><div id='n_end'> N End Line: 97</div><BR>