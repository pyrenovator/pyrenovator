<html><h3>Pattern ID :25765
</h3><img src='78008998.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    from relative distances (with length 2*tokens-1) to absolute distance (length tokens)
    
    query_index = torch.arange(tokens).unsqueeze(0)  &#47&#47 [1, dim]
    key_index = <a id="change">torch.arange(</a>tokens<a id="change">)</a>.unsqueeze(1)  &#47&#47 [dim, 1]

    relative_index = (key_index - query_index) + tokens - 1  &#47&#47 dim X dim (zero indexed)
    flatten_index = rearrange(relative_index, &quoti j-&gt;(i j)&quot)  &#47&#47 flatten</code></pre><h3>After Change</h3><pre><code class='java'>
      Input: [bs, heads, length, 2*length - 1]
      Output: [bs, heads, length, length]
    
    <a id="change">b</a><a id="change">, h, l, _, device, dtype</a> = *q.shape, q.device, q.dtype
    dd = {&quotdevice&quot: device, &quotdtype&quot: dtype}
    col_pad = <a id="change">torch.zeros(</a>(<a id="change">b</a><a id="change">, h, l, 1</a>)<a id="change">, **dd)</a>
    x = torch.cat((q, col_pad), dim=3)  &#47&#47 zero pad 2l-1 to 2l
    flat_x = rearrange(x, &quotb h l c -&gt; b h (l c)&quot)
    flat_pad = torch.zeros((b, h, l - 1), **dd)
    flat_x_padded<a id="change"> = </a>torch.cat((flat_x, flat_pad), dim=2)
    final_x = flat_x_padded.reshape(b, h, l + 1, 2 * l - 1)
    final_x = final_x[:, :, :l, (l - 1):]
    return final_x</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/the-ai-summer/self-attention-cv/commit/400427e8b940a91d0baa90037b7bf2308c8bc9e9#diff-f79da185517a56871e3cc6d2d4115a64d416dea8e8acec3c6ee83a6fae923630L6' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78008998</div><div id='project'> Project Name: the-ai-summer/self-attention-cv</div><div id='commit'> Commit Name: 400427e8b940a91d0baa90037b7bf2308c8bc9e9</div><div id='time'> Time: 2021-02-09</div><div id='author'> Author: black.adaloglou@gmail.com</div><div id='file'> File Name: self_attention_cv/pos_embeddings/relative_embeddings_1D.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: relative_to_absolute(1)</div><div id='n_method'> N Method Name: relative_to_absolute(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: self_attention_cv/pos_embeddings/relative_embeddings_1D.py</div><div id='n_file'> N File Name: self_attention_cv/pos_embeddings/relative_embeddings_1D.py</div><div id='m_start'> M Start Line: 6</div><div id='m_end'> M End Line: 17</div><div id='n_start'> N Start Line: 11</div><div id='n_end'> N End Line: 27</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    from relative distances (with length 2*tokens-1) to absolute distance (length tokens)
    
    query_index = torch.arange(tokens).unsqueeze(0)  &#47&#47 [1, dim]
    key_index = <a id="change">torch.arange(</a>tokens<a id="change">)</a>.unsqueeze(1)  &#47&#47 [dim, 1]

    relative_index = (key_index - query_index) + tokens - 1  &#47&#47 dim X dim (zero indexed)
    flatten_index = rearrange(relative_index, &quoti j-&gt;(i j)&quot)  &#47&#47 flatten</code></pre><h3>After Change</h3><pre><code class='java'>
      Input: [bs, heads, length, 2*length - 1]
      Output: [bs, heads, length, length]
    
    b<a id="change">, h, l, _, device, dtype</a> = *q.shape, q.device, q.dtype
    dd = {&quotdevice&quot: device, &quotdtype&quot: dtype}
    col_pad = <a id="change">torch.zeros(</a>(b<a id="change">, h, l, 1</a>)<a id="change">, **dd)</a>
    x = torch.cat((q, col_pad), dim=3)  &#47&#47 zero pad 2l-1 to 2l
    flat_x = rearrange(x, &quotb h l c -&gt; b h (l c)&quot)
    flat_pad = torch.zeros((b, h, l - 1), **dd)
    flat_x_padded<a id="change"> = </a>torch.cat((flat_x, flat_pad), dim=2)
    final_x = flat_x_padded.reshape(b, h, l + 1, 2 * l - 1)
    final_x = final_x[:, :, :l, (l - 1):]
    return final_x</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/the-ai-summer/self-attention-cv/commit/400427e8b940a91d0baa90037b7bf2308c8bc9e9#diff-f79da185517a56871e3cc6d2d4115a64d416dea8e8acec3c6ee83a6fae923630L6' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78008999</div><div id='project'> Project Name: the-ai-summer/self-attention-cv</div><div id='commit'> Commit Name: 400427e8b940a91d0baa90037b7bf2308c8bc9e9</div><div id='time'> Time: 2021-02-09</div><div id='author'> Author: black.adaloglou@gmail.com</div><div id='file'> File Name: self_attention_cv/pos_embeddings/relative_embeddings_1D.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: relative_to_absolute(1)</div><div id='n_method'> N Method Name: relative_to_absolute(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: self_attention_cv/pos_embeddings/relative_embeddings_1D.py</div><div id='n_file'> N File Name: self_attention_cv/pos_embeddings/relative_embeddings_1D.py</div><div id='m_start'> M Start Line: 6</div><div id='m_end'> M End Line: 17</div><div id='n_start'> N Start Line: 11</div><div id='n_end'> N End Line: 27</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

            &#47&#47 Emission score for next tag, only added if next timestep is valid (mask == 1)
            &#47&#47 shape: (batch_size,)
            score += emissions[i, <a id="change">ops.arange(</a>batch_size<a id="change">)</a>, tags[i]] * mask[i]
            i += 1

        &#47&#47 End transition score</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Start transition score and first emission
        &#47&#47 shape: (batch_size,)
        score = self.start_transitions[tags[0]]
        indices = ops.stack([<a id="change">ops.zeros(</a>(batch_size<a id="change"></a>,), mindspore.int64<a id="change">)</a>, arange(batch_size), tags[0]])
        &#47&#47 score += emissions[0, arange(batch_size), tags[0]]
        score<a id="change"> += </a>ops.gather_nd(emissions, indices.T)

        i = Tensor(1, mindspore.int64)
        while i &lt; seq_length:
        &#47&#47 for i in range(1, seq_length):
            &#47&#47 Transition score to next tag, only added if next timestep is valid (mask == 1)
            &#47&#47 shape: (batch_size,)
            t_indices = ops.stack([tags[i - 1], tags[i]])
            &#47&#47 score += self.transitions[tags[i - 1], tags[i]] * mask[i]
            score += ops.gather_nd(self.transitions, t_indices.T) * mask[i]

            &#47&#47 Emission score for next tag, only added if next timestep is valid (mask == 1)
            &#47&#47 shape: (batch_size,)
            e_indices = ops.stack([ops.tile(i, (batch_size<a id="change"></a>,)), arange(batch_size), tags[i]])
            score += ops.gather_nd(emissions, e_indices.T) * mask[i]
            i += 1
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mindlab-ai/mindnlp/commit/60bfafb3c99d7dec61f86c61b4f9286b7e0f3726#diff-73482b95ced66c68f1088fa6fd7897dd34c6e67545479c19661275715889cc90L143' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78009008</div><div id='project'> Project Name: mindlab-ai/mindnlp</div><div id='commit'> Commit Name: 60bfafb3c99d7dec61f86c61b4f9286b7e0f3726</div><div id='time'> Time: 2023-03-25</div><div id='author'> Author: lvyufeng@cqu.edu.cn</div><div id='file'> File Name: mindnlp/modules/crf.py</div><div id='m_class'> M Class Name: CRF</div><div id='n_method'> N Class Name: CRF</div><div id='m_method'> M Method Name: _compute_score(5)</div><div id='n_method'> N Method Name: _compute_score(5)</div><div id='m_parent_class'> M Parent Class: nn.Cell</div><div id='n_parent_class'> N Parent Class: nn.Cell</div><div id='m_file'> M File Name: mindnlp/modules/crf.py</div><div id='n_file'> N File Name: mindnlp/modules/crf.py</div><div id='m_start'> M Start Line: 153</div><div id='m_end'> M End Line: 170</div><div id='n_start'> N Start Line: 159</div><div id='n_end'> N End Line: 183</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if self.drop &lt; 1:
            self.emb = self.dropout(self.emb)

        count = <a id="change">np.arange(</a>x.shape[0]<a id="change">)</a> + 1
        self.c_t = torch.zeros_like(self.emb)  &#47&#47 shape=(seq_len, batch_size, day_dim)
        for i, att_timesteps in enumerate(count):
            &#47&#47 按时间步迭代，计算每个时间步的经attention的gru输出</code></pre><h3>After Change</h3><pre><code class='java'>
        return out

    def forward(self, x):
        batch_size<a id="change">, time_steps, _</a> = x.size()
        x = self.proj(x)
        x = self.dropout(x)

        out<a id="change"> = </a><a id="change">torch.zeros(</a>(batch_size<a id="change">, time_steps, self.hidden_dim</a>)<a id="change">)</a>

        for cur_time in range(time_steps):
            cur_x = x[:, : cur_time + 1, :]
            out[:, cur_time, :] = self.retain_encoder(cur_x)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yhzhu99/covid-ehr-benchmarks/commit/b3d4ba85ad8e8cfeb3e45e07e5fadfa3fd4a25fa#diff-77d2a7ae5e3183c97c4a93ec2d675da0a9f18941a477d8d2a5d9e1d496f4b387L63' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78009018</div><div id='project'> Project Name: yhzhu99/covid-ehr-benchmarks</div><div id='commit'> Commit Name: b3d4ba85ad8e8cfeb3e45e07e5fadfa3fd4a25fa</div><div id='time'> Time: 2022-06-25</div><div id='author'> Author: yhzhu99@gmail.com</div><div id='file'> File Name: app/models/backbones/retain.py</div><div id='m_class'> M Class Name: RETAIN</div><div id='n_method'> N Class Name: RETAIN</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: app/models/backbones/retain.py</div><div id='n_file'> N File Name: app/models/backbones/retain.py</div><div id='m_start'> M Start Line: 64</div><div id='m_end'> M End Line: 83</div><div id='n_start'> N Start Line: 44</div><div id='n_end'> N End Line: 53</div><BR>