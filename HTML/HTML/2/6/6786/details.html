<html><h3>Pattern ID :6786
</h3><img src='23158817.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    self.upos=[]
    with open(conllu,"r",encoding="utf-8") as f:
      for s in f.read().strip().split("\n\n"):
        u=[(w[1],w[3]) for w in [t.split("\t") <a id="change">for</a> t in s.split("\n")] if len(w)==10 and w[0].isdecimal()]
        v=tokenizer([t for t,p in u],add_special_tokens=False)["input_ids"]
        self.ids.append([tokenizer.cls_token_id]+sum(v,[])+[tokenizer.sep_token_id])
        self.upos.append(["SYM"]+<a id="change">sum(</a>[["B-"+p]+["I-"+p]*(len(v[i])-1) if len(v[i])&gt;1 else [p] for i,(t,p) in enumerate(u)],[]<a id="change">)</a>+["SYM"])
    self.label2id={l:i for i,l in enumerate(sorted(set(sum(self.upos,[]))))}
  def __call__(*args):
    lid={l:i for i,l in enumerate(sorted(set(sum([list(t.label2id) for t in args],[]))))}</code></pre><h3>After Change</h3><pre><code class='java'>
          v=tokenizer(w[1],add_special_tokens=False)["input_ids"]
          i+=v
          u+=[w[3]] if len(v)==1 else ["B-"+w[3]]+["I-"+w[3]]*(len(v)-1)
        elif <a id="change">t.strip()=="" and len(i)&gt;0</a>:
          self.ids.append([tokenizer.cls_token_id]+i+[tokenizer.sep_token_id])
          self.upos.append(["SYM"]+u+["SYM"])
          i,u=[],[]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/koichiyasuoka/esupar/commit/d918c7219af3718aae5c9a29ce8402133110ae54#diff-5c9a99099f28048bee1e5ade1dd2cb0b174ff1230b8f3a69e408e809843070c5L10' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23158817</div><div id='project'> Project Name: koichiyasuoka/esupar</div><div id='commit'> Commit Name: d918c7219af3718aae5c9a29ce8402133110ae54</div><div id='time'> Time: 2022-01-03</div><div id='author'> Author: yasuoka@kanji.zinbun.kyoto-u.ac.jp</div><div id='file'> File Name: esupar/train.py</div><div id='m_class'> M Class Name: UPOSDataset</div><div id='n_method'> N Class Name: UPOSDataset</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: esupar/train.py</div><div id='n_file'> N File Name: esupar/train.py</div><div id='m_start'> M Start Line: 10</div><div id='m_end'> M End Line: 16</div><div id='n_start'> N Start Line: 10</div><div id='n_end'> N End Line: 22</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.args = args
        self.pad_idx = numericalizer.pad_id

        if <a id="change">sum(</a>emb<a id="change">.dim for emb in encoder_embeddings)</a> != args.dimension:
            raise ValueError(&quotHidden dimension must be equal to the sum of the embedding sizes to use IdentityEncoder&quot)

        self.encoder_embeddings = CombinedEmbedding(numericalizer, encoder_embeddings, args.dimension,</code></pre><h3>After Change</h3><pre><code class='java'>
                                                    project=False,
                                                    finetune_pretrained=args.train_encoder_embeddings)

        <a id="change">if </a><a id="change">self.args.rnn_layers &gt; 0 and self.args.rnn_dimension != self.args.dimension</a>:
            self.dropout = nn.Dropout(args.dropout_ratio)
            self.projection = nn.Linear(self.encoder_embeddings.dimension, self.args.rnn_dimension, bias=False)
        else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/ae1bf6a643f0c4ae8d6df12b291a9271e5fe4543#diff-2a9a18573b4512fdca0696a6ddb0ac7061b044f90150c1dde95c604b9ed45434L36' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23158802</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: ae1bf6a643f0c4ae8d6df12b291a9271e5fe4543</div><div id='time'> Time: 2020-01-18</div><div id='author'> Author: gcampagn@cs.stanford.edu</div><div id='file'> File Name: decanlp/models/identity_encoder.py</div><div id='m_class'> M Class Name: IdentityEncoder</div><div id='n_method'> N Class Name: IdentityEncoder</div><div id='m_method'> M Method Name: __init__(4)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: decanlp/models/identity_encoder.py</div><div id='n_file'> N File Name: decanlp/models/identity_encoder.py</div><div id='m_start'> M Start Line: 41</div><div id='m_end'> M End Line: 44</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 53</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if self.cpu_offload_params:
            self.param_groups_fp16_flat_cpu_memory = []
            for j, param_group in enumerate(self.optimizer.param_groups):
                total_params = <a id="change">sum(</a>[p.ds_tensor.numel() <a id="change">for</a> p in param_group[&quotparams&quot]]<a id="change">)</a>
                self.param_groups_fp16_flat_cpu_memory.append(
                    torch.empty(total_params,
                                dtype=torch.half,</code></pre><h3>After Change</h3><pre><code class='java'>
                see_memory_usage(f"After Flattening param group {i}", force=False)

                &#47&#47create a pinned memory to be used for swapping out params to NVME after optimizer step
                <a id="change">if </a><a id="change">self.fp16_partitioned_groups_flat[
                        -1] is None and self.param_group_fp16_flat_reuse_buffer is None</a>:
                    self.param_group_fp16_flat_reuse_buffer = torch.empty(
                        max(self.fp16_partitioned_groups_flat_numel),
                        dtype=torch.half,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/0d4a54a04d658db40a120bc10c6f1f1a4478f6f1#diff-1ad5daa1b31aa5573616024068d646f0c38e88d4d3a71d3d0e4bc352ea232178L879' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23158820</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: 0d4a54a04d658db40a120bc10c6f1f1a4478f6f1</div><div id='time'> Time: 2021-04-18</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/runtime/zero/stage3.py</div><div id='m_class'> M Class Name: FP16_DeepSpeedZeroOptimizer_Stage3</div><div id='n_method'> N Class Name: FP16_DeepSpeedZeroOptimizer_Stage3</div><div id='m_method'> M Method Name: _create_fp16_partitions_with_defragmentation(1)</div><div id='n_method'> N Method Name: _create_fp16_partitions_with_defragmentation(1)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: deepspeed/runtime/zero/stage3.py</div><div id='n_file'> N File Name: deepspeed/runtime/zero/stage3.py</div><div id='m_start'> M Start Line: 884</div><div id='m_end'> M End Line: 944</div><div id='n_start'> N Start Line: 1079</div><div id='n_end'> N End Line: 1177</div><BR>