<html><h3>Pattern ID :16471
</h3><img src='55408949.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            "dtype": self.weight.data.dtype,
        }

        <a id="change">self.weight.data.copy_(
            </a>functional.identity_hv(
                self.num_embeddings, self.embedding_dim, **factory_kwargs
            )<a id="change">
        )</a>

        self._fill_padding_idx_with_zero()

    def forward(self, input: Tensor) -&gt; Tensor:</code></pre><h3>After Change</h3><pre><code class='java'>
    def reset_parameters(self) -&gt; None:
        factory_kwargs = {"device": self.weight.device, "dtype": self.weight.dtype}

        <a id="change">with torch.no_grad()</a><a id="change">:
            </a>embeddings<a id="change"> = </a>functional.identity_hv(
                self.num_embeddings,
                self.embedding_dim,
                self.vsa_model,
                **factory_kwargs
            )
            <a id="change">self.weight.copy_(</a>embeddings<a id="change">)</a>

        self._fill_padding_idx_with_empty()

    def _fill_padding_idx_with_empty(self) -&gt; None:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/hyperdimensional-computing/torchhd/commit/90c6926d8c62c42ec5f2726007c581213fb41322#diff-d7f17cefd7a9cec7e1df84bbc00adfc7e0d840fd12a7e7b2fa0859efbfb54530L50' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55408949</div><div id='project'> Project Name: hyperdimensional-computing/torchhd</div><div id='commit'> Commit Name: 90c6926d8c62c42ec5f2726007c581213fb41322</div><div id='time'> Time: 2023-01-22</div><div id='author'> Author: mikeheddes@gmail.com</div><div id='file'> File Name: torchhd/embeddings.py</div><div id='m_class'> M Class Name: Identity</div><div id='n_method'> N Class Name: Identity</div><div id='m_method'> M Method Name: reset_parameters(1)</div><div id='n_method'> N Method Name: reset_parameters(1)</div><div id='m_parent_class'> M Parent Class: nn.Embedding</div><div id='n_parent_class'> N Parent Class: nn.Embedding</div><div id='m_file'> M File Name: torchhd/embeddings.py</div><div id='n_file'> N File Name: torchhd/embeddings.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 58</div><div id='n_start'> N Start Line: 228</div><div id='n_end'> N End Line: 239</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            "dtype": self.weight.data.dtype,
        }

        <a id="change">self.weight.data.copy_(
            </a>functional.circular_hv(
                self.num_embeddings,
                self.embedding_dim,
                randomness=self.randomness,
                **factory_kwargs
            )<a id="change">
        )</a>

        self._fill_padding_idx_with_zero()

    def forward(self, input: torch.Tensor) -&gt; torch.Tensor:</code></pre><h3>After Change</h3><pre><code class='java'>
    def reset_parameters(self) -&gt; None:
        factory_kwargs = {"device": self.weight.device, "dtype": self.weight.dtype}

        <a id="change">with torch.no_grad()</a><a id="change">:
            </a>embeddings<a id="change"> = </a>functional.circular_hv(
                self.num_embeddings,
                self.embedding_dim,
                self.vsa_model,
                randomness=self.randomness,
                **factory_kwargs
            )
            <a id="change">self.weight.copy_(</a>embeddings<a id="change">)</a>

    def forward(self, input: Tensor) -&gt; Tensor:
        mapped = functional.map_range(
            input, self.phase, self.period, 0, self.num_embeddings</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hyperdimensional-computing/torchhd/commit/90c6926d8c62c42ec5f2726007c581213fb41322#diff-d7f17cefd7a9cec7e1df84bbc00adfc7e0d840fd12a7e7b2fa0859efbfb54530L276' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55408948</div><div id='project'> Project Name: hyperdimensional-computing/torchhd</div><div id='commit'> Commit Name: 90c6926d8c62c42ec5f2726007c581213fb41322</div><div id='time'> Time: 2023-01-22</div><div id='author'> Author: mikeheddes@gmail.com</div><div id='file'> File Name: torchhd/embeddings.py</div><div id='m_class'> M Class Name: Circular</div><div id='n_method'> N Class Name: Circular</div><div id='m_method'> M Method Name: reset_parameters(1)</div><div id='n_method'> N Method Name: reset_parameters(1)</div><div id='m_parent_class'> M Parent Class: nn.Embedding</div><div id='n_parent_class'> N Parent Class: nn.Embedding</div><div id='m_file'> M File Name: torchhd/embeddings.py</div><div id='n_file'> N File Name: torchhd/embeddings.py</div><div id='m_start'> M Start Line: 278</div><div id='m_end'> M End Line: 291</div><div id='n_start'> N Start Line: 721</div><div id='n_end'> N End Line: 733</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            "dtype": self.weight.data.dtype,
        }

        <a id="change">self.weight.data.copy_(
            </a>functional.level_hv(
                self.num_embeddings,
                self.embedding_dim,
                randomness=self.randomness,
                **factory_kwargs
            )<a id="change">
        )</a>

        self._fill_padding_idx_with_zero()

    def forward(self, input: torch.Tensor) -&gt; torch.Tensor:</code></pre><h3>After Change</h3><pre><code class='java'>
    def reset_parameters(self) -&gt; None:
        factory_kwargs = {"device": self.weight.device, "dtype": self.weight.dtype}

        <a id="change">with torch.no_grad()</a><a id="change">:
            </a>embeddings<a id="change"> = </a>functional.level_hv(
                self.num_embeddings,
                self.embedding_dim,
                self.vsa_model,
                randomness=self.randomness,
                **factory_kwargs
            )
            <a id="change">self.weight.copy_(</a>embeddings<a id="change">)</a>

    def forward(self, input: Tensor) -&gt; Tensor:
        index = functional.value_to_index(
            input, self.low, self.high, self.num_embeddings</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hyperdimensional-computing/torchhd/commit/90c6926d8c62c42ec5f2726007c581213fb41322#diff-d7f17cefd7a9cec7e1df84bbc00adfc7e0d840fd12a7e7b2fa0859efbfb54530L150' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55408950</div><div id='project'> Project Name: hyperdimensional-computing/torchhd</div><div id='commit'> Commit Name: 90c6926d8c62c42ec5f2726007c581213fb41322</div><div id='time'> Time: 2023-01-22</div><div id='author'> Author: mikeheddes@gmail.com</div><div id='file'> File Name: torchhd/embeddings.py</div><div id='m_class'> M Class Name: Level</div><div id='n_method'> N Class Name: Level</div><div id='m_method'> M Method Name: reset_parameters(1)</div><div id='n_method'> N Method Name: reset_parameters(1)</div><div id='m_parent_class'> M Parent Class: nn.Embedding</div><div id='n_parent_class'> N Parent Class: nn.Embedding</div><div id='m_file'> M File Name: torchhd/embeddings.py</div><div id='n_file'> N File Name: torchhd/embeddings.py</div><div id='m_start'> M Start Line: 152</div><div id='m_end'> M End Line: 165</div><div id='n_start'> N Start Line: 483</div><div id='n_end'> N End Line: 495</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            "dtype": self.weight.data.dtype,
        }

        <a id="change">self.weight.data.copy_(
            </a>functional.thermometer_hv(
                self.num_embeddings, self.embedding_dim, **factory_kwargs
            )<a id="change">
        )</a>

        self._fill_padding_idx_with_zero()

    def forward(self, input: torch.Tensor) -&gt; torch.Tensor:</code></pre><h3>After Change</h3><pre><code class='java'>
    def reset_parameters(self) -&gt; None:
        factory_kwargs = {"device": self.weight.device, "dtype": self.weight.dtype}

        <a id="change">with torch.no_grad()</a><a id="change">:
            </a>embeddings<a id="change"> = </a>functional.thermometer_hv(
                self.num_embeddings,
                self.embedding_dim,
                self.vsa_model,
                **factory_kwargs
            )
            <a id="change">self.weight.copy_(</a>embeddings<a id="change">)</a>

    def forward(self, input: Tensor) -&gt; Tensor:
        index = functional.value_to_index(
            input, self.low, self.high, self.num_embeddings</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hyperdimensional-computing/torchhd/commit/90c6926d8c62c42ec5f2726007c581213fb41322#diff-d7f17cefd7a9cec7e1df84bbc00adfc7e0d840fd12a7e7b2fa0859efbfb54530L213' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55408947</div><div id='project'> Project Name: hyperdimensional-computing/torchhd</div><div id='commit'> Commit Name: 90c6926d8c62c42ec5f2726007c581213fb41322</div><div id='time'> Time: 2023-01-22</div><div id='author'> Author: mikeheddes@gmail.com</div><div id='file'> File Name: torchhd/embeddings.py</div><div id='m_class'> M Class Name: Thermometer</div><div id='n_method'> N Class Name: Thermometer</div><div id='m_method'> M Method Name: reset_parameters(1)</div><div id='n_method'> N Method Name: reset_parameters(1)</div><div id='m_parent_class'> M Parent Class: nn.Embedding</div><div id='n_parent_class'> N Parent Class: nn.Embedding</div><div id='m_file'> M File Name: torchhd/embeddings.py</div><div id='n_file'> N File Name: torchhd/embeddings.py</div><div id='m_start'> M Start Line: 215</div><div id='m_end'> M End Line: 225</div><div id='n_start'> N Start Line: 601</div><div id='n_end'> N End Line: 612</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            "dtype": self.weight.data.dtype,
        }

        <a id="change">self.weight.data.copy_(
            </a>functional.random_hv(
                self.num_embeddings, self.embedding_dim, **factory_kwargs
            )<a id="change">
        )</a>

        self._fill_padding_idx_with_zero()

    def forward(self, input: Tensor) -&gt; Tensor:</code></pre><h3>After Change</h3><pre><code class='java'>
    def reset_parameters(self) -&gt; None:
        factory_kwargs = {"device": self.weight.device, "dtype": self.weight.dtype}

        <a id="change">with torch.no_grad()</a><a id="change">:
            </a>embeddings<a id="change"> = </a>functional.random_hv(
                self.num_embeddings,
                self.embedding_dim,
                self.vsa_model,
                **factory_kwargs
            )
            <a id="change">self.weight.copy_(</a>embeddings<a id="change">)</a>

        self._fill_padding_idx_with_empty()

    def _fill_padding_idx_with_empty(self) -&gt; None:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hyperdimensional-computing/torchhd/commit/90c6926d8c62c42ec5f2726007c581213fb41322#diff-d7f17cefd7a9cec7e1df84bbc00adfc7e0d840fd12a7e7b2fa0859efbfb54530L91' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55408946</div><div id='project'> Project Name: hyperdimensional-computing/torchhd</div><div id='commit'> Commit Name: 90c6926d8c62c42ec5f2726007c581213fb41322</div><div id='time'> Time: 2023-01-22</div><div id='author'> Author: mikeheddes@gmail.com</div><div id='file'> File Name: torchhd/embeddings.py</div><div id='m_class'> M Class Name: Random</div><div id='n_method'> N Class Name: Random</div><div id='m_method'> M Method Name: reset_parameters(1)</div><div id='n_method'> N Method Name: reset_parameters(1)</div><div id='m_parent_class'> M Parent Class: nn.Embedding</div><div id='n_parent_class'> N Parent Class: nn.Embedding</div><div id='m_file'> M File Name: torchhd/embeddings.py</div><div id='n_file'> N File Name: torchhd/embeddings.py</div><div id='m_start'> M Start Line: 93</div><div id='m_end'> M End Line: 101</div><div id='n_start'> N Start Line: 349</div><div id='n_end'> N End Line: 360</div><BR>