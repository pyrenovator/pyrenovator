<html><h3>Pattern ID :30716
</h3><img src='90536151.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>


def conv_encoder(inputs, mlp_ratio=4, kernel_size=7, layer_scale=1e-6, drop_rate=0, activation="gelu", name=""):
    input_channel = <a id="change">inputs.shape[-1]</a>
    nn = depthwise_conv2d_no_bias(inputs, kernel_size, use_bias=True, padding="SAME", name=name)
    nn = norm_inverted_bottleneck(nn, mlp_ratio, layer_scale, drop_rate, activation=activation, name=name)
    &#47&#47 print(f"{nn.shape = }, {inputs.shape = }")
    return keras.layers.Add(name=name + "output")([inputs, nn])</code></pre><h3>After Change</h3><pre><code class='java'>

def conv_encoder(inputs, mlp_ratio=4, kernel_size=7, layer_scale=1e-6, drop_rate=0, activation="gelu", name=""):
    nn = depthwise_conv2d_no_bias(inputs, kernel_size, use_bias=True, padding="SAME", name=name)
    nn = nn<a id="change"> if </a><a id="change">image_data_format() == "channels_last" else </a>layers.Permute([2, 3, 1])(nn)  &#47&#47 channels_first -&gt; channels_last
    nn = norm_inverted_bottleneck(nn, mlp_ratio, layer_scale, drop_rate, activation=activation, name=name)
    nn = nn if image_data_format() == "channels_last" else layers.Permute([3, 1, 2])(nn)  &#47&#47 channels_last -&gt; channels_first
    &#47&#47 print(f"{nn.shape = }, {inputs.shape = }")</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/7fe31da02f008f26eff018ec2199631227c94efc#diff-a119549323a000d7b33706b44fad5bc04a07d913bec886b503d88f2f13240579L135' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 90536151</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: 7fe31da02f008f26eff018ec2199631227c94efc</div><div id='time'> Time: 2023-02-10</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/edgenext/edgenext.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: conv_encoder(7)</div><div id='n_method'> N Method Name: conv_encoder(7)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/edgenext/edgenext.py</div><div id='n_file'> N File Name: keras_cv_attention_models/edgenext/edgenext.py</div><div id='m_start'> M Start Line: 135</div><div id='m_end'> M End Line: 139</div><div id='n_start'> N Start Line: 147</div><div id='n_end'> N End Line: 152</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
):
    if attn_block_params.get("attn_type", None) == "halo":  &#47&#47 HaloAttention
        halo_block_size = attn_block_params.get("attn_params", {}).get("block_size", DEFAULT_PARAMS["halo"]["block_size"])
        if inputs.shape[1] % halo_block_size != 0 or <a id="change">inputs.shape[2]</a> % halo_block_size != 0:
            gap_h = halo_block_size - inputs.shape[1] % halo_block_size
            gap_w = halo_block_size - inputs.shape[2] % halo_block_size
            pad_head_h, pad_tail_h = gap_h // 2, gap_h - gap_h // 2</code></pre><h3>After Change</h3><pre><code class='java'>
):
    if attn_block_params.get("attn_type", None) == "halo":  &#47&#47 HaloAttention
        halo_block_size = attn_block_params.get("attn_params", {}).get("block_size", DEFAULT_PARAMS["halo"]["block_size"])
        height, width = inputs.shape[1:-1]<a id="change"> if </a><a id="change">image_data_format() == "channels_last" else </a>inputs.shape[2:]
        if height % halo_block_size != 0 or width % halo_block_size != 0:
            gap_h = halo_block_size - height % halo_block_size
            gap_w = halo_block_size - width % halo_block_size</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/2ba27b0132168f3590dd4b3bead9edc15a70ba7d#diff-1f71df69cfd2e478a7dfb4976b2eecc6edb982e949d811902e030615cfa9cf3cL135' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 90536150</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: 2ba27b0132168f3590dd4b3bead9edc15a70ba7d</div><div id='time'> Time: 2023-02-11</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/aotnet/aotnet.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: aot_block(17)</div><div id='n_method'> N Method Name: aot_block(17)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/aotnet/aotnet.py</div><div id='n_file'> N File Name: keras_cv_attention_models/aotnet/aotnet.py</div><div id='m_start'> M Start Line: 156</div><div id='m_end'> M End Line: 158</div><div id='n_start'> N Start Line: 156</div><div id='n_end'> N End Line: 159</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        if use_block_pos_emb:
            block_pos_emb = BiasPositionalEmbedding(axis=[1, 2, 3], attn_height=nn.shape[1], name=stage_name + "pos_emb")
            block_pos_emb.build([None, num_head, <a id="change">nn.shape[1]</a> * nn.shape[2], (nn.shape[1] // sr_ratio) * (nn.shape[2] // sr_ratio)])
        else:
            block_pos_emb = None
</code></pre><h3>After Change</h3><pre><code class='java'>
        nn = layer_norm(nn, name=stage_name)

        if use_block_pos_emb:
            height, width = nn.shape[1:-1]<a id="change"> if </a><a id="change">image_data_format() == "channels_last" else </a>nn.shape[2:]
            block_pos_emb = BiasPositionalEmbedding(axis=[1, 2, 3], attn_height=height, name=stage_name + "pos_emb")
            block_pos_emb.build([None, num_head, height * width, (height // sr_ratio) * (width // sr_ratio)])
        else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/2ba27b0132168f3590dd4b3bead9edc15a70ba7d#diff-f52477ea03b2a8f18695211ce6217a2ea1e5dd5afaa7adfd75a231c5a04692bcL188' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 90536152</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: 2ba27b0132168f3590dd4b3bead9edc15a70ba7d</div><div id='time'> Time: 2023-02-11</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/cmt/cmt.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: CMT(22)</div><div id='n_method'> N Method Name: CMT(22)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/cmt/cmt.py</div><div id='n_file'> N File Name: keras_cv_attention_models/cmt/cmt.py</div><div id='m_start'> M Start Line: 212</div><div id='m_end'> M End Line: 248</div><div id='n_start'> N Start Line: 197</div><div id='n_end'> N End Line: 235</div><BR>