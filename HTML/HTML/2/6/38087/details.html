<html><h3>Pattern ID :38087
</h3><img src='109158656.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Loading loss scale eagerly
        if not args.megatron:
            opt_state_dict = checkpoint["optimizer"]
            optimizer.loss_scaler = <a id="change">opt_state_dict["loss_scaler"]</a>
            optimizer.loss_scaler.model = model
            optimizer.dynamic_loss_scale = opt_state_dict["dynamic_loss_scale"]
            optimizer.overflow = opt_state_dict["overflow"]
            optimizer.first_closure_call_this_step = opt_state_dict["first_closure_call_this_step"]</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 need to pass prefix without ranks to smp
        local_ckpt_path = local_ckpt_path.split(".pt")[0] + ".pt"

    <a id="change">if </a>args.gather_if_shard &gt; 0:
        &#47&#47 Should expect v2 checkpoint here
        checkpoint = smp.load(local_ckpt_path, partial=partial)
    else:
        &#47&#47 Loading separately for model and opt
        checkpoint<a id="change"> = </a>torch.load(f"{local_ckpt_path}_{smp.pp_rank()}_{smp.tp_rank()}_0")
        if smp.rdp_rank() != 0:
            opt_checkpoint<a id="change"> = </a><a id="change">torch.load(
                </a>f"{local_ckpt_path}_{smp.pp_rank()}_{smp.tp_rank()}_{smp.rdp_rank()}"<a id="change">
            )</a>

    if load_model:
        checkpointed_model = (
            translate_hf_state_dict_to_smdistributed(checkpoint["model"], seq_length)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/aws/deep-learning-containers/commit/3e717d20db19b3c962141db2734b8ce2345c1ba0#diff-a40cc024999d8233ec1f28f99103151a632b2030188bc7ae76fa6aaaa88ba23bL211' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 109158656</div><div id='project'> Project Name: aws/deep-learning-containers</div><div id='commit'> Commit Name: 3e717d20db19b3c962141db2734b8ce2345c1ba0</div><div id='time'> Time: 2022-07-15</div><div id='author'> Author: 33940270+YangFei1990@users.noreply.github.com</div><div id='file'> File Name: test/sagemaker_tests/pytorch/training/resources/gpt2/train_gpt_simple.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: load_model_and_optimizer(11)</div><div id='n_method'> N Method Name: load_model_and_optimizer(11)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: test/sagemaker_tests/pytorch/training/resources/gpt2/train_gpt_simple.py</div><div id='n_file'> N File Name: test/sagemaker_tests/pytorch/training/resources/gpt2/train_gpt_simple.py</div><div id='m_start'> M Start Line: 307</div><div id='m_end'> M End Line: 348</div><div id='n_start'> N Start Line: 211</div><div id='n_end'> N End Line: 244</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 Build necessary components
    train_loader = get_loader(config[&quotdata&quot], &quottrain&quot)

    if <a id="change">config[&quotdata&quot][&quotoverfit&quot]</a>:
        val_loader = get_loader(config[&quotdata&quot], &quottrain&quot)
    else:
        val_loader = get_loader(config[&quotdata&quot], &quotval&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
    scheduler = torch.optim.lr_scheduler.StepLR(optim, config[&quottraining&quot][&quotlr_drop&quot])

    &#47&#47 Load checkpoint if applicable
    <a id="change">if </a>args.resume is not None:
        checkpoint = <a id="change">torch.load(</a>Path(args.resume)<a id="change">)</a>

        &#47&#47 Unpack and load content
        model.load_state_dict(checkpoint[&quotmodel_state_dict&quot])
        optim.load_state_dict(checkpoint[&quotoptimizer_state_dict&quot])
        scheduler.load_state_dict(checkpoint[&quotscheduler_state_dict&quot])
        epoch<a id="change"> = </a>checkpoint[&quotepoch&quot]
        metric_start_val = checkpoint[&quotmetric_max_val&quot]
    else:
        epoch = 0
        metric_start_val<a id="change"> = </a>0

    &#47&#47 Init logging
    path_to_run = Path(os.getcwd()) / &quotruns&quot / config[&quottraining&quot][&quotexperiment_name&quot]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bwittmann/transoar/commit/943b60f71cbfae5fcb65729b42c3b9464b433db2#diff-0e048206896ef3808bf29e00f4ca534eb723fe51e27a47b583a92e913c33bbcfL16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 109158658</div><div id='project'> Project Name: bwittmann/transoar</div><div id='commit'> Commit Name: 943b60f71cbfae5fcb65729b42c3b9464b433db2</div><div id='time'> Time: 2021-11-29</div><div id='author'> Author: bastian.wittmann@tum.de</div><div id='file'> File Name: scripts/train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(2)</div><div id='n_method'> N Method Name: train(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/train.py</div><div id='n_file'> N File Name: scripts/train.py</div><div id='m_start'> M Start Line: 17</div><div id='m_end'> M End Line: 51</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 67</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for batch_idx, interaction in enumerate(eval_data):
            &#47&#47 todo:
            USER_ID = self.config[&quotUSER_ID_FIELD&quot]
            ITEM_ID = <a id="change">self.config[&quotITEM_ID_FIELD&quot]</a>
            users, items = interaction[USER_ID], interaction[ITEM_ID]
            scores = self.model.predict(interaction.to(self.device))
            batch_size = users.size()[0]</code></pre><h3>After Change</h3><pre><code class='java'>
                    break

    def evaluate(self, eval_data, load_best_model=True):
        <a id="change">if </a>load_best_model:
            &#47&#47 todo: more flexible settings
            checkpoint_file = self.checkpoint_dir + &quot/model_best.pth&quot
            checkpoint<a id="change"> = </a><a id="change">torch.load(</a>checkpoint_file<a id="change">)</a>
            self.model.load_state_dict(checkpoint[&quotstate_dict&quot])
            message_output<a id="change"> = </a>&quotLoading model structure and parameters from {}&quot.format(checkpoint_file)
            print(message_output)

        self.model.eval()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/recbole/commit/9a769dda3fd556549ce944046d6388298782c141#diff-0564ece5aadc13d5923043addc422a8058c6d96026493e84652cedc2f1bdca99L100' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 109158679</div><div id='project'> Project Name: rucaibox/recbole</div><div id='commit'> Commit Name: 9a769dda3fd556549ce944046d6388298782c141</div><div id='time'> Time: 2020-07-13</div><div id='author'> Author: 2015201909@ruc.edu.cn</div><div id='file'> File Name: trainer/trainer.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: evaluate(3)</div><div id='n_method'> N Method Name: evaluate(2)</div><div id='m_parent_class'> M Parent Class: AbstractTrainer</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: trainer/trainer.py</div><div id='n_file'> N File Name: trainer/trainer.py</div><div id='m_start'> M Start Line: 102</div><div id='m_end'> M End Line: 110</div><div id='n_start'> N Start Line: 149</div><div id='n_end'> N End Line: 165</div><BR>