<html><h3>Pattern ID :32182
</h3><img src='94131868.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        lse_positive = torch.logsumexp(self.log_scale * (pos - self.pos_margin) * pos_weight, dim=-1)

        
        neg<a id="change"> = </a>dists + <a id="change">1e5</a><a id="change"> * </a><a id="change">pos_mask.float()</a>
        neg_weight =  (self.neg_margin - neg).detach()
        neg_weight = torch.max(torch.zeros_like(neg_weight), neg_weight)
        lse_negative = torch.logsumexp(self.log_scale * (self.neg_margin - neg) * neg_weight, dim=-1)
</code></pre><h3>After Change</h3><pre><code class='java'>
        lse_positive = torch.logsumexp(-self.log_scale * (pos - self.pos_margin) * pos_weight, dim=-1)

        neg = dists - 1e5 * (~neg_mask).float()
        neg_weight<a id="change"> =  </a><a id="change">(neg - self.neg_optimal).detach()</a>
        neg_weight = torch.max(torch.zeros_like(neg_weight), neg_weight)
        lse_negative = torch.logsumexp(self.log_scale * (neg - self.neg_margin) * neg_weight, dim=-1)

        loss = F.softplus(lse_positive + lse_negative) / self.log_scale</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/xuyangbai/d3feat.pytorch/commit/f19b93196387b22f1cb416f9a0214b2cffaf8e5e#diff-afc9c0f856a1fa54a2d35dfcd375a176b7b736953195238a3a51870eef4314bbL123' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 94131868</div><div id='project'> Project Name: xuyangbai/d3feat.pytorch</div><div id='commit'> Commit Name: f19b93196387b22f1cb416f9a0214b2cffaf8e5e</div><div id='time'> Time: 2020-07-16</div><div id='author'> Author: 653823597@qq.com</div><div id='file'> File Name: utils/loss.py</div><div id='m_class'> M Class Name: CircleLoss</div><div id='n_method'> N Class Name: CircleLoss</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: utils/loss.py</div><div id='n_file'> N File Name: utils/loss.py</div><div id='m_start'> M Start Line: 123</div><div id='m_end'> M End Line: 152</div><div id='n_start'> N Start Line: 125</div><div id='n_end'> N End Line: 157</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 log_probs_list = tf.unstack(log_probs, axis=1)
        &#47&#47 missing = 1. - torch.cast(present, torch.float32)
        &#47&#47 missing_list = tf.unstack(missing, axis=1)
        missing = <a id="change">1.</a><a id="change"> - </a><a id="change">present.float()</a>

        &#47&#47 Cumulative Discounted Returns.  The true value function V*(s).
        cumulative_rewards = []
        batch_size, seq_len = dis_predictions.size()
        for t in range(seq_len):
            cum_value = torch.zeros((batch_size, 1))
            cum_value = cum_value.cuda(self.device)
            for s in range(t, seq_len):
                cum_value_tmp = missing[:, s] * np.power(self.gamma, (s - t)) * rewards[:, s]
                cum_value_tmp = cum_value_tmp.unsqueeze(dim=1)
                cum_value += cum_value_tmp
            cumulative_rewards.append(cum_value)
        cumulative_rewards = torch.stack(cumulative_rewards, dim=1).squeeze()

        &#47&#47&#47&#47 REINFORCE with different baselines.
        &#47&#47 We create a separate critic functionality for the Discriminator.  This
        &#47&#47 will need to operate unidirectionally and it may take in the past context.
        &#47&#47 Critic loss calculated from the estimated value function \hat{V}(s)
        &#47&#47 versus the true value function V*(s).
        critic_loss = self.create_critic_loss(cumulative_rewards, estimated_values, present)

        &#47&#47 Baselines are coming from the critic&quots estimated state values.
        &#47&#47 baselines = tf.unstack(estimated_values, axis=1)
        baselines = estimated_values

        &#47&#47&#47&#47 Calculate the Advantages, A(s,a) = Q(s,a) - \hat{V}(s).
        advantages = []
        final_gen_objective = torch.zeros([batch_size, 1]).cuda(self.device)
        for t in range(seq_len):
            log_probability = log_probs[:, t].unsqueeze(dim=1)
            cum_advantage = torch.zeros((batch_size, 1))
            cum_advantage = cum_advantage.cuda(self.device)
            for s in range(t, seq_len):
                cum_advantage_tmp = missing[:, s] * np.power(self.gamma, (s - t)) * rewards[:, s]
                cum_advantage_tmp = cum_advantage_tmp.unsqueeze(dim=1)
                cum_advantage += cum_advantage_tmp
            cum_advantage -= baselines[:, t].unsqueeze(dim=1)
            &#47&#47 Clip advantages.
            cum_advantage = torch.clamp(cum_advantage, -self.advantage_clipping, self.advantage_clipping)
            advantage = missing[:, t].unsqueeze(dim=1) * cum_advantage
            advantages.append(advantage)
            &#47&#47 cum_advantage.detach()
            final_gen_objective<a id="change"> += </a>torch.mul(log_probability, missing[:, t].unsqueeze(dim=1) * cum_advantage)
        final_gen_objective = -torch.sum(final_gen_objective) / batch_size  &#47&#47 max the reward
        maintain_averages_op = None
        advantages = torch.stack(advantages, dim=1)</code></pre><h3>After Change</h3><pre><code class='java'>
        zeros = torch.zeros_like(mask_present, dtype=torch.float32)
        log_probs = torch.where(mask_present, zeros, log_probs)
        rewards = torch.where(mask_present, zeros, rewards)
        rewards = <a id="change">rewards.detach()</a>

        &#47&#47 Unstack Tensors into lists.
        missing = 1. - mask_present.float()

        &#47&#47 Cumulative Discounted Returns.  The true value function V*(s).
        cumulative_rewards = []
        batch_size, seq_len = dis_predictions.size()
        for t in range(seq_len):
            cum_value = torch.zeros((batch_size, 1))
            cum_value = cum_value.cuda(device)
            for s in range(t, seq_len):
                cum_value_tmp = missing[:, s] * np.power(self.gamma, (s - t)) * rewards[:, s]
                cum_value_tmp = cum_value_tmp.unsqueeze(dim=1)
                cum_value += cum_value_tmp
            cumulative_rewards.append(cum_value)  &#47&#47 bs*1
        cumulative_rewards = torch.stack(cumulative_rewards, dim=1).squeeze()

        &#47&#47 REINFORCE with different baselines.
        &#47&#47 We create a separate critic functionality for the Discriminator.  This
        &#47&#47 will need to operate unidirectionally and it may take in the past context.
        &#47&#47 Critic loss calculated from the estimated value function \hat{V}(s)
        &#47&#47 versus the true value function V*(s).
        cumulative_rewards = cumulative_rewards.detach()
        critic_loss = self.create_critic_loss(cumulative_rewards, estimated_values, mask_present)

        &#47&#47 Baselines are coming from the critic&quots estimated state values.
        baselines = estimated_values
        baselines = baselines.detach()

        &#47&#47&#47&#47 Calculate the Advantages, A(s,a) = Q(s,a) - \hat{V}(s).
        final_gen_objective = torch.zeros([batch_size, 1]).cuda(self.device)
        for t in range(seq_len):
            log_probability = log_probs[:, t].unsqueeze(dim=1)  &#47&#47 bs*1
            cum_advantage = torch.zeros((batch_size, 1))  &#47&#47 bs*1
            cum_advantage = cum_advantage.cuda(self.device)
            for s in range(t, seq_len):
                cum_advantage_tmp = missing[:, s] * np.power(self.gamma, (s - t)) * rewards[:, s]
                cum_advantage_tmp = cum_advantage_tmp.unsqueeze(dim=1)
                cum_advantage = cum_advantage + cum_advantage_tmp
            cum_advantage = cum_advantage - baselines[:, t].unsqueeze(dim=1)
            &#47&#47 Clip advantages.
            cum_advantage = torch.clamp(cum_advantage, -self.advantage_clipping, self.advantage_clipping)
            cum_advantage_ = cum_advantage.detach()
            final_gen_objective<a id="change"> = </a>final_gen_objective + torch.mul(log_probability,
                                                                  missing[:, t].unsqueeze(dim=1) * cum_advantage_)
        final_gen_objective = -torch.sum(final_gen_objective) / (torch.sum(missing))  &#47&#47 max the reward
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/cc5517ab006f13503389f456551219a634d7ca28#diff-68afacedbfa3668a63caea6bfdbbe7bdc3951d5d959770422411900c650f67c1L211' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 94131869</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: cc5517ab006f13503389f456551219a634d7ca28</div><div id='time'> Time: 2020-12-26</div><div id='author'> Author: 1318829605@qq.com</div><div id='file'> File Name: textbox/module/Generator/MaskGANGenerator.py</div><div id='m_class'> M Class Name: MaskGANGenerator</div><div id='n_method'> N Class Name: MaskGANGenerator</div><div id='m_method'> M Method Name: calculate_reinforce_objective(5)</div><div id='n_method'> N Method Name: calculate_reinforce_objective(5)</div><div id='m_parent_class'> M Parent Class: GenerativeAdversarialNet</div><div id='n_parent_class'> N Parent Class: GenerativeAdversarialNet</div><div id='m_file'> M File Name: textbox/module/Generator/MaskGANGenerator.py</div><div id='n_file'> N File Name: textbox/module/Generator/MaskGANGenerator.py</div><div id='m_start'> M Start Line: 255</div><div id='m_end'> M End Line: 301</div><div id='n_start'> N Start Line: 236</div><div id='n_end'> N End Line: 290</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    else:   &#47&#47 cmap: [256, 3|4] uint8
        assert isinstance(cmap, torch.Tensor) and cmap.shape[0] == 256
        heatmap = cmap[(heatmap * 255).long()].transpose(1, 3).transpose(2, 3)
        heatmap<a id="change"> = </a><a id="change">heatmap.float() / 255</a>
    &#47&#47 Note that C==4 for most cmaps
    heatmap = torch.as_tensor(heatmap.transpose(0, 3, 1, 2))  &#47&#47 (N, C, H, W)
    return heatmap[0] if squeeze_flag else heatmap
</code></pre><h3>After Change</h3><pre><code class='java'>
def apply_cmap(heatmap: torch.Tensor, cmap: Union[Colormap, torch.Tensor] = jet) -&gt; torch.Tensor:
    if cmap is None:
        return heatmap
    heatmap = <a id="change">heatmap.detach()</a>.cpu()
    squeeze_flag = False
    if len(heatmap.shape) == 2:
        heatmap = heatmap.unsqueeze(0)  &#47&#47 (N, H, W)
        squeeze_flag = True
    if isinstance(cmap, Colormap):      &#47&#47 Note that C==4 for most cmaps
        heatmap = torch.as_tensor(cmap(heatmap.numpy()))  &#47&#47 (N, H, W, C)
    else:
        cmap = torch.as_tensor(cmap)
        assert cmap.shape[0] == 256     &#47&#47 cmap: [256, 3|4]
        heatmap = cmap[(heatmap * 255).long()]  &#47&#47 (N, H, W, C)  uint8
    heatmap<a id="change"> = </a>heatmap.transpose(1, 3).transpose(2, 3).float()  &#47&#47 (N, C, H, W)
    heatmap = heatmap / 255 if heatmap.max() &gt; 1 else heatmap  &#47&#47 (N, C, H, W) float
    return heatmap[0] if squeeze_flag else heatmap
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ain-soph/trojanzoo/commit/80e74988c8d77c00322fd1144f83d6ff4e5ee2cb#diff-9826381a50ee9f64319e221dbad2bbbefebdcfdfea0d279eaea735ee921b4d73L13' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 94131880</div><div id='project'> Project Name: ain-soph/trojanzoo</div><div id='commit'> Commit Name: 80e74988c8d77c00322fd1144f83d6ff4e5ee2cb</div><div id='time'> Time: 2020-12-31</div><div id='author'> Author: ain-soph@live.com</div><div id='file'> File Name: trojanvision/utils/__init__.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: apply_cmap(2)</div><div id='n_method'> N Method Name: apply_cmap(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: trojanvision/utils/__init__.py</div><div id='n_file'> N File Name: trojanvision/utils/__init__.py</div><div id='m_start'> M Start Line: 14</div><div id='m_end'> M End Line: 27</div><div id='n_start'> N Start Line: 15</div><div id='n_end'> N End Line: 29</div><BR>