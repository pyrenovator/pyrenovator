<html><h3>Pattern ID :25956
</h3><img src='78412141.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)
    grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)
    x_pad = F.pad(x, [1, 1, 1, 1, 0, 0, 0, 0])
    x = <a id="change">x_pad[grid_batch, :, grid_x, grid_y]</a>.permute(0, 3, 1, 2)
    return x

</code></pre><h3>After Change</h3><pre><code class='java'>

def rand_translation(x, ratio=0.125):
    import pdb; pdb.set_trace()
    shift_x, shift_y = int(x.size(2)<a id="change"> * ratio</a> + 0.5), <a id="change">int(</a>x.size(3)<a id="change"> * ratio</a> + 0.5<a id="change">)</a>
    translation_x = torch.randint(-shift_x, shift_x + 1, size=[x.size(0), 1, 1], device=x.device)
    translation_y = torch.randint(-shift_y, shift_y + 1, size=[x.size(0), 1, 1], device=x.device)
    grid_batch, grid_x, grid_y = torch.meshgrid(
        torch.arange(x.size(0), dtype=torch.long, device=x.device),</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/postech-cvlab/pytorch-studiogan/commit/32579a1865b2a7829e766d8ce393609701382953#diff-bae102768496ce7fd6380da84f8497957addb0c769dbb5f14c038933d08aa6fdL69' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78412141</div><div id='project'> Project Name: postech-cvlab/pytorch-studiogan</div><div id='commit'> Commit Name: 32579a1865b2a7829e766d8ce393609701382953</div><div id='time'> Time: 2020-08-23</div><div id='author'> Author: first287@naver.com</div><div id='file'> File Name: utils/diff_aug.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: rand_translation(2)</div><div id='n_method'> N Method Name: rand_translation(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: utils/diff_aug.py</div><div id='n_file'> N File Name: utils/diff_aug.py</div><div id='m_start'> M Start Line: 69</div><div id='m_end'> M End Line: 80</div><div id='n_start'> N Start Line: 70</div><div id='n_end'> N End Line: 81</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    img *= 0.15

    &#47&#47 Center crop
    img = <a id="change">img[25:-25, 25:-25, :]</a>

    &#47&#47 Clip to [0, 1]
    img += 0.5
    img = np.clip(img, 0, 1)</code></pre><h3>After Change</h3><pre><code class='java'>
    img *= 0.15

    &#47&#47 Center crop
    hh_crop, ww_crop = <a id="change">int(</a>img.shape[0]<a id="change"> * </a>crop_border<a id="change">)</a>, int(img.shape[1]<a id="change"> * </a>crop_border)
    img = img[hh_crop:-hh_crop, ww_crop:-ww_crop]

    &#47&#47 Clip to [0, 1]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/d411c57807dedc4b03ca737a6596ae6ecc429dd5#diff-1ec9a19aafb9379c6e226dccc101dafcc65576f11136e0603301b13fca3f7db4L37' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78412142</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: d411c57807dedc4b03ca737a6596ae6ecc429dd5</div><div id='time'> Time: 2022-01-07</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/visualizing/visualizing.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: __deprocess_image__(2)</div><div id='n_method'> N Method Name: __deprocess_image__(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/visualizing/visualizing.py</div><div id='n_file'> N File Name: keras_cv_attention_models/visualizing/visualizing.py</div><div id='m_start'> M Start Line: 37</div><div id='m_end'> M End Line: 44</div><div id='n_start'> N Start Line: 31</div><div id='n_end'> N End Line: 39</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 if user supplies a mask that is only off by one from the source sequence, resolve it for them
        mask = kwargs.get(&quotmask&quot, None)
        if mask is not None and mask.shape[1] == x.shape[1]:
            mask = <a id="change">mask[:, :-1]</a>
            kwargs[&quotmask&quot] = mask

        out = self.net(xi, **kwargs)
        loss = F.cross_entropy(out.transpose(1, 2), xo, ignore_index = self.ignore_index)</code></pre><h3>After Change</h3><pre><code class='java'>
        if self.mask_prob &gt; 0.:
            rand = torch.randn(inp.shape, device = x.device)
            rand[:, 0] = -torch.finfo(rand.dtype).max &#47&#47 first token should not be masked out
            num_mask = min(<a id="change">int(</a>seq<a id="change"> * </a>self.mask_prob<a id="change">)</a>, seq<a id="change"> - </a>1)
            indices = rand.topk(num_mask, dim = -1).indices
            mask = ~torch.zeros_like(inp).scatter(1, indices, 1.).bool()
            kwargs.update(context_mask = mask)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/x-transformers/commit/595a4745d532c20b8ebd310256c342e946a4cef7#diff-b70a3173d353a448f8f499d8b685672d9bccac7b78bc1d36b77f84afe33be694L106' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78412143</div><div id='project'> Project Name: lucidrains/x-transformers</div><div id='commit'> Commit Name: 595a4745d532c20b8ebd310256c342e946a4cef7</div><div id='time'> Time: 2022-11-02</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: x_transformers/autoregressive_wrapper.py</div><div id='m_class'> M Class Name: AutoregressiveWrapper</div><div id='n_method'> N Class Name: AutoregressiveWrapper</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: x_transformers/autoregressive_wrapper.py</div><div id='n_file'> N File Name: x_transformers/autoregressive_wrapper.py</div><div id='m_start'> M Start Line: 107</div><div id='m_end'> M End Line: 118</div><div id='n_start'> N Start Line: 122</div><div id='n_end'> N End Line: 142</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)
    grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)
    x_pad = F.pad(x, [1, 1, 1, 1, 0, 0, 0, 0])
    x = <a id="change">x_pad[grid_batch, :, grid_x, grid_y]</a>.permute(0, 3, 1, 2)
    return x

</code></pre><h3>After Change</h3><pre><code class='java'>

def rand_translation(x, ratio=0.125):
    import pdb; pdb.set_trace()
    shift_x, shift_y = <a id="change">int(</a>x.size(2)<a id="change"> * </a>ratio + 0.5<a id="change">)</a>, int(x.size(3)<a id="change"> * </a>ratio + 0.5)
    translation_x = torch.randint(-shift_x, shift_x + 1, size=[x.size(0), 1, 1], device=x.device)
    translation_y = torch.randint(-shift_y, shift_y + 1, size=[x.size(0), 1, 1], device=x.device)
    grid_batch, grid_x, grid_y = torch.meshgrid(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/postech-cvlab/pytorch-studiogan/commit/32579a1865b2a7829e766d8ce393609701382953#diff-bae102768496ce7fd6380da84f8497957addb0c769dbb5f14c038933d08aa6fdL67' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78412144</div><div id='project'> Project Name: postech-cvlab/pytorch-studiogan</div><div id='commit'> Commit Name: 32579a1865b2a7829e766d8ce393609701382953</div><div id='time'> Time: 2020-08-23</div><div id='author'> Author: first287@naver.com</div><div id='file'> File Name: utils/diff_aug.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: rand_translation(2)</div><div id='n_method'> N Method Name: rand_translation(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: utils/diff_aug.py</div><div id='n_file'> N File Name: utils/diff_aug.py</div><div id='m_start'> M Start Line: 69</div><div id='m_end'> M End Line: 80</div><div id='n_start'> N Start Line: 70</div><div id='n_end'> N End Line: 81</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 print(f"{ww = }, {hh = }, {cc = }, {num_patches = }, {valid_ww = }, {overlap_s = }")
    &#47&#47 ww = 30, hh = 30, cc = 192, num_patches = 14, valid_ww = 28, overlap_s = 1

    center = tf.reshape(<a id="change">pad_inputs[:, :valid_ww, :valid_ww, :]</a>, temp_shape) &#47&#47 (1, 14, 2, 14, 2, 192)
    ww_overlap = tf.reshape(pad_inputs[:, :valid_ww, overlap_s:valid_ww + overlap_s, :], temp_shape)  &#47&#47 (1, 14, 2, 14, 2, 192)
    hh_overlap = tf.reshape(pad_inputs[:, overlap_s:valid_ww + overlap_s, :valid_ww, :], temp_shape)  &#47&#47 (1, 14, 2, 14, 2, 192)
    corner_overlap = tf.reshape(pad_inputs[:, overlap_s:valid_ww + overlap_s, overlap_s:valid_ww + overlap_s, :], temp_shape) &#47&#47 (1, 14, 2, 14, 2, 192)</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 kernel_size, strides = 3, 2
    &#47&#47 inputs = np.random.uniform(size=[1, 64, 28, 192])
    kernel_size = sizes[1] if isinstance(sizes, (list, tuple)) else sizes
    <a id="change">strides</a> = strides[1] if isinstance(strides, (list, tuple)) else strides

    if padding.upper() == "SAME":
        pad = kernel_size // 2
        pad_inputs = tf.pad(inputs, [[0, 0], [pad, pad], [pad, pad], [0, 0]])
    else:
        pad_inputs = inputs

    _, hh, ww, cc = pad_inputs.shape
    num_patches_hh, num_patches_ww = <a id="change">int(</a>tf.math.ceil(hh<a id="change"> / </a>strides) - 1<a id="change">)</a>, int(tf.math.ceil(ww / strides) - 1)
    valid_hh, valid_ww = num_patches_hh * strides, num_patches_ww<a id="change"> * </a>strides
    overlap_s = kernel_size - strides
    temp_shape = (-1, num_patches_hh, strides, num_patches_ww, strides, cc)
    &#47&#47 print(f"{ww = }, {hh = }, {cc = }, {num_patches_hh = }, {num_patches_ww = }, {valid_hh = }, {valid_ww = }, {overlap_s = }")</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/c945694eeaf340f96627ec0155b9b26ddad5d30c#diff-346aa59a353ab2958ad8559a1c05a8fc850eaead58fd103d6bcb5a5130b699ceL178' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78412146</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: c945694eeaf340f96627ec0155b9b26ddad5d30c</div><div id='time'> Time: 2021-10-08</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/common_layers.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: tpu_extract_patches_overlap_1(6)</div><div id='n_method'> N Method Name: tpu_extract_patches_overlap_1(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/common_layers.py</div><div id='n_file'> N File Name: keras_cv_attention_models/common_layers.py</div><div id='m_start'> M Start Line: 180</div><div id='m_end'> M End Line: 214</div><div id='n_start'> N Start Line: 183</div><div id='n_end'> N End Line: 217</div><BR>