<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        with torch.enable_grad(), torch.cuda.amp.autocast(self.autocast):
            with torch.autograd.graph.saved_tensors_hooks(self.inner_pack, self.inner_unpack):
                out = self.module_list[self.idx](self.x1)
            <a id="change">self.cache(</a>x1.detach_(), <a id="change">self.coupling_inverse(x0, out.detach()).detach_())</a>
            with torch.autograd.graph.saved_tensors_hooks(self.inner_pack, self.inner_unpack):
                _unused = self.coupling_forward(x0, out)
        return self.unpack(key)
</code></pre><h3>After Change</h3><pre><code class='java'>
        x1 = self.cache.x1
        with torch.random.fork_rng(self.cuda_devices):
            torch.set_rng_state(self.cpu_state)
            <a id="change">if </a>self.cuda:
                torch.utils.checkpoint.set_device_states(self.cuda_devices, self.cuda_states)
            with torch.enable_grad(), torch.cuda.amp.autocast(self.autocast):
                with torch.autograd.graph.saved_tensors_hooks(self.inner_pack, self.inner_unpack):</code></pre>