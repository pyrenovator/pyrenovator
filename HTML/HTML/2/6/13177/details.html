<html><h3>Pattern ID :13177
</h3><img src='44564044.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        with torch.enable_grad(), torch.cuda.amp.autocast(self.autocast):
            with torch.autograd.graph.saved_tensors_hooks(self.inner_pack, self.inner_unpack):
                out = self.module_list[self.idx](self.x1)
            <a id="change">self.cache(</a>x1.detach_(), <a id="change">self.coupling_inverse(x0, out.detach()).detach_())</a>
            with torch.autograd.graph.saved_tensors_hooks(self.inner_pack, self.inner_unpack):
                _unused = self.coupling_forward(x0, out)
        return self.unpack(key)
</code></pre><h3>After Change</h3><pre><code class='java'>
        x1 = self.cache.x1
        with torch.random.fork_rng(self.cuda_devices):
            torch.set_rng_state(self.cpu_state)
            <a id="change">if </a>self.cuda:
                torch.utils.checkpoint.set_device_states(self.cuda_devices, self.cuda_states)
            with torch.enable_grad(), torch.cuda.amp.autocast(self.autocast):
                with torch.autograd.graph.saved_tensors_hooks(self.inner_pack, self.inner_unpack):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/clashluke/revlib/commit/3beacf35cd5bfc86f4bb2062158a137b7d3f3c5b#diff-a30da84ea8f217da1469b87e7e46cf331f17c8509ac1c91b3d2ce7d97a354659L157' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 44564044</div><div id='project'> Project Name: clashluke/revlib</div><div id='commit'> Commit Name: 3beacf35cd5bfc86f4bb2062158a137b7d3f3c5b</div><div id='time'> Time: 2021-10-27</div><div id='author'> Author: 39779310+ClashLuke@users.noreply.github.com</div><div id='file'> File Name: revlib/__init__.py</div><div id='m_class'> M Class Name: ReversibleModule</div><div id='n_method'> N Class Name: ReversibleModule</div><div id='m_method'> M Method Name: unpack(2)</div><div id='n_method'> N Method Name: unpack(2)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: revlib/__init__.py</div><div id='n_file'> N File Name: revlib/__init__.py</div><div id='m_start'> M Start Line: 157</div><div id='m_end'> M End Line: 166</div><div id='n_start'> N Start Line: 164</div><div id='n_end'> N End Line: 172</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    x0 = self.coupling_inverse(y1, out.detach()).detach_()
                    self.cache(x0, x1)
                else:
                    x0 = <a id="change">self.coupling_inverse(y1, out[0].detach()).detach_()</a>
                    <a id="change">self.cache(</a>x0, x1[0]<a id="change">)</a>
                with torch.autograd.graph.saved_tensors_hooks(self.inner_pack, self.inner_unpack):
                    _unused = self.coupling_forward(x0, out)
        return self.unpack(key)
</code></pre><h3>After Change</h3><pre><code class='java'>
                with torch.autograd.graph.saved_tensors_hooks(self.inner_pack, self.inner_unpack):
                    out = self.wrapped_module(x1, *self.input_args, **self.input_kwargs)
                out = take_0th_tensor(out)
                <a id="change">if </a>not isinstance(out, torch.Tensor):
                    out = out[0]
                x0 = self.coupling_inverse(y1, out.detach()).detach_()
                self.cache(x0, x1)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/clashluke/revlib/commit/0a4dccbb225445fa7b4aaa37f9a45300ee18f9cd#diff-27dbe7773eec5c50b26c4f116cdff7cba9b8e8580d331a31f6741cb7f50d0d09L177' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 44564043</div><div id='project'> Project Name: clashluke/revlib</div><div id='commit'> Commit Name: 0a4dccbb225445fa7b4aaa37f9a45300ee18f9cd</div><div id='time'> Time: 2021-12-30</div><div id='author'> Author: 39779310+ClashLuke@users.noreply.github.com</div><div id='file'> File Name: revlib/core.py</div><div id='m_class'> M Class Name: ReversibleModule</div><div id='n_method'> N Class Name: ReversibleModule</div><div id='m_method'> M Method Name: unpack(2)</div><div id='n_method'> N Method Name: unpack(2)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: revlib/core.py</div><div id='n_file'> N File Name: revlib/core.py</div><div id='m_start'> M Start Line: 183</div><div id='m_end'> M End Line: 199</div><div id='n_start'> N Start Line: 194</div><div id='n_end'> N End Line: 199</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        with torch.enable_grad(), torch.cuda.amp.autocast(self.autocast):
            with torch.autograd.graph.saved_tensors_hooks(self.inner_pack, self.inner_unpack):
                out = self.module_list[self.idx](self.x1)
            <a id="change">self.cache(</a>x1.detach_(), <a id="change">self.coupling_inverse(x0, out.detach()).detach_())</a>
            with torch.autograd.graph.saved_tensors_hooks(self.inner_pack, self.inner_unpack):
                _unused = self.coupling_forward(x0, out)
        return self.unpack(key)
</code></pre><h3>After Change</h3><pre><code class='java'>
        x1 = self.cache.x1
        with torch.random.fork_rng(self.cuda_devices):
            torch.set_rng_state(self.cpu_state)
            <a id="change">if </a>self.cuda:
                torch.utils.checkpoint.set_device_states(self.cuda_devices, self.cuda_states)
            with torch.enable_grad(), torch.cuda.amp.autocast(self.autocast):
                with torch.autograd.graph.saved_tensors_hooks(self.inner_pack, self.inner_unpack):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/homebrewnlp/revlib/commit/3beacf35cd5bfc86f4bb2062158a137b7d3f3c5b#diff-a30da84ea8f217da1469b87e7e46cf331f17c8509ac1c91b3d2ce7d97a354659L152' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 44564042</div><div id='project'> Project Name: homebrewnlp/revlib</div><div id='commit'> Commit Name: 3beacf35cd5bfc86f4bb2062158a137b7d3f3c5b</div><div id='time'> Time: 2021-10-27</div><div id='author'> Author: 39779310+ClashLuke@users.noreply.github.com</div><div id='file'> File Name: revlib/__init__.py</div><div id='m_class'> M Class Name: ReversibleModule</div><div id='n_method'> N Class Name: ReversibleModule</div><div id='m_method'> M Method Name: unpack(2)</div><div id='n_method'> N Method Name: unpack(2)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: revlib/__init__.py</div><div id='n_file'> N File Name: revlib/__init__.py</div><div id='m_start'> M Start Line: 157</div><div id='m_end'> M End Line: 166</div><div id='n_start'> N Start Line: 164</div><div id='n_end'> N End Line: 172</div><BR>