<html><h3>Pattern ID :39422
</h3><img src='111898283.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
	train_labs = torch.tensor(train_data[&quotlabels&quot]).cuda()
	train_ids = torch.tensor(train_data[&quotuid&quot]).cuda()

	<a id="change">if args[&quotembed_size&quot] == 768</a>:
		model = RobertaModel.from_pretrained(&quotroberta-base&quot).cuda()
	else:
		model = RobertaModel.from_pretrained(&quotroberta-large&quot).cuda()</code></pre><h3>After Change</h3><pre><code class='java'>
    test_data = pickle.load(test_data_file)
    
    &#47&#47 Creating required save directories
    <a id="change">if </a>not os.path.isdir(args[&quotsave_dir&quot]+args[&quotsave_folder&quot]):
        os.mkdir(args[&quotsave_dir&quot]+args[&quotsave_folder&quot])
        
        print("{} train data loaded".format(len(train_data[&quotencodings&quot])))
        print("{} dev data loaded".format(len(dev_data[&quotencodings&quot])))
        print("{} test data loaded".format(len(test_data[&quotencodings&quot])))
        
        train_data_file.close()
        dev_data_file.close()
        test_data_file.close()
        
        &#47&#47 Separating the data fields
        train_enc = torch.tensor(train_data[&quotencodings&quot]).cuda()
        train_attention_mask = torch.tensor(train_data[&quotattention_mask&quot]).cuda()
        train_segs = torch.tensor(train_data[&quotsegments&quot]).cuda()
        train_labs = torch.tensor(train_data[&quotlabels&quot]).cuda()
        train_ids = torch.tensor(train_data[&quotuid&quot]).cuda()


        &#47&#47 Intialize Models
        model<a id="change"> = </a><a id="change">AutoModel.from_pretrained(</a>args[&quotmodel_type&quot]<a id="change">)</a>.cuda()
        args[&quotembed_size&quot]<a id="change"> = </a>model.config.hidden_size
        classifier = FeedForward(args[&quotembed_size&quot],int(args[&quotembed_size&quot]/2),args[&quotnooflabels&quot]).cuda()

        &#47&#47 Creating the training dataloaders</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/utahnlp/infotabs-code/commit/27cf8e2d7a767e0c5ee1a285797dd8d68090d707#diff-22b44a302a031db01b956acf4520f7dcbc49d0fad57ce247cdb5fe22b5267f18L83' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111898283</div><div id='project'> Project Name: utahnlp/infotabs-code</div><div id='commit'> Commit Name: 27cf8e2d7a767e0c5ee1a285797dd8d68090d707</div><div id='time'> Time: 2021-11-22</div><div id='author'> Author: maitrey@redfish.cs.utah.edu</div><div id='file'> File Name: scripts/roberta/classifier.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(1)</div><div id='n_method'> N Method Name: train(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/roberta/classifier.py</div><div id='n_file'> N File Name: scripts/roberta/classifier.py</div><div id='m_start'> M Start Line: 83</div><div id='m_end'> M End Line: 164</div><div id='n_start'> N Start Line: 112</div><div id='n_end'> N End Line: 193</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    st = torch.load(f&quot{delta_ckpt}&quot)
    pretrained_st = torch.load(ckpt)[&quotstate_dict&quot]
    for each in pretrained_st.keys():
        <a id="change">if &quotattn2&quot in each</a>:
            print(each)

    embed = None</code></pre><h3>After Change</h3><pre><code class='java'>
def compress(delta_ckpt, ckpt, diffuser=False, compression_ratio=0.6, device=&quotcuda&quot):
    st = torch.load(f&quot{delta_ckpt}&quot)

    <a id="change">if </a>not diffuser:
        compressed_key = &quotstate_dict&quot
        compressed_st = {compressed_key: {}}
        pretrained_st = torch.load(ckpt)[&quotstate_dict&quot]
        if &quotembed&quot in st[&quotstate_dict&quot]:
            compressed_st[&quotstate_dict&quot][&quotembed&quot] = st[&quotstate_dict&quot][&quotembed&quot]
            del st[&quotstate_dict&quot][&quotembed&quot]

        st = st[&quotstate_dict&quot]
    else:
        from diffusers import StableDiffusionPipeline
        compressed_key = &quotunet&quot
        compressed_st = {compressed_key: {}}
        pretrained_st<a id="change"> = </a><a id="change">StableDiffusionPipeline.from_pretrained(</a>ckpt<a id="change">, torch_dtype=torch.float16)</a>.to("cuda")
        pretrained_st<a id="change"> = </a>pretrained_st.unet.state_dict()
        if &quotmodifier_token&quot in st:
            compressed_st[&quotmodifier_token&quot] = st[&quotmodifier_token&quot]
        st = st[&quotunet&quot]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/adobe-research/custom-diffusion/commit/5cd1e9c869b793d88573533a6a2adccd10aadcd0#diff-0f4293c247a4f4e8eab25c82da6ce7037c91175297d9dae021e3b167f28c1121L9' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111898282</div><div id='project'> Project Name: adobe-research/custom-diffusion</div><div id='commit'> Commit Name: 5cd1e9c869b793d88573533a6a2adccd10aadcd0</div><div id='time'> Time: 2023-01-05</div><div id='author'> Author: nupurkumari@Nupurs-MacBook-Pro.local</div><div id='file'> File Name: src/compress.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: compress(5)</div><div id='n_method'> N Method Name: compress(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/compress.py</div><div id='n_file'> N File Name: src/compress.py</div><div id='m_start'> M Start Line: 10</div><div id='m_end'> M End Line: 48</div><div id='n_start'> N Start Line: 8</div><div id='n_end'> N End Line: 48</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    trainer.fit(use_lora=args.lora_rank)

    <a id="change">if args.lora_rank &gt; 0</a>:
        torch.save({&quotmodel_state_dict&quot: lora.lora_state_dict(trainer.model)}, args.save_path)
    else:
        torch.save(trainer.model, args.save_path)</code></pre><h3>After Change</h3><pre><code class='java'>
            raise ValueError(f&quotUnsupported model "{args.model}"&quot)

    &#47&#47 configure tokenizer
    <a id="change">if </a>args.model == &quotgpt2&quot:
        tokenizer<a id="change"> = </a><a id="change">GPT2Tokenizer.from_pretrained(</a>&quotgpt2&quot<a id="change">)</a>
        tokenizer.pad_token<a id="change"> = </a>tokenizer.eos_token
    elif args.model == &quotbloom&quot:
        tokenizer = BloomTokenizerFast.from_pretrained(args.pretrain)
        tokenizer.pad_token = tokenizer.eos_token</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hpcaitech/colossalai/commit/2e16f842a9e5b1fb54e7e41070e9d2bb5cd64d7c#diff-ae334630116a22e70bef5ac44f98680bffc0c93d8a594dd5dd3148cf507da0afL16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111898270</div><div id='project'> Project Name: hpcaitech/colossalai</div><div id='commit'> Commit Name: 2e16f842a9e5b1fb54e7e41070e9d2bb5cd64d7c</div><div id='time'> Time: 2023-02-22</div><div id='author'> Author: 70618399+ht-zhou@users.noreply.github.com</div><div id='file'> File Name: applications/ChatGPT/examples/train_reward_model.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(1)</div><div id='n_method'> N Method Name: train(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: applications/ChatGPT/examples/train_reward_model.py</div><div id='n_file'> N File Name: applications/ChatGPT/examples/train_reward_model.py</div><div id='m_start'> M Start Line: 30</div><div id='m_end'> M End Line: 66</div><div id='n_start'> N Start Line: 31</div><div id='n_end'> N End Line: 84</div><BR>