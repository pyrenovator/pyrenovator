<html><h3>Pattern ID :30003
</h3><img src='88972301.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                for task in itertools.islice(tasks, self.simultaneous_tasks)
            }

            while <a id="change">futures</a>:
                &#47&#47 Wait for the next future to complete.
                done, futures = concurrent.futures.wait(
                    futures, return_when=concurrent.futures.FIRST_COMPLETED
                )

                &#47&#47 Schedule the next set of futures.  We don&quott want more than N futures
                &#47&#47 in the pool at a time, to keep memory consumption down.
                <a id="change">for </a>task in itertools.islice(tasks, len(done))<a id="change">:
                    </a><a id="change">futures.add(
                        </a>executor.submit(self.compute_func, task)<a id="change">
                    )</a></code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 Schedule the first N futures.  We don&quott want to schedule them all
            &#47&#47 at once, to avoid consuming excessive amounts of memory.

            futures = <a id="change">[
                executor.submit(self.compute_func, task) \
                    for task in tasks
            ]</a>
            kwargs = {
                &quottotal&quot: len(futures),
                &quotunit&quot: &quotit&quot,
                &quotunit_scale&quot: True,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/dsgoficial/pytorch_segmentation_models_trainer/commit/0bfae1005a07bd2600614e2e59d704e9c1258954#diff-b124c057b8031099a9ee98d2fefd82adb1053cb9883bc49f1a5601a4b25bda94L33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 88972301</div><div id='project'> Project Name: dsgoficial/pytorch_segmentation_models_trainer</div><div id='commit'> Commit Name: 0bfae1005a07bd2600614e2e59d704e9c1258954</div><div id='time'> Time: 2021-04-19</div><div id='author'> Author: philipeborba@gmail.com</div><div id='file'> File Name: pytorch_segmentation_models_trainer/tools/parallel_processing/process_executor.py</div><div id='m_class'> M Class Name: Executor</div><div id='n_method'> N Class Name: Executor</div><div id='m_method'> M Method Name: execute_tasks(2)</div><div id='n_method'> N Method Name: execute_tasks(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: pytorch_segmentation_models_trainer/tools/parallel_processing/process_executor.py</div><div id='n_file'> N File Name: pytorch_segmentation_models_trainer/tools/parallel_processing/process_executor.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 52</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 50</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            else simultaneous_tasks

    def execute_tasks(self, tasks: Iterator):
       with concurrent.futures.ThreadPoolExecutor() as <a id="change">executor</a>:
            &#47&#47 Schedule the first N futures.  We don&quott want to schedule them all
            &#47&#47 at once, to avoid consuming excessive amounts of memory.
            futures = {
                executor.submit(self.compute_func, task)
                for task in itertools.islice(tasks, self.simultaneous_tasks)
            }

            while futures:
                &#47&#47 Wait for the next future to complete.
                done, futures = concurrent.futures.wait(
                    futures, return_when=concurrent.futures.FIRST_COMPLETED
                )

                &#47&#47 Schedule the next set of futures.  We don&quott want more than N futures
                &#47&#47 in the pool at a time, to keep memory consumption down.
                <a id="change">for task</a> in itertools.islice(tasks, len(done))<a id="change">:
                    </a><a id="change">futures.add(
                        </a>executor.submit(self.compute_func, task)<a id="change">
                    )</a></code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 Schedule the first N futures.  We don&quott want to schedule them all
            &#47&#47 at once, to avoid consuming excessive amounts of memory.

            futures = <a id="change">[
                executor.submit(self.compute_func, task) \
                    for task in tasks
            ]</a>
            kwargs = {
                &quottotal&quot: len(futures),
                &quotunit&quot: &quotit&quot,
                &quotunit_scale&quot: True,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/dsgoficial/pytorch_segmentation_models_trainer/commit/0bfae1005a07bd2600614e2e59d704e9c1258954#diff-b124c057b8031099a9ee98d2fefd82adb1053cb9883bc49f1a5601a4b25bda94L32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 88972300</div><div id='project'> Project Name: dsgoficial/pytorch_segmentation_models_trainer</div><div id='commit'> Commit Name: 0bfae1005a07bd2600614e2e59d704e9c1258954</div><div id='time'> Time: 2021-04-19</div><div id='author'> Author: philipeborba@gmail.com</div><div id='file'> File Name: pytorch_segmentation_models_trainer/tools/parallel_processing/process_executor.py</div><div id='m_class'> M Class Name: Executor</div><div id='n_method'> N Class Name: Executor</div><div id='m_method'> M Method Name: execute_tasks(2)</div><div id='n_method'> N Method Name: execute_tasks(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: pytorch_segmentation_models_trainer/tools/parallel_processing/process_executor.py</div><div id='n_file'> N File Name: pytorch_segmentation_models_trainer/tools/parallel_processing/process_executor.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 52</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 50</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def generate(self, eval_data):
        generate_corpus = []
        first_token_ids = set()
        for i, <a id="change">corpus</a> in enumerate(eval_data):
            text_sequence = corpus["target_text"]
            <a id="change">for text</a> in text_sequence<a id="change">:
                </a>sentence = &quot &quot.join(text)
                encoding_dict = self.tokenizer(sentence)
                <a id="change">first_token_ids.add(</a>encoding_dict[&quotinput_ids&quot][0]<a id="change">)</a>
        first_token_ids = list(first_token_ids)

        with torch.no_grad():
            for _ in range(self.eval_generate_num):</code></pre><h3>After Change</h3><pre><code class='java'>
                num_return_sequences=eval_data.batch_size
            )
            generated_text = self.tokenizer.batch_decode(sample_outputs, skip_special_tokens=True)
            generate_corpus.extend(<a id="change">[text.lower().split() for text in generated_text]</a>)
        return generate_corpus

    def calculate_loss(self, corpus, epoch_idx=-1, nll_test=False):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/53c76331ad0c943d52e3310affd25d0e505eb830#diff-46c204cb38a17e9732183ae3be044daf1499fd8305089a2b66f8f827b7ee5e66L52' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 88972303</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 53c76331ad0c943d52e3310affd25d0e505eb830</div><div id='time'> Time: 2021-01-19</div><div id='author'> Author: 1020139164@qq.com</div><div id='file'> File Name: textbox/model/LM/xlnet.py</div><div id='m_class'> M Class Name: XLNet</div><div id='n_method'> N Class Name: XLNet</div><div id='m_method'> M Method Name: generate(2)</div><div id='n_method'> N Method Name: generate(2)</div><div id='m_parent_class'> M Parent Class: UnconditionalGenerator</div><div id='n_parent_class'> N Parent Class: UnconditionalGenerator</div><div id='m_file'> M File Name: textbox/model/LM/xlnet.py</div><div id='n_file'> N File Name: textbox/model/LM/xlnet.py</div><div id='m_start'> M Start Line: 54</div><div id='m_end'> M End Line: 75</div><div id='n_start'> N Start Line: 60</div><div id='n_end'> N End Line: 70</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def generate(self, eval_data):
        generate_corpus = []
        first_token_ids = set()
        for <a id="change">corpus</a> in eval_data:
            text_sequence = corpus["target_text"]
            <a id="change">for text</a> in text_sequence<a id="change">:
                </a>sentence = &quot &quot.join(text)
                encoding_dict = self.tokenizer(sentence)
                <a id="change">first_token_ids.add(</a>encoding_dict[&quotinput_ids&quot][0]<a id="change">)</a>
        first_token_ids = list(first_token_ids)

        with torch.no_grad():
            for _ in range(self.eval_generate_num):</code></pre><h3>After Change</h3><pre><code class='java'>
                num_return_sequences=eval_data.batch_size
            )
            generated_text = self.tokenizer.batch_decode(sample_outputs, skip_special_tokens=True)
            generate_corpus.extend(<a id="change">[text.lower().split() for text in generated_text]</a>)
        return generate_corpus

    def calculate_loss(self, corpus, epoch_idx=-1, nll_test=False):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/53c76331ad0c943d52e3310affd25d0e505eb830#diff-da9020b7921d1fba6b2fab2060235123581b65e72d8336411bd2530895ce313fL49' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 88972302</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 53c76331ad0c943d52e3310affd25d0e505eb830</div><div id='time'> Time: 2021-01-19</div><div id='author'> Author: 1020139164@qq.com</div><div id='file'> File Name: textbox/model/LM/gpt2.py</div><div id='m_class'> M Class Name: GPT2</div><div id='n_method'> N Class Name: GPT2</div><div id='m_method'> M Method Name: generate(2)</div><div id='n_method'> N Method Name: generate(2)</div><div id='m_parent_class'> M Parent Class: UnconditionalGenerator</div><div id='n_parent_class'> N Parent Class: UnconditionalGenerator</div><div id='m_file'> M File Name: textbox/model/LM/gpt2.py</div><div id='n_file'> N File Name: textbox/model/LM/gpt2.py</div><div id='m_start'> M Start Line: 51</div><div id='m_end'> M End Line: 72</div><div id='n_start'> N Start Line: 60</div><div id='n_end'> N End Line: 70</div><BR>