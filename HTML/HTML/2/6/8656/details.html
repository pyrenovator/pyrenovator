<html><h3>Pattern ID :8656
</h3><img src='30034816.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        :return:
        
        batch_size, N, _ = tar_candidate.size()
        tar_pred_prob<a id="change">, dx, dy, top_m_indices = </a><a id="change">self.forward(</a>feat_in, tar_candidate<a id="change">)</a>

        &#47&#47 select the M output and gt
        index_offset = torch.arange(0, batch_size, device=self.device).view(batch_size, -1).repeat(1, self.M).view(-1)
        top_m_indices = top_m_indices.view(-1) + index_offset * N</code></pre><h3>After Change</h3><pre><code class='java'>
        batch_size, N, _ = tar_candidate.size()

        &#47&#47 pred prob and compute cls loss
        feat_in_prob = torch.cat([<a id="change">feat_in.unsqueeze(1</a><a id="change">)</a>.repeat(1, N, 1), tar_candidate], dim=2)
        tar_candit_prob<a id="change"> = </a>self.prob_mlp(feat_in_prob).squeeze(-1)               &#47&#47 [batch_size, self.N_tar]
        _<a id="change">, indices = </a>tar_candit_prob.topk(self.M, dim=1)

        &#47&#47 select the M output and gt
        index_offset = torch.arange(0, batch_size, device=self.device).view(batch_size, -1).repeat(1, self.M).view(-1)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/henry1iu/tnt-trajectory-predition/commit/f39d0655e9e763f4dd61411259fdd4d214f6f34d#diff-62f1e94c741c7f9de60de56afd69a4d711a920fcbe44cef948ec2491a6158b3eL92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 30034816</div><div id='project'> Project Name: henry1iu/tnt-trajectory-predition</div><div id='commit'> Commit Name: f39d0655e9e763f4dd61411259fdd4d214f6f34d</div><div id='time'> Time: 2021-04-09</div><div id='author'> Author: liu.jb.henry@gmail.com</div><div id='file'> File Name: core/model/layers/target_prediction.py</div><div id='m_class'> M Class Name: TargetPred</div><div id='n_method'> N Class Name: TargetPred</div><div id='m_method'> M Method Name: loss(6)</div><div id='n_method'> N Method Name: loss(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: core/model/layers/target_prediction.py</div><div id='n_file'> N File Name: core/model/layers/target_prediction.py</div><div id='m_start'> M Start Line: 92</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 93</div><div id='n_end'> N End Line: 112</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        src = self.token_embeddings(src_ids)  &#47&#47 (N, L) -&gt; (N, L, H)
        tgt = self.token_embeddings(tgt_ids)  &#47&#47 (N, L) -&gt; (N, L, H)
        hidden<a id="change"> = </a><a id="change">self.enc_dec.forward(</a>src, tgt, src_key_padding_mask, tgt_key_padding_mask<a id="change">)</a>
        return hidden

    def step(self, X: torch.Tensor, y: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:
        src_ids, src_key_padding_mask = X[:, 0, 0], X[:, 0, 1]</code></pre><h3>After Change</h3><pre><code class='java'>
        :return (N, L, H)
        
        N, L = src_ids.size()  &#47&#47 (N, L)
        pos_encodings<a id="change"> = </a><a id="change">self.pos_encodings.unsqueeze(0</a><a id="change">)</a>.expand(N, L, -1)  &#47&#47 (L, H) -&gt; (1, L, H) -&gt; (N, L, H)
        &#47&#47 --- lookup embedding vectors --- &#47&#47
        src = self.token_embeddings(src_ids)  &#47&#47 (N, L) -&gt; (N, L, H)
        tgt = self.token_embeddings(tgt_ids)  &#47&#47 (N, L) -&gt; (N, L, H)
        &#47&#47 --- encode positions --- &#47&#47
        src = src + pos_encodings  &#47&#47 (N, L, H) + (N, L, H) -&gt; (N, L, H)
        tgt<a id="change"> = </a>tgt + pos_encodings  &#47&#47 (N, L, H) + (N, L, H) -&gt; (N, L, H)
        &#47&#47 --- encode & decode --- &#47&#47
        memory = self.encoder.forward(src, src_key_padding_mask)  &#47&#47 ... -&gt; (N, L, H)
        hidden = self.decoder.forward(tgt, memory, tgt_key_padding_mask, src_key_padding_mask)  &#47&#47 ... (N, L, H)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/eubinecto/dekorde/commit/64becc1447ef5fab1e9f640b0f96594fc766d72b#diff-a59f34bb8045c685da25633b05da921e6e29d72553f0e1867a8284ab6a5ec3adL59' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 30034778</div><div id='project'> Project Name: eubinecto/dekorde</div><div id='commit'> Commit Name: 64becc1447ef5fab1e9f640b0f96594fc766d72b</div><div id='time'> Time: 2021-12-12</div><div id='author'> Author: eubinecto</div><div id='file'> File Name: enkorde/models.py</div><div id='m_class'> M Class Name: Transformer</div><div id='n_method'> N Class Name: Transformer</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: LightningModule</div><div id='n_parent_class'> N Parent Class: LightningModule</div><div id='m_file'> M File Name: enkorde/models.py</div><div id='n_file'> N File Name: enkorde/models.py</div><div id='m_start'> M Start Line: 68</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 42</div><div id='n_end'> N End Line: 52</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            c = torch.tensor(c, dtype=torch.float).to(next(self.parameters()).device)
        if normalize_before:
            c = (c - self.mean) / self.scale
        c<a id="change"> = </a><a id="change">self.forward(</a>c.transpose(1, 0).unsqueeze(0)<a id="change">)</a>
        return c.squeeze(0).transpose(1, 0)
</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, c, normalize_before=False):
        if normalize_before:
            c = (c - self.mean) / self.scale
        c<a id="change"> = </a>self.input_conv(<a id="change">c.unsqueeze(0</a><a id="change">)</a>)
        for i in range(self.num_upsamples):
            c = self.upsamples[i](c)
            cs = 0.0  &#47&#47 initialize
            for j in range(self.num_blocks):
                cs += self.blocks[i * self.num_blocks + j](c)
            c = cs / self.num_blocks
        c<a id="change"> = </a>self.output_conv(c)
        return c.squeeze(0).squeeze(0)

    def remove_weight_norm(self):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/c309bced25efcaf67b20f1b1897d0ad43edd7ecd#diff-e0d99876122344a37a71a0648cfdd3db0736656eea8119811049b1305c6dd581L64' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 30034794</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: c309bced25efcaf67b20f1b1897d0ad43edd7ecd</div><div id='time'> Time: 2021-08-10</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/InferenceArchitectures/InferenceHiFiGAN.py</div><div id='m_class'> M Class Name: HiFiGANGenerator</div><div id='n_method'> N Class Name: HiFiGANGenerator</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/InferenceArchitectures/InferenceHiFiGAN.py</div><div id='n_file'> N File Name: InferenceInterfaces/InferenceArchitectures/InferenceHiFiGAN.py</div><div id='m_start'> M Start Line: 65</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 66</div><div id='n_end'> N End Line: 74</div><BR>