<html><h3>Pattern ID :15355
</h3><img src='52075242.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        m = re.match(&quothmp[s]?([0-9]+)$&quot, head_name)  &#47&#47 $ the end of string match
        if m is not None:
            n_keypoints = int(m.group(1))
            <a id="change">LOG.debug(&quotusing %d keypoints&quot</a>, n_keypoints<a id="change">)</a>
            LOG.info(&quotnot supported yet&quot)

        else:
            n_keypoints = 17
            <a id="change">LOG.info(&quotdefault COCO 17 keypoints are supported for now&quot</a><a id="change">)</a>

        LOG.info(&quotselected encoder heatmap for %s with %d keypoints&quot, head_name, n_keypoints)
        return HeatMaps(square_length, stride)
</code></pre><h3>After Change</h3><pre><code class='java'>
        if m is not None:
            n_keypoints = int(m.group(1))  &#47&#47 group eg: hmps17, hmps, 17
            LOG.info(&quotusing %d keypoints to generate heatmaps&quot, n_keypoints)
            <a id="change">assert </a>n_keypoints == 17, f&quot{n_keypoints} keypoints not supported&quot

        else:
            n_keypoints = 17</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/hellojialee/offsetguided/commit/26e1af5df4d3f60a3d305693aa261ab30bad3aeb#diff-2b619520273fef1504be9db0372f3598eb3f6f82aff83470914cc0db3ade9fedL71' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 52075242</div><div id='project'> Project Name: hellojialee/offsetguided</div><div id='commit'> Commit Name: 26e1af5df4d3f60a3d305693aa261ab30bad3aeb</div><div id='time'> Time: 2020-06-20</div><div id='author'> Author: ustclijia@gmail.com</div><div id='file'> File Name: encoder/factory.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: factory_head(3)</div><div id='n_method'> N Method Name: factory_head(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: encoder/factory.py</div><div id='n_file'> N File Name: encoder/factory.py</div><div id='m_start'> M Start Line: 71</div><div id='m_end'> M End Line: 77</div><div id='n_start'> N Start Line: 74</div><div id='n_end'> N End Line: 82</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                logger.dump(step=batches_trained)
                batches_trained += 1
                if (training_batches is not None and batches_trained &gt;= training_batches):
                    <a id="change">logging.info(f"Breaking out of training in epoch {epochs_trained} because max batches "
                                 f"value of {training_batches} has been reached"</a><a id="change">)</a>
                    training_complete = True
                    break

            assert batches_trained &gt; 0, \
                "went through training loop with no batches---empty dataset?"
            if epochs_trained == 0:
                &#47&#47 we infer the size of the dataset from the number of
                &#47&#47 iterations through the loop the first time
                <a id="change">logging.debug(f"Dataset size is {batches_trained}"</a><a id="change">)</a>

            if self.scheduler is not None:
                self.scheduler.step()
            loss_record.append(loss_meter.avg)</code></pre><h3>After Change</h3><pre><code class='java'>
                sub_ds.shuffle(self.shuffle_buffer_size)

        if not self.shuffle_batches:
            <a id="change">assert </a>len(datasets) &lt;= 1, \
                "InterleavedDataset will intrinsically shuffle batches; do " \
                "not use multi-task training if shuffle_batches=False is " \
                f"required (got {len(datasets)} datasets)"</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/ccdc28141c799043c5385b20f1201bc6971e462b#diff-da75b71a2421881ac87f16bdedbc66a6eee21a60650cb052fb123cfe1436b72fL215' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 52075243</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: ccdc28141c799043c5385b20f1201bc6971e462b</div><div id='time'> Time: 2020-11-19</div><div id='author'> Author: sam@qxcv.net</div><div id='file'> File Name: src/il_representations/algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: learn(4)</div><div id='n_method'> N Method Name: learn(4)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: src/il_representations/algos/representation_learner.py</div><div id='n_file'> N File Name: src/il_representations/algos/representation_learner.py</div><div id='m_start'> M Start Line: 220</div><div id='m_end'> M End Line: 354</div><div id='n_start'> N Start Line: 220</div><div id='n_end'> N End Line: 343</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        batches_trained = 0
        epochs_trained = 0
        training_complete = False
        <a id="change">logging.debug(f"Training with {training_epochs} epochs and {training_batches} batches"</a><a id="change">)</a>
        logging.debug(f"Batch size is {self.batch_size}")

        while not training_complete:
            loss_meter = AverageMeter()
            &#47&#47 Set encoder and decoder to be in training mode

            for step, batch in enumerate(dataloader):
                &#47&#47 Construct batch (currently just using Torch&quots default batch-creator)
                contexts, targets, traj_ts_info, extra_context = self.unpack_batch(batch)

                &#47&#47 Use an algorithm-specific augmentation strategy to augment either
                &#47&#47 just context, or both context and targets
                contexts, targets = self._prep_tensors(contexts), self._prep_tensors(targets)
                extra_context = self._prep_tensors(extra_context)
                traj_ts_info = self._prep_tensors(traj_ts_info)
                &#47&#47 Note: preprocessing might be better to do on CPU if, in future, we can parallelize doing so
                contexts = self._preprocess(contexts)
                if self.preprocess_target:
                    targets = self._preprocess(targets)
                contexts, targets = self.augmenter(contexts, targets)
                extra_context = self._preprocess_extra_context(extra_context)


                &#47&#47 These will typically just use the forward() function for the encoder, but can optionally
                &#47&#47 use a specific encode_context and encode_target if one is implemented
                encoded_contexts = self.encoder.encode_context(contexts, traj_ts_info)
                encoded_targets = self.encoder.encode_target(targets, traj_ts_info)
                &#47&#47 Typically the identity function
                extra_context = self.encoder.encode_extra_context(extra_context, traj_ts_info)

                &#47&#47 Use an algorithm-specific decoder to "decode" the representations into a loss-compatible tensor
                &#47&#47 As with encode, these will typically just use forward()
                decoded_contexts = self.decoder.decode_context(encoded_contexts, traj_ts_info, extra_context)
                decoded_targets = self.decoder.decode_target(encoded_targets, traj_ts_info, extra_context)

                &#47&#47 Optionally add to the batch before loss. By default, this is an identity operation, but
                &#47&#47 can also implement momentum queue logic
                decoded_contexts, decoded_targets = self.batch_extender(decoded_contexts, decoded_targets)

                &#47&#47 Use an algorithm-specific loss function. Typically this only requires decoded_contexts and
                &#47&#47 decoded_targets, but VAE requires encoded_contexts, so we pass it in here

                loss = self.loss_calculator(decoded_contexts, decoded_targets, encoded_contexts)
                loss_item = loss.item()
                assert not np.isnan(loss_item), "Loss is not NAN"
                loss_meter.update(loss_item)

                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()
                del loss  &#47&#47 so we don&quott use again

                gradient_norm, weight_norm = self._calculate_norms()

                &#47&#47 FIXME(sam): don&quott plot this every batch, plot it every k
                &#47&#47 batches (will make log files much smaller & let us stream
                &#47&#47 them to head node on Ray cluster)
                loss_meter.update(loss_item)
                logger.record(&quotloss&quot, loss_item)
                logger.record(&quotgradient_norm&quot, gradient_norm.item())
                logger.record(&quotweight_norm&quot, weight_norm.item())
                logger.record(&quotepoch&quot, epochs_trained)
                logger.record(&quotwithin_epoch_step&quot, step)
                logger.record(&quotbatches_trained&quot, batches_trained)
                logger.dump(step=batches_trained)
                batches_trained += 1
                if (training_batches is not None and batches_trained &gt;= training_batches):
                    <a id="change">logging.info(f"Breaking out of training in epoch {epochs_trained} because max batches "
                                 f"value of {training_batches} has been reached"</a><a id="change">)</a>
                    training_complete = True
                    break

            assert batches_trained &gt; 0, \</code></pre><h3>After Change</h3><pre><code class='java'>
                torch.save(self.decoder, os.path.join(
                    self.decoder_checkpoints_path, f&quot{epoch_num}_epochs.ckpt&quot))

        <a id="change">assert </a>should_save_checkpoint, "did not save checkpoint on last epoch"

        return loss_record, most_recent_encoder_checkpoint_path
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/579e0a8ca8ba0c924b8c8f393d9445915448617d#diff-da75b71a2421881ac87f16bdedbc66a6eee21a60650cb052fb123cfe1436b72fL215' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 52075240</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: 579e0a8ca8ba0c924b8c8f393d9445915448617d</div><div id='time'> Time: 2020-11-19</div><div id='author'> Author: sam@qxcv.net</div><div id='file'> File Name: src/il_representations/algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: learn(4)</div><div id='n_method'> N Method Name: learn(4)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: src/il_representations/algos/representation_learner.py</div><div id='n_file'> N File Name: src/il_representations/algos/representation_learner.py</div><div id='m_start'> M Start Line: 220</div><div id='m_end'> M End Line: 354</div><div id='n_start'> N Start Line: 220</div><div id='n_end'> N End Line: 343</div><BR>