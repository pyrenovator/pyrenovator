<html><h3>Pattern ID :3014
</h3><img src='11668657.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        if i &gt;= 10: break

        frames = <a id="change">frames.to(</a>DEVICE<a id="change">)</a>  &#47&#47 [1, T, 3, h, w]
        frames_vis = postprocess_img(frames.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
        input = frames[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 3, h, w]

        pred_rgb = pred_rgb_model.pred_n(input, pred_length=VIDEO_PRED_LENGTH)  &#47&#47 [1, T, 3, h, w]
        pred_rgb_vis = postprocess_img(pred_rgb)  &#47&#47 [T, 3, h, w]

        pred_rgb = torch.cat([input, pred_rgb], dim=1)
        pred_rgb = torch.stack([seg_model(pred_rgb[:, i]) for i in range(pred_rgb.shape[1])], dim=1)
        pred_rgb = pred_rgb.argmax(dim=2).squeeze()  &#47&#47 [T, h, w]
        pred_then_colorized_vis = colorize_semseg(postprocess_mask(pred_rgb), num_classes=SYNPICK_CLASSES) &#47&#47 [T, 3, h, w]

        frames_seg = [seg_model(frames[:, i]).argmax(dim=1) for i in range(frames.shape[1])]
        frames_seg<a id="change"> = </a>torch.stack(frames_seg, dim=1)  &#47&#47 [1, 1, h, w]
        input_seg = frames_seg[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 1, h, w]

        pred_mask = pred_mask_model.pred_n(input_seg, pred_length=VIDEO_PRED_LENGTH)</code></pre><h3>After Change</h3><pre><code class='java'>
            pred_mask_vis = colorize_semseg(postprocess_mask(pred_mask), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2)  &#47&#47 [T, 3, h, w]

            frames_colorized = colorize_semseg(postprocess_mask(frames_seg.squeeze()), num_classes=SYNPICK_CLASSES)
            frames_colorized_vis<a id="change"> = </a><a id="change">frames_colorized.transpose(0</a>, <a id="change">3</a>, 1, 2<a id="change">)</a>  &#47&#47 [T, 3, h, w]

            input_colorized = preprocess_img(frames_colorized[:VIDEO_IN_LENGTH]).to(DEVICE).unsqueeze(dim=0)  &#47&#47 [b, t, 3, h, w]
            colorized_then_pred = pred_colorized_mask_model.pred_n(input_colorized, pred_length=VIDEO_PRED_LENGTH)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ais-bonn/vp-suite/commit/13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3#diff-e07d70acfca9139cbf2c37b7a0074bdfbb966d41dc6c7edcc2cef05e78c00af0L16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11668657</div><div id='project'> Project Name: ais-bonn/vp-suite</div><div id='commit'> Commit Name: 13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3</div><div id='time'> Time: 2021-08-02</div><div id='author'> Author: boltres@ais.uni-bonn.de</div><div id='file'> File Name: scripts/visualize_4_way.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: visualize_4_way(1)</div><div id='n_method'> N Method Name: visualize_4_way(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/visualize_4_way.py</div><div id='n_file'> N File Name: scripts/visualize_4_way.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 73</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 74</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    with torch.no_grad():
        for i in tqdm(range(10)):

            frames = <a id="change">next(iter_loader).to(</a>DEVICE<a id="change">)</a>  &#47&#47 [1, T, 3, h, w]
            frames_vis = postprocess_img(frames.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
            input = frames[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 3, h, w]

            pred_rgb = pred_rgb_model.pred_n(input, pred_length=VIDEO_PRED_LENGTH)
            pred_rgb = torch.cat([input, pred_rgb], dim=1)  &#47&#47 [1, T, 3, h, w]
            pred_rgb_vis = postprocess_img(pred_rgb.squeeze(dim=0))  &#47&#47 [T, 3, h, w]

            pred_rgb = torch.stack([seg_model(pred_rgb[:, i]) for i in range(pred_rgb.shape[1])], dim=1)
            pred_rgb = pred_rgb.argmax(dim=2).squeeze()  &#47&#47 [T, h, w]
            pred_then_colorized_vis = colorize_semseg(postprocess_mask(pred_rgb), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2) &#47&#47 [T, 3, h, w]

            frames_seg = torch.stack([seg_model(frames[:, i]) for i in range(frames.shape[1])], dim=1).argmax(dim=2)  &#47&#47 [1, T, 1, h, w]
            frames_seg_in = torch.stack([(frames_seg == i) for i in range(SYNPICK_CLASSES)], dim=2).float()  &#47&#47 [1, T, c, h, w] one-hot float
            input_seg = frames_seg_in[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, c, h, w]
            pred_mask = pred_mask_model.pred_n(input_seg, pred_length=VIDEO_PRED_LENGTH).argmax(dim=2)  &#47&#47 [1, n, 1, h, w]
            pred_mask = torch.cat([input_seg.argmax(dim=2), pred_mask], dim=1).squeeze()  &#47&#47 [T, h, w]
            pred_mask_vis = colorize_semseg(postprocess_mask(pred_mask), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2)  &#47&#47 [T, 3, h, w]

            frames_colorized = colorize_semseg(postprocess_mask(frames_seg.squeeze()), num_classes=SYNPICK_CLASSES)
            frames_colorized_vis = frames_colorized.transpose(0, 3, 1, 2)  &#47&#47 [T, 3, h, w]

            input_colorized = preprocess_img(frames_colorized[:VIDEO_IN_LENGTH]).to(DEVICE).unsqueeze(dim=0)  &#47&#47 [b, t, 3, h, w]
            colorized_then_pred = pred_colorized_mask_model.pred_n(input_colorized, pred_length=VIDEO_PRED_LENGTH)
            colorized_then_pred = torch.cat([input_colorized, colorized_then_pred], dim=1).squeeze(dim=0)
            colorized_then_pred_vis<a id="change"> = </a>postprocess_img(colorized_then_pred)  &#47&#47 [T, 3, h, w]

            save_vid_vis(
                out_fp=os.path.join(cfg.out_dir, "4way_vis_{}.gif".format(str(i))),</code></pre><h3>After Change</h3><pre><code class='java'>
            seg_pred_color_vis = colorize_semseg(postprocess_mask(seg_then_pred), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2)  &#47&#47 [T, 3, h, w]

            seg_colorized = colorize_semseg(postprocess_mask(seg.squeeze()), num_classes=SYNPICK_CLASSES)
            seg_color_per_frame_vis<a id="change"> = </a><a id="change">seg_colorized.transpose(</a>0, 3, <a id="change">1</a>, <a id="change">2</a><a id="change">)</a>  &#47&#47 [T, 3, h, w]

            input_colorized = preprocess_img(seg_colorized[:VIDEO_IN_LENGTH]).to(DEVICE).unsqueeze(dim=0)  &#47&#47 [b, t, 3, h, w]
            seg_color_pred = pred_colorized_mask_model.pred_n(input_colorized, pred_length=VIDEO_PRED_LENGTH)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ais-bonn/vp-suite/commit/12f06dedbeb7683194c69214a6c984951ddd53a5#diff-e07d70acfca9139cbf2c37b7a0074bdfbb966d41dc6c7edcc2cef05e78c00af0L14' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11667977</div><div id='project'> Project Name: ais-bonn/vp-suite</div><div id='commit'> Commit Name: 12f06dedbeb7683194c69214a6c984951ddd53a5</div><div id='time'> Time: 2021-08-02</div><div id='author'> Author: boltres@ais.uni-bonn.de</div><div id='file'> File Name: scripts/visualize_4_way.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: visualize_4_way(1)</div><div id='n_method'> N Method Name: visualize_4_way(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/visualize_4_way.py</div><div id='n_file'> N File Name: scripts/visualize_4_way.py</div><div id='m_start'> M Start Line: 28</div><div id='m_end'> M End Line: 62</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 76</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if self._use_dB_normalization:
            audio_segment.normalize(target_db=self._target_dB)
        &#47&#47 获取音频特征
        samples<a id="change"> = </a><a id="change">audio_segment.to(</a>&quotint16&quot<a id="change">)</a>
        waveform = torch.from_numpy(np.expand_dims(samples, 0)).float()
        if self._feature_method == &quotspectrogram&quot:
            &#47&#47 计算声谱图
            feature = spectrogram(waveform=waveform,</code></pre><h3>After Change</h3><pre><code class='java'>
            audio_segment.normalize(target_db=self._target_dB)
        &#47&#47 获取音频特征
        waveform = torch.from_numpy(np.expand_dims(audio_segment.samples, 0)).float()
        feature<a id="change"> = </a><a id="change">self.feat_fun(waveform).squeeze(0).transpose(1</a>, <a id="change">0</a><a id="change">)</a>.numpy()
        &#47&#47 归一化
        mean = np.mean(feature, 1, keepdims=True)
        std = np.std(feature, 1, keepdims=True)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yeyupiaoling/audioclassification-pytorch/commit/f9a39f29e647cb3c02b8bb832a8d66c8655e4b1e#diff-16d41d5a471aa7cc4fe1b2a36c807558d42d547e1de4cd47ce61937322983e62L33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11668383</div><div id='project'> Project Name: yeyupiaoling/audioclassification-pytorch</div><div id='commit'> Commit Name: f9a39f29e647cb3c02b8bb832a8d66c8655e4b1e</div><div id='time'> Time: 2022-12-06</div><div id='author'> Author: yeyupiaoling@foxmail.com</div><div id='file'> File Name: macls/data_utils/featurizer/audio_featurizer.py</div><div id='m_class'> M Class Name: AudioFeaturizer</div><div id='n_method'> N Class Name: AudioFeaturizer</div><div id='m_method'> M Method Name: featurize(2)</div><div id='n_method'> N Method Name: featurize(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: macls/data_utils/featurizer/audio_featurizer.py</div><div id='n_file'> N File Name: macls/data_utils/featurizer/audio_featurizer.py</div><div id='m_start'> M Start Line: 48</div><div id='m_end'> M End Line: 66</div><div id='n_start'> N Start Line: 57</div><div id='n_end'> N End Line: 58</div><BR>