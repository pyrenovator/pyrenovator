<html><h3>Pattern ID :1610
</h3><img src='7441825.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    if config[&quotmask_type&quot] == &quothole&quot:
        result = x * (1. - mask)
    elif <a id="change"></a>config[&quotmask_type&quot] == &quotmosaic&quot:
        &#47&#47 TODO: Matching the mosaic patch size and the mask size
        mosaic_unit_size = config[&quotmosaic_unit_size&quot]
        downsampled_image = F.interpolate(x, scale_factor=1. / mosaic_unit_size, mode=&quotnearest&quot)
        upsampled_image = F.interpolate(downsampled_image, size=(height, width), mode=&quotnearest&quot)
        result = upsampled_image * mask + x * (1. - mask)
    else:
        <a id="change">raise NotImplementedError(&quotNot implemented mask type.&quot</a><a id="change">)</a>

    return result, mask</code></pre><h3>After Change</h3><pre><code class='java'>
    height, width, _ = config[&quotimage_shape&quot]
    max_mask = x.shape[0]
    result = torch.ones_like(x)
    mask = <a id="change">torch.ones(size=[x.shape[0], 1, x.shape[2], x.shape[3]])</a>
    for i in range(max_mask):
        mask_temp = random_mask(height=height, width=width)
        mask_temp = torch.tensor(mask_temp, dtype=torch.float32)
        if x.is_cuda:
            mask_temp.cuda()
        result[i, :, :, :] = x[i, :, :, :] * (1. - mask_temp)
        mask[i, :, :, :]<a id="change"> = </a>mask[i, :, :, :] * mask_temp
    return result, mask
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/sayednadim/global-and-local-attention-based-free-form-image-inpainting/commit/76ff7604018fa398ac445982097becbe3fc20e3a#diff-4a9d05cc3eadd7aa0b347854fe63c55a626198aae56f6d3482457196186e5d60L49' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7441825</div><div id='project'> Project Name: sayednadim/global-and-local-attention-based-free-form-image-inpainting</div><div id='commit'> Commit Name: 76ff7604018fa398ac445982097becbe3fc20e3a</div><div id='time'> Time: 2020-08-16</div><div id='author'> Author: smnadimuddin@gmail.com</div><div id='file'> File Name: model/mask.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mask_image(2)</div><div id='n_method'> N Method Name: mask_image(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model/mask.py</div><div id='n_file'> N File Name: model/mask.py</div><div id='m_start'> M Start Line: 56</div><div id='m_end'> M End Line: 72</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if dtype is None:
        dtype = torch.get_default_dtype()

    <a id="change">if </a>dtype in {torch.complex64, torch.complex128}:
        <a id="change">raise NotImplementedError("Complex hypervectors are not supported yet."</a><a id="change">)</a>

    if dtype == torch.uint8:
        raise ValueError("Unsigned integer hypervectors are not supported.")
</code></pre><h3>After Change</h3><pre><code class='java'>
            num_embeddings, embedding_dim, dtype=dtype, device=device
        )
        angle.uniform_(-math.pi, math.pi)
        magnitude<a id="change"> = </a><a id="change">torch.ones(
            </a>num_embeddings, embedding_dim<a id="change">, dtype=dtype, device=device
        )</a>

        result = torch.polar(magnitude, angle)
        result.requires_grad = requires_grad
        return result</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hyperdimensional-computing/torchhd/commit/1f7e9dbf92a4a1be0d4285b6ccd7231afa85c2a3#diff-2eec1c18711dc8b77e517b45771208f50de1693b062b658d75343e8e081d67cdL91' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7441827</div><div id='project'> Project Name: hyperdimensional-computing/torchhd</div><div id='commit'> Commit Name: 1f7e9dbf92a4a1be0d4285b6ccd7231afa85c2a3</div><div id='time'> Time: 2022-06-07</div><div id='author'> Author: mikeheddes@gmail.com</div><div id='file'> File Name: torchhd/functional.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: random_hv(0)</div><div id='n_method'> N Method Name: random_hv(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchhd/functional.py</div><div id='n_file'> N File Name: torchhd/functional.py</div><div id='m_start'> M Start Line: 132</div><div id='m_end'> M End Line: 135</div><div id='n_start'> N Start Line: 178</div><div id='n_end'> N End Line: 193</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        :return: attention result of shape (B, N, F) where B is the batch size, N the query sequence length
            and F the number of output channels (= `num_output_channels`)
        
        <a id="change">if </a>attn_mask is not None:
            <a id="change">raise NotImplementedError("attention masks not supported yet"</a><a id="change">)</a>

        q = self.q_proj(x_q)
        k = self.k_proj(x_kv)
        v = self.v_proj(x_kv)</code></pre><h3>After Change</h3><pre><code class='java'>
            i = q.shape[2]
            j = k.shape[2]

            causal_mask<a id="change"> = </a><a id="change">torch.ones(</a>(i, j)<a id="change">, device=x_q.device, dtype=torch.bool)</a>.triu(j - i + 1)
            attn.masked_fill_(causal_mask, attn_max_neg)

        attn = attn.softmax(dim=-1)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/krasserm/perceiver-io/commit/c2b9af32775fd28f693dd1b572142935efd31b99#diff-866d7079788f8c2d5430c75794ec5cca33c737ad6524b8b4f98feb4650471239L64' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7441832</div><div id='project'> Project Name: krasserm/perceiver-io</div><div id='commit'> Commit Name: c2b9af32775fd28f693dd1b572142935efd31b99</div><div id='time'> Time: 2022-09-25</div><div id='author'> Author: krasserm@googlemail.com</div><div id='file'> File Name: perceiver/model/core/modules.py</div><div id='m_class'> M Class Name: MultiHeadAttention</div><div id='n_method'> N Class Name: MultiHeadAttention</div><div id='m_method'> M Method Name: forward(6)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: perceiver/model/core/modules.py</div><div id='n_file'> N File Name: perceiver/model/core/modules.py</div><div id='m_start'> M Start Line: 64</div><div id='m_end'> M End Line: 93</div><div id='n_start'> N Start Line: 75</div><div id='n_end'> N End Line: 120</div><BR>