<html><h3>Pattern ID :40013
</h3><img src='113802312.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def forward(self, pred, target):
        log_prob = F.log_softmax(pred, dim=-1)
        dist = torch.empty_like(pred).fill_(self.smoothing / (<a id="change">pred.size(-1</a><a id="change">) - </a>1))
        dist.scatter_(dim=-1, index=target[..., None], value=(1 - self.smoothing))
        loss = F.kl_div(log_prob, dist)
        return loss</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, pred: torch.Tensor, target: torch.Tensor, mask: torch.Tensor):
        pred = pred.flatten(0, 1)
        target = target.flatten(0, 1)
        mask<a id="change"> = </a><a id="change">mask.flatten(0, 1).float()</a>
        chunked_pred = torch.chunk(pred, chunks=self.chunk, dim=0)
        chunked_target = torch.chunk(target, chunks=self.chunk, dim=0)
        chunked_mask = torch.chunk(mask, chunks=self.chunk, dim=0)
        log_prob = [F.log_softmax(p, dim=-1) for p in chunked_pred]
        loss<a id="change"> = </a>[self.smoothed_loss(p, t, m)[None]\
            for p, t, m in zip(log_prob, chunked_target, chunked_mask)]
        loss = torch.cat(loss, dim=0).sum()
        return loss / mask.sum()</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/rick-mccoy/reformer-pytorch/commit/3411114d22e0bfcae2e106f5c82a3211da83f409#diff-fe652c109b5da8ce3b578ba9b2009d72fccfc98ec85a96850e18c5af2f882069L11' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113802312</div><div id='project'> Project Name: rick-mccoy/reformer-pytorch</div><div id='commit'> Commit Name: 3411114d22e0bfcae2e106f5c82a3211da83f409</div><div id='time'> Time: 2020-02-29</div><div id='author'> Author: rickmccoy3141@gmail.com</div><div id='file'> File Name: model/labelsmoothing.py</div><div id='m_class'> M Class Name: LabelSmoothing</div><div id='n_method'> N Class Name: LabelSmoothing</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/labelsmoothing.py</div><div id='n_file'> N File Name: model/labelsmoothing.py</div><div id='m_start'> M Start Line: 11</div><div id='m_end'> M End Line: 16</div><div id='n_start'> N Start Line: 13</div><div id='n_end'> N End Line: 24</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 Calculate the exact sampling point
    if kernel == &quotnearest&quot:
        idx = pos_discrete[0] + <a id="change">x.size(-1</a><a id="change">) * </a>pos_discrete[1]
    else:
        idx = pos_discrete[0] + (x.size(-1) + 1) * pos_discrete[1]
</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 The target coordinates do not require gradients
    pos = torch.arange(sizes[0] * sizes[1], **dkwargs)
    pos_i = (pos // sizes[1]).float()
    pos_j<a id="change"> = </a><a id="change">(pos % sizes[1]).float()</a>
    &#47&#47 Map the target coordinates to the source coordinates
    &#47&#47 This implements the backward warping
    pos_tar = torch.stack([pos_j, pos_i, torch.ones_like(pos_i)], dim=0)
    pos_src = torch.matmul(m.inverse(), pos_tar)
    pos_src = pos_src[:2] / pos_src[-1, :]
    &#47&#47 Out of the image
    pos_bound = pos_src.new_tensor([x.size(-1), x.size(-2)]) - 0.5
    pos_bound.unsqueeze_(-1)
    pos_in = torch.logical_and(pos_src.ge(-0.5), pos_src.lt(pos_bound))
    pos_in = pos_in.all(0)
    &#47&#47 Remove the outside region and compensate subpixel shift
    sub = (k % 2) / 2
    pos_src = pos_src[..., pos_in]
    pos_src_sub = pos_src - sub
    pos_discrete<a id="change"> = </a>pos_src_sub.ceil().long()
    pos_frac = pos_src_sub - pos_src.floor()
    pos_frac.unsqueeze_(1)
    &#47&#47 (2, 1, HW)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thstkdgus35/bicubic_pytorch/commit/eb261bd72c7d717dab243fa09c6be01c8cdce6cb#diff-b450ef659f3c8d1a1deba7ce15262780c34c49f50a06e98c32aaafb14564c273L34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113802379</div><div id='project'> Project Name: thstkdgus35/bicubic_pytorch</div><div id='commit'> Commit Name: eb261bd72c7d717dab243fa09c6be01c8cdce6cb</div><div id='time'> Time: 2020-07-26</div><div id='author'> Author: sonsang35@gmail.com</div><div id='file'> File Name: core_warp.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: warp_by_size(6)</div><div id='n_method'> N Method Name: warp_by_size(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: core_warp.py</div><div id='n_file'> N File Name: core_warp.py</div><div id='m_start'> M Start Line: 38</div><div id='m_end'> M End Line: 104</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 92</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        out_masks = make_non_pad_mask(olens).unsqueeze(-1).to(ys.device)
        out_masks = torch.nn.functional.pad(out_masks.transpose(1, 2), [0, ys.size(1) - out_masks.size(1), 0, 0, 0, 0], value=False).transpose(1, 2)
        out_weights = out_masks.float() / out_masks.sum(dim=1, keepdim=True).float()
        out_weights /= ys.size(0)<a id="change"> * </a><a id="change">ys.size(2</a><a id="change">)</a>

        &#47&#47 apply weight
        l1_loss = l1_loss.mul(out_weights).masked_select(out_masks).sum()
</code></pre><h3>After Change</h3><pre><code class='java'>
        out_weights = out_masks.float() / out_masks.sum(dim=1, keepdim=True).float()
        out_weights /= gold_spectrograms.size(0) * gold_spectrograms.size(2)
        duration_masks = make_non_pad_mask(text_lengths).to(gold_spectrograms.device)
        duration_weights<a id="change"> = </a>(duration_masks.float() / <a id="change">duration_masks.sum(dim=1, keepdim=True).float()</a>)

        &#47&#47 apply weight
        l1_loss = l1_loss.mul(out_weights).masked_select(out_masks).sum()
        duration_loss<a id="change"> = </a>(duration_loss.mul(duration_weights).masked_select(duration_masks).sum())

        return l1_loss, duration_loss
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/b8532b46fafdc2f07c5ce57d6b7711db0682be18#diff-d7f9aee10ac5450baf13668ce069a9ea393323a61e8217b09a70a6ecc1e72757L17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113802316</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: b8532b46fafdc2f07c5ce57d6b7711db0682be18</div><div id='time'> Time: 2023-03-09</div><div id='author'> Author: lux.florian@gmail.com</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/ToucanTTS/ToucanTTSLoss.py</div><div id='m_class'> M Class Name: ToucanTTSLoss</div><div id='n_method'> N Class Name: ToucanTTSLoss</div><div id='m_method'> M Method Name: forward(8)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/ToucanTTS/ToucanTTSLoss.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/ToucanTTS/ToucanTTSLoss.py</div><div id='m_start'> M Start Line: 35</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 19</div><div id='n_end'> N End Line: 53</div><BR>