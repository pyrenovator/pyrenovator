<html><h3>Pattern ID :1322
</h3><img src='6412193.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        init.kaiming_uniform_(instance_weight, a=math.sqrt(5))
        with torch.no_grad():
            self.weight.data[:] = instance_weight
        <a id="change">if </a>self.bias is not None:
            bound = 1 / math.sqrt(self.in_channels)
            instance_bias = torch.Tensor(self.out_channels)
            instance_bias<a id="change"> = </a>instance_bias.uniform_(-bound, bound)
            with torch.no_grad():
                self.bias.data[:]<a id="change"> = </a>instance_bias

    @torch.no_grad()
    def initialize_module(self, module, input):</code></pre><h3>After Change</h3><pre><code class='java'>
    def reset_parameters(self) -&gt; None:
        bound = 1 / math.sqrt(self.in_channels)
        init.uniform_(self.weight.data, -bound, bound)
        <a id="change">if </a>self.bias is not None:
            <a id="change">init.uniform_(</a>self.bias.data, <a id="change">-bound</a>, bound<a id="change">)</a>

    @torch.no_grad()
    def initialize_module(self, module, input):
        pattern = [chr(s + 97) for s in range(input[0].ndim)]  &#47&#47 &quota&quot, &quotb&quot, ...</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/torchspatiotemporal/tsl/commit/2528cb05523e84a384b1248d9ffb774773fd1eb6#diff-0707740074ec4ca1b880501c6b0a70d576ae473f6f666e7493ab3828ded35336L83' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6412193</div><div id='project'> Project Name: torchspatiotemporal/tsl</div><div id='commit'> Commit Name: 2528cb05523e84a384b1248d9ffb774773fd1eb6</div><div id='time'> Time: 2022-12-14</div><div id='author'> Author: ivan.marisca@hotmail.it</div><div id='file'> File Name: tsl/nn/base/parallel.py</div><div id='m_class'> M Class Name: ParallelLinear</div><div id='n_method'> N Class Name: ParallelLinear</div><div id='m_method'> M Method Name: reset_parameters(1)</div><div id='n_method'> N Method Name: reset_parameters(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: tsl/nn/base/parallel.py</div><div id='n_file'> N File Name: tsl/nn/base/parallel.py</div><div id='m_start'> M Start Line: 83</div><div id='m_end'> M End Line: 94</div><div id='n_start'> N Start Line: 83</div><div id='n_end'> N End Line: 88</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        with torch.no_grad():
            self.weight.data[:] = instance_weight.repeat(self.n_instances, 1, 1)

        <a id="change">if </a>self.bias is not None:
            instance_bias<a id="change"> = </a>torch.Tensor(1, self.out_channels)
            fan_in, _ = init._calculate_fan_in_and_fan_out(instance_weight)
            bound = 1 / math.sqrt(fan_in) if fan_in &gt; 0 else 0
            instance_bias.uniform_(-bound, bound)
            with torch.no_grad():
                self.bias.data[:]<a id="change"> = </a>instance_bias

    def forward(self, x):
        x = rearrange(x, &quotb t n f -&gt; b (n f) t&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
    def reset_parameters(self) -&gt; None:
        bound = 1 / math.sqrt(self.in_channels * self.kernel_size)
        init.uniform_(self.weight.data, -bound, bound)
        <a id="change">if </a>self.bias is not None:
            <a id="change">init.uniform_(</a>self.bias.data, <a id="change">-bound</a>, bound<a id="change">)</a>

    def forward(self, x):
        x = rearrange(x, &quotb t n f -&gt; b (n f) t&quot)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/torchspatiotemporal/tsl/commit/2528cb05523e84a384b1248d9ffb774773fd1eb6#diff-0707740074ec4ca1b880501c6b0a70d576ae473f6f666e7493ab3828ded35336L186' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6412194</div><div id='project'> Project Name: torchspatiotemporal/tsl</div><div id='commit'> Commit Name: 2528cb05523e84a384b1248d9ffb774773fd1eb6</div><div id='time'> Time: 2022-12-14</div><div id='author'> Author: ivan.marisca@hotmail.it</div><div id='file'> File Name: tsl/nn/base/parallel.py</div><div id='m_class'> M Class Name: ParallelConv1D</div><div id='n_method'> N Class Name: ParallelConv1D</div><div id='m_method'> M Method Name: reset_parameters(1)</div><div id='n_method'> N Method Name: reset_parameters(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: tsl/nn/base/parallel.py</div><div id='n_file'> N File Name: tsl/nn/base/parallel.py</div><div id='m_start'> M Start Line: 187</div><div id='m_end'> M End Line: 201</div><div id='n_start'> N Start Line: 183</div><div id='n_end'> N End Line: 188</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if dtype is None:
        dtype = torch.get_default_dtype()

    <a id="change">if </a>dtype in {torch.complex64, torch.complex128}:
        raise NotImplementedError("Complex hypervectors are not supported yet.")

    if dtype == torch.uint8:</code></pre><h3>After Change</h3><pre><code class='java'>
    if dtype == torch.uint8:
        raise ValueError("Unsigned integer hypervectors are not supported.")

    <a id="change">if </a>dtype in {torch.complex64, torch.complex128}:
        dtype = torch.float if dtype == torch.complex64 else torch.double

        angle = torch.empty(
            num_embeddings, embedding_dim, dtype=dtype, device=device
        )
        <a id="change">angle.uniform_(-math.pi</a>, math.pi<a id="change">)</a>
        magnitude<a id="change"> = </a>torch.ones(
            num_embeddings, embedding_dim, dtype=dtype, device=device
        )

        result<a id="change"> = </a>torch.polar(magnitude, angle)
        result.requires_grad = requires_grad
        return result
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hyperdimensional-computing/torchhd/commit/1f7e9dbf92a4a1be0d4285b6ccd7231afa85c2a3#diff-2eec1c18711dc8b77e517b45771208f50de1693b062b658d75343e8e081d67cdL91' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6412181</div><div id='project'> Project Name: hyperdimensional-computing/torchhd</div><div id='commit'> Commit Name: 1f7e9dbf92a4a1be0d4285b6ccd7231afa85c2a3</div><div id='time'> Time: 2022-06-07</div><div id='author'> Author: mikeheddes@gmail.com</div><div id='file'> File Name: torchhd/functional.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: random_hv(0)</div><div id='n_method'> N Method Name: random_hv(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchhd/functional.py</div><div id='n_file'> N File Name: torchhd/functional.py</div><div id='m_start'> M Start Line: 132</div><div id='m_end'> M End Line: 135</div><div id='n_start'> N Start Line: 178</div><div id='n_end'> N End Line: 193</div><BR>