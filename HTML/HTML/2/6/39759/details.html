<html><h3>Pattern ID :39759
</h3><img src='113219198.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 So we trace once and look at the graph, and get the indices of the nodes that lead into the original fx output
    &#47&#47 node. Then we use those indices to select from train_nodes returned by torchvision get_graph_node_names
    tracer = NodePathTracer(leaf_modules=list(_leaf_modules), autowrap_functions=list(_autowrap_functions))
    graph<a id="change"> = </a>tracer.trace(model)
    graph_nodes = list(reversed(graph.nodes))
    output_node_names = [n.name for n in <a id="change">graph_nodes[0]</a>._input_nodes.keys()]
    graph_node_names = [n.name for n in graph_nodes]
    output_node_indices = [-<a id="change">graph_node_names.index(</a>node_name<a id="change">)</a> for node_name in output_node_names]
    train_nodes, eval_nodes = get_graph_node_names(
        model, tracer_kwargs={&quotleaf_modules&quot: list(_leaf_modules), &quotautowrap_functions&quot: list(_autowrap_functions)})
    eval_return_nodes<a id="change"> = </a>[eval_nodes[ix] for ix in output_node_indices]

    fx_model = create_feature_extractor(
        model, train_return_nodes=[train_nodes[-1]], eval_return_nodes=eval_return_nodes,</code></pre><h3>After Change</h3><pre><code class='java'>
        outputs = torch.cat(outputs)

    model = _create_fx_model(model)
    fx_outputs = tuple(<a id="change">model(</a>inputs<a id="change">)</a>.values())
    if isinstance(fx_outputs, tuple):
        fx_outputs = torch.cat(fx_outputs)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/feng-lab/pytorch-image-models/commit/9b3519545d6bf901047dccd24832793c95919cd4#diff-0adb667cd397bd56edce10eec11e1b10821740a10d72bd148b09645fc9108968L320' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113219198</div><div id='project'> Project Name: feng-lab/pytorch-image-models</div><div id='commit'> Commit Name: 9b3519545d6bf901047dccd24832793c95919cd4</div><div id='time'> Time: 2021-11-19</div><div id='author'> Author: rwightman@gmail.com</div><div id='file'> File Name: tests/test_models.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_model_forward_fx(2)</div><div id='n_method'> N Method Name: test_model_forward_fx(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/test_models.py</div><div id='n_file'> N File Name: tests/test_models.py</div><div id='m_start'> M Start Line: 320</div><div id='m_end'> M End Line: 348</div><div id='n_start'> N Start Line: 348</div><div id='n_end'> N End Line: 360</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            model.to(device)
            target_img_tensor.to(device)
            model.eval()
            out<a id="change"> = </a>model(target_img_tensor)
            &#47&#47 ps = torch.exp(out)
            ps = out
            prediction_percentages = <a id="change">(ps.cpu().numpy()[0])</a>.tolist()
            pred<a id="change"> = </a><a id="change">prediction_percentages.index(</a>max(prediction_percentages)<a id="change">)</a>
            pred_labels.append(pred)
    show_roc(true_labels, pred_labels, auc=auc, figure_size=figure_size)

def plot_confusion_matrix(cm,</code></pre><h3>After Change</h3><pre><code class='java'>

        with torch.no_grad():
            model.eval()
            out = <a id="change">model(</a>imgs<a id="change">)</a>
            &#47&#47 ps = torch.exp(out)
            ps = out
            print(ps.shape)
            print (ps)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/radtorch/radtorch/commit/74b5ef917af3aebdf033166bf8b81cbc9ceb9b6e#diff-ea0c5d78e98f3b87371717beabaf20a4c1a834cd943d71bad1e08f7fc9e04250L176' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113219197</div><div id='project'> Project Name: radtorch/radtorch</div><div id='commit'> Commit Name: 74b5ef917af3aebdf033166bf8b81cbc9ceb9b6e</div><div id='time'> Time: 2020-03-01</div><div id='author'> Author: elbanan@users.noreply.github.com</div><div id='file'> File Name: radtorch/visutils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: show_nn_roc(5)</div><div id='n_method'> N Method Name: show_nn_roc(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: radtorch/visutils.py</div><div id='n_file'> N File Name: radtorch/visutils.py</div><div id='m_start'> M Start Line: 199</div><div id='m_end'> M End Line: 216</div><div id='n_start'> N Start Line: 201</div><div id='n_end'> N End Line: 215</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 So we trace once and look at the graph, and get the indices of the nodes that lead into the original fx output
    &#47&#47 node. Then we use those indices to select from train_nodes returned by torchvision get_graph_node_names
    tracer = NodePathTracer(leaf_modules=list(_leaf_modules), autowrap_functions=list(_autowrap_functions))
    graph<a id="change"> = </a>tracer.trace(model)
    graph_nodes = list(reversed(graph.nodes))
    output_node_names = [n.name for n in <a id="change">graph_nodes[0]</a>._input_nodes.keys()]
    graph_node_names = [n.name for n in graph_nodes]
    output_node_indices = [-<a id="change">graph_node_names.index(</a>node_name<a id="change">)</a> for node_name in output_node_names]
    train_nodes, eval_nodes = get_graph_node_names(
        model, tracer_kwargs={&quotleaf_modules&quot: list(_leaf_modules), &quotautowrap_functions&quot: list(_autowrap_functions)})
    train_return_nodes<a id="change"> = </a>[train_nodes[ix] for ix in output_node_indices]
    
    model = create_feature_extractor(
        model, train_return_nodes=train_return_nodes, eval_return_nodes=[eval_nodes[-1]],</code></pre><h3>After Change</h3><pre><code class='java'>
    model.train()

    model = _create_fx_model(model, train=True)
    outputs = tuple(<a id="change">model(</a>torch.randn((batch_size, *input_size))<a id="change">)</a>.values())
    if isinstance(outputs, tuple):
        outputs = torch.cat(outputs)
    outputs.mean().backward()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/feng-lab/pytorch-image-models/commit/9b3519545d6bf901047dccd24832793c95919cd4#diff-0adb667cd397bd56edce10eec11e1b10821740a10d72bd148b09645fc9108968L360' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113219196</div><div id='project'> Project Name: feng-lab/pytorch-image-models</div><div id='commit'> Commit Name: 9b3519545d6bf901047dccd24832793c95919cd4</div><div id='time'> Time: 2021-11-19</div><div id='author'> Author: rwightman@gmail.com</div><div id='file'> File Name: tests/test_models.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_model_backward_fx(2)</div><div id='n_method'> N Method Name: test_model_backward_fx(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/test_models.py</div><div id='n_file'> N File Name: tests/test_models.py</div><div id='m_start'> M Start Line: 365</div><div id='m_end'> M End Line: 396</div><div id='n_start'> N Start Line: 378</div><div id='n_end'> N End Line: 386</div><BR>