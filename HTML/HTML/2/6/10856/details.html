<html><h3>Pattern ID :10856
</h3><img src='37410041.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        input_ids = ids_tensor([config.batch_size, config.seq_length], config.vocab_size)

        input_mask = None
        <a id="change">if self.config.use_input_mask</a>:
            input_mask<a id="change"> = </a><a id="change">random_attention_mask([</a>config.batch_size, config.seq_length<a id="change"></a>]<a id="change">)</a>

        token_type_ids = None
        if self.config.use_token_type_ids:
            token_type_ids = ids_tensor([config.batch_size, config.seq_length], config.type_vocab_size)</code></pre><h3>After Change</h3><pre><code class='java'>
        input_ids = ids_tensor([self.batch_size, self.seq_length], self.vocab_size)

        input_mask = None
        <a id="change">if </a>self.use_input_mask:
            input_mask = random_attention_mask([self.batch_size, self.seq_length])

        token_type_ids = None</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/8d63af54fdac61a222f6738d2af3402328e76d96#diff-dd9c7ad46b9b088af8d663076fc9a7eb994098d5778447fd2f52dbfff389a78fL96' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 37410041</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 8d63af54fdac61a222f6738d2af3402328e76d96</div><div id='time'> Time: 2023-03-28</div><div id='author'> Author: 709153940@qq.com</div><div id='file'> File Name: tests/transformers/tinybert/test_modeling.py</div><div id='m_class'> M Class Name: TinyBertModelTester</div><div id='n_method'> N Class Name: TinyBertModelTester</div><div id='m_method'> M Method Name: prepare_config_and_inputs(1)</div><div id='n_method'> N Method Name: prepare_config_and_inputs(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/transformers/tinybert/test_modeling.py</div><div id='n_file'> N File Name: tests/transformers/tinybert/test_modeling.py</div><div id='m_start'> M Start Line: 96</div><div id='m_end'> M End Line: 113</div><div id='n_start'> N Start Line: 193</div><div id='n_end'> N End Line: 208</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        input_ids = ids_tensor([config.batch_size, config.seq_length], config.vocab_size)

        input_mask = None
        <a id="change">if self.config.use_input_mask</a>:
            input_mask<a id="change"> = </a><a id="change">random_attention_mask([</a>config.batch_size, config.seq_length<a id="change"></a>]<a id="change">)</a>

        token_type_ids = None
        if self.config.use_token_type_ids:
            token_type_ids = ids_tensor([config.batch_size, config.seq_length], config.type_vocab_size)</code></pre><h3>After Change</h3><pre><code class='java'>
            input_mask = random_attention_mask([self.batch_size, self.seq_length])

        token_type_ids = None
        <a id="change">if </a>self.use_token_type_ids:
            token_type_ids = ids_tensor([self.batch_size, self.seq_length], self.type_vocab_size)

        sequence_labels = None</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/8a5841015fd3fa92fc426c3683cd39f50669088f#diff-9e8cf8bbb1fcb38d455165c30a6011f7c4913447c064655e1484624ec33ab079L91' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 37410034</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 8a5841015fd3fa92fc426c3683cd39f50669088f</div><div id='time'> Time: 2023-03-23</div><div id='author'> Author: 50394665+JunnYu@users.noreply.github.com</div><div id='file'> File Name: tests/transformers/roformer/test_modeling.py</div><div id='m_class'> M Class Name: RoFormerModelTester</div><div id='n_method'> N Class Name: RoFormerModelTester</div><div id='m_method'> M Method Name: prepare_config_and_inputs(1)</div><div id='n_method'> N Method Name: prepare_config_and_inputs(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/transformers/roformer/test_modeling.py</div><div id='n_file'> N File Name: tests/transformers/roformer/test_modeling.py</div><div id='m_start'> M Start Line: 92</div><div id='m_end'> M End Line: 117</div><div id='n_start'> N Start Line: 98</div><div id='n_end'> N End Line: 113</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        input_ids = ids_tensor([config.batch_size, config.seq_length], config.vocab_size)

        input_mask = None
        <a id="change">if config.use_input_mask</a>:
            input_mask<a id="change"> = </a><a id="change">random_attention_mask([</a>config.batch_size, config.seq_length<a id="change"></a>]<a id="change">)</a>

        token_type_ids = None
        if config.use_token_type_ids:
            token_type_ids = ids_tensor([config.batch_size, config.seq_length], config.type_vocab_size)</code></pre><h3>After Change</h3><pre><code class='java'>
            input_mask = random_attention_mask([self.batch_size, self.seq_length])

        token_type_ids = None
        <a id="change">if </a>self.use_token_type_ids:
            token_type_ids = ids_tensor([self.batch_size, self.seq_length], self.type_vocab_size)

        sequence_labels = None</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/428c21a246f93dea64a181d3825db9be8fc512aa#diff-5f0175d6ff5dde45b2ec40cd3b625e299672d3db05383cd0d7991efe43bf37f8L90' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 37410038</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 428c21a246f93dea64a181d3825db9be8fc512aa</div><div id='time'> Time: 2023-02-28</div><div id='author'> Author: 35913314+1649759610@users.noreply.github.com</div><div id='file'> File Name: tests/transformers/skep/test_modeling.py</div><div id='m_class'> M Class Name: SkepModelTester</div><div id='n_method'> N Class Name: SkepModelTester</div><div id='m_method'> M Method Name: prepare_config_and_inputs(1)</div><div id='n_method'> N Method Name: prepare_config_and_inputs(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/transformers/skep/test_modeling.py</div><div id='n_file'> N File Name: tests/transformers/skep/test_modeling.py</div><div id='m_start'> M Start Line: 91</div><div id='m_end'> M End Line: 102</div><div id='n_start'> N Start Line: 90</div><div id='n_end'> N End Line: 100</div><BR>