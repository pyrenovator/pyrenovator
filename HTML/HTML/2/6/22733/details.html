<html><h3>Pattern ID :22733
</h3><img src='72190668.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    dace_module = DaceModule(module, backward=True)

    dace_outputs = []
    <a id="change">for </a>inp, <a id="change">inp_src</a> in <a id="change">zip(</a>dace_inputs, input_values<a id="change">):
        </a>inp.copy_(inp_src)
        inp.requires_grad = True
        s<a id="change"> = </a>dace_module(inp).sum()
        s.backward()
        dace_outputs.append(inp.grad.clone().detach())
        print(dace_outputs[-1])</code></pre><h3>After Change</h3><pre><code class='java'>
        s = module(pytorch_input).sum()
    s.backward()

    <a id="change">print("Pytorch output:"</a><a id="change">)</a>
    print(pytorch_input.grad)

    dace_module = DaceModule(module, backward=True)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/spcl/daceml/commit/682aea4a22edc4a5268188596bcf443bd041a0a7#diff-6b594ac1652083c98f3550d2f555bfc8748a335580d09701a127b3502938fb38L10' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 72190668</div><div id='project'> Project Name: spcl/daceml</div><div id='commit'> Commit Name: 682aea4a22edc4a5268188596bcf443bd041a0a7</div><div id='time'> Time: 2021-03-01</div><div id='author'> Author: oliverrausch99@gmail.com</div><div id='file'> File Name: tests/autodiff/pytorch/test_pytorch.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: run_pytorch_module(3)</div><div id='n_method'> N Method Name: run_pytorch_module(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/autodiff/pytorch/test_pytorch.py</div><div id='n_file'> N File Name: tests/autodiff/pytorch/test_pytorch.py</div><div id='m_start'> M Start Line: 13</div><div id='m_end'> M End Line: 45</div><div id='n_start'> N Start Line: 10</div><div id='n_end'> N End Line: 44</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
def align_layer_names_multi_stage(target_names, tail_align_dict={}, full_name_align_dict={}, tail_split_position=2, specific_match_func=None):
    if isinstance(tail_split_position, int):
        tail_align_dict, full_name_align_dict, tail_split_position = [tail_align_dict], [full_name_align_dict], [tail_split_position]
    <a id="change">for </a>ii, jj, <a id="change">kk</a> in <a id="change">zip(</a>tail_align_dict, full_name_align_dict, tail_split_position<a id="change">):
        </a>target_names<a id="change"> = </a>match_layer_names_with_torch(target_names, ii, jj, kk)

    if specific_match_func is not None:
        target_names = specific_match_func(target_names)</code></pre><h3>After Change</h3><pre><code class='java'>
        cur_tail = tail_align_dict[idx] if idx &lt; len(tail_align_dict) else {}
        cur_full = full_name_align_dict[idx] if idx &lt; len(full_name_align_dict) else {}
        cur_split = tail_split_position[idx] if idx &lt; len(tail_split_position) else tail_split_position[-1]
        <a id="change">print("&gt;&gt;&gt;&gt; tail_align_dict:"</a>, cur_tail<a id="change">)</a>
        print("&gt;&gt;&gt;&gt; full_name_align_dict:", cur_full)
        print("&gt;&gt;&gt;&gt; tail_split_position:", cur_split)
        target_names = match_layer_names_with_torch(target_names, cur_tail, cur_full, cur_split)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/e6caa341b219ff7aabd1f12311014d1df5a70118#diff-37028f58f90dc39d0ed1f23dec40bd7e001ad2d587c2dd6ddd16655aaec34d38L132' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 72190664</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: e6caa341b219ff7aabd1f12311014d1df5a70118</div><div id='time'> Time: 2022-03-16</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/download_and_load.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: align_layer_names_multi_stage(5)</div><div id='n_method'> N Method Name: align_layer_names_multi_stage(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/download_and_load.py</div><div id='n_file'> N File Name: keras_cv_attention_models/download_and_load.py</div><div id='m_start'> M Start Line: 135</div><div id='m_end'> M End Line: 138</div><div id='n_start'> N Start Line: 135</div><div id='n_end'> N End Line: 146</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        with torch.no_grad():
            start = 0
            if self.iteration &gt; 0:
                <a id="change">for </a>P, <a id="change">V</a> in <a id="change">zip(</a>self.model.parameter_order, self.model.parameter_vector_len<a id="change">):
                    </a>start<a id="change"> += </a>V
            self.current_Y = self.model.full_sample(self.current_state + h).view(-1)
            if self.model.target.has_mask: &#47&#47 fixme something to do with the mask is a problem
                loss = torch.sum(((self.Y - self.current_Y)**2 if self.W is None else ((self.Y - self.current_Y)**2 * self.W))[torch.logical_not(self.mask)]) / self.ndf</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47         self.L = self.L_history[-6:][np.argmax(np.abs(self.rho_history[-6:]))] * np.exp(np.random.normal(loc = 0, scale = 1))
        h = self.update_h_v2()
        if self.verbose &gt; 1:
            <a id="change">print("h: "</a>, h.detach().cpu().numpy()<a id="change">)</a>
        
        with torch.no_grad():
            self.current_Y = self.model.full_sample(self.current_state + h).view(-1)
            if self.model.target.has_mask:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/connorstoneastro/autoprof/commit/e7f256bf984d720d18daababa4852f2f7a2f4ac1#diff-52615ad08cfc1cfad1befd14d3c383d34ae33d73e933e1359265221e8731fb61L75' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 72190667</div><div id='project'> Project Name: connorstoneastro/autoprof</div><div id='commit'> Commit Name: e7f256bf984d720d18daababa4852f2f7a2f4ac1</div><div id='time'> Time: 2022-12-13</div><div id='author'> Author: connorstone628@gmail.com</div><div id='file'> File Name: autoprof/fit/lm.py</div><div id='m_class'> M Class Name: LM</div><div id='n_method'> N Class Name: LM</div><div id='m_method'> M Method Name: step_method1(2)</div><div id='n_method'> N Method Name: step_method1(2)</div><div id='m_parent_class'> M Parent Class: BaseOptimizer</div><div id='n_parent_class'> N Parent Class: BaseOptimizer</div><div id='m_file'> M File Name: autoprof/fit/lm.py</div><div id='n_file'> N File Name: autoprof/fit/lm.py</div><div id='m_start'> M Start Line: 91</div><div id='m_end'> M End Line: 161</div><div id='n_start'> N Start Line: 89</div><div id='n_end'> N End Line: 162</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    print(pattern)

    input = []
    <a id="change">for </a>_target, <a id="change">_pattern</a> in <a id="change">zip(</a>target, pattern<a id="change">):
        </a>_input<a id="change"> = </a>_target[_pattern] + 1e-1 * torch.randn(C, T)
        input.append(_input.unsqueeze(dim=0))
    
    input = torch.cat(input, dim=0)</code></pre><h3>After Change</h3><pre><code class='java'>
    input = torch.randint(2, (batch_size, C, T), dtype=torch.float)
    target = torch.randint(2, (batch_size, C, T), dtype=torch.float)
    
    <a id="change">print(</a>&quot-&quot*10, <a id="change">"Negative SI-SDR (PIT)"</a>, &quot-&quot*10<a id="change">)</a>
    criterion = NegSISDR()
    pit_criterion = PIT(criterion, n_sources=C)
    loss, pattern = pit_criterion(input, target)
    </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tky823/dnn-based_source_separation/commit/a2c8fff0b948824663d007770528fa8eaecabcf6#diff-22aca1dcfba1cb607c12abfa769f86ec60cb0d8e7969b24efc450d5a0ffd0cf5L322' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 72190660</div><div id='project'> Project Name: tky823/dnn-based_source_separation</div><div id='commit'> Commit Name: a2c8fff0b948824663d007770528fa8eaecabcf6</div><div id='time'> Time: 2021-06-12</div><div id='author'> Author: 40362510+tky823@users.noreply.github.com</div><div id='file'> File Name: src/criterion/pit.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _test_sink_pit(0)</div><div id='n_method'> N Method Name: _test_sink_pit(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/criterion/pit.py</div><div id='n_file'> N File Name: src/criterion/pit.py</div><div id='m_start'> M Start Line: 327</div><div id='m_end'> M End Line: 340</div><div id='n_start'> N Start Line: 327</div><div id='n_end'> N End Line: 337</div><BR>