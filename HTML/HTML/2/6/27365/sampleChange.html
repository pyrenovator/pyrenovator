<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        model, task = model_w_task
        local_rank = int(os.getenv("LOCAL_RANK", "0"))

        <a id="change">if </a>"gpt-j-6B" in model and dtype == torch.half:
            _model<a id="change"> = </a>AutoModelForCausalLM.from_pretrained(model,
                                                          revision="float16",
                                                          torch_dtype=torch.float16)
            tokenizer<a id="change"> = </a>AutoTokenizer.from_pretrained(model)
            _model.half()
            pipe = pipeline(
                task,</code></pre><h3>After Change</h3><pre><code class='java'>
            pipe.model.half()

        &#47&#47 Switch device to GPU after converting to half
        device = <a id="change">torch.device(f"cuda:{local_rank}"</a><a id="change">)</a>
        pipe.device<a id="change"> = </a>device
        pipe.model.to(device)

        &#47&#47 Warm-up queries for perf measurement</code></pre>