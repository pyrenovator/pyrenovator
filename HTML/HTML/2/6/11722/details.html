<html><h3>Pattern ID :11722
</h3><img src='39545598.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                         penwidth=&quot2&quot),
        engine=&quotdot&quot
    )
    <a id="change">g.body.extend(</a>[&quotrandkdir=LR&quot]<a id="change">)</a>

    g.node(&quotc_{k-2}&quot, fillcolor=&quotdarkseagreen2&quot)
    g.node(&quotc_{k-1}&quot, fillcolor=&quotdarkseagreen2&quot)
    assert len(genotype) % 2 == 0</code></pre><h3>After Change</h3><pre><code class='java'>
            for _ in range(2):
                op, x_i = genotype[i]
                s.node(str(i), label=op, fillcolor=&quotghostwhite&quot)
                g.edge(<a id="change">xs[x_i]</a>, str(i))
                g.edge(str(i),&quotadd&quot+str(node))
                i += 1
        xs.append(&quotadd&quot+str(node))
        
    g.node(&quotconcat&quot, label=&quotC&quot, fillcolor=&quotpalegoldenrod&quot)
    for name in <a id="change">xs[-3:]</a>:
        g.edge(name, &quotconcat&quot)
    g.node(&quoty&quot, fillcolor=&quotcyan3&quot, shape=&quotplaintext&quot)
    g.edge(&quotconcat&quot,&quoty&quot)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/woodywff/nas_3d_unet/commit/a545a3bf9ef55ec3f9d7881f84079f44027753e6#diff-38a8c5358d8bcad31aafbfd0c7db8c8edeb23a4b2162eb9e835438d204a20913L31' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39545598</div><div id='project'> Project Name: woodywff/nas_3d_unet</div><div id='commit'> Commit Name: a545a3bf9ef55ec3f9d7881f84079f44027753e6</div><div id='time'> Time: 2020-04-07</div><div id='author'> Author: woodywff@aliyun.com</div><div id='file'> File Name: helper.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: visualize(4)</div><div id='n_method'> N Method Name: visualize(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: helper.py</div><div id='n_file'> N File Name: helper.py</div><div id='m_start'> M Start Line: 31</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 34</div><div id='n_end'> N End Line: 71</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 might be expensive though
        note_ons = [(n.start, n.pitch, n.velocity, program) for n in inst.notes]
        note_offs = [(n.end, n.pitch, 0, program) for n in inst.notes]
        <a id="change">inst_events.extend(</a>note_ons+note_offs<a id="change">)</a>
    if len(inst_events) &lt; 64:
        return
    time, pitch, vel, prog = zip(*sorted(inst_events))
    delta = torch.FloatTensor([0, *time]).diff(1)</code></pre><h3>After Change</h3><pre><code class='java'>
            nbp[n.pitch].append(n)
            
        &#47&#47 shorten all notes so they end 2*$margin before next (within pitch)
        for <a id="change">seq</a> in nbp.values():
            for i,n in enumerate(<a id="change">seq[:-1]</a>):
                max_end = <a id="change">seq[i+1]</a>.start-2*time_margin
                if n.end &gt; max_end:
                    n.end = max_end
                &#47&#47 and flatten again</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/intelligent-instruments-lab/iil-python-tools/commit/78c2ab9e98adc304bebc8cff2541364d27d91dab#diff-8af53289ffb9f0e2a971a5b93eff5e24e5fe8ee26ecbc05887330392031aa724L11' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39545597</div><div id='project'> Project Name: intelligent-instruments-lab/iil-python-tools</div><div id='commit'> Commit Name: 78c2ab9e98adc304bebc8cff2541364d27d91dab</div><div id='time'> Time: 2022-04-15</div><div id='author'> Author: victor.shepardson@gmail.com</div><div id='file'> File Name: notepredictor/scripts/lakh_prep_multitrack.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: process(1)</div><div id='n_method'> N Method Name: process(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: notepredictor/scripts/lakh_prep_multitrack.py</div><div id='n_file'> N File Name: notepredictor/scripts/lakh_prep_multitrack.py</div><div id='m_start'> M Start Line: 19</div><div id='m_end'> M End Line: 38</div><div id='n_start'> N Start Line: 22</div><div id='n_end'> N End Line: 50</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        else:
            pil_images = []
            for intermediate_img in intermediates:
                <a id="change">pil_images.extend(</a>list(map(T.ToPILImage(), intermediate_img.unbind(dim = 0)))<a id="change">)</a>
        
        return pil_images &#47&#47 now you have a bunch of pillow images you can just .save(/where/ever/you/want.png)

    def p_losses(self, unet, x_start, times, *, noise_scheduler, lowres_cond_img = None, lowres_aug_times = None, text_embeds = None, text_mask = None, noise = None, times_next = None):</code></pre><h3>After Change</h3><pre><code class='java'>
        assert not (not self.condition_on_text and exists(text_embeds)), &quotimagen specified not to be conditioned on text, yet it is presented&quot
        assert not (exists(text_embeds) and text_embeds.shape[-1] != self.text_embed_dim), f&quotinvalid text embedding dimension being passed in (should be {self.text_embed_dim})&quot

        <a id="change">outputs</a> = []

        is_cuda = next(self.parameters()).is_cuda
        device = next(self.parameters()).device

        lowres_sample_noise_level = default(lowres_sample_noise_level, self.lowres_sample_noise_level)

        for unet_number, unet, channel, image_size, noise_scheduler in tqdm(zip(range(1, len(self.unets) + 1), self.unets, self.sample_channels, self.image_sizes, self.noise_schedulers)):

            context = self.one_unet_in_gpu(unet = unet) if is_cuda else null_context()

            with context:
                lowres_cond_img = lowres_noise_times = None
                shape = (batch_size, channel, image_size, image_size)

                if unet.lowres_cond:
                    lowres_noise_times = noise_scheduler.get_times(batch_size, lowres_sample_noise_level, device = device)

                    lowres_cond_img = resize_image_to(img, image_size)
                    lowres_cond_img, _ = noise_scheduler.q_sample(x_start = lowres_cond_img, t = lowres_noise_times, noise = torch.randn_like(lowres_cond_img))

                shape = (batch_size, self.channels, image_size, image_size)

                img = self.p_sample_loop(
                    unet,
                    shape,
                    text_embeds = text_embeds,
                    text_mask = text_masks,
                    cond_scale = cond_scale,
                    lowres_cond_img = lowres_cond_img,
                    lowres_noise_times = lowres_noise_times,
                    noise_scheduler = noise_scheduler
                )

                outputs.append(img)

            if exists(stop_at_unet_number) and stop_at_unet_number == unet_number:
                break

        output_index = -1 if not return_all_unet_outputs else slice(None) &#47&#47 either return last unet output or all unet outputs

        if not return_pil_images:
            return <a id="change">outputs[output_index]</a>

        if not return_all_unet_outputs:
            outputs = <a id="change">outputs[-1:]</a>

        pil_images = list(map(lambda img: list(map(T.ToPILImage(), img.unbind(dim = 0))), outputs))

        return pil_images[output_index] &#47&#47 now you have a bunch of pillow images you can just .save(/where/ever/you/want.png)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/bfe761b52c93f53c1a961c0912bed3b33042382c#diff-edef3c5fe92797a22c0b8fc6cca1d57b4b84ef03dfdfe802ed9147e21fc88109L1432' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39545596</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: bfe761b52c93f53c1a961c0912bed3b33042382c</div><div id='time'> Time: 2022-06-11</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_class'> M Class Name: Imagen</div><div id='n_method'> N Class Name: Imagen</div><div id='m_method'> M Method Name: sample(11)</div><div id='n_method'> N Method Name: sample(11)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imagen_pytorch/imagen_pytorch.py</div><div id='n_file'> N File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_start'> M Start Line: 1443</div><div id='m_end'> M End Line: 1511</div><div id='n_start'> N Start Line: 1441</div><div id='n_end'> N End Line: 1507</div><BR>