<html><h3>Pattern ID :19533
</h3><img src='63575816.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def _run(self, epochs, train_dataset, eval_dataset, list_callback,
             cb_params, print_steps):
        Training process for non-data sinking mode.
        <a id="change">raise </a>NotImplementedError

    def _run_ds_sink(self, train_dataset, eval_dataset, list_callback,
                     cb_params, print_steps, eval_steps):</code></pre><h3>After Change</h3><pre><code class='java'>
        for epoch in range(0, self.epochs):
            self.cur_epoch_nums += 1
            self.cur_step_nums = 0
            <a id="change">with </a><a id="change">tqdm(total=total) as t:
                </a>t.set_description(&quotEpoch %i&quot % epoch)
                loss_total<a id="change"> = </a>0
                for data in self.train_dataset.create_tuple_iterator():
                    if mode == &quotpynative&quot:
                        loss = self._run_step(data)
                    elif <a id="change"></a>mode == &quotgraph&quot:
                        loss = ms_function(self._run_step)(data)
                    self.cur_step_nums<a id="change"> += </a>1
                    loss_total += loss
                    t.set_postfix(loss=loss_total/self.cur_step_nums)
                    t.update(1)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/mindlab-ai/mindnlp/commit/bd14f94512afa0075b31f2ccee1072676219ddcc#diff-3c1ce0c5786010c5a01e1dc4b40f7d1cb98698ef638a2e2eaf62da139ee33649L110' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63575816</div><div id='project'> Project Name: mindlab-ai/mindnlp</div><div id='commit'> Commit Name: bd14f94512afa0075b31f2ccee1072676219ddcc</div><div id='time'> Time: 2022-07-28</div><div id='author'> Author: laixinyi@cqu.edu.cn</div><div id='file'> File Name: text/engine/trainer.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: _run(2)</div><div id='n_method'> N Method Name: _run(7)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: text/engine/trainer.py</div><div id='n_file'> N File Name: text/engine/trainer.py</div><div id='m_start'> M Start Line: 110</div><div id='m_end'> M End Line: 113</div><div id='n_start'> N Start Line: 132</div><div id='n_end'> N End Line: 174</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                                      deterministic: bool = False) \
            -&gt; Tuple[Sequence[ActionType], Sequence[float]]:
        implementation of :class:`~maze.core.agent.policy.Policy`
        <a id="change">raise </a>NotImplementedError

    def network_for(self, actor_id: Optional[ActorID]) -&gt; nn.Module:
        Helper function for returning a network for the given policy ID (using either just the sub-step ID</code></pre><h3>After Change</h3><pre><code class='java'>
            -&gt; Tuple[Sequence[ActionType], Sequence[float]]:
        implementation of :class:`~maze.core.agent.policy.Policy`
        assert deterministic, &quotCompute top actions only supported if deterministic == True for torch policy&quot
        <a id="change">with </a><a id="change">torch.no_grad():
            </a>policy_out = self.compute_substep_policy_output(observation, actor_id)
            actions<a id="change"> = </a>list()
            probs<a id="change"> = </a>list()
            for k, dist in policy_out.prob_dist.distribution_dict.items():
                <a id="change">if </a>isinstance(dist, CategoricalProbabilityDistribution):
                    for aa in dist.logits.argsort(-1, descending=True)[:num_candidates]:
                        actions.append({k: aa.numpy()})
                        probs.append(dist.dist.probs[aa])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/enlite-ai/maze/commit/23fa8f944dc838e38248d1cafe10f476cbc597b4#diff-92e333a960bae1a2574e681e1f527176c05f76baf245e1d51d25a0d85a9ce865L126' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63575759</div><div id='project'> Project Name: enlite-ai/maze</div><div id='commit'> Commit Name: 23fa8f944dc838e38248d1cafe10f476cbc597b4</div><div id='time'> Time: 2021-12-13</div><div id='author'> Author: office@enlite.ai</div><div id='file'> File Name: maze/core/agent/torch_policy.py</div><div id='m_class'> M Class Name: TorchPolicy</div><div id='n_method'> N Class Name: TorchPolicy</div><div id='m_method'> M Method Name: compute_top_action_candidates(7)</div><div id='n_method'> N Method Name: compute_top_action_candidates(7)</div><div id='m_parent_class'> M Parent Class: TorchModel,Policy</div><div id='n_parent_class'> N Parent Class: TorchModel,Policy</div><div id='m_file'> M File Name: maze/core/agent/torch_policy.py</div><div id='n_file'> N File Name: maze/core/agent/torch_policy.py</div><div id='m_start'> M Start Line: 135</div><div id='m_end'> M End Line: 135</div><div id='n_start'> N Start Line: 136</div><div id='n_end'> N End Line: 150</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                                      deterministic: bool = False) \
            -&gt; Tuple[Sequence[ActionType], Sequence[float]]:
        implementation of :class:`~maze.core.agent.policy.Policy`
        <a id="change">raise </a>NotImplementedError

    def network_for(self, actor_id: Optional[ActorID]) -&gt; nn.Module:
        Helper function for returning a network for the given policy ID (using either just the sub-step ID</code></pre><h3>After Change</h3><pre><code class='java'>
            -&gt; Tuple[Sequence[ActionType], Sequence[float]]:
        implementation of :class:`~maze.core.agent.policy.Policy`
        assert deterministic, &quotCompute top actions only supported if deterministic == True for torch policy&quot
        <a id="change">with </a><a id="change">torch.no_grad():
            </a>policy_out = self.compute_substep_policy_output(observation, actor_id)
            actions<a id="change"> = </a>list()
            probs<a id="change"> = </a>list()
            for k, dist in policy_out.prob_dist.distribution_dict.items():
                <a id="change">if </a>isinstance(dist, CategoricalProbabilityDistribution):
                    for aa in dist.logits.argsort(-1, descending=True)[:num_candidates]:
                        actions.append({k: aa.numpy()})
                        probs.append(dist.dist.probs[aa])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/enlite-ai/maze/commit/5b963aa4b7b76249adcc9207715d3a12fdb87494#diff-92e333a960bae1a2574e681e1f527176c05f76baf245e1d51d25a0d85a9ce865L126' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63575828</div><div id='project'> Project Name: enlite-ai/maze</div><div id='commit'> Commit Name: 5b963aa4b7b76249adcc9207715d3a12fdb87494</div><div id='time'> Time: 2021-12-13</div><div id='author'> Author: office@enlite.ai</div><div id='file'> File Name: maze/core/agent/torch_policy.py</div><div id='m_class'> M Class Name: TorchPolicy</div><div id='n_method'> N Class Name: TorchPolicy</div><div id='m_method'> M Method Name: compute_top_action_candidates(7)</div><div id='n_method'> N Method Name: compute_top_action_candidates(7)</div><div id='m_parent_class'> M Parent Class: TorchModel,Policy</div><div id='n_parent_class'> N Parent Class: TorchModel,Policy</div><div id='m_file'> M File Name: maze/core/agent/torch_policy.py</div><div id='n_file'> N File Name: maze/core/agent/torch_policy.py</div><div id='m_start'> M Start Line: 135</div><div id='m_end'> M End Line: 135</div><div id='n_start'> N Start Line: 136</div><div id='n_end'> N End Line: 150</div><BR>