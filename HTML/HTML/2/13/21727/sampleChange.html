<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    driver_memory = f"{spark_memory}g"
    user_home = os.environ["HOME"]
    spark = (
        <a id="change">SparkSession.builder.config("spark.driver.memory", driver_memory)
        .config("spark.sql.shuffle.partitions", str(shuffle_partitions))
        .config("spark.local.dir", os.path.join(user_home, "tmp"))
        .config("spark.driver.bindAddress", "127.0.0.1")
        .config("spark.driver.host", "localhost")
        .config("spark.sql.execution.arrow.pyspark.enabled", "true")
        .master("local[*]")
        .enableHiveSupport()
        .getOrCreate()
    )</a>
    return spark


def logger_with_settings() -&gt; logging.Logger:</code></pre><h3>After Change</h3><pre><code class='java'>
    driver_memory = f"{spark_memory}g"
    user_home = os.environ["HOME"]
    spark = (
        <a id="change">SparkSession.builder.config("spark.driver.memory", driver_memory)
        .config("spark.driver.extraJavaOptions",
                "-Dio.netty.tryReflectionSetAccessible=true")
        .config("spark.sql.shuffle.partitions", str(shuffle_partitions))
        .config("spark.local.dir", os.path.join(user_home, "tmp"))
        .config("spark.driver.bindAddress", "127.0.0.1")
        .config("spark.driver.host", "localhost")
        .config("spark.sql.execution.arrow.pyspark.enabled", "true")
        .master("local[*]")
        .enableHiveSupport()
        .getOrCreate()
    )</a>
    return spark


def logger_with_settings() -&gt; logging.Logger:</code></pre>