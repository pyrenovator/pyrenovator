<html><h3>Pattern ID :24284
</h3><img src='75329180.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        rel_coors = self.rel_coors_norm(rel_coors)

        coors_out = <a id="change">einsum(&quotb h i j, b i j c -&gt; b i c h&quot</a>, coor_weights, rel_coors<a id="change">)</a>
        coors_out = self.to_coors_out(coors_out)

        &#47&#47 derive attention
</code></pre><h3>After Change</h3><pre><code class='java'>
            coor_weights = coor_weights.softmax(dim = -1)

        rel_coors = self.rel_coors_norm(rel_coors)
        rel_coors = <a id="change">repeat(</a>rel_coors, <a id="change">&quotb i j c -&gt; b i j c h&quot</a><a id="change">, h = h)</a>

        if exists(self.coors_gate):
            rel_coors_signs = <a id="change">self.coors_gate(</a>coors_gate_input<a id="change">)</a>
            rel_coors_signs<a id="change"> = </a><a id="change">rearrange(</a>rel_coors_signs, <a id="change">&quotb i j h -&gt; b i j () h&quot</a><a id="change">)</a>
            rel_coors<a id="change"> = </a>rel_coors<a id="change"> * </a>rel_coors_signs

        coors_out<a id="change"> = einsum(&quotb h i j, b i j c h -&gt; b i c h&quot</a>, coor_weights, rel_coors<a id="change">)</a>
        coors_out = self.to_coors_out(coors_out)

        &#47&#47 derive attention
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/en-transformer/commit/5fa899a08f06db745808ae06275da2e2b4ada435#diff-e9ced413215f4c69daca6b09b62593523941c3f008a4967b67f3544a7aea30adL298' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75329180</div><div id='project'> Project Name: lucidrains/en-transformer</div><div id='commit'> Commit Name: 5fa899a08f06db745808ae06275da2e2b4ada435</div><div id='time'> Time: 2021-05-18</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: en_transformer/old.py</div><div id='m_class'> M Class Name: EquivariantAttention</div><div id='n_method'> N Class Name: EquivariantAttention</div><div id='m_method'> M Method Name: forward(6)</div><div id='n_method'> N Method Name: forward(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: en_transformer/old.py</div><div id='n_file'> N File Name: en_transformer/old.py</div><div id='m_start'> M Start Line: 298</div><div id='m_end'> M End Line: 309</div><div id='n_start'> N Start Line: 304</div><div id='n_end'> N End Line: 322</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        coor_attn = coor_weights.softmax(dim = -2)
        rel_coors = self.norm_rel_coors(rel_coors)
        coors_out = <a id="change">einsum(&quotb i j h, b i j c -&gt; b i c h&quot</a>, coor_attn, rel_coors<a id="change">)</a>

        coors_out = self.combine_coors_heads(coors_out)

        &#47&#47 derive attention</code></pre><h3>After Change</h3><pre><code class='java'>

        coor_attn = coor_weights.softmax(dim = -2)

        rel_coors_sign<a id="change"> = </a><a id="change">rearrange(self.coors_gate(</a>coors_mlp_input<a id="change">)</a>, <a id="change">&quotb i j h -&gt; b h i j ()&quot</a><a id="change">)</a>

        rel_coors = self.norm_rel_coors(rel_coors)
        rel_coors<a id="change"> = </a><a id="change">repeat(</a>rel_coors, <a id="change">&quotb i j c -&gt; b h i j c&quot</a><a id="change">, h = h) * </a>rel_coors_sign

        coors_out<a id="change"> = einsum(&quotb i j h, b h i j c -&gt; b i c h&quot</a>, coor_attn, rel_coors<a id="change">)</a>

        coors_out = self.combine_coors_heads(coors_out)

        &#47&#47 derive attention</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/en-transformer/commit/f9c37c746e9fd4423bea32d0dcde2a466e252ba2#diff-002dbd1d79d50bcdc8ad3d0c2fd89cd8a5967d841ed4b4339d5b5872c1836c54L173' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75329173</div><div id='project'> Project Name: lucidrains/en-transformer</div><div id='commit'> Commit Name: f9c37c746e9fd4423bea32d0dcde2a466e252ba2</div><div id='time'> Time: 2021-05-16</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: en_transformer/coors_attention.py</div><div id='m_class'> M Class Name: EquivariantAttention</div><div id='n_method'> N Class Name: EquivariantAttention</div><div id='m_method'> M Method Name: forward(6)</div><div id='n_method'> N Method Name: forward(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: en_transformer/coors_attention.py</div><div id='n_file'> N File Name: en_transformer/coors_attention.py</div><div id='m_start'> M Start Line: 306</div><div id='m_end'> M End Line: 308</div><div id='n_start'> N Start Line: 303</div><div id='n_end'> N End Line: 318</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        rel_coors = self.rel_coors_norm(rel_coors)

        coors_out = <a id="change">einsum(&quotb i j, b i j c -&gt; b i c&quot</a>, coor_weights, rel_coors<a id="change">)</a>

        &#47&#47 derive attention

        sim = qk.clone()</code></pre><h3>After Change</h3><pre><code class='java'>

        coor_attn = coor_weights.softmax(dim = -2)

        rel_coors_sign = <a id="change">self.coors_gate(</a>coors_mlp_input<a id="change">)</a>
        rel_coors_sign<a id="change"> = </a><a id="change">rearrange(</a>rel_coors_sign, <a id="change">&quotb i j h -&gt; b i j () h&quot</a><a id="change">)</a>

        rel_coors = self.norm_rel_coors(rel_coors)

        rel_coors = <a id="change">repeat(</a>rel_coors, <a id="change">&quotb i j c -&gt; b i j c h&quot</a><a id="change">, h = h)</a>

        rel_coors<a id="change"> = </a>rel_coors<a id="change"> * </a>rel_coors_sign

        coors_out<a id="change"> = einsum(&quotb i j h, b i j c h, h -&gt; b i c&quot</a>, coor_attn, rel_coors, self.coors_combine<a id="change">)</a>

        &#47&#47 derive attention

        sim = qk.clone()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/en-transformer/commit/3cf2206856883bba9a13ba4541510b4fe48a6628#diff-f288a1692c1c58a186cb9ac763046f632757db1647271b97852e59e3fc5696b9L167' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75329175</div><div id='project'> Project Name: lucidrains/en-transformer</div><div id='commit'> Commit Name: 3cf2206856883bba9a13ba4541510b4fe48a6628</div><div id='time'> Time: 2021-05-16</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: en_transformer/en_transformer.py</div><div id='m_class'> M Class Name: EquivariantAttention</div><div id='n_method'> N Class Name: EquivariantAttention</div><div id='m_method'> M Method Name: forward(6)</div><div id='n_method'> N Method Name: forward(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: en_transformer/en_transformer.py</div><div id='n_file'> N File Name: en_transformer/en_transformer.py</div><div id='m_start'> M Start Line: 182</div><div id='m_end'> M End Line: 307</div><div id='n_start'> N Start Line: 189</div><div id='n_end'> N End Line: 325</div><BR>