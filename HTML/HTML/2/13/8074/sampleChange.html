<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    if koffset is None:
        return HashGPU.apply(idx)
    else:
        <a id="change">return </a><a id="change">KernelHashGPU.apply(</a>idx, koffset<a id="change">)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
           offsets: Optional[torch.Tensor] = None) -&gt; torch.Tensor:
    assert coords.dtype == torch.int, coords.dtype
    assert coords.ndim == 2 and coords.shape[1] == 4, coords.shape
    coords<a id="change"> = </a><a id="change">coords.contiguous()</a>

    &#47&#47 TODO(Zhijian): We might be able to merge `hash_kernel` and `hash`.
    if offsets is None:
        if coords.device.type == &quotcuda&quot:
            return torchsparse.backend.hash_cuda(coords)
        elif coords.device.type == &quotcpu&quot:
            return torchsparse.backend.hash_cpu(coords)
        else:
            device = coords.device
            return torchsparse.backend.hash_cpu(coords.cpu()).to(device)
    else:
        assert offsets.dtype == torch.int, offsets.dtype
        assert offsets.ndim == 2 and offsets.shape[1] == 3, offsets.shape
        offsets = offsets.contiguous()

        <a id="change">if coords.device.type == &quotcuda&quot</a>:
            return torchsparse.backend.kernel_hash_cuda(coords, offsets)
        elif <a id="change">coords.device.type == &quotcpu&quot</a>:
            return torchsparse.backend.kernel_hash_cpu(coords, offsets)
        else:
            device<a id="change"> = </a>coords.device
            return <a id="change">torchsparse.backend.kernel_hash_cpu(coords.cpu(),
                                                       offsets.cpu()).to(</a>device<a id="change">)</a>
</code></pre>