<html><h3>Pattern ID :6188
</h3><img src='21170256.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def bare_named_parameters(
        self, prefix: str = "", recurse: bool = True
    ) -&gt; Iterator[Tuple[str, torch.nn.Parameter]]:
        <a id="change">yield from </a>self._named_parameters(self.module, prefix, recurse, False)

    @staticmethod
    def _sharded_parameter_names(module: nn.Module, prefix: str = "") -&gt; Iterator[str]:</code></pre><h3>After Change</h3><pre><code class='java'>
    def bare_named_parameters(
        self, prefix: str = "", recurse: bool = True
    ) -&gt; Iterator[Tuple[str, torch.nn.Parameter]]:
        gen<a id="change"> = </a>self._named_parameters(self.module, prefix, recurse, False)
        <a id="change">memo = set()</a>
        <a id="change">for </a>key, <a id="change">param</a> in gen<a id="change">:
            if param in memo</a>:
                <a id="change">continue</a>
            <a id="change">memo.add(param</a><a id="change">)</a>
            <a id="change">yield </a>key<a id="change">, param</a>

    @staticmethod
    def _sharded_parameter_names(module: nn.Module, prefix: str = "") -&gt; Iterator[str]:
        module = get_unwrapped_module(module)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 11</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/facebookresearch/torchrec/commit/37a1ed76db8009a58db3cb983fab3b557e2f07c1#diff-088378575010e7b9e27ea06507ba52fcc8604bcf9cb107f4939a9a49b0d52c89L512' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21170256</div><div id='project'> Project Name: facebookresearch/torchrec</div><div id='commit'> Commit Name: 37a1ed76db8009a58db3cb983fab3b557e2f07c1</div><div id='time'> Time: 2022-07-02</div><div id='author'> Author: xingl@fb.com</div><div id='file'> File Name: torchrec/distributed/model_parallel.py</div><div id='m_class'> M Class Name: DistributedModelParallel</div><div id='n_method'> N Class Name: DistributedModelParallel</div><div id='m_method'> M Method Name: bare_named_parameters(3)</div><div id='n_method'> N Method Name: bare_named_parameters(3)</div><div id='m_parent_class'> M Parent Class: FusedOptimizerModule,nn.Module</div><div id='n_parent_class'> N Parent Class: FusedOptimizerModule,nn.Module</div><div id='m_file'> M File Name: torchrec/distributed/model_parallel.py</div><div id='n_file'> N File Name: torchrec/distributed/model_parallel.py</div><div id='m_start'> M Start Line: 512</div><div id='m_end'> M End Line: 512</div><div id='n_start'> N Start Line: 518</div><div id='n_end'> N End Line: 526</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def named_buffers(
        self, prefix: str = "", recurse: bool = True
    ) -&gt; Iterator[Tuple[str, torch.Tensor]]:
        <a id="change">yield from </a>self._named_buffers(self.module, prefix, recurse)

    @property
    def fused_optimizer(self) -&gt; KeyedOptimizer:</code></pre><h3>After Change</h3><pre><code class='java'>
    def named_buffers(
        self, prefix: str = "", recurse: bool = True
    ) -&gt; Iterator[Tuple[str, torch.Tensor]]:
        gen<a id="change"> = </a>self._named_buffers(self.module, prefix, recurse)
        <a id="change">memo = set()</a>
        <a id="change">for </a>key, <a id="change">param</a> in gen<a id="change">:
            if param in memo</a>:
                <a id="change">continue</a>
            <a id="change">memo.add(</a>param<a id="change">)</a>
            <a id="change">yield </a>key<a id="change">, param</a>

    @property
    def fused_optimizer(self) -&gt; KeyedOptimizer:
        return self._optim</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/facebookresearch/torchrec/commit/37a1ed76db8009a58db3cb983fab3b557e2f07c1#diff-088378575010e7b9e27ea06507ba52fcc8604bcf9cb107f4939a9a49b0d52c89L538' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21170255</div><div id='project'> Project Name: facebookresearch/torchrec</div><div id='commit'> Commit Name: 37a1ed76db8009a58db3cb983fab3b557e2f07c1</div><div id='time'> Time: 2022-07-02</div><div id='author'> Author: xingl@fb.com</div><div id='file'> File Name: torchrec/distributed/model_parallel.py</div><div id='m_class'> M Class Name: DistributedModelParallel</div><div id='n_method'> N Class Name: DistributedModelParallel</div><div id='m_method'> M Method Name: named_buffers(3)</div><div id='n_method'> N Method Name: named_buffers(3)</div><div id='m_parent_class'> M Parent Class: FusedOptimizerModule,nn.Module</div><div id='n_parent_class'> N Parent Class: FusedOptimizerModule,nn.Module</div><div id='m_file'> M File Name: torchrec/distributed/model_parallel.py</div><div id='n_file'> N File Name: torchrec/distributed/model_parallel.py</div><div id='m_start'> M Start Line: 541</div><div id='m_end'> M End Line: 541</div><div id='n_start'> N Start Line: 553</div><div id='n_end'> N End Line: 561</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def named_parameters(
        self, prefix: str = "", recurse: bool = True
    ) -&gt; Iterator[Tuple[str, torch.nn.Parameter]]:
        <a id="change">yield from </a>self._named_parameters(self.module, prefix, recurse)

    def bare_named_parameters(
        self, prefix: str = "", recurse: bool = True</code></pre><h3>After Change</h3><pre><code class='java'>
    def named_parameters(
        self, prefix: str = "", recurse: bool = True
    ) -&gt; Iterator[Tuple[str, torch.nn.Parameter]]:
        gen<a id="change"> = </a>self._named_parameters(self.module, prefix, recurse)
        <a id="change">memo = set()</a>
        <a id="change">for </a>key, <a id="change">param</a> in gen<a id="change">:
            if param in memo</a>:
                <a id="change">continue</a>
            <a id="change">memo.add(</a>param<a id="change">)</a>
            <a id="change">yield </a>key<a id="change">, param</a>

    def bare_named_parameters(
        self, prefix: str = "", recurse: bool = True
    ) -&gt; Iterator[Tuple[str, torch.nn.Parameter]]:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/facebookresearch/torchrec/commit/37a1ed76db8009a58db3cb983fab3b557e2f07c1#diff-088378575010e7b9e27ea06507ba52fcc8604bcf9cb107f4939a9a49b0d52c89L504' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21170254</div><div id='project'> Project Name: facebookresearch/torchrec</div><div id='commit'> Commit Name: 37a1ed76db8009a58db3cb983fab3b557e2f07c1</div><div id='time'> Time: 2022-07-02</div><div id='author'> Author: xingl@fb.com</div><div id='file'> File Name: torchrec/distributed/model_parallel.py</div><div id='m_class'> M Class Name: DistributedModelParallel</div><div id='n_method'> N Class Name: DistributedModelParallel</div><div id='m_method'> M Method Name: named_parameters(3)</div><div id='n_method'> N Method Name: named_parameters(3)</div><div id='m_parent_class'> M Parent Class: FusedOptimizerModule,nn.Module</div><div id='n_parent_class'> N Parent Class: FusedOptimizerModule,nn.Module</div><div id='m_file'> M File Name: torchrec/distributed/model_parallel.py</div><div id='n_file'> N File Name: torchrec/distributed/model_parallel.py</div><div id='m_start'> M Start Line: 507</div><div id='m_end'> M End Line: 507</div><div id='n_start'> N Start Line: 507</div><div id='n_end'> N End Line: 515</div><BR>