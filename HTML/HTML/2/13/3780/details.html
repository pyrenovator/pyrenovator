<html><h3>Pattern ID :3780
</h3><img src='14138535.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        output, attn_scores = lstm(src_tokens, tgt_tokens, src_length, mask=mask)

        assert output.shape == (8, 16, 1000)
        <a id="change">assert </a>attn_scores.shape == (8, 16, 16)

    def test_lstm_pynative(self):
        </code></pre><h3>After Change</h3><pre><code class='java'>
        context.set_context(mode=context.GRAPH_MODE)

        vocab_size = 1000
        <a id="change">embedding_size</a><a id="change"> = 32</a>
        hidden_size<a id="change"> = 16</a>
        num_layers = 2
        has_bias = True
        dropout = 0.1
        bidirectional = False
        encoder_output_units = 16
        embedding<a id="change"> = nn</a><a id="change">.Embedding(</a>vocab_size, <a id="change">embedding_size</a><a id="change">)</a>
        lstm_layer<a id="change"> = nn.LSTM(embedding_size</a>, hidden_size<a id="change">, num_layers=num_layers, has_bias=has_bias,
                             batch_first=True, dropout=dropout, bidirectional=bidirectional)</a>

        lstm_encoder<a id="change"> = Seq2SeqEncoder(</a>embedding, lstm_layer<a id="change">)</a>
        lstm_decoder = Seq2SeqDecoder(embedding, lstm_layer, dropout=dropout, attention=True,
                                      encoder_output_units=encoder_output_units)
        lstm = LSTM(lstm_encoder, lstm_decoder)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/mindspore-lab/mindnlp/commit/c676fa08ea605ad36d403199d95ff9d5776b4529#diff-6ac96140525af09fa3124fbd35f0028a3200d99b7c63cee20255efb39981d102L89' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14138535</div><div id='project'> Project Name: mindspore-lab/mindnlp</div><div id='commit'> Commit Name: c676fa08ea605ad36d403199d95ff9d5776b4529</div><div id='time'> Time: 2022-10-11</div><div id='author'> Author: 48319911+WarruzuEndo@users.noreply.github.com</div><div id='file'> File Name: tests/ut/models/test_seq2seq.py</div><div id='m_class'> M Class Name: TestLSTM</div><div id='n_method'> N Class Name: TestLSTM</div><div id='m_method'> M Method Name: test_lstm_graph(1)</div><div id='n_method'> N Method Name: test_lstm_graph(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: tests/ut/models/test_seq2seq.py</div><div id='n_file'> N File Name: tests/ut/models/test_seq2seq.py</div><div id='m_start'> M Start Line: 89</div><div id='m_end'> M End Line: 103</div><div id='n_start'> N Start Line: 110</div><div id='n_end'> N End Line: 132</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        output, attn_scores = lstm(src_tokens, tgt_tokens, src_length, mask=mask)

        assert output.shape == (8, 16, 1000)
        <a id="change">assert </a>attn_scores.shape == (8, 16, 16)


class TestGRU(unittest.TestCase):</code></pre><h3>After Change</h3><pre><code class='java'>
        context.set_context(mode=context.PYNATIVE_MODE)

        vocab_size = 1000
        <a id="change">embedding_size</a><a id="change"> = 32</a>
        hidden_size<a id="change"> = 16</a>
        num_layers = 2
        has_bias = True
        dropout = 0.1
        bidirectional = False
        encoder_output_units = 16
        embedding<a id="change"> = </a><a id="change">nn.Embedding(</a>vocab_size, embedding_size<a id="change">)</a>
        lstm_layer<a id="change"> = nn.LSTM(</a>embedding_size, hidden_size<a id="change">, num_layers=num_layers, has_bias=has_bias,
                             batch_first=True, dropout=dropout, bidirectional=bidirectional)</a>

        lstm_encoder<a id="change"> = Seq2SeqEncoder(</a>embedding, lstm_layer<a id="change">)</a>
        lstm_decoder = Seq2SeqDecoder(embedding, lstm_layer, dropout=dropout, attention=True,
                                      encoder_output_units=encoder_output_units)
        lstm = GRU(lstm_encoder, lstm_decoder)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mindlab-ai/mindnlp/commit/c676fa08ea605ad36d403199d95ff9d5776b4529#diff-6ac96140525af09fa3124fbd35f0028a3200d99b7c63cee20255efb39981d102L105' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14138534</div><div id='project'> Project Name: mindlab-ai/mindnlp</div><div id='commit'> Commit Name: c676fa08ea605ad36d403199d95ff9d5776b4529</div><div id='time'> Time: 2022-10-11</div><div id='author'> Author: 48319911+WarruzuEndo@users.noreply.github.com</div><div id='file'> File Name: tests/ut/models/test_seq2seq.py</div><div id='m_class'> M Class Name: TestLSTM</div><div id='n_method'> N Class Name: TestLSTM</div><div id='m_method'> M Method Name: test_lstm_pynative(1)</div><div id='n_method'> N Method Name: test_lstm_pynative(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: tests/ut/models/test_seq2seq.py</div><div id='n_file'> N File Name: tests/ut/models/test_seq2seq.py</div><div id='m_start'> M Start Line: 111</div><div id='m_end'> M End Line: 125</div><div id='n_start'> N Start Line: 142</div><div id='n_end'> N End Line: 164</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        output, attn_scores = lstm(src_tokens, tgt_tokens, src_length, mask=mask)

        assert output.shape == (8, 16, 1000)
        <a id="change">assert </a>attn_scores.shape == (8, 16, 16)

    def test_lstm_pynative(self):
        </code></pre><h3>After Change</h3><pre><code class='java'>
        context.set_context(mode=context.GRAPH_MODE)

        vocab_size = 1000
        <a id="change">embedding_size</a><a id="change"> = 32</a>
        hidden_size<a id="change"> = 16</a>
        num_layers = 2
        has_bias = True
        dropout = 0.1
        bidirectional = False
        encoder_output_units = 16
        embedding<a id="change"> = </a><a id="change">nn.Embedding(</a>vocab_size, embedding_size<a id="change">)</a>
        lstm_layer<a id="change"> = nn.LSTM(</a>embedding_size, hidden_size<a id="change">, num_layers=num_layers, has_bias=has_bias,
                             batch_first=True, dropout=dropout, bidirectional=bidirectional)</a>

        lstm_encoder<a id="change"> = Seq2SeqEncoder(</a>embedding, lstm_layer<a id="change">)</a>
        lstm_decoder = Seq2SeqDecoder(embedding, lstm_layer, dropout=dropout, attention=True,
                                      encoder_output_units=encoder_output_units)
        lstm = LSTM(lstm_encoder, lstm_decoder)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mindlab-ai/mindnlp/commit/c676fa08ea605ad36d403199d95ff9d5776b4529#diff-6ac96140525af09fa3124fbd35f0028a3200d99b7c63cee20255efb39981d102L83' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14138532</div><div id='project'> Project Name: mindlab-ai/mindnlp</div><div id='commit'> Commit Name: c676fa08ea605ad36d403199d95ff9d5776b4529</div><div id='time'> Time: 2022-10-11</div><div id='author'> Author: 48319911+WarruzuEndo@users.noreply.github.com</div><div id='file'> File Name: tests/ut/models/test_seq2seq.py</div><div id='m_class'> M Class Name: TestLSTM</div><div id='n_method'> N Class Name: TestLSTM</div><div id='m_method'> M Method Name: test_lstm_graph(1)</div><div id='n_method'> N Method Name: test_lstm_graph(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: tests/ut/models/test_seq2seq.py</div><div id='n_file'> N File Name: tests/ut/models/test_seq2seq.py</div><div id='m_start'> M Start Line: 89</div><div id='m_end'> M End Line: 103</div><div id='n_start'> N Start Line: 110</div><div id='n_end'> N End Line: 132</div><BR>