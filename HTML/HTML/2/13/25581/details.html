<html><h3>Pattern ID :25581
</h3><img src='77836451.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        total_uploaded_size = 0
        total_dataset_nbytes = 0
        info_to_dump: DatasetInfo = next(iter(self.values())).info.copy()
        dataset_name<a id="change"> = </a><a id="change">repo_id.split("/"</a><a id="change">)</a>[-1]
        info_to_dump.splits = SplitDict(dataset_name=dataset_name)

        for split in self.keys():</code></pre><h3>After Change</h3><pre><code class='java'>
        info_to_dump.dataset_size = total_dataset_nbytes
        info_to_dump.size_in_bytes = total_uploaded_size + total_dataset_nbytes

        api<a id="change"> = </a>HfApi(endpoint=config.HF_ENDPOINT)
        <a id="change">repo_files</a> = hf_api_list_repo_files(api, repo_id, repo_type="dataset", revision=branch, token=token)

        &#47&#47 push to the deprecated dataset_infos.json
        <a id="change">if config.DATASETDICT_INFOS_FILENAME in repo_files</a>:
            buffer = BytesIO()
            buffer.write(b&quot{"default": &quot)
            info_to_dump._dump_info(buffer, pretty_print=True)
            buffer.write(b"}")
            HfApi(endpoint=config.HF_ENDPOINT).upload_file(
                path_or_fileobj=buffer.getvalue(),
                path_in_repo=config.DATASETDICT_INFOS_FILENAME,
                repo_id=repo_id,
                token=token,
                repo_type="dataset",
                revision=branch,
            )
        &#47&#47 push to README
        <a id="change">if "README.md" in repo_files</a>:
            download_config<a id="change"> = </a>DownloadConfig()
            download_config.download_desc<a id="change"> = </a>"Downloading metadata"
            dataset_readme_path = cached_path(
                hf_hub_url(repo_id, "README.md"),
                download_config=download_config,
            )
            dataset_metadata = DatasetMetadata.from_readme(Path(dataset_readme_path))
            with open(dataset_readme_path, encoding="utf-8") as readme_file:
                readme_content = readme_file.read()
        else:
            dataset_metadata = DatasetMetadata()
            readme_content<a id="change"> = </a>f&quot&#47&#47 Dataset Card for "{repo_id.split("/")[-1]}"\n\n[More Information needed](https://github.com/huggingface/datasets/blob/main/CONTRIBUTING.md&#47&#47how-to-contribute-to-the-dataset-cards)&quot
        DatasetInfosDict({"default": info_to_dump}).to_metadata(dataset_metadata)
        HfApi(endpoint=config.HF_ENDPOINT).upload_file(
            path_or_fileobj=dataset_metadata._to_readme(readme_content).encode(),</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/huggingface/datasets/commit/67e65c90e9490810b89ee140da11fdd13c356c9c#diff-a03fe8c218f22c8b26cc51f588cf5466c27f433373033d8724f66f996c2beda8L1346' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 77836451</div><div id='project'> Project Name: huggingface/datasets</div><div id='commit'> Commit Name: 67e65c90e9490810b89ee140da11fdd13c356c9c</div><div id='time'> Time: 2022-10-03</div><div id='author'> Author: 42851186+lhoestq@users.noreply.github.com</div><div id='file'> File Name: src/datasets/dataset_dict.py</div><div id='m_class'> M Class Name: DatasetDict</div><div id='n_method'> N Class Name: DatasetDict</div><div id='m_method'> M Method Name: push_to_hub(8)</div><div id='n_method'> N Method Name: push_to_hub(8)</div><div id='m_parent_class'> M Parent Class: dict</div><div id='n_parent_class'> N Parent Class: dict</div><div id='m_file'> M File Name: src/datasets/dataset_dict.py</div><div id='n_file'> N File Name: src/datasets/dataset_dict.py</div><div id='m_start'> M Start Line: 1346</div><div id='m_end'> M End Line: 1386</div><div id='n_start'> N Start Line: 1350</div><div id='n_end'> N End Line: 1416</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            info_to_dump.splits[split] = SplitInfo(
                str(split), num_bytes=dataset_nbytes, num_examples=len(self[split]), dataset_name=dataset_name
            )
        organization<a id="change">, dataset_name = </a><a id="change">repo_id.split("/"</a><a id="change">)</a>
        info_to_dump.download_checksums = None
        info_to_dump.download_size = total_uploaded_size
        info_to_dump.dataset_size = total_dataset_nbytes
        info_to_dump.size_in_bytes = total_uploaded_size + total_dataset_nbytes</code></pre><h3>After Change</h3><pre><code class='java'>
        info_to_dump.size_in_bytes = total_uploaded_size + total_dataset_nbytes

        api = HfApi(endpoint=config.HF_ENDPOINT)
        <a id="change">repo_files</a><a id="change"> = </a>hf_api_list_repo_files(api, repo_id, repo_type="dataset", revision=branch, token=token)

        &#47&#47 push to the deprecated dataset_infos.json
        <a id="change">if config.DATASETDICT_INFOS_FILENAME in repo_files</a>:
            buffer = BytesIO()
            buffer.write(b&quot{"default": &quot)
            info_to_dump._dump_info(buffer, pretty_print=True)
            buffer.write(b"}")
            HfApi(endpoint=config.HF_ENDPOINT).upload_file(
                path_or_fileobj=buffer.getvalue(),
                path_in_repo=config.DATASETDICT_INFOS_FILENAME,
                repo_id=repo_id,
                token=token,
                repo_type="dataset",
                revision=branch,
            )
        &#47&#47 push to README
        <a id="change">if "README.md" in repo_files</a>:
            download_config<a id="change"> = </a>DownloadConfig()
            download_config.download_desc = "Downloading metadata"
            dataset_readme_path = cached_path(
                hf_hub_url(repo_id, "README.md"),
                download_config=download_config,
            )
            dataset_metadata = DatasetMetadata.from_readme(Path(dataset_readme_path))
            with open(dataset_readme_path, encoding="utf-8") as readme_file:
                readme_content<a id="change"> = </a>readme_file.read()
        else:
            dataset_metadata = DatasetMetadata()
            readme_content<a id="change"> = </a>f&quot&#47&#47 Dataset Card for "{repo_id.split("/")[-1]}"\n\n[More Information needed](https://github.com/huggingface/datasets/blob/main/CONTRIBUTING.md&#47&#47how-to-contribute-to-the-dataset-cards)&quot
        DatasetInfosDict({"default": info_to_dump}).to_metadata(dataset_metadata)
        HfApi(endpoint=config.HF_ENDPOINT).upload_file(
            path_or_fileobj=dataset_metadata._to_readme(readme_content).encode(),</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/datasets/commit/67e65c90e9490810b89ee140da11fdd13c356c9c#diff-a03fe8c218f22c8b26cc51f588cf5466c27f433373033d8724f66f996c2beda8L1284' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 77836450</div><div id='project'> Project Name: huggingface/datasets</div><div id='commit'> Commit Name: 67e65c90e9490810b89ee140da11fdd13c356c9c</div><div id='time'> Time: 2022-10-03</div><div id='author'> Author: 42851186+lhoestq@users.noreply.github.com</div><div id='file'> File Name: src/datasets/dataset_dict.py</div><div id='m_class'> M Class Name: DatasetDict</div><div id='n_method'> N Class Name: DatasetDict</div><div id='m_method'> M Method Name: push_to_hub(8)</div><div id='n_method'> N Method Name: push_to_hub(8)</div><div id='m_parent_class'> M Parent Class: dict</div><div id='n_parent_class'> N Parent Class: dict</div><div id='m_file'> M File Name: src/datasets/dataset_dict.py</div><div id='n_file'> N File Name: src/datasets/dataset_dict.py</div><div id='m_start'> M Start Line: 1346</div><div id='m_end'> M End Line: 1386</div><div id='n_start'> N Start Line: 1350</div><div id='n_end'> N End Line: 1416</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        super(Baseline, self).__init__()
        stage_with_gcb = [False, False, False, False]
        if gcb and stage_with_gcb_str:
            stage_with_gcb_list<a id="change"> = </a>map(int, <a id="change">stage_with_gcb_str.split(&quot,&quot</a><a id="change">)</a>)
            for n in stage_with_gcb_list:
                stage_with_gcb[n] = True
        if num_layers in [50, 101, &quot101_32x8d&quot]:</code></pre><h3>After Change</h3><pre><code class='java'>
        self.bn = nn.Sequential(nn.BatchNorm2d(reduce_dim))
        self._init_bn(self.bn)

        <a id="change">self.loss_type</a><a id="change"> = </a>loss_type
        <a id="change">if &quotsoftmax&quot in self.loss_type</a>:
            self.fc_layer = nn.Sequential(nn.Dropout(), nn.Linear(reduce_dim, num_classes))
            self._init_fc(self.fc_layer)
            if &quotlabelsmooth&quot in self.loss_type:
                self.ce_loss<a id="change"> = </a>CrossEntropyLabelSmooth(num_classes)
            else:
                self.ce_loss<a id="change"> = </a>nn.CrossEntropyLoss()  &#47&#47 .cuda()
        elif &quotarcface&quot in self.loss_type:
            pass
        elif &quotcircle&quot in self.loss_type:
            self.fc_layer<a id="change"> = </a>Circle(num_classes, reduce_dim)

        <a id="change">if &quottriplet&quot in self.loss_type</a>:
            self.tri_loss = TripletLoss(margin, normalize_feature=not &quotcircle&quot in self.loss_type) &#47&#47.cuda()

    @staticmethod</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tencentyouturesearch/personreid-cacenet/commit/a82d51979279b93a4f34eff01d16de2af6f02b4d#diff-0bb3c15e92cf390ebe34d0347c1f8b228f6048214f97b56c95ca086dba70a523L21' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 77836314</div><div id='project'> Project Name: tencentyouturesearch/personreid-cacenet</div><div id='commit'> Commit Name: a82d51979279b93a4f34eff01d16de2af6f02b4d</div><div id='time'> Time: 2020-08-13</div><div id='author'> Author: fufuyu@tencent.com</div><div id='file'> File Name: models/baseline.py</div><div id='m_class'> M Class Name: Baseline</div><div id='n_method'> N Class Name: Baseline</div><div id='m_method'> M Method Name: __init__(9)</div><div id='n_method'> N Method Name: __init__(8)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/baseline.py</div><div id='n_file'> N File Name: models/baseline.py</div><div id='m_start'> M Start Line: 26</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 15</div><div id='n_end'> N End Line: 65</div><BR>