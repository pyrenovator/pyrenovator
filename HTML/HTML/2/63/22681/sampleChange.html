<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            self.kernels[CP]["forward"](Q, K, V, out)

        &#47&#47 measure
        start<a id="change"> = </a>torch.cuda.Event(enable_timing=True)
        <a id="change">end = </a>torch.cuda.Event(enable_timing=True)
        <a id="change">start.record()</a>
        for i in range(10):
            self.kernels[CP]["forward"](Q, K, V, out)
        <a id="change">end.record()</a>
        torch.cuda.synchronize()
        <a id="change">print(</a><a id="change">"[{}] GPU time taken: {} (ms)".format(
            </a>CP,
            <a id="change">start.elapsed_time(end</a><a id="change">)
        ))</a>

    def _test_benchmark_backward(self, CP):
        N = 10
        L = 1000</code></pre><h3>After Change</h3><pre><code class='java'>

    def _test_benchmark_forward(self, CP):
        print("{:&gt;4} {:&gt;5} {:&gt;5} {:&gt;5} {:&gt;5} {:&gt;12}".format("N", "L", "H", "E", "M", "FW Time (ms)"))
        <a id="change">for </a>N, L, H, E, <a id="change">M</a> in <a id="change">[
            [8</a>, <a id="change">4096</a>, <a id="change">8</a>, <a id="change">512</a>, <a id="change">512</a>],
            <a id="change">[1</a>, <a id="change">4096</a>, <a id="change">8</a>, <a id="change">512</a>, <a id="change">512</a>],
            <a id="change">[16</a>, <a id="change">512</a>, <a id="change">8</a>, <a id="change">512</a>, <a id="change">512</a>],
            <a id="change">[16</a>, <a id="change">128</a>, <a id="change">8</a>, <a id="change">512</a>, <a id="change">512</a>],
            <a id="change">[1</a>, <a id="change">128</a>, <a id="change">8</a>, <a id="change">512</a>, <a id="change">512</a>],
            <a id="change">[16</a>, <a id="change">4096</a>, <a id="change">1</a>, <a id="change">512</a>, <a id="change">512</a>],
            <a id="change">[16</a>, <a id="change">4096</a>, <a id="change">8</a>, <a id="change">64</a>, <a id="change">64</a>]<a id="change"></a>,
        ]<a id="change">:
            </a>Q = torch.rand(N, H, L, E).cuda()
            K = torch.rand(N, H, L, E).cuda()
            V = torch.rand(N, H, L, M).cuda()
            out = torch.rand(N, H, L, M).cuda()

            &#47&#47 warmup the cache
            for i in range(10):
                self.kernels[CP]["forward"](Q, K, V, out)

            &#47&#47 measure
            start<a id="change"> = </a>torch.cuda.Event(enable_timing=True)
            <a id="change">end = </a>torch.cuda.Event(enable_timing=True)
            <a id="change">start.record()</a>
            for i in range(10):
                self.kernels[CP]["forward"](Q, K, V, out)
            <a id="change">end.record()</a>
            torch.cuda.synchronize()
            <a id="change">print(</a><a id="change">"{:&gt;5} {:&gt;5} {:&gt;5} {:&gt;5} {:&gt;5} {:&gt;8.1f}".format(
                </a>N, L, H, E, <a id="change">M</a>,
                <a id="change">start.elapsed_time(end</a><a id="change">)
            ))</a>

    def _test_benchmark_backward(self, CP):
        print("{:&gt;4} {:&gt;5} {:&gt;5} {:&gt;5} {:&gt;5} {:&gt;12}".format("N", "L", "H", "E", "M", "BW Time (ms)"))
        for N, L, H, E, M in [</code></pre>