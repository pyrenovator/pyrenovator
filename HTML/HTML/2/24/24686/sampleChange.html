<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 Modify grad_inputs_schema to support grad_prompts
            assert len(requested_backends[0].args_schema) == 1 and len(grads) in (1, 2)  &#47&#47 TODO generalize
            grad_inputs_schema_with_prompts = (
                requested_backends[0].args_schema * len(grads)<a id="change">,
                requested_backends[0].kwargs_schema</a>,
            )  &#47&#47 TODO generalize

            &#47&#47 Serialize the overall grad_inputs
            serialized_grad_inputs<a id="change"> = </a><a id="change">[
                serialize_torch_tensor(result.to(proto.dtype), proto.compression, allow_inplace=True)
                for result, proto in zip(grads, nested_flatten(grad_inputs_schema_with_prompts))
            ]</a>
            &#47&#47 Split the serialized_grad_inputs for streaming and respond
            output_split<a id="change"> = </a><a id="change">[
                part for tensor in serialized_grad_inputs for part in split_for_streaming(tensor, DEFAULT_MAX_MSG_SIZE)
            ]</a>

            <a id="change">async for part</a> in <a id="change">as_aiter(</a>*<a id="change">output_split):
                yield </a>runtime_pb2.ExpertResponse(tensors=[part])

    def _check_uids(self, uids: str) -&gt; Sequence[ModuleUID]:
        Check that the first request to rpc_inference is valid</code></pre><h3>After Change</h3><pre><code class='java'>
                *flat_tensors, requested_backends=requested_backends, prioritizer=self._prioritizer, points=points
            )
            &#47&#47 Split the serialized_grad_inputs for streaming and respond
            <a id="change">for </a>tensor in self._serialize_grads(grads, requested_backends, metadata)<a id="change">:
                for part</a> in <a id="change">split_for_streaming(tensor</a>, DEFAULT_MAX_MSG_SIZE<a id="change">)</a><a id="change">:
                    yield </a>runtime_pb2.ExpertResponse(tensors=[part])

    def _serialize_grads(
        self,</code></pre>