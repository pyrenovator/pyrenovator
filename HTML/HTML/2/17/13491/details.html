<html><h3>Pattern ID :13491
</h3><img src='45476657.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        total_loss = 0.
        total_samples = 0.

        for emb_images, <a id="change">emb_text</a> in <a id="change">zip(</a><a id="change">image_reader(batch_size=batch_size, start=start, end=end)</a>,
                <a id="change">text_reader(batch_size=batch_size, start=start, end=end))</a>:

            emb_images_tensor<a id="change"> = torch.tensor(emb_images[0]).to(</a>device<a id="change">)</a>
            emb_text_tensor = <a id="change">torch.tensor(</a>emb_text[0]<a id="change">)</a>.to(device)

            batches = emb_images_tensor.shape[0]
</code></pre><h3>After Change</h3><pre><code class='java'>
        total_loss = 0.
        total_samples = 0.

        for image_embeddings, text_data in <a id="change">tqdm(</a>dataloader<a id="change">)</a>:

            batches = image_embeddings.shape[0]

            input_args = dict(image_embed=image_embeddings)
            <a id="change">if text_conditioned</a>:
                input_args<a id="change"> = </a><a id="change">dict(**input_args, text = text_data)</a>
            else:
                input_args<a id="change"> = </a><a id="change">dict(**input_args, text_embed=text_data)</a>

            loss = model(**input_args)

            total_loss += loss * batches</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 13</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/4a59dea4cfad72176f35700296adfbc28e205598#diff-283456789c9565d0a8ad235fc41b44188f310b3043c3bcdeb6678f1958a57b51L41' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45476657</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: 4a59dea4cfad72176f35700296adfbc28e205598</div><div id='time'> Time: 2022-05-15</div><div id='author'> Author: 51308183+nousr@users.noreply.github.com</div><div id='file'> File Name: train_diffusion_prior.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: eval_model(5)</div><div id='n_method'> N Method Name: eval_model(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_diffusion_prior.py</div><div id='n_file'> N File Name: train_diffusion_prior.py</div><div id='m_start'> M Start Line: 41</div><div id='m_end'> M End Line: 57</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 61</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        total_loss = 0.
        total_samples = 0.

        for emb_images, <a id="change">emb_text</a> in <a id="change">zip(</a><a id="change">image_reader(batch_size=batch_size, start=start, end=end)</a>,
                <a id="change">text_reader(batch_size=batch_size, start=start, end=end))</a>:

            emb_images_tensor<a id="change"> = torch.tensor(emb_images[0]).to(</a>device<a id="change">)</a>
            emb_text_tensor = <a id="change">torch.tensor(</a>emb_text[0]<a id="change">)</a>.to(device)

            batches = emb_images_tensor.shape[0]
</code></pre><h3>After Change</h3><pre><code class='java'>
        total_loss = 0.
        total_samples = 0.

        for image_embeddings, text_data in <a id="change">tqdm(</a>dataloader<a id="change">)</a>:

            batches = image_embeddings.shape[0]

            input_args = dict(image_embed=image_embeddings)
            <a id="change">if text_conditioned</a>:
                input_args<a id="change"> = </a><a id="change">dict(**input_args, text = text_data)</a>
            else:
                input_args<a id="change"> = </a><a id="change">dict(**input_args, text_embed=text_data)</a>

            loss = model(**input_args)

            total_loss += loss * batches</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/4a59dea4cfad72176f35700296adfbc28e205598#diff-283456789c9565d0a8ad235fc41b44188f310b3043c3bcdeb6678f1958a57b51L41' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45476656</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: 4a59dea4cfad72176f35700296adfbc28e205598</div><div id='time'> Time: 2022-05-15</div><div id='author'> Author: 51308183+nousr@users.noreply.github.com</div><div id='file'> File Name: train_diffusion_prior.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: eval_model(5)</div><div id='n_method'> N Method Name: eval_model(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_diffusion_prior.py</div><div id='n_file'> N File Name: train_diffusion_prior.py</div><div id='m_start'> M Start Line: 41</div><div id='m_end'> M End Line: 57</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 61</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    for _ in range(epochs):

        for emb_images,<a id="change">emb_text</a> in <a id="change">zip(</a><a id="change">image_reader(batch_size=batch_size, start=0, end=train_set_size)</a>,
                <a id="change">text_reader(batch_size=batch_size, start=0, end=train_set_size))</a>:

            trainer.train()
            
            emb_images_tensor = <a id="change">torch.tensor(</a>emb_images[0]<a id="change">)</a>.to(device)
            emb_text_tensor<a id="change"> = torch.tensor(emb_text[0]).to(</a>device<a id="change">)</a>

            loss = trainer(text_embed = emb_text_tensor, image_embed = emb_images_tensor)

            &#47&#47 Samples per second</code></pre><h3>After Change</h3><pre><code class='java'>

    for _ in range(epochs):

        for image, text in <a id="change">tqdm(</a>train_loader<a id="change">)</a>:
            
            diffusion_prior.train()
            
            input_args = dict(image_embed=image)
            <a id="change">if dp_condition_on_text_encodings</a>:
                input_args<a id="change"> = </a><a id="change">dict(**input_args, text = text)</a>
            else:
                input_args<a id="change"> = </a><a id="change">dict(**input_args, text_embed=text)</a>

            loss = trainer(**input_args)

            &#47&#47 Samples per second</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/4a59dea4cfad72176f35700296adfbc28e205598#diff-283456789c9565d0a8ad235fc41b44188f310b3043c3bcdeb6678f1958a57b51L144' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45476688</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: 4a59dea4cfad72176f35700296adfbc28e205598</div><div id='time'> Time: 2022-05-15</div><div id='author'> Author: 51308183+nousr@users.noreply.github.com</div><div id='file'> File Name: train_diffusion_prior.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(32)</div><div id='n_method'> N Method Name: train(29)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_diffusion_prior.py</div><div id='n_file'> N File Name: train_diffusion_prior.py</div><div id='m_start'> M Start Line: 200</div><div id='m_end'> M End Line: 343</div><div id='n_start'> N Start Line: 179</div><div id='n_end'> N End Line: 369</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    tstart = train_set_size
    tend = train_set_size+NUM_TEST_EMBEDDINGS

    for embt, <a id="change">embi</a> in <a id="change">zip(</a><a id="change">text_reader(batch_size=NUM_TEST_EMBEDDINGS, start=tstart, end=tend)</a>, 
            <a id="change">image_reader(batch_size=NUM_TEST_EMBEDDINGS, start=tstart, end=tend))</a>:
       &#47&#47 make a copy of the text embeddings for shuffling
       text_embed = <a id="change">torch.tensor(</a>embt[0]<a id="change">)</a>.to(device)
       text_embed_shuffled = text_embed.clone()
        &#47&#47 roll the text embeddings to simulate "unrelated" captions
       rolled_idx = torch.roll(torch.arange(NUM_TEST_EMBEDDINGS), 1)
       text_embed_shuffled = text_embed_shuffled[rolled_idx]
       text_embed_shuffled = text_embed_shuffled / \
           text_embed_shuffled.norm(dim=1, keepdim=True)
       test_text_shuffled_cond = dict(text_embed=text_embed_shuffled)
        &#47&#47 prepare the text embedding
       text_embed = text_embed / text_embed.norm(dim=1, keepdim=True)
       test_text_cond = dict(text_embed=text_embed)
        &#47&#47 prepare image embeddings
       test_image_embeddings<a id="change"> = torch.tensor(embi[0]).to(</a>device<a id="change">)</a>
       test_image_embeddings = test_image_embeddings / \
           test_image_embeddings.norm(dim=1, keepdim=True)
        &#47&#47 predict on the unshuffled text embeddings
       predicted_image_embeddings = diffusion_prior.p_sample_loop(</code></pre><h3>After Change</h3><pre><code class='java'>

    cos = nn.CosineSimilarity(dim=1, eps=1e-6)

    for test_image_embeddings, text_data in <a id="change">tqdm(</a>dataloader<a id="change">)</a>:

        &#47&#47 we are text conditioned, we produce an embedding from the tokenized text
        <a id="change">if text_conditioned</a>:
            text_embedding, text_encodings, text_mask = diffusion_prior.clip.embed_text(
                text_data)
            text_cond<a id="change"> = </a><a id="change">dict(text_embed=text_embedding,
                             text_encodings=text_encodings, mask=text_mask)</a>
        else:
            text_embedding = text_data
            text_cond<a id="change"> = </a><a id="change">dict(text_embed=text_embedding)</a>

        &#47&#47 make a copy of the text embeddings for shuffling
        text_embed_shuffled = text_embedding.clone()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/4a59dea4cfad72176f35700296adfbc28e205598#diff-283456789c9565d0a8ad235fc41b44188f310b3043c3bcdeb6678f1958a57b51L63' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45476636</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: 4a59dea4cfad72176f35700296adfbc28e205598</div><div id='time'> Time: 2022-05-15</div><div id='author'> Author: 51308183+nousr@users.noreply.github.com</div><div id='file'> File Name: train_diffusion_prior.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: report_cosine_sims(3)</div><div id='n_method'> N Method Name: report_cosine_sims(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_diffusion_prior.py</div><div id='n_file'> N File Name: train_diffusion_prior.py</div><div id='m_start'> M Start Line: 63</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 73</div><div id='n_end'> N End Line: 119</div><BR>