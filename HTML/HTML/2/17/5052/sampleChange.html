<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        option.set_trt_cache_file(cache_file)
        &#47&#47 Need to enable collect shape for ernie
        if dynamic_shape is not None:
            <a id="change">option.enable_paddle_trt_collect_shape()</a>
            for key, shape_dict in dynamic_shape.items():
                option.set_trt_input_shape(
                    key,
                    min_shape=shape_dict["min_shape"],</code></pre><h3>After Change</h3><pre><code class='java'>
        option.paddle_infer_option.delete_pass(pass_name)
    if use_trt:
        option.paddle_infer_option.disable_trt_ops(disable_paddle_trt_ops)
        option.paddle_infer_option.enable_trt<a id="change"> = True</a>
        <a id="change">if use_fp16</a>:
            option.trt_option.enable_fp16<a id="change"> = True</a>
        else:
            &#47&#47 Note(zhoushunjie): These four passes don&quott support fp32 now.
            &#47&#47 Remove this line of code in future.
            only_fp16_passes<a id="change"> = </a><a id="change">[
                "trt_cross_multihead_matmul_fuse_pass"</a>,
                <a id="change">"trt_flash_multihead_matmul_fuse_pass"</a>,
                <a id="change">"preln_elementwise_groupnorm_act_pass"</a>,
                <a id="change">"elementwise_groupnorm_act_pass"</a>,
            ]
            <a id="change">for </a><a id="change">curr_pass</a> in only_fp16_passes<a id="change">:
                </a><a id="change">option.paddle_infer_option.delete_pass(curr_pass</a><a id="change">)</a>
        cache_file = os.path.join(model_dir, model_prefix, "_opt_cache/")
        option.set_trt_cache_file(cache_file)
        &#47&#47 Need to enable collect shape for ernie
        if dynamic_shape is not None:
            option.paddle_infer_option.collect_trt_shape<a id="change"> = True</a>
            for key, shape_dict in dynamic_shape.items():
                option.trt_option.set_shape(
                    key, shape_dict["min_shape"], shape_dict.get("opt_shape", None), shape_dict.get("max_shape", None)
                )</code></pre>