<html><h3>Pattern ID :5052
</h3><img src='17766159.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        option.set_trt_cache_file(cache_file)
        &#47&#47 Need to enable collect shape for ernie
        if dynamic_shape is not None:
            <a id="change">option.enable_paddle_trt_collect_shape()</a>
            for key, shape_dict in dynamic_shape.items():
                option.set_trt_input_shape(
                    key,
                    min_shape=shape_dict["min_shape"],</code></pre><h3>After Change</h3><pre><code class='java'>
        option.paddle_infer_option.delete_pass(pass_name)
    if use_trt:
        option.paddle_infer_option.disable_trt_ops(disable_paddle_trt_ops)
        option.paddle_infer_option.enable_trt<a id="change"> = True</a>
        <a id="change">if use_fp16</a>:
            option.trt_option.enable_fp16<a id="change"> = True</a>
        else:
            &#47&#47 Note(zhoushunjie): These four passes don&quott support fp32 now.
            &#47&#47 Remove this line of code in future.
            only_fp16_passes<a id="change"> = </a><a id="change">[
                "trt_cross_multihead_matmul_fuse_pass"</a>,
                <a id="change">"trt_flash_multihead_matmul_fuse_pass"</a>,
                <a id="change">"preln_elementwise_groupnorm_act_pass"</a>,
                <a id="change">"elementwise_groupnorm_act_pass"</a>,
            ]
            <a id="change">for </a><a id="change">curr_pass</a> in only_fp16_passes<a id="change">:
                </a><a id="change">option.paddle_infer_option.delete_pass(curr_pass</a><a id="change">)</a>
        cache_file = os.path.join(model_dir, model_prefix, "_opt_cache/")
        option.set_trt_cache_file(cache_file)
        &#47&#47 Need to enable collect shape for ernie
        if dynamic_shape is not None:
            option.paddle_infer_option.collect_trt_shape<a id="change"> = True</a>
            for key, shape_dict in dynamic_shape.items():
                option.trt_option.set_shape(
                    key, shape_dict["min_shape"], shape_dict.get("opt_shape", None), shape_dict.get("max_shape", None)
                )</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/40aeee11ddba93279d9c7cd2377e985185159d46#diff-89e5cfa6354423a955af53eb0fbb406811f0c7baddaadb1ebd6f3eded2b9ffd3L115' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17766159</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 40aeee11ddba93279d9c7cd2377e985185159d46</div><div id='time'> Time: 2023-03-08</div><div id='author'> Author: zhoushunjie@baidu.com</div><div id='file'> File Name: ppdiffusers/deploy/inpaint_legacy_infer.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: create_paddle_inference_runtime(9)</div><div id='n_method'> N Method Name: create_paddle_inference_runtime(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: ppdiffusers/deploy/inpaint_legacy_infer.py</div><div id='n_file'> N File Name: ppdiffusers/deploy/inpaint_legacy_infer.py</div><div id='m_start'> M Start Line: 115</div><div id='m_end'> M End Line: 137</div><div id='n_start'> N Start Line: 115</div><div id='n_end'> N End Line: 148</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        option.set_trt_cache_file(cache_file)
        &#47&#47 Need to enable collect shape for ernie
        if dynamic_shape is not None:
            <a id="change">option.enable_paddle_trt_collect_shape()</a>
            for key, shape_dict in dynamic_shape.items():
                option.set_trt_input_shape(
                    key,
                    min_shape=shape_dict["min_shape"],</code></pre><h3>After Change</h3><pre><code class='java'>
        option.paddle_infer_option.delete_pass(pass_name)
    if use_trt:
        option.paddle_infer_option.disable_trt_ops(disable_paddle_trt_ops)
        option.paddle_infer_option.enable_trt<a id="change"> = </a>True
        <a id="change">if use_fp16</a>:
            option.trt_option.enable_fp16<a id="change"> = </a>True
        else:
            &#47&#47 Note(zhoushunjie): These four passes don&quott support fp32 now.
            &#47&#47 Remove this line of code in future.
            only_fp16_passes<a id="change"> = </a><a id="change">[
                "trt_cross_multihead_matmul_fuse_pass"</a>,
                <a id="change">"trt_flash_multihead_matmul_fuse_pass"</a>,
                <a id="change">"preln_elementwise_groupnorm_act_pass"</a>,
                <a id="change">"elementwise_groupnorm_act_pass"</a>,
            ]
            <a id="change">for </a><a id="change">curr_pass</a> in only_fp16_passes<a id="change">:
                </a><a id="change">option.paddle_infer_option.delete_pass(</a>curr_pass<a id="change">)</a>
        cache_file = os.path.join(model_dir, model_prefix, "_opt_cache/")
        option.set_trt_cache_file(cache_file)
        &#47&#47 Need to enable collect shape for ernie
        if dynamic_shape is not None:
            option.paddle_infer_option.collect_trt_shape<a id="change"> = </a>True
            for key, shape_dict in dynamic_shape.items():
                option.trt_option.set_shape(
                    key, shape_dict["min_shape"], shape_dict.get("opt_shape", None), shape_dict.get("max_shape", None)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/40aeee11ddba93279d9c7cd2377e985185159d46#diff-89e5cfa6354423a955af53eb0fbb406811f0c7baddaadb1ebd6f3eded2b9ffd3L104' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17766158</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 40aeee11ddba93279d9c7cd2377e985185159d46</div><div id='time'> Time: 2023-03-08</div><div id='author'> Author: zhoushunjie@baidu.com</div><div id='file'> File Name: ppdiffusers/deploy/inpaint_legacy_infer.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: create_paddle_inference_runtime(9)</div><div id='n_method'> N Method Name: create_paddle_inference_runtime(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: ppdiffusers/deploy/inpaint_legacy_infer.py</div><div id='n_file'> N File Name: ppdiffusers/deploy/inpaint_legacy_infer.py</div><div id='m_start'> M Start Line: 115</div><div id='m_end'> M End Line: 137</div><div id='n_start'> N Start Line: 115</div><div id='n_end'> N End Line: 148</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        option.set_trt_cache_file(cache_file)
        &#47&#47 Need to enable collect shape for ernie
        if dynamic_shape is not None:
            <a id="change">option.enable_paddle_trt_collect_shape()</a>
            for key, shape_dict in dynamic_shape.items():
                option.set_trt_input_shape(
                    key,
                    min_shape=shape_dict["min_shape"],</code></pre><h3>After Change</h3><pre><code class='java'>
        option.paddle_infer_option.delete_pass(pass_name)
    if use_trt:
        option.paddle_infer_option.disable_trt_ops(disable_paddle_trt_ops)
        option.paddle_infer_option.enable_trt<a id="change"> = </a>True
        <a id="change">if use_fp16</a>:
            option.trt_option.enable_fp16<a id="change"> = </a>True
        else:
            &#47&#47 Note(zhoushunjie): These four passes don&quott support fp32 now.
            &#47&#47 Remove this line of code in future.
            only_fp16_passes<a id="change"> = </a><a id="change">[
                "trt_cross_multihead_matmul_fuse_pass"</a>,
                <a id="change">"trt_flash_multihead_matmul_fuse_pass"</a>,
                <a id="change">"preln_elementwise_groupnorm_act_pass"</a>,
                <a id="change">"elementwise_groupnorm_act_pass"</a>,
            ]
            <a id="change">for </a><a id="change">curr_pass</a> in only_fp16_passes<a id="change">:
                </a><a id="change">option.paddle_infer_option.delete_pass(</a>curr_pass<a id="change">)</a>
        cache_file = os.path.join(model_dir, model_prefix, "_opt_cache/")
        option.set_trt_cache_file(cache_file)
        &#47&#47 Need to enable collect shape for ernie
        if dynamic_shape is not None:
            option.paddle_infer_option.collect_trt_shape<a id="change"> = </a>True
            for key, shape_dict in dynamic_shape.items():
                option.trt_option.set_shape(
                    key, shape_dict["min_shape"], shape_dict.get("opt_shape", None), shape_dict.get("max_shape", None)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/40aeee11ddba93279d9c7cd2377e985185159d46#diff-fe0a189e2e820165e0147b2dfdca5a7c6dd3dbb0e4f0fcd331b08ea38e9ebcdcL106' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17766174</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 40aeee11ddba93279d9c7cd2377e985185159d46</div><div id='time'> Time: 2023-03-08</div><div id='author'> Author: zhoushunjie@baidu.com</div><div id='file'> File Name: ppdiffusers/deploy/img_to_img_infer.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: create_paddle_inference_runtime(9)</div><div id='n_method'> N Method Name: create_paddle_inference_runtime(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: ppdiffusers/deploy/img_to_img_infer.py</div><div id='n_file'> N File Name: ppdiffusers/deploy/img_to_img_infer.py</div><div id='m_start'> M Start Line: 117</div><div id='m_end'> M End Line: 139</div><div id='n_start'> N Start Line: 117</div><div id='n_end'> N End Line: 150</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        option.set_trt_cache_file(cache_file)
        &#47&#47 Need to enable collect shape for ernie
        if dynamic_shape is not None:
            <a id="change">option.enable_paddle_trt_collect_shape()</a>
            for key, shape_dict in dynamic_shape.items():
                option.set_trt_input_shape(
                    key,
                    min_shape=shape_dict["min_shape"],</code></pre><h3>After Change</h3><pre><code class='java'>
        option.paddle_infer_option.delete_pass(pass_name)
    if use_trt:
        option.paddle_infer_option.disable_trt_ops(disable_paddle_trt_ops)
        option.paddle_infer_option.enable_trt<a id="change"> = </a>True
        <a id="change">if use_fp16</a>:
            option.trt_option.enable_fp16<a id="change"> = </a>True
        else:
            &#47&#47 Note(zhoushunjie): These four passes don&quott support fp32 now.
            &#47&#47 Remove this line of code in future.
            only_fp16_passes<a id="change"> = </a><a id="change">[
                "trt_cross_multihead_matmul_fuse_pass"</a>,
                <a id="change">"trt_flash_multihead_matmul_fuse_pass"</a>,
                <a id="change">"preln_elementwise_groupnorm_act_pass"</a>,
                <a id="change">"elementwise_groupnorm_act_pass"</a>,
            ]
            <a id="change">for </a><a id="change">curr_pass</a> in only_fp16_passes<a id="change">:
                </a><a id="change">option.paddle_infer_option.delete_pass(</a>curr_pass<a id="change">)</a>
        cache_file = os.path.join(model_dir, model_prefix, "_opt_cache/")
        option.set_trt_cache_file(cache_file)
        &#47&#47 Need to enable collect shape for ernie
        if dynamic_shape is not None:
            option.paddle_infer_option.collect_trt_shape<a id="change"> = </a>True
            for key, shape_dict in dynamic_shape.items():
                option.trt_option.set_shape(
                    key, shape_dict["min_shape"], shape_dict.get("opt_shape", None), shape_dict.get("max_shape", None)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/40aeee11ddba93279d9c7cd2377e985185159d46#diff-b23127166a0fb5dfc4e38602522352ade0bfd03a7cb1a1891f5101172258ca66L104' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17766154</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 40aeee11ddba93279d9c7cd2377e985185159d46</div><div id='time'> Time: 2023-03-08</div><div id='author'> Author: zhoushunjie@baidu.com</div><div id='file'> File Name: ppdiffusers/deploy/inpaint_infer.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: create_paddle_inference_runtime(9)</div><div id='n_method'> N Method Name: create_paddle_inference_runtime(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: ppdiffusers/deploy/inpaint_infer.py</div><div id='n_file'> N File Name: ppdiffusers/deploy/inpaint_infer.py</div><div id='m_start'> M Start Line: 115</div><div id='m_end'> M End Line: 137</div><div id='n_start'> N Start Line: 115</div><div id='n_end'> N End Line: 148</div><BR>