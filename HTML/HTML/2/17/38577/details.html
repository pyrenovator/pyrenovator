<html><h3>Pattern ID :38577
</h3><img src='110376084.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            char_lens = torch.cat([char_lens, char_lens], dim=0)
        loss = params.ctc_cost(pout, chars, pout_lens, char_lens)

        stats<a id="change"> = </a><a id="change">{}</a>
        if stage != "train":
            ind2lab = params.train_loader.label_dict["char"]["index2lab"]
            sequence = ctc_greedy_decode(pout, pout_lens, blank_id=-1)
            char_seq<a id="change"> = </a><a id="change">convert_index_to_lab(</a>sequence, <a id="change">ind2lab</a><a id="change">)</a>
            word_seq = merge_char(char_seq)
            chars<a id="change"> = </a><a id="change">undo_padding(</a>chars, char_lens<a id="change">)</a>
            chars<a id="change"> = </a><a id="change">convert_index_to_lab(</a>chars, <a id="change">ind2lab</a><a id="change">)</a>
            words = merge_char(chars)
            cer_stats<a id="change"> = </a><a id="change">edit_distance.wer_details_for_batch(
                </a>ids, chars, char_seq<a id="change">, compute_alignments=True
            )</a>
            wer_stats = edit_distance.wer_details_for_batch(
                ids, words, word_seq, compute_alignments=True
            )
            stats["CER"]<a id="change"> = </a>cer_stats
            stats["WER"] = wer_stats
        return loss<a id="change">, stats</a>

    def fit_batch(self, batch):
        inputs, targets = batch
        predictions = self.compute_forward(inputs)</code></pre><h3>After Change</h3><pre><code class='java'>

        if stage != sb.Stage.TRAIN:
            sequence = ctc_greedy_decode(pout, pout_lens, blank_id=-1)
            <a id="change">self.cer_metric.append(
                ids</a>, sequence, <a id="change">chars</a>, char_lens, self.ind2lab<a id="change">
            )</a>
            <a id="change">self.wer_metric.append(
                ids</a>, sequence, <a id="change">chars</a>, char_lens, self.ind2lab<a id="change">
            )</a>

        return loss

    def on_stage_start(self, stage, epoch=None):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 14</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/f99935e22d4ccb4dc7118ccc6e0960276d2a7c2e#diff-1e446a48e9ee0d179c098c95bbc48d47c154f3d625c3cc783146741cf860b00cL39' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110376084</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: f99935e22d4ccb4dc7118ccc6e0960276d2a7c2e</div><div id='time'> Time: 2020-09-11</div><div id='author'> Author: plantinga.peter@protonmail.com</div><div id='file'> File Name: recipes/LibriSpeech/ASR/CTC/experiment.py</div><div id='m_class'> M Class Name: ASR</div><div id='n_method'> N Class Name: ASR</div><div id='m_method'> M Method Name: compute_objectives(4)</div><div id='n_method'> N Method Name: compute_objectives(4)</div><div id='m_parent_class'> M Parent Class: sb.Brain</div><div id='n_parent_class'> N Parent Class: sb.core.Brain</div><div id='m_file'> M File Name: recipes/LibriSpeech/ASR/CTC/experiment.py</div><div id='n_file'> N File Name: recipes/LibriSpeech/ASR/CTC/experiment.py</div><div id='m_start'> M Start Line: 77</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 39</div><div id='n_end'> N End Line: 50</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            char_lens = torch.cat([char_lens, char_lens], dim=0)
        loss = params.ctc_cost(pout, chars, pout_lens, char_lens)

        stats<a id="change"> = </a><a id="change">{}</a>
        if stage != "train":
            <a id="change">ind2lab</a> = params.train_loader.label_dict["char"]["index2lab"]
            sequence = ctc_greedy_decode(pout, pout_lens, blank_id=-1)
            char_seq = <a id="change">convert_index_to_lab(</a>sequence, ind2lab<a id="change">)</a>
            word_seq<a id="change"> = </a>merge_char(char_seq)
            chars<a id="change"> = </a><a id="change">undo_padding(</a>chars, char_lens<a id="change">)</a>
            chars<a id="change"> = </a><a id="change">convert_index_to_lab(</a>chars, ind2lab<a id="change">)</a>
            words = merge_char(chars)
            cer_stats = edit_distance.wer_details_for_batch(
                ids, chars, char_seq, compute_alignments=True
            )
            wer_stats<a id="change"> = </a><a id="change">edit_distance.wer_details_for_batch(
                </a>ids, words, word_seq<a id="change">, compute_alignments=True
            )</a>
            stats["CER"] = cer_stats
            stats["WER"]<a id="change"> = </a>wer_stats
        return loss<a id="change">, stats</a>

    def fit_batch(self, batch):
        inputs, targets = batch
        predictions = self.compute_forward(inputs)</code></pre><h3>After Change</h3><pre><code class='java'>

        if stage != sb.Stage.TRAIN:
            sequence = ctc_greedy_decode(pout, pout_lens, blank_id=-1)
            <a id="change">self.cer_metric.append(
                </a>ids, sequence, chars, char_lens, self.ind2lab<a id="change">
            )</a>
            <a id="change">self.wer_metric.append(
                </a>ids, sequence, chars, char_lens, self.ind2lab<a id="change">
            )</a>

        return loss

    def on_stage_start(self, stage, epoch=None):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/f99935e22d4ccb4dc7118ccc6e0960276d2a7c2e#diff-1e446a48e9ee0d179c098c95bbc48d47c154f3d625c3cc783146741cf860b00cL69' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110376085</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: f99935e22d4ccb4dc7118ccc6e0960276d2a7c2e</div><div id='time'> Time: 2020-09-11</div><div id='author'> Author: plantinga.peter@protonmail.com</div><div id='file'> File Name: recipes/LibriSpeech/ASR/CTC/experiment.py</div><div id='m_class'> M Class Name: ASR</div><div id='n_method'> N Class Name: ASR</div><div id='m_method'> M Method Name: compute_objectives(4)</div><div id='n_method'> N Method Name: compute_objectives(4)</div><div id='m_parent_class'> M Parent Class: sb.Brain</div><div id='n_parent_class'> N Parent Class: sb.core.Brain</div><div id='m_file'> M File Name: recipes/LibriSpeech/ASR/CTC/experiment.py</div><div id='n_file'> N File Name: recipes/LibriSpeech/ASR/CTC/experiment.py</div><div id='m_start'> M Start Line: 77</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 39</div><div id='n_end'> N End Line: 50</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        loss_seq = params.seq_cost(p_seq, phns_with_eos, length=rel_length)
        loss = params.ctc_weight * loss_ctc + (1 - params.ctc_weight) * loss_seq

        stats<a id="change"> = </a><a id="change">{}</a>
        if stage != "train":
            <a id="change">ind2lab</a> = params.train_loader.label_dict["phn"]["index2lab"]
            sequence<a id="change"> = </a><a id="change">convert_index_to_lab(</a>hyps, ind2lab<a id="change">)</a>
            phns<a id="change"> = </a><a id="change">undo_padding(</a>phns, phn_lens<a id="change">)</a>
            phns<a id="change"> = </a><a id="change">convert_index_to_lab(</a>phns, ind2lab<a id="change">)</a>
            per_stats<a id="change"> = </a><a id="change">edit_distance.wer_details_for_batch(
                </a>ids, phns, sequence<a id="change">, compute_alignments=True
            )</a>
            stats["PER"]<a id="change"> = </a>per_stats
        return loss<a id="change">, stats</a>

    def fit_batch(self, batch):
        inputs, targets = batch
        predictions = self.compute_forward(inputs, targets)</code></pre><h3>After Change</h3><pre><code class='java'>
        loss = self.ctc_weight * loss_ctc + (1 - self.ctc_weight) * loss_seq

        &#47&#47 Record losses for posterity
        <a id="change">self.ctc_metrics.append(</a>ids, p_ctc, phns, wav_lens, phn_lens<a id="change">)</a>
        self.seq_metrics.append(ids, p_seq, phns_with_eos, rel_length)
        if stage != sb.Stage.TRAIN:
            <a id="change">self.per_metrics.append(</a>ids, hyps, phns, phn_lens, self.ind2lab<a id="change">)</a>

        return loss

    def fit_batch(self, batch):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/530a3c9f6e2f4cd6f5ada9f814f426b6686d2aa0#diff-fdf75244812c06c4beefdad73256a828c2cd10262ed01d2aa6a93bade6e4feccL110' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110376087</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 530a3c9f6e2f4cd6f5ada9f814f426b6686d2aa0</div><div id='time'> Time: 2020-09-01</div><div id='author'> Author: plantinga.peter@protonmail.com</div><div id='file'> File Name: recipes/TIMIT/ASR_seq2seq/experiment.py</div><div id='m_class'> M Class Name: ASR</div><div id='n_method'> N Class Name: ASR</div><div id='m_method'> M Method Name: compute_objectives(4)</div><div id='n_method'> N Method Name: compute_objectives(4)</div><div id='m_parent_class'> M Parent Class: sb.Brain</div><div id='n_parent_class'> N Parent Class: sb.core.Brain</div><div id='m_file'> M File Name: recipes/TIMIT/ASR_seq2seq/experiment.py</div><div id='n_file'> N File Name: recipes/TIMIT/ASR_seq2seq/experiment.py</div><div id='m_start'> M Start Line: 111</div><div id='m_end'> M End Line: 148</div><div id='n_start'> N Start Line: 55</div><div id='n_end'> N End Line: 88</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        pout, pout_lens = predictions
        ids, phns, phn_lens = targets
        phns, phn_lens = phns.to(params.device), phn_lens.to(params.device)
        stats<a id="change"> = </a><a id="change">{}</a>

        if stage == "train":
            if hasattr(params, "env_corrupt"):
                phns = torch.cat([phns, phns], dim=0)
                phn_lens = torch.cat([phn_lens, phn_lens], dim=0)
            loss = params.compute_cost(pout, phns, pout_lens, phn_lens)
        else:
            loss = params.compute_cost(pout, phns, pout_lens, phn_lens)
            <a id="change">ind2lab</a> = params.train_loader.label_dict["phn"]["index2lab"]
            sequence = ctc_greedy_decode(pout, pout_lens, blank_id=-1)
            sequence<a id="change"> = </a><a id="change">convert_index_to_lab(</a>sequence, ind2lab<a id="change">)</a>
            phns<a id="change"> = </a><a id="change">undo_padding(</a>phns, phn_lens<a id="change">)</a>
            phns<a id="change"> = </a><a id="change">convert_index_to_lab(</a>phns, ind2lab<a id="change">)</a>
            per_stats<a id="change"> = </a><a id="change">edit_distance.wer_details_for_batch(
                </a>ids, phns, sequence<a id="change">, compute_alignments=True
            )</a>
            stats["PER"]<a id="change"> = </a>per_stats
        return loss<a id="change">, stats</a>

    def on_epoch_end(self, epoch, train_stats, valid_stats=None):
        per = summarize_error_rate(valid_stats["PER"])
        old_lr, new_lr = params.lr_annealing([params.optimizer], epoch, per)</code></pre><h3>After Change</h3><pre><code class='java'>
            loss = params.compute_cost(pout, phns, pout_lens, phn_lens)
            ind2lab = params.train_loader.label_dict["phn"]["index2lab"]
            sequence = ctc_greedy_decode(pout, pout_lens, blank_id=-1)
            <a id="change">self.stats[stage]["PER"].append(
                </a>ids, sequence, phns<a id="change">, target_len=phn_lens, ind2lab=ind2lab
            )</a>

        <a id="change">self.stats[stage]["loss"].append(</a>ids, pout, phns, pout_lens, phn_lens<a id="change">)</a>
        return loss

    def on_epoch_start(self, epoch):
        self.stats = {</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/e3d4eee7f563a8cc5130b487af9956f70f2d4956#diff-2ee084344967a526c2ad2831a4820a7c58dbf3aaba30042ae50c0500eddd7a08L54' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110376095</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: e3d4eee7f563a8cc5130b487af9956f70f2d4956</div><div id='time'> Time: 2020-08-10</div><div id='author'> Author: plantinga.peter@protonmail.com</div><div id='file'> File Name: recipes/TIMIT/ASR_CTC/experiment.py</div><div id='m_class'> M Class Name: ASR</div><div id='n_method'> N Class Name: ASR</div><div id='m_method'> M Method Name: compute_objectives(4)</div><div id='n_method'> N Method Name: compute_objectives(4)</div><div id='m_parent_class'> M Parent Class: sb.core.Brain</div><div id='n_parent_class'> N Parent Class: sb.core.Brain</div><div id='m_file'> M File Name: recipes/TIMIT/ASR_CTC/experiment.py</div><div id='n_file'> N File Name: recipes/TIMIT/ASR_CTC/experiment.py</div><div id='m_start'> M Start Line: 58</div><div id='m_end'> M End Line: 76</div><div id='n_start'> N Start Line: 62</div><div id='n_end'> N End Line: 68</div><BR>