<html><h3>Pattern ID :1699
</h3><img src='8143228.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    losses = AverageMeter(&quotLoss&quot, &quot:3.2f&quot)
    trans_losses = AverageMeter(&quotTrans Loss&quot, &quot:5.4f&quot)
    cls_accs = AverageMeter(&quotCls Acc&quot, &quot:3.1f&quot)
    tgt_accs<a id="change"> = </a><a id="change">AverageMeter(&quotTgt Acc&quot</a>, <a id="change">&quot:3.1f&quot</a><a id="change">)</a>

    progress = ProgressMeter(
        args.iters_per_epoch,
        [batch_time, data_time, losses, trans_losses, cls_accs, tgt_accs],
        prefix="Epoch: [{}]".format(epoch))

    &#47&#47 switch to train mode
    model.train()
    jmmd_loss.train()

    end = time.time()
    for i in range(args.iters_per_epoch):
        x_s, labels_s = next(train_source_iter)
        x_t, labels_t = next(train_target_iter)

        x_s = x_s.to(device)
        x_t = x_t.to(device)
        labels_s = labels_s.to(device)
        labels_t<a id="change"> = </a><a id="change">labels_t.to(</a>device<a id="change">)</a>

        &#47&#47 measure data loading time
        data_time.update(time.time() - end)

        &#47&#47 compute output
        x = torch.cat((x_s, x_t), dim=0)
        y, f = model(x)
        y_s, y_t = y.chunk(2, dim=0)
        f_s, f_t = f.chunk(2, dim=0)

        cls_loss = F.cross_entropy(y_s, labels_s)
        transfer_loss = jmmd_loss(
            (f_s, F.softmax(y_s, dim=1)),
            (f_t, F.softmax(y_t, dim=1))
        )
        loss = cls_loss + transfer_loss * args.trade_off

        cls_acc = accuracy(y_s, labels_s)[0]
        tgt_acc<a id="change"> = </a><a id="change">accuracy(y_t, labels_t)[0]</a>

        losses.update(loss.item(), x_s.size(0))
        cls_accs.update(cls_acc.item(), x_s.size(0))
        <a id="change">tgt_accs.update(tgt_acc.item()</a>, <a id="change">x_t.size(0</a><a id="change">))</a>
        trans_losses.update(transfer_loss.item(), x_s.size(0))

        &#47&#47 compute gradient and do SGD step
        optimizer.zero_grad()</code></pre><h3>After Change</h3><pre><code class='java'>
    end = time.time()
    for i in range(args.iters_per_epoch):
        x_s, labels_s = next(train_source_iter)[:2]
        x_t, = <a id="change">next(train_target_iter)[:1]</a>

        x_s = x_s.to(device)
        x_t = x_t.to(device)
        labels_s = labels_s.to(device)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 6</div><BR><div id='size'>Non-data size: 12</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/e67c5c44b5082e84a56d7d6480d9c71a7f6a2fc0#diff-3061439f129585d652373903ef6faad4951f7865718049c26a23c8008c2d6516L160' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8143228</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: e67c5c44b5082e84a56d7d6480d9c71a7f6a2fc0</div><div id='time'> Time: 2022-02-10</div><div id='author'> Author: 13126830206@163.com</div><div id='file'> File Name: examples/domain_adaptation/image_classification/jan.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(8)</div><div id='n_method'> N Method Name: train(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/domain_adaptation/image_classification/jan.py</div><div id='n_file'> N File Name: examples/domain_adaptation/image_classification/jan.py</div><div id='m_start'> M Start Line: 160</div><div id='m_end'> M End Line: 202</div><div id='n_start'> N Start Line: 170</div><div id='n_end'> N End Line: 171</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    losses = AverageMeter(&quotLoss&quot, &quot:3.2f&quot)
    trans_losses = AverageMeter(&quotTrans Loss&quot, &quot:5.4f&quot)
    cls_accs = AverageMeter(&quotCls Acc&quot, &quot:3.1f&quot)
    tgt_accs<a id="change"> = </a><a id="change">AverageMeter(&quotTgt Acc&quot</a>, <a id="change">&quot:3.1f&quot</a><a id="change">)</a>

    progress = ProgressMeter(
        args.iters_per_epoch,
        [batch_time, data_time, losses, trans_losses, cls_accs, tgt_accs],
        prefix="Epoch: [{}]".format(epoch))

    &#47&#47 switch to train mode
    model.train()
    mkmmd_loss.train()

    end = time.time()
    for i in range(args.iters_per_epoch):
        x_s, labels_s = next(train_source_iter)
        x_t, labels_t = next(train_target_iter)

        x_s = x_s.to(device)
        x_t = x_t.to(device)
        labels_s = labels_s.to(device)
        labels_t<a id="change"> = </a><a id="change">labels_t.to(</a>device<a id="change">)</a>

        &#47&#47 measure data loading time
        data_time.update(time.time() - end)

        &#47&#47 compute output
        y_s, f_s = model(x_s)
        y_t, f_t = model(x_t)

        cls_loss = F.cross_entropy(y_s, labels_s)
        transfer_loss = mkmmd_loss(f_s, f_t)
        loss = cls_loss + transfer_loss * args.trade_off

        cls_acc = accuracy(y_s, labels_s)[0]
        tgt_acc<a id="change"> = </a><a id="change">accuracy(y_t, labels_t)[0]</a>

        losses.update(loss.item(), x_s.size(0))
        cls_accs.update(cls_acc.item(), x_s.size(0))
        <a id="change">tgt_accs.update(tgt_acc.item()</a>, <a id="change">x_t.size(0</a><a id="change">))</a>
        trans_losses.update(transfer_loss.item(), x_s.size(0))

        &#47&#47 compute gradient and do SGD step
        optimizer.zero_grad()</code></pre><h3>After Change</h3><pre><code class='java'>
    end = time.time()
    for i in range(args.iters_per_epoch):
        x_s, labels_s = next(train_source_iter)[:2]
        x_t, = <a id="change">next(train_target_iter)[:1]</a>
        x_s = x_s.to(device)
        x_t = x_t.to(device)
        labels_s = labels_s.to(device)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/e67c5c44b5082e84a56d7d6480d9c71a7f6a2fc0#diff-e25afe18851d1826c8f3cbe365a9873bbda77df31aa4067b4faf7951b2caf20fL141' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8143229</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: e67c5c44b5082e84a56d7d6480d9c71a7f6a2fc0</div><div id='time'> Time: 2022-02-10</div><div id='author'> Author: 13126830206@163.com</div><div id='file'> File Name: examples/domain_adaptation/image_classification/dan.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(8)</div><div id='n_method'> N Method Name: train(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/domain_adaptation/image_classification/dan.py</div><div id='n_file'> N File Name: examples/domain_adaptation/image_classification/dan.py</div><div id='m_start'> M Start Line: 149</div><div id='m_end'> M End Line: 186</div><div id='n_start'> N Start Line: 159</div><div id='n_end'> N End Line: 160</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    src_feature_norm = AverageMeter(&quotSource Feature Norm&quot, &quot:3.2f&quot)
    tgt_feature_norm = AverageMeter(&quotTarget Feature Norm&quot, &quot:3.2f&quot)
    cls_accs = AverageMeter(&quotCls Acc&quot, &quot:3.1f&quot)
    tgt_accs<a id="change"> = </a><a id="change">AverageMeter(&quotTgt Acc&quot</a>, <a id="change">&quot:3.1f&quot</a><a id="change">)</a>

    progress = ProgressMeter(
        args.iters_per_epoch,
        [batch_time, data_time, cls_losses, norm_losses, src_feature_norm, tgt_feature_norm, cls_accs, tgt_accs],
        prefix="Epoch: [{}]".format(epoch))

    &#47&#47 switch to train mode
    model.train()

    end = time.time()
    for i in range(args.iters_per_epoch):
        x_s, labels_s = next(train_source_iter)
        x_t, labels_t = next(train_target_iter)

        x_s = x_s.to(device)
        x_t = x_t.to(device)
        labels_s = labels_s.to(device)
        labels_t<a id="change"> = </a><a id="change">labels_t.to(</a>device<a id="change">)</a>

        &#47&#47 measure data loading time
        data_time.update(time.time() - end)

        &#47&#47 compute output
        y_s, f_s = model(x_s)
        y_t, f_t = model(x_t)

        &#47&#47 classification loss
        cls_loss = F.cross_entropy(y_s, labels_s)
        &#47&#47 norm loss
        norm_loss = adaptive_feature_norm(f_s) + adaptive_feature_norm(f_t)
        loss = cls_loss + norm_loss * args.trade_off_norm

        &#47&#47 using entropy minimization
        if args.trade_off_entropy:
            y_t = F.softmax(y_t, dim=1)
            entropy_loss = entropy(y_t, reduction=&quotmean&quot)
            loss += entropy_loss * args.trade_off_entropy

        &#47&#47 compute gradient and do SGD step
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        &#47&#47 update statistics
        cls_acc = accuracy(y_s, labels_s)[0]
        tgt_acc<a id="change"> = </a><a id="change">accuracy(y_t, labels_t)[0]</a>

        cls_losses.update(cls_loss.item(), x_s.size(0))
        norm_losses.update(norm_loss.item(), x_s.size(0))
        src_feature_norm.update(f_s.norm(p=2, dim=1).mean().item(), x_s.size(0))
        tgt_feature_norm.update(f_t.norm(p=2, dim=1).mean().item(), x_s.size(0))
        cls_accs.update(cls_acc.item(), x_s.size(0))
        <a id="change">tgt_accs.update(tgt_acc.item()</a>, <a id="change">x_s.size(0</a><a id="change">))</a>

        &#47&#47 measure elapsed time
        batch_time.update(time.time() - end)
        end = time.time()</code></pre><h3>After Change</h3><pre><code class='java'>

    end = time.time()
    for i in range(args.iters_per_epoch):
        x_s, labels_s = <a id="change">next(train_source_iter)[:2]</a>
        x_t, = next(train_target_iter)[:1]

        x_s = x_s.to(device)
        x_t = x_t.to(device)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/e67c5c44b5082e84a56d7d6480d9c71a7f6a2fc0#diff-f44d27ac6d6ea04cc8966b9da0ff33bd73ec628af90638807197d76d499ab383L135' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8143230</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: e67c5c44b5082e84a56d7d6480d9c71a7f6a2fc0</div><div id='time'> Time: 2022-02-10</div><div id='author'> Author: 13126830206@163.com</div><div id='file'> File Name: examples/domain_adaptation/image_classification/afn.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(7)</div><div id='n_method'> N Method Name: train(7)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/domain_adaptation/image_classification/afn.py</div><div id='n_file'> N File Name: examples/domain_adaptation/image_classification/afn.py</div><div id='m_start'> M Start Line: 144</div><div id='m_end'> M End Line: 197</div><div id='n_start'> N Start Line: 153</div><div id='n_end'> N End Line: 154</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    losses = AverageMeter(&quotLoss&quot, &quot:3.2f&quot)
    trans_losses = AverageMeter(&quotTrans Loss&quot, &quot:3.2f&quot)
    cls_accs = AverageMeter(&quotCls Acc&quot, &quot:3.1f&quot)
    tgt_accs<a id="change"> = </a><a id="change">AverageMeter(&quotTgt Acc&quot</a>, <a id="change">&quot:3.1f&quot</a><a id="change">)</a>

    progress = ProgressMeter(
        args.iters_per_epoch,
        [batch_time, data_time, losses, trans_losses, cls_accs, tgt_accs],
        prefix="Epoch: [{}]".format(epoch))

    &#47&#47 switch to train mode
    G.train()
    F1.train()
    F2.train()

    end = time.time()
    for i in range(args.iters_per_epoch):
        x_s, labels_s = next(train_source_iter)
        x_t, labels_t = next(train_target_iter)

        x_s = x_s.to(device)
        x_t = x_t.to(device)
        labels_s = labels_s.to(device)
        labels_t<a id="change"> = </a><a id="change">labels_t.to(</a>device<a id="change">)</a>
        x = torch.cat((x_s, x_t), dim=0)
        assert x.requires_grad is False

        &#47&#47 measure data loading time
        data_time.update(time.time() - end)

        &#47&#47 Step A train all networks to minimize loss on source domain
        optimizer_g.zero_grad()
        optimizer_f.zero_grad()

        g = G(x)
        y_1 = F1(g)
        y_2 = F2(g)
        y1_s, y1_t = y_1.chunk(2, dim=0)
        y2_s, y2_t = y_2.chunk(2, dim=0)

        y1_t, y2_t = F.softmax(y1_t, dim=1), F.softmax(y2_t, dim=1)
        loss = F.cross_entropy(y1_s, labels_s) + F.cross_entropy(y2_s, labels_s) + \
               (entropy(y1_t) + entropy(y2_t)) * args.trade_off_entropy
        loss.backward()
        optimizer_g.step()
        optimizer_f.step()

        &#47&#47 Step B train classifier to maximize discrepancy
        optimizer_g.zero_grad()
        optimizer_f.zero_grad()

        g = G(x)
        y_1 = F1(g)
        y_2 = F2(g)
        y1_s, y1_t = y_1.chunk(2, dim=0)
        y2_s, y2_t = y_2.chunk(2, dim=0)
        y1_t, y2_t = F.softmax(y1_t, dim=1), F.softmax(y2_t, dim=1)
        loss = F.cross_entropy(y1_s, labels_s) + F.cross_entropy(y2_s, labels_s) + \
               (entropy(y1_t) + entropy(y2_t)) * args.trade_off_entropy - \
               classifier_discrepancy(y1_t, y2_t) * args.trade_off
        loss.backward()
        optimizer_f.step()

        &#47&#47 Step C train genrator to minimize discrepancy
        for k in range(args.num_k):
            optimizer_g.zero_grad()
            g = G(x)
            y_1 = F1(g)
            y_2 = F2(g)
            y1_s, y1_t = y_1.chunk(2, dim=0)
            y2_s, y2_t = y_2.chunk(2, dim=0)
            y1_t, y2_t = F.softmax(y1_t, dim=1), F.softmax(y2_t, dim=1)
            mcd_loss = classifier_discrepancy(y1_t, y2_t) * args.trade_off
            mcd_loss.backward()
            optimizer_g.step()

        cls_acc = accuracy(y1_s, labels_s)[0]
        tgt_acc<a id="change"> = </a><a id="change">accuracy(y1_t, labels_t)[0]</a>

        losses.update(loss.item(), x_s.size(0))
        cls_accs.update(cls_acc.item(), x_s.size(0))
        <a id="change">tgt_accs.update(tgt_acc.item()</a>, <a id="change">x_t.size(0</a><a id="change">))</a>
        trans_losses.update(mcd_loss.item(), x_s.size(0))

        &#47&#47 measure elapsed time
        batch_time.update(time.time() - end)</code></pre><h3>After Change</h3><pre><code class='java'>

    end = time.time()
    for i in range(args.iters_per_epoch):
        x_s, labels_s = <a id="change">next(train_source_iter)[:2]</a>
        x_t, = next(train_target_iter)[:1]

        x_s = x_s.to(device)
        x_t = x_t.to(device)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/e67c5c44b5082e84a56d7d6480d9c71a7f6a2fc0#diff-4ee109cb2382d75a3e5415a216cc9d379ff14fb70da71f262fd3f0552b76b73aL150' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8143224</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: e67c5c44b5082e84a56d7d6480d9c71a7f6a2fc0</div><div id='time'> Time: 2022-02-10</div><div id='author'> Author: 13126830206@163.com</div><div id='file'> File Name: examples/domain_adaptation/image_classification/mcd.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(9)</div><div id='n_method'> N Method Name: train(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/domain_adaptation/image_classification/mcd.py</div><div id='n_file'> N File Name: examples/domain_adaptation/image_classification/mcd.py</div><div id='m_start'> M Start Line: 158</div><div id='m_end'> M End Line: 236</div><div id='n_start'> N Start Line: 169</div><div id='n_end'> N End Line: 170</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    losses = AverageMeter(&quotLoss&quot, &quot:3.2f&quot)
    trans_losses = AverageMeter(&quotTrans Loss&quot, &quot:3.2f&quot)
    cls_accs = AverageMeter(&quotCls Acc&quot, &quot:3.1f&quot)
    tgt_accs<a id="change"> = </a><a id="change">AverageMeter(&quotTgt Acc&quot</a>, <a id="change">&quot:3.1f&quot</a><a id="change">)</a>

    progress = ProgressMeter(
        args.iters_per_epoch,
        [batch_time, data_time, losses, trans_losses, cls_accs, tgt_accs],
        prefix="Epoch: [{}]".format(epoch))

    &#47&#47 switch to train mode
    classifier.train()
    mdd.train()

    end = time.time()
    for i in range(args.iters_per_epoch):
        optimizer.zero_grad()

        x_s, labels_s = next(train_source_iter)
        x_t, labels_t = next(train_target_iter)

        x_s = x_s.to(device)
        x_t = x_t.to(device)
        labels_s = labels_s.to(device)
        labels_t<a id="change"> = </a><a id="change">labels_t.to(</a>device<a id="change">)</a>

        &#47&#47 measure data loading time
        data_time.update(time.time() - end)

        &#47&#47 compute output
        x = torch.cat((x_s, x_t), dim=0)
        outputs, outputs_adv = classifier(x)
        y_s, y_t = outputs.chunk(2, dim=0)
        y_s_adv, y_t_adv = outputs_adv.chunk(2, dim=0)

        &#47&#47 compute cross entropy loss on source domain
        cls_loss = F.cross_entropy(y_s, labels_s)
        &#47&#47 compute margin disparity discrepancy between domains
        &#47&#47 for adversarial classifier, minimize negative mdd is equal to maximize mdd
        transfer_loss = -mdd(y_s, y_s_adv, y_t, y_t_adv)
        loss = cls_loss + transfer_loss * args.trade_off
        classifier.step()

        cls_acc = accuracy(y_s, labels_s)[0]
        tgt_acc<a id="change"> = </a><a id="change">accuracy(y_t, labels_t)[0]</a>

        losses.update(loss.item(), x_s.size(0))
        cls_accs.update(cls_acc.item(), x_s.size(0))
        <a id="change">tgt_accs.update(tgt_acc.item()</a>, <a id="change">x_t.size(0</a><a id="change">))</a>
        trans_losses.update(transfer_loss.item(), x_s.size(0))

        &#47&#47 compute gradient and do SGD step
        loss.backward()</code></pre><h3>After Change</h3><pre><code class='java'>
    for i in range(args.iters_per_epoch):
        optimizer.zero_grad()

        x_s, labels_s = <a id="change">next(train_source_iter)[:2]</a>
        x_t, = next(train_target_iter)[:1]

        x_s = x_s.to(device)
        x_t = x_t.to(device)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/e67c5c44b5082e84a56d7d6480d9c71a7f6a2fc0#diff-651a02a1803d75b8373156475ba53c300b495f828e47c3a9c89adee9726d7eedL138' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8143240</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: e67c5c44b5082e84a56d7d6480d9c71a7f6a2fc0</div><div id='time'> Time: 2022-02-10</div><div id='author'> Author: 13126830206@163.com</div><div id='file'> File Name: examples/domain_adaptation/image_classification/mdd.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(8)</div><div id='n_method'> N Method Name: train(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/domain_adaptation/image_classification/mdd.py</div><div id='n_file'> N File Name: examples/domain_adaptation/image_classification/mdd.py</div><div id='m_start'> M Start Line: 146</div><div id='m_end'> M End Line: 191</div><div id='n_start'> N Start Line: 158</div><div id='n_end'> N End Line: 159</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    cls_losses = AverageMeter(&quotCls Loss&quot, &quot:3.2f&quot)
    cons_losses = AverageMeter(&quotCons Loss&quot, &quot:3.2f&quot)
    cls_accs = AverageMeter(&quotCls Acc&quot, &quot:3.1f&quot)
    tgt_accs<a id="change"> = </a><a id="change">AverageMeter(&quotTgt Acc&quot</a>, <a id="change">&quot:3.1f&quot</a><a id="change">)</a>

    progress = ProgressMeter(
        args.iters_per_epoch,
        [batch_time, data_time, cls_losses, cons_losses, cls_accs, tgt_accs],
        prefix="Epoch: [{}]".format(epoch))

    &#47&#47 switch to train mode
    model.train()
    teacher.train()

    end = time.time()
    for i in range(args.iters_per_epoch):
        x_s, labels_s = next(train_source_iter)
        (x_t1, x_t2), labels_t = next(train_target_iter)

        x_s = x_s.to(device)
        x_t1 = x_t1.to(device)
        x_t2 = x_t2.to(device)
        labels_s = labels_s.to(device)
        labels_t<a id="change"> = </a><a id="change">labels_t.to(</a>device<a id="change">)</a>

        &#47&#47 measure data loading time
        data_time.update(time.time() - end)

        &#47&#47 compute output
        y_s, _ = model(x_s)
        y_t, _ = model(x_t1)
        y_t_teacher, _ = teacher(x_t2)

        &#47&#47 classification loss
        cls_loss = F.cross_entropy(y_s, labels_s)
        &#47&#47 compute output and mask
        y_t = F.softmax(y_t, dim=1)
        y_t_teacher = F.softmax(y_t_teacher, dim=1)
        max_prob, _ = y_t_teacher.max(dim=1)
        mask = (max_prob &gt; args.threshold).float()

        &#47&#47 consistent loss
        cons_loss = consistent_loss(y_t, y_t_teacher, mask)
        &#47&#47 balance loss
        balance_loss = class_balance_loss(y_t) * mask.mean()

        loss = cls_loss + args.trade_off_cons * cons_loss + args.trade_off_balance * balance_loss

        &#47&#47 compute gradient and do SGD step
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        lr_scheduler.step()

        &#47&#47 update teacher
        teacher.update()

        &#47&#47 update statistics
        cls_acc = accuracy(y_s, labels_s)[0]
        tgt_acc<a id="change"> = </a><a id="change">accuracy(y_t, labels_t)[0]</a>
        cls_losses.update(cls_loss.item(), x_s.size(0))
        cons_losses.update(cons_loss.item(), x_s.size(0))
        cls_accs.update(cls_acc.item(), x_s.size(0))
        <a id="change">tgt_accs.update(tgt_acc.item()</a>, <a id="change">x_s.size(0</a><a id="change">))</a>

        &#47&#47 measure elapsed time
        batch_time.update(time.time() - end)
        end = time.time()</code></pre><h3>After Change</h3><pre><code class='java'>
    end = time.time()
    for i in range(args.iters_per_epoch):
        x_s, labels_s = next(train_source_iter)[:2]
        (x_t1, x_t2), = <a id="change">next(train_target_iter)[:1]</a>

        x_s = x_s.to(device)
        x_t1 = x_t1.to(device)
        x_t2 = x_t2.to(device)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/e67c5c44b5082e84a56d7d6480d9c71a7f6a2fc0#diff-804ffd2efb4161cbf0297ee479234b980e0c1291580f319c556e343c6a2188e7L175' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8143225</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: e67c5c44b5082e84a56d7d6480d9c71a7f6a2fc0</div><div id='time'> Time: 2022-02-10</div><div id='author'> Author: 13126830206@163.com</div><div id='file'> File Name: examples/domain_adaptation/image_classification/self_ensemble.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(10)</div><div id='n_method'> N Method Name: train(10)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/domain_adaptation/image_classification/self_ensemble.py</div><div id='n_file'> N File Name: examples/domain_adaptation/image_classification/self_ensemble.py</div><div id='m_start'> M Start Line: 183</div><div id='m_end'> M End Line: 243</div><div id='n_start'> N Start Line: 193</div><div id='n_end'> N End Line: 194</div><BR>