<html><h3>Pattern ID :7390
</h3><img src='24592118.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    output3d = cotrans.forward_regular(example_clip)
    assert torch.allclose(target, output3d)

    o = <a id="change">[]</a>
    &#47&#47 Manual zero pad (due to padding=1 in Conv3d)
    zeros = torch.zeros_like(example_clip[:, :, 0])
    o.append(<a id="change">cotrans.forward(</a>zeros<a id="change">)</a>)
    <a id="change">for i</a> in <a id="change">range(example_clip.shape[2]</a><a id="change">)</a><a id="change">:
        o.append(cotrans</a><a id="change">.forward(example_clip</a>[:, :, <a id="change">i</a>]<a id="change">))</a>
    <a id="change">o.append(cotrans.forward(</a>zeros<a id="change">)</a><a id="change">)</a>

    &#47&#47 For debugging:
    &#47&#47 close = []
    &#47&#47 equal = []</code></pre><h3>After Change</h3><pre><code class='java'>
    target = trans.forward(example_clip)

    &#47&#47 Recurrent block
    <a id="change">cotrans</a> = CoX3DTransform(
        dim_in=2,
        dim_out=2,
        temp_kernel_size=3,
        stride=2,
        dim_inner=5,
        num_groups=5,
        stride_1x1=False,
        inplace_relu=True,
        eps=1e-5,
        bn_mmt=0.1,
        dilation=1,
        norm_module=torch.nn.BatchNorm3d,
        se_ratio=0.1,
        swish_inner=True,
        block_idx=0,
        temporal_window_size=example_clip.shape[2],  &#47&#47 +2 from padding
        temporal_fill="zeros",
        se_scope="clip",
    )
    co.load_state_dict(cotrans, trans.state_dict(), flatten=True)
    cotrans.eval()  &#47&#47 This has a major effect on BatchNorm result

    &#47&#47 forward
    output = <a id="change">cotrans.forward(</a>example_clip<a id="change">)</a>
    assert torch.allclose(target, output)

    &#47&#47 forward_steps
    output = cotrans.forward_steps(example_clip, pad_end=True)
    assert torch.allclose(target, output)

    &#47&#47 forward_steps - broken up
    cotrans.clean_state()
    nothing<a id="change"> = cotrans</a><a id="change">.forward_steps(example_clip[:, :, :-1]</a><a id="change">, pad_end=False)</a>  &#47&#47 init
    assert isinstance(nothing, TensorPlaceholder)

    lasts = <a id="change">cotrans.forward_steps(example_clip[:, :, -1:]</a><a id="change">, pad_end=True)</a>
    assert torch.allclose(lasts, target)

    &#47&#47 forward_step
    <a id="change">cotrans.clean_state()</a>
    nothing = cotrans.forward_steps(example_clip[:, :, :], pad_end=False)  &#47&#47 init
    assert isinstance(nothing, TensorPlaceholder)

    &#47&#47 Manual pad end.
    zeros = torch.zeros_like(example_clip[:, :, 0])
    step<a id="change"> = cotrans</a><a id="change">.forward_step(</a>zeros<a id="change">)</a>
    assert torch.allclose(step, target[:, :, 0])  &#47&#47 (4/4) correct in SE pool
    step = cotrans.forward_step(zeros)
    assert torch.allclose(step, target[:, :, 1], atol=5e-3)  &#47&#47 (3/4) correct in pool
    step = cotrans.forward_step(zeros)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 19</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lukashedegaard/co3d/commit/3a1ca5de4898fd89bc774492cf0eeaed905baba1#diff-81ebfd3b7da0e2057c99c1622bd2ed14cb38bdb040741812bc0eb3de8e60005eL598' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24592118</div><div id='project'> Project Name: lukashedegaard/co3d</div><div id='commit'> Commit Name: 3a1ca5de4898fd89bc774492cf0eeaed905baba1</div><div id='time'> Time: 2021-09-10</div><div id='author'> Author: lh@eng.au.dk</div><div id='file'> File Name: tests/cox3d/test_x3d.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_CoX3DTransform(0)</div><div id='n_method'> N Method Name: test_CoX3DTransform(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/cox3d/test_x3d.py</div><div id='n_file'> N File Name: tests/cox3d/test_x3d.py</div><div id='m_start'> M Start Line: 601</div><div id='m_end'> M End Line: 657</div><div id='n_start'> N Start Line: 598</div><div id='n_end'> N End Line: 672</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        stem_func_name="x3d_stem",
    )

    <a id="change">cotrans</a> = CoVideoModelStem(
        dim_in=[2],
        dim_out=[2],
        kernel=[[5, 3, 3]],
        stride=[[1, 2, 2]],
        padding=[[2, 1, 1]],
        norm_module=torch.nn.BatchNorm3d,
        stem_func_name="x3d_stem",
        temporal_fill="zeros",
    )
    cotrans.load_state_dict(trans.state_dict())

    &#47&#47 Training mode has large effect on BatchNorm result - test will fail otherwise
    trans.eval()
    cotrans.eval()

    &#47&#47 Forward through models
    target = trans([example_clip])[0]

    outputs = <a id="change">[]</a>
    &#47&#47 Manual zero pad (due to padding=1 in trans.b Conv3d)
    zeros = torch.zeros_like(example_clip[:, :, 0])
    outputs.append(cotrans.forward([zeros])[0])
    outputs.append(cotrans.forward([zeros])[0])
    <a id="change">for i</a> in <a id="change">range(example_clip.shape[2]</a><a id="change">)</a><a id="change">:
        outputs.append(</a><a id="change">cotrans.forward(</a>[<a id="change">example_clip</a>[:, :, i]]<a id="change">)</a>[0]<a id="change">)</a>
    outputs.append(<a id="change">cotrans.forward(</a>[zeros]<a id="change">)</a>[0])
    <a id="change">outputs.append(cotrans.forward(</a>[zeros]<a id="change">)</a>[0]<a id="change">)</a>

    &#47&#47 For debugging:
    &#47&#47 close = []
    &#47&#47 for t in range(target.shape[2]):</code></pre><h3>After Change</h3><pre><code class='java'>
        stem_func_name="x3d_stem",
    )

    <a id="change">cotrans</a> = CoVideoModelStem(
        dim_in=2,
        dim_out=2,
        kernel=[5, 3, 3],
        stride=[1, 2, 2],
        padding=[2, 1, 1],
        norm_module=torch.nn.BatchNorm3d,
        stem_func_name="x3d_stem",
        temporal_fill="zeros",
    )
    cotrans.load_state_dict(trans.state_dict(), flatten=True)
    assert cotrans.delay == 2

    &#47&#47 Training mode has large effect on BatchNorm result - test will fail otherwise
    trans.eval()
    cotrans.eval()

    sample = torch.randn((1, 2, 4, 4, 4))

    &#47&#47 Forward through models
    target = trans.forward([sample])[0]

    &#47&#47 forward
    output = <a id="change">cotrans.forward(</a>sample<a id="change">)</a>
    assert torch.allclose(target, output)

    &#47&#47 forward_steps
    output = cotrans.forward_steps(sample, pad_end=True)
    assert torch.allclose(target, output)

    &#47&#47 forward_steps - broken up
    <a id="change">cotrans.clean_state()</a>
    nothing = <a id="change">cotrans.forward_steps(sample[:, :, :-2]</a><a id="change">, pad_end=False)</a>  &#47&#47 init
    assert isinstance(nothing, TensorPlaceholder)

    mid<a id="change"> = </a><a id="change">cotrans.forward_step(</a>sample[:, :, -2]<a id="change">)</a>
    assert torch.allclose(mid, target[:, :, 0])

    lasts<a id="change"> = </a><a id="change">cotrans.forward_steps(sample[:, :, -1:]</a><a id="change">, pad_end=True)</a>
    assert torch.allclose(lasts, target[:, :, 1:])


def test_CoX3DTransform():</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lukashedegaard/co3d/commit/6f21aa05a02b4da9bc04a9da72466d99be8a9046#diff-81ebfd3b7da0e2057c99c1622bd2ed14cb38bdb040741812bc0eb3de8e60005eL640' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24592182</div><div id='project'> Project Name: lukashedegaard/co3d</div><div id='commit'> Commit Name: 6f21aa05a02b4da9bc04a9da72466d99be8a9046</div><div id='time'> Time: 2021-09-10</div><div id='author'> Author: lh@eng.au.dk</div><div id='file'> File Name: tests/cox3d/test_x3d.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_VideoModelStem(0)</div><div id='n_method'> N Method Name: test_VideoModelStem(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/cox3d/test_x3d.py</div><div id='n_file'> N File Name: tests/cox3d/test_x3d.py</div><div id='m_start'> M Start Line: 651</div><div id='m_end'> M End Line: 694</div><div id='n_start'> N Start Line: 84</div><div id='n_end'> N End Line: 133</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    target = trans(example_clip)

    &#47&#47 Recurrent block
    <a id="change">cotrans</a> = CoX3DTransform(
        dim_in=2,
        dim_out=2,
        temp_kernel_size=3,
        stride=2,
        dim_inner=5,
        num_groups=5,
        stride_1x1=False,
        inplace_relu=True,
        eps=1e-5,
        bn_mmt=0.1,
        dilation=1,
        norm_module=torch.nn.BatchNorm3d,
        se_ratio=0.1,
        swish_inner=True,
        block_idx=0,
        temporal_window_size=example_clip.shape[2],
        temporal_fill="zeros",
    )
    cotrans.load_state_dict(trans.state_dict())
    cotrans.eval()  &#47&#47 This has a major effect on BatchNorm result

    &#47&#47 Forward 3D works like the original
    output3d = cotrans.forward_regular(example_clip)
    assert torch.allclose(target, output3d)

    o = <a id="change">[]</a>
    &#47&#47 Manual zero pad (due to padding=1 in Conv3d)
    zeros = torch.zeros_like(example_clip[:, :, 0])
    o.append(<a id="change">cotrans.forward(</a>zeros<a id="change">)</a>)
    <a id="change">for i</a> in <a id="change">range(example_clip.shape[2]</a><a id="change">)</a><a id="change">:
        o.append(</a><a id="change">cotrans.forward(example_clip</a>[:, :, i]<a id="change">))</a>
    <a id="change">o.append(cotrans.forward(</a>zeros<a id="change">)</a><a id="change">)</a>

    &#47&#47 For debugging:
    &#47&#47 close = []
    &#47&#47 equal = []</code></pre><h3>After Change</h3><pre><code class='java'>
    target = trans.forward(example_clip)

    &#47&#47 Recurrent block
    <a id="change">cotrans</a> = CoX3DTransform(
        dim_in=2,
        dim_out=2,
        temp_kernel_size=3,
        stride=2,
        dim_inner=5,
        num_groups=5,
        stride_1x1=False,
        inplace_relu=True,
        eps=1e-5,
        bn_mmt=0.1,
        dilation=1,
        norm_module=torch.nn.BatchNorm3d,
        se_ratio=0.1,
        swish_inner=True,
        block_idx=0,
        temporal_window_size=example_clip.shape[2],  &#47&#47 +2 from padding
        temporal_fill="zeros",
        se_scope="clip",
    )
    co.load_state_dict(cotrans, trans.state_dict(), flatten=True)
    cotrans.eval()  &#47&#47 This has a major effect on BatchNorm result

    &#47&#47 forward
    output = <a id="change">cotrans.forward(</a>example_clip<a id="change">)</a>
    assert torch.allclose(target, output)

    &#47&#47 forward_steps
    output = cotrans.forward_steps(example_clip, pad_end=True)
    assert torch.allclose(target, output)

    &#47&#47 forward_steps - broken up
    cotrans.clean_state()
    nothing<a id="change"> = </a><a id="change">cotrans.forward_steps(example_clip[:, :, :-1]</a><a id="change">, pad_end=False)</a>  &#47&#47 init
    assert isinstance(nothing, TensorPlaceholder)

    lasts = <a id="change">cotrans.forward_steps(example_clip[:, :, -1:]</a><a id="change">, pad_end=True)</a>
    assert torch.allclose(lasts, target)

    &#47&#47 forward_step
    <a id="change">cotrans.clean_state()</a>
    nothing = cotrans.forward_steps(example_clip[:, :, :], pad_end=False)  &#47&#47 init
    assert isinstance(nothing, TensorPlaceholder)

    &#47&#47 Manual pad end.
    zeros = torch.zeros_like(example_clip[:, :, 0])
    step = cotrans.forward_step(zeros)
    assert torch.allclose(step, target[:, :, 0])  &#47&#47 (4/4) correct in SE pool
    step<a id="change"> = </a><a id="change">cotrans.forward_step(</a>zeros<a id="change">)</a>
    assert torch.allclose(step, target[:, :, 1], atol=5e-3)  &#47&#47 (3/4) correct in pool
    step = cotrans.forward_step(zeros)
    assert torch.allclose(step, target[:, :, 2], atol=5e-3)  &#47&#47 (2/4) correct in pool
    step = cotrans.forward_step(zeros)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lukashedegaard/co3d/commit/3a1ca5de4898fd89bc774492cf0eeaed905baba1#diff-81ebfd3b7da0e2057c99c1622bd2ed14cb38bdb040741812bc0eb3de8e60005eL581' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24592114</div><div id='project'> Project Name: lukashedegaard/co3d</div><div id='commit'> Commit Name: 3a1ca5de4898fd89bc774492cf0eeaed905baba1</div><div id='time'> Time: 2021-09-10</div><div id='author'> Author: lh@eng.au.dk</div><div id='file'> File Name: tests/cox3d/test_x3d.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_CoX3DTransform(0)</div><div id='n_method'> N Method Name: test_CoX3DTransform(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/cox3d/test_x3d.py</div><div id='n_file'> N File Name: tests/cox3d/test_x3d.py</div><div id='m_start'> M Start Line: 601</div><div id='m_end'> M End Line: 657</div><div id='n_start'> N Start Line: 598</div><div id='n_end'> N End Line: 672</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    target = trans(example_clip)

    &#47&#47 Recurrent block
    <a id="change">cotrans</a> = CoX3DTransform(
        dim_in=2,
        dim_out=2,
        temp_kernel_size=3,
        stride=2,
        dim_inner=5,
        num_groups=5,
        stride_1x1=False,
        inplace_relu=True,
        eps=1e-5,
        bn_mmt=0.1,
        dilation=1,
        norm_module=torch.nn.BatchNorm3d,
        se_ratio=0.1,
        swish_inner=True,
        block_idx=0,
        temporal_window_size=example_clip.shape[2],
        temporal_fill="zeros",
    )
    cotrans.load_state_dict(trans.state_dict())
    cotrans.eval()  &#47&#47 This has a major effect on BatchNorm result

    &#47&#47 Forward 3D works like the original
    output3d = cotrans.forward_regular(example_clip)
    assert torch.allclose(target, output3d)

    o = <a id="change">[]</a>
    &#47&#47 Manual zero pad (due to padding=1 in Conv3d)
    zeros = torch.zeros_like(example_clip[:, :, 0])
    o.append(<a id="change">cotrans.forward(</a>zeros<a id="change">)</a>)
    <a id="change">for i</a> in <a id="change">range(example_clip.shape[2]</a><a id="change">)</a><a id="change">:
        o.append(</a><a id="change">cotrans.forward(example_clip</a>[:, :, i]<a id="change">))</a>
    <a id="change">o.append(cotrans.forward(</a>zeros<a id="change">)</a><a id="change">)</a>

    &#47&#47 For debugging:
    &#47&#47 close = []
    &#47&#47 equal = []</code></pre><h3>After Change</h3><pre><code class='java'>
    target = trans.forward(example_clip)

    &#47&#47 Recurrent block
    <a id="change">cotrans</a> = CoX3DTransform(
        dim_in=2,
        dim_out=2,
        temp_kernel_size=3,
        stride=2,
        dim_inner=5,
        num_groups=5,
        stride_1x1=False,
        inplace_relu=True,
        eps=1e-5,
        bn_mmt=0.1,
        dilation=1,
        norm_module=torch.nn.BatchNorm3d,
        se_ratio=0.1,
        swish_inner=True,
        block_idx=0,
        temporal_window_size=example_clip.shape[2],  &#47&#47 +2 from padding
        temporal_fill="zeros",
        se_scope="clip",
    )
    co.load_state_dict(cotrans, trans.state_dict(), flatten=True)
    cotrans.eval()  &#47&#47 This has a major effect on BatchNorm result

    &#47&#47 forward
    output = <a id="change">cotrans.forward(</a>example_clip<a id="change">)</a>
    assert torch.allclose(target, output)

    &#47&#47 forward_steps
    output = cotrans.forward_steps(example_clip, pad_end=True)
    assert torch.allclose(target, output)

    &#47&#47 forward_steps - broken up
    cotrans.clean_state()
    nothing<a id="change"> = </a><a id="change">cotrans.forward_steps(example_clip[:, :, :-1]</a><a id="change">, pad_end=False)</a>  &#47&#47 init
    assert isinstance(nothing, TensorPlaceholder)

    lasts = <a id="change">cotrans.forward_steps(example_clip[:, :, -1:]</a><a id="change">, pad_end=True)</a>
    assert torch.allclose(lasts, target)

    &#47&#47 forward_step
    <a id="change">cotrans.clean_state()</a>
    nothing = cotrans.forward_steps(example_clip[:, :, :], pad_end=False)  &#47&#47 init
    assert isinstance(nothing, TensorPlaceholder)

    &#47&#47 Manual pad end.
    zeros = torch.zeros_like(example_clip[:, :, 0])
    step = cotrans.forward_step(zeros)
    assert torch.allclose(step, target[:, :, 0])  &#47&#47 (4/4) correct in SE pool
    step = cotrans.forward_step(zeros)
    assert torch.allclose(step, target[:, :, 1], atol=5e-3)  &#47&#47 (3/4) correct in pool
    step<a id="change"> = </a><a id="change">cotrans.forward_step(</a>zeros<a id="change">)</a>
    assert torch.allclose(step, target[:, :, 2], atol=5e-3)  &#47&#47 (2/4) correct in pool
    step = cotrans.forward_step(zeros)
    assert torch.allclose(step, target[:, :, 3], atol=5e-3)  &#47&#47 (1/4) correct in pool
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lukashedegaard/co3d/commit/85d83724404879a086f4b9ef26aee5f4398830ac#diff-81ebfd3b7da0e2057c99c1622bd2ed14cb38bdb040741812bc0eb3de8e60005eL581' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24592112</div><div id='project'> Project Name: lukashedegaard/co3d</div><div id='commit'> Commit Name: 85d83724404879a086f4b9ef26aee5f4398830ac</div><div id='time'> Time: 2021-08-25</div><div id='author'> Author: lh@eng.au.dk</div><div id='file'> File Name: tests/cox3d/test_x3d.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_CoX3DTransform(0)</div><div id='n_method'> N Method Name: test_CoX3DTransform(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/cox3d/test_x3d.py</div><div id='n_file'> N File Name: tests/cox3d/test_x3d.py</div><div id='m_start'> M Start Line: 601</div><div id='m_end'> M End Line: 657</div><div id='n_start'> N Start Line: 598</div><div id='n_end'> N End Line: 672</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        stem_func_name="x3d_stem",
    )

    <a id="change">cotrans</a> = CoVideoModelStem(
        dim_in=[2],
        dim_out=[2],
        kernel=[[5, 3, 3]],
        stride=[[1, 2, 2]],
        padding=[[2, 1, 1]],
        norm_module=torch.nn.BatchNorm3d,
        stem_func_name="x3d_stem",
        temporal_fill="zeros",
    )
    cotrans.load_state_dict(trans.state_dict())

    &#47&#47 Training mode has large effect on BatchNorm result - test will fail otherwise
    trans.eval()
    cotrans.eval()

    &#47&#47 Forward through models
    target = trans([example_clip])[0]

    outputs = <a id="change">[]</a>
    &#47&#47 Manual zero pad (due to padding=1 in trans.b Conv3d)
    zeros = torch.zeros_like(example_clip[:, :, 0])
    outputs.append(cotrans.forward([zeros])[0])
    outputs.append(cotrans.forward([zeros])[0])
    <a id="change">for i</a> in <a id="change">range(example_clip.shape[2]</a><a id="change">)</a><a id="change">:
        outputs.append(</a><a id="change">cotrans.forward(</a>[<a id="change">example_clip</a>[:, :, i]]<a id="change">)</a>[0]<a id="change">)</a>
    outputs.append(<a id="change">cotrans.forward(</a>[zeros]<a id="change">)</a>[0])
    <a id="change">outputs.append(cotrans.forward(</a>[zeros]<a id="change">)</a>[0]<a id="change">)</a>

    &#47&#47 For debugging:
    &#47&#47 close = []
    &#47&#47 for t in range(target.shape[2]):</code></pre><h3>After Change</h3><pre><code class='java'>
        stem_func_name="x3d_stem",
    )

    <a id="change">cotrans</a> = CoVideoModelStem(
        dim_in=2,
        dim_out=2,
        kernel=[5, 3, 3],
        stride=[1, 2, 2],
        padding=[2, 1, 1],
        norm_module=torch.nn.BatchNorm3d,
        stem_func_name="x3d_stem",
        temporal_fill="zeros",
    )
    cotrans.load_state_dict(trans.state_dict(), flatten=True)
    assert cotrans.delay == 2

    &#47&#47 Training mode has large effect on BatchNorm result - test will fail otherwise
    trans.eval()
    cotrans.eval()

    sample = torch.randn((1, 2, 4, 4, 4))

    &#47&#47 Forward through models
    target = trans.forward([sample])[0]

    &#47&#47 forward
    output = <a id="change">cotrans.forward(</a>sample<a id="change">)</a>
    assert torch.allclose(target, output)

    &#47&#47 forward_steps
    output = cotrans.forward_steps(sample, pad_end=True)
    assert torch.allclose(target, output)

    &#47&#47 forward_steps - broken up
    <a id="change">cotrans.clean_state()</a>
    nothing = <a id="change">cotrans.forward_steps(sample[:, :, :-2]</a><a id="change">, pad_end=False)</a>  &#47&#47 init
    assert isinstance(nothing, TensorPlaceholder)

    mid<a id="change"> = </a><a id="change">cotrans.forward_step(</a>sample[:, :, -2]<a id="change">)</a>
    assert torch.allclose(mid, target[:, :, 0])

    lasts<a id="change"> = </a><a id="change">cotrans.forward_steps(sample[:, :, -1:]</a><a id="change">, pad_end=True)</a>
    assert torch.allclose(lasts, target[:, :, 1:])


def test_CoX3DTransform():</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lukashedegaard/co3d/commit/24480f6c659a3758910b24e4a64782780e294c90#diff-81ebfd3b7da0e2057c99c1622bd2ed14cb38bdb040741812bc0eb3de8e60005eL640' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24592124</div><div id='project'> Project Name: lukashedegaard/co3d</div><div id='commit'> Commit Name: 24480f6c659a3758910b24e4a64782780e294c90</div><div id='time'> Time: 2021-08-31</div><div id='author'> Author: lh@eng.au.dk</div><div id='file'> File Name: tests/cox3d/test_x3d.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_VideoModelStem(0)</div><div id='n_method'> N Method Name: test_VideoModelStem(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/cox3d/test_x3d.py</div><div id='n_file'> N File Name: tests/cox3d/test_x3d.py</div><div id='m_start'> M Start Line: 651</div><div id='m_end'> M End Line: 694</div><div id='n_start'> N Start Line: 84</div><div id='n_end'> N End Line: 133</div><BR>