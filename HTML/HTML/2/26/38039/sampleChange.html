<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            self.train(self.n_epochs, batch_size=self.batch_size)

            &#47&#47 Evaluate agent
            <a id="change">if 0 &lt; eval_freq &lt;= timesteps_since_eval and eval_env is not None</a>:
                timesteps_since_eval<a id="change"> %= </a>eval_freq
                <a id="change">sync_envs_normalization(</a>self.env, <a id="change">eval_env</a><a id="change">)</a>

                mean_reward<a id="change">, _ = </a><a id="change">evaluate_policy(</a>self, <a id="change">eval_env</a>, n_eval_episodes<a id="change">)</a>
                if self.tb_writer is not None:
                    self.tb_writer.add_scalar(&quotEval/reward&quot, mean_reward, self.num_timesteps)

                <a id="change">evaluations.append(</a>mean_reward<a id="change">)</a>
                <a id="change">if self.verbose &gt; 0</a>:
                    <a id="change">print(</a><a id="change">"Eval num_timesteps={}, mean_reward={:.2f}".format(</a>self.num_timesteps, evaluations[-1]<a id="change">))</a>
                    <a id="change">print("FPS: {:.2f}".format(</a>self.num_timesteps<a id="change"> / </a>(<a id="change">time.time()</a><a id="change"> - </a>self.start_time)<a id="change">)</a><a id="change">)</a>

        return self

    def get_opt_parameters(self):</code></pre><h3>After Change</h3><pre><code class='java'>
            self.train(self.n_epochs, batch_size=self.batch_size)

            &#47&#47 Evaluate the agent
            timesteps_since_eval<a id="change"> = </a><a id="change">self._eval_policy(</a>eval_freq, eval_env, n_eval_episodes,
                                                     timesteps_since_eval<a id="change">, deterministic=True)</a>
            &#47&#47 For tensorboard integration
            &#47&#47 if self.tb_writer is not None:
            &#47&#47     self.tb_writer.add_scalar(&quotEval/reward&quot, mean_reward, self.num_timesteps)
</code></pre>