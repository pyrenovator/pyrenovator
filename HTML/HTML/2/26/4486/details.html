<html><h3>Pattern ID :4486
</h3><img src='16360221.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    tokenizer = AutoTokenizer.from_pretrained(args.params_path)

    examples = []
    <a id="change">for </a><a id="change">text</a> in data<a id="change">:
        </a>result = tokenizer(text=text, max_seq_len=args.max_seq_length)
        <a id="change">examples.append(</a>(<a id="change">result[&quotinput_ids&quot]</a><a id="change">, result[&quottoken_type_ids&quot]</a>)<a id="change">)</a>

    &#47&#47 Seperates data into some batches.
    batches = <a id="change">[
        examples[i:i + args.batch_size]
        for i in range(0, len(examples), args.batch_size)
    ]</a>

    batchify_fn = lambda samples, fn=Tuple(
        Pad(axis=0, pad_val=tokenizer.pad_token_id),  &#47&#47 input
        Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  &#47&#47 segment
    ): fn(samples)

    results = []
    model.eval()
    for <a id="change">batch</a> in batches:
        input_ids<a id="change">, token_type_ids</a> = batchify_fn(batch)
        input_ids<a id="change"> = paddle.to_tensor(</a>input_ids<a id="change">)</a>
        token_type_ids<a id="change"> = paddle</a><a id="change">.to_tensor(</a>token_type_ids<a id="change">)</a>
        logits<a id="change"> = model(</a>input_ids, token_type_ids<a id="change">)</a>
        probs = F.softmax(logits, axis=1)
        idx = paddle.argmax(probs, axis=1).numpy()
        idx = idx.tolist()
        labels = [label_list[i] for i in idx]</code></pre><h3>After Change</h3><pre><code class='java'>
        for t, r in zip(data_ds.data, results):
            f.write(t["text"] + &quot\t&quot + r + &quot\n&quot)
    logger.info("Prediction results save in {}.".format(args.output_file))
    <a id="change">return</a>


if __name__ == "__main__":
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 20</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/ab2bd216c120e37a65d4073ba4e8af31a282728f#diff-05078f2b312998dd66ce71f24193df90b56635bb1860ae9f5162abcca8c8c9c3L41' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 16360221</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: ab2bd216c120e37a65d4073ba4e8af31a282728f</div><div id='time'> Time: 2022-09-05</div><div id='author'> Author: 63761690+lugimzzz@users.noreply.github.com</div><div id='file'> File Name: applications/text_classification/multi_class/predict.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: predict(0)</div><div id='n_method'> N Method Name: predict(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: applications/text_classification/multi_class/predict.py</div><div id='n_file'> N File Name: applications/text_classification/multi_class/predict.py</div><div id='m_start'> M Start Line: 41</div><div id='m_end'> M End Line: 88</div><div id='n_start'> N Start Line: 51</div><div id='n_end'> N End Line: 96</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    model = AutoModelForSequenceClassification.from_pretrained(args.params_path)
    tokenizer = AutoTokenizer.from_pretrained(args.params_path)

    <a id="change">examples</a> = []
    <a id="change">for </a><a id="change">text</a> in data<a id="change">:
        </a>result = tokenizer(text=text, max_seq_len=args.max_seq_length)
        <a id="change">examples.append(</a>(<a id="change">result[&quotinput_ids&quot]</a><a id="change">, result[&quottoken_type_ids&quot]</a>)<a id="change">)</a>

    &#47&#47 Seperates data into some batches.
    batches = <a id="change">[
        examples[i:i + args.batch_size]
        for i in range(0, len(examples), args.batch_size)
    ]</a>

    batchify_fn = lambda samples, fn=Tuple(
        Pad(axis=0, pad_val=tokenizer.pad_token_id),  &#47&#47 input
        Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  &#47&#47 segment
    ): fn(samples)

    results = []
    model.eval()
    for <a id="change">batch</a> in batches:
        input_ids<a id="change">, token_type_ids</a> = batchify_fn(batch)
        input_ids<a id="change"> = paddle.to_tensor(</a>input_ids<a id="change">)</a>
        token_type_ids<a id="change"> = </a><a id="change">paddle.to_tensor(</a>token_type_ids<a id="change">)</a>
        logits<a id="change"> = model(</a>input_ids, token_type_ids<a id="change">)</a>
        probs = F.sigmoid(logits).numpy()
        for prob in probs:
            labels = []
            for i, p in enumerate(prob):</code></pre><h3>After Change</h3><pre><code class='java'>
            logger.info("level {} : {}".format(d + 1, &quot,&quot.join(
                hierarchical_labels[d])))
        logger.info("--------------------")
    <a id="change">return</a>


if __name__ == "__main__":
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/ab2bd216c120e37a65d4073ba4e8af31a282728f#diff-2a0a90d0e749072f5c37380fd576e4ef271b64effa977e780ba61e37110e1c9eL40' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 16360223</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: ab2bd216c120e37a65d4073ba4e8af31a282728f</div><div id='time'> Time: 2022-09-05</div><div id='author'> Author: 63761690+lugimzzz@users.noreply.github.com</div><div id='file'> File Name: applications/text_classification/hierarchical/predict.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: predict(0)</div><div id='n_method'> N Method Name: predict(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: applications/text_classification/hierarchical/predict.py</div><div id='n_file'> N File Name: applications/text_classification/hierarchical/predict.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 98</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 107</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    model = AutoModelForSequenceClassification.from_pretrained(args.params_path)
    tokenizer = AutoTokenizer.from_pretrained(args.params_path)

    <a id="change">examples</a> = []
    <a id="change">for </a><a id="change">text</a> in data<a id="change">:
        </a>result = tokenizer(text=text, max_seq_len=args.max_seq_length)
        <a id="change">examples.append(</a>(<a id="change">result[&quotinput_ids&quot]</a><a id="change">, result[&quottoken_type_ids&quot]</a>)<a id="change">)</a>

    &#47&#47 Seperates data into some batches.
    batches = <a id="change">[
        examples[i:i + args.batch_size]
        for i in range(0, len(examples), args.batch_size)
    ]</a>

    batchify_fn = lambda samples, fn=Tuple(
        Pad(axis=0, pad_val=tokenizer.pad_token_id),  &#47&#47 input
        Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  &#47&#47 segment
    ): fn(samples)

    results = []
    model.eval()
    for <a id="change">batch</a> in batches:
        input_ids<a id="change">, token_type_ids</a> = batchify_fn(batch)
        input_ids<a id="change"> = </a><a id="change">paddle.to_tensor(</a>input_ids<a id="change">)</a>
        token_type_ids<a id="change"> = paddle.to_tensor(</a>token_type_ids<a id="change">)</a>
        logits<a id="change"> = model(</a>input_ids, token_type_ids<a id="change">)</a>
        probs = F.softmax(logits, axis=1)
        idx = paddle.argmax(probs, axis=1).numpy()
        idx = idx.tolist()
        labels = [label_list[i] for i in idx]</code></pre><h3>After Change</h3><pre><code class='java'>
        for t, r in zip(data_ds.data, results):
            f.write(t["text"] + &quot\t&quot + r + &quot\n&quot)
    logger.info("Prediction results save in {}.".format(args.output_file))
    <a id="change">return</a>


if __name__ == "__main__":
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/ab2bd216c120e37a65d4073ba4e8af31a282728f#diff-05078f2b312998dd66ce71f24193df90b56635bb1860ae9f5162abcca8c8c9c3L41' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 16360222</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: ab2bd216c120e37a65d4073ba4e8af31a282728f</div><div id='time'> Time: 2022-09-05</div><div id='author'> Author: 63761690+lugimzzz@users.noreply.github.com</div><div id='file'> File Name: applications/text_classification/multi_class/predict.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: predict(0)</div><div id='n_method'> N Method Name: predict(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: applications/text_classification/multi_class/predict.py</div><div id='n_file'> N File Name: applications/text_classification/multi_class/predict.py</div><div id='m_start'> M Start Line: 41</div><div id='m_end'> M End Line: 88</div><div id='n_start'> N Start Line: 51</div><div id='n_end'> N End Line: 96</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    model = AutoModelForSequenceClassification.from_pretrained(args.params_path)
    tokenizer = AutoTokenizer.from_pretrained(args.params_path)

    <a id="change">examples</a> = []
    <a id="change">for </a><a id="change">text</a> in data<a id="change">:
        </a>result = tokenizer(text=text, max_seq_len=args.max_seq_length)
        <a id="change">examples.append(</a>(<a id="change">result[&quotinput_ids&quot]</a><a id="change">, result[&quottoken_type_ids&quot]</a>)<a id="change">)</a>

    &#47&#47 Seperates data into some batches.
    batches = <a id="change">[
        examples[i:i + args.batch_size]
        for i in range(0, len(examples), args.batch_size)
    ]</a>

    batchify_fn = lambda samples, fn=Tuple(
        Pad(axis=0, pad_val=tokenizer.pad_token_id),  &#47&#47 input
        Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  &#47&#47 segment
    ): fn(samples)

    results = []
    model.eval()
    for <a id="change">batch</a> in batches:
        input_ids<a id="change">, token_type_ids</a> = batchify_fn(batch)
        input_ids<a id="change"> = paddle.to_tensor(</a>input_ids<a id="change">)</a>
        token_type_ids<a id="change"> = </a><a id="change">paddle.to_tensor(</a>token_type_ids<a id="change">)</a>
        logits<a id="change"> = model(</a>input_ids, token_type_ids<a id="change">)</a>
        probs = F.sigmoid(logits).numpy()
        for prob in probs:
            labels = []
            for i, p in enumerate(prob):</code></pre><h3>After Change</h3><pre><code class='java'>
            f.write(d["sentence"] + &quot\t&quot + &quot, &quot.join(label) + &quot\n&quot)
    logger.info("Prediction results save in {}.".format(args.output_file))

    <a id="change">return</a>


if __name__ == "__main__":
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/ab2bd216c120e37a65d4073ba4e8af31a282728f#diff-de6df134549c5a81da0dcb67de8dcb731eec96065540817ad06b3f3623fed63dL41' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 16360241</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: ab2bd216c120e37a65d4073ba4e8af31a282728f</div><div id='time'> Time: 2022-09-05</div><div id='author'> Author: 63761690+lugimzzz@users.noreply.github.com</div><div id='file'> File Name: applications/text_classification/multi_label/predict.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: predict(0)</div><div id='n_method'> N Method Name: predict(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: applications/text_classification/multi_label/predict.py</div><div id='n_file'> N File Name: applications/text_classification/multi_label/predict.py</div><div id='m_start'> M Start Line: 41</div><div id='m_end'> M End Line: 92</div><div id='n_start'> N Start Line: 51</div><div id='n_end'> N End Line: 101</div><BR>