<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    tokenizer = AutoTokenizer.from_pretrained(args.params_path)

    examples = []
    <a id="change">for </a><a id="change">text</a> in data<a id="change">:
        </a>result = tokenizer(text=text, max_seq_len=args.max_seq_length)
        <a id="change">examples.append(</a>(<a id="change">result[&quotinput_ids&quot]</a><a id="change">, result[&quottoken_type_ids&quot]</a>)<a id="change">)</a>

    &#47&#47 Seperates data into some batches.
    batches = <a id="change">[
        examples[i:i + args.batch_size]
        for i in range(0, len(examples), args.batch_size)
    ]</a>

    batchify_fn = lambda samples, fn=Tuple(
        Pad(axis=0, pad_val=tokenizer.pad_token_id),  &#47&#47 input
        Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  &#47&#47 segment
    ): fn(samples)

    results = []
    model.eval()
    for <a id="change">batch</a> in batches:
        input_ids<a id="change">, token_type_ids</a> = batchify_fn(batch)
        input_ids<a id="change"> = paddle.to_tensor(</a>input_ids<a id="change">)</a>
        token_type_ids<a id="change"> = paddle</a><a id="change">.to_tensor(</a>token_type_ids<a id="change">)</a>
        logits<a id="change"> = model(</a>input_ids, token_type_ids<a id="change">)</a>
        probs = F.softmax(logits, axis=1)
        idx = paddle.argmax(probs, axis=1).numpy()
        idx = idx.tolist()
        labels = [label_list[i] for i in idx]</code></pre><h3>After Change</h3><pre><code class='java'>
        for t, r in zip(data_ds.data, results):
            f.write(t["text"] + &quot\t&quot + r + &quot\n&quot)
    logger.info("Prediction results save in {}.".format(args.output_file))
    <a id="change">return</a>


if __name__ == "__main__":
</code></pre>