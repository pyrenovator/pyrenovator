<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47targets = [{k:v for k,v in t.items()} for t in targets]
            
        outputs = model(samples)
        <a id="change">loss_dict</a> = <a id="change">criterion(</a>outputs, targets<a id="change">)</a>
        <a id="change">weight_dict = </a>criterion.weight_dict
        losses<a id="change"> = </a><a id="change">sum(loss_dict[k]</a><a id="change"> * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)</a>

        losses.backward()
        if ((batch_id +1) % accum_iter == 0) or (batch_id + 1 == len(dataloader)):
            optimizer.step()</code></pre><h3>After Change</h3><pre><code class='java'>
    train_loss_cls_meter = AverageMeter()
    train_loss_reg_meter = AverageMeter()
    train_loss_rpn_cls_meter = AverageMeter()
    train_loss_rpn_reg_meter<a id="change"> = </a><a id="change">AverageMeter()</a>

    time_st = time.time()

    &#47&#47iou_types = (&quotbbox&quot, )
    &#47&#47coco_evaluator = CocoEvaluator(base_ds, iou_types)

    for batch_id, data in enumerate(dataloader):
        samples = data[0]
        targets = data[1]
            
        loss_dict = model(samples, targets)
        losses = <a id="change">sum(loss</a><a id="change"> for loss in loss_dict.values())</a>
        losses.backward()

        if ((batch_id +1) % accum_iter == 0) or (batch_id + 1 == len(dataloader)):
            optimizer.step()
            optimizer.clear_grad()

        &#47&#47 logging losses
        batch_size = samples.tensors.shape[0]
        train_loss_cls_meter.update(loss_dict[&quotloss_cls&quot].numpy()[0], batch_size)
        train_loss_reg_meter.update(loss_dict[&quotloss_reg&quot].numpy()[0], batch_size)
        train_loss_rpn_cls_meter.update(loss_dict[&quotloss_rpn_cls&quot].numpy()[0], batch_size)
        <a id="change">train_loss_rpn_reg_meter.update(loss_dict[&quotloss_rpn_reg&quot]</a><a id="change">.numpy()[0]</a>, batch_size<a id="change">)</a>
    
        if batch_id &gt; 0 and batch_id % debug_steps == 0:
            logger.info(
                f"Train Step[{batch_id:04d}/{total_batch:04d}], " + 
                f"Avg loss_cls: {train_loss_cls_meter.avg:.4f}, " + 
                f"Avg loss_reg: {train_loss_reg_meter.avg:.4f}, " + 
                f"Avg loss_rpn_cls: {train_loss_rpn_cls_meter.avg:.4f}, " + 
                f"Avg loss_rpn_reg: {train_loss_rpn_reg_meter.avg:.4f}") 

    train_time = time.time() - time_st
    <a id="change">return </a>(train_loss_cls_meter.avg<a id="change">,
            train_loss_reg_meter.avg,
            train_loss_rpn_cls_meter.avg,
            train_loss_rpn_reg_meter.avg,
            train_time</a>)


def validate(dataloader, model, base_ds, total_batch, debug_steps=100):</code></pre>