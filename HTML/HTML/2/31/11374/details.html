<html><h3>Pattern ID :11374
</h3><img src='38831696.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    print(&quottraining...&quot)
    loss_function = nn.MSELoss().to(args.device)
    loss = 0
    for <a id="change">epoch</a> in <a id="change">range(</a>args.E<a id="change">)</a>:
        for (seq, label) in Dtr:
            seq = seq.to(args.device)
            label = label.to(args.device)
            y_pred = model(seq)
            optimizer.zero_grad()
            &#47&#47 compute proximal_term
            proximal_term = 0.0
            for w, w_t in zip(model.parameters(), global_model.parameters()):
                proximal_term += (w - w_t).norm(2)

            loss = loss_function(y_pred, label) + (args.mu / 2) * proximal_term
            loss.backward()
            optimizer.step()
        stepLR.step()

        <a id="change">print(&quotepoch&quot</a>, <a id="change">epoch</a>, <a id="change">&quot:&quot</a>, loss.item()<a id="change">)</a>

    return model

</code></pre><h3>After Change</h3><pre><code class='java'>
                                    momentum=0.9, weight_decay=args.weight_decay)
    stepLR = StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)
    &#47&#47 training
    min_epochs<a id="change"> = 10</a>
    best_model = None
    min_val_loss = 5
    print(&quottraining...&quot)
    loss_function = nn.MSELoss().to(args.device)
    for <a id="change">epoch</a> in <a id="change">tqdm(</a><a id="change">range(</a>args.E<a id="change">))</a>:
        <a id="change">train_loss = </a><a id="change">[]</a>
        for (seq, label) in Dtr:
            seq = seq.to(args.device)
            label = label.to(args.device)
            y_pred = model(seq)
            optimizer.zero_grad()
            &#47&#47 compute proximal_term
            proximal_term = 0.0
            for w, w_t in zip(model.parameters(), global_model.parameters()):
                proximal_term += (w - w_t).norm(2)

            loss = loss_function(y_pred, label) + (args.mu / 2) * proximal_term
            <a id="change">train_loss.append(</a>loss.item()<a id="change">)</a>
            loss.backward()
            optimizer.step()
        stepLR.step()
        &#47&#47 validation
        <a id="change">val_loss = </a><a id="change">get_val_loss(</a>args, <a id="change">model</a>, Val<a id="change">)</a>
        <a id="change">if epoch + 1 &gt;= min_epochs</a><a id="change"> and val_loss &lt; min_val_loss</a>:
            min_val_loss<a id="change"> = val_loss</a>
            best_model<a id="change"> = copy.deepcopy(model</a><a id="change">)</a>

        print(<a id="change">&quotepoch {:03d} train_loss {:.8f} val_loss {:.8f}&quot.format(epoch</a>, <a id="change">np.mean(train_loss</a><a id="change">)</a>, <a id="change">val_loss</a><a id="change">)</a>)
        <a id="change">model.train()</a>

    return best_model

</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 21</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ki-ljl/fedprox-pytorch/commit/ec79be9ac3b849a36f4a1c44ed59d5569d3f4eaa#diff-1ebfaf6cb3592166b73835fa82333cb7109e7c624865c0039a7b22ff34aa27faL34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38831696</div><div id='project'> Project Name: ki-ljl/fedprox-pytorch</div><div id='commit'> Commit Name: ec79be9ac3b849a36f4a1c44ed59d5569d3f4eaa</div><div id='time'> Time: 2022-06-28</div><div id='author'> Author: lijunliang.ki@gmail.com</div><div id='file'> File Name: client.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(3)</div><div id='n_method'> N Method Name: train(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: client.py</div><div id='n_file'> N File Name: client.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 53</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 81</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    print(&quottraining...&quot)
    loss_function = nn.MSELoss().to(args.device)
    loss = 0
    for <a id="change">epoch</a> in <a id="change">range(</a>args.E<a id="change">)</a>:
        for (seq, label) in Dtr:
            seq = seq.to(args.device)
            label = label.to(args.device)
            y_pred = model(seq)
            loss = loss_function(y_pred, label)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        lr_step.step()

        <a id="change">print(&quotepoch&quot</a>, epoch, <a id="change">&quot:&quot</a>, loss.item()<a id="change">)</a>

    return model

</code></pre><h3>After Change</h3><pre><code class='java'>
    loss_function = nn.MSELoss().to(args.device)
    loss = 0
    best_model = None
    min_val_loss<a id="change"> = 5</a>
    min_epochs = 5
    for <a id="change">epoch</a> in <a id="change">tqdm(</a><a id="change">range(</a>args.E<a id="change">))</a>:
        <a id="change">train_loss = </a><a id="change">[]</a>
        for (seq, label) in Dtr:
            seq = seq.to(args.device)
            label = label.to(args.device)
            y_pred = model(seq)
            loss = loss_function(y_pred, label)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            <a id="change">train_loss.append(</a>loss.cpu().item()<a id="change">)</a>
        lr_step.step()
        &#47&#47 validation
        <a id="change">val_loss = </a><a id="change">get_val_loss(</a>args, model, Val<a id="change">)</a>
        <a id="change">model.train()</a>
        <a id="change">if </a><a id="change">epoch + 1 &gt; min_epochs and val_loss &lt; min_val_loss</a>:
            min_val_loss<a id="change"> = </a>val_loss
            best_model<a id="change"> = copy.deepcopy(</a>model<a id="change">)</a>

        tqdm.write(<a id="change">&quotepoch {:03d} train_loss {:.8f} val_loss {:.8f}&quot.format(</a>epoch, <a id="change">np.mean(</a>train_loss<a id="change">)</a>, val_loss<a id="change">)</a>)

    return best_model
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ki-ljl/fedper/commit/b2e313f883e1580340cc243247b9f9197ed033f2#diff-1ebfaf6cb3592166b73835fa82333cb7109e7c624865c0039a7b22ff34aa27faL19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38831697</div><div id='project'> Project Name: ki-ljl/fedper</div><div id='commit'> Commit Name: b2e313f883e1580340cc243247b9f9197ed033f2</div><div id='time'> Time: 2022-08-05</div><div id='author'> Author: lijunliang.ki@gmail.com</div><div id='file'> File Name: client.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(2)</div><div id='n_method'> N Method Name: train(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: client.py</div><div id='n_file'> N File Name: client.py</div><div id='m_start'> M Start Line: 21</div><div id='m_end'> M End Line: 47</div><div id='n_start'> N Start Line: 36</div><div id='n_end'> N End Line: 73</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    x = copy.deepcopy(ann)
    optimizer = ScaffoldOptimizer(ann.parameters(), lr=ann.lr, weight_decay=1e-4)
    lr_step = StepLR(optimizer, step_size=10, gamma=0.1)
    for <a id="change">epoch</a> in <a id="change">range(</a>ann.E<a id="change">)</a>:
        for (seq, label) in Dtr:
            seq = seq.to(device)
            label = label.to(device)
            y_pred = ann(seq)
            loss = loss_function(y_pred, label)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step(server.control, ann.control)
        lr_step.step()

        <a id="change">print(&quotepoch&quot</a>, epoch, <a id="change">&quot:&quot</a>, loss.item()<a id="change">)</a>
    &#47&#47 update c
    &#47&#47 c+ &lt;- ci - c + 1/(steps * lr) * (x-yi)
    &#47&#47 save ann
    temp = {}</code></pre><h3>After Change</h3><pre><code class='java'>
    optimizer = ScaffoldOptimizer(ann.parameters(), lr=ann.lr, weight_decay=1e-4)
    lr_step = StepLR(optimizer, step_size=10, gamma=0.1)
    &#47&#47 training
    min_epochs<a id="change"> = 10</a>
    best_model = None
    min_val_loss = 5
    for <a id="change">epoch</a> in <a id="change">tqdm(</a><a id="change">range(</a>ann.E<a id="change">))</a>:
        <a id="change">train_loss = </a><a id="change">[]</a>
        for (seq, label) in Dtr:
            seq = seq.to(device)
            label = label.to(device)
            y_pred = ann(seq)
            loss = loss_function(y_pred, label)
            <a id="change">train_loss.append(</a>loss.item()<a id="change">)</a>
            optimizer.zero_grad()
            loss.backward()
            optimizer.step(server.control, ann.control)
        lr_step.step()
        &#47&#47 validation
        <a id="change">val_loss = </a><a id="change">get_val_loss(</a>ann, Val<a id="change">)</a>
        <a id="change">if </a><a id="change">epoch + 1 &gt;= min_epochs and val_loss &lt; min_val_loss</a>:
            min_val_loss<a id="change"> = </a>val_loss
            best_model<a id="change"> = copy.deepcopy(</a>ann<a id="change">)</a>

        print(<a id="change">&quotepoch {:03d} train_loss {:.8f} val_loss {:.8f}&quot.format(</a>epoch, <a id="change">np.mean(</a>train_loss<a id="change">)</a>, val_loss<a id="change">)</a>)
        <a id="change">ann.train()</a>

    ann = copy.deepcopy(best_model)
    &#47&#47 update c
    &#47&#47 c+ &lt;- ci - c + 1/(steps * lr) * (x-yi)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ki-ljl/scaffold-federated-learning/commit/6114b73509f1065fb792b8584726bb52ba328e0b#diff-1ebfaf6cb3592166b73835fa82333cb7109e7c624865c0039a7b22ff34aa27faL23' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38831761</div><div id='project'> Project Name: ki-ljl/scaffold-federated-learning</div><div id='commit'> Commit Name: 6114b73509f1065fb792b8584726bb52ba328e0b</div><div id='time'> Time: 2022-06-28</div><div id='author'> Author: lijunliang.ki@gmail.com</div><div id='file'> File Name: client.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(2)</div><div id='n_method'> N Method Name: train(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: client.py</div><div id='n_file'> N File Name: client.py</div><div id='m_start'> M Start Line: 29</div><div id='m_end'> M End Line: 44</div><div id='n_start'> N Start Line: 41</div><div id='n_end'> N End Line: 73</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    print(&quottraining...&quot)
    loss_function = nn.MSELoss().to(args.device)
    loss = 0
    for <a id="change">epoch</a> in <a id="change">range(</a>args.E<a id="change">)</a>:
        for (seq, label) in Dtr:
            seq = seq.to(args.device)
            label = label.to(args.device)
            y_pred = model(seq)
            optimizer.zero_grad()
            &#47&#47 compute proximal_term
            proximal_term = 0.0
            for w, w_t in zip(model.parameters(), global_model.parameters()):
                proximal_term += (w - w_t).norm(2)

            loss = loss_function(y_pred, label) + (args.mu / 2) * proximal_term
            loss.backward()
            optimizer.step()
        stepLR.step()

        <a id="change">print(&quotepoch&quot</a>, epoch, <a id="change">&quot:&quot</a>, loss.item()<a id="change">)</a>

    return model

</code></pre><h3>After Change</h3><pre><code class='java'>
                                    momentum=0.9, weight_decay=args.weight_decay)
    stepLR = StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)
    &#47&#47 training
    min_epochs<a id="change"> = 10</a>
    best_model = None
    min_val_loss = 5
    print(&quottraining...&quot)
    loss_function = nn.MSELoss().to(args.device)
    for <a id="change">epoch</a> in <a id="change">tqdm(</a><a id="change">range(</a>args.E<a id="change">))</a>:
        <a id="change">train_loss = </a><a id="change">[]</a>
        for (seq, label) in Dtr:
            seq = seq.to(args.device)
            label = label.to(args.device)
            y_pred = model(seq)
            optimizer.zero_grad()
            &#47&#47 compute proximal_term
            proximal_term = 0.0
            for w, w_t in zip(model.parameters(), global_model.parameters()):
                proximal_term += (w - w_t).norm(2)

            loss = loss_function(y_pred, label) + (args.mu / 2) * proximal_term
            <a id="change">train_loss.append(</a>loss.item()<a id="change">)</a>
            loss.backward()
            optimizer.step()
        stepLR.step()
        &#47&#47 validation
        <a id="change">val_loss = </a><a id="change">get_val_loss(</a>args, model, Val<a id="change">)</a>
        <a id="change">if </a><a id="change">epoch + 1 &gt;= min_epochs and val_loss &lt; min_val_loss</a>:
            min_val_loss<a id="change"> = </a>val_loss
            best_model<a id="change"> = copy.deepcopy(</a>model<a id="change">)</a>

        print(<a id="change">&quotepoch {:03d} train_loss {:.8f} val_loss {:.8f}&quot.format(</a>epoch, <a id="change">np.mean(</a>train_loss<a id="change">)</a>, val_loss<a id="change">)</a>)
        <a id="change">model.train()</a>

    return best_model

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ki-ljl/fedprox-pytorch/commit/ec79be9ac3b849a36f4a1c44ed59d5569d3f4eaa#diff-1ebfaf6cb3592166b73835fa82333cb7109e7c624865c0039a7b22ff34aa27faL19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38831707</div><div id='project'> Project Name: ki-ljl/fedprox-pytorch</div><div id='commit'> Commit Name: ec79be9ac3b849a36f4a1c44ed59d5569d3f4eaa</div><div id='time'> Time: 2022-06-28</div><div id='author'> Author: lijunliang.ki@gmail.com</div><div id='file'> File Name: client.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(3)</div><div id='n_method'> N Method Name: train(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: client.py</div><div id='n_file'> N File Name: client.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 53</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 81</div><BR>