<html><h3>Pattern ID :1099
</h3><img src='5550932.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu().numpy()
        sounddevice.play(wav, samplerate=16000)
        <a id="change">if blocking</a>:
            from time import sleep
            <a id="change">sounddevice.wait()</a>
            <a id="change">sleep(0.5</a><a id="change">)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu()

        <a id="change">if not blocking</a>:
            sounddevice.play(<a id="change">wav.numpy()</a>, samplerate=16000)

        else:
            silence<a id="change"> = torch</a><a id="change">.zeros([12000</a>]<a id="change">)</a>
            <a id="change">sounddevice.play(torch.cat((wav, silence), 0).numpy()</a><a id="change">, samplerate=16000)</a>
            <a id="change">sounddevice.wait()</a>
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 7</div><BR><div id='size'>Non-data size: 14</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/bcd49e18ea00dba6d8f2a1489f775c94a95dd515#diff-a6275ccf529f8a90da2c5bcf972061f18aabc1aca0e64bb1343448e55432cd85L267' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5550932</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: bcd49e18ea00dba6d8f2a1489f775c94a95dd515</div><div id='time'> Time: 2021-04-09</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/CSS10_DE_TransformerTTSInference.py</div><div id='m_class'> M Class Name: CSS10_DE_TransformerTTSInference</div><div id='n_method'> N Class Name: CSS10_DE_TransformerTTSInference</div><div id='m_method'> M Method Name: read_aloud(4)</div><div id='n_method'> N Method Name: read_aloud(4)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/CSS10_DE_TransformerTTSInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/CSS10_DE_TransformerTTSInference.py</div><div id='m_start'> M Start Line: 267</div><div id='m_end'> M End Line: 272</div><div id='n_start'> N Start Line: 267</div><div id='n_end'> N End Line: 275</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu().numpy()
        sounddevice.play(wav, samplerate=16000)
        <a id="change">if blocking</a>:
            from time import sleep
            <a id="change">sounddevice.wait()</a>
            <a id="change">sleep(0.5</a><a id="change">)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu()

        <a id="change">if not blocking</a>:
            sounddevice.play(<a id="change">wav.numpy()</a>, samplerate=16000)

        else:
            silence<a id="change"> = </a><a id="change">torch.zeros([12000</a>]<a id="change">)</a>
            <a id="change">sounddevice.play(torch.cat((wav, silence), 0).numpy()</a><a id="change">, samplerate=16000)</a>
            <a id="change">sounddevice.wait()</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/bcd49e18ea00dba6d8f2a1489f775c94a95dd515#diff-dab6edd8d6f0f2ed19df76cb1a0e53c8b06f151b518f2cdc301b80e79022e62aL267' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5550933</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: bcd49e18ea00dba6d8f2a1489f775c94a95dd515</div><div id='time'> Time: 2021-04-09</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/LibriTTS_TransformerTTSInference.py</div><div id='m_class'> M Class Name: LibriTTS_TransformerTTSInference</div><div id='n_method'> N Class Name: LibriTTS_TransformerTTSInference</div><div id='m_method'> M Method Name: read_aloud(4)</div><div id='n_method'> N Method Name: read_aloud(4)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/LibriTTS_TransformerTTSInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/LibriTTS_TransformerTTSInference.py</div><div id='m_start'> M Start Line: 268</div><div id='m_end'> M End Line: 273</div><div id='n_start'> N Start Line: 271</div><div id='n_end'> N End Line: 279</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu().numpy()
        sounddevice.play(wav, samplerate=16000)
        <a id="change">if blocking</a>:
            from time import sleep
            <a id="change">sounddevice.wait()</a>
            <a id="change">sleep(0.5</a><a id="change">)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu()

        <a id="change">if not blocking</a>:
            sounddevice.play(<a id="change">wav.numpy()</a>, samplerate=16000)

        else:
            silence<a id="change"> = </a><a id="change">torch.zeros([12000</a>]<a id="change">)</a>
            <a id="change">sounddevice.play(torch.cat((wav, silence), 0).numpy()</a><a id="change">, samplerate=16000)</a>
            <a id="change">sounddevice.wait()</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/bcd49e18ea00dba6d8f2a1489f775c94a95dd515#diff-74abc2e7bebe273ec5fa359ca3a9ef79f13947e109a095575f6b818f4e7f438cL255' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5550934</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: bcd49e18ea00dba6d8f2a1489f775c94a95dd515</div><div id='time'> Time: 2021-04-09</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/LibriTTS_FastSpeechInference.py</div><div id='m_class'> M Class Name: LibriTTS_FastSpeechInference</div><div id='n_method'> N Class Name: LibriTTS_FastSpeechInference</div><div id='m_method'> M Method Name: read_aloud(4)</div><div id='n_method'> N Method Name: read_aloud(4)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/LibriTTS_FastSpeechInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/LibriTTS_FastSpeechInference.py</div><div id='m_start'> M Start Line: 256</div><div id='m_end'> M End Line: 261</div><div id='n_start'> N Start Line: 259</div><div id='n_end'> N End Line: 267</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu().numpy()
        sounddevice.play(wav, samplerate=16000)
        <a id="change">if blocking</a>:
            from time import sleep
            <a id="change">sounddevice.wait()</a>
            <a id="change">sleep(0.5</a><a id="change">)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu()

        <a id="change">if not blocking</a>:
            sounddevice.play(<a id="change">wav.numpy()</a>, samplerate=16000)

        else:
            silence<a id="change"> = </a><a id="change">torch.zeros([12000</a>]<a id="change">)</a>
            <a id="change">sounddevice.play(torch.cat((wav, silence), 0).numpy()</a><a id="change">, samplerate=16000)</a>
            <a id="change">sounddevice.wait()</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/bcd49e18ea00dba6d8f2a1489f775c94a95dd515#diff-a6275ccf529f8a90da2c5bcf972061f18aabc1aca0e64bb1343448e55432cd85L266' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5550935</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: bcd49e18ea00dba6d8f2a1489f775c94a95dd515</div><div id='time'> Time: 2021-04-09</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/CSS10_DE_TransformerTTSInference.py</div><div id='m_class'> M Class Name: CSS10_DE_TransformerTTSInference</div><div id='n_method'> N Class Name: CSS10_DE_TransformerTTSInference</div><div id='m_method'> M Method Name: read_aloud(4)</div><div id='n_method'> N Method Name: read_aloud(4)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/CSS10_DE_TransformerTTSInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/CSS10_DE_TransformerTTSInference.py</div><div id='m_start'> M Start Line: 267</div><div id='m_end'> M End Line: 272</div><div id='n_start'> N Start Line: 267</div><div id='n_end'> N End Line: 275</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu().numpy()
        sounddevice.play(wav, samplerate=16000)
        <a id="change">if blocking</a>:
            from time import sleep
            <a id="change">sounddevice.wait()</a>
            <a id="change">sleep(0.5</a><a id="change">)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu()

        <a id="change">if not blocking</a>:
            sounddevice.play(<a id="change">wav.numpy()</a>, samplerate=16000)

        else:
            silence<a id="change"> = </a><a id="change">torch.zeros([12000</a>]<a id="change">)</a>
            <a id="change">sounddevice.play(torch.cat((wav, silence), 0).numpy()</a><a id="change">, samplerate=16000)</a>
            <a id="change">sounddevice.wait()</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/bcd49e18ea00dba6d8f2a1489f775c94a95dd515#diff-4b2f26f3d3287b567ffaec37b852ede237af7e76f93c389c33396f41ee6a1cf0L254' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5550929</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: bcd49e18ea00dba6d8f2a1489f775c94a95dd515</div><div id='time'> Time: 2021-04-09</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/Thorsten_FastSpeechInference.py</div><div id='m_class'> M Class Name: Thorsten_FastSpeechInference</div><div id='n_method'> N Class Name: Thorsten_FastSpeechInference</div><div id='m_method'> M Method Name: read_aloud(4)</div><div id='n_method'> N Method Name: read_aloud(4)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/Thorsten_FastSpeechInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/Thorsten_FastSpeechInference.py</div><div id='m_start'> M Start Line: 255</div><div id='m_end'> M End Line: 260</div><div id='n_start'> N Start Line: 255</div><div id='n_end'> N End Line: 263</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu().numpy()
        sounddevice.play(wav, samplerate=16000)
        <a id="change">if blocking</a>:
            from time import sleep
            <a id="change">sounddevice.wait()</a>
            <a id="change">sleep(0.5</a><a id="change">)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu()

        <a id="change">if not blocking</a>:
            sounddevice.play(<a id="change">wav.numpy()</a>, samplerate=16000)

        else:
            silence<a id="change"> = </a><a id="change">torch.zeros([12000</a>]<a id="change">)</a>
            <a id="change">sounddevice.play(torch.cat((wav, silence), 0).numpy()</a><a id="change">, samplerate=16000)</a>
            <a id="change">sounddevice.wait()</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/bcd49e18ea00dba6d8f2a1489f775c94a95dd515#diff-5bc5a06d8b433d6922e60b5122e9c76c928a2c5cc586bf3652f7e3a892f92434L266' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5550931</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: bcd49e18ea00dba6d8f2a1489f775c94a95dd515</div><div id='time'> Time: 2021-04-09</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/Thorsten_TransformerTTSInference.py</div><div id='m_class'> M Class Name: Thorsten_TransformerTTSInference</div><div id='n_method'> N Class Name: Thorsten_TransformerTTSInference</div><div id='m_method'> M Method Name: read_aloud(4)</div><div id='n_method'> N Method Name: read_aloud(4)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/Thorsten_TransformerTTSInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/Thorsten_TransformerTTSInference.py</div><div id='m_start'> M Start Line: 267</div><div id='m_end'> M End Line: 272</div><div id='n_start'> N Start Line: 267</div><div id='n_end'> N End Line: 275</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu().numpy()
        sounddevice.play(wav, samplerate=16000)
        <a id="change">if blocking</a>:
            from time import sleep
            <a id="change">sounddevice.wait()</a>
            <a id="change">sleep(0.5</a><a id="change">)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu()

        <a id="change">if not blocking</a>:
            sounddevice.play(<a id="change">wav.numpy()</a>, samplerate=16000)

        else:
            silence<a id="change"> = </a><a id="change">torch.zeros([12000</a>]<a id="change">)</a>
            <a id="change">sounddevice.play(torch.cat((wav, silence), 0).numpy()</a><a id="change">, samplerate=16000)</a>
            <a id="change">sounddevice.wait()</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/bcd49e18ea00dba6d8f2a1489f775c94a95dd515#diff-e6d48253299933f465e93859a42d702a5dbda1a7756b6a45627b057bf79fb6ccL254' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5550940</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: bcd49e18ea00dba6d8f2a1489f775c94a95dd515</div><div id='time'> Time: 2021-04-09</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/CSS10_DE_FastSpeechInference.py</div><div id='m_class'> M Class Name: CSS10_DE_FastSpeechInference</div><div id='n_method'> N Class Name: CSS10_DE_FastSpeechInference</div><div id='m_method'> M Method Name: read_aloud(4)</div><div id='n_method'> N Method Name: read_aloud(4)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/CSS10_DE_FastSpeechInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/CSS10_DE_FastSpeechInference.py</div><div id='m_start'> M Start Line: 255</div><div id='m_end'> M End Line: 260</div><div id='n_start'> N Start Line: 255</div><div id='n_end'> N End Line: 263</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu().numpy()
        sounddevice.play(wav, samplerate=16000)
        <a id="change">if blocking</a>:
            from time import sleep
            <a id="change">sounddevice.wait()</a>
            <a id="change">sleep(0.5</a><a id="change">)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
    def read_aloud(self, text, view=False, blocking=False):
        wav = self(text, view).cpu()

        <a id="change">if not blocking</a>:
            sounddevice.play(<a id="change">wav.numpy()</a>, samplerate=16000)

        else:
            silence<a id="change"> = </a><a id="change">torch.zeros([12000</a>]<a id="change">)</a>
            <a id="change">sounddevice.play(torch.cat((wav, silence), 0).numpy()</a><a id="change">, samplerate=16000)</a>
            <a id="change">sounddevice.wait()</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/bcd49e18ea00dba6d8f2a1489f775c94a95dd515#diff-7124e6f073c534a915fb11031490bc1eefbd46b5fe091b401d9c84fad2d69d69L266' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5550937</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: bcd49e18ea00dba6d8f2a1489f775c94a95dd515</div><div id='time'> Time: 2021-04-09</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/LJSpeech_TransformerTTSInference.py</div><div id='m_class'> M Class Name: LJSpeech_TransformerTTSInference</div><div id='n_method'> N Class Name: LJSpeech_TransformerTTSInference</div><div id='m_method'> M Method Name: read_aloud(4)</div><div id='n_method'> N Method Name: read_aloud(4)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/LJSpeech_TransformerTTSInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/LJSpeech_TransformerTTSInference.py</div><div id='m_start'> M Start Line: 267</div><div id='m_end'> M End Line: 272</div><div id='n_start'> N Start Line: 267</div><div id='n_end'> N End Line: 275</div><BR>