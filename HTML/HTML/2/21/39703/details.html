<html><h3>Pattern ID :39703
</h3><img src='113006364.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 Data loading code
    normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    <a id="change">if args.center_crop</a>:
        train_transform<a id="change"> = T</a><a id="change">.Compose([
            </a><a id="change">ResizeImage(256</a><a id="change">)</a>,
            <a id="change">T.CenterCrop(224</a><a id="change">)</a>,
            <a id="change">T.RandomHorizontalFlip()</a>,
            <a id="change">T.ToTensor()</a>,
            normalize<a id="change"></a>
        ]<a id="change">)</a>
    else:
        train_transform = T.Compose([
            ResizeImage(256),</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(args.lr), momentum=args.momentum, weight_decay=args.wd, nesterov=True)
    milestones<a id="change"> = </a><a id="change">[]</a>
    <a id="change">for milestone</a> in <a id="change">args.lr_decay_epochs.split(&quot,&quot</a><a id="change">)</a><a id="change">:
        </a><a id="change">milestones.append(int(milestone</a><a id="change">)</a><a id="change">)</a>

    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(
        optimizer, milestones, gamma=args.lr_gamma)

    &#47&#47 resume from the best checkpoint
    if args.phase != &quottrain&quot:
        checkpoint = torch.load(logger.get_checkpoint_path(&quotbest&quot), map_location=&quotcpu&quot)
        classifier.load_state_dict(checkpoint)

    if args.phase == &quottest&quot:
        acc1 = validate(test_loader, classifier, args)
        print(acc1)
        return


    &#47&#47 compute relationship

    relationship_path = &quotrelationship_d.npy&quot
    &#47&#47 if not os.path.exists(relationship_path):
    if 1 == 1:
        train_source_labels, train_target_labels = get_feature(determin_train_loader, classifier)

        val_source_labels, val_target_labels = get_feature(val_loader, classifier)
        relationship = direct_relationship_learning(train_source_labels, train_target_labels, val_source_labels, val_target_labels)

        np.save(relationship_path, relationship)
    else:
        relationship = np.load(relationship_path)

    &#47&#47 start training
    best_acc1 = 0.0
    for epoch in range(args.epochs):
        &#47&#47 train for one epoch
        train(train_loader, classifier, optimizer,
              epoch, relationship, args)
        <a id="change">lr_scheduler.step()</a>
        &#47&#47 evaluate on validation set
        acc1 = validate(val_loader, classifier, args)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 15</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/96e352da11edca9558ecbc23473e925f96db18e7#diff-46e5f7f40f62982cd2fed0316172ea915e81cf8a967098e824cd534cc2215dc0L49' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113006364</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 96e352da11edca9558ecbc23473e925f96db18e7</div><div id='time'> Time: 2021-03-06</div><div id='author'> Author: jiyf990330@163.com</div><div id='file'> File Name: examples-ft/classification/co_tuning.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples-ft/classification/co_tuning.py</div><div id='n_file'> N File Name: examples-ft/classification/co_tuning.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 132</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 125</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 Data loading code
    normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    <a id="change">if args.center_crop</a>:
        train_transform<a id="change"> = </a><a id="change">T.Compose([
            </a><a id="change">ResizeImage(256</a><a id="change">)</a>,
            <a id="change">T.CenterCrop(224</a><a id="change">)</a>,
            <a id="change">T.RandomHorizontalFlip()</a>,
            <a id="change">T.ToTensor()</a>,
            normalize<a id="change"></a>
        ]<a id="change">)</a>
    else:
        train_transform = T.Compose([
            ResizeImage(256),</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(args.lr), momentum=args.momentum, weight_decay=args.wd, nesterov=True)
    milestones<a id="change"> = </a><a id="change">[]</a>
    <a id="change">for milestone</a> in <a id="change">args.lr_decay_epochs.split(&quot,&quot</a><a id="change">)</a><a id="change">:
        </a><a id="change">milestones.append(int(</a>milestone<a id="change">)</a><a id="change">)</a>

    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(
        optimizer, milestones, gamma=args.lr_gamma)
    &#47&#47 resume from the best checkpoint
    if args.phase != &quottrain&quot:
        checkpoint = torch.load(logger.get_checkpoint_path(&quotbest&quot), map_location=&quotcpu&quot)
        classifier.load_state_dict(checkpoint)

    if args.phase == &quottest&quot:
        acc1 = validate(test_loader, classifier, args)
        print(acc1)
        return

    &#47&#47 start training
    best_acc1 = 0.0
    bss_module = BSS(k=args.k)
    for epoch in range(args.epochs):
        &#47&#47 train for one epoch
        train(train_loader, classifier, bss_module, optimizer,
              epoch, args)
        <a id="change">lr_scheduler.step()</a>
        &#47&#47 evaluate on validation set
        acc1 = validate(val_loader, classifier, args)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/96e352da11edca9558ecbc23473e925f96db18e7#diff-2e03f86ced0a44455d83c026773232973fc32252fd8007daedfeb10640c080f4L32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113006361</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 96e352da11edca9558ecbc23473e925f96db18e7</div><div id='time'> Time: 2021-03-06</div><div id='author'> Author: jiyf990330@163.com</div><div id='file'> File Name: examples-ft/classification/BSS.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples-ft/classification/BSS.py</div><div id='n_file'> N File Name: examples-ft/classification/BSS.py</div><div id='m_start'> M Start Line: 48</div><div id='m_end'> M End Line: 108</div><div id='n_start'> N Start Line: 48</div><div id='n_end'> N End Line: 102</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 Data loading code
    normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    <a id="change">if args.center_crop</a>:
        train_transform<a id="change"> = </a><a id="change">T.Compose([
            </a><a id="change">ResizeImage(256</a><a id="change">)</a>,
            <a id="change">T.CenterCrop(224</a><a id="change">)</a>,
            <a id="change">T.RandomHorizontalFlip()</a>,
            <a id="change">T.ToTensor()</a>,
            normalize<a id="change"></a>
        ]<a id="change">)</a>
    else:
        train_transform = T.Compose([
            ResizeImage(256),</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(args.lr), momentum=args.momentum, weight_decay=args.wd, nesterov=True)

    milestones<a id="change"> = </a><a id="change">[]</a>
    <a id="change">for milestone</a> in <a id="change">args.lr_decay_epochs.split(&quot,&quot</a><a id="change">)</a><a id="change">:
        </a><a id="change">milestones.append(int(</a>milestone<a id="change">)</a><a id="change">)</a>

    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(
        optimizer, milestones, gamma=args.lr_gamma)
    print(&quotbase&quot, lr_scheduler.base_lrs)
    print(milestones)
    input()
    &#47&#47 resume from the best checkpoint
    if args.phase != &quottrain&quot:
        checkpoint = torch.load(logger.get_checkpoint_path(&quotbest&quot), map_location=&quotcpu&quot)
        classifier.load_state_dict(checkpoint)

    if args.phase == &quottest&quot:
        acc1 = validate(test_loader, classifier, args)
        print(acc1)
        return

    &#47&#47 start training
    best_acc1 = 0.0
    for epoch in range(args.epochs):
        &#47&#47 train for one epoch
        train(train_loader, classifier, optimizer,
               epoch, args)
        <a id="change">lr_scheduler.step()</a>
        &#47&#47 evaluate on validation set
        acc1 = validate(val_loader, classifier, args)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/96e352da11edca9558ecbc23473e925f96db18e7#diff-de517f4be733b533531facce839aff3df62bd42f60dcfc65b33d03da3b12fe1cL31' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113006362</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 96e352da11edca9558ecbc23473e925f96db18e7</div><div id='time'> Time: 2021-03-06</div><div id='author'> Author: jiyf990330@163.com</div><div id='file'> File Name: examples-ft/classification/baseline.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples-ft/classification/baseline.py</div><div id='n_file'> N File Name: examples-ft/classification/baseline.py</div><div id='m_start'> M Start Line: 47</div><div id='m_end'> M End Line: 106</div><div id='n_start'> N Start Line: 46</div><div id='n_end'> N End Line: 102</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 Data loading code
    normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    <a id="change">if args.center_crop</a>:
        train_transform<a id="change"> = </a><a id="change">T.Compose([
            </a><a id="change">ResizeImage(256</a><a id="change">)</a>,
            <a id="change">T.CenterCrop(224</a><a id="change">)</a>,
            <a id="change">T.RandomHorizontalFlip()</a>,
            <a id="change">T.ToTensor()</a>,
            normalize<a id="change"></a>
        ]<a id="change">)</a>
    else:
        train_transform = T.Compose([
            ResizeImage(256),</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(args.lr), momentum=args.momentum, weight_decay=args.wd, nesterov=True)

    milestones<a id="change"> = </a><a id="change">[]</a>
    <a id="change">for milestone</a> in <a id="change">args.lr_decay_epochs.split(&quot,&quot</a><a id="change">)</a><a id="change">:
        </a><a id="change">milestones.append(int(</a>milestone<a id="change">)</a><a id="change">)</a>
    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(
        optimizer, milestones, gamma=args.lr_gamma)
    &#47&#47 resume from the best checkpoint
    if args.phase != &quottrain&quot:
        checkpoint = torch.load(logger.get_checkpoint_path(&quotbest&quot), map_location=&quotcpu&quot)
        classifier.load_state_dict(checkpoint)

    if args.phase == &quottest&quot:
        acc1 = validate(test_loader, classifier, args)
        print(acc1)
        return

    &#47&#47 start training
    best_acc1 = 0.0
    for epoch in range(args.epochs):
        &#47&#47 train for one epoch
        train(train_loader, classifier, optimizer, epoch, args)
        <a id="change">lr_scheduler.step()</a>

        &#47&#47 evaluate on validation set
        acc1 = validate(val_loader, classifier, args)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/96e352da11edca9558ecbc23473e925f96db18e7#diff-af213fe85ad680208e4b0dd406f03fe20dcb22d3e4d00d5808a69f56510c84ceL32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113006363</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: 96e352da11edca9558ecbc23473e925f96db18e7</div><div id='time'> Time: 2021-03-06</div><div id='author'> Author: jiyf990330@163.com</div><div id='file'> File Name: examples-ft/classification/StochNorm.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples-ft/classification/StochNorm.py</div><div id='n_file'> N File Name: examples-ft/classification/StochNorm.py</div><div id='m_start'> M Start Line: 48</div><div id='m_end'> M End Line: 109</div><div id='n_start'> N Start Line: 47</div><div id='n_end'> N End Line: 100</div><BR>