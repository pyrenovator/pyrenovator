<html><h3>Pattern ID :19342
</h3><img src='63077392.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            request_obj = dist.broadcast(
                tensor, self.local_rank, group=pg, async_op=True)
            request_objects.append(request_obj)
        <a id="change">return </a>request_objects

    def _recv_tensors_bcast(self, x, batch_idx, src, pg):
        &#47&#47 TODO: Double buffering like p2p</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 tensor.detach_()  &#47&#47 RuntimeError: Can&quott detach views in-place. Use detach() instead
            &#47&#47 FIXME: see https://github.com/pytorch/pytorch/issues/25814
            &#47&#47 (its problematic with the tensor.grad, which we plan to avoid anyway.)
            <a id="change">if </a>is_grad:
                <a id="change">with torch.no_grad()</a><a id="change">:
                    </a>tensor<a id="change"> = </a><a id="change">tensor.clone().detach_()</a>
            else:
                tensor.detach_()

            if self.verbose:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/saareliad/ftpipe/commit/1700dc3f0c7fe3e4b196360d6b6e4d9e4cd5b74e#diff-597c91cede4cb70894e6f1af1f3b0d85ca3900d3cb65726958a00dc960104605L27' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63077392</div><div id='project'> Project Name: saareliad/ftpipe</div><div id='commit'> Commit Name: 1700dc3f0c7fe3e4b196360d6b6e4d9e4cd5b74e</div><div id='time'> Time: 2019-12-24</div><div id='author'> Author: saareliad@campus.technion.ac.il</div><div id='file'> File Name: pipeline/communication/bcast.py</div><div id='m_class'> M Class Name: BCASTCommunicationHandler</div><div id='n_method'> N Class Name: BCASTCommunicationHandler</div><div id='m_method'> M Method Name: _send_tensors_bcast(5)</div><div id='n_method'> N Method Name: _send_tensors_bcast(4)</div><div id='m_parent_class'> M Parent Class: SimpleCommBase</div><div id='n_parent_class'> N Parent Class: SimpleCommBase</div><div id='m_file'> M File Name: pipeline/communication/bcast.py</div><div id='n_file'> N File Name: pipeline/communication/bcast.py</div><div id='m_start'> M Start Line: 27</div><div id='m_end'> M End Line: 37</div><div id='n_start'> N Start Line: 28</div><div id='n_end'> N End Line: 52</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        t = self.sample_random_times(b, device = device)
        img = decimal_to_bits(img)

        <a id="change">return </a>self.p_losses(img, t, *args, **kwargs)

&#47&#47 dataset classes
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 this technique will slow down training by 25%, but seems to lower FID significantly

        self_cond = None
        <a id="change">if </a>random() &lt; 0.5:
            <a id="change">with torch.no_grad()</a><a id="change">:
                </a>self_cond<a id="change"> = </a><a id="change">self.model(noised_img, noise_cond).detach_()</a>

        &#47&#47 predict and take gradient step

        pred = self.model(noised_img, noise_cond, self_cond)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/bit-diffusion/commit/70044d12755081b62303081a44ee196b783efd1b#diff-fa1704ed33520f9e00eadcb67b10c809ebe7cdd9d08435ae908b1c8126a28435L595' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63077393</div><div id='project'> Project Name: lucidrains/bit-diffusion</div><div id='commit'> Commit Name: 70044d12755081b62303081a44ee196b783efd1b</div><div id='time'> Time: 2022-08-17</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: bit_diffusion/bit_diffusion.py</div><div id='m_class'> M Class Name: BitDiffusion</div><div id='n_method'> N Class Name: BitDiffusion</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: bit_diffusion/bit_diffusion.py</div><div id='n_file'> N File Name: bit_diffusion/bit_diffusion.py</div><div id='m_start'> M Start Line: 599</div><div id='m_end'> M End Line: 602</div><div id='n_start'> N Start Line: 568</div><div id='n_end'> N End Line: 587</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        super().__init__()

    def forward(self, x):
        <a id="change">return </a>x
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 this technique will slow down training by 25%, but seems to lower FID significantly

        self_cond = None
        <a id="change">if </a>random() &lt; 0.5:
            <a id="change">with torch.no_grad()</a><a id="change">:
                </a>self_cond<a id="change"> = </a><a id="change">self.model(noised_img, noise_level).detach_()</a>

        &#47&#47 predict and take gradient step

        pred = self.model(noised_img, noise_level, self_cond)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/chroma-pytorch/commit/aed1623c205056b5a530d116d30f647eb6693b14#diff-87cc35c197eceb7ad843ce57b88d472a20512b8f8fe0f03cacecbd1101576f43L10' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63077389</div><div id='project'> Project Name: lucidrains/chroma-pytorch</div><div id='commit'> Commit Name: aed1623c205056b5a530d116d30f647eb6693b14</div><div id='time'> Time: 2022-12-04</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: chroma_pytorch/chroma_pytorch.py</div><div id='m_class'> M Class Name: Chroma</div><div id='n_method'> N Class Name: Chroma</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: chroma_pytorch/chroma_pytorch.py</div><div id='n_file'> N File Name: chroma_pytorch/chroma_pytorch.py</div><div id='m_start'> M Start Line: 11</div><div id='m_end'> M End Line: 11</div><div id='n_start'> N Start Line: 506</div><div id='n_end'> N End Line: 536</div><BR>