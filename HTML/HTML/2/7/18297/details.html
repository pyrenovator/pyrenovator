<html><h3>Pattern ID :18297
</h3><img src='59940422.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                outputs = model(inputs, masked_lm_labels=labels, position_ids=position_ids, token_type_ids=segment_ids)
            else:
                if args.model_type == &quotbart&quot:
                    decoder_input_ids = <a id="change">labels[:, :-1].contiguous()</a>
                    decoder_input_ids[decoder_input_ids == args.mlm_ignore_index] = tokenizer.pad_token_id
                    lm_labels = labels[:, 1:].clone()
                    outputs = model(inputs, labels=labels, lm_labels=lm_labels, decoder_input_ids=decoder_input_ids, position_ids=position_ids, token_type_ids=segment_ids)
                else:</code></pre><h3>After Change</h3><pre><code class='java'>
            inputs, labels = mask_tokens(inputs, labels, tokenizer, args.mlm_probability, args.mlm_ignore_index)
        inputs = inputs.to(args.device)
        labels = labels.to(args.device)
        attention_mask<a id="change"> = </a><a id="change">attention_mask.to(</a>args.device<a id="change">)</a>
        position_ids = position_ids.to(args.device)
        segment_ids = segment_ids.to(args.device)

        with torch.no_grad():</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/b84a6548a69fd9f62652eed1c74fd4b1fdb8b65b#diff-90e760d3065758cd3fed35d36be801cfed8d2418d888df295dbecdc933432ad7L318' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59940422</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: b84a6548a69fd9f62652eed1c74fd4b1fdb8b65b</div><div id='time'> Time: 2020-11-15</div><div id='author'> Author: mehrad@stanford.edu</div><div id='file'> File Name: genienlp/paraphrase/run_lm_finetuning.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate(5)</div><div id='n_method'> N Method Name: evaluate(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: genienlp/paraphrase/run_lm_finetuning.py</div><div id='n_file'> N File Name: genienlp/paraphrase/run_lm_finetuning.py</div><div id='m_start'> M Start Line: 318</div><div id='m_end'> M End Line: 344</div><div id='n_start'> N Start Line: 330</div><div id='n_end'> N End Line: 369</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            if args.model_type in [&quotbart&quot, &quotmbart&quot]:
                &#47&#47 this should have been handled internally by huggingfaces&quots BART code
                &#47&#47 TODO remove this once they add it
                decoder_input_ids = <a id="change">labels[:, :-1].contiguous()</a>
                decoder_input_ids[decoder_input_ids == args.mlm_ignore_index] = tokenizer.pad_token_id
                lm_labels = labels[:, 1:].clone()
                model_inputs[&quotdecoder_input_ids&quot] = decoder_input_ids
                model_inputs[&quotlm_labels&quot] = lm_labels</code></pre><h3>After Change</h3><pre><code class='java'>
                inputs, labels = mask_tokens(inputs, labels, tokenizer, args.mlm_probability, args.mlm_ignore_index)
            inputs = inputs.to(args.device)
            labels = labels.to(args.device)
            attention_mask<a id="change"> = </a><a id="change">attention_mask.to(</a>args.device<a id="change">)</a>
            position_ids = position_ids.to(args.device)
            segment_ids = segment_ids.to(args.device)
            model.train()
            </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/b84a6548a69fd9f62652eed1c74fd4b1fdb8b65b#diff-90e760d3065758cd3fed35d36be801cfed8d2418d888df295dbecdc933432ad7L68' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59940420</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: b84a6548a69fd9f62652eed1c74fd4b1fdb8b65b</div><div id='time'> Time: 2020-11-15</div><div id='author'> Author: mehrad@stanford.edu</div><div id='file'> File Name: genienlp/paraphrase/run_lm_finetuning.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(4)</div><div id='n_method'> N Method Name: train(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: genienlp/paraphrase/run_lm_finetuning.py</div><div id='n_file'> N File Name: genienlp/paraphrase/run_lm_finetuning.py</div><div id='m_start'> M Start Line: 182</div><div id='m_end'> M End Line: 207</div><div id='n_start'> N Start Line: 190</div><div id='n_end'> N End Line: 219</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                                           )
            input_ids.append(encoding_dict.input_ids)
        input_ids = torch.cat(input_ids, dim=0).to(self.device)
        decoder_input_ids = <a id="change">input_ids[:, :-1].contiguous()</a>
        labels = input_ids[:, 1:].contiguous()
        perm_mask = torch.ones((input_ids.shape[0],
                                decoder_input_ids.shape[1],
                                decoder_input_ids.shape[1]),</code></pre><h3>After Change</h3><pre><code class='java'>
            input_ids.append(encoding_dict.input_ids)
            attn_masks.append(encoding_dict[&quotattention_mask&quot])
        input_ids = torch.cat(input_ids, dim=0).to(self.device)
        attn_masks<a id="change"> = </a><a id="change">torch.cat(attn_masks, dim=0).to(</a>self.device<a id="change">)</a>

        decoder_target_ids = input_ids[:, 1:].contiguous()

        perm_mask = torch.ones(input_ids.shape[0], input_ids.shape[1], input_ids.shape[1]).to(self.device)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/53c76331ad0c943d52e3310affd25d0e505eb830#diff-46c204cb38a17e9732183ae3be044daf1499fd8305089a2b66f8f827b7ee5e66L77' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59940421</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 53c76331ad0c943d52e3310affd25d0e505eb830</div><div id='time'> Time: 2021-01-19</div><div id='author'> Author: 1020139164@qq.com</div><div id='file'> File Name: textbox/model/LM/xlnet.py</div><div id='m_class'> M Class Name: XLNet</div><div id='n_method'> N Class Name: XLNet</div><div id='m_method'> M Method Name: calculate_loss(4)</div><div id='n_method'> N Method Name: calculate_loss(3)</div><div id='m_parent_class'> M Parent Class: UnconditionalGenerator</div><div id='n_parent_class'> N Parent Class: UnconditionalGenerator</div><div id='m_file'> M File Name: textbox/model/LM/xlnet.py</div><div id='n_file'> N File Name: textbox/model/LM/xlnet.py</div><div id='m_start'> M Start Line: 90</div><div id='m_end'> M End Line: 113</div><div id='n_start'> N Start Line: 72</div><div id='n_end'> N End Line: 111</div><BR>