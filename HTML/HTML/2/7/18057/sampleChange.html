<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                    optimizer.step()
                    if scheduler is not None:
                        scheduler.step()
                    <a id="change">self.model.zero_grad()</a>
                    global_step += 1
                    if (global_step) % print_every == 0:
                        logger.info(f"Global step: {global_step}, epoch step:{step+1}")
                    if (global_step%train_steps_per_epoch in checkpoints) \</code></pre><h3>After Change</h3><pre><code class='java'>
                writer_step += 1

                if (step+1)%self.t_config.gradient_accumulation_steps == 0:
                    <a id="change">if max_grad_norm &gt; 0</a>:
                        <a id="change">torch.nn.utils.clip_grad_norm_(</a><a id="change">self.model.parameters()</a>, <a id="change">max_grad_norm</a><a id="change">)</a>
                    optimizer.step()
                    if scheduler is not None:
                        scheduler.step()
                    optimizer.zero_grad()</code></pre>