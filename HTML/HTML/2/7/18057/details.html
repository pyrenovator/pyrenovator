<html><h3>Pattern ID :18057
</h3><img src='59186803.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                    optimizer.step()
                    if scheduler is not None:
                        scheduler.step()
                    <a id="change">self.model.zero_grad()</a>
                    global_step += 1
                    if (global_step) % print_every == 0:
                        logger.info(f"Global step: {global_step}, epoch step:{step+1}")
                    if (global_step%train_steps_per_epoch in checkpoints) \</code></pre><h3>After Change</h3><pre><code class='java'>
                writer_step += 1

                if (step+1)%self.t_config.gradient_accumulation_steps == 0:
                    <a id="change">if max_grad_norm &gt; 0</a>:
                        <a id="change">torch.nn.utils.clip_grad_norm_(</a><a id="change">self.model.parameters()</a>, <a id="change">max_grad_norm</a><a id="change">)</a>
                    optimizer.step()
                    if scheduler is not None:
                        scheduler.step()
                    optimizer.zero_grad()</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/airaria/textbrewer/commit/7a8d3c7e324b4b05dbce0b1fc5025bfda6d1cfc0#diff-5b22dd587c7520eb69a70284f115afcc66a5efa35be48a388b6f28f1ac00f843L35' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59186803</div><div id='project'> Project Name: airaria/textbrewer</div><div id='commit'> Commit Name: 7a8d3c7e324b4b05dbce0b1fc5025bfda6d1cfc0</div><div id='time'> Time: 2020-04-14</div><div id='author'> Author: yangziqing@163.com</div><div id='file'> File Name: src/textbrewer/distiller_train.py</div><div id='m_class'> M Class Name: BasicTrainer</div><div id='n_method'> N Class Name: BasicTrainer</div><div id='m_method'> M Method Name: train(11)</div><div id='n_method'> N Method Name: train(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/textbrewer/distiller_train.py</div><div id='n_file'> N File Name: src/textbrewer/distiller_train.py</div><div id='m_start'> M Start Line: 35</div><div id='m_end'> M End Line: 112</div><div id='n_start'> N Start Line: 35</div><div id='n_end'> N End Line: 121</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    optimizer.step()
                    if scheduler is not None:
                        scheduler.step()
                    <a id="change">self.model_S.zero_grad()</a>
                    global_step += 1
                    if self.d_config.kd_loss_weight_scheduler is not None:
                        self.d_config.kd_loss_weight = \
                            self.d_config.kd_loss_weight_scheduler(global_step/total_global_steps)</code></pre><h3>After Change</h3><pre><code class='java'>
                writer_step += 1

                if (step+1)%self.t_config.gradient_accumulation_steps == 0:
                    <a id="change">if max_grad_norm &gt; 0</a>:
                        <a id="change">torch.nn.utils.clip_grad_norm_(</a><a id="change">self.model_S.parameters()</a>, max_grad_norm<a id="change">)</a>
                    optimizer.step()
                    if scheduler is not None:
                        scheduler.step()
                    optimizer.zero_grad()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/airaria/textbrewer/commit/7a8d3c7e324b4b05dbce0b1fc5025bfda6d1cfc0#diff-17be5ab2b887e15799155290d2098d680934eb0bd04342ec6e296efef31a196eL47' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59186802</div><div id='project'> Project Name: airaria/textbrewer</div><div id='commit'> Commit Name: 7a8d3c7e324b4b05dbce0b1fc5025bfda6d1cfc0</div><div id='time'> Time: 2020-04-14</div><div id='author'> Author: yangziqing@163.com</div><div id='file'> File Name: src/textbrewer/distiller_basic.py</div><div id='m_class'> M Class Name: BasicDistiller</div><div id='n_method'> N Class Name: BasicDistiller</div><div id='m_method'> M Method Name: train(11)</div><div id='n_method'> N Method Name: train(8)</div><div id='m_parent_class'> M Parent Class: AbstractDistiller</div><div id='n_parent_class'> N Parent Class: AbstractDistiller</div><div id='m_file'> M File Name: src/textbrewer/distiller_basic.py</div><div id='n_file'> N File Name: src/textbrewer/distiller_basic.py</div><div id='m_start'> M Start Line: 47</div><div id='m_end'> M End Line: 148</div><div id='n_start'> N Start Line: 47</div><div id='n_end'> N End Line: 167</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            optimizer.step()
            if scheduler is not None:
                scheduler.step()
            <a id="change">self.model_S.zero_grad()</a>

            if self.d_config.kd_loss_weight_scheduler is not None:
                self.d_config.kd_loss_weight = \
                    self.d_config.kd_loss_weight_scheduler(global_step/total_global_steps)</code></pre><h3>After Change</h3><pre><code class='java'>
                scalar_total_loss = total_loss.cpu().item() * self.t_config.gradient_accumulation_steps
                self.tb_writer.add_scalar(&quotscalar/total_loss&quot, scalar_total_loss, writer_step)
                writer_step += 1
            <a id="change">if max_grad_norm &gt; 0</a>:
                <a id="change">torch.nn.utils.clip_grad_norm_(</a><a id="change">self.model_S.parameters()</a>, max_grad_norm<a id="change">)</a> 
            optimizer.step()
            if scheduler is not None:
                scheduler.step()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/airaria/textbrewer/commit/7a8d3c7e324b4b05dbce0b1fc5025bfda6d1cfc0#diff-a0df517a14c387489a167be94325fce9e4eceac1f693d479ceaa7822801fdf1aL36' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59186801</div><div id='project'> Project Name: airaria/textbrewer</div><div id='commit'> Commit Name: 7a8d3c7e324b4b05dbce0b1fc5025bfda6d1cfc0</div><div id='time'> Time: 2020-04-14</div><div id='author'> Author: yangziqing@163.com</div><div id='file'> File Name: src/textbrewer/distiller_multitask.py</div><div id='m_class'> M Class Name: MultiTaskDistiller</div><div id='n_method'> N Class Name: MultiTaskDistiller</div><div id='m_method'> M Method Name: train(11)</div><div id='n_method'> N Method Name: train(8)</div><div id='m_parent_class'> M Parent Class: BasicDistiller</div><div id='n_parent_class'> N Parent Class: BasicDistiller</div><div id='m_file'> M File Name: src/textbrewer/distiller_multitask.py</div><div id='n_file'> N File Name: src/textbrewer/distiller_multitask.py</div><div id='m_start'> M Start Line: 36</div><div id='m_end'> M End Line: 94</div><div id='n_start'> N Start Line: 36</div><div id='n_end'> N End Line: 106</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        writer_step = 0
        for current_epoch in tqdm(range(int(num_epochs)),disable=None):
            logger.info(f"Epoch {current_epoch+1}")
            <a id="change">self.model.zero_grad()</a>
            logger.info(f"Length of current epoch in forward batch: {len(dataloader)}")
            for step, batch in tqdm(enumerate(dataloader),disable=None):
                if batch_postprocessor is not None:
                    batch = batch_postprocessor(batch)</code></pre><h3>After Change</h3><pre><code class='java'>
                writer_step += 1

                if (step+1)%self.t_config.gradient_accumulation_steps == 0:
                    <a id="change">if max_grad_norm &gt; 0</a>:
                        <a id="change">torch.nn.utils.clip_grad_norm_(</a><a id="change">self.model.parameters()</a>, max_grad_norm<a id="change">)</a> 
                    optimizer.step()
                    if scheduler is not None:
                        scheduler.step()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/airaria/textbrewer/commit/7a8d3c7e324b4b05dbce0b1fc5025bfda6d1cfc0#diff-5b22dd587c7520eb69a70284f115afcc66a5efa35be48a388b6f28f1ac00f843L35' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59186799</div><div id='project'> Project Name: airaria/textbrewer</div><div id='commit'> Commit Name: 7a8d3c7e324b4b05dbce0b1fc5025bfda6d1cfc0</div><div id='time'> Time: 2020-04-14</div><div id='author'> Author: yangziqing@163.com</div><div id='file'> File Name: src/textbrewer/distiller_train.py</div><div id='m_class'> M Class Name: BasicTrainer</div><div id='n_method'> N Class Name: BasicTrainer</div><div id='m_method'> M Method Name: train(11)</div><div id='n_method'> N Method Name: train(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/textbrewer/distiller_train.py</div><div id='n_file'> N File Name: src/textbrewer/distiller_train.py</div><div id='m_start'> M Start Line: 35</div><div id='m_end'> M End Line: 112</div><div id='n_start'> N Start Line: 35</div><div id='n_end'> N End Line: 121</div><BR>