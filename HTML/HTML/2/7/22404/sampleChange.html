<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        image = output.images

        generator<a id="change"> = </a><a id="change">torch.Generator(device=device).manual_seed(0</a><a id="change">)</a>
        image_from_tuple = alt_pipe(
            [prompt],
            generator=generator,
            guidance_scale=6.0,</code></pre><h3>After Change</h3><pre><code class='java'>
    def test_alt_diffusion_pndm(self):
        device = "cpu"  &#47&#47 ensure determinism for the device-dependent torch.Generator

        components = <a id="change">self.get_dummy_components()</a>
        components["scheduler"] = PNDMScheduler(skip_prk_steps=True)
        torch.manual_seed(0)
        text_encoder_config = RobertaSeriesConfig(
            hidden_size=32,
            project_dim=32,
            intermediate_size=37,
            layer_norm_eps=1e-05,
            num_attention_heads=4,
            num_hidden_layers=5,
            vocab_size=5002,
        )
        &#47&#47 TODO: remove after fixing the non-deterministic text encoder
        text_encoder = RobertaSeriesModelWithTransformation(text_encoder_config)
        components["text_encoder"] = text_encoder
        alt_pipe = AltDiffusionPipeline(**components)
        alt_pipe = alt_pipe.to(device)
        alt_pipe.set_progress_bar_config(disable=None)

        inputs = <a id="change">self.get_dummy_inputs(</a>device<a id="change">)</a>
        output = alt_pipe(**inputs)
        image = output.images
        image_slice = image[0, -3:, -3:, -1]
</code></pre>