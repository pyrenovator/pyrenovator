<html><h3>Pattern ID :11308
</h3><img src='38461711.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            self.hparams.ind2lab,
            task="encode",
        )
        target_tokens<a id="change"> = </a><a id="change">target_tokens.to(</a>self.device<a id="change">)</a>
        target_token_lens = target_token_lens.to(self.device)
        if hasattr(self.hparams, "env_corrupt") and stage == sb.Stage.TRAIN:
            target_tokens = torch.cat([target_tokens, target_tokens], dim=0)
            target_token_lens = torch.cat(
                [target_token_lens, target_token_lens], dim=0
            )

        &#47&#47 Add char_lens by one for eos token
        abs_length = torch.round(target_token_lens * target_tokens.shape[1])

        &#47&#47 Append eos token at the end of the label sequences
        target_tokens_with_eos = sb.data_io.data_io.append_eos_token(
            target_tokens, length=abs_length, eos_index=self.hparams.eos_index
        )

        &#47&#47 Convert to speechbrain-style relative length
        rel_length = (abs_length + 1) / <a id="change">target_tokens_with_eos.shape[1]</a>
        loss_seq = self.hparams.seq_cost(
            p_seq, target_tokens_with_eos, length=rel_length
        )
</code></pre><h3>After Change</h3><pre><code class='java'>
                for utt_seq in predicted_tokens
            ]

            target_semantics = <a id="change">[wrd.split(" ") for wrd in batch.semantics]</a>

            for i in range(len(target_semantics)):
                print(" ".join(predicted_semantics[i]).replace("|", ","))
                print(" ".join(target_semantics[i]).replace("|", ","))</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/ee71b8424ecddf9a73e3107efc22c00df7e29338#diff-67521b803dd780b9cdda3e40a06d851f3604ae241b94063587af15304e148255L82' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38461711</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: ee71b8424ecddf9a73e3107efc22c00df7e29338</div><div id='time'> Time: 2021-01-16</div><div id='author'> Author: mirco.ravanelli@gmail.com</div><div id='file'> File Name: recipes/timers-and-such/direct/train.py</div><div id='m_class'> M Class Name: SLU</div><div id='n_method'> N Class Name: SLU</div><div id='m_method'> M Method Name: compute_objectives(4)</div><div id='n_method'> N Method Name: compute_objectives(4)</div><div id='m_parent_class'> M Parent Class: sb.Brain</div><div id='n_parent_class'> N Parent Class: sb.Brain</div><div id='m_file'> M File Name: recipes/timers-and-such/direct/train.py</div><div id='n_file'> N File Name: recipes/timers-and-such/direct/train.py</div><div id='m_start'> M Start Line: 89</div><div id='m_end'> M End Line: 146</div><div id='n_start'> N Start Line: 82</div><div id='n_end'> N End Line: 108</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for text in source_text:
            text = &quot &quot.join(text)
            encoding_dict = self.tokenizer(text, return_tensors=&quotpt&quot)
            input_ids<a id="change"> = </a><a id="change">encoding_dict[&quotinput_ids&quot].to(</a>self.device<a id="change">)</a>

            output_ids = self.model.generate(input_ids, max_length=self.max_target_length, early_stopping=True)

            generate_text = self.tokenizer.decode(<a id="change">output_ids[0]</a>, skip_special_tokens=True)
            generate_corpus.append(generate_text.lower().split())

        return generate_corpus</code></pre><h3>After Change</h3><pre><code class='java'>
            input_ids, attention_mask=attn_masks, num_beams=5, max_length=self.max_target_length, early_stopping=True
        )
        generated_text = self.tokenizer.batch_decode(sample_outputs, skip_special_tokens=True)
        generate_corpus = <a id="change">[text.lower().split() for text in generated_text]</a>
        return generate_corpus

    def tokenize_text(self, text):
        input_ids = []</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/47a1a3dc1eee71dd585124dbf1786e2508d34561#diff-256d1cc3e26719e1a4665d427f3287df187da7886f0bdca794d1e8832f37233cL37' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38461715</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 47a1a3dc1eee71dd585124dbf1786e2508d34561</div><div id='time'> Time: 2021-04-15</div><div id='author'> Author: 1020139164@qq.com</div><div id='file'> File Name: textbox/model/Seq2Seq/prophetnet.py</div><div id='m_class'> M Class Name: ProphetNet</div><div id='n_method'> N Class Name: ProphetNet</div><div id='m_method'> M Method Name: generate(3)</div><div id='n_method'> N Method Name: generate(3)</div><div id='m_parent_class'> M Parent Class: Seq2SeqGenerator</div><div id='n_parent_class'> N Parent Class: Seq2SeqGenerator</div><div id='m_file'> M File Name: textbox/model/Seq2Seq/prophetnet.py</div><div id='n_file'> N File Name: textbox/model/Seq2Seq/prophetnet.py</div><div id='m_start'> M Start Line: 38</div><div id='m_end'> M End Line: 50</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 45</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for text in source_text:
            sentence = &quot &quot.join(text)
            encoding_dict = self.tokenizer(sentence, return_tensors="pt")
            input_ids<a id="change"> = </a><a id="change">encoding_dict[&quotinput_ids&quot].to(</a>self.device<a id="change">)</a>
            sample_outputs = self.decoder.generate(
                input_ids, num_beams=5, max_length=self.max_target_length, early_stopping=True
            )
            generated_text = self.tokenizer.decode(<a id="change">sample_outputs[0]</a>, skip_special_tokens=True)
            generate_corpus.append(generated_text.lower().split())
        return generate_corpus
</code></pre><h3>After Change</h3><pre><code class='java'>
            input_ids, attention_mask=attn_masks, num_beams=5, max_length=self.max_target_length, early_stopping=True
        )
        generated_text = self.tokenizer.batch_decode(sample_outputs, skip_special_tokens=True)
        generate_corpus = <a id="change">[text.lower().split() for text in generated_text]</a>
        return generate_corpus

    def tokenize_text(self, text):
        texts = [&quot &quot.join(t) for t in text]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/47a1a3dc1eee71dd585124dbf1786e2508d34561#diff-cb6154a8f614953fc099f2d791b0b41c862387b24dc8dc538bfe98ebbaa4a3b7L42' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38461717</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 47a1a3dc1eee71dd585124dbf1786e2508d34561</div><div id='time'> Time: 2021-04-15</div><div id='author'> Author: 1020139164@qq.com</div><div id='file'> File Name: textbox/model/Seq2Seq/bart.py</div><div id='m_class'> M Class Name: BART</div><div id='n_method'> N Class Name: BART</div><div id='m_method'> M Method Name: generate(3)</div><div id='n_method'> N Method Name: generate(3)</div><div id='m_parent_class'> M Parent Class: Seq2SeqGenerator</div><div id='n_parent_class'> N Parent Class: Seq2SeqGenerator</div><div id='m_file'> M File Name: textbox/model/Seq2Seq/bart.py</div><div id='n_file'> N File Name: textbox/model/Seq2Seq/bart.py</div><div id='m_start'> M Start Line: 43</div><div id='m_end'> M End Line: 54</div><div id='n_start'> N Start Line: 41</div><div id='n_end'> N End Line: 48</div><BR>