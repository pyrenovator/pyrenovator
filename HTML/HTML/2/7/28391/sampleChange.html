<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        lin_neurons=512,
    ):

        blocks<a id="change"> = []</a>

        &#47&#47 TDNN layers
        for block_index in range(tdnn_blocks):
            <a id="change">blocks.extend(
                [
                    </a>lambda input_shape: sb.nnet.Conv1d(
                        input_shape=input_shape,
                        out_channels=tdnn_channels[block_index],
                        kernel_size=tdnn_kernel_sizes[block_index],
                        dilation=tdnn_dilations[block_index],
                    ),
                    activation(),
                    sb.nnet.BatchNorm1d<a id="change"></a>,
                ]<a id="change">
            )</a>

        &#47&#47 Statistical pooling
        blocks.append(sb.nnet.StatisticsPooling())
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 TDNN layers
        for block_index in range(tdnn_blocks):
            <a id="change">self.append(
                </a>sb.nnet.Conv1d<a id="change">,
                out_channels=tdnn_channels[block_index],
                kernel_size=tdnn_kernel_sizes[block_index],
                dilation=tdnn_dilations[block_index],
            )</a>
            self.append(activation())
            self.append(sb.nnet.BatchNorm1d)

        &#47&#47 Statistical pooling
        self.append(sb.nnet.StatisticsPooling())

        &#47&#47 Final linear transformation
        <a id="change">self.append(</a>sb.nnet.Linear<a id="change">, n_neurons=lin_neurons, bias=True)</a>


class Classifier(sb.nnet.Sequential):
    This class implements the last MLP on the top of xvector features.</code></pre>