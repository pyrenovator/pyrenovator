<html><h3>Pattern ID :6116
</h3><img src='21132802.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        with torch.no_grad():
            for key in self.source_dict:
                <a id="change">self.target_dict[key]</a>.data.copy_(self.target_dict[key].data*decay + \
                                                 <a id="change">self.source_dict[key]</a>.data*(1. - decay))


class Ema_stylegan(object):</code></pre><h3>After Change</h3><pre><code class='java'>
        with torch.no_grad():
            for p_ema, p in zip(self.target.parameters(), self.source.parameters()):
                p_ema.copy_(p.lerp(p_ema, decay))
            <a id="change">for </a>b_ema, <a id="change">b</a> in <a id="change">zip(</a>self.target.buffers(), self.source.buffers()<a id="change">)</a><a id="change">:
                </a><a id="change">b_ema.copy_(b</a><a id="change">)</a>


class Ema_stylegan(object):
    def __init__(self, source, target, ema_kimg, ema_rampup, effective_batch_size, d_updates_per_step):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/postech-cvlab/pytorch-studiogan/commit/ef4ecad79da761dd90c169fcf808352bda162e5f#diff-2436d321347d697a9892a647be2fabeb2c289447ce8fc97cb749778105cbf7c5L52' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21132802</div><div id='project'> Project Name: postech-cvlab/pytorch-studiogan</div><div id='commit'> Commit Name: ef4ecad79da761dd90c169fcf808352bda162e5f</div><div id='time'> Time: 2021-09-26</div><div id='author'> Author: first287@naver.com</div><div id='file'> File Name: src/utils/ema.py</div><div id='m_class'> M Class Name: Ema</div><div id='n_method'> N Class Name: Ema</div><div id='m_method'> M Method Name: update(2)</div><div id='n_method'> N Method Name: update(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: src/utils/ema.py</div><div id='n_file'> N File Name: src/utils/ema.py</div><div id='m_start'> M Start Line: 52</div><div id='m_end'> M End Line: 54</div><div id='n_start'> N Start Line: 54</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            decay = self.decay

        with torch.no_grad():
            for <a id="change">key</a> in self.source_dict:
                <a id="change">self.target_dict[key]</a>.data.copy_(self.target_dict[key].data*decay + \
                                                 <a id="change">self.source_dict[key]</a>.data*(1. - decay))


class Ema_stylegan(object):</code></pre><h3>After Change</h3><pre><code class='java'>
        with torch.no_grad():
            for p_ema, p in zip(self.target.parameters(), self.source.parameters()):
                p_ema.copy_(p.lerp(p_ema, decay))
            <a id="change">for </a>b_ema, <a id="change">b</a> in <a id="change">zip(</a>self.target.buffers(), self.source.buffers()<a id="change">)</a><a id="change">:
                </a><a id="change">b_ema.copy_(</a>b<a id="change">)</a>


class Ema_stylegan(object):
    def __init__(self, source, target, ema_kimg, ema_rampup, effective_batch_size, d_updates_per_step):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/postech-cvlab/pytorch-studiogan/commit/ef4ecad79da761dd90c169fcf808352bda162e5f#diff-2436d321347d697a9892a647be2fabeb2c289447ce8fc97cb749778105cbf7c5L45' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21132803</div><div id='project'> Project Name: postech-cvlab/pytorch-studiogan</div><div id='commit'> Commit Name: ef4ecad79da761dd90c169fcf808352bda162e5f</div><div id='time'> Time: 2021-09-26</div><div id='author'> Author: first287@naver.com</div><div id='file'> File Name: src/utils/ema.py</div><div id='m_class'> M Class Name: Ema</div><div id='n_method'> N Class Name: Ema</div><div id='m_method'> M Method Name: update(2)</div><div id='n_method'> N Method Name: update(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: src/utils/ema.py</div><div id='n_file'> N File Name: src/utils/ema.py</div><div id='m_start'> M Start Line: 52</div><div id='m_end'> M End Line: 54</div><div id='n_start'> N Start Line: 54</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    else:
      decay = self.decay
    with torch.no_grad():
      for <a id="change">key</a> in self.source_dict:
        self.target_dict[key].data.copy_(<a id="change">self.target_dict[key]</a>.data * decay + <a id="change">self.source_dict[key]</a>.data * (1-decay))


class EmaDpSyncBN(object):</code></pre><h3>After Change</h3><pre><code class='java'>
        with torch.no_grad():
            for p_ema, p in zip(self.target.parameters(), self.source.parameters()):
                p_ema.copy_(p.lerp(p_ema, decay))
            <a id="change">for </a>b_ema, <a id="change">b</a> in <a id="change">zip(</a>self.target.buffers(), self.source.buffers()<a id="change">)</a><a id="change">:
                </a><a id="change">b_ema.copy_(</a>b<a id="change">)</a>


class EmaStylegan2(object):
    def __init__(self, source, target, ema_kimg, ema_rampup, effective_batch_size, d_updates_per_step):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/postech-cvlab/pytorch-studiogan/commit/8f81e01a361f269930587a59de0280e272ccb91d#diff-2436d321347d697a9892a647be2fabeb2c289447ce8fc97cb749778105cbf7c5L45' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21132800</div><div id='project'> Project Name: postech-cvlab/pytorch-studiogan</div><div id='commit'> Commit Name: 8f81e01a361f269930587a59de0280e272ccb91d</div><div id='time'> Time: 2021-09-30</div><div id='author'> Author: first287@naver.com</div><div id='file'> File Name: src/utils/ema.py</div><div id='m_class'> M Class Name: Ema</div><div id='n_method'> N Class Name: Ema</div><div id='m_method'> M Method Name: update(2)</div><div id='n_method'> N Method Name: update(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: src/utils/ema.py</div><div id='n_file'> N File Name: src/utils/ema.py</div><div id='m_start'> M Start Line: 51</div><div id='m_end'> M End Line: 52</div><div id='n_start'> N Start Line: 54</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                for part in partitions:
                    params, offsets = partition_param_map[part]
                    found = False
                    for <a id="change">p_idx</a>, _p in enumerate(params):
                        if p.__hash__() == _p.__hash__():
                            found = True
                            if <a id="change">offsets[p_idx]</a>[0] is not None:
                                my_part = part.narrow(0,
                                                      <a id="change">offsets[p_idx]</a>[0],
                                                      offsets[p_idx][1])
                                parts.append(my_part)
                    assert found</code></pre><h3>After Change</h3><pre><code class='java'>
            flat_all_grads = torch.cat(flat_comm_grads)

            &#47&#47 copy back reduced gradients but only those needed for this local rank
            <a id="change">for </a>param, <a id="change">updated_grad</a> in <a id="change">zip(</a>self.fp16_groups[i], _unflatten_dense_tensors(flat_all_grads, self.fp16_groups[i])<a id="change">)</a><a id="change">:
                </a>if param in my_params:
                    <a id="change">param.grad.copy_(</a>updated_grad<a id="change">)</a>

    def step(self, closure=None):
        &#47&#47 First compute norm for all group so we know if there is overflow
        self.overflow = self.overflow_checker.check()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/55ed105771d08fbffc0cb6d8cd56a2e61206ad1d#diff-458bf13440cbc0013d248079431500c00e3907e0a747c77fa0c8dda6b8b25f88L530' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21132805</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: 55ed105771d08fbffc0cb6d8cd56a2e61206ad1d</div><div id='time'> Time: 2020-09-15</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/runtime/zero/stage1.py</div><div id='m_class'> M Class Name: FP16_DeepSpeedZeroOptimizer_Stage1</div><div id='n_method'> N Class Name: FP16_DeepSpeedZeroOptimizer_Stage1</div><div id='m_method'> M Method Name: reduce_scatter_gradients(4)</div><div id='n_method'> N Method Name: reduce_scatter_gradients(4)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: deepspeed/runtime/zero/stage1.py</div><div id='n_file'> N File Name: deepspeed/runtime/zero/stage1.py</div><div id='m_start'> M Start Line: 539</div><div id='m_end'> M End Line: 613</div><div id='n_start'> N Start Line: 536</div><div id='n_end'> N End Line: 605</div><BR>