<html><h3>Pattern ID :24332
</h3><img src='75576961.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        adv_log_pi = adv_log_pi.detach().cpu().numpy().flatten()
        if return_logits:
            logits_pi = outs[-1]
            logits_adv = <a id="change">self._adversary.forward(
                observation, deterministic, return_log_prob=True
            )[-1]</a>
            logits_pi = logits_pi.detach().cpu().numpy().flatten()
            logits_adv = logits_adv.detach().cpu().numpy().flatten()
            return action, log_pi, adv_log_pi, logits_pi, logits_adv
        return action, log_pi, adv_log_pi</code></pre><h3>After Change</h3><pre><code class='java'>
            params_pi = params_pi.detach().cpu().numpy().flatten()
            params_adv = params_adv.detach().cpu().numpy().flatten()
        else:
            mean = <a id="change">actor_distrib.mean.detach().cpu().numpy().flatten()</a>
            scale<a id="change"> = </a><a id="change">actor_distrib.scale.detach().cpu().numpy().flatten()</a>
            params_pi = np.concatenate([mean, scale], -1)
            mean<a id="change"> = </a>adversary_distrib.mean.detach().cpu().numpy().flatten()
            scale = adversary_distrib.scale.detach().cpu().numpy().flatten()
            params_adv<a id="change"> = </a>np.concatenate([mean, scale], -1)
        return action, log_pi, adv_log_pi, params_pi, params_adv

    def compute_values(self, observations: Observation) -&gt; np.ndarray:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/yfletberliac/adversarially-guided-actor-critic/commit/4958ecb8ca6e7e344852f7aa9fc8668cd8cd074b#diff-513f475959da3d0565e9ebe8fc9a9ab196187c5415b4d26445a650fd2fae785cL115' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75576961</div><div id='project'> Project Name: yfletberliac/adversarially-guided-actor-critic</div><div id='commit'> Commit Name: 4958ecb8ca6e7e344852f7aa9fc8668cd8cd074b</div><div id='time'> Time: 2021-07-07</div><div id='author'> Author: cibeah.cb@gmail.com</div><div id='file'> File Name: agac_torch/agac/agac_ppo.py</div><div id='m_class'> M Class Name: PPO</div><div id='n_method'> N Class Name: PPO</div><div id='m_method'> M Method Name: select_action(3)</div><div id='n_method'> N Method Name: select_action(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: agac_torch/agac/agac_ppo.py</div><div id='n_file'> N File Name: agac_torch/agac/agac_ppo.py</div><div id='m_start'> M Start Line: 115</div><div id='m_end'> M End Line: 138</div><div id='n_start'> N Start Line: 121</div><div id='n_end'> N End Line: 146</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        hidden_states = paddle.zeros(
            (batch_size_attention, sequence_length, dim // self.heads),
            dtype=query.dtype)
        slice_size = self._slice_size if self._slice_size is not None else <a id="change">hidden_states.shape[
            0]</a>
        for i in range(hidden_states.shape[0] // slice_size):
            start_idx = i * slice_size
            end_idx = (i + 1) * slice_size
            attn_slice = (paddle.matmul(query[start_idx:end_idx],</code></pre><h3>After Change</h3><pre><code class='java'>

    def _sliced_attention(self, query, key, value):
        &#47&#47 query, key, value flatten [bs*num_heads, seqlen, head_dim]
        query = <a id="change">query.flatten(</a>0, 1<a id="change">)</a>
        key<a id="change"> = </a>key.flatten(0, 1)
        value<a id="change"> = </a><a id="change">value.flatten(</a>0, 1<a id="change">)</a>

        batch_size_attention, sequence_length = query.shape[0], query.shape[1]
        hidden_states = paddle.zeros(
            (batch_size_attention, sequence_length, self.head_dim),
            dtype=query.dtype)
        slice_size = self._slice_size if self._slice_size is not None else batch_size_attention

        for i in range(batch_size_attention // slice_size):
            start_idx = i * slice_size
            end_idx = (i + 1) * slice_size
            attn_slice = (paddle.matmul(query[start_idx:end_idx],
                                        key[start_idx:end_idx],
                                        transpose_y=True) * self.scale
                          )  &#47&#47 TODO: use baddbmm for better performance
            attn_slice = F.softmax(attn_slice, axis=-1)
            attn_slice = paddle.matmul(attn_slice, value[start_idx:end_idx])

            hidden_states[start_idx:end_idx] = attn_slice

        &#47&#47 reshape back to [bs, num_heads, seqlen, head_dim]
        hidden_states<a id="change"> = </a>hidden_states.reshape(
            [-1, self.num_heads, sequence_length, self.head_dim])
        &#47&#47 reshape hidden_states
        hidden_states = self.reshape_batch_dim_to_heads(hidden_states)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/8842fbf8a150623cf9d45594cf77d285a675fe37#diff-48869f3818940f62054674405a41c572f181c3190431c629d45e928498f02a82L338' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75577088</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 8842fbf8a150623cf9d45594cf77d285a675fe37</div><div id='time'> Time: 2022-11-17</div><div id='author'> Author: 50394665+JunnYu@users.noreply.github.com</div><div id='file'> File Name: ppdiffusers/ppdiffusers/models/attention.py</div><div id='m_class'> M Class Name: CrossAttention</div><div id='n_method'> N Class Name: CrossAttention</div><div id='m_method'> M Method Name: _sliced_attention(4)</div><div id='n_method'> N Method Name: _sliced_attention(6)</div><div id='m_parent_class'> M Parent Class: nn.Layer</div><div id='n_parent_class'> N Parent Class: nn.Layer</div><div id='m_file'> M File Name: ppdiffusers/ppdiffusers/models/attention.py</div><div id='n_file'> N File Name: ppdiffusers/ppdiffusers/models/attention.py</div><div id='m_start'> M Start Line: 338</div><div id='m_end'> M End Line: 345</div><div id='n_start'> N Start Line: 327</div><div id='n_end'> N End Line: 351</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for smap in saliency_maps:
            sparse_feat = torch.sum(torch.abs(smap))

            n_channels = <a id="change">smap.shape[0]</a>
            kernel = torch.tensor([[0., 1., 0.],
                                    [1., -4., 1.],
                                    [0., 1., 0.]])
            kernel = kernel.view(1, 1, 3, 3).repeat(1, n_channels, 1, 1)</code></pre><h3>After Change</h3><pre><code class='java'>
        return torch.cat(saliency_maps)

    def cal_explanation_feature(self, saliency_maps: torch.Tensor) -&gt; float:
        sparse_feats = <a id="change">saliency_maps.flatten(start_dim=1)</a>.norm(p=1)    &#47&#47 (N)
        smooth_feats<a id="change"> = </a><a id="change">self.conv2d(saliency_maps).flatten(start_dim=1)</a>.norm(p=1)    &#47&#47 (N)
        persist_feats<a id="change"> = </a>0.0  &#47&#47 todo (N)

        exp_feats<a id="change"> = </a>self.lambd_sp * sparse_feats + self.lambd_sm * smooth_feats + self.lambd_pe * persist_feats
        return exp_feats.median()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ain-soph/trojanzoo/commit/afe7bbd2d2e9f901ee8cf56c3b9320b9272a81af#diff-5528b4636bddd4d9ccc9486227970324e4344e01059ddca8b9863336ce85d70cL67' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75577067</div><div id='project'> Project Name: ain-soph/trojanzoo</div><div id='commit'> Commit Name: afe7bbd2d2e9f901ee8cf56c3b9320b9272a81af</div><div id='time'> Time: 2020-07-22</div><div id='author'> Author: ain-soph@live.com</div><div id='file'> File Name: trojanzoo/defense/backdoor/neuron_inspect.py</div><div id='m_class'> M Class Name: Neuron_Inspect</div><div id='n_method'> N Class Name: Neuron_Inspect</div><div id='m_method'> M Method Name: cal_explanation_feature(2)</div><div id='n_method'> N Method Name: cal_explanation_feature(2)</div><div id='m_parent_class'> M Parent Class: Defense_Backdoor</div><div id='n_parent_class'> N Parent Class: Defense_Backdoor</div><div id='m_file'> M File Name: trojanzoo/defense/backdoor/neuron_inspect.py</div><div id='n_file'> N File Name: trojanzoo/defense/backdoor/neuron_inspect.py</div><div id='m_start'> M Start Line: 68</div><div id='m_end'> M End Line: 84</div><div id='n_start'> N Start Line: 68</div><div id='n_end'> N End Line: 73</div><BR>