<html><h3>Pattern ID :24619
</h3><img src='76370845.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            labels = scaler.transform(labels)  &#47&#47 subtract mean, divide by std
        labels = torch.Tensor(labels)
        if args.dataset_type == &quotregression_with_binning&quot:
            labels = <a id="change">labels.long().squeeze(1</a><a id="change">)</a>

        if next(model.parameters()).is_cuda:
            mask, labels = mask.cuda(), labels.cuda()

        &#47&#47 Run model
        model.zero_grad()
        preds = model(mol_batch)
        loss<a id="change"> = </a>loss_func(preds, labels) * mask
        loss = loss.sum() / mask.sum()

        if logger is not None:</code></pre><h3>After Change</h3><pre><code class='java'>
        model.zero_grad()
        preds = model(mol_batch)
        if args.dataset_type == &quotregression_with_binning&quot:
            preds<a id="change"> = </a>preds.view(<a id="change">labels.size(0</a><a id="change">)</a>, labels.size(1), -1)
            labels = labels.long()
            loss = 0
            for task in range(labels.size(1)):
                loss<a id="change"> += </a>loss_func(preds[:, task, :], labels[:, task]) * mask[:, task] &#47&#47for some reason cross entropy doesn&quott support multi target
        loss = loss.sum() / mask.sum()

        if logger is not None:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/aamini/chemprop/commit/282ebf6536c6987b85ee291850db47e34e2bac2f#diff-1ae5c6142982c466b6120408cea60c9e765c62ef258032b838fb5274077b166dL49' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76370845</div><div id='project'> Project Name: aamini/chemprop</div><div id='commit'> Commit Name: 282ebf6536c6987b85ee291850db47e34e2bac2f</div><div id='time'> Time: 2018-09-26</div><div id='author'> Author: yangk@mit.edu</div><div id='file'> File Name: train_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(9)</div><div id='n_method'> N Method Name: train(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_utils.py</div><div id='n_file'> N File Name: train_utils.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 63</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 67</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        (time, batch), chw = obs_size[:2], obs_size[2:]
        observation = observation.view(time * batch, *chw)

    conv_features<a id="change"> = </a><a id="change">cnn(observation).squeeze(-1</a><a id="change">)</a>.squeeze(-1)
    if with_time:
        &#47&#47 noinspection PyUnboundLocalVariable
        conv_features = conv_features.view(time, batch, -1)</code></pre><h3>After Change</h3><pre><code class='java'>
        img = img.view(time * batch, *chw)

    conv_features = cnn(img)
    conv_features<a id="change"> = </a>conv_features.view(<a id="change">conv_features.size(0</a><a id="change">)</a>, -1)

    if with_time:
        &#47&#47 noinspection PyUnboundLocalVariable
        conv_features = conv_features.view(time, batch, -1)

    if type(observation) is dict:
        observation[&quotfeatures&quot]<a id="change"> = </a>conv_features

    return conv_features
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/cherrypiesexy/imitation_learning/commit/998cc46be20ad6a3824f9bb6677b8d7daefc3cbb#diff-01e92845078bbf7bccbf88d841e7aa8ebe12e50df805b2305f2da6d4e4f6215aL6' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76370846</div><div id='project'> Project Name: cherrypiesexy/imitation_learning</div><div id='commit'> Commit Name: 998cc46be20ad6a3824f9bb6677b8d7daefc3cbb</div><div id='time'> Time: 2021-01-02</div><div id='author'> Author: interga@post-hardcore.ru</div><div id='file'> File Name: algorithms/nn/conv_encoders.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: cnn_forward(2)</div><div id='n_method'> N Method Name: cnn_forward(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: algorithms/nn/conv_encoders.py</div><div id='n_file'> N File Name: algorithms/nn/conv_encoders.py</div><div id='m_start'> M Start Line: 12</div><div id='m_end'> M End Line: 14</div><div id='n_start'> N Start Line: 8</div><div id='n_end'> N End Line: 30</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            probs[:, 0] = torch.ones(batch_size).to(device)
        else:
            probs = p_select * cumprod_1_minus_p * torch.cumsum(previous_probs / cumprod_1_minus_p, dim=-1)
            probs<a id="change"> = </a><a id="change">probs.squeeze(1</a><a id="change">)</a>

        probs = probs * encoder_masks
        normalization_factor = probs.sum(-1, keepdim=True) + 1e-12
        probs = probs / normalization_factor</code></pre><h3>After Change</h3><pre><code class='java'>
            probs [batch_size, tgt_len, src_len]
        
        device = hidden_states.device
        tgt_len<a id="change"> = </a><a id="change">hidden_states.size(1</a><a id="change">)</a>
        batch_size, src_len, _ = encoder_outputs.size()

        energy = self.score(hidden_states, encoder_outputs)
        p_select = torch.sigmoid(energy + self.gaussian_noise(energy.size()).to(device))
        cumprod_1_minus_p = self.safe_cumprod(1 - p_select)

        if previous_probs is None:
            probs = torch.zeros(batch_size, tgt_len, src_len).to(device)
            probs[:, :, 0] = torch.ones(batch_size, tgt_len).to(device)
        else:
            probs = p_select * cumprod_1_minus_p * torch.cumsum(previous_probs / cumprod_1_minus_p, dim=-1)

        encoder_masks<a id="change"> = </a>encoder_masks.unsqueeze(1).repeat(1, tgt_len, 1)
        probs = probs * encoder_masks
        normalization_factor = probs.sum(-1, keepdim=True) + 1e-12
        probs = probs / normalization_factor</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/967fc58bc72f549bde3d8cba8dcd88b0bd40e138#diff-d9e15dc978d5b328aa30538e301dd8e56d5b98120cfda66705f8f322cd15c30fL142' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76370854</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 967fc58bc72f549bde3d8cba8dcd88b0bd40e138</div><div id='time'> Time: 2020-12-06</div><div id='author'> Author: lijunyi@ruc.edu.cn</div><div id='file'> File Name: textbox/module/Attention/attention_mechanism.py</div><div id='m_class'> M Class Name: MonotonicAttention</div><div id='n_method'> N Class Name: MonotonicAttention</div><div id='m_method'> M Method Name: soft(5)</div><div id='n_method'> N Method Name: soft(5)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: textbox/module/Attention/attention_mechanism.py</div><div id='n_file'> N File Name: textbox/module/Attention/attention_mechanism.py</div><div id='m_start'> M Start Line: 163</div><div id='m_end'> M End Line: 169</div><div id='n_start'> N Start Line: 162</div><div id='n_end'> N End Line: 175</div><BR>