<html><h3>Pattern ID :26650
</h3><img src='79685935.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                        scaled_loss.backward()
                else:
                    total_loss.backward()
                scalar_total_loss<a id="change"> = </a>total_loss.cpu().item() * self.t_config.gradient_accumulation_steps
                <a id="change">self.tb_writer.add_scalar(</a>&quotscalar/total_loss&quot, scalar_total_loss, writer_step<a id="change">)</a>
                writer_step += 1
            if max_grad_norm &gt; 0:
                if self.t_config.fp16:
                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), max_grad_norm)</code></pre><h3>After Change</h3><pre><code class='java'>
                        scaled_loss.backward()
                else:
                    total_loss.backward()
                <a id="change">if self.rank == 0</a>:
                    scalar_total_loss<a id="change"> = </a>total_loss.cpu().item() * self.t_config.gradient_accumulation_steps
                    <a id="change">self.tb_writer.add_scalar(</a>&quotscalar/total_loss&quot, scalar_total_loss, writer_step<a id="change">)</a>
                writer_step += 1
            if max_grad_norm &gt; 0:
                if self.t_config.fp16:
                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), max_grad_norm)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/airaria/textbrewer/commit/47e97a5e0d969ecfff62cb79216235e25384b10a#diff-a0df517a14c387489a167be94325fce9e4eceac1f693d479ceaa7822801fdf1aL65' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 79685935</div><div id='project'> Project Name: airaria/textbrewer</div><div id='commit'> Commit Name: 47e97a5e0d969ecfff62cb79216235e25384b10a</div><div id='time'> Time: 2020-07-28</div><div id='author'> Author: yangziqing@163.com</div><div id='file'> File Name: src/textbrewer/distiller_multitask.py</div><div id='m_class'> M Class Name: MultiTaskDistiller</div><div id='n_method'> N Class Name: MultiTaskDistiller</div><div id='m_method'> M Method Name: train(11)</div><div id='n_method'> N Method Name: train(11)</div><div id='m_parent_class'> M Parent Class: BasicDistiller</div><div id='n_parent_class'> N Parent Class: BasicDistiller</div><div id='m_file'> M File Name: src/textbrewer/distiller_multitask.py</div><div id='n_file'> N File Name: src/textbrewer/distiller_multitask.py</div><div id='m_start'> M Start Line: 67</div><div id='m_end'> M End Line: 114</div><div id='n_start'> N Start Line: 65</div><div id='n_end'> N End Line: 123</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                else:
                    total_loss.backward()

                scalar_total_loss<a id="change"> = </a>total_loss.cpu().item() * self.t_config.gradient_accumulation_steps
                <a id="change">self.tb_writer.add_scalar(</a>&quotscalar/total_loss&quot, scalar_total_loss, writer_step<a id="change">)</a>
                writer_step += 1

                if (step+1)%self.t_config.gradient_accumulation_steps == 0:
                    if max_grad_norm &gt; 0:</code></pre><h3>After Change</h3><pre><code class='java'>
                else:
                    total_loss.backward()

                <a id="change">if self.rank == 0</a>:
                    scalar_total_loss<a id="change"> = </a>total_loss.cpu().item() * self.t_config.gradient_accumulation_steps
                    <a id="change">self.tb_writer.add_scalar(</a>&quotscalar/total_loss&quot, scalar_total_loss, writer_step<a id="change">)</a>
                writer_step += 1

                if (step+1)%self.t_config.gradient_accumulation_steps == 0:
                    if max_grad_norm &gt; 0:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/airaria/textbrewer/commit/47e97a5e0d969ecfff62cb79216235e25384b10a#diff-5b22dd587c7520eb69a70284f115afcc66a5efa35be48a388b6f28f1ac00f843L35' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 79685931</div><div id='project'> Project Name: airaria/textbrewer</div><div id='commit'> Commit Name: 47e97a5e0d969ecfff62cb79216235e25384b10a</div><div id='time'> Time: 2020-07-28</div><div id='author'> Author: yangziqing@163.com</div><div id='file'> File Name: src/textbrewer/distiller_train.py</div><div id='m_class'> M Class Name: BasicTrainer</div><div id='n_method'> N Class Name: BasicTrainer</div><div id='m_method'> M Method Name: train(11)</div><div id='n_method'> N Method Name: train(11)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/textbrewer/distiller_train.py</div><div id='n_file'> N File Name: src/textbrewer/distiller_train.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 158</div><div id='n_start'> N Start Line: 54</div><div id='n_end'> N End Line: 181</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def write_loss(self, total_loss, writer_step):

        cpu_total_loss<a id="change"> = </a>total_loss.cpu().item() * self.t_config.gradient_accumulation_steps
        <a id="change">self.tb_writer.add_scalar(</a>&quotscalar/total_loss&quot, cpu_total_loss, writer_step<a id="change">)</a>

        &#47&#47for name, loss in losses_dict.items():
        &#47&#47    cpu_loss = loss.cpu().item() * self.t_config.gradient_accumulation_steps
        &#47&#47    self.tb_writer.add_scalar(f"scalar/{name}", cpu_loss, writer_step)</code></pre><h3>After Change</h3><pre><code class='java'>


    def write_loss(self, total_loss, writer_step):
        <a id="change">if self.rank == 0</a>:
            cpu_total_loss<a id="change"> = </a>total_loss.cpu().item() * self.t_config.gradient_accumulation_steps
            <a id="change">self.tb_writer.add_scalar(</a>&quotscalar/total_loss&quot, cpu_total_loss, writer_step<a id="change">)</a>

        &#47&#47for name, loss in losses_dict.items():
        &#47&#47    cpu_loss = loss.cpu().item() * self.t_config.gradient_accumulation_steps
        &#47&#47    self.tb_writer.add_scalar(f"scalar/{name}", cpu_loss, writer_step)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/airaria/textbrewer/commit/47e97a5e0d969ecfff62cb79216235e25384b10a#diff-17be5ab2b887e15799155290d2098d680934eb0bd04342ec6e296efef31a196eL36' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 79685926</div><div id='project'> Project Name: airaria/textbrewer</div><div id='commit'> Commit Name: 47e97a5e0d969ecfff62cb79216235e25384b10a</div><div id='time'> Time: 2020-07-28</div><div id='author'> Author: yangziqing@163.com</div><div id='file'> File Name: src/textbrewer/distiller_basic.py</div><div id='m_class'> M Class Name: BasicDistiller</div><div id='n_method'> N Class Name: BasicDistiller</div><div id='m_method'> M Method Name: write_loss(3)</div><div id='n_method'> N Method Name: write_loss(3)</div><div id='m_parent_class'> M Parent Class: AbstractDistiller</div><div id='n_parent_class'> N Parent Class: AbstractDistiller</div><div id='m_file'> M File Name: src/textbrewer/distiller_basic.py</div><div id='n_file'> N File Name: src/textbrewer/distiller_basic.py</div><div id='m_start'> M Start Line: 38</div><div id='m_end'> M End Line: 39</div><div id='n_start'> N Start Line: 43</div><div id='n_end'> N End Line: 52</div><BR>