<html><h3>Pattern ID :12214
</h3><img src='41380566.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        

        shadow_params = {}
        encoding_list_for_params<a id="change"> = []</a>

        self.apply_gating_logic()

        <a id="change">for </a>name, param in self._module_to_wrap.named_parameters()<a id="change">:

            &#47&#47 Store current weight for use later on
            </a>shadow_params[name] = param.detach().clone()
            &#47&#47 Create a list of encoding parameters for params
            if self.param_quantizers[name].enabled:
                <a id="change">encoding_list_for_params.append(</a>self._parameters[name + &quot_encoding_min&quot]<a id="change">)</a>
                encoding_list_for_params.append(self._parameters[name + &quot_encoding_max&quot])

        &#47&#47 Quantize inputs
        quantized_inputs = self._quantize_activation(inputs, self.input_quantizers, &quotinput&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
        if isinstance(quantized_inputs, torch.Tensor):
            quantized_inputs = [quantized_inputs]

        <a id="change">with </a><a id="change">self._quantize_params(quantized_inputs):
            &#47&#47 Call the forward of the wrapped module
            </a>wrapped_output = self._module_to_wrap(*quantized_inputs)

        &#47&#47 Quantize the outputs
        &#47&#47 pylint: disable=all</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/quic/aimet/commit/c9cadfe0cede11da01757e9e189988fa912b05dd#diff-e539521643643e71817d62bf10237ce2573286f0a9b3800d46a4f3c6a51c23baL733' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41380566</div><div id='project'> Project Name: quic/aimet</div><div id='commit'> Commit Name: c9cadfe0cede11da01757e9e189988fa912b05dd</div><div id='time'> Time: 2022-05-19</div><div id='author'> Author: quic_kyunggeu@quicinc.com</div><div id='file'> File Name: TrainingExtensions/torch/src/python/aimet_torch/qc_quantize_op.py</div><div id='m_class'> M Class Name: LearnedGridQuantWrapper</div><div id='n_method'> N Class Name: LearnedGridQuantWrapper</div><div id='m_method'> M Method Name: forward(1)</div><div id='n_method'> N Method Name: forward(1)</div><div id='m_parent_class'> M Parent Class: QcQuantizeWrapper</div><div id='n_parent_class'> N Parent Class: QcQuantizeWrapper</div><div id='m_file'> M File Name: TrainingExtensions/torch/src/python/aimet_torch/qc_quantize_op.py</div><div id='n_file'> N File Name: TrainingExtensions/torch/src/python/aimet_torch/qc_quantize_op.py</div><div id='m_start'> M Start Line: 733</div><div id='m_end'> M End Line: 763</div><div id='n_start'> N Start Line: 737</div><div id='n_end'> N End Line: 751</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>


def read_shard(ckpt_dir):
    out<a id="change"> = []</a>
    <a id="change">for idx</a> in range(WEIGHT_PIECES)<a id="change">:
        </a>file_path = ckpt_dir + f"{idx}.npz"
        with smart_open(file_path, "rb") as f:
            buf = f.read()
            f_io = io.BytesIO(buf)
            deserialized = np.load(f_io)
            for i in deserialized:
                <a id="change">out.append(</a>deserialized[i]<a id="change">)</a>
    return out


def deep_replace(d, value):</code></pre><h3>After Change</h3><pre><code class='java'>


def read_shard(ckpt_dir):
    <a id="change">with </a><a id="change">smart_open(ckpt_dir, "rb") as f:
        </a>buf = f.read()
    f_io = io.BytesIO(buf)
    deserialized = list(np.load(f_io).items())
    return [tensor for idx, tensor in sorted(deserialized, key=lambda x: int(x[0]))]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/homebrewnlp/homebrewnlp-jax/commit/8c9cc16b7d3e0be58199b36a90e4c40d2e7e1626#diff-ded7b1244f44df4f2cc244746bfb4ef768ee5f12cf303be377f049d243181fb6L82' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41380565</div><div id='project'> Project Name: homebrewnlp/homebrewnlp-jax</div><div id='commit'> Commit Name: 8c9cc16b7d3e0be58199b36a90e4c40d2e7e1626</div><div id='time'> Time: 2022-09-05</div><div id='author'> Author: 39779310+ClashLuke@users.noreply.github.com</div><div id='file'> File Name: src/utils/checkpoint.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: read_shard(1)</div><div id='n_method'> N Method Name: read_shard(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/utils/checkpoint.py</div><div id='n_file'> N File Name: src/utils/checkpoint.py</div><div id='m_start'> M Start Line: 83</div><div id='m_end'> M End Line: 92</div><div id='n_start'> N Start Line: 73</div><div id='n_end'> N End Line: 77</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        

        shadow_params = {}
        encoding_list_for_params<a id="change"> = []</a>

        self.apply_gating_logic()

        <a id="change">for </a>name, <a id="change">param</a> in self._module_to_wrap.named_parameters()<a id="change">:

            &#47&#47 Store current weight for use later on
            </a>shadow_params[name] = param.detach().clone()
            &#47&#47 Create a list of encoding parameters for params
            if self.param_quantizers[name].enabled:
                encoding_list_for_params.append(self._parameters[name + &quot_encoding_min&quot])
                <a id="change">encoding_list_for_params.append(</a>self._parameters[name + &quot_encoding_max&quot]<a id="change">)</a>

        &#47&#47 Quantize inputs
        quantized_inputs = self._quantize_activation(inputs, self.input_quantizers, &quotinput&quot)
        if isinstance(quantized_inputs, torch.Tensor):</code></pre><h3>After Change</h3><pre><code class='java'>
        if isinstance(quantized_inputs, torch.Tensor):
            quantized_inputs = [quantized_inputs]

        <a id="change">with </a><a id="change">self._quantize_params(quantized_inputs):
            &#47&#47 Call the forward of the wrapped module
            </a>wrapped_output = self._module_to_wrap(*quantized_inputs)

        &#47&#47 Quantize the outputs
        &#47&#47 pylint: disable=all</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/quic/aimet/commit/c9cadfe0cede11da01757e9e189988fa912b05dd#diff-e539521643643e71817d62bf10237ce2573286f0a9b3800d46a4f3c6a51c23baL725' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41380564</div><div id='project'> Project Name: quic/aimet</div><div id='commit'> Commit Name: c9cadfe0cede11da01757e9e189988fa912b05dd</div><div id='time'> Time: 2022-05-19</div><div id='author'> Author: quic_kyunggeu@quicinc.com</div><div id='file'> File Name: TrainingExtensions/torch/src/python/aimet_torch/qc_quantize_op.py</div><div id='m_class'> M Class Name: LearnedGridQuantWrapper</div><div id='n_method'> N Class Name: LearnedGridQuantWrapper</div><div id='m_method'> M Method Name: forward(1)</div><div id='n_method'> N Method Name: forward(1)</div><div id='m_parent_class'> M Parent Class: QcQuantizeWrapper</div><div id='n_parent_class'> N Parent Class: QcQuantizeWrapper</div><div id='m_file'> M File Name: TrainingExtensions/torch/src/python/aimet_torch/qc_quantize_op.py</div><div id='n_file'> N File Name: TrainingExtensions/torch/src/python/aimet_torch/qc_quantize_op.py</div><div id='m_start'> M Start Line: 733</div><div id='m_end'> M End Line: 763</div><div id='n_start'> N Start Line: 737</div><div id='n_end'> N End Line: 751</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        with tf.variable_scope(&quotFast-RCNN&quot):

            with tf.variable_scope(&quotrois_pooling&quot):
                roi_features_list<a id="change"> = []</a>
                <a id="change">for </a>level_name, <a id="change">rois</a> in zip(self.cfgs.LEVEL, rois_list)<a id="change">:  &#47&#47 exclude P6_rois

                    &#47&#47 if mode == 0:
                    </a>roi_features = roi_extractor.roi_align(feature_maps=feature_pyramid[level_name],
                                                           rois=rois, img_shape=img_shape,
                                                           scope=level_name)
                    &#47&#47 else:
                    &#47&#47     raise Exception(&quotonly support roi align (mode=0)&quot)

                    <a id="change">roi_features_list.append(</a>roi_features<a id="change">)</a>

                all_roi_features = tf.concat(roi_features_list, axis=0)  &#47&#47 [minibatch_size, H, W, C]

            with tf.variable_scope(&quotbuild_fc_layers&quot):</code></pre><h3>After Change</h3><pre><code class='java'>

                fc2 = slim.fully_connected(fc1, num_outputs=1024, trainable=is_training, scope=&quotfc2&quot)

            <a id="change">with </a><a id="change">tf.variable_scope(&quothorizen_branch&quot):
                </a>with slim.arg_scope([slim.fully_connected], weights_regularizer=slim.l2_regularizer(self.cfgs.WEIGHT_DECAY)):
                    cls_score_h = slim.fully_connected(fc2,
                                                       num_outputs=self.cfgs.CLASS_NUM + 1,
                                                       weights_initializer=self.cfgs.INITIALIZER,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yangxue0827/rotationdetection/commit/a1a748ef567969afbb9ac4cd216d41995669829e#diff-93bb9b0aa4ef630eea9dbb7b13e95744cfda647736f5b72881fb01728e102cd2L13' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41380562</div><div id='project'> Project Name: yangxue0827/rotationdetection</div><div id='commit'> Commit Name: a1a748ef567969afbb9ac4cd216d41995669829e</div><div id='time'> Time: 2020-11-03</div><div id='author'> Author: yangxue0827@126.com</div><div id='file'> File Name: libs/models/box_heads/box_head_base.py</div><div id='m_class'> M Class Name: BoxHead</div><div id='n_method'> N Class Name: BoxHead</div><div id='m_method'> M Method Name: fc_head(7)</div><div id='n_method'> N Method Name: fc_head(7)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: libs/models/box_heads/box_head_base.py</div><div id='n_file'> N File Name: libs/models/box_heads/box_head_base.py</div><div id='m_start'> M Start Line: 17</div><div id='m_end'> M End Line: 51</div><div id='n_start'> N Start Line: 59</div><div id='n_end'> N End Line: 108</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &quotinput_ids&quot: torch.zeros((1, seq_len), dtype=torch.int64).to(device)
    }

    peak_memory<a id="change"> = []</a>
    <a id="change">for _</a> in range(n_trials)<a id="change">:
        </a>rss = memory_usage(proc=(_track_peak_memory, (model, inputs)),
                           max_usage=True,
                           backend=&quotpsutil&quot,
                           include_children=False,
                           multiprocess=True)
        <a id="change">peak_memory.append(</a>rss<a id="change">)</a>

    return np.median(peak_memory) if use_median else np.mean(peak_memory)
</code></pre><h3>After Change</h3><pre><code class='java'>
        &quotinput_ids&quot: torch.zeros((1, seq_len), dtype=torch.int64).to(device)
    }

    <a id="change">with </a><a id="change">profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
                 profile_memory=True) as p:
        </a>model(**inputs)

    if device == &quotcpu&quot:
        peak_memory = sum([key.cpu_memory_usage for key in p.key_averages()])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/archai/commit/f966cd315f5e8f126a3296c0852981a9249b309b#diff-4da44c5a16a311faa454a0083c1d2a6b89e065482be4715d4129dfdca566cc1eL78' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41380561</div><div id='project'> Project Name: microsoft/archai</div><div id='commit'> Commit Name: f966cd315f5e8f126a3296c0852981a9249b309b</div><div id='time'> Time: 2022-12-16</div><div id='author'> Author: gth.rosa@uol.com.br</div><div id='file'> File Name: archai/nlp/nas/search_utils/constraints.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: measure_peak_memory(5)</div><div id='n_method'> N Method Name: measure_peak_memory(7)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: archai/nlp/nas/search_utils/constraints.py</div><div id='n_file'> N File Name: archai/nlp/nas/search_utils/constraints.py</div><div id='m_start'> M Start Line: 80</div><div id='m_end'> M End Line: 123</div><div id='n_start'> N Start Line: 106</div><div id='n_end'> N End Line: 115</div><BR>