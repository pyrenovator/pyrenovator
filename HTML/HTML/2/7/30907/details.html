<html><h3>Pattern ID :30907
</h3><img src='91001772.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        
        length = input.size(1)

        return self.pe[:, <a id="change">:</a>length]


class DPTBlock(nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>

    def forward(self, x):

        x<a id="change"> = </a>x.permute(0, 2, 1).contiguous()

        &#47&#47 x is seq_len, batch, channels
        &#47&#47 x = x + self.pe[:x.size(0), :]

        &#47&#47 x is batch, channels, seq_len
        x = x<a id="change"> + </a>self.pe[:, :, :x.size(2)]

        x<a id="change"> = </a><a id="change">self.dropout(</a>x<a id="change">)</a>

        x<a id="change"> = </a>x.permute(0, 2, 1).contiguous()

        <a id="change">return </a>x


class DPTBlock(nn.Module):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/zhongyang-debug/attention-is-all-you-need-in-speech-separation/commit/361486e2e14685189e9a65a81fa779b4728c6e18#diff-7c8acbb8793a584bfe2ae80520bfb2e801e64479bf65e6f723edd575961f9c17L133' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 91001772</div><div id='project'> Project Name: zhongyang-debug/attention-is-all-you-need-in-speech-separation</div><div id='commit'> Commit Name: 361486e2e14685189e9a65a81fa779b4728c6e18</div><div id='time'> Time: 2022-08-16</div><div id='author'> Author: 68770882+Zhongyang-debug@users.noreply.github.com</div><div id='file'> File Name: model/sepformer.py</div><div id='m_class'> M Class Name: Positional_Encoding</div><div id='n_method'> N Class Name: Positional_Encoding</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/sepformer.py</div><div id='n_file'> N File Name: model/sepformer.py</div><div id='m_start'> M Start Line: 133</div><div id='m_end'> M End Line: 135</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 155</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        x = self.embedding(x, **kwargs)  &#47&#47 (batch_size, target_seq_len, d_model)
        x *= tf.math.sqrt(tf.cast(self.d_model, x.dtype))
        x += tf.cast(self.pos_encoding[:, <a id="change">:</a>seq_len, :], dtype=x.dtype)

        x = self.dropout(x, **kwargs)
</code></pre><h3>After Change</h3><pre><code class='java'>
        output = pos_enc_tgt

        for i in range(self.num_layers):
            normed_output<a id="change"> = </a>self.layer_norm(output, **kwargs)
            output = output<a id="change"> + </a>self.dropout(
                self.attention[i](normed_output, normed_output, normed_output, target_mask, **kwargs),
                **kwargs,
            )
            normed_output = self.layer_norm(output, **kwargs)
            output<a id="change"> = </a>output + <a id="change">self.dropout(
                </a>self.source_attention[i](normed_output, memory, memory, source_mask, **kwargs)<a id="change">,
                **kwargs,
            )</a>
            normed_output = self.layer_norm(output, **kwargs)
            output<a id="change"> = </a>output + self.dropout(self.position_feed_forward[i](normed_output, **kwargs), **kwargs)

        &#47&#47 (batch_size, seq_len, d_model)
        <a id="change">return </a>self.layer_norm(output, **kwargs)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mindee/doctr/commit/9530f81d15395006b4844299236bdadba11c1dde#diff-e1106a3628d5365c5fe2e4fec7304ea8e40c58a5439f23d8f20513e722955178L242' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 91001774</div><div id='project'> Project Name: mindee/doctr</div><div id='commit'> Commit Name: 9530f81d15395006b4844299236bdadba11c1dde</div><div id='time'> Time: 2022-07-01</div><div id='author'> Author: felixdittrich92@gmail.com</div><div id='file'> File Name: doctr/models/recognition/transformer/tensorflow.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: call(5)</div><div id='n_method'> N Method Name: call(5)</div><div id='m_parent_class'> M Parent Class: NestedObject,layers.Layer</div><div id='n_parent_class'> N Parent Class: tf.keras.layers.Layer</div><div id='m_file'> M File Name: doctr/models/recognition/transformer/tensorflow.py</div><div id='n_file'> N File Name: doctr/models/recognition/transformer/tensorflow.py</div><div id='m_start'> M Start Line: 251</div><div id='m_end'> M End Line: 265</div><div id='n_start'> N Start Line: 160</div><div id='n_end'> N End Line: 179</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        x = self.embedding(x)  &#47&#47 (batch_size, target_seq_len, d_model)
        x *= math.sqrt(self.d_model)
        x += self.pos_encoding[:, <a id="change">:</a>seq_len, :]
        x = self.dropout(x)

        &#47&#47 Batch first = True in decoder</code></pre><h3>After Change</h3><pre><code class='java'>

        tgt = self.embed(tgt) * math.sqrt(self.d_model)
        pos_enc_tgt = self.positional_encoding(tgt)
        output<a id="change"> = </a>pos_enc_tgt

        for i in range(self.num_layers):
            normed_output = self.layer_norm(output)
            output = output<a id="change"> + </a>self.dropout(
                self.attention[i](normed_output, normed_output, normed_output, target_mask)
            )
            normed_output = self.layer_norm(output)
            output<a id="change"> = </a>output + <a id="change">self.dropout(
                </a>self.source_attention[i](normed_output, memory, memory, source_mask)<a id="change">
            )</a>
            normed_output<a id="change"> = </a>self.layer_norm(output)
            output = output + self.dropout(self.position_feed_forward[i](normed_output))

        <a id="change">return </a>self.layer_norm(output)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mindee/doctr/commit/fddceba7bee5098b4219b7ba6a0bdf4f4a98adfe#diff-5eb4b6b7a215017ac91351a0c5e665af04fa644ddf1ecd5037545ba096ec1337L69' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 91001775</div><div id='project'> Project Name: mindee/doctr</div><div id='commit'> Commit Name: fddceba7bee5098b4219b7ba6a0bdf4f4a98adfe</div><div id='time'> Time: 2022-06-09</div><div id='author'> Author: felixdittrich92@gmail.com</div><div id='file'> File Name: doctr/models/recognition/transformer/pytorch.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: doctr/models/recognition/transformer/pytorch.py</div><div id='n_file'> N File Name: doctr/models/recognition/transformer/pytorch.py</div><div id='m_start'> M Start Line: 74</div><div id='m_end'> M End Line: 91</div><div id='n_start'> N Start Line: 147</div><div id='n_end'> N End Line: 167</div><BR>