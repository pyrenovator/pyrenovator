<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        image = np.ascontiguousarray(image, dtype=np.float32)
        image = image
        image /= 255
        if <a id="change">len(</a>image.shape<a id="change">)</a> == 3:
            image = image[None]  &#47&#47 expand for batch dim

        input_name = self.model.get_inputs()[0].name</code></pre><h3>After Change</h3><pre><code class='java'>
        original_image, processed_image = self.image_preprocessing(image, input_shape)
        
        &#47&#47 Inference
        <a id="change">if </a><a id="change">self.use_onnx</a>:
            &#47&#47 Input names of ONNX model on which it is exported   
            input_name = self.model.get_inputs()[0].name
            &#47&#47 Run onnx model 
            pred = self.model.run([self.model.get_outputs()[0].name], {input_name: processed_image})[0]
            &#47&#47 Run Pytorch model        
        else:
            processed_image = torch.from_numpy(processed_image).to(self.device)
            &#47&#47 Change image floating point precision if fp16 set to true
            processed_image = processed_image.half() if self.fp16 else processed_image.float() 
            pred = self.model(processed_image, augment=False)[0]
            pred<a id="change"> = pred.detach().cpu().numpy()</a>
        
        if isinstance(pred, np.ndarray):
            pred = torch.tensor(pred, device=self.device)
        predictions = non_max_suppression(</code></pre>