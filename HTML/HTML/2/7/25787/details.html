<html><h3>Pattern ID :25787
</h3><img src='78040230.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    use_gpu = True if args.device == &quotgpu&quot else False

    faiss_document_store = "faiss_document_store.db"
    <a id="change">if </a>os.path.exists(args.index_name) and os.path.exists(faiss_document_store):
        &#47&#47 connect to existed FAISS Index
        document_store<a id="change"> = </a><a id="change">FAISSDocumentStore.load(</a>args.index_name<a id="change">)</a>
        if (os.path.exists(args.params_path)):
            retriever<a id="change"> = </a>DensePassageRetriever(
                document_store=document_store,
                query_embedding_model=args.query_embedding_model,
                params_path=args.params_path,
                output_emb_size=args.embedding_dim,
                max_seq_len_query=args.max_seq_len_query,
                max_seq_len_passage=args.max_seq_len_passage,
                batch_size=args.retriever_batch_size,
                use_gpu=use_gpu,
                embed_title=False,
            )
        else:
            retriever = DensePassageRetriever(
                document_store=document_store,
                query_embedding_model=args.query_embedding_model,
                passage_embedding_model=args.passage_embedding_model,
                max_seq_len_query=args.max_seq_len_query,
                max_seq_len_passage=args.max_seq_len_passage,
                batch_size=args.retriever_batch_size,
                use_gpu=use_gpu,
                embed_title=False,
            )
    else:
        doc_dir = "data/dureader_dev"
        dureader_data = "https://paddlenlp.bj.bcebos.com/applications/dureader_dev.zip"

        fetch_archive_from_http(url=dureader_data, output_dir=doc_dir)
        dicts<a id="change"> = </a>convert_files_to_dicts(dir_path=doc_dir,
                                       split_paragraphs=True,
                                       encoding=&quotutf-8&quot)
</code></pre><h3>After Change</h3><pre><code class='java'>

    use_gpu = True if args.device == &quotgpu&quot else False

    <a id="change">if </a>(args.search_engine == &quotmilvus&quot):
        retriever<a id="change"> = </a>get_milvus_retriever(use_gpu)
    else:
        retriever = get_faiss_retriever(use_gpu)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/e893a6304e2564d57fb06d42ea7e6f76abfa9b01#diff-0fd6879ca5b6071cd33e25c5c135f46df8debc8c9cdf29f3293b9110765e3fb7L55' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78040230</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: e893a6304e2564d57fb06d42ea7e6f76abfa9b01</div><div id='time'> Time: 2022-09-18</div><div id='author'> Author: w5688414@gmail.com</div><div id='file'> File Name: pipelines/examples/semantic-search/semantic_search_example.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: semantic_search_tutorial(0)</div><div id='n_method'> N Method Name: semantic_search_tutorial(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: pipelines/examples/semantic-search/semantic_search_example.py</div><div id='n_file'> N File Name: pipelines/examples/semantic-search/semantic_search_example.py</div><div id='m_start'> M Start Line: 55</div><div id='m_end'> M End Line: 131</div><div id='n_start'> N Start Line: 185</div><div id='n_end'> N End Line: 193</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        onnx.checker.check_model(onnx_model)
    except RuntimeError as e:
        opset_version=11
        <a id="change">if </a>"aten::upsample_bilinear2d" in e.args[0]:
            operator_export_type<a id="change"> = </a>torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK
            torch.onnx.export(model, dummy_input, onnx_file, verbose=True,
                              input_names=[ "input" ] , output_names=["output"],
                              opset_version = opset_version,
                              operator_export_type=operator_export_type)
            onnx_model<a id="change"> = </a><a id="change">onnx.load(</a>onnx_file<a id="change">)</a>
            onnx.checker.check_model(onnx_model)
        else:
            raise Exception(e)
    except Exception as e:</code></pre><h3>After Change</h3><pre><code class='java'>
    convert torch model to tflite model using onnx
    
    if type(input_shape[0]) == tuple:
        <a id="change">if </a>check_model_is_cuda(model):
            dummy_input<a id="change"> = </a>tuple([torch.randn(ishape, device="cuda") for ishape in input_shape])
        else:
            dummy_input<a id="change"> = </a>tuple([torch.randn(ishape, device="cpu") for ishape in input_shape])
    elif type(input_shape) == tuple:
        if check_model_is_cuda(model):
            dummy_input = torch.randn(input_shape, device="cuda")</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/kuroko1t/nne/commit/a00ac8516ac6f9381d377673bd5eeb6db0c7961c#diff-fce3963ac4e3974ea4e6e8994066ae3c32f6cdfbbc4b09613cda6b754b521f7fL26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78040310</div><div id='project'> Project Name: kuroko1t/nne</div><div id='commit'> Commit Name: a00ac8516ac6f9381d377673bd5eeb6db0c7961c</div><div id='time'> Time: 2021-05-18</div><div id='author'> Author: kurosawa.yk@gmail.com</div><div id='file'> File Name: nne/onnx.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: cv2onnx(4)</div><div id='n_method'> N Method Name: cv2onnx(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: nne/onnx.py</div><div id='n_file'> N File Name: nne/onnx.py</div><div id='m_start'> M Start Line: 30</div><div id='m_end'> M End Line: 57</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 50</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def process(self, audio_path):
        &#47&#47 start = timeit.default_timer()
        with torch.no_grad():
            <a id="change">if </a>isinstance(audio_path, str):
            	audio<a id="change">, _ = </a><a id="change">librosa.load(</a>audio_path<a id="change">, sr=self.sample_rate)</a>  &#47&#47 reading the data
            else:
            	audio<a id="change"> = </a>audio_path
            feats = self.proc.process_audio(audio).T
            feats = torch.from_numpy(feats)
            feats = feats.unsqueeze(0)</code></pre><h3>After Change</h3><pre><code class='java'>


    def process(self, audio_path, inference_model, plot = False):
        <a id="change">if </a>inference_model == "PF":                 &#47&#47 instantiating a Particle Filter decoder - Is Chosen for online inference
            self.estimator<a id="change"> = </a>particle_filter_cascade(beats_per_bar=[], fps=50, plot=plot)
        elif inference_model == "DBN":                &#47&#47 instantiating an HMM decoder - Is chosen for offline inference
            self.estimator<a id="change"> = </a>DBNDownBeatTrackingProcessor(beats_per_bar=[2, 3, 4], fps=50)
        else:
            raise RuntimeError(&quotinference_model can be either "PF" or "DBN"&quot)
        preds = self.activation_extractor(audio_path)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mjhydri/beatnet/commit/0fb33177b8fcafe2daff996b597bcb04eeb71a15#diff-592f3b4d9c6eeded7fac4dbc1ac54ce2d8b7012a1045e4bc17945a64e9ce0a32L47' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78040275</div><div id='project'> Project Name: mjhydri/beatnet</div><div id='commit'> Commit Name: 0fb33177b8fcafe2daff996b597bcb04eeb71a15</div><div id='time'> Time: 2021-10-29</div><div id='author'> Author: mj.hydri@gmail.com</div><div id='file'> File Name: src/BeatNet/BeatNet.py</div><div id='m_class'> M Class Name: BeatNet</div><div id='n_method'> N Class Name: BeatNet</div><div id='m_method'> M Method Name: process(4)</div><div id='n_method'> N Method Name: process(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/BeatNet/BeatNet.py</div><div id='n_file'> N File Name: src/BeatNet/BeatNet.py</div><div id='m_start'> M Start Line: 47</div><div id='m_end'> M End Line: 71</div><div id='n_start'> N Start Line: 39</div><div id='n_end'> N End Line: 51</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 ex.: https://discuss.pytorch.org/t/bidirectional-lstm-and-onnx-runtime-warnings/136374
    &#47&#47 We need the nb of dims to be fixed to reserve GPU memory when using ONNX Runtime io binding API
    &#47&#47 Below we reopen the model and override the dynamic shape by a fixed one
    <a id="change">if </a>isinstance(model_pytorch, STransformerWrapper):  &#47&#47 for sentence-transformers model only
        output<a id="change"> = </a>model_pytorch(**inputs_pytorch)
        assert len(output.shape) == 2, "unexpected output tensor shape (!=2)"
        nb_dim<a id="change"> = </a>output.shape[1]
        onnx_model<a id="change"> = </a><a id="change">onnx.load(</a>output_path<a id="change">)</a>
        assert len(onnx_model.graph.output) == 1, "unexpected number of output tensors (!=1)"
        assert len(onnx_model.graph.output[0].type.tensor_type.shape.dim) == 2, "unexpected ouput tensor shape (!=2)"
        onnx_model.graph.output[0].type.tensor_type.shape.dim[1].dim_value = nb_dim
        onnx.save(onnx_model, output_path)</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 dynamic axis == variable length axis
    dynamic_axis = dict()
    for k in inputs_pytorch.keys():
        <a id="change">if </a>var_output_seq:
            &#47&#47 seq axis name is fixed to be matched with output seq axis name (for output shape prediction)
            dynamic_axis[k] = {0: "batch_size", 1: "sequence"}
        else:
            &#47&#47 if there is no specific requirement, each axis name is unique, fix some issue on T5 model
            dynamic_axis[k]<a id="change"> = </a>{0: "batch_size", 1: f"sequence-{k}"}
    dynamic_axis["output"] = {0: "batch_size"}
    if var_output_seq:
        dynamic_axis["output"][1] = "sequence"</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/els-rd/transformer-deploy/commit/d397869e95ee07570c47edefec01bdc673391b65#diff-b6a8238b3fb9a4340f2344d1920d7d21bb6d84607a20cc2039932f706418c8a6L81' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78040312</div><div id='project'> Project Name: els-rd/transformer-deploy</div><div id='commit'> Commit Name: d397869e95ee07570c47edefec01bdc673391b65</div><div id='time'> Time: 2022-05-23</div><div id='author'> Author: pommedeterresautee@users.noreply.github.com</div><div id='file'> File Name: src/transformer_deploy/backends/pytorch_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: convert_to_onnx(5)</div><div id='n_method'> N Method Name: convert_to_onnx(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/transformer_deploy/backends/pytorch_utils.py</div><div id='n_file'> N File Name: src/transformer_deploy/backends/pytorch_utils.py</div><div id='m_start'> M Start Line: 118</div><div id='m_end'> M End Line: 158</div><div id='n_start'> N Start Line: 113</div><div id='n_end'> N End Line: 150</div><BR>