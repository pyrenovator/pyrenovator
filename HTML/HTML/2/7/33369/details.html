<html><h3>Pattern ID :33369
</h3><img src='96103064.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        super().__init__(env, args, action_length)
        self.input_size = env.observation().shape

        layers, filters = <a id="change">args.get(</a>&quotlayers&quot, <a id="change">3</a><a id="change">)</a>, <a id="change">args.get(</a>&quotfilters&quot, <a id="change">32</a><a id="change">)</a>
        internal_size = (filters, *self.input_size[1:])

        self.encoder = Encoder(self.input_size, filters)
        self.body = DRCCore(layers, filters, filters)</code></pre><h3>After Change</h3><pre><code class='java'>
        self.num_layers = num_layers

        blocks = []
        <a id="change">for </a>_ in <a id="change">range(</a>self.num_layers<a id="change">):
            </a>blocks.append(ConvLSTMCell(
                input_dim=input_dim,
                hidden_dim=hidden_dim,
                kernel_size=(kernel_size, kernel_size),</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/dena/handyrl/commit/c2731f3af6293f7583d95d8546e41ef8c5bfc5af#diff-fada037ad086638e65c7ae77e3d223963e9afaa26326aab0ea718f4013176e43L188' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 96103064</div><div id='project'> Project Name: dena/handyrl</div><div id='commit'> Commit Name: c2731f3af6293f7583d95d8546e41ef8c5bfc5af</div><div id='time'> Time: 2020-07-06</div><div id='author'> Author: a.a.b.a.b.c.a.b.c.d.abcd1234@gmail.com</div><div id='file'> File Name: model.py</div><div id='m_class'> M Class Name: DRC</div><div id='n_method'> N Class Name: DRC</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: BaseModel</div><div id='m_file'> M File Name: model.py</div><div id='n_file'> N File Name: model.py</div><div id='m_start'> M Start Line: 288</div><div id='m_end'> M End Line: 297</div><div id='n_start'> N Start Line: 188</div><div id='n_end'> N End Line: 200</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

            filename=os.path.join(self.videos_dir, video_name.replace(&quot.yuv&quot, &quot.mp4&quot))

            <a id="change">video_capture</a> = cv2.VideoCapture()
            video_capture.open(filename)
            cap=cv2.VideoCapture(filename)

            video_channel = 3

            video_height_crop = 448
            video_width_crop = 448

            video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))

            video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
            video_length_read = 5

            transformed_video = torch.zeros([video_length_read, video_channel,  video_height_crop, video_width_crop])
                    
            frame_idx = 0
            frame_ts = <a id="change">video_capture.get(0</a><a id="change">)</a>
            for i in range(video_length):
                &#47&#47 the current time: ms
                last_ts = <a id="change">video_capture.get(0</a><a id="change">)</a>
                has_frames, frame = video_capture.read()
                
                if last_ts &gt;= frame_ts and frame_idx &lt; video_length_read:
                    if frame_idx &lt;= video_length_read:</code></pre><h3>After Change</h3><pre><code class='java'>
                    frame_idx += 1

            if video_read_index &lt; video_length_read:
                <a id="change">for </a>i in <a id="change">range(</a>video_read_index, video_length_read<a id="change">):
                    </a>transformed_video[i] = transformed_video[video_read_index - 1]
    
            video_capture.release()
            video[i_type] = transformed_video</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sunwei925/compressedvqa/commit/09b7b06f419c50f543d05799599f367bfc40e56d#diff-e42ca25bb5510426ff2e770dc5dec52a2e8bce0c9a6ac8a51ec50277e98b7ddfL107' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 96103054</div><div id='project'> Project Name: sunwei925/compressedvqa</div><div id='commit'> Commit Name: 09b7b06f419c50f543d05799599f367bfc40e56d</div><div id='time'> Time: 2022-05-09</div><div id='author'> Author: sunwei925@163.com</div><div id='file'> File Name: data_loader.py</div><div id='m_class'> M Class Name: VideoDataset_FR</div><div id='n_method'> N Class Name: VideoDataset_FR</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: data.Dataset</div><div id='n_parent_class'> N Parent Class: data.Dataset</div><div id='m_file'> M File Name: data_loader.py</div><div id='n_file'> N File Name: data_loader.py</div><div id='m_start'> M Start Line: 123</div><div id='m_end'> M End Line: 157</div><div id='n_start'> N Start Line: 137</div><div id='n_end'> N End Line: 164</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        filename=os.path.join(self.videos_dir, video_name.replace(&quot.yuv&quot, &quot.mp4&quot))

        <a id="change">video_capture</a> = cv2.VideoCapture()
        video_capture.open(filename)
        cap=cv2.VideoCapture(filename)

        video_channel = 3

        video_height_crop = 448
        video_width_crop = 448

        video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))

        video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
       
        video_length_read = 10

        transformed_video = torch.zeros([video_length_read, video_channel,  video_height_crop, video_width_crop])
                
        frame_idx = 0
        frame_ts = <a id="change">video_capture.get(0</a><a id="change">)</a>
        for i in range(video_length):
            &#47&#47 the current time: ms
            last_ts = <a id="change">video_capture.get(0</a><a id="change">)</a>
            has_frames, frame = video_capture.read()
            
            if last_ts &gt;= frame_ts and frame_idx &lt; video_length_read:
                if frame_idx &lt;= video_length_read:</code></pre><h3>After Change</h3><pre><code class='java'>
                frame_idx += 1

        if video_read_index &lt; video_length_read:
            <a id="change">for </a>i in <a id="change">range(</a>video_read_index, video_length_read<a id="change">):
                </a>transformed_video[i] = transformed_video[video_read_index - 1]

        video_capture.release()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sunwei925/compressedvqa/commit/09b7b06f419c50f543d05799599f367bfc40e56d#diff-e42ca25bb5510426ff2e770dc5dec52a2e8bce0c9a6ac8a51ec50277e98b7ddfL39' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 96103053</div><div id='project'> Project Name: sunwei925/compressedvqa</div><div id='commit'> Commit Name: 09b7b06f419c50f543d05799599f367bfc40e56d</div><div id='time'> Time: 2022-05-09</div><div id='author'> Author: sunwei925@163.com</div><div id='file'> File Name: data_loader.py</div><div id='m_class'> M Class Name: VideoDataset_NR</div><div id='n_method'> N Class Name: VideoDataset_NR</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: data.Dataset</div><div id='n_parent_class'> N Parent Class: data.Dataset</div><div id='m_file'> M File Name: data_loader.py</div><div id='n_file'> N File Name: data_loader.py</div><div id='m_start'> M Start Line: 45</div><div id='m_end'> M End Line: 79</div><div id='n_start'> N Start Line: 55</div><div id='n_end'> N End Line: 82</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        super().__init__(env, args, action_length)
        self.input_size = env.observation().shape

        layers, filters = <a id="change">args.get(</a>&quotlayers&quot, <a id="change">3</a><a id="change">)</a>, <a id="change">args.get(</a>&quotfilters&quot, <a id="change">32</a><a id="change">)</a>
        internal_size = (filters, *self.input_size[1:])

        self.encoder = Encoder(self.input_size, filters)
        self.body = DRCCore(layers, filters, filters)</code></pre><h3>After Change</h3><pre><code class='java'>
        self.num_layers = num_layers

        blocks = []
        <a id="change">for </a>_ in <a id="change">range(</a>self.num_layers<a id="change">):
            </a>blocks.append(ConvLSTMCell(
                input_dim=input_dim,
                hidden_dim=hidden_dim,
                kernel_size=(kernel_size, kernel_size),</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/dena/handyrl/commit/c2731f3af6293f7583d95d8546e41ef8c5bfc5af#diff-fada037ad086638e65c7ae77e3d223963e9afaa26326aab0ea718f4013176e43L287' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 96103057</div><div id='project'> Project Name: dena/handyrl</div><div id='commit'> Commit Name: c2731f3af6293f7583d95d8546e41ef8c5bfc5af</div><div id='time'> Time: 2020-07-06</div><div id='author'> Author: a.a.b.a.b.c.a.b.c.d.abcd1234@gmail.com</div><div id='file'> File Name: model.py</div><div id='m_class'> M Class Name: DRC</div><div id='n_method'> N Class Name: DRC</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: BaseModel</div><div id='m_file'> M File Name: model.py</div><div id='n_file'> N File Name: model.py</div><div id='m_start'> M Start Line: 288</div><div id='m_end'> M End Line: 297</div><div id='n_start'> N Start Line: 188</div><div id='n_end'> N End Line: 200</div><BR>