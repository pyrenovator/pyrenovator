<html><h3>Pattern ID :1031
</h3><img src='5081353.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        
        

        <a id="change">raise </a>NotImplementedError


class MemTransformerLMOnnxConfig(OnnxConfig):</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Shape of present states (past states when outputting)
        &#47&#47 [2, batch_size, n_head, total_seq_len, d_head]
        &#47&#47 Note total_seq_len is current seq_len + past_seq_len
        presents = [(<a id="change">f&quotpresent_{i}&quot</a><a id="change">, {1: &quotbatch_size&quot, 3: &quottotal_seq_len&quot}</a>) for i in range(self.config[&quotn_layer&quot])]
        <a id="change">return </a><a id="change">OrderedDict(</a>[(<a id="change">&quotlogits&quot</a><a id="change">, {0: &quotbatch_size&quot, 1: &quotseq_len&quot}</a>)] + presents<a id="change">)</a>


class HfGPT2OnnxConfig(OnnxConfig):
    Provides an ONNX-export configuration for HfGPT2.</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/microsoft/archai/commit/6878b01a5792e5c3a06a5db1be363600cc31f430#diff-fe9dc30c81061786fc78605c562e41e2b2f0ed857b833dd74cd33ead47276101L53' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5081353</div><div id='project'> Project Name: microsoft/archai</div><div id='commit'> Commit Name: 6878b01a5792e5c3a06a5db1be363600cc31f430</div><div id='time'> Time: 2022-12-16</div><div id='author'> Author: gth.rosa@uol.com.br</div><div id='file'> File Name: archai/nlp/nvidia_transformer_xl/onnx/onnx_utils/configs.py</div><div id='m_class'> M Class Name: OnnxConfig</div><div id='n_method'> N Class Name: OnnxConfig</div><div id='m_method'> M Method Name: outputs(1)</div><div id='n_method'> N Method Name: outputs(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: archai/nlp/nvidia_transformer_xl/onnx/onnx_utils/configs.py</div><div id='n_file'> N File Name: archai/nlp/nvidia_transformer_xl/onnx/onnx_utils/configs.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 53</div><div id='n_start'> N Start Line: 59</div><div id='n_end'> N End Line: 60</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        

        <a id="change">raise </a>NotImplementedError

    @property
    def outputs(self) -&gt; None:</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 Shape of past states
        &#47&#47 [past_key_values, batch_size, n_head, past_seq_len, d_head]
        pasts = [(<a id="change">f&quotpast_{i}&quot</a><a id="change">, {1: &quotbatch_size&quot, 3: &quotpast_seq_len&quot}</a>) for i in range(self.config[&quotn_layer&quot])]
        <a id="change">return </a><a id="change">OrderedDict(</a>[(<a id="change">&quotinput_ids&quot</a><a id="change">, {0: &quotbatch_size&quot, 1: &quotseq_len&quot}</a>)] + pasts<a id="change">)</a>

    @property
    def outputs(self) -&gt; OrderedDict:
        Defines the outputs and their shapes to be used when exporting to ONNX.</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/archai/commit/6878b01a5792e5c3a06a5db1be363600cc31f430#diff-fe9dc30c81061786fc78605c562e41e2b2f0ed857b833dd74cd33ead47276101L40' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5081352</div><div id='project'> Project Name: microsoft/archai</div><div id='commit'> Commit Name: 6878b01a5792e5c3a06a5db1be363600cc31f430</div><div id='time'> Time: 2022-12-16</div><div id='author'> Author: gth.rosa@uol.com.br</div><div id='file'> File Name: archai/nlp/nvidia_transformer_xl/onnx/onnx_utils/configs.py</div><div id='m_class'> M Class Name: OnnxConfig</div><div id='n_method'> N Class Name: OnnxConfig</div><div id='m_method'> M Method Name: inputs(1)</div><div id='n_method'> N Method Name: inputs(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: archai/nlp/nvidia_transformer_xl/onnx/onnx_utils/configs.py</div><div id='n_file'> N File Name: archai/nlp/nvidia_transformer_xl/onnx/onnx_utils/configs.py</div><div id='m_start'> M Start Line: 45</div><div id='m_end'> M End Line: 45</div><div id='n_start'> N Start Line: 47</div><div id='n_end'> N End Line: 48</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                ]
            )

        <a id="change">raise </a>AssertionError("Unsupported task &quot{self.task}&quot for modality `{self.modality}`")

    @property
    def outputs(self) -&gt; OrderedDict[str, OutputDescription]:</code></pre><h3>After Change</h3><pre><code class='java'>
    @property
    def _input_descriptions(self) -&gt; OrderedDict[str, InputDescription]:
        if self.modality == "text" and self.seq2seq == "decoder":
            <a id="change">return </a><a id="change">OrderedDict(
                </a>[
                    (
                        "encoder_last_hidden_state",
                        InputDescription(
                            "encoder_last_hidden_state",
                            "Sequence of hidden states at the output of the last layer of the encoder",
                        )
                    ),
                    (
                        <a id="change">"input_ids"</a><a id="change">,
                        InputDescription(
                            "decoder_input_ids",
                            "Indices of decoder input sequence tokens in the vocabulary",
                        )</a>
                    ),
                    (
                        <a id="change">"attention_mask"</a><a id="change">,
                        InputDescription(
                            "decoder_attention_mask",
                            "Mask to avoid performing attention on padding token indices (1 = not masked, 0 = masked)",
                        )</a>
                    ),
                ]<a id="change">
            )</a>

        if self.modality == "text" and self.task in [
            "default",
            "causal-lm",</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/exporters/commit/0ec6acabdae817c53f9228b042bfed039c4f8f69#diff-9efb11cf718ed446ee8267cf92b9821a82990cbd1065fff1622e9c347464e3d3L155' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5081354</div><div id='project'> Project Name: huggingface/exporters</div><div id='commit'> Commit Name: 0ec6acabdae817c53f9228b042bfed039c4f8f69</div><div id='time'> Time: 2022-10-03</div><div id='author'> Author: mail@hollance.com</div><div id='file'> File Name: src/exporters/coreml/config.py</div><div id='m_class'> M Class Name: CoreMLConfig</div><div id='n_method'> N Class Name: CoreMLConfig</div><div id='m_method'> M Method Name: _input_descriptions(1)</div><div id='n_method'> N Method Name: _input_descriptions(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/exporters/coreml/config.py</div><div id='n_file'> N File Name: src/exporters/coreml/config.py</div><div id='m_start'> M Start Line: 156</div><div id='m_end'> M End Line: 253</div><div id='n_start'> N Start Line: 181</div><div id='n_end'> N End Line: 306</div><BR>