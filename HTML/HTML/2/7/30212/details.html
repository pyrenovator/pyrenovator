<html><h3>Pattern ID :30212
</h3><img src='89666168.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    x_mask = torch.logical_not(torch.isnan(x))
    x_mask = torch.cummax(x_mask, -1)[1]
    output = x.gather(-1, x_mask)
    output<a id="change"> = </a><a id="change">output.transpose(-2</a>, <a id="change">-1</a><a id="change">)</a>  &#47&#47 shape (n, s, c)
    &#47&#47 Fill initial NaNs
    if torch.sum(torch.isnan(output)) &gt; 0:
        assert fill is not None, "argument &quotfill&quot must be provided"</code></pre><h3>After Change</h3><pre><code class='java'>
    
    assert len(input.size()) &gt;= 2, "Tensor &quotinput&quot must have at least two dimensions"
    if select is None:
        select<a id="change"> = </a>torch.arange(<a id="change">input.size(-1</a><a id="change">)</a>)
    &#47&#47 Last observation carried forward (all channels)
    x = input.transpose(-2, -1)  &#47&#47 shape (n, c, s)
    x_mask = torch.logical_not(torch.isnan(x))</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/philipdarke/torchtime/commit/b2519cb539c86e8471c692d7a3f469396a389cf5#diff-9605334f34b5e45bb643b4a69142a5e8954311d691ed30c9487a19523cefe16bL63' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 89666168</div><div id='project'> Project Name: philipdarke/torchtime</div><div id='commit'> Commit Name: b2519cb539c86e8471c692d7a3f469396a389cf5</div><div id='time'> Time: 2022-07-06</div><div id='author'> Author: 43066442+philipdarke@users.noreply.github.com</div><div id='file'> File Name: src/torchtime/impute.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: forward_impute(3)</div><div id='n_method'> N Method Name: forward_impute(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/torchtime/impute.py</div><div id='n_file'> N File Name: src/torchtime/impute.py</div><div id='m_start'> M Start Line: 84</div><div id='m_end'> M End Line: 87</div><div id='n_start'> N Start Line: 63</div><div id='n_end'> N End Line: 107</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        head_dim = embed_dim // (self.num_heads * 3)

        &#47&#47 Transpose seq_len and num_heads dim
        query_projected<a id="change"> = </a><a id="change">query_projected.view(
            batch_size, seq_len, 3 * self.num_heads, head_dim
        ).transpose(1</a>, <a id="change">2</a><a id="change">)</a>
        query, key, value = query_projected.chunk(3, 1)

        &#47&#47 the output of sdp = (batch, num_heads, seq_len, head_dim)
        attn, _ = torch.nn.functional._scaled_dot_product_attention(</code></pre><h3>After Change</h3><pre><code class='java'>
        )

        batch_size = query_projected.size(0)
        embed_dim = <a id="change">query_projected.size(2</a><a id="change">)</a>
        head_dim = embed_dim // (self.num_heads * 3)

        query, key, value = query_projected.chunk(3, -1)

        query = query.view(batch_size, -1, self.num_heads, head_dim).transpose(1, 2)
        key = key.view(batch_size, -1, self.num_heads, head_dim).transpose(1, 2)
        value<a id="change"> = </a>value.view(batch_size, -1, self.num_heads, head_dim).transpose(1, 2)

        &#47&#47 the output of sdp = (batch, num_heads, seq_len, head_dim)
        attn, _ = torch.nn.functional._scaled_dot_product_attention(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/d06d569e90f3ca3e721b679be285385e5bd3eea9#diff-a448dc0556e0de2ca5fa51c2ecf64422e62bcdce6232979511e141485be0a330L16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 89666169</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: d06d569e90f3ca3e721b679be285385e5bd3eea9</div><div id='time'> Time: 2022-10-18</div><div id='author'> Author: drisspg@fb.com</div><div id='file'> File Name: benchmarks/transformer/sdp.py</div><div id='m_class'> M Class Name: CompositeMHA</div><div id='n_method'> N Class Name: CompositeMHA</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: benchmarks/transformer/sdp.py</div><div id='n_file'> N File Name: benchmarks/transformer/sdp.py</div><div id='m_start'> M Start Line: 24</div><div id='m_end'> M End Line: 49</div><div id='n_start'> N Start Line: 26</div><div id='n_end'> N End Line: 52</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        value_states = value_states.view(*proj_shape)

        src_len = key_states.size(1)
        attn_weights<a id="change"> = </a>torch.bmm(query_states, <a id="change">key_states.transpose(1</a>, <a id="change">2</a><a id="change">)</a>)

        &#47&#47 q_t is [batch, seq_length, n_heads, dim_per_head]
        import ipdb; ipdb.set_trace()</code></pre><h3>After Change</h3><pre><code class='java'>

        proj_shape = (bsz * self.num_heads, -1, self.head_dim)
        query_states = self._shape(query_states, tgt_len, bsz)
        src_len<a id="change"> = </a><a id="change">key_states.size(2</a><a id="change">)</a>

        &#47&#47 compute scores
        attn_weights = torch.matmul(
            query_states, key_states.transpose(3, 2)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/joaolages/ratransformers/commit/87d3c27f618c060b396039f71734d515d3343a4b#diff-3bc988b93d619436305f06eadc62abd2469ae4a8ee0a636980fcd5202ebeee6fL18' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 89666171</div><div id='project'> Project Name: joaolages/ratransformers</div><div id='commit'> Commit Name: 87d3c27f618c060b396039f71734d515d3343a4b</div><div id='time'> Time: 2022-02-11</div><div id='author'> Author: joaop.glages@gmail.com</div><div id='file'> File Name: src/ratransformers/bart.py</div><div id='m_class'> M Class Name: BartRelationalAttention</div><div id='n_method'> N Class Name: BartRelationalAttention</div><div id='m_method'> M Method Name: forward(7)</div><div id='n_method'> N Method Name: forward(7)</div><div id='m_parent_class'> M Parent Class: BartAttention</div><div id='n_parent_class'> N Parent Class: BartAttention</div><div id='m_file'> M File Name: src/ratransformers/bart.py</div><div id='n_file'> N File Name: src/ratransformers/bart.py</div><div id='m_start'> M Start Line: 43</div><div id='m_end'> M End Line: 138</div><div id='n_start'> N Start Line: 43</div><div id='n_end'> N End Line: 139</div><BR>