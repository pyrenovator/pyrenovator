<html><h3>Pattern ID :25650
</h3><img src='77924836.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    analysis.benchmark_results = [performance_summary]
    summary = analysis.summary()

    <a id="change">summary["MODEL"]</a> = model_path
    _display_summary_as_table(summary)

    if save:</code></pre><h3>After Change</h3><pre><code class='java'>
    )
    summary.pretty_print()

    <a id="change">if compare is not None</a>:
        if "," in compare:
            compare = compare.split(",")
        else:
            compare = [compare]

        print("Comparison Analysis:")
        for model_to_compare in compare:
            compare_model_analysis = ModelAnalysis.create(model_to_compare)
            <a id="change">_LOGGER.info(f"Running Performance Analysis on {model_to_compare}"</a><a id="change">)</a>
            performance_summary = run_benchmark_and_analysis(
                onnx_model=model_to_path(model_to_compare),
                scenario=scenario,
            )
            compare_model_analysis.benchmark_results = [performance_summary]
            summary_comparison_model = compare_model_analysis.summary(
                by_types=by_types,
                by_layers=by_layers,
            )
            print(f"Comparing {model_path} with {model_to_compare}")
            print("Note: comparison analysis displays differences b/w models")
            comparison<a id="change"> = </a>summary - summary_comparison_model
            comparison.pretty_print()

    if save:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/neuralmagic/deepsparse/commit/f9c812958895f509c2c6c0194b839cb47c2faed8#diff-e476fb1c5e0f0162e9b4600c452f43c3878b345b117b6ceaa3e0d75bdcf9802bL48' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 77924836</div><div id='project'> Project Name: neuralmagic/deepsparse</div><div id='commit'> Commit Name: f9c812958895f509c2c6c0194b839cb47c2faed8</div><div id='time'> Time: 2023-04-19</div><div id='author'> Author: rahul@neuralmagic.com</div><div id='file'> File Name: src/deepsparse/analyze.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(7)</div><div id='n_method'> N Method Name: main(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/deepsparse/analyze.py</div><div id='n_file'> N File Name: src/deepsparse/analyze.py</div><div id='m_start'> M Start Line: 64</div><div id='m_end'> M End Line: 92</div><div id='n_start'> N Start Line: 48</div><div id='n_end'> N End Line: 122</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    with local_execution_manager(context_path):
        if not trial_class:
            logging.debug("Loading trial class from experiment configuration")
            trial_class = load.load_trial_implementation(<a id="change">env.experiment_config["entrypoint"]</a>)

        controller = load.load_controller_from_trial(
            trial_class=trial_class,</code></pre><h3>After Change</h3><pre><code class='java'>
    logging.info(f"Using hyperparameters: {env.hparams}")
    logging.debug(f"Using a test experiment config: {env.experiment_config}")

    <a id="change">if </a>native_context_cls is not None and <a id="change">controller_cls is not None</a>:
        &#47&#47 Case 1: test one batch for Native implementation.
        controller_cls.pre_execute_hook(env=env, hvd_config=hvd_config)
        context<a id="change"> = </a>native_context_cls(env=env, hvd_config=hvd_config)

        def train_fn() -&gt; None:
            controller = cast(Type[det.TrialController], controller_cls).from_native(
                context=context,
                env=env,
                workloads=workloads,
                load_path=None,
                rendezvous_info=rendezvous_info,
                hvd_config=hvd_config,
            )
            controller.run()
            checkpoint_dir.cleanup()

        context._set_train_fn(train_fn)
        logging.info(
            "Note: to submit an experiment to the cluster, change mode argument to Mode.CLUSTER"
        )
        return context

    elif trial_class is not None:
        &#47&#47 Case 2: test one batch for Trial implementation.
        controller = load.load_controller_from_trial(
            trial_class=trial_class,
            env=env,
            workloads=workloads,
            load_path=None,
            rendezvous_info=rendezvous_info,
            hvd_config=hvd_config,
        )
        controller.run()
        checkpoint_dir.cleanup()
        <a id="change">logging.info(
            "Note: to submit an experiment to the cluster, change mode argument to Mode.CLUSTER"</a><a id="change">
        )</a>

    else:
        raise errors.InternalException(
            "Must provide a trial_def if using Trial API or "</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/determined-ai/determined/commit/03270c0aafa01876b93c31eeb61b052807608307#diff-2e9eea92d2d4e898e5ac7ab67a269b4276d4b0c5d909e1321e370f5d74155039L431' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 77924832</div><div id='project'> Project Name: determined-ai/determined</div><div id='commit'> Commit Name: 03270c0aafa01876b93c31eeb61b052807608307</div><div id='time'> Time: 2020-05-15</div><div id='author'> Author: shiyuan@determined.ai</div><div id='file'> File Name: harness/determined/experimental/_native.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_one_batch(4)</div><div id='n_method'> N Method Name: test_one_batch(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: harness/determined/experimental/_native.py</div><div id='n_file'> N File Name: harness/determined/experimental/_native.py</div><div id='m_start'> M Start Line: 432</div><div id='m_end'> M End Line: 466</div><div id='n_start'> N Start Line: 325</div><div id='n_end'> N End Line: 387</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    
    with open(path, &quotr&quot) as fp:        
        args = yaml.full_load(fp.read())
    lg = logger(name, &quotlog/{}.log&quot.format(name), <a id="change">args[&quotsolver&quot][&quotpretrained&quot]</a>)
        
    &#47&#47 general settings
    args[&quotname&quot] = name</code></pre><h3>After Change</h3><pre><code class='java'>
        gpu_list = &quot,&quot.join([str(x) for x in args[&quotgpu_ids&quot]])
    lg.info(&quotAvailable gpus: {}&quot.format(gpu_list))
    os.environ[&quotCUDA_VISIBLE_DEVICES&quot] = gpu_list    
    <a id="change">if &quot,&quot in gpu_list</a>:
        args[&quotnetworks&quot][&quotdataparallel&quot]<a id="change"> = </a>True
        <a id="change">lg.info(&quotUsing Dataparallel&quot</a><a id="change">)</a>

    &#47&#47 create directories for paths
    args[&quotsolver&quot][&quotpretrained&quot] = pretrained
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nju-jet/sr_framework/commit/347951486f31c664f29999a7154f0f0c43a09b05#diff-bd1404f9a7e2ebead5dd526dab37d5b23ddc152d4ee8c9a854afd0e37d500fd6L12' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 77924835</div><div id='project'> Project Name: nju-jet/sr_framework</div><div id='commit'> Commit Name: 347951486f31c664f29999a7154f0f0c43a09b05</div><div id='time'> Time: 2020-09-20</div><div id='author'> Author: 151220022@smail.nju.edu.cn</div><div id='file'> File Name: sr_framework/options/options.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: parse(1)</div><div id='n_method'> N Method Name: parse(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: sr_framework/options/options.py</div><div id='n_file'> N File Name: sr_framework/options/options.py</div><div id='m_start'> M Start Line: 17</div><div id='m_end'> M End Line: 56</div><div id='n_start'> N Start Line: 13</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    logger.info("dist_world_size={}".format(dist_world_size))
    current_env["CUDA_VISIBLE_DEVICES"] = ",".join(map(str, local_gpu_ids))
    logger.info("Setting CUDA_VISIBLE_DEVICES={}".format(
        <a id="change">current_env["CUDA_VISIBLE_DEVICES"]</a>))
    exclusion_counts_per_node = None

    &#47&#47 set PyTorch distributed related environmental variables</code></pre><h3>After Change</h3><pre><code class='java'>
        if "NCCL" in k:
            logger.info(f"{args.node_rank} {k}={current_env[k]}")

    <a id="change">if args.world_info == "None"</a>:
        raise ValueError("world_info can not be None")
    world_info = base64.urlsafe_b64decode(args.world_info)
    world_info = json.loads(world_info)

    logger.info(f"WORLD INFO DICT: {world_info}")
    node_list = list(world_info.keys())
    args.nnodes = len(node_list)
    local_node = node_list[args.node_rank]
    local_gpu_ids = world_info[local_node]
    num_local_procs = len(local_gpu_ids)
    logger.info(
        f"nnodes={args.nnodes}, num_local_procs={num_local_procs}, node_rank={args.node_rank}"
    )

    global_rank_mapping = defaultdict(list)
    curr_global_rank = 0
    dist_world_size = 0
    for node_id in node_list:
        gids = world_info[node_id]
        dist_world_size += len(gids)
        for gid in gids:
            global_rank_mapping[node_id].append(curr_global_rank)
            curr_global_rank += 1
    logger.info(f"global_rank_mapping={global_rank_mapping}")
    logger.info(f"dist_world_size={dist_world_size}")
    current_env["CUDA_VISIBLE_DEVICES"] = ",".join(map(str, local_gpu_ids))
    logger.info(f"Setting CUDA_VISIBLE_DEVICES={current_env[&quotCUDA_VISIBLE_DEVICES&quot]}")

    &#47&#47 set PyTorch distributed related environmental variables
    current_env["MASTER_ADDR"] = args.master_addr
    current_env["MASTER_PORT"] = str(args.master_port)
    current_env["WORLD_SIZE"] = str(dist_world_size)

    processes = []
    cmd<a id="change"> = </a>[]
    for local_rank in range(0, num_local_procs):
        &#47&#47 each process&quots rank
        dist_rank = global_rank_mapping[local_node][local_rank]
        current_env["RANK"] = str(dist_rank)
        current_env["LOCAL_RANK"] = str(local_rank)

        &#47&#47 spawn the processes
        cmd = [sys.executable,
               "-u",
               args.training_script,
               f"--local_rank={local_rank}"] + args.training_script_args

        process = subprocess.Popen(cmd, env=current_env)
        processes.append(process)

    sig_names = {2: "SIGINT", 15: "SIGTERM"}
    last_return_code = None

    def sigkill_handler(signum, frame):
        for process in processes:
            logger.info(f"Killing subprocess {process.pid}")
            try:
                process.kill()
            except Exception:
                pass
        if last_return_code is not None:
            raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
        if signum in sig_names:
            logger.info(f"Main process received {sig_names[signum]}, exiting")
        sys.exit(1)

    &#47&#47 pass SIGINT/SIGTERM to children if the parent is being terminated
    signal.signal(signal.SIGINT, sigkill_handler)
    signal.signal(signal.SIGTERM, sigkill_handler)

    alive_processes = set(processes)
    while len(alive_processes):
        finished_processes = []
        for process in alive_processes:
            if process.poll() is None:
                &#47&#47 the process is still running
                continue
            else:
                if process.returncode != 0:
                    last_return_code = process.returncode  &#47&#47 for sigkill_handler
                    sigkill_handler(signal.SIGTERM, None)  &#47&#47 not coming back
                else:
                    &#47&#47 exited cleanly
                    <a id="change">logger.info(f"Process {process.pid} exits successfully."</a><a id="change">)</a>
                    finished_processes.append(process)
        alive_processes = set(alive_processes) - set(finished_processes)

        time.sleep(1)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/cf1f16016f7c700bc53e2d50df06d063469b5e7d#diff-d8d5404962a9fff74af7a35d2ae74df5831bb9ef8368902062bd3bcf821aa2a3L67' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 77924824</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: cf1f16016f7c700bc53e2d50df06d063469b5e7d</div><div id='time'> Time: 2021-11-05</div><div id='author'> Author: chunyang.wen@gmail.com</div><div id='file'> File Name: deepspeed/launcher/launch.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: deepspeed/launcher/launch.py</div><div id='n_file'> N File Name: deepspeed/launcher/launch.py</div><div id='m_start'> M Start Line: 68</div><div id='m_end'> M End Line: 146</div><div id='n_start'> N Start Line: 73</div><div id='n_end'> N End Line: 159</div><BR>