<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 batch size of data to normalize the gradient by 1/batch_size.
            trainer.step(batch.data[0].shape[0])
        &#47&#47 Gets the evaluation result.
        name<a id="change">, acc = </a><a id="change">metric.get()</a>
        &#47&#47 name_loss, running_loss = loss_metric.get()
        &#47&#47 Reset evaluation result to initial state.
        metric.reset()
        print("training acc at epoch %d: %s=%f" % (i, name, acc))</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 Use Accuracy and Cross Entropy Loss as the evaluation metric.
    accuracy_metric = mx.metric.Accuracy()
    loss_metric = mx.metric.CrossEntropy()
    metrics = <a id="change">mx.metric.CompositeEvalMetric()</a>
    <a id="change">for child_metric</a> in <a id="change">[</a>accuracy_metric, loss_metric<a id="change"></a>]<a id="change">:
        </a><a id="change">metrics.add(child_metric</a><a id="change">)</a>
    softmax_cross_entropy_loss = gluon.loss.SoftmaxCrossEntropyLoss()
    for i in range(epoch):
        &#47&#47 Reset the train data iterator.
        train_data.reset()</code></pre>