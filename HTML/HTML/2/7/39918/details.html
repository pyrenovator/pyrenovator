<html><h3>Pattern ID :39918
</h3><img src='113443843.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

def adjust_learning_rate(epoch, batch_idx):
    if epoch &lt; args.warmup_epochs:
        epoch<a id="change"> += </a><a id="change">float(</a>batch_idx<a id="change"> + </a>1<a id="change">) / </a>len(train_loader)
        lr_adj = 1. / hvd.size() * (epoch * (hvd.size() - 1) /
                                    args.warmup_epochs + 1)
    elif epoch &lt; 60: &#47&#4740: &#47&#4760:</code></pre><h3>After Change</h3><pre><code class='java'>
        lr_adj = 1. / hvd.size() * (epoch * (hvd.size() - 1) / args.warmup_epochs + 1)
    else:
        lr_adj = 1.
        <a id="change">for </a>e in args.lr_decay<a id="change">:
            </a>if epoch &gt; e:
                lr_adj<a id="change"> *= </a>0.1
         
    for param_group in optimizer.param_groups:
        param_group[&quotlr&quot] = args.lr * hvd.size() * lr_adj</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/gpauloski/kfac_pytorch/commit/cbda6c06839e29ad0ac4680cc491afc25e0514cb#diff-ecda7fc6c5166c4c75287fc6c3db2673b912f5fb536070a7eb2d4bcfb730ef4eL204' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113443843</div><div id='project'> Project Name: gpauloski/kfac_pytorch</div><div id='commit'> Commit Name: cbda6c06839e29ad0ac4680cc491afc25e0514cb</div><div id='time'> Time: 2020-02-23</div><div id='author'> Author: gpauloski@yahoo.com</div><div id='file'> File Name: examples/pytorch_cifar10_resnet.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: adjust_learning_rate(1)</div><div id='n_method'> N Method Name: adjust_learning_rate(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/pytorch_cifar10_resnet.py</div><div id='n_file'> N File Name: examples/pytorch_cifar10_resnet.py</div><div id='m_start'> M Start Line: 204</div><div id='m_end'> M End Line: 218</div><div id='n_start'> N Start Line: 225</div><div id='n_end'> N End Line: 230</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        mask_flag = torch.nn.functional.max_pool2d(one_zero_m, (self.block_size, self.block_size), stride=1, padding=1)
        mask = 1.0 - mask_flag

        elem_numel = input_shape<a id="change">[0] * input_shape[1] * </a>input_shape[2] * input_shape[3]
        elem_numel_m = <a id="change">float(</a>elem_numel<a id="change">)</a>

        elem_sum = mask.sum()

        output<a id="change"> = </a>input * mask *<a id="change"> elem_numel_m / </a>elem_sum
        return output

</code></pre><h3>After Change</h3><pre><code class='java'>
                shape = x.shape[2:]
            else:
                shape = x.shape[1:3]
            <a id="change">for s</a> in shape<a id="change">:
                </a>gamma<a id="change"> *= </a>s / (s - self.block_size + 1)

            matrix = torch.rand(x.shape, device=x.device)
            matrix = (matrix &lt; gamma).float()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/miemie2013/miemiedetection/commit/aabe1f2d364493c30179de6cf7d5c2d0c6ee7258#diff-a8b191246b197a19b67f7091a6ab58484cff81cdb9be1d770800a043a751c910L537' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113443875</div><div id='project'> Project Name: miemie2013/miemiedetection</div><div id='commit'> Commit Name: aabe1f2d364493c30179de6cf7d5c2d0c6ee7258</div><div id='time'> Time: 2021-12-30</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmdet/models/custom_layers.py</div><div id='m_class'> M Class Name: DropBlock</div><div id='n_method'> N Class Name: DropBlock</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: mmdet/models/custom_layers.py</div><div id='n_file'> N File Name: mmdet/models/custom_layers.py</div><div id='m_start'> M Start Line: 538</div><div id='m_end'> M End Line: 576</div><div id='n_start'> N Start Line: 724</div><div id='n_end'> N End Line: 745</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

def adjust_learning_rate(epoch, batch_idx):
    if epoch &lt; args.warmup_epochs:
        epoch<a id="change"> += </a><a id="change">float(</a>batch_idx<a id="change"> + </a>1<a id="change">) / </a>len(train_loader)
        lr_adj = 1. / hvd.size() * (epoch * (hvd.size() - 1) /
                                    args.warmup_epochs + 1)
    elif epoch &lt; 60: &#47&#4740: &#47&#4760:</code></pre><h3>After Change</h3><pre><code class='java'>
        lr_adj = 1. / hvd.size() * (epoch * (hvd.size() - 1) / args.warmup_epochs + 1)
    else:
        lr_adj = 1.
        <a id="change">for e</a> in args.lr_decay<a id="change">:
            </a>if epoch &gt; e:
                lr_adj<a id="change"> *= </a>0.1
         
    for param_group in optimizer.param_groups:
        param_group[&quotlr&quot] = args.lr * hvd.size() * lr_adj</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/gpauloski/kfac-pytorch/commit/cbda6c06839e29ad0ac4680cc491afc25e0514cb#diff-ecda7fc6c5166c4c75287fc6c3db2673b912f5fb536070a7eb2d4bcfb730ef4eL204' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113443893</div><div id='project'> Project Name: gpauloski/kfac-pytorch</div><div id='commit'> Commit Name: cbda6c06839e29ad0ac4680cc491afc25e0514cb</div><div id='time'> Time: 2020-02-23</div><div id='author'> Author: gpauloski@yahoo.com</div><div id='file'> File Name: examples/pytorch_cifar10_resnet.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: adjust_learning_rate(1)</div><div id='n_method'> N Method Name: adjust_learning_rate(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/pytorch_cifar10_resnet.py</div><div id='n_file'> N File Name: examples/pytorch_cifar10_resnet.py</div><div id='m_start'> M Start Line: 204</div><div id='m_end'> M End Line: 218</div><div id='n_start'> N Start Line: 225</div><div id='n_end'> N End Line: 230</div><BR>