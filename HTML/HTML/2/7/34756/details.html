<html><h3>Pattern ID :34756
</h3><img src='99755811.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    async def rpc_info(self, request: runtime_pb2.ExpertUID, context: P2PContext) -&gt; runtime_pb2.ExpertInfo:
        Return metadata about stored block uids and current load
        rpc_info<a id="change"> = </a><a id="change">{}</a>
        if request.uid:
            backend = self.module_backends[request.uid]
            rpc_info.update(self.module_backends[request.uid].get_info())
        else:</code></pre><h3>After Change</h3><pre><code class='java'>

        if request.uid:
            block_info = self.module_backends[request.uid].get_info()
            common_keys<a id="change"> = </a>set(result.keys()) & set(block_info.keys())
            <a id="change">if </a>common_keys:
                <a id="change">raise </a><a id="change">RuntimeError(f"The block&quots rpc_info has keys reserved for the server&quots rpc_info: {common_keys}"</a><a id="change">)</a>
            result.update(block_info)

        return runtime_pb2.ExpertInfo(serialized_info=MSGPackSerializer.dumps(result))
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/bigscience-workshop/distributed-bloom/commit/6b12b0d050f73826f6f66481d40146370e2bebbb#diff-1ec81fca927b01043d0984c86a71115967ba3530e5d168e50ebd69d48a3c0728L385' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 99755811</div><div id='project'> Project Name: bigscience-workshop/distributed-bloom</div><div id='commit'> Commit Name: 6b12b0d050f73826f6f66481d40146370e2bebbb</div><div id='time'> Time: 2023-01-12</div><div id='author'> Author: borzunov.alexander@gmail.com</div><div id='file'> File Name: src/petals/server/handler.py</div><div id='m_class'> M Class Name: TransformerConnectionHandler</div><div id='n_method'> N Class Name: TransformerConnectionHandler</div><div id='m_method'> M Method Name: rpc_info(3)</div><div id='n_method'> N Method Name: rpc_info(3)</div><div id='m_parent_class'> M Parent Class: ConnectionHandler</div><div id='n_parent_class'> N Parent Class: ConnectionHandler</div><div id='m_file'> M File Name: src/petals/server/handler.py</div><div id='n_file'> N File Name: src/petals/server/handler.py</div><div id='m_start'> M Start Line: 385</div><div id='m_end'> M End Line: 396</div><div id='n_start'> N Start Line: 387</div><div id='n_end'> N End Line: 402</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
          salience over all examples. They are sorted according to their
          salience.
    
    config<a id="change"> = </a>config or <a id="change">{}</a>
    &#47&#47 If no specific inputs provided, use the entire dataset.
    inputs_to_use = indexed_inputs or dataset.examples
    token_saliencies = self.salience_mappers[
        config[SALIENCE_MAPPER_KEY]].run_with_metadata(inputs_to_use, model,</code></pre><h3>After Change</h3><pre><code class='java'>
    if not config:
      raise TypeError(&quotconfig must be provided&quot)

    salience_key<a id="change">: Optional[str] = </a>config.get(SALIENCE_MAPPER_KEY)
    <a id="change">if </a>not salience_key:
      raise ValueError(f&quotconfig[{SALIENCE_MAPPER_KEY}] must be provided&quot)

    salience_interpreter: Optional[
        lit_components.Interpreter] = self.salience_mappers.get(salience_key)
    if not (salience_interpreter and
            salience_interpreter.is_compatible(model=model, dataset=dataset)):
      <a id="change">raise </a><a id="change">RuntimeError(f&quotRequested interpreter, {salience_key}, is &quot
                         &quotincompatible with model and/or dataset.&quot</a><a id="change">)</a>

    &#47&#47 If no specific inputs provided, use the entire dataset.
    inputs_to_use = indexed_inputs or dataset.examples
    token_saliencies = salience_interpreter.run_with_metadata(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pair-code/lit/commit/ecd3a6623f2a0d45ae26c74d0d72fb68b7bcb9aa#diff-492331b1bbc8f61b87b8854be3c68802bf2dd40756221cb20ad01b9eb89ddfe6L157' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 99755815</div><div id='project'> Project Name: pair-code/lit</div><div id='commit'> Commit Name: ecd3a6623f2a0d45ae26c74d0d72fb68b7bcb9aa</div><div id='time'> Time: 2022-11-03</div><div id='author'> Author: ryanmullins@google.com</div><div id='file'> File Name: lit_nlp/components/salience_clustering.py</div><div id='m_class'> M Class Name: SalienceClustering</div><div id='n_method'> N Class Name: SalienceClustering</div><div id='m_method'> M Method Name: run_with_metadata(6)</div><div id='n_method'> N Method Name: run_with_metadata(6)</div><div id='m_parent_class'> M Parent Class: lit_components.Interpreter</div><div id='n_parent_class'> N Parent Class: lit_components.Interpreter</div><div id='m_file'> M File Name: lit_nlp/components/salience_clustering.py</div><div id='n_file'> N File Name: lit_nlp/components/salience_clustering.py</div><div id='m_start'> M Start Line: 187</div><div id='m_end'> M End Line: 193</div><div id='n_start'> N Start Line: 193</div><div id='n_end'> N End Line: 210</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            x = set_device(input_data, device)
        else:
            if dtypes is None:
                dtypes<a id="change"> = </a><a id="change">[</a>torch.float<a id="change"></a>] * len(input_data)
            input_size = get_correct_input_sizes(input_data)
            x = get_input_tensor(input_size, batch_dim, dtypes, device)
</code></pre><h3>After Change</h3><pre><code class='java'>
    input_data: INPUT_DATA_TYPE, device: torch.device
) -&gt; Tuple[INPUT_DATA_TYPE, CORRECTED_INPUT_SIZE_TYPE]:
     Reads sample input data to get the input size. 
    x<a id="change"> = </a>None
    if isinstance(input_data, torch.Tensor):
        input_size = get_correct_input_sizes(input_data.size())
        x = [set_device(input_data, device)]

    elif isinstance(input_data, (list, tuple)):
        if all(isinstance(data, torch.Tensor) for data in input_data):
            input_sizes = [
                data.size() for data in input_data  &#47&#47 type: ignore[union-attr]
            ]
            input_size = get_correct_input_sizes(input_sizes)
            x = set_device(input_data, device)

    <a id="change">if </a>x is None:
        <a id="change">raise </a><a id="change">RuntimeError(
            "Input type is not recognized. Please ensure input_data is valid.\n"
            "For multiple inputs to the network, ensure input_data passed in is "
            "a sequence of tensors or a list of tuple sizes. If you are having "
            "trouble here, please submit a GitHub issue."</a><a id="change">
        )</a>

    return x, input_size

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tyleryep/torchinfo/commit/b3510714cc642b1e896e15b54b25bdb034faa332#diff-2642c7b47aafa9ce78758f30d62959e2a563c9b6b235bdfb512097f808e616c5L192' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 99755802</div><div id='project'> Project Name: tyleryep/torchinfo</div><div id='commit'> Commit Name: b3510714cc642b1e896e15b54b25bdb034faa332</div><div id='time'> Time: 2020-12-24</div><div id='author'> Author: tyep@cs.stanford.edu</div><div id='file'> File Name: torchinfo/torchinfo.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: process_input_data(2)</div><div id='n_method'> N Method Name: process_input_data(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchinfo/torchinfo.py</div><div id='n_file'> N File Name: torchinfo/torchinfo.py</div><div id='m_start'> M Start Line: 193</div><div id='m_end'> M End Line: 222</div><div id='n_start'> N Start Line: 217</div><div id='n_end'> N End Line: 241</div><BR>