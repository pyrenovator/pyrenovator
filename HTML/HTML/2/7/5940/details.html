<html><h3>Pattern ID :5940
</h3><img src='20857082.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                       deterministic: bool = False) -&gt; ActionType:
        implementation of :class:`~maze.core.agent.policy.Policy`
        
        action<a id="change">, _</a> = self.compute_action_with_logits(observation, actor_id, deterministic)
        return action

    @override(Policy)</code></pre><h3>After Change</h3><pre><code class='java'>
                       deterministic: bool = False) -&gt; ActionType:
        implementation of :class:`~maze.core.agent.policy.Policy`
        
        <a id="change">with torch</a><a id="change">.no_grad():
            </a>policy_out = self.compute_substep_policy_output(observation, actor_id)
            if <a id="change">deterministic</a>:
                action<a id="change"> = </a>policy_out.prob_dist.deterministic_sample()
            else:
                action<a id="change"> = </a>policy_out.prob_dist.sample()
        return convert_to_numpy(action, cast=None, in_place=False)

    @override(Policy)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/enlite-ai/maze/commit/53f2ea0b5fb4905306f4410f61af75372256fbcc#diff-92e333a960bae1a2574e681e1f527176c05f76baf245e1d51d25a0d85a9ce865L179' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 20857082</div><div id='project'> Project Name: enlite-ai/maze</div><div id='commit'> Commit Name: 53f2ea0b5fb4905306f4410f61af75372256fbcc</div><div id='time'> Time: 2021-06-24</div><div id='author'> Author: office@enlite.ai</div><div id='file'> File Name: maze/core/agent/torch_policy.py</div><div id='m_class'> M Class Name: TorchPolicy</div><div id='n_method'> N Class Name: TorchPolicy</div><div id='m_method'> M Method Name: compute_action(6)</div><div id='n_method'> N Method Name: compute_action(6)</div><div id='m_parent_class'> M Parent Class: TorchModel,Policy</div><div id='n_parent_class'> N Parent Class: TorchModel,Policy</div><div id='m_file'> M File Name: maze/core/agent/torch_policy.py</div><div id='n_file'> N File Name: maze/core/agent/torch_policy.py</div><div id='m_start'> M Start Line: 197</div><div id='m_end'> M End Line: 198</div><div id='n_start'> N Start Line: 179</div><div id='n_end'> N End Line: 185</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
def visualize_4_way(cfg):

    &#47&#47 MODELS
    seg_model_path<a id="change">, pred_rgb_model_path, pred_mask_model_path, pred_colorized_mask_model_path</a> = model_paths
    seg_model = torch.load(cfg.seg)
    pred_rgb_model = torch.load(cfg.pred_rgb)
    pred_mask_model = torch.load(cfg.pred_mask)</code></pre><h3>After Change</h3><pre><code class='java'>
    test_loader = DataLoader(test_data, batch_size=1, shuffle=True, num_workers=4)
    iter_loader = iter(test_loader)

    <a id="change">with torch</a><a id="change">.no_grad():
        </a>for <a id="change">i</a> in tqdm(range(10)):

            frames = next(iter_loader).to(DEVICE)  &#47&#47 [1, T, 3, h, w]
            frames_vis = postprocess_img(frames.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
            input = frames[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 3, h, w]

            pred_rgb = pred_rgb_model.pred_n(input, pred_length=VIDEO_PRED_LENGTH)
            pred_rgb = torch.cat([input, pred_rgb], dim=1)  &#47&#47 [1, T, 3, h, w]
            pred_rgb_vis = postprocess_img(pred_rgb.squeeze(dim=0))  &#47&#47 [T, 3, h, w]

            pred_rgb = torch.stack([seg_model(pred_rgb[:, i]) for i in range(pred_rgb.shape[1])], dim=1)
            pred_rgb = pred_rgb.argmax(dim=2).squeeze()  &#47&#47 [T, h, w]
            pred_then_colorized_vis = colorize_semseg(postprocess_mask(pred_rgb), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2) &#47&#47 [T, 3, h, w]

            frames_seg = torch.stack([seg_model(frames[:, i]) for i in range(frames.shape[1])], dim=1).argmax(dim=2)  &#47&#47 [1, T, 1, h, w]
            frames_seg_in<a id="change"> = </a>torch.stack([(frames_seg == i) for i in range(SYNPICK_CLASSES)], dim=2).float()  &#47&#47 [1, T, c, h, w] one-hot float
            input_seg = frames_seg_in[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, c, h, w]
            pred_mask = pred_mask_model.pred_n(input_seg, pred_length=VIDEO_PRED_LENGTH).argmax(dim=2)  &#47&#47 [1, n, 1, h, w]
            pred_mask = torch.cat([input_seg.argmax(dim=2), pred_mask], dim=1).squeeze()  &#47&#47 [T, h, w]
            pred_mask_vis = colorize_semseg(postprocess_mask(pred_mask), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2)  &#47&#47 [T, 3, h, w]

            frames_colorized = colorize_semseg(postprocess_mask(frames_seg.squeeze()), num_classes=SYNPICK_CLASSES)
            frames_colorized_vis<a id="change"> = </a>frames_colorized.transpose(0, 3, 1, 2)  &#47&#47 [T, 3, h, w]

            input_colorized = preprocess_img(frames_colorized[:VIDEO_IN_LENGTH]).to(DEVICE).unsqueeze(dim=0)  &#47&#47 [b, t, 3, h, w]
            colorized_then_pred = pred_colorized_mask_model.pred_n(input_colorized, pred_length=VIDEO_PRED_LENGTH)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ais-bonn/vp-suite/commit/13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3#diff-e07d70acfca9139cbf2c37b7a0074bdfbb966d41dc6c7edcc2cef05e78c00af0L13' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 20857070</div><div id='project'> Project Name: ais-bonn/vp-suite</div><div id='commit'> Commit Name: 13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3</div><div id='time'> Time: 2021-08-02</div><div id='author'> Author: boltres@ais.uni-bonn.de</div><div id='file'> File Name: scripts/visualize_4_way.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: visualize_4_way(1)</div><div id='n_method'> N Method Name: visualize_4_way(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/visualize_4_way.py</div><div id='n_file'> N File Name: scripts/visualize_4_way.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 73</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 74</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    print(&quotmodel loaded&quot)

    dataiter = iter(dataloader)
    images<a id="change">, labels</a> = dataiter.next()

    for i, data in enumerate(dataloader, 0):
        inputs, labels = data</code></pre><h3>After Change</h3><pre><code class='java'>
    total_pred = {classname: 0 for classname in classes}

    &#47&#47 again no gradients needed
    <a id="change">with torch</a><a id="change">.no_grad():
        </a>for <a id="change">data</a> in dataloader:
            inputs, labels = data
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)    
            _<a id="change">, predictions = </a>torch.max(outputs, 1)
            &#47&#47 collect the correct predictions for each class
            for label, prediction in zip(labels, predictions):
                if label == prediction:
                    correct_pred[classes[label]] += 1
                total_pred[classes[label]]<a id="change"> += </a>1

    
    &#47&#47 print accuracy for each class</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/loretoparisi/hf-experiments/commit/286971f578836b95fec5d7123b3b23cd5fa01603#diff-e18ee566b47545dc43db41d92acbfe58becfa49e56bec72bca5adea1445e53e3L147' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 20857078</div><div id='project'> Project Name: loretoparisi/hf-experiments</div><div id='commit'> Commit Name: 286971f578836b95fec5d7123b3b23cd5fa01603</div><div id='time'> Time: 2021-05-11</div><div id='author'> Author: loretoparisi@gmail.com</div><div id='file'> File Name: src/mlpvision/train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test(5)</div><div id='n_method'> N Method Name: test(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/mlpvision/train.py</div><div id='n_file'> N File Name: src/mlpvision/train.py</div><div id='m_start'> M Start Line: 156</div><div id='m_end'> M End Line: 176</div><div id='n_start'> N Start Line: 158</div><div id='n_end'> N End Line: 192</div><BR>