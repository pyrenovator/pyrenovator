<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    test_sampler = torch.utils.data.distributed.DistributedSampler(test_dataset)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=2, pin_memory=True, sampler=test_sampler)

    if <a id="change">args.evaluate</a>:
        validate(test_loader, model, criterion, local_rank, args)
        return

    for epoch in range(args.start_epoch, args.epochs):
        train_sampler.set_epoch(epoch)
        test_sampler.set_epoch(epoch)

        adjust_learning_rate(optimizer, epoch, args)

        &#47&#47 train for one epoch
        train(train_loader, model, criterion, optimizer, epoch, local_rank, args)

        &#47&#47 evaluate on validation set
        acc1<a id="change"> = </a>validate(val_loader, model, criterion, local_rank, args)

        &#47&#47 remember best acc@1 and save checkpoint
        is_best = acc1 &gt; best_acc1
        best_acc1<a id="change"> = </a><a id="change">max(</a>acc1, best_acc1<a id="change">)</a>

        if args.local_rank == 0:
            save_checkpoint(
                {</code></pre><h3>After Change</h3><pre><code class='java'>

        for step, (images, labels) in enumerate(train_loader):
            &#47&#47 将对应进程的数据放到对应 GPU 上
            images<a id="change"> = </a>images.cuda(local_rank, non_blocking=True)
            labels = labels.cuda(local_rank, non_blocking=True)

            outputs = <a id="change">model(</a>images<a id="change">)</a>
            loss<a id="change"> = </a>criterion(outputs, labels)

            &#47&#47 torch.distributed.barrier()的作用是，阻塞进程，保证每个进程运行完这一行代码之前的所有代码，才能继续执行，这样才计算平均loss和平均acc的时候不会出现因为进程执行速度不一致的错误
            torch.distributed.barrier()</code></pre>