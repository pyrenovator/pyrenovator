<html><h3>Pattern ID :1707
</h3><img src='8145688.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>


    def add_clip_predictions(self, video_ids, clip_predictions, labels):
        <a id="change">super().add_clip_predictions(</a>video_ids, clip_predictions, labels<a id="change">)</a>

        assert labels.dim() in [1,2], f&quottarget has to be 1D or 2D tensor but got {target.dim()}-D.&quot
        if labels.dim() == 2:
            &#47&#47 Convert 2D one-hot label to 1D label</code></pre><h3>After Change</h3><pre><code class='java'>


    def add_clip_predictions(self, video_ids, clip_predictions, labels):
        <a id="change">video_ids</a><a id="change">, clip_predictions, labels = </a><a id="change">super().add_clip_predictions(video_ids</a>, <a id="change">clip_predictions</a>, <a id="change">labels</a><a id="change">)</a>
        if video_ids is None:
            return      &#47&#47 sometimes, after filtering the samples, there can be no samples to do anything.

        assert labels.dim() in [1,2], f&quottarget has to be 1D or 2D tensor but got {target.dim()}-D.&quot</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/kiyoon/pyvideoai/commit/4e88dceed941f9b6785d294fee48660ff837521f#diff-6a3e8cb508e2b37c324a12cd921860eb1d957b08e17f663fc7e7e790c8a3008bL22' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8145688</div><div id='project'> Project Name: kiyoon/pyvideoai</div><div id='commit'> Commit Name: 4e88dceed941f9b6785d294fee48660ff837521f</div><div id='time'> Time: 2022-02-28</div><div id='author'> Author: yoonkr33@gmail.com</div><div id='file'> File Name: pyvideoai/metrics/mean_perclass_accuracy.py</div><div id='m_class'> M Class Name: ClipMeanPerclassAccuracyMetric</div><div id='n_method'> N Class Name: ClipMeanPerclassAccuracyMetric</div><div id='m_method'> M Method Name: add_clip_predictions(4)</div><div id='n_method'> N Method Name: add_clip_predictions(4)</div><div id='m_parent_class'> M Parent Class: Metric</div><div id='n_parent_class'> N Parent Class: Metric</div><div id='m_file'> M File Name: pyvideoai/metrics/mean_perclass_accuracy.py</div><div id='n_file'> N File Name: pyvideoai/metrics/mean_perclass_accuracy.py</div><div id='m_start'> M Start Line: 22</div><div id='m_end'> M End Line: 22</div><div id='n_start'> N Start Line: 22</div><div id='n_end'> N End Line: 26</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>


    def add_clip_predictions(self, video_ids, clip_predictions, labels):
        <a id="change">super().add_clip_predictions(</a>video_ids, clip_predictions, labels<a id="change">)</a>

        assert labels.dim() in [1,2], f&quottarget has to be 1D or 2D tensor but got {target.dim()}-D.&quot
        if labels.dim() == 2:
            &#47&#47 Convert 2D one-hot label to 1D label</code></pre><h3>After Change</h3><pre><code class='java'>


    def add_clip_predictions(self, video_ids, clip_predictions, labels):
        video_ids<a id="change">, clip_predictions, labels = </a><a id="change">super().add_clip_predictions(</a>video_ids, clip_predictions, labels<a id="change">)</a>
        if video_ids is None:
            return      &#47&#47 sometimes, after filtering the samples, there can be no samples to do anything.

        assert labels.dim() in [1,2], f&quottarget has to be 1D or 2D tensor but got {target.dim()}-D.&quot</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/kiyoon/pyvideoai/commit/4e88dceed941f9b6785d294fee48660ff837521f#diff-6a3e8cb508e2b37c324a12cd921860eb1d957b08e17f663fc7e7e790c8a3008bL21' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8145689</div><div id='project'> Project Name: kiyoon/pyvideoai</div><div id='commit'> Commit Name: 4e88dceed941f9b6785d294fee48660ff837521f</div><div id='time'> Time: 2022-02-28</div><div id='author'> Author: yoonkr33@gmail.com</div><div id='file'> File Name: pyvideoai/metrics/mean_perclass_accuracy.py</div><div id='m_class'> M Class Name: ClipMeanPerclassAccuracyMetric</div><div id='n_method'> N Class Name: ClipMeanPerclassAccuracyMetric</div><div id='m_method'> M Method Name: add_clip_predictions(4)</div><div id='n_method'> N Method Name: add_clip_predictions(4)</div><div id='m_parent_class'> M Parent Class: Metric</div><div id='n_parent_class'> N Parent Class: Metric</div><div id='m_file'> M File Name: pyvideoai/metrics/mean_perclass_accuracy.py</div><div id='n_file'> N File Name: pyvideoai/metrics/mean_perclass_accuracy.py</div><div id='m_start'> M Start Line: 22</div><div id='m_end'> M End Line: 22</div><div id='n_start'> N Start Line: 22</div><div id='n_end'> N End Line: 26</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def add_clip_predictions(self, video_ids, clip_predictions, labels):
        We will ignore the video_ids and store all the clip predictions independently without aggregating (like averaging).
         
        <a id="change">super().add_clip_predictions(</a>video_ids, clip_predictions, labels<a id="change">)</a>
        with torch.no_grad():
            if &quotvideo_ids&quot in self.data.keys():
                self.data[&quotvideo_ids&quot] = torch.cat((self.data[&quotvideo_ids&quot], video_ids), dim=0)
                self.data[&quotclip_predictions&quot] = torch.cat((self.data[&quotclip_predictions&quot], clip_predictions), dim=0)</code></pre><h3>After Change</h3><pre><code class='java'>
    def add_clip_predictions(self, video_ids, clip_predictions, labels):
        We will ignore the video_ids and store all the clip predictions independently without aggregating (like averaging).
         
        video_ids<a id="change">, clip_predictions, labels = </a><a id="change">super().add_clip_predictions(</a>video_ids, clip_predictions, labels<a id="change">)</a>
        with torch.no_grad():
            if &quotvideo_ids&quot in self.data.keys():
                self.data[&quotvideo_ids&quot] = torch.cat((self.data[&quotvideo_ids&quot], video_ids), dim=0)
                self.data[&quotclip_predictions&quot] = torch.cat((self.data[&quotclip_predictions&quot], clip_predictions), dim=0)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/kiyoon/pyvideoai/commit/1ac7e48870f25a58c8fbd23f55dff68fa38650f3#diff-9c73601aa918974365fb7bf3192601a041f45f39a8743863e91dd5ba9be714bdL212' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8145684</div><div id='project'> Project Name: kiyoon/pyvideoai</div><div id='commit'> Commit Name: 1ac7e48870f25a58c8fbd23f55dff68fa38650f3</div><div id='time'> Time: 2021-07-21</div><div id='author'> Author: yoonkr33@gmail.com</div><div id='file'> File Name: pyvideoai/metrics/metric.py</div><div id='m_class'> M Class Name: ClipMetric</div><div id='n_method'> N Class Name: ClipMetric</div><div id='m_method'> M Method Name: add_clip_predictions(4)</div><div id='n_method'> N Method Name: add_clip_predictions(4)</div><div id='m_parent_class'> M Parent Class: Metric</div><div id='n_parent_class'> N Parent Class: Metric</div><div id='m_file'> M File Name: pyvideoai/metrics/metric.py</div><div id='n_file'> N File Name: pyvideoai/metrics/metric.py</div><div id='m_start'> M Start Line: 215</div><div id='m_end'> M End Line: 215</div><div id='n_start'> N Start Line: 217</div><div id='n_end'> N End Line: 217</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def add_clip_predictions(self, video_ids, clip_predictions, labels):
        We will average the clip predictions with the same video_ids.
         
        <a id="change">super().add_clip_predictions(</a>video_ids, clip_predictions, labels<a id="change">)</a>
        with torch.no_grad():
            for video_id, clip_prediction, label in zip(video_ids, clip_predictions, labels):
                video_id = video_id.item()
                &#47&#47label = label.item()</code></pre><h3>After Change</h3><pre><code class='java'>
    def add_clip_predictions(self, video_ids, clip_predictions, labels):
        We will average the clip predictions with the same video_ids.
         
        video_ids<a id="change">, clip_predictions, labels = </a><a id="change">super().add_clip_predictions(</a>video_ids, clip_predictions, labels<a id="change">)</a>
        with torch.no_grad():
            for video_id, clip_prediction, label in zip(video_ids, clip_predictions, labels):
                video_id = video_id.item()
                &#47&#47label = label.item()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/kiyoon/pyvideoai/commit/1ac7e48870f25a58c8fbd23f55dff68fa38650f3#diff-9c73601aa918974365fb7bf3192601a041f45f39a8743863e91dd5ba9be714bdL243' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8145685</div><div id='project'> Project Name: kiyoon/pyvideoai</div><div id='commit'> Commit Name: 1ac7e48870f25a58c8fbd23f55dff68fa38650f3</div><div id='time'> Time: 2021-07-21</div><div id='author'> Author: yoonkr33@gmail.com</div><div id='file'> File Name: pyvideoai/metrics/metric.py</div><div id='m_class'> M Class Name: AverageMetric</div><div id='n_method'> N Class Name: AverageMetric</div><div id='m_method'> M Method Name: add_clip_predictions(4)</div><div id='n_method'> N Method Name: add_clip_predictions(4)</div><div id='m_parent_class'> M Parent Class: Metric</div><div id='n_parent_class'> N Parent Class: Metric</div><div id='m_file'> M File Name: pyvideoai/metrics/metric.py</div><div id='n_file'> N File Name: pyvideoai/metrics/metric.py</div><div id='m_start'> M Start Line: 246</div><div id='m_end'> M End Line: 246</div><div id='n_start'> N Start Line: 248</div><div id='n_end'> N End Line: 248</div><BR>