<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 Create gaussians with mean=mu and variance=sigma^2
    g = torch.distributions.Normal(loc=mu, scale=sigma)
    &#47&#47 p(y|x,w) = exp(log p(y|x,w))
    loss<a id="change"> = </a><a id="change">torch.exp(</a>g.log_prob(target)<a id="change">)</a>
    &#47&#47 Sum along the dimension of target variables to reduce the dim of loss
    &#47&#47 (B, max(T), G, D_out) -&gt; (B, max(T), G)
    loss = torch.sum(loss, dim=3)
    &#47&#47 Sum all Gaussians with weight coefficients pi</code></pre><h3>After Change</h3><pre><code class='java'>
    target = target.unsqueeze(2).expand_as(sigma)

    &#47&#47 Expand the dim of pi as (B,max(T),G) -&gt; (B,max(T),G,1)-&gt; (B,max(T),G,D_out)
    pi<a id="change"> = </a><a id="change">pi.unsqueeze(3</a><a id="change">)</a>.expand_as(sigma)

    &#47&#47 Create gaussians with mean=mu and variance=sigma^2
    dist = torch.distributions.Normal(loc=mu, scale=sigma)

    &#47&#47 Use torch.log_sum_exp instead of the combination of torch.sum and torch.log
    &#47&#47 Please see https://github.com/r9y9/nnsvs/pull/20&#47&#47discussion_r495514563
    &#47&#47 log p(y|x,w) + log pi
    loss = dist.log_prob(target)<a id="change"> + </a>torch.log(pi)
    
    &#47&#47 Calculate negative log likelihood and average it
    &#47&#47 (B, max(T), G, D_out) -&gt; (B, max(T), D_out) -&gt; (B, D_out)
    loss = torch.logsumexp(loss, dim=2)
    loss = <a id="change">-torch.mean(loss, dim=1)</a>
    
    &#47&#47 Sum along the dimension of target variables to reduce the dim of loss
    &#47&#47 (B, D_out) -&gt; (B)
    loss = torch.sum(loss, dim=1)</code></pre>