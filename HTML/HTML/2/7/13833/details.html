<html><h3>Pattern ID :13833
</h3><img src='46075519.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                data, target = data.cuda(), target.cuda()
            optimizer.zero_grad()
            &#47&#47 Split data into sub-batches of size batch_size
            <a id="change">for i</a> in <a id="change">range(</a>0, len(data), args.batch_size<a id="change">):
                </a>data_batch = data[i:i + args.batch_size]
                target_batch<a id="change"> = </a>target[i:i + args.batch_size]
                output<a id="change"> = </a>model(data_batch)
                train_accuracy.update(accuracy(output, target_batch))
                loss = F.cross_entropy(output, target_batch)
                train_loss.update(loss)</code></pre><h3>After Change</h3><pre><code class='java'>

def train(epoch):
    model.train()
    <a id="change">for </a>scheduler in lr_scheduler<a id="change">:
        </a><a id="change">scheduler.step()</a>
    train_sampler.set_epoch(epoch)
    train_loss = Metric(&quottrain_loss&quot)
    train_accuracy = Metric(&quottrain_accuracy&quot)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/gpauloski/kfac-pytorch/commit/9afedfd17a78f485b4e75637ad3d59b90627938f#diff-19a5fa9b14aac49ae8de1f5bc85e046f7959f5d60ae3c3575533ff98fc6d2f5fL193' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 46075519</div><div id='project'> Project Name: gpauloski/kfac-pytorch</div><div id='commit'> Commit Name: 9afedfd17a78f485b4e75637ad3d59b90627938f</div><div id='time'> Time: 2020-03-05</div><div id='author'> Author: gpauloski@yahoo.com</div><div id='file'> File Name: examples/pytorch_imagenet_resnet50.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(1)</div><div id='n_method'> N Method Name: train(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/pytorch_imagenet_resnet50.py</div><div id='n_file'> N File Name: examples/pytorch_imagenet_resnet50.py</div><div id='m_start'> M Start Line: 208</div><div id='m_end'> M End Line: 235</div><div id='n_start'> N Start Line: 193</div><div id='n_end'> N End Line: 219</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 - eta -&gt; η
        &#47&#47 - pred_image_direction -&gt; "direction pointingc to x_t"
        &#47&#47 - pred_prev_image -&gt; "x_t-1"
        <a id="change">for t</a> in tqdm.tqdm(reversed(<a id="change">range(</a>num_inference_steps<a id="change">)</a>), total=num_inference_steps)<a id="change">:
            &#47&#47 1. predict noise residual
            </a>timesteps = torch.tensor([inference_step_times[t]] * image.shape[0], device=torch_device)
            pred_noise_t = self.unet(image, timesteps)

            if isinstance(pred_noise_t, dict):
                pred_noise_t = pred_noise_t["sample"]

            &#47&#47 2. predict previous mean of image x_t-1
            pred_prev_image<a id="change"> = </a>self.noise_scheduler.step(pred_noise_t, image, t, num_inference_steps, eta)

            &#47&#47 3. optionally sample variance
            variance = 0
            if eta &gt; 0:
                noise = torch.randn(image.shape, generator=generator).to(image.device)
                variance<a id="change"> = </a>self.noise_scheduler.get_variance(t, num_inference_steps).sqrt() * eta * noise

            &#47&#47 4. set current image to prev_image: x_t -&gt; x_t-1
            image = pred_prev_image + variance</code></pre><h3>After Change</h3><pre><code class='java'>

        self.scheduler.set_timesteps(num_inference_steps)

        <a id="change">for </a>t in tqdm.tqdm(self.scheduler.timesteps)<a id="change">:
            </a>residual = self.unet(image, t)

            if isinstance(residual, dict):
                residual = residual["sample"]

            &#47&#47 2. predict previous mean of image x_t-1 and add variance depending on eta
            &#47&#47 do x_t -&gt; x_t-1
            image = <a id="change">self.scheduler.step(</a>residual, t, image, eta<a id="change">)</a>["prev_sample"]

        &#47&#47 decode image with vae
        image = self.vqvae.decode(image)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/f448360bd0dfe5e28ee65ab2130532db91d5eafe#diff-5a7ee70ffdbd476077b691c023447641dd657f00acfc79868f392d410574c691L15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 46075517</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: f448360bd0dfe5e28ee65ab2130532db91d5eafe</div><div id='time'> Time: 2022-07-15</div><div id='author'> Author: patrick.v.platen@gmail.com</div><div id='file'> File Name: src/diffusers/pipelines/latent_diffusion_uncond/pipeline_latent_diffusion_uncond.py</div><div id='m_class'> M Class Name: LatentDiffusionUncondPipeline</div><div id='n_method'> N Class Name: LatentDiffusionUncondPipeline</div><div id='m_method'> M Method Name: __call__(6)</div><div id='n_method'> N Method Name: __call__(6)</div><div id='m_parent_class'> M Parent Class: DiffusionPipeline</div><div id='n_parent_class'> N Parent Class: DiffusionPipeline</div><div id='m_file'> M File Name: src/diffusers/pipelines/latent_diffusion_uncond/pipeline_latent_diffusion_uncond.py</div><div id='n_file'> N File Name: src/diffusers/pipelines/latent_diffusion_uncond/pipeline_latent_diffusion_uncond.py</div><div id='m_start'> M Start Line: 31</div><div id='m_end'> M End Line: 71</div><div id='n_start'> N Start Line: 31</div><div id='n_end'> N End Line: 50</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 - eta -&gt; η
        &#47&#47 - pred_image_direction -&gt; "direction pointingc to x_t"
        &#47&#47 - pred_prev_image -&gt; "x_t-1"
        <a id="change">for t</a> in tqdm.tqdm(reversed(<a id="change">range(</a>num_inference_steps<a id="change">)</a>), total=num_inference_steps)<a id="change">:
            &#47&#47 1. predict noise residual
            </a>with torch.no_grad():
                residual = self.unet(image, inference_step_times[t])

                if isinstance(residual, dict):
                    residual = residual["sample"]

            &#47&#47 2. predict previous mean of image x_t-1
            pred_prev_image<a id="change"> = </a>self.noise_scheduler.step(residual, image, t, num_inference_steps, eta)

            &#47&#47 3. optionally sample variance
            variance = 0
            if eta &gt; 0:
                noise = torch.randn(image.shape, generator=generator).to(image.device)
                variance<a id="change"> = </a>self.noise_scheduler.get_variance(t, num_inference_steps).sqrt() * eta * noise

            &#47&#47 4. set current image to prev_image: x_t -&gt; x_t-1
            image = pred_prev_image + variance</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 set step values
        self.scheduler.set_timesteps(num_inference_steps)

        <a id="change">for </a>t in tqdm.tqdm(self.scheduler.timesteps)<a id="change">:
            &#47&#47 1. predict noise residual
            </a>with torch.no_grad():
                residual = self.unet(image, t)

                if isinstance(residual, dict):
                    residual = residual["sample"]

            &#47&#47 2. predict previous mean of image x_t-1 and add variance depending on eta
            &#47&#47 do x_t -&gt; x_t-1
            image = <a id="change">self.scheduler.step(</a>residual, t, image, eta<a id="change">)</a>["prev_sample"]

        return {"sample": image}
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/f448360bd0dfe5e28ee65ab2130532db91d5eafe#diff-e50584b7225637d287e815f280f5d4eba5415903cafc62f029cd5f03b738f577L30' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 46075483</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: f448360bd0dfe5e28ee65ab2130532db91d5eafe</div><div id='time'> Time: 2022-07-15</div><div id='author'> Author: patrick.v.platen@gmail.com</div><div id='file'> File Name: src/diffusers/pipelines/ddim/pipeline_ddim.py</div><div id='m_class'> M Class Name: DDIMPipeline</div><div id='n_method'> N Class Name: DDIMPipeline</div><div id='m_method'> M Method Name: __call__(6)</div><div id='n_method'> N Method Name: __call__(6)</div><div id='m_parent_class'> M Parent Class: DiffusionPipeline</div><div id='n_parent_class'> N Parent Class: DiffusionPipeline</div><div id='m_file'> M File Name: src/diffusers/pipelines/ddim/pipeline_ddim.py</div><div id='n_file'> N File Name: src/diffusers/pipelines/ddim/pipeline_ddim.py</div><div id='m_start'> M Start Line: 35</div><div id='m_end'> M End Line: 77</div><div id='n_start'> N Start Line: 42</div><div id='n_end'> N End Line: 59</div><BR>