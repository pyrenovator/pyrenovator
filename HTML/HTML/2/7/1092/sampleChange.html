<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        z_list = [self._zero_state(hs)]
        for _ in range(1, len(self.lstm)):
            c_list += [self._zero_state(hs)]
            z_list<a id="change"> += </a><a id="change">[</a><a id="change">self._zero_state(</a>hs<a id="change">)</a>]
        prev_out = hs.new_zeros(1, self.odim)

        &#47&#47 initialize attention</code></pre><h3>After Change</h3><pre><code class='java'>
        z_list = [self._zero_state(hs)]
        for _ in range(1, len(self.lstm)):
            c_list = c_list + [self._zero_state(hs)]
            z_list = z_list + <a id="change">[</a><a id="change">self._zero_state(</a>hs<a id="change">)</a>]
        prev_out = hs.new_zeros(1, self.odim)

        &#47&#47 initialize attention
        prev_att_w = None
        self.att.reset()

        &#47&#47 setup for attention constraint
        if use_att_constraint:
            last_attended_idx = 0
        else:
            last_attended_idx = None

        &#47&#47 loop for an output sequence
        idx = 0
        outs, att_ws, probs = [], [], []
        while True:
            &#47&#47 updated index
            idx = idx + self.reduction_factor

            &#47&#47 decoder calculation
            if self.use_att_extra_inputs:
                att_c, att_w = self.att(hs,
                                        ilens,
                                        z_list[0],
                                        prev_att_w,
                                        prev_out,
                                        last_attended_idx=last_attended_idx,
                                        backward_window=backward_window,
                                        forward_window=forward_window, )
            else:
                att_c, att_w = self.att(hs,
                                        ilens,
                                        z_list[0],
                                        prev_att_w,
                                        last_attended_idx=last_attended_idx,
                                        backward_window=backward_window,
                                        forward_window=forward_window, )

            att_ws = att_ws + [att_w]
            if self.speaker_embedding_projection_size is not None:
                prenet_out = self.prenet(torch.cat([prev_out, speaker_embedding], dim=-1)) if self.prenet is not None else prev_out
            else:
                prenet_out = self.prenet(prev_out) if self.prenet is not None else prev_out
            xs = torch.cat([att_c, prenet_out], dim=1)
            z_list[0], c_list[0] = self.lstm[0](xs, (z_list[0], c_list[0]))
            for i in range(1, len(self.lstm)):
                z_list[i], c_list[i] = self.lstm[i](z_list[i - 1], (z_list[i], c_list[i]))
            zcs = (torch.cat([z_list[-1], att_c], dim=1) if self.use_concate else z_list[-1])
            outs<a id="change"> = </a>outs<a id="change"> + </a>[self.feat_out(zcs).view(1, self.odim, -1)]  &#47&#47 [(1, odim, r), ...]
            probs = probs + [torch.sigmoid(self.prob_out(zcs))[0]]  &#47&#47 [(r), ...]
            if self.output_activation_fn is not None:
                prev_out = self.output_activation_fn(outs[-1][:, :, -1])  &#47&#47 (1, odim)</code></pre>