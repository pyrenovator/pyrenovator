<html><h3>Pattern ID :17949
</h3><img src='58853571.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        x = x.unsqueeze(-1)
        x = self.project_to_steps(x)  &#47&#47 BxCxTxS
        x = self.dropout(x)
        x = <a id="change">x.unsqueeze(0).expand(</a>targets.size(0), -1, <a id="change">-1</a>, <a id="change">-1</a>, -1<a id="change">)</a>

        copies, bsz, dim, tsz, steps = x.shape
        steps = min(steps, tsz - self.offset)
        predictions = x.new(bsz * copies * (tsz - self.offset + 1) * steps - ((steps + 1) * steps // 2) * copies * bsz)</code></pre><h3>After Change</h3><pre><code class='java'>
            else:
                pos_num = (end - start) // copies
                predictions[start:end] = torch.einsum(
                    "bct,nbct-&gt;nbt", x[..., :-offset, i], <a id="change">targets</a>[..., <a id="change">offset</a>:]
                ).flatten()
                labels[start : start + pos_num] = 1.0
                if weights is not None:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/mohammadkhalifa/fairseq-tagging/commit/3335de5f441ee1b3824e16dcd98db620e40beaba#diff-9b4dd2bdb515c86c631253c805af3041e9bbf4ce7f68af6a1900ef5b4ffa5c5aL411' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58853571</div><div id='project'> Project Name: mohammadkhalifa/fairseq-tagging</div><div id='commit'> Commit Name: 3335de5f441ee1b3824e16dcd98db620e40beaba</div><div id='time'> Time: 2020-02-29</div><div id='author'> Author: alexei.b@gmail.com</div><div id='file'> File Name: fairseq/models/wav2vec.py</div><div id='m_class'> M Class Name: Wav2VecPredictionsModel</div><div id='n_method'> N Class Name: Wav2VecPredictionsModel</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: fairseq/models/wav2vec.py</div><div id='n_file'> N File Name: fairseq/models/wav2vec.py</div><div id='m_start'> M Start Line: 411</div><div id='m_end'> M End Line: 439</div><div id='n_start'> N Start Line: 638</div><div id='n_end'> N End Line: 691</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if (torch.sum(torch.isnan(cam_coords)) &gt; 0) or (torch.sum(torch.isinf(cam_coords)) &gt; 0):
            print(&quotWarning: Nan or Inf values in camera coordinate tensor.&quot)

        T_c2_c0 = <a id="change">cam_calib[&quotT_c2_c0&quot].unsqueeze(0).expand(</a>batch_size, <a id="change">4</a>, <a id="change">4</a><a id="change">)</a>.cuda()
        cam_coords = se3_inv(T_c2_c0).bmm(cam_coords)

        return cam_coords[:, :3, :], valid_points</code></pre><h3>After Change</h3><pre><code class='java'>
        batch_size, height, width = disparity.size()

        K2, K3 = cam_calib[&quotK2&quot].cuda(), cam_calib[&quotK3&quot].cuda()
        T_c2_c0 = <a id="change">cam_calib</a>[&quotT_c2_c0&quot][<a id="change">:</a>batch_size, :, :].float().cuda()
        T_c3_c0 = cam_calib[&quotT_c3_c0&quot][:batch_size, :, :].float().cuda()
        self.b = abs(T_c3_c0.bmm(se3_inv(T_c2_c0))[0, 0, 3])
        self.fl = K2[0, 0, 0]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/utiasasrl/hero_radar_odometry/commit/4eb1bdf7c40f496a3cd9fb79125911fcbf880f89#diff-a87808e398bbe5556e0bcab7c9a1127424e926136cf458eacb604bb416eefb69L164' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58853592</div><div id='project'> Project Name: utiasasrl/hero_radar_odometry</div><div id='commit'> Commit Name: 4eb1bdf7c40f496a3cd9fb79125911fcbf880f89</div><div id='time'> Time: 2020-08-17</div><div id='author'> Author: mona.gridseth@robotics.utias.utoronto.ca</div><div id='file'> File Name: utils/stereo_camera_model.py</div><div id='m_class'> M Class Name: StereoCameraModel</div><div id='n_method'> N Class Name: StereoCameraModel</div><div id='m_method'> M Method Name: inverse_camera_model(4)</div><div id='n_method'> N Method Name: inverse_camera_model(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: utils/stereo_camera_model.py</div><div id='n_file'> N File Name: utils/stereo_camera_model.py</div><div id='m_start'> M Start Line: 178</div><div id='m_end'> M End Line: 191</div><div id='n_start'> N Start Line: 185</div><div id='n_end'> N End Line: 202</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        batch_size = cam_coords.size(0)

        T_c2_c0 = <a id="change">cam_calib[&quotT_c2_c0&quot].unsqueeze(0).expand(</a>batch_size, <a id="change">4</a>, <a id="change">4</a><a id="change">)</a>.cuda()
        if cam_coords.size(1) == 4:
            cam_coords = T_c2_c0.bmm(cam_coords)
        else:</code></pre><h3>After Change</h3><pre><code class='java'>
        batch_size = cam_coords.size(0)

        K2, K3 = cam_calib[&quotK2&quot].cuda(), cam_calib[&quotK3&quot].cuda()
        T_c2_c0 = <a id="change">cam_calib</a>[&quotT_c2_c0&quot][<a id="change">:</a>batch_size, :, :].float().cuda()
        T_c3_c0 = cam_calib[&quotT_c3_c0&quot][:batch_size, :, :].float().cuda()
        self.b = abs(T_c3_c0.bmm(se3_inv(T_c2_c0))[0, 0, 3])
        self.fl = K2[0, 0, 0]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/utiasasrl/hero_radar_odometry/commit/4eb1bdf7c40f496a3cd9fb79125911fcbf880f89#diff-a87808e398bbe5556e0bcab7c9a1127424e926136cf458eacb604bb416eefb69L132' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58853599</div><div id='project'> Project Name: utiasasrl/hero_radar_odometry</div><div id='commit'> Commit Name: 4eb1bdf7c40f496a3cd9fb79125911fcbf880f89</div><div id='time'> Time: 2020-08-17</div><div id='author'> Author: mona.gridseth@robotics.utias.utoronto.ca</div><div id='file'> File Name: utils/stereo_camera_model.py</div><div id='m_class'> M Class Name: StereoCameraModel</div><div id='n_method'> N Class Name: StereoCameraModel</div><div id='m_method'> M Method Name: camera_model(3)</div><div id='n_method'> N Method Name: camera_model(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: utils/stereo_camera_model.py</div><div id='n_file'> N File Name: utils/stereo_camera_model.py</div><div id='m_start'> M Start Line: 141</div><div id='m_end'> M End Line: 154</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 160</div><BR>