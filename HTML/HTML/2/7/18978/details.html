<html><h3>Pattern ID :18978
</h3><img src='61741614.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    width = width or height
    n, c, h, w = x.shape
    h_, w_ = h // height, w // width
    return <a id="change">x.view(n, c, h_, height, w_, width).permute(0</a>, <a id="change">2</a>, 4, <a id="change">1</a>, 3, <a id="change">5</a><a id="change">)</a>.reshape(-1, c, height, width)


def minibatch_std_layer(x, channels=1, group_channels=None, epsilon=1e-8):</code></pre><h3>After Change</h3><pre><code class='java'>
    nd = len(spatial)
    assert len(spatial) == len(size)
    v = n, c
    <a id="change">for </a>cur, new in <a id="change">zip(</a>spatial, size<a id="change">):
        </a>v += (cur // new, new)
    perm = (0,) + tuple(range(2, nd * 2 + 1, 2)) + tuple(range(1, nd * 3, 2))
    return x.view(v).permute(perm).reshape((-1, c) + tuple(size))
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/fzj-inm1-bda/celldetection/commit/7fecd1666583cd1340eeee72c1548c9a6ee00db4#diff-eeb4de74e6ebc17b01b3327fa57ac57e7f4c415f58ab6e06f9d0c01bc0072e55L57' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 61741614</div><div id='project'> Project Name: fzj-inm1-bda/celldetection</div><div id='commit'> Commit Name: 7fecd1666583cd1340eeee72c1548c9a6ee00db4</div><div id='time'> Time: 2023-03-21</div><div id='author'> Author: eric@upschulte.com</div><div id='file'> File Name: celldetection/ops/commons.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: split_spatially(2)</div><div id='n_method'> N Method Name: split_spatially(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: celldetection/ops/commons.py</div><div id='n_file'> N File Name: celldetection/ops/commons.py</div><div id='m_start'> M Start Line: 57</div><div id='m_end'> M End Line: 74</div><div id='n_start'> N Start Line: 71</div><div id='n_end'> N End Line: 79</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                zip(self.ls_pos_embed, self.ls_transformer_encoder, self.ls_block_aggregation)):
            if level &gt; 0:
                &#47&#47 Switch back to channels last for transformer
                x = <a id="change">x.permute(0</a>, <a id="change">2</a>, <a id="change">3</a>, <a id="change">1</a><a id="change">)</a> &#47&#47 (B, H&quot, W&quot, C)
            x = blockify(x, self.block_size) &#47&#47 (B, T, N, C&quot)
            x = x + pos_embed
            x = transformer(x) &#47&#47 (B, T, N, C&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
        x = x.reshape(B, H//self.patch_size, W//self.patch_size, -1) &#47&#47 (B, H&quot, W&quot, C&quot)
        x = x.permute(0, 3, 1, 2)
        &#47&#47 NOTE: TorchScript won&quott let us subscript module lists with integer variables, so we iterate instead
        <a id="change">for </a>level, block_agg in <a id="change">zip(</a>self.levels, self.block_aggs<a id="change">):
            </a>x = level(x)
            x = block_agg(x)
        &#47&#47 Layer norm done over channel dim only
        x = self.norm(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/feng-lab/pytorch-image-models/commit/b11d949a06f4c19be616aba25e49bf33d13a6b23#diff-e211399888fa3b741d9160f3d951ddc724fe39ee05d9e83b46718906f0098cbcL318' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 61741486</div><div id='project'> Project Name: feng-lab/pytorch-image-models</div><div id='commit'> Commit Name: b11d949a06f4c19be616aba25e49bf33d13a6b23</div><div id='time'> Time: 2021-07-03</div><div id='author'> Author: alexander.soare159@gmail.com</div><div id='file'> File Name: timm/models/nest.py</div><div id='m_class'> M Class Name: Nest</div><div id='n_method'> N Class Name: Nest</div><div id='m_method'> M Method Name: forward_features(2)</div><div id='n_method'> N Method Name: forward_features(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: timm/models/nest.py</div><div id='n_file'> N File Name: timm/models/nest.py</div><div id='m_start'> M Start Line: 323</div><div id='m_end'> M End Line: 339</div><div id='n_start'> N Start Line: 342</div><div id='n_end'> N End Line: 348</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            video = torch.cat([image.unsqueeze(2), video], dim=2)  &#47&#47 1 x 64 x 21 x 16 x 16
        else:
            video = image.unsqueeze(2)
        video = <a id="change">video.view(*video.shape[:3], -1).permute(0</a>, <a id="change">2</a>, <a id="change">3</a>, <a id="change">1</a><a id="change">)</a>  &#47&#47 B x T x (H x W) x C -&gt; 1 x 21 x (16*16) x 64
        video = self.attention(video)  &#47&#47 1 x 21 x 256 x 64
        return video
</code></pre><h3>After Change</h3><pre><code class='java'>
        video = self.stem(video)
        s = None
        if len(self.encoder) &gt; 0:
            <a id="change">for </a>block, remapper in <a id="change">zip(</a>self.encoder, self.remapper<a id="change">):
                </a>if block.scaler is not None:
                    prev_s = nn.functional.interpolate(video, scale_factor=(1, 0.5, 0.5), recompute_scale_factor=False)
                else:
                    prev_s = video</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/laion-ai/phenaki/commit/e510eaef70feb098d2c1b5fac8b34291c1955c9e#diff-d2675e29d21c30767dbf4b16980547aac6cc99b46ce44781ec89d09ee7193467L60' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 61741573</div><div id='project'> Project Name: laion-ai/phenaki</div><div id='commit'> Commit Name: e510eaef70feb098d2c1b5fac8b34291c1955c9e</div><div id='time'> Time: 2022-10-17</div><div id='author'> Author: d6582533@gmail.com</div><div id='file'> File Name: vivq.py</div><div id='m_class'> M Class Name: Encoder</div><div id='n_method'> N Class Name: Encoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: vivq.py</div><div id='n_file'> N File Name: vivq.py</div><div id='m_start'> M Start Line: 62</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 90</div><div id='n_end'> N End Line: 104</div><BR>