<html><h3>Pattern ID :5920
</h3><img src='20821181.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        assert m2.compute_groups == {}

        for _ in range(2):  &#47&#47 repeat to emulate effect of multiple epochs
            preds<a id="change"> = torch</a><a id="change">.randn(</a>10, 3<a id="change">)</a>.softmax(dim=-1)
            target = torch.randint(3, (10,))
            m.update(preds, target)
            m2.update(preds, target)

            for _, member in m.items():
                assert member._update_called

            assert m.compute_groups == expected
            assert m2.compute_groups == {}

            preds<a id="change"> = torch</a><a id="change">.randn(</a>10, 3<a id="change">)</a>.softmax(dim=-1)
            target = torch.randint(3, (10,))
            &#47&#47 compute groups should kick in here
            m.update(preds, target)</code></pre><h3>After Change</h3><pre><code class='java'>
    )
    def test_check_compute_groups_correctness(self, metrics, expected, preds, target, prefix, postfix):
        Check that compute groups are formed after initialization and that metrics are correctly computed.
        <a id="change">if </a><a id="change">isinstance(</a>metrics, MetricCollection<a id="change">)</a>:
            prefix, postfix = None, None  &#47&#47 disable for nested collections
        m = MetricCollection(deepcopy(metrics), prefix=prefix, postfix=postfix, compute_groups=True)
        &#47&#47 Construct without for comparison</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorchlightning/metrics/commit/c2f55fa5f84bf1549a26bdab67d572503f06e18f#diff-330cbceebe6b405322f6b6da58eec20c9b26152524d2a87ea49945037e1a1a13L345' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 20821181</div><div id='project'> Project Name: pytorchlightning/metrics</div><div id='commit'> Commit Name: c2f55fa5f84bf1549a26bdab67d572503f06e18f</div><div id='time'> Time: 2022-06-13</div><div id='author'> Author: skaftenicki@gmail.com</div><div id='file'> File Name: test/unittests/bases/test_collections.py</div><div id='m_class'> M Class Name: TestComputeGroups</div><div id='n_method'> N Class Name: TestComputeGroups</div><div id='m_method'> M Method Name: test_check_compute_groups_correctness(7)</div><div id='n_method'> N Method Name: test_check_compute_groups_correctness(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: test/unittests/bases/test_collections.py</div><div id='n_file'> N File Name: test/unittests/bases/test_collections.py</div><div id='m_start'> M Start Line: 345</div><div id='m_end'> M End Line: 357</div><div id='n_start'> N Start Line: 378</div><div id='n_end'> N End Line: 382</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        assert m2.compute_groups == {}

        for _ in range(2):  &#47&#47 repeat to emulate effect of multiple epochs
            preds<a id="change"> = </a><a id="change">torch.randn(</a>10, 3<a id="change">)</a>.softmax(dim=-1)
            target = torch.randint(3, (10,))
            m.update(preds, target)
            m2.update(preds, target)

            for _, member in m.items():
                assert member._update_called

            assert m.compute_groups == expected
            assert m2.compute_groups == {}

            preds<a id="change"> = </a><a id="change">torch.randn(</a>10, 3<a id="change">)</a>.softmax(dim=-1)
            target = torch.randint(3, (10,))
            &#47&#47 compute groups should kick in here
            m.update(preds, target)</code></pre><h3>After Change</h3><pre><code class='java'>
    )
    def test_check_compute_groups_correctness(self, metrics, expected, preds, target, prefix, postfix):
        Check that compute groups are formed after initialization and that metrics are correctly computed.
        <a id="change">if </a><a id="change">isinstance(</a>metrics, MetricCollection<a id="change">)</a>:
            prefix, postfix = None, None  &#47&#47 disable for nested collections
        m = MetricCollection(deepcopy(metrics), prefix=prefix, postfix=postfix, compute_groups=True)
        &#47&#47 Construct without for comparison</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorchlightning/metrics/commit/c2f55fa5f84bf1549a26bdab67d572503f06e18f#diff-330cbceebe6b405322f6b6da58eec20c9b26152524d2a87ea49945037e1a1a13L335' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 20821180</div><div id='project'> Project Name: pytorchlightning/metrics</div><div id='commit'> Commit Name: c2f55fa5f84bf1549a26bdab67d572503f06e18f</div><div id='time'> Time: 2022-06-13</div><div id='author'> Author: skaftenicki@gmail.com</div><div id='file'> File Name: test/unittests/bases/test_collections.py</div><div id='m_class'> M Class Name: TestComputeGroups</div><div id='n_method'> N Class Name: TestComputeGroups</div><div id='m_method'> M Method Name: test_check_compute_groups_correctness(7)</div><div id='n_method'> N Method Name: test_check_compute_groups_correctness(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: test/unittests/bases/test_collections.py</div><div id='n_file'> N File Name: test/unittests/bases/test_collections.py</div><div id='m_start'> M Start Line: 345</div><div id='m_end'> M End Line: 357</div><div id='n_start'> N Start Line: 378</div><div id='n_end'> N End Line: 382</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            if latents is None:
                if device.type == "mps":
                    &#47&#47 randn does not work reproducibly on mps
                    latents<a id="change"> = </a><a id="change">torch.randn(</a>shape<a id="change">, generator=generator, device="cpu", dtype=dtype)</a>.to(device)
                else:
                    latents = torch.randn(shape, generator=generator, device=device, dtype=dtype)
            else:
                if latents.shape != shape:
                    raise ValueError(f"Unexpected latents shape, got {latents.shape}, expected {shape}")
                latents = latents.to(device)

            &#47&#47 scale the initial noise by the standard deviation required by the scheduler
            latents = latents * self.scheduler.init_noise_sigma
            return latents, None, None
        else:
            init_latent_dist = self.vae.encode(image).latent_dist
            init_latents = init_latent_dist.sample(generator=generator)
            init_latents = 0.18215 * init_latents
            init_latents = torch.cat([init_latents] * batch_size, dim=0)
            init_latents_orig = init_latents
            shape = init_latents.shape

            &#47&#47 add noise to latents using the timesteps
            if device.type == "mps":
                noise<a id="change"> = </a><a id="change">torch.randn(</a>shape<a id="change">, generator=generator, device="cpu", dtype=dtype)</a>.to(device)
            else:
                noise = torch.randn(shape, generator=generator, device=device, dtype=dtype)
            latents = self.scheduler.add_noise(init_latents, noise, timestep)</code></pre><h3>After Change</h3><pre><code class='java'>
        if image is None:
            batch_size = batch_size * num_images_per_prompt
            shape = (batch_size, num_channels_latents, height // self.vae_scale_factor, width // self.vae_scale_factor)
            <a id="change">if </a><a id="change">isinstance(</a>generator, list<a id="change">)</a> and len(generator) != batch_size:
                raise ValueError(
                    f"You have passed a list of generators of length {len(generator)}, but requested an effective batch"
                    f" size of {batch_size}. Make sure the batch size matches the length of the generators."</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/2ced899cc7cff5c37f2186819c90538ce301908c#diff-137485cb3293be40e8fbae3f413853388988a06e9c6c73352686946677ad2eb3L626' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 20821183</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: 2ced899cc7cff5c37f2186819c90538ce301908c</div><div id='time'> Time: 2023-04-27</div><div id='author'> Author: patrick.v.platen@gmail.com</div><div id='file'> File Name: examples/community/lpw_stable_diffusion.py</div><div id='m_class'> M Class Name: StableDiffusionLongPromptWeightingPipeline</div><div id='n_method'> N Class Name: StableDiffusionLongPromptWeightingPipeline</div><div id='m_method'> M Method Name: prepare_latents(12)</div><div id='n_method'> N Method Name: prepare_latents(10)</div><div id='m_parent_class'> M Parent Class: DiffusionPipeline,TextualInversionLoaderMixin,FromCkptMixin,LoraLoaderMixin</div><div id='n_parent_class'> N Parent Class: StableDiffusionPipeline</div><div id='m_file'> M File Name: examples/community/lpw_stable_diffusion.py</div><div id='n_file'> N File Name: examples/community/lpw_stable_diffusion.py</div><div id='m_start'> M Start Line: 628</div><div id='m_end'> M End Line: 662</div><div id='n_start'> N Start Line: 822</div><div id='n_end'> N End Line: 862</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            if latents is None:
                if device.type == "mps":
                    &#47&#47 randn does not work reproducibly on mps
                    latents<a id="change"> = </a><a id="change">torch.randn(</a>shape<a id="change">, generator=generator, device="cpu", dtype=dtype)</a>.to(device)
                else:
                    latents = torch.randn(shape, generator=generator, device=device, dtype=dtype)
            else:
                if latents.shape != shape:
                    raise ValueError(f"Unexpected latents shape, got {latents.shape}, expected {shape}")
                latents = latents.to(device)

            &#47&#47 scale the initial noise by the standard deviation required by the scheduler
            latents = latents * self.scheduler.init_noise_sigma
            return latents, None, None
        else:
            init_latent_dist = self.vae.encode(image).latent_dist
            init_latents = init_latent_dist.sample(generator=generator)
            init_latents = 0.18215 * init_latents
            init_latents = torch.cat([init_latents] * batch_size, dim=0)
            init_latents_orig = init_latents
            shape = init_latents.shape

            &#47&#47 add noise to latents using the timesteps
            if device.type == "mps":
                noise<a id="change"> = </a><a id="change">torch.randn(</a>shape<a id="change">, generator=generator, device="cpu", dtype=dtype)</a>.to(device)
            else:
                noise = torch.randn(shape, generator=generator, device=device, dtype=dtype)
            latents = self.scheduler.add_noise(init_latents, noise, timestep)</code></pre><h3>After Change</h3><pre><code class='java'>
        if image is None:
            batch_size = batch_size * num_images_per_prompt
            shape = (batch_size, num_channels_latents, height // self.vae_scale_factor, width // self.vae_scale_factor)
            <a id="change">if </a><a id="change">isinstance(</a>generator, list<a id="change">)</a> and len(generator) != batch_size:
                raise ValueError(
                    f"You have passed a list of generators of length {len(generator)}, but requested an effective batch"
                    f" size of {batch_size}. Make sure the batch size matches the length of the generators."</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/9965cb50eac12e397473f01535aab43aae76b4ab#diff-137485cb3293be40e8fbae3f413853388988a06e9c6c73352686946677ad2eb3L626' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 20821182</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: 9965cb50eac12e397473f01535aab43aae76b4ab</div><div id='time'> Time: 2023-04-22</div><div id='author'> Author: SKYTNT@outlook.com</div><div id='file'> File Name: examples/community/lpw_stable_diffusion.py</div><div id='m_class'> M Class Name: StableDiffusionLongPromptWeightingPipeline</div><div id='n_method'> N Class Name: StableDiffusionLongPromptWeightingPipeline</div><div id='m_method'> M Method Name: prepare_latents(12)</div><div id='n_method'> N Method Name: prepare_latents(10)</div><div id='m_parent_class'> M Parent Class: DiffusionPipeline,TextualInversionLoaderMixin,FromCkptMixin,LoraLoaderMixin</div><div id='n_parent_class'> N Parent Class: StableDiffusionPipeline</div><div id='m_file'> M File Name: examples/community/lpw_stable_diffusion.py</div><div id='n_file'> N File Name: examples/community/lpw_stable_diffusion.py</div><div id='m_start'> M Start Line: 628</div><div id='m_end'> M End Line: 662</div><div id='n_start'> N Start Line: 822</div><div id='n_end'> N End Line: 862</div><BR>