<html><h3>Pattern ID :17046
</h3><img src='57191691.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47in-batch negative sample
        &#47&#47!! TODO: use mask matrix. It&quots slow now.
        batch_size<a id="change"> = </a><a id="change">y.size(0</a><a id="change">)</a>
        scores<a id="change"> = </a>torch.ones(batch_size, 1 + self.n_neg, device=y.device)  &#47&#47positive sample in the first position.
        y_expand = torch.cat((y, y))
        for i in range(batch_size):
            scores[i, :] = torch.cat((y_expand[i].view(-1), y_expand[i + 1:i + 1 + self.n_neg]))</code></pre><h3>After Change</h3><pre><code class='java'>

        scores = pred - torch.log(sample_weight)  &#47&#47Sampling Bias Corrected, using broadcast
        if user_embedding.shape[0] * (self.n_neg + 1) != self.index0.shape[0]:  &#47&#47 last batch
            batch_size<a id="change"> = </a><a id="change">user_embedding.shape[0]</a>
            index0 = self.index0[:batch_size * (self.n_neg + 1)]
            index1 = self.index1[:batch_size * (self.n_neg + 1)]
            index0[np.where(index0 &gt;= batch_size)] -= batch_size
            index1[np.where(index1 &gt;= batch_size)] -= batch_size</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/datawhalechina/torch-rechub/commit/d0461152ddffad7a6bf7c7532b7b540094623e95#diff-16cab9e6b17798cf716613c6493b3a5a50aea041bdf0c65f5c89b59a4d0c686aL55' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 57191691</div><div id='project'> Project Name: datawhalechina/torch-rechub</div><div id='commit'> Commit Name: d0461152ddffad7a6bf7c7532b7b540094623e95</div><div id='time'> Time: 2022-06-07</div><div id='author'> Author: icewwl@163.com</div><div id='file'> File Name: torch_rechub/models/matching/youtube_sbc.py</div><div id='m_class'> M Class Name: YoutubeSBC</div><div id='n_method'> N Class Name: YoutubeSBC</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: torch_rechub/models/matching/youtube_sbc.py</div><div id='n_file'> N File Name: torch_rechub/models/matching/youtube_sbc.py</div><div id='m_start'> M Start Line: 55</div><div id='m_end'> M End Line: 80</div><div id='n_start'> N Start Line: 60</div><div id='n_end'> N End Line: 87</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 them together.
        if not mems: mems = self.init_mems()

        tgt_len<a id="change"> = </a><a id="change">target.size(0</a><a id="change">)</a>
        hidden, new_mems = self._forward(data, mems=mems)

        pred_hid<a id="change"> = </a>hidden[-tgt_len:]

    parser = argparse.ArgumentParser(description=&quotunit test&quot)
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47       happening. We can instead just take the hidden output and push it to the
        &#47&#47       2 MLP which are learning the policy
        &#47&#47 pred_hid = hidden[-tgt_len:]
        pred_hid<a id="change"> = </a><a id="change">hidden[-1]</a>
        &#47&#47 TODO : Check if this should be -1 or the entire hidden itself?

        &#47&#47 TODO : Jerrod : NEED TO CHANGE THIS (ADD MLP that maps to correct &#47&#47 actions
        &#47&#47 TODO : Shakti : I dont think so since this output will be succeeded by 2 MLPs in</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jerrodparker20/adaptive-transformers-in-rl/commit/333fad51ae6344cec5ac341e6f304f40fcb028f5#diff-fa6bc1f27fcb2650947162d654bbfa0b14260f02704743b3aad6d8b62878e3d4L457' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 57191676</div><div id='project'> Project Name: jerrodparker20/adaptive-transformers-in-rl</div><div id='commit'> Commit Name: 333fad51ae6344cec5ac341e6f304f40fcb028f5</div><div id='time'> Time: 2020-03-11</div><div id='author'> Author: shakti.shrivastava13@gmail.com</div><div id='file'> File Name: StableTransformersReplication/transformer_xl.py</div><div id='m_class'> M Class Name: MemTransformerLM</div><div id='n_method'> N Class Name: MemTransformerLM</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: StableTransformersReplication/transformer_xl.py</div><div id='n_file'> N File Name: StableTransformersReplication/transformer_xl.py</div><div id='m_start'> M Start Line: 464</div><div id='m_end'> M End Line: 467</div><div id='n_start'> N Start Line: 485</div><div id='n_end'> N End Line: 493</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.fc = nn.Linear(out_channels + num_layers * hidden_size, 1)

    def forward(self, x):
        batch_size<a id="change"> = </a><a id="change">x.size(0</a><a id="change">)</a>
        embedding = self.dropout(self.embed(x))
        conv_in = embedding.permute(0, 2, 1)
        conv_out = self.conv(conv_in)
        values, indices = conv_out.max(dim=-1)
        conv_out = conv_out.permute(2, 0, 1)
        try:
            _, (hidden, _) = self.rnn(conv_out)
        except ValueError:
            _, hidden = self.rnn(conv_out)
        hidden<a id="change"> = </a>hidden.reshape(batch_size, -1)
        fc_in = torch.cat((hidden, values), dim=-1)
        output = self.fc(fc_in).squeeze(1)
        return output</code></pre><h3>After Change</h3><pre><code class='java'>
        values, indices = conv_out.max(dim=-1)
        conv_out = conv_out.permute(2, 0, 1)
        rnn_out, _ = self.rnn(conv_out)
        hidden<a id="change"> = </a><a id="change">rnn_out[-1]</a>
        fc_in = torch.cat((hidden, values), dim=-1)
        output = self.fc(fc_in).squeeze(1)
        return output
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jaketae/deep-malware-detection/commit/f47900498ab32b4bde599d548ad57290443f0a8b#diff-dcfeaa5ac3dffd54264034760914588d92fc7395c81eaa9274715840dc28100bL136' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 57191677</div><div id='project'> Project Name: jaketae/deep-malware-detection</div><div id='commit'> Commit Name: f47900498ab32b4bde599d548ad57290443f0a8b</div><div id='time'> Time: 2020-11-27</div><div id='author'> Author: jaesungtae@gmail.com</div><div id='file'> File Name: models.py</div><div id='m_class'> M Class Name: ResRCNN</div><div id='n_method'> N Class Name: ResRCNN</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models.py</div><div id='n_file'> N File Name: models.py</div><div id='m_start'> M Start Line: 137</div><div id='m_end'> M End Line: 147</div><div id='n_start'> N Start Line: 142</div><div id='n_end'> N End Line: 143</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.fc = nn.Linear(num_layers * hidden_size, 1)

    def forward(self, x):
        batch_size<a id="change"> = </a><a id="change">x.size(0</a><a id="change">)</a>
        embedding = self.dropout(self.embed(x))
        conv_in = embedding.permute(0, 2, 1)
        conv_out = self.conv(conv_in)
        conv_out = conv_out.permute(2, 0, 1)
        try:
            _, (hidden, _) = self.rnn(conv_out)
        except ValueError:
            _, hidden = self.rnn(conv_out)
        hidden<a id="change"> = </a>hidden.reshape(batch_size, -1)
        output = self.fc(hidden).squeeze(1)
        return output
</code></pre><h3>After Change</h3><pre><code class='java'>
        conv_out = self.conv(conv_in)
        conv_out = conv_out.permute(2, 0, 1)
        rnn_out, _ = self.rnn(conv_out)
        hidden<a id="change"> = </a><a id="change">rnn_out[-1]</a>
        output = self.fc(hidden).squeeze(1)
        return output

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jaketae/deep-malware-detection/commit/f47900498ab32b4bde599d548ad57290443f0a8b#diff-dcfeaa5ac3dffd54264034760914588d92fc7395c81eaa9274715840dc28100bL91' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 57191679</div><div id='project'> Project Name: jaketae/deep-malware-detection</div><div id='commit'> Commit Name: f47900498ab32b4bde599d548ad57290443f0a8b</div><div id='time'> Time: 2020-11-27</div><div id='author'> Author: jaesungtae@gmail.com</div><div id='file'> File Name: models.py</div><div id='m_class'> M Class Name: RCNN</div><div id='n_method'> N Class Name: RCNN</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models.py</div><div id='n_file'> N File Name: models.py</div><div id='m_start'> M Start Line: 92</div><div id='m_end'> M End Line: 101</div><div id='n_start'> N Start Line: 96</div><div id='n_end'> N End Line: 97</div><BR>