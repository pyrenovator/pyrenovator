<html><h3>Pattern ID :4918
</h3><img src='17273710.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def _crop(prediction, target, mask, channel_dim):
        mask = mask.type(torch.bool)
        pred = []
        <a id="change">trgt</a> = <a id="change">[]</a>
        n_channels = prediction.shape[channel_dim]
        &#47&#47 for now only support same mask for all channels
        &#47&#47 to be able to stack/concat afterwards
        &#47&#47 TODO: make this more efficient, and for different
        &#47&#47 masks per channel
        assert mask.shape[channel_dim] == 1
        <a id="change">for </a>c in range(n_channels)<a id="change">:
            </a>p = torch.index_select(prediction, channel_dim, torch.LongTensor([c]))
            t = torch.index_select(target, channel_dim, torch.LongTensor([c]))
            pred.append(p[mask])
            <a id="change">trgt.append(</a>t[mask]<a id="change">)</a>
        &#47&#47 transpose to have N x C
        &#47&#47 needed in torch_em.loss.dice.flatten_samples
        pred = torch.stack(pred).transpose(0, 1)
        trgt = <a id="change">torch.stack(trgt</a><a id="change">)</a>.transpose(0, 1)
        return pred, trgt

    def _multiply(prediction, target, mask, channel_dim):</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 masks per channel
        assert mask.shape[channel_dim] == 1
        &#47&#47 remove singleton axis
        mask = <a id="change">mask.squeeze()</a>
        &#47&#47 move channel axis to end
        prediction = prediction.moveaxis(channel_dim, -1)
        target = target.moveaxis(channel_dim, -1)
        &#47&#47 output has shape N x C</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/constantinpape/torch-em/commit/6a9fecb01af03bfbe5971bc1fd29c1bc06e9c455#diff-61ea7c66723637b374b24d895d6c2d6a2763d6b6d1bba5c85dfff871838b8d00L48' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17273710</div><div id='project'> Project Name: constantinpape/torch-em</div><div id='commit'> Commit Name: 6a9fecb01af03bfbe5971bc1fd29c1bc06e9c455</div><div id='time'> Time: 2022-12-09</div><div id='author'> Author: jonas.hellgoth@gmx.de</div><div id='file'> File Name: torch_em/loss/wrapper.py</div><div id='m_class'> M Class Name: ApplyMask</div><div id='n_method'> N Class Name: ApplyMask</div><div id='m_method'> M Method Name: _crop(4)</div><div id='n_method'> N Method Name: _crop(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torch_em/loss/wrapper.py</div><div id='n_file'> N File Name: torch_em/loss/wrapper.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 66</div><div id='n_start'> N Start Line: 48</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        mo = self.ao2mo(ao)
        bgrad = self.get_grad_operator(x, ao, grad_ao, mo)
        print(bgrad.shape)
        <a id="change">out</a> = <a id="change">[]</a>
        <a id="change">for ig</a> in range(3)<a id="change">:
            </a>grads = self.pool.kinetic(mo, bgrad[..., ig])
            print(grads.shape)
            psi = self.pool(mo)
            print(psi.shape)
            aa = self.fc(grads * psi) / self.fc(psi)
            print(aa.shape)
            <a id="change">out.append(</a>aa<a id="change">)</a>
        return <a id="change">torch.stack(</a>out<a id="change">)</a>

    def get_grad_operator(self, x, ao, grad_ao, mo):
        Compute the gradient operator
</code></pre><h3>After Change</h3><pre><code class='java'>
        psi = self.pool(mo)
        out = self.fc(grads * psi) / self.fc(psi)

        return <a id="change">out.transpose(0, 1).squeeze()</a>

    def get_grad_operator(self, x, ao, grad_ao, mo):
        Compute the gradient operator
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nlesc-jcer/qmctorch/commit/768d611456931e6ab5349bbe77fa45f2dcd415fd#diff-45e01a4679a00946fdb660a1d038f367c96bedd8aa2dce3bbeb916e2b806045dL306' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17273709</div><div id='project'> Project Name: nlesc-jcer/qmctorch</div><div id='commit'> Commit Name: 768d611456931e6ab5349bbe77fa45f2dcd415fd</div><div id='time'> Time: 2020-08-18</div><div id='author'> Author: nicolas.gm.renaud@gmail.com</div><div id='file'> File Name: qmctorch/wavefunction/wf_orbital.py</div><div id='m_class'> M Class Name: Orbital</div><div id='n_method'> N Class Name: Orbital</div><div id='m_method'> M Method Name: gradient_jacobi(2)</div><div id='n_method'> N Method Name: gradient_jacobi(2)</div><div id='m_parent_class'> M Parent Class: WaveFunction</div><div id='n_parent_class'> N Parent Class: WaveFunction</div><div id='m_file'> M File Name: qmctorch/wavefunction/wf_orbital.py</div><div id='n_file'> N File Name: qmctorch/wavefunction/wf_orbital.py</div><div id='m_start'> M Start Line: 323</div><div id='m_end'> M End Line: 334</div><div id='n_start'> N Start Line: 323</div><div id='n_end'> N End Line: 330</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
class ApplyMask:
    def _crop(prediction, target, mask, channel_dim):
        mask = mask.type(torch.bool)
        <a id="change">pred</a> = <a id="change">[]</a>
        trgt = []
        n_channels = prediction.shape[channel_dim]
        &#47&#47 for now only support same mask for all channels
        &#47&#47 to be able to stack/concat afterwards
        &#47&#47 TODO: make this more efficient, and for different
        &#47&#47 masks per channel
        assert mask.shape[channel_dim] == 1
        <a id="change">for c</a> in range(n_channels)<a id="change">:
            </a>p = torch.index_select(prediction, channel_dim, torch.LongTensor([c]))
            t = torch.index_select(target, channel_dim, torch.LongTensor([c]))
            <a id="change">pred.append(</a>p[mask]<a id="change">)</a>
            trgt.append(t[mask])
        &#47&#47 transpose to have N x C
        &#47&#47 needed in torch_em.loss.dice.flatten_samples
        pred = <a id="change">torch.stack(</a>pred<a id="change">)</a>.transpose(0, 1)
        trgt = torch.stack(trgt).transpose(0, 1)
        return pred, trgt
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 masks per channel
        assert mask.shape[channel_dim] == 1
        &#47&#47 remove singleton axis
        mask = <a id="change">mask.squeeze()</a>
        &#47&#47 move channel axis to end
        prediction = prediction.moveaxis(channel_dim, -1)
        target = target.moveaxis(channel_dim, -1)
        &#47&#47 output has shape N x C</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/constantinpape/torch-em/commit/6a9fecb01af03bfbe5971bc1fd29c1bc06e9c455#diff-61ea7c66723637b374b24d895d6c2d6a2763d6b6d1bba5c85dfff871838b8d00L47' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17273708</div><div id='project'> Project Name: constantinpape/torch-em</div><div id='commit'> Commit Name: 6a9fecb01af03bfbe5971bc1fd29c1bc06e9c455</div><div id='time'> Time: 2022-12-09</div><div id='author'> Author: jonas.hellgoth@gmx.de</div><div id='file'> File Name: torch_em/loss/wrapper.py</div><div id='m_class'> M Class Name: ApplyMask</div><div id='n_method'> N Class Name: ApplyMask</div><div id='m_method'> M Method Name: _crop(4)</div><div id='n_method'> N Method Name: _crop(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torch_em/loss/wrapper.py</div><div id='n_file'> N File Name: torch_em/loss/wrapper.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 66</div><div id='n_start'> N Start Line: 48</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        x = q + self.num_q * r
        Mvt = self.Mv.unsqueeze(0)

        <a id="change">p</a> = <a id="change">[]</a>
        Mv = []

        <a id="change">for </a>qt, <a id="change">xt</a> in zip(q.permute(1, 0), x.permute(1, 0))<a id="change">:
            </a>kt = self.k_emb_layer(qt)
            vt = self.v_emb_layer(xt)

            wt = torch.softmax(torch.matmul(kt, self.Mk), dim=-1)

            &#47&#47 Read Process
            rt = (wt.unsqueeze(-1) * Mvt).sum(1)
            ft = torch.tanh(self.f_layer(torch.cat([rt, kt], dim=-1)))
            pt = torch.sigmoid(self.p_layer(ft)).squeeze()

            &#47&#47 Write Process
            et = torch.sigmoid(self.e_layer(vt))
            Mvt = Mvt * (1 - (wt.unsqueeze(-1) * et.unsqueeze(1)))
            at = torch.tanh(self.a_layer(vt))
            Mvt = Mvt + (wt.unsqueeze(-1) * at.unsqueeze(1))

            <a id="change">p.append(</a>pt<a id="change">)</a>
            Mv.append(Mvt)

        p = <a id="change">torch.stack(</a>p<a id="change">, dim=1)</a>
        Mv = torch.stack(Mv, dim=1)

        return p, Mv
</code></pre><h3>After Change</h3><pre><code class='java'>
                )
            )
        )
        p = <a id="change">torch.sigmoid(self.p_layer(f)).squeeze()</a>

        return p, Mv

    def train_model(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hcnoh/knowledge-tracing-collection-pytorch/commit/c42b01b83dbe54e94f4294009fbfe8bd910e3638#diff-f2ab9795149528e0325dcc207d9bb2ee66e3cdd4dff09817a550ab5174cc8763L39' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17273707</div><div id='project'> Project Name: hcnoh/knowledge-tracing-collection-pytorch</div><div id='commit'> Commit Name: c42b01b83dbe54e94f4294009fbfe8bd910e3638</div><div id='time'> Time: 2021-10-06</div><div id='author'> Author: rhc0624@gmail.com</div><div id='file'> File Name: models/dkvmn.py</div><div id='m_class'> M Class Name: DKVMN</div><div id='n_method'> N Class Name: DKVMN</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: Module</div><div id='n_parent_class'> N Parent Class: Module</div><div id='m_file'> M File Name: models/dkvmn.py</div><div id='n_file'> N File Name: models/dkvmn.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 66</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 87</div><BR>