<html><h3>Pattern ID :31955
</h3><img src='93425937.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Extract Y channel hr image data.
        hr_image = np.array(hr_image).astype(np.float32)
        hr_ycbcr = imgproc.convert_rgb_to_ycbcr(hr_image)
        hr_image_y<a id="change"> = </a>hr_ycbcr[..., 0]
        hr_image_y<a id="change"> /= </a>255.
        hr_tensor_y = torch.from_numpy(hr_image_y).to(config.device).unsqueeze(0).unsqueeze(0)
        hr_tensor_y<a id="change"> = </a><a id="change">hr_tensor_y.half()</a>

        &#47&#47 Only reconstruct the Y channel image data.
        with torch.no_grad():
            sr_tensor_y = model(lr_tensor_y).clamp_(0.0, 1.0)</code></pre><h3>After Change</h3><pre><code class='java'>
        print(f"Processing `{os.path.abspath(hr_image_path)}`...")
        &#47&#47 Make low-resolution images.
        image = Image.open(hr_image_path).convert("RGB")
        image_width = (image.width // config.upscale_factor)<a id="change"> * </a>config.upscale_factor
        image_height = (image.height // config.upscale_factor)<a id="change"> * </a>config.upscale_factor
        image = image.resize(<a id="change">[</a>image_width, image_height<a id="change"></a>], Image.BICUBIC)
        image = image.resize([image.width // config.upscale_factor, image.height // config.upscale_factor], Image.BICUBIC)
        image = image.resize([image.width * config.upscale_factor, image.height * config.upscale_factor], Image.BICUBIC)
        &#47&#47 Extract Y channel image data.</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lornatang/vdsr-pytorch/commit/a74f59d38f5d880febe1040548b5865af385e8db#diff-58b7fc05c0526d9a9b3c0b50dda416fcbf0a654e696da4b6df82cbb5a6b2dcfcL53' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 93425937</div><div id='project'> Project Name: lornatang/vdsr-pytorch</div><div id='commit'> Commit Name: a74f59d38f5d880febe1040548b5865af385e8db</div><div id='time'> Time: 2021-11-17</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: validate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: validate.py</div><div id='n_file'> N File Name: validate.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 63</div><div id='n_end'> N End Line: 84</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Extract Y channel lr image data.
        lr_image = np.array(lr_image).astype(np.float32)
        lr_ycbcr = imgproc.convert_rgb_to_ycbcr(lr_image)
        lr_image_y<a id="change"> = </a>lr_ycbcr[..., 0]
        lr_image_y<a id="change"> /= </a>255.
        lr_tensor_y = torch.from_numpy(lr_image_y).to(config.device).unsqueeze(0).unsqueeze(0)
        lr_tensor_y<a id="change"> = </a><a id="change">lr_tensor_y.half()</a>

        &#47&#47 Extract Y channel bicubic image data.
        bic_image = np.array(bic_image).astype(np.float32)
        bic_ycbcr = imgproc.convert_rgb_to_ycbcr(bic_image)</code></pre><h3>After Change</h3><pre><code class='java'>

        print(f"Processing `{os.path.abspath(hr_image_path)}`...")
        lr_image = Image.open(lr_image_path).convert("RGB")
        bic_image = lr_image.resize(<a id="change">[</a>int(lr_image.width<a id="change"> * </a>config.upscale_factor), int(lr_image.height<a id="change"> * </a>config.upscale_factor)<a id="change"></a>], Image.BICUBIC)
        hr_image = Image.open(hr_image_path).convert("RGB")

        &#47&#47 Extract Y channel lr image data</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/espcn-pytorch/commit/3d7da32ace2da2b908bad2a32243b464f206e72a#diff-58b7fc05c0526d9a9b3c0b50dda416fcbf0a654e696da4b6df82cbb5a6b2dcfcL27' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 93425921</div><div id='project'> Project Name: lornatang/espcn-pytorch</div><div id='commit'> Commit Name: 3d7da32ace2da2b908bad2a32243b464f206e72a</div><div id='time'> Time: 2021-11-30</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: validate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: validate.py</div><div id='n_file'> N File Name: validate.py</div><div id='m_start'> M Start Line: 65</div><div id='m_end'> M End Line: 95</div><div id='n_start'> N Start Line: 63</div><div id='n_end'> N End Line: 88</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    total_files = len(file_names)

    for index in range(total_files):
        lr_image_path<a id="change"> = </a>os.path.join(config.lr_dir, file_names[index])
        sr_image_path = os.path.join(config.sr_dir, file_names[index])
        hr_image_path = os.path.join(config.hr_dir, file_names[index])

        print(f"Processing `{os.path.abspath(hr_image_path)}`...")
        &#47&#47 Make low-resolution images.
        lr_image = Image.open(lr_image_path).convert("RGB")
        hr_image = Image.open(hr_image_path).convert("RGB")
        bic_image = lr_image.resize([hr_image.width, hr_image.height], Image.BICUBIC)

        &#47&#47 Extract Y channel lr image data.
        lr_image = np.array(lr_image).astype(np.float32)
        lr_ycbcr = imgproc.convert_rgb_to_ycbcr(lr_image)
        lr_image_y = lr_ycbcr[..., 0]
        lr_image_y<a id="change"> /= </a>255.
        lr_tensor_y = torch.from_numpy(lr_image_y).to(config.device).unsqueeze(0).unsqueeze(0)
        lr_tensor_y<a id="change"> = </a><a id="change">lr_tensor_y.half()</a>

        &#47&#47 Extract Y channel bicubic image data.
        bic_image = np.array(bic_image).astype(np.float32)
        bic_ycbcr = imgproc.convert_rgb_to_ycbcr(bic_image)</code></pre><h3>After Change</h3><pre><code class='java'>
        hr_image_height = hr_image.height // config.upscale_factor * config.upscale_factor
        hr_image = hr_image.resize([hr_image_width, hr_image_height], Image.BICUBIC)

        lr_image = hr_image.resize(<a id="change">[</a>hr_image.width<a id="change"> // </a>config.upscale_factor, hr_image.height<a id="change"> // </a>config.upscale_factor<a id="change"></a>], Image.BICUBIC)
        bic_image = lr_image.resize([hr_image.width, hr_image.height], Image.BICUBIC)

        &#47&#47 Extract Y channel lr image data.</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/fsrcnn-pytorch/commit/5a0ecdd432cc264e98e446689348e5565a84ac1f#diff-58b7fc05c0526d9a9b3c0b50dda416fcbf0a654e696da4b6df82cbb5a6b2dcfcL27' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 93425812</div><div id='project'> Project Name: lornatang/fsrcnn-pytorch</div><div id='commit'> Commit Name: 5a0ecdd432cc264e98e446689348e5565a84ac1f</div><div id='time'> Time: 2021-11-19</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: validate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: validate.py</div><div id='n_file'> N File Name: validate.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 95</div><div id='n_start'> N Start Line: 63</div><div id='n_end'> N End Line: 98</div><BR>