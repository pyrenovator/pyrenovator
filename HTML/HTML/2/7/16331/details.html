<html><h3>Pattern ID :16331
</h3><img src='54783747.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        venv_chans_first = make_vec_env(gym_env_name_chans_first,
                                        n_envs=1,
                                        parallel=False)
    elif <a id="change">benchmark[&quotbenchmark_name&quot] == &quotdm_control&quot</a>:
        gym_env_name_chans_first<a id="change">, dataset_dict = </a>load_dataset_dm_control()
        venv_chans_first = make_vec_env(gym_env_name_chans_first,
                                        n_envs=1,
                                        parallel=False)
    elif benchmark[&quotbenchmark_name&quot] == &quotatari&quot:
        dataset_dict = load_dataset_atari()
        gym_env_name_chans_last<a id="change"> = </a>benchmark[&quotatari_env_id&quot]
        venv_nhwc = VecFrameStack(make_atari_env(gym_env_name_chans_last), 4)
        venv_chans_first<a id="change"> = </a>VecTransposeImage(venv_nhwc)
    else:
        raise NotImplementedError(
            f"this code does not yet support "</code></pre><h3>After Change</h3><pre><code class='java'>
    log_dir = il_train_ex.observers[0].dir
    imitation_logger.configure(log_dir, ["stdout", "tensorboard"])

    venv<a id="change"> = </a>auto_env.load_vec_env()
    dataset_dict = auto_env.load_dataset()
    dataset = TransitionsMinimalDataset(dataset_dict)

    if encoder_path:
        logging.info(f"Loading pretrained encoder from &quot{encoder_path}&quot")
        encoder = th.load(encoder_path)
    else:
        logging.info(f"No encoder provided, will init from scratch")
        encoder = None

    logging.info(f"Setting up &quot{algo}&quot IL algorithm")

    if algo == &quotbc&quot:
        do_training_bc(dataset=dataset,
                       venv_chans_first=venv,
                       out_dir=log_dir,
                       encoder=encoder)

    elif algo == &quotgail&quot:
        do_training_gail(dataset=dataset,
                         venv_chans_first=venv,
                         encoder=encoder)

    else:
        raise NotImplementedError(f"Can&quott handle algorithm &quot{algo}&quot")

    &#47&#47 FIXME(sam): make sure this always closes correctly, even when there&quots an
    &#47&#47 exception after creating it (could use try/catch or a context manager)
    <a id="change">venv.close()</a>

    return log_dir

</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/e27cbb99e7f7a03a80d5ff8063b3071bf534edda#diff-b8a30b79d4b477ae4ff3f89cb23e1e0d8475a5ef44d82945f1ab0d152531016cL158' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 54783747</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: e27cbb99e7f7a03a80d5ff8063b3071bf534edda</div><div id='time'> Time: 2020-08-13</div><div id='author'> Author: sam@qxcv.net</div><div id='file'> File Name: src/il_representations/scripts/il_train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(5)</div><div id='n_method'> N Method Name: train(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/il_representations/scripts/il_train.py</div><div id='n_file'> N File Name: src/il_representations/scripts/il_train.py</div><div id='m_start'> M Start Line: 164</div><div id='m_end'> M End Line: 211</div><div id='n_start'> N Start Line: 158</div><div id='n_end'> N End Line: 187</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        venv_chans_first = make_vec_env(gym_env_name_chans_first,
                                        n_envs=1,
                                        parallel=False)
    elif <a id="change">benchmark[&quotbenchmark_name&quot] == &quotatari&quot</a>:
        dataset_dict<a id="change"> = </a>load_dataset_atari()
        gym_env_name_chans_last<a id="change"> = </a>benchmark[&quotatari_env_id&quot]
        venv_nhwc<a id="change"> = </a>VecFrameStack(make_atari_env(gym_env_name_chans_last), 4)
        venv_chans_first = VecTransposeImage(venv_nhwc)
    else:
        raise NotImplementedError(</code></pre><h3>After Change</h3><pre><code class='java'>
    log_dir = il_train_ex.observers[0].dir
    imitation_logger.configure(log_dir, ["stdout", "tensorboard"])

    venv<a id="change"> = </a>auto_env.load_vec_env()
    dataset_dict = auto_env.load_dataset()
    dataset = TransitionsMinimalDataset(dataset_dict)

    if encoder_path:
        logging.info(f"Loading pretrained encoder from &quot{encoder_path}&quot")
        encoder = th.load(encoder_path)
    else:
        logging.info(f"No encoder provided, will init from scratch")
        encoder = None

    logging.info(f"Setting up &quot{algo}&quot IL algorithm")

    if algo == &quotbc&quot:
        do_training_bc(dataset=dataset,
                       venv_chans_first=venv,
                       out_dir=log_dir,
                       encoder=encoder)

    elif algo == &quotgail&quot:
        do_training_gail(dataset=dataset,
                         venv_chans_first=venv,
                         encoder=encoder)

    else:
        raise NotImplementedError(f"Can&quott handle algorithm &quot{algo}&quot")

    &#47&#47 FIXME(sam): make sure this always closes correctly, even when there&quots an
    &#47&#47 exception after creating it (could use try/catch or a context manager)
    <a id="change">venv.close()</a>

    return log_dir

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/4f43a9030853ed574d23f2e86f5253fc4ccd11de#diff-b8a30b79d4b477ae4ff3f89cb23e1e0d8475a5ef44d82945f1ab0d152531016cL155' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 54783748</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: 4f43a9030853ed574d23f2e86f5253fc4ccd11de</div><div id='time'> Time: 2020-08-13</div><div id='author'> Author: sam@qxcv.net</div><div id='file'> File Name: src/il_representations/scripts/il_train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(5)</div><div id='n_method'> N Method Name: train(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/il_representations/scripts/il_train.py</div><div id='n_file'> N File Name: src/il_representations/scripts/il_train.py</div><div id='m_start'> M Start Line: 164</div><div id='m_end'> M End Line: 211</div><div id='n_start'> N Start Line: 158</div><div id='n_end'> N End Line: 187</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Use PIL to read high-resolution image
        image = Image.open(f"{args.inputs_dir}/{file_name}").convert("RGB")

        <a id="change">if </a>image.width &gt;= args.image_size and <a id="change">image.height &gt;= args.image_size</a>:
            index<a id="change"> = </a>1
            for pos_x in range(0, image.width - args.image_size + 1, args.step):
                for pos_y in range(0, image.height - args.image_size + 1, args.step):
                    crop_image<a id="change"> = </a>image.crop([pos_x, pos_y, pos_x + args.image_size, pos_y + args.image_size])
                    &#47&#47 Save all images
                    crop_image.save(f"{image_dir}/{file_name.split(&quot.&quot)[-2]}_{index:04d}.{file_name.split(&quot.&quot)[-1]}")
                index<a id="change"> += </a>1
    print("Data split successful.")

</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 Splitting images with multiple threads
    progress_bar = tqdm(total=len(image_file_names), unit="image", desc="Split")
    workers_pool<a id="change"> = </a>Pool(args.num_workers)
    for image_file_name in image_file_names:
        workers_pool.apply_async(worker, args=(image_file_name, args), callback=lambda arg: progress_bar.update(1))
    <a id="change">workers_pool.close()</a>
    workers_pool.join()
    progress_bar.close()

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/srgan-pytorch/commit/1d6be4b16a40a639450395e57e387a892f712cf5#diff-0b98e85a7205055fa6d3ef3a8c2e37a80de3ee37091286945a09dacc88f5ed7aL22' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 54783755</div><div id='project'> Project Name: lornatang/srgan-pytorch</div><div id='commit'> Commit Name: 1d6be4b16a40a639450395e57e387a892f712cf5</div><div id='time'> Time: 2022-01-11</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: scripts/prepare_dataset.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/prepare_dataset.py</div><div id='n_file'> N File Name: scripts/prepare_dataset.py</div><div id='m_start'> M Start Line: 23</div><div id='m_end'> M End Line: 42</div><div id='n_start'> N Start Line: 23</div><div id='n_end'> N End Line: 38</div><BR>