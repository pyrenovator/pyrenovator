<html><h3>Pattern ID :12835
</h3><img src='43456150.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

            model.zero_grad()

            pred<a id="change"> = </a>model(
                <a id="change">torch.autograd.Variable(batch).to(</a>device<a id="change">)</a>, lengths.cpu().numpy()
            )  &#47&#47&#47&#47 perform forward pass
            pred<a id="change"> = </a>torch.squeeze(pred)
            loss = criterion(
                pred.to(device), torch.autograd.Variable(targets.float()).to(device)
            )  &#47&#47&#47&#47 compute loss

            loss.backward()  &#47&#47&#47&#47 perform backward pass
            optimizer.step()  &#47&#47&#47&#47 update weights

            pred_val<a id="change"> = </a>pred &gt;= 0.5  &#47&#47&#47&#47 get predictions
            y_true += list(targets.int().numpy())  &#47&#47&#47&#47 accumulate targets from batch
            y_pred += list(
                pred_val.data.int().detach().cpu().numpy()</code></pre><h3>After Change</h3><pre><code class='java'>

            model.zero_grad()
            &#47&#47&#47&#47 perform forward pass
            pred<a id="change"> = </a>model(
                <a id="change">sent1.to(</a>device<a id="change">)</a>,
                sent2.to(device),
                sents1_len.to(device),
                sents2_len.to(device),
            )

            &#47&#47&#47&#47 compute loss
            loss = criterion(
                pred.to(device), torch.autograd.Variable(targets.float()).to(device)
            )

            &#47&#47&#47&#47 perform backward pass
            loss.backward()

            &#47&#47&#47&#47 update weights
            optimizer.step()

            &#47&#47&#47&#47 accumulate targets from batch
            y_true += list(targets.float().numpy())

            &#47&#47&#47&#47 accumulate preds from batch
            y_pred<a id="change"> += </a>list(pred.data.float().detach().cpu().numpy())

            &#47&#47&#47&#47 accumulate train loss
            total_loss += loss</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/shahrukhx01/siamese-nn-semantic-text-similarity/commit/f3d054dd14ef532c408b1306c3341115777ac22f#diff-be822a1f9a4a693be118629ef529ccaecde36733327973c865b9d50a0c7bb839L16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 43456150</div><div id='project'> Project Name: shahrukhx01/siamese-nn-semantic-text-similarity</div><div id='commit'> Commit Name: f3d054dd14ef532c408b1306c3341115777ac22f</div><div id='time'> Time: 2021-12-30</div><div id='author'> Author: sk28671@gmail.com</div><div id='file'> File Name: siamese_sts/trainer/train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train_model(6)</div><div id='n_method'> N Method Name: train_model(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: siamese_sts/trainer/train.py</div><div id='n_file'> N File Name: siamese_sts/trainer/train.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 47</div><div id='n_start'> N Start Line: 16</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        if i &gt;= 10: break

        frames<a id="change"> = </a><a id="change">frames.to(</a>DEVICE<a id="change">)</a>  &#47&#47 [1, T, 3, h, w]
        frames_vis = postprocess_img(frames.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
        input = frames[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 3, h, w]

        pred_rgb = pred_rgb_model.pred_n(input, pred_length=VIDEO_PRED_LENGTH)  &#47&#47 [1, T, 3, h, w]
        pred_rgb_vis = postprocess_img(pred_rgb)  &#47&#47 [T, 3, h, w]

        pred_rgb = torch.cat([input, pred_rgb], dim=1)
        pred_rgb = torch.stack([seg_model(pred_rgb[:, i]) for i in range(pred_rgb.shape[1])], dim=1)
        pred_rgb = pred_rgb.argmax(dim=2).squeeze()  &#47&#47 [T, h, w]
        pred_then_colorized_vis = colorize_semseg(postprocess_mask(pred_rgb), num_classes=SYNPICK_CLASSES) &#47&#47 [T, 3, h, w]

        frames_seg = [seg_model(frames[:, i]).argmax(dim=1) for i in range(frames.shape[1])]
        frames_seg<a id="change"> = </a>torch.stack(frames_seg, dim=1)  &#47&#47 [1, 1, h, w]
        input_seg = frames_seg[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 1, h, w]

        pred_mask = pred_mask_model.pred_n(input_seg, pred_length=VIDEO_PRED_LENGTH)
        pred_mask = pred_mask.argmax(dim=2)  &#47&#47 [1, T, 1, h, w]
        pred_mask = postprocess_mask(torch.cat([input_seg, pred_mask], dim=1).squeeze())  &#47&#47 [T, h, w]
        pred_mask_vis = colorize_semseg(pred_mask, num_classes=SYNPICK_CLASSES)  &#47&#47 [T, 3, h, w]

        frames_colorized = colorize_semseg(postprocess_mask(frames_seg.squeeze()), num_classes=SYNPICK_CLASSES).unsqueeze(dim=0) &#47&#47 [1, T, 3, h, w]
        frames_colorized_vis<a id="change"> = </a>postprocess_img(frames_colorized.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
        input_colorized = frames_colorized[:VIDEO_IN_LENGTH]

        colorized_then_pred = pred_colorized_mask_model.pred_n(input_colorized, pred_length=VIDEO_PRED_LENGTH)</code></pre><h3>After Change</h3><pre><code class='java'>
    with torch.no_grad():
        for i in tqdm(range(10)):

            frames<a id="change"> = </a><a id="change">next(iter_loader).to(</a>DEVICE<a id="change">)</a>  &#47&#47 [1, T, 3, h, w]
            frames_vis = postprocess_img(frames.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
            input = frames[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 3, h, w]

            pred_rgb = pred_rgb_model.pred_n(input, pred_length=VIDEO_PRED_LENGTH)
            pred_rgb = torch.cat([input, pred_rgb], dim=1)  &#47&#47 [1, T, 3, h, w]
            pred_rgb_vis = postprocess_img(pred_rgb.squeeze(dim=0))  &#47&#47 [T, 3, h, w]

            pred_rgb = torch.stack([seg_model(pred_rgb[:, i]) for i in range(pred_rgb.shape[1])], dim=1)
            pred_rgb = pred_rgb.argmax(dim=2).squeeze()  &#47&#47 [T, h, w]
            pred_then_colorized_vis = colorize_semseg(postprocess_mask(pred_rgb), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2) &#47&#47 [T, 3, h, w]

            frames_seg = torch.stack([seg_model(frames[:, i]) for i in range(frames.shape[1])], dim=1).argmax(dim=2)  &#47&#47 [1, T, 1, h, w]
            frames_seg_in<a id="change"> = </a>torch.stack([(frames_seg == i) for i in range(SYNPICK_CLASSES)], dim=2).float()  &#47&#47 [1, T, c, h, w] one-hot float
            input_seg = frames_seg_in[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, c, h, w]
            pred_mask = pred_mask_model.pred_n(input_seg, pred_length=VIDEO_PRED_LENGTH).argmax(dim=2)  &#47&#47 [1, n, 1, h, w]
            pred_mask = torch.cat([input_seg.argmax(dim=2), pred_mask], dim=1).squeeze()  &#47&#47 [T, h, w]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ais-bonn/vp-suite/commit/13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3#diff-e07d70acfca9139cbf2c37b7a0074bdfbb966d41dc6c7edcc2cef05e78c00af0L13' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 43456213</div><div id='project'> Project Name: ais-bonn/vp-suite</div><div id='commit'> Commit Name: 13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3</div><div id='time'> Time: 2021-08-02</div><div id='author'> Author: boltres@ais.uni-bonn.de</div><div id='file'> File Name: scripts/visualize_4_way.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: visualize_4_way(1)</div><div id='n_method'> N Method Name: visualize_4_way(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/visualize_4_way.py</div><div id='n_file'> N File Name: scripts/visualize_4_way.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 73</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 74</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    backbone = models.__dict__[args.arch](pretrained=True)
    num_classes = train_dataset.num_classes
    pretrained_head = backbone.copy_head()
    classifier<a id="change"> = </a><a id="change">Classifier(backbone, num_classes, source_head=pretrained_head).to(</a>device<a id="change">)</a>

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(args.lr), momentum=args.momentum, weight_decay=args.wd, nesterov=True)
    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, args.lr_decay_epochs, gamma=args.lr_gamma)

    &#47&#47 resume from the best checkpoint
    if args.phase != &quottrain&quot:
        checkpoint = torch.load(logger.get_checkpoint_path(&quotbest&quot), map_location=&quotcpu&quot)
        classifier.load_state_dict(checkpoint)

    if args.phase == &quottest&quot:
        acc1<a id="change"> = </a>validate(test_loader, classifier, args)
        print(acc1)
        return


    &#47&#47 compute relationship

    relationship_path = args.relationship
    if not os.path.exists(relationship_path):
        r<a id="change"> = </a>Relationship(determin_train_loader, val_loader, classifier)
        relationship<a id="change"> = </a>r.get_relationship(direct=args.direct)
        np.save(relationship_path, relationship)
    else:
        relationship = np.load(relationship_path)</code></pre><h3>After Change</h3><pre><code class='java'>
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = models.__dict__[args.arch](pretrained=True)
    num_classes = train_dataset.num_classes
    classifier = <a id="change">Classifier(backbone, num_classes, head_source=backbone.copy_head()).to(</a>device<a id="change">)</a>

    &#47&#47 define optimizer and lr scheduler
    optimizer = SGD(classifier.get_parameters(args.lr), momentum=args.momentum, weight_decay=args.wd, nesterov=True)
    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, args.lr_decay_epochs, gamma=args.lr_gamma)

    &#47&#47 resume from the best checkpoint
    if args.phase == &quottest&quot:
        checkpoint = torch.load(logger.get_checkpoint_path(&quotbest&quot), map_location=&quotcpu&quot)
        classifier.load_state_dict(checkpoint)
        acc1 = validate(val_loader, classifier, args)
        print(acc1)
        return

    &#47&#47 build relationship between source classes and target classes
    relationship<a id="change"> = </a>Relationship(determin_train_loader, classifier, device, os.path.join(logger.root, args.relationship))
    co_tuning_loss = CoTuningLoss()

    &#47&#47 start training</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/d2d33527cdc174b9ef6dd2644337e3e3e50028ac#diff-46e5f7f40f62982cd2fed0316172ea915e81cf8a967098e824cd534cc2215dc0L32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 43457152</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: d2d33527cdc174b9ef6dd2644337e3e3e50028ac</div><div id='time'> Time: 2021-03-10</div><div id='author'> Author: 13126830206@163.com</div><div id='file'> File Name: examples-ft/classification/co_tuning.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples-ft/classification/co_tuning.py</div><div id='n_file'> N File Name: examples-ft/classification/co_tuning.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 132</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 100</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            optimizer.zero_microbatch_grad()
            output = model(torch.unsqueeze(X_microbatch.to(torch.float32), 0))    &#47&#47这要是这里要做升维

            loss = criterion(output, torch.unsqueeze(<a id="change">y_microbatch.to(</a>torch.long<a id="change">)</a>, 0))       &#47&#47相反，这边对于的output就不用升维了

            loss.backward()         &#47&#47梯度求导，这边求出梯度
            optimizer.microbatch_step()  &#47&#47 这个step做的是每个样本的梯度裁剪和梯度累加的操作

            train_loss<a id="change"> += </a>loss.item()  &#47&#47 损失累加
            prediction = output.argmax(dim=1, keepdim=True)  &#47&#47 将one-hot输出转为单个标量
            correct += prediction.eq(y_microbatch.view_as(prediction)).sum().item()  &#47&#47 比较得到准确率
</code></pre><h3>After Change</h3><pre><code class='java'>
        optimizer.step()  &#47&#47 这个做的是梯度加噪和梯度平均更新下降的操作

        &#47&#47训练集测试损失值和准确率
        train_output<a id="change">=</a>model(<a id="change">data.to(</a>torch.float32<a id="change">)</a>)
        train_loss<a id="change">=</a>criterion(train_output,target).item()
        prediction = train_output.argmax(dim=1, keepdim=True)  &#47&#47 将one-hot输出转为单个标量
        correct<a id="change"> = </a>prediction.eq(target.view_as(prediction)).sum().item()  &#47&#47 比较得到准确率
        train_acc<a id="change">=</a>100. * correct/len(data)
        i+=1

        &#47&#47 print(f&quotbatch: {i}, &quotf&quotTrain set: loss: {train_loss:.4f}, &quot</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jefffffu/awesome-differential-privacy-and-meachine-learning/commit/2ebbe536f3de4fe260e92dfa2a45dd3bab30a414#diff-aecaebc49c1330d797ceb7c3e3b703c3d28e5366804cbea249ee3aca40cfbd58L7' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 43456154</div><div id='project'> Project Name: jefffffu/awesome-differential-privacy-and-meachine-learning</div><div id='commit'> Commit Name: 2ebbe536f3de4fe260e92dfa2a45dd3bab30a414</div><div id='time'> Time: 2022-12-06</div><div id='author'> Author: 1193147851@qq.com</div><div id='file'> File Name: train_and_validation/train_with_dp.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train_dynamic_add_noise(4)</div><div id='n_method'> N Method Name: train_dynamic_add_noise(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_and_validation/train_with_dp.py</div><div id='n_file'> N File Name: train_and_validation/train_with_dp.py</div><div id='m_start'> M Start Line: 10</div><div id='m_end'> M End Line: 40</div><div id='n_start'> N Start Line: 13</div><div id='n_end'> N End Line: 45</div><BR>