<html><h3>Pattern ID :14126
</h3><img src='47181711.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            dict_data = process_sembert(sentence,question,label,self.tokenizer,self.vocab,self.max_token_len,enhanced_data_dict,self.tag_tokenizer)

            datable("input_ids", dict_data["input_ids"])
            <a id="change">datable("input_mask"</a>, <a id="change">dict_data["input_mask"]</a><a id="change">)</a>
            datable("token_type_ids", dict_data["token_type_ids"])
            datable("input_tag_ids", dict_data["input_tag_ids"])
            datable("start_end_idx", dict_data["start_end_idx"])
            datable("label", dict_data["label"])</code></pre><h3>After Change</h3><pre><code class='java'>
        print("Processing data...")
        for sentence, question, label in tqdm(zip(data[&quotsentence&quot], data[&quotquestion&quot], data[&quotlabel&quot]),
                                              total=len(data[&quotsentence&quot])):
            tokenized_data = <a id="change">self.tokenizer.encode_plus(text=sentence, text_pair=question,
                                                        truncation=&quotlongest_first&quot,
                                                        padding="max_length",
                                                        add_special_tokens=True,
                                                        max_length=self.max_token_len)</a>
            datable("input_ids", tokenized_data["input_ids"])
            datable("token_type_ids", tokenized_data["token_type_ids"])
            <a id="change">datable("attention_mask"</a>, tokenized_data["attention_mask"]<a id="change">)</a>
            datable("label", self.vocab["label_vocab"].label2id(label))
        return DataTableSet(datable)

    def process_train(self, data):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/cognlp/cogktr/commit/3129fa7e5bea047a2f9fb814b65b2c5d4dfd8c69#diff-e7911de0fb4761540a2f9787c678e3f30db0b3201a9df48e9dac1ee45b7a7e27L24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 47181711</div><div id='project'> Project Name: cognlp/cogktr</div><div id='commit'> Commit Name: 3129fa7e5bea047a2f9fb814b65b2c5d4dfd8c69</div><div id='time'> Time: 2022-06-20</div><div id='author'> Author: 2113809110@qq.com</div><div id='file'> File Name: cogktr/data/processor/qnli_processors/qnli_processor.py</div><div id='m_class'> M Class Name: QnliProcessor</div><div id='n_method'> N Class Name: QnliProcessor</div><div id='m_method'> M Method Name: _process(2)</div><div id='n_method'> N Method Name: _process(3)</div><div id='m_parent_class'> M Parent Class: BaseProcessor</div><div id='n_parent_class'> N Parent Class: BaseProcessor</div><div id='m_file'> M File Name: cogktr/data/processor/qnli_processors/qnli_processor.py</div><div id='n_file'> N File Name: cogktr/data/processor/qnli_processors/qnli_processor.py</div><div id='m_start'> M Start Line: 37</div><div id='m_end'> M End Line: 50</div><div id='n_start'> N Start Line: 24</div><div id='n_end'> N End Line: 34</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for sentence in tqdm(zip(data[&quotsentence&quot]), total=len(data[&quotsentence&quot])):
            token = self.tokenizer.encode(text=sentence, truncation=True, padding="max_length", add_special_tokens=True,
                                          max_length=self.max_token_len)
            <a id="change">datable("input_ids"</a>, token<a id="change">)</a>
        return DataTableSet(datable)


if __name__ == "__main__":</code></pre><h3>After Change</h3><pre><code class='java'>
        for sentence in tqdm(zip(data[&quotsentence&quot]), total=len(data[&quotsentence&quot])):
            token = self.tokenizer.encode(text=sentence, truncation=True, padding="max_length", add_special_tokens=True,
                                          max_length=self.max_token_len)
            tokenized_data = <a id="change">self.tokenizer.encode_plus(text=sentence,
                                                        padding="max_length",
                                                        add_special_tokens=True,
                                                        max_length=self.max_token_len)</a>
            datable("input_ids", tokenized_data["input_ids"])
            datable("token_type_ids", tokenized_data["token_type_ids"])
            <a id="change">datable("attention_mask"</a>, <a id="change">tokenized_data["attention_mask"]</a><a id="change">)</a>
        return DataTableSet(datable)


if __name__ == "__main__":</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/cognlp/cogktr/commit/858e06249781dc8a1cbfb44285f6a42ed23befed#diff-9a8bbca1c843091162205d0077b11845446bf8eb8f3f056cb627a03cb210e6a2L35' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 47181727</div><div id='project'> Project Name: cognlp/cogktr</div><div id='commit'> Commit Name: 858e06249781dc8a1cbfb44285f6a42ed23befed</div><div id='time'> Time: 2022-08-02</div><div id='author'> Author: 2113809110@qq.com</div><div id='file'> File Name: cogktr/data/processor/sst2_processors/sst2_processor.py</div><div id='m_class'> M Class Name: Sst2Processor</div><div id='n_method'> N Class Name: Sst2Processor</div><div id='m_method'> M Method Name: process_test(2)</div><div id='n_method'> N Method Name: process_test(2)</div><div id='m_parent_class'> M Parent Class: BaseProcessor</div><div id='n_parent_class'> N Parent Class: BaseProcessor</div><div id='m_file'> M File Name: cogktr/data/processor/sst2_processors/sst2_processor.py</div><div id='n_file'> N File Name: cogktr/data/processor/sst2_processors/sst2_processor.py</div><div id='m_start'> M Start Line: 39</div><div id='m_end'> M End Line: 41</div><div id='n_start'> N Start Line: 48</div><div id='n_end'> N End Line: 54</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        print("Processing data...")
        for sentence, question, label in tqdm(zip(data[&quotsentence&quot], data[&quotquestion&quot], data[&quotlabel&quot]),
                                              total=len(data[&quotsentence&quot])):
            tokenized_data = <a id="change">self.tokenizer.encode_plus(text=sentence, text_pair=question,
                                                        truncation=&quotlongest_first&quot,
                                                        padding="max_length",
                                                        add_special_tokens=True,
                                                        max_length=self.max_token_len)</a>
            datable("input_ids", tokenized_data["input_ids"])
            datable("token_type_ids", tokenized_data["token_type_ids"])
            <a id="change">datable("attention_mask"</a>, tokenized_data["attention_mask"]<a id="change">)</a>
            datable("label", self.vocab["label_vocab"].label2id(label))
        return DataTableSet(datable)

    def process_train(self, data):</code></pre><h3>After Change</h3><pre><code class='java'>
            dict_data = process_sembert(sentence,question,label,self.tokenizer,self.vocab,self.max_token_len,self.srl_tagger,enhanced_data_dict,self.tag_tokenizer)

            datable("input_ids", dict_data["input_ids"])
            <a id="change">datable("input_mask"</a>, <a id="change">dict_data["input_mask"]</a><a id="change">)</a>
            datable("token_type_ids", dict_data["token_type_ids"])
            datable("input_tag_ids", dict_data["input_tag_ids"])
            datable("start_end_idx", dict_data["start_end_idx"])
            datable("label", dict_data["label"])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/cognlp/cogktr/commit/8de85e31d06141ecf8c7e93b05b7bf5aa1fef1a3#diff-e7911de0fb4761540a2f9787c678e3f30db0b3201a9df48e9dac1ee45b7a7e27L28' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 47181709</div><div id='project'> Project Name: cognlp/cogktr</div><div id='commit'> Commit Name: 8de85e31d06141ecf8c7e93b05b7bf5aa1fef1a3</div><div id='time'> Time: 2022-06-14</div><div id='author'> Author: 1208314139@qq.com</div><div id='file'> File Name: cogktr/data/processor/qnli_processors/qnli_processor.py</div><div id='m_class'> M Class Name: QnliProcessor</div><div id='n_method'> N Class Name: QnliProcessor</div><div id='m_method'> M Method Name: _process(3)</div><div id='n_method'> N Method Name: _process(2)</div><div id='m_parent_class'> M Parent Class: BaseProcessor</div><div id='n_parent_class'> N Parent Class: BaseProcessor</div><div id='m_file'> M File Name: cogktr/data/processor/qnli_processors/qnli_processor.py</div><div id='n_file'> N File Name: cogktr/data/processor/qnli_processors/qnli_processor.py</div><div id='m_start'> M Start Line: 32</div><div id='m_end'> M End Line: 42</div><div id='n_start'> N Start Line: 31</div><div id='n_end'> N End Line: 44</div><BR>