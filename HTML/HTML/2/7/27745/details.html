<html><h3>Pattern ID :27745
</h3><img src='82232934.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 masked by the missing entries
        &#47&#47 note, different batch may contain different number of real entities
        tensor_list = []
        <a id="change">for </a>i, batch in enumerate(out)<a id="change">:
            </a>mean_entity = 0.
            real_number = real_number_tensor[i]
            real_number = real_number<a id="change"> if real_number != 0</a><a id="change"> else </a>1
            for j, entity in enumerate(batch):
                if j &gt;= real_number_tensor[i]:
                    break        
                mean_entity = mean_entity + entity
            mean_entity = mean_entity / (real_number)
            <a id="change">tensor_list.append(</a>mean_entity.reshape(1, -1)<a id="change">)</a>
        tensor_mean = torch.cat(tensor_list, dim=0)
        print(&quottensor_mean:&quot, tensor_mean) if debug else None
</code></pre><h3>After Change</h3><pre><code class='java'>
        print(&quotentity_num:&quot, entity_num) if debug else None

        &#47&#47 generate the mask for transformer
        mask<a id="change"> = </a><a id="change">torch.arange(</a>0, self.max_entities<a id="change">)</a>.float()
        mask = mask.repeat(batch_size, 1)
        mask = mask &lt; entity_num.unsqueeze(dim=1)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/liuruoze/mini-alphastar/commit/612d42a7bf5ef827e1e919198d839fce106155cd#diff-71869e70f9cb835282d541d2d3529d25b6ed6795c79bc770e860e9318619f6b1L716' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 82232934</div><div id='project'> Project Name: liuruoze/mini-alphastar</div><div id='commit'> Commit Name: 612d42a7bf5ef827e1e919198d839fce106155cd</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: liuruoze@163.com</div><div id='file'> File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_class'> M Class Name: EntityEncoder</div><div id='n_method'> N Class Name: EntityEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='n_file'> N File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_start'> M Start Line: 721</div><div id='m_end'> M End Line: 758</div><div id='n_start'> N Start Line: 716</div><div id='n_end'> N End Line: 778</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if ids_freq_mapping is not None:
            sorted_idx = np.flipud(np.argsort(ids_freq_mapping))

        <a id="change">for </a><a id="change">_id</a> in range(self.num_embeddings)<a id="change">:
            </a>chunk_id, offset_in_chunk = divmod(_id<a id="change"> if ids_freq_mapping is None</a><a id="change"> else </a>sorted_idx[_id], self.chunk_size)
            <a id="change">self.index_mapping_table.append(</a>(chunk_id, offset_in_chunk)<a id="change">)</a>
            self.IMP_chunkid_Embedding.weight[_id] = chunk_id
            self.IMP_offsetinchunk_Embedding.weight[_id] = offset_in_chunk
        self.IMP_chunkid_Embedding = self.IMP_chunkid_Embedding.cuda()
        self.IMP_offsetinchunk_Embedding = self.IMP_offsetinchunk_Embedding.cuda()</code></pre><h3>After Change</h3><pre><code class='java'>
        if ids_freq_mapping is not None:
            sorted_idx = torch.argsort(torch.from_numpy(ids_freq_mapping).cuda(), descending=True)
        else:
            sorted_idx<a id="change"> = </a><a id="change">torch.arange(</a>self.num_embeddings<a id="change">, device=torch.cuda.current_device(), dtype=torch.long)</a>

        divs = torch.div(sorted_idx, self.chunk_size, rounding_mode=&quotfloor&quot).unsqueeze(1)
        mods = torch.remainder(sorted_idx, self.chunk_size).unsqueeze(1)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hpcaitech/freqcacheembedding/commit/649b198bab518ec907dcf5b4ad2f33c6058b5697#diff-aab5f7e7e049810d29a74e3eab12af668892a81357998cc464ab0f8cd2272767L114' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 82232935</div><div id='project'> Project Name: hpcaitech/freqcacheembedding</div><div id='commit'> Commit Name: 649b198bab518ec907dcf5b4ad2f33c6058b5697</div><div id='time'> Time: 2022-07-26</div><div id='author'> Author: 34452939+zxgx@users.noreply.github.com</div><div id='file'> File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='m_class'> M Class Name: ChunkParamMgr</div><div id='n_method'> N Class Name: ChunkParamMgr</div><div id='m_method'> M Method Name: reorder(2)</div><div id='n_method'> N Method Name: reorder(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='n_file'> N File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='m_start'> M Start Line: 122</div><div id='m_end'> M End Line: 130</div><div id='n_start'> N Start Line: 125</div><div id='n_end'> N End Line: 133</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    mrr, hits = [], []

    <a id="change">for </a><a id="change">i</a>, (s, p, o) in enumerate(test_spo)<a id="change">:
        </a>row = scores[i]  &#47&#47 corresponding predictions
        idx = o<a id="change"> if direction == "o"</a><a id="change"> else </a>s
        true_score = row[idx]

        &#47&#47 remove current label from scores
        row = row.clone()
        row[idx] = float("-Inf")

        &#47&#47 follow LibKGE protocol for ranking and ties
        rank = int(torch.sum(row &gt; true_score, dtype=torch.long))
        num_ties = int(torch.sum(row == true_score, dtype=torch.long))
        rank = rank + num_ties // 2 + 1

        &#47&#47 compute MRR and Hits@k
        <a id="change">mrr.append(</a>1 / rank<a id="change">)</a>
        hits.append(int(rank &lt;= k))

    return mrr, hits
</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 get the scores of the true target subjects/objects
    idx = 0 if direction == "s" else 2
    targets = test_spo[:, idx].long()
    arange = <a id="change">torch.arange(</a>len(targets)<a id="change">, dtype=torch.long, device="cpu")</a>
    true_scores = scores[arange, targets].view(-1, 1)

    &#47&#47 remove the true subjects/objects from the scores so they don&quott factor in rankings
    scores = scores.clone()
    scores[arange, targets] = float("-Inf")

    &#47&#47 follow LibKGE protocol by taking the mean rank among all entities with same score
    ranks = torch.sum(scores &gt; true_scores, dim=1, dtype=torch.double)
    num_ties = torch.sum(scores == true_scores, dim=1, dtype=torch.double)
    ranks = ranks + num_ties // 2 + 1  &#47&#47 ranks are one-indexed

    mrr = (1 / ranks).numpy()
    hits<a id="change"> = </a>(ranks &lt;= k).numpy()
    return list(mrr), list(hits)

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tsafavi/codex/commit/3dddca246e4fb616cef251bafb32dac648e8eedb#diff-7473d3c6ae8fdca415f05877da582b17af17f591a0a1312717bb10fd4da4b992L119' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 82232932</div><div id='project'> Project Name: tsafavi/codex</div><div id='commit'> Commit Name: 3dddca246e4fb616cef251bafb32dac648e8eedb</div><div id='time'> Time: 2020-07-08</div><div id='author'> Author: tsafavi@umich.edu</div><div id='file'> File Name: scripts/baseline.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate_rankings(5)</div><div id='n_method'> N Method Name: evaluate_rankings(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/baseline.py</div><div id='n_file'> N File Name: scripts/baseline.py</div><div id='m_start'> M Start Line: 129</div><div id='m_end'> M End Line: 151</div><div id='n_start'> N Start Line: 129</div><div id='n_end'> N End Line: 148</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 masked by the missing entries
        &#47&#47 note, different batch may contain different number of real entities
        tensor_list = []
        <a id="change">for </a>i, <a id="change">batch</a> in enumerate(out)<a id="change">:
            </a>mean_entity = 0.
            real_number = real_number_tensor[i]
            real_number = real_number<a id="change"> if real_number != 0</a><a id="change"> else </a>1
            for j, entity in enumerate(batch):
                if j &gt;= real_number_tensor[i]:
                    break        
                mean_entity = mean_entity + entity
            mean_entity = mean_entity / (real_number)
            <a id="change">tensor_list.append(</a>mean_entity.reshape(1, -1)<a id="change">)</a>
        tensor_mean = torch.cat(tensor_list, dim=0)
        print(&quottensor_mean:&quot, tensor_mean) if debug else None
</code></pre><h3>After Change</h3><pre><code class='java'>
        print(&quotentity_num:&quot, entity_num) if debug else None

        &#47&#47 generate the mask for transformer
        mask = <a id="change">torch.arange(</a>0, self.max_entities<a id="change">)</a>.float()
        mask = mask.repeat(batch_size, 1)
        mask = mask &lt; entity_num.unsqueeze(dim=1)

        print(&quotmask:&quot, mask) if debug else None
        print(&quotmask.shape:&quot, mask.shape) if debug else None

        &#47&#47 mask: [batch_size, max_entities]
        device = next(self.parameters()).device
        mask = mask.to(device)

        &#47&#47 assert the input shape is : batch_seq_size x entities_size x embeding_size
        &#47&#47 note: because the feature size of entity is not equal to 256, so it can not fed into transformer directly.
        &#47&#47 thus, we add a embedding layer to transfer it to right size.
        &#47&#47 x is batch_entities_tensor (dim = 3). Shape: batch_seq_size x entities_size x embeding_size
        x = self.embedd(x)
        print(&quotx.shape:&quot, x.shape) if debug else None

        &#47&#47 mask for transformer need a special format
        mask_seq_len = mask.shape[-1]
        tran_mask = mask.unsqueeze(1)

        &#47&#47 tran_mask: [batch_seq_size x max_entities x max_entities]
        tran_mask<a id="change"> = </a>tran_mask.repeat(1, mask_seq_len, 1)

        &#47&#47 out: [batch_seq_size x entities_size x embeding_size]
        out = self.transformer(x, mask=tran_mask)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/liuruoze/mini-alphastar/commit/612d42a7bf5ef827e1e919198d839fce106155cd#diff-71869e70f9cb835282d541d2d3529d25b6ed6795c79bc770e860e9318619f6b1L717' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 82232931</div><div id='project'> Project Name: liuruoze/mini-alphastar</div><div id='commit'> Commit Name: 612d42a7bf5ef827e1e919198d839fce106155cd</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: liuruoze@163.com</div><div id='file'> File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_class'> M Class Name: EntityEncoder</div><div id='n_method'> N Class Name: EntityEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='n_file'> N File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_start'> M Start Line: 721</div><div id='m_end'> M End Line: 758</div><div id='n_start'> N Start Line: 716</div><div id='n_end'> N End Line: 778</div><BR>