<html><h3>Pattern ID :28146
</h3><img src='83095059.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    if dx &lt; 0:
        xx *= -1
    Lx = torch.sinc(xx) * torch.sinc(xx / scale)
    Lx[0<a id="change"> if dx &gt; 0</a><a id="change">  else </a>-1] = 0

    yy = torch.arange(int(-scale), int(scale+1), dtype = dtype, device = device) - dy &#47&#47torch.flip(torch.arange(int(-scale), int(scale+1), dtype = dtype, device = device) - dy, (0,))
    if dy &lt; 0:</code></pre><h3>After Change</h3><pre><code class='java'>
    sub-pixel length.

    
    xsign<a id="change"> = </a>(1<a id="change"> - </a>2*<a id="change">(dx &lt; 0).to(dtype = torch.int32)</a>) &#47&#47 flips the kernel if the shift is negative
    xx = xsign<a id="change">*</a>(torch.arange(int(-scale), int(scale+1), dtype = dtype, device = device) - dx)
    Lx = torch.sinc(xx) * torch.sinc(xx / scale)

    ysign = (1 - 2*(dy &lt; 0).to(dtype = torch.int32))</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/connorstoneastro/autoprof/commit/c470a85d1d5174a01e42cea82ad90447d70035d5#diff-a7b6f02c4d36a3cde70a8d71970baafe50bed69ca74dc191afb03b9c20891382L130' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83095059</div><div id='project'> Project Name: connorstoneastro/autoprof</div><div id='commit'> Commit Name: c470a85d1d5174a01e42cea82ad90447d70035d5</div><div id='time'> Time: 2023-01-11</div><div id='author'> Author: connorstone628@gmail.com</div><div id='file'> File Name: autoprof/utils/interpolate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _shift_Lanczos_kernel_torch(5)</div><div id='n_method'> N Method Name: _shift_Lanczos_kernel_torch(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: autoprof/utils/interpolate.py</div><div id='n_file'> N File Name: autoprof/utils/interpolate.py</div><div id='m_start'> M Start Line: 130</div><div id='m_end'> M End Line: 148</div><div id='n_start'> N Start Line: 130</div><div id='n_end'> N End Line: 143</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for i, batch in enumerate(out):
            mean_entity = 0.
            real_number = real_number_tensor[i]
            real_number = real_number<a id="change"> if real_number != 0</a><a id="change"> else </a>1
            for j, entity in enumerate(batch):
                if j &gt;= real_number_tensor[i]:
                    break        </code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 mask: [batch_size, max_entities]
        device = next(self.parameters()).device
        mask = <a id="change">mask.to(</a>device<a id="change">)</a>

        &#47&#47 assert the input shape is : batch_seq_size x entities_size x embeding_size
        &#47&#47 note: because the feature size of entity is not equal to 256, so it can not fed into transformer directly.
        &#47&#47 thus, we add a embedding layer to transfer it to right size.
        &#47&#47 x is batch_entities_tensor (dim = 3). Shape: batch_seq_size x entities_size x embeding_size
        x = self.embedd(x)
        print(&quotx.shape:&quot, x.shape) if debug else None

        &#47&#47 mask for transformer need a special format
        mask_seq_len = mask.shape[-1]
        tran_mask = mask.unsqueeze(1)

        &#47&#47 tran_mask: [batch_seq_size x max_entities x max_entities]
        tran_mask = tran_mask.repeat(1, mask_seq_len, 1)

        &#47&#47 out: [batch_seq_size x entities_size x embeding_size]
        out = self.transformer(x, mask=tran_mask)
        print(&quotout.shape:&quot, out.shape) if debug else None

        &#47&#47 entity_embeddings: [batch_seq_size x entities_size x conv1_output_size]
        entity_embeddings = F.relu(self.conv1(F.relu(out).transpose(1, 2))).transpose(1, 2)
        print(&quotentity_embeddings.shape:&quot, entity_embeddings.shape) if debug else None

        &#47&#47 AlphaStar: The mean of the transformer output across across the units (masked by the missing entries) 
        &#47&#47 is fed through a linear layer of size 256 and a ReLU to yield `embedded_entity`
        masked_out<a id="change"> = </a>out<a id="change"> * </a>mask.unsqueeze(2)

        &#47&#47 sum over across the units
        &#47&#47 masked_out: [batch_seq_size x entities_size x embeding_size]
        &#47&#47 z: [batch_size, embeding_size]
        z = masked_out.sum(dim=1, keepdim=False)

        &#47&#47 here we should dived by the entity_num, not the cls.max_entities
        &#47&#47 z: [batch_size, embeding_size]
        z = z<a id="change"> / </a>entity_num

        &#47&#47 note, dim=1 means the mean is across all entities in one timestep
        &#47&#47 The mean of the transformer output across across the units  </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/liuruoze/mini-alphastar/commit/612d42a7bf5ef827e1e919198d839fce106155cd#diff-71869e70f9cb835282d541d2d3529d25b6ed6795c79bc770e860e9318619f6b1L717' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83095057</div><div id='project'> Project Name: liuruoze/mini-alphastar</div><div id='commit'> Commit Name: 612d42a7bf5ef827e1e919198d839fce106155cd</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: liuruoze@163.com</div><div id='file'> File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_class'> M Class Name: EntityEncoder</div><div id='n_method'> N Class Name: EntityEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='n_file'> N File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_start'> M Start Line: 721</div><div id='m_end'> M End Line: 758</div><div id='n_start'> N Start Line: 716</div><div id='n_end'> N End Line: 778</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if dx &lt; 0:
        xx *= -1
    Lx = torch.sinc(xx) * torch.sinc(xx / scale)
    Lx[0<a id="change"> if dx &gt; 0</a><a id="change">  else </a>-1] = 0

    yy = torch.arange(int(-scale), int(scale+1), dtype = dtype, device = device) - dy &#47&#47torch.flip(torch.arange(int(-scale), int(scale+1), dtype = dtype, device = device) - dy, (0,))
    if dy &lt; 0:</code></pre><h3>After Change</h3><pre><code class='java'>
    sub-pixel length.

    
    xsign<a id="change"> = </a>(1<a id="change"> - </a>2*<a id="change">(dx &lt; 0).to(dtype = torch.int32)</a>) &#47&#47 flips the kernel if the shift is negative
    xx = xsign<a id="change">*</a>(torch.arange(int(-scale), int(scale+1), dtype = dtype, device = device) - dx)
    Lx = torch.sinc(xx) * torch.sinc(xx / scale)

    ysign = (1 - 2*(dy &lt; 0).to(dtype = torch.int32))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/connorstoneastro/autoprof/commit/a0ad8000781a5d54daec1ff2d1051f727c29dd36#diff-0553de9eb4c4bf7620c396ae32e353adfa67451ce35e4604af221047036c87cfL125' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83095062</div><div id='project'> Project Name: connorstoneastro/autoprof</div><div id='commit'> Commit Name: a0ad8000781a5d54daec1ff2d1051f727c29dd36</div><div id='time'> Time: 2023-01-11</div><div id='author'> Author: connorstone628@gmail.com</div><div id='file'> File Name: build/lib/autoprof/utils/interpolate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _shift_Lanczos_kernel_torch(5)</div><div id='n_method'> N Method Name: _shift_Lanczos_kernel_torch(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: build/lib/autoprof/utils/interpolate.py</div><div id='n_file'> N File Name: build/lib/autoprof/utils/interpolate.py</div><div id='m_start'> M Start Line: 130</div><div id='m_end'> M End Line: 148</div><div id='n_start'> N Start Line: 130</div><div id='n_end'> N End Line: 143</div><BR>