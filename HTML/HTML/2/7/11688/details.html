<html><h3>Pattern ID :11688
</h3><img src='39520313.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            source_pp = source_layer["positional_embedding:0"]  &#47&#47 weights
        else:
            source_pp = source_layer.pp  &#47&#47 layer
        self.pp.assign(tf.image.resize(source_pp, <a id="change">self.pp.shape[1:3]</a>, method=method))

    def show_pos_emb(self, rows=16, base_size=1):
        import matplotlib.pyplot as plt</code></pre><h3>After Change</h3><pre><code class='java'>
            source_pp = source_layer.pp  &#47&#47 layer

        source_pp = tf.cast(source_pp, self.pp.dtype)
        <a id="change">if </a>self.is_fused_height_width:
            hh = ww = int(<a id="change">tf.math.sqrt(</a>float(source_pp.shape[1])<a id="change">)</a>)  &#47&#47 assume source weights are all square shape
            ss<a id="change"> = </a>tf.reshape(source_pp[:, -hh * ww:], [1, hh, ww, -1])  &#47&#47 If has cls_token
            tt = tf.image.resize(ss, [self.height, self.width], method=method)
            tt = tf.reshape(tt, [1, self.height * self.width, -1])

            tt = tf.concat([source_pp[:, :-hh * ww], tt], axis=1)  &#47&#47 If has cls_token
        else:
            tt<a id="change"> = </a>tf.image.resize(source_pp, [self.height, self.width], method=method)
        self.pp.assign(tt)

    def show_pos_emb(self, rows=16, base_size=1):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/8776edc81f38b435615eee79514c4b7b8b88fc67#diff-70a89c021ce6222b18ca0d8fb02d602b2b15343d3af62a18df1b7034f8955a29L209' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39520313</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: 8776edc81f38b435615eee79514c4b7b8b88fc67</div><div id='time'> Time: 2023-01-10</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/volo/volo.py</div><div id='m_class'> M Class Name: PositionalEmbedding</div><div id='n_method'> N Class Name: PositionalEmbedding</div><div id='m_method'> M Method Name: load_resized_weights(3)</div><div id='n_method'> N Method Name: load_resized_weights(3)</div><div id='m_parent_class'> M Parent Class: keras.layers.Layer</div><div id='n_parent_class'> N Parent Class: keras.layers.Layer</div><div id='m_file'> M File Name: keras_cv_attention_models/volo/volo.py</div><div id='n_file'> N File Name: keras_cv_attention_models/volo/volo.py</div><div id='m_start'> M Start Line: 209</div><div id='m_end'> M End Line: 209</div><div id='n_start'> N Start Line: 216</div><div id='n_end'> N End Line: 226</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                D = pre_dist_mat[bi]**2
                M = D[:1, :] + D[:, :1] - D 
                u,s,v = torch.svd_lowrank(M/2)
                preds_3d.append( <a id="change">(u@torch.diag(s).sqrt())[:, :3]</a>.t() )
            return torch.stack(preds_3d, dim=0), torch.zeros_like(torch.stack(his, dim=0))
        else:
            if verbose:</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 do it by eigendecomposition - way faster but not weights
    &#47&#47 https://www.biorxiv.org/content/10.1101/2020.11.27.401232v1.full.pdf
    if eigen == True:
        <a id="change">if </a>weights is None:
            D = pre_dist_mat**2
            M =  0.5 * (D[:, :1, :] + D[:, :, :1] - D) 
            &#47&#47 do loop svd bc it&quots faster: (2-3x in CPU and 1-2x in GPU)
            &#47&#47 https://discuss.pytorch.org/t/batched-svd-lowrank-being-much-slower-than-loop-implementation-both-cpu-and-gpu/119336
            svds = [torch.svd_lowrank(mi) for mi in M]
            u = torch.stack([svd[0] for svd in svds], dim=0)
            s = torch.stack([svd[1] for svd in svds], dim=0)
            v<a id="change"> = </a>torch.stack([svd[2] for svd in svds], dim=0)
            preds_3d<a id="change"> = </a>torch.transpose( torch.bmm(u, <a id="change">torch.diag_embed(s).sqrt()</a>)[..., :3], -1, -2)
            
            return preds_3d, torch.zeros_like(torch.stack(his, dim=0))
        else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/alphafold2/commit/c3e564efd689bff4df9759b2855bdbb6dcd1b67b#diff-f9b2e05be1f80257f9a80ec7cc1290e3337a54fcc62aeee31b23a4cb827f12efL636' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39520350</div><div id='project'> Project Name: lucidrains/alphafold2</div><div id='commit'> Commit Name: c3e564efd689bff4df9759b2855bdbb6dcd1b67b</div><div id='time'> Time: 2021-04-25</div><div id='author'> Author: ericalcaide1@gmail.com</div><div id='file'> File Name: alphafold2_pytorch/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mds_torch(6)</div><div id='n_method'> N Method Name: mds_torch(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: alphafold2_pytorch/utils.py</div><div id='n_file'> N File Name: alphafold2_pytorch/utils.py</div><div id='m_start'> M Start Line: 650</div><div id='m_end'> M End Line: 668</div><div id='n_start'> N Start Line: 645</div><div id='n_end'> N End Line: 671</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    
    shape = distogram.shape
    n_bins = torch.ones(shape[-1] + 1) * min_t
    <a id="change">n_bins[1:]</a> = torch.tensor(bins)
    &#47&#47 center - median
    cum_dist = torch.cumsum(distogram, dim=-1)
    central  = torch.searchsorted(cum_dist, 0.5)</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 mask diagonal to 0 dist
    central[np.arange(shape[-2]), np.arange(shape[-3])] = 0.
    &#47&#47 provide weights
    <a id="change">if </a>wide == "var":
        weights = (distogram * (bins - central.unsqueeze(-1))**2).sum(dim=-1)
    elif wide == "sqrt":
        weights<a id="change"> = </a><a id="change">(distogram * (bins - central.unsqueeze(-1))**2).sum(dim=-1).sqrt()</a>
    else:
        weights<a id="change"> = </a>torch.zeros_like(central)
    &#47&#47 rescale to 0-1. lower std / var  --&gt; weight=1
    weights = 1 / (1+weights)
    &#47&#47 TODO: rescale to 0-1?</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/alphafold2/commit/5013886fc413e143b7f3341db644d320a11c3804#diff-09d0cbaf891d623ac245ccf84485a687b554217349ca55557c60b33234b969aeL110' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39520368</div><div id='project'> Project Name: lucidrains/alphafold2</div><div id='commit'> Commit Name: 5013886fc413e143b7f3341db644d320a11c3804</div><div id='time'> Time: 2021-01-14</div><div id='author'> Author: ericacaide1@gmail.com</div><div id='file'> File Name: utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: center_distogram_torch(5)</div><div id='n_method'> N Method Name: center_distogram_torch(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: utils.py</div><div id='n_file'> N File Name: utils.py</div><div id='m_start'> M Start Line: 119</div><div id='m_end'> M End Line: 130</div><div id='n_start'> N Start Line: 110</div><div id='n_end'> N End Line: 139</div><BR>