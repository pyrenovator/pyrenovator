<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Do this before wrapping.
        eval_dataset = dataloader.dataset

        <a id="change">if </a>is_torch_tpu_available():
            dataloader<a id="change"> = </a>pl.ParallelLoader(dataloader, <a id="change">[</a>args.device<a id="change"></a>]).per_device_loader(args.device)

        if args.past_index &gt;= 0:
            self._past = None</code></pre><h3>After Change</h3><pre><code class='java'>
        self.infer_sess = None

        &#47&#47 Check if there are labels in the dataset
        dummy_inputs = <a id="change">next(</a><a id="change">iter(</a>dataloader<a id="change">))</a>
        has_labels<a id="change"> = </a>all(dummy_inputs.get(k) is not None <a id="change">for</a> k in self.label_names)

        if self.onnx_model_path and (has_labels == self.exported_with_loss):
            logger.info("[INFO] Inference with given ONNX model")</code></pre>