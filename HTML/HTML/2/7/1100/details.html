<html><h3>Pattern ID :1100
</h3><img src='5561936.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        y1_grad, y2_grad = grad_outputs
        y1, y2 = Reversible.outputs
        mask = ctx.mask
        x1<a id="change">, x2</a> = ctx.function.reverse(y1, y2, mask)
        Reversible.outputs = (x1, x2)
        with torch.enable_grad():
            if not x1.requires_grad:</code></pre><h3>After Change</h3><pre><code class='java'>
            gy1 = ctx.layer.g_block(y1)
            gy1.backward(y2_grad)

        <a id="change">with torch.no_grad()</a><a id="change">:
            </a>x2<a id="change"> = </a>y2 - gy1
            x1_grad<a id="change"> = </a>y1_grad + y1.grad
            y1.grad<a id="change"> = </a>None

        with torch.enable_grad():
            x2.requires_grad = True</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/rick-mccoy/reformer-pytorch/commit/ba4ca176c189afc7a5ab76d9aea596478ea128a8#diff-e3774f35f62b92bb1d53bca86868831d64cd22450484b63085497e63bb739c16L24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5561936</div><div id='project'> Project Name: rick-mccoy/reformer-pytorch</div><div id='commit'> Commit Name: ba4ca176c189afc7a5ab76d9aea596478ea128a8</div><div id='time'> Time: 2020-01-15</div><div id='author'> Author: rickmccoy3141@gmail.com</div><div id='file'> File Name: model/reversible.py</div><div id='m_class'> M Class Name: Reversible</div><div id='n_method'> N Class Name: Reversible</div><div id='m_method'> M Method Name: backward(1)</div><div id='n_method'> N Method Name: backward(1)</div><div id='m_parent_class'> M Parent Class: Function</div><div id='n_parent_class'> N Parent Class: Function</div><div id='m_file'> M File Name: model/reversible.py</div><div id='n_file'> N File Name: model/reversible.py</div><div id='m_start'> M Start Line: 26</div><div id='m_end'> M End Line: 36</div><div id='n_start'> N Start Line: 24</div><div id='n_end'> N End Line: 49</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    print(&quotmodel loaded&quot)

    dataiter = iter(dataloader)
    images<a id="change">, labels</a> = dataiter.next()

    for i, data in enumerate(dataloader, 0):
        inputs, labels = data</code></pre><h3>After Change</h3><pre><code class='java'>
    total_pred = {classname: 0 for classname in classes}

    &#47&#47 again no gradients needed
    <a id="change">with torch.no_grad()</a><a id="change">:
        </a>for data in dataloader:
            inputs, labels = data
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)    
            _<a id="change">, predictions = </a>torch.max(outputs, 1)
            &#47&#47 collect the correct predictions for each class
            for label, prediction in zip(labels, predictions):
                if label == prediction:
                    correct_pred[classes[label]]<a id="change"> += </a>1
                total_pred[classes[label]]<a id="change"> += </a>1

    
    &#47&#47 print accuracy for each class</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/loretoparisi/hf-experiments/commit/286971f578836b95fec5d7123b3b23cd5fa01603#diff-e18ee566b47545dc43db41d92acbfe58becfa49e56bec72bca5adea1445e53e3L147' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5562133</div><div id='project'> Project Name: loretoparisi/hf-experiments</div><div id='commit'> Commit Name: 286971f578836b95fec5d7123b3b23cd5fa01603</div><div id='time'> Time: 2021-05-11</div><div id='author'> Author: loretoparisi@gmail.com</div><div id='file'> File Name: src/mlpvision/train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test(5)</div><div id='n_method'> N Method Name: test(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/mlpvision/train.py</div><div id='n_file'> N File Name: src/mlpvision/train.py</div><div id='m_start'> M Start Line: 156</div><div id='m_end'> M End Line: 176</div><div id='n_start'> N Start Line: 158</div><div id='n_end'> N End Line: 192</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            queries_per_block = min(L, 1024//k) 
            threads = k * queries_per_block
            blocks = ((L*k)//threads) + C + 1
            query_map = torch.ones((N<a id="change">, H, blocks</a>), dtype=torch.int32).cuda() * L 
            blocks_map = torch.ones((N, H, blocks), dtype=torch.int32).cuda() * -1 
            _, sorted_group_indices = torch.sort(groups, descending=True, dim=-1)
</code></pre><h3>After Change</h3><pre><code class='java'>

        else:
            &#47&#47 Allocate bookkeeping parameters to facilitate the kernel
            <a id="change">with torch.no_grad()</a><a id="change">:
                </a>Q_pb = 16
                block_counts = (counts + Q_pb - 1) // Q_pb
                block_counts = block_counts.int()
                block_counts_cumsum<a id="change"> = </a>block_counts.view(-1).cumsum(-1).view(N, H, C).int()
                indx_maps = torch.ones(
                    (block_counts.sum(), 4),
                    device=Q.device,
                    dtype=torch.int32
                )
                counts_cumsum<a id="change"> = </a>counts.cumsum(-1).int()
                total_blocks<a id="change"> = </a>block_counts.sum().item()

            &#47&#47 Actually perform the dot product
            ClusteredSparseDotProduct.dot[device.type](</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/idiap/fast-transformers/commit/ac1fd6316f59b56faa3b4e9236810d4e97ed5b15#diff-e91bf79b7e2f1026ed509f7acfa914077ef9851d0eb373421f7aa40468c45da4L162' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5562066</div><div id='project'> Project Name: idiap/fast-transformers</div><div id='commit'> Commit Name: ac1fd6316f59b56faa3b4e9236810d4e97ed5b15</div><div id='time'> Time: 2020-11-25</div><div id='author'> Author: avyas@idiap.ch</div><div id='file'> File Name: fast_transformers/sparse_product/__init__.py</div><div id='m_class'> M Class Name: ClusteredSparseDotProduct</div><div id='n_method'> N Class Name: ClusteredSparseDotProduct</div><div id='m_method'> M Method Name: forward(7)</div><div id='n_method'> N Method Name: forward(7)</div><div id='m_parent_class'> M Parent Class: torch.autograd.Function</div><div id='n_parent_class'> N Parent Class: torch.autograd.Function</div><div id='m_file'> M File Name: fast_transformers/sparse_product/__init__.py</div><div id='n_file'> N File Name: fast_transformers/sparse_product/__init__.py</div><div id='m_start'> M Start Line: 185</div><div id='m_end'> M End Line: 201</div><div id='n_start'> N Start Line: 164</div><div id='n_end'> N End Line: 208</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                images = images.view(self.batch_size, -1)
                
                &#47&#47 initialize random noise
                z = torch.rand((self.batch_size<a id="change">, 100</a>))
                
                real_labels = Variable(torch.ones(self.batch_size)).to(self.device)
                fake_labels = Variable(torch.zeros(self.batch_size)).to(self.device)</code></pre><h3>After Change</h3><pre><code class='java'>
                    }
                    self.logger.log_losses(info, generator_iter)

                    <a id="change">with torch.no_grad()</a><a id="change">:
                        </a>fake_images = self.G(z)[:self.number_of_images]
                        real_images<a id="change"> = </a>images[:self.number_of_images]
                        &#47&#47 discriminate real images and fake images
                        fake_labels<a id="change"> = </a>self.D(fake_images).flatten()
                        real_labels<a id="change"> = </a>self.D(images).flatten()

                    info = {
                        &quotreal_images&quot: real_images.cpu().detach().numpy(),</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/luzhixing12345/anime-wgan/commit/0a8816f8a7e456f3393ccf2f0468adecf03b24b3#diff-ca0ad08595f099a7c8f11ccc52a68c596e54243e36367fb089e5b297c7a51bceL39' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5562185</div><div id='project'> Project Name: luzhixing12345/anime-wgan</div><div id='commit'> Commit Name: 0a8816f8a7e456f3393ccf2f0468adecf03b24b3</div><div id='time'> Time: 2022-05-09</div><div id='author'> Author: luzhixing12345@163.com</div><div id='file'> File Name: model/GAN.py</div><div id='m_class'> M Class Name: GAN</div><div id='n_method'> N Class Name: GAN</div><div id='m_method'> M Method Name: train(2)</div><div id='n_method'> N Method Name: train(2)</div><div id='m_parent_class'> M Parent Class: BasicGAN</div><div id='n_parent_class'> N Parent Class: BasicGAN</div><div id='m_file'> M File Name: model/GAN.py</div><div id='n_file'> N File Name: model/GAN.py</div><div id='m_start'> M Start Line: 42</div><div id='m_end'> M End Line: 128</div><div id='n_start'> N Start Line: 113</div><div id='n_end'> N End Line: 199</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        with torch.no_grad():
            model.eval()
            pout = model(feats)
            loss<a id="change">, wer</a> = sb.compute_cost_wer(pout, phn, [wav_len, phn_len])
            losses[&quotloss&quot].append(loss.detach())
            losses[&quotwer&quot].append(wer.detach())
</code></pre><h3>After Change</h3><pre><code class='java'>
                    phn, predictions, stats = losses[&quotwer_stats&quot]
            )
    elif mode == &quottest&quot:
        <a id="change">with torch.no_grad()</a><a id="change">:
            </a>model.eval()
            pout<a id="change"> = </a>model(feats)
            predictions = filter_ctc_output(
                predictions, blank_id=sb.compute_cost.blank_index
            )
            refs<a id="change"> = </a>zip(id, phn)
            hyps<a id="change"> = </a>zip(id, predictions)
            details_by_utt = edit_distance.wer_details_by_utterance(refs, hyps)
            losses[&quotwer_details&quot].extend(details_by_utt)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/4c504abf68fef69963a2fe3bc31386936365e967#diff-cc729d9ec20925028da905dbc287a98ba5a5d665dae4d283ef71f0b47e44741aL55' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5561947</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 4c504abf68fef69963a2fe3bc31386936365e967</div><div id='time'> Time: 2020-04-08</div><div id='author'> Author: aku.rouhe@aalto.fi</div><div id='file'> File Name: recipes/ASR_CTC/TIMIT/VGG2_BLSTM_MLP/experiment.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: neural_computations(6)</div><div id='n_method'> N Method Name: neural_computations(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: recipes/ASR_CTC/TIMIT/VGG2_BLSTM_MLP/experiment.py</div><div id='n_file'> N File Name: recipes/ASR_CTC/TIMIT/VGG2_BLSTM_MLP/experiment.py</div><div id='m_start'> M Start Line: 72</div><div id='m_end'> M End Line: 79</div><div id='n_start'> N Start Line: 61</div><div id='n_end'> N End Line: 102</div><BR>