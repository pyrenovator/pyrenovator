<html><h3>Pattern ID :34352
</h3><img src='98565086.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        q = self.proj_q(q).view(-1, q.size(1), self._head_dims)
        k = self.proj_k(k).view(-1, k.size(1), self._head_dims)
        v = self.proj_v(v).view(-1, <a id="change">v.size(1</a><a id="change">)</a>, self._head_dims)

        att = torch.bmm(q, k.transpose(1, 2)) / self._h_dims**0.5

        if mask is not None:
            mask = torch.where(mask &gt; 0, .0, float(&quot-inf&quot))
            att += mask.repeat_interleave(self._heads, dim=0)

        att = att.softmax(-1)

        if self.dropout is not None:
            att = self.dropout(att)

        m<a id="change"> = </a>torch.bmm(att, v).view(-1, att.size(1), self._h_dims)
        m = self.proj_m(m)

        return m</code></pre><h3>After Change</h3><pre><code class='java'>

        q = self.q(q).view(-1, b, self._head_dims).transpose(0, 1)
        k = self.k(k).view(-1, b, self._head_dims).transpose(0, 1)
        v = <a id="change">self.v(v).view(-1, b, self._head_dims).transpose(0</a>, <a id="change">1</a><a id="change">)</a>

        att = torch.bmm(q, k.transpose(1, 2)) / self._h_dims**0.5

        if mask is not None:
            mask = torch.where(mask &gt; 0, .0, float(&quot-inf&quot))
            mask = mask.repeat_interleave(self._heads, dim=0)
            att += mask.unsqueeze(1).expand(-1, att.size(1), -1)

        att = att.softmax(-1)

        if self.dropout is not None:
            att = self.dropout(att)

        m = torch.bmm(att, v).transpose(0, 1).contiguous()
        m<a id="change"> = </a>self.m(m).view(m.size(0), -1, self._h_dims).transpose(0, 1)

        return m
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/yeliudev/nncore/commit/e58a22da4dce9778c38aae284b0c80d84937b04c#diff-b66764790ba7b310b71bcb990fc01ea802675de40cfbd1e8da361bbc4827b8c3L79' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 98565086</div><div id='project'> Project Name: yeliudev/nncore</div><div id='commit'> Commit Name: e58a22da4dce9778c38aae284b0c80d84937b04c</div><div id='time'> Time: 2021-11-05</div><div id='author'> Author: yeliudev@outlook.com</div><div id='file'> File Name: nncore/nn/blocks/transformer.py</div><div id='m_class'> M Class Name: MultiHeadAttention</div><div id='n_method'> N Class Name: MultiHeadAttention</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: nncore/nn/blocks/transformer.py</div><div id='n_file'> N File Name: nncore/nn/blocks/transformer.py</div><div id='m_start'> M Start Line: 79</div><div id='m_end'> M End Line: 98</div><div id='n_start'> N Start Line: 79</div><div id='n_end'> N End Line: 105</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47        nonpadding: [B, 1, T]
        &#47&#47        cond: [B, C_g, T]
        zs, _ = self.decoder(x=encoded_texts.transpose(1, 2), nonpadding=text_lens, cond=utterance_embedding, infer=False, noise_scale=1.0)  &#47&#47 (B, Lmax, adim)
        before_outs<a id="change"> = </a>self.feat_out(zs).view(<a id="change">zs.size(0</a><a id="change">)</a>, -1, self.odim)  &#47&#47 (B, Lmax, odim)

        &#47&#47 postnet -&gt; (B, Lmax//r * r, odim)
        after_outs = before_outs + self.post_flow(before_outs.transpose(1, 2)).transpose(1, 2)</code></pre><h3>After Change</h3><pre><code class='java'>
            if not use_posterior:
                z = torch.randn_like(z)

        before_outs = <a id="change">self.decoder.decoder(z, nonpadding=speech_lens, cond=encoded_texts).transpose(1</a>, <a id="change">2</a><a id="change">)</a>

        &#47&#47 forward flow post-net
        if run_glow:
            after_outs = before_outs + self.post_flow(before_outs.transpose(1, 2)).transpose(1, 2)  &#47&#47 postnet -&gt; (B, Lmax, odim)
        else:
            after_outs<a id="change"> = </a>before_outs

        if not is_inference:
            return before_outs, after_outs, predicted_durations, pitch_predictions, energy_predictions, kl_loss</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/1f6ef3294b6593510f03bf07885afb4754888c42#diff-12643f5b2c8b9a82605c22c3f362317aa32afc7f0c07d080244ac4cefb2f5794L244' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 98565007</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 1f6ef3294b6593510f03bf07885afb4754888c42</div><div id='time'> Time: 2022-11-29</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/PortaSpeech/PortaSpeech.py</div><div id='m_class'> M Class Name: PortaSpeech</div><div id='n_method'> N Class Name: PortaSpeech</div><div id='m_method'> M Method Name: _forward(14)</div><div id='n_method'> N Method Name: _forward(12)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module,ABC</div><div id='n_parent_class'> N Parent Class: torch.nn.Module,ABC</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/PortaSpeech/PortaSpeech.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/PortaSpeech/PortaSpeech.py</div><div id='m_start'> M Start Line: 303</div><div id='m_end'> M End Line: 309</div><div id='n_start'> N Start Line: 258</div><div id='n_end'> N End Line: 330</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        key_states = key_states.view(*proj_shape)
        value_states = value_states.view(*proj_shape)

        src_len<a id="change"> = </a><a id="change">key_states.size(1</a><a id="change">)</a>
        attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))

        &#47&#47 q_t is [batch, seq_length, n_heads, dim_per_head]
        import ipdb; ipdb.set_trace()</code></pre><h3>After Change</h3><pre><code class='java'>
        src_len = key_states.size(2)

        &#47&#47 compute scores
        attn_weights<a id="change"> = </a>torch.matmul(
            query_states, <a id="change">key_states.transpose(3</a>, <a id="change">2</a><a id="change">)</a>
        )  &#47&#47 equivalent of torch.einsum("bnqd,bnkd-&gt;bnqk", query_states, key_states), compatible with onnx op&gt;9

        &#47&#47 q_t is [batch, seq_length, n_heads, dim_per_head]
        q_t = query_states.permute(0, 2, 1, 3)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/joaolages/ratransformers/commit/87d3c27f618c060b396039f71734d515d3343a4b#diff-3bc988b93d619436305f06eadc62abd2469ae4a8ee0a636980fcd5202ebeee6fL18' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 98565213</div><div id='project'> Project Name: joaolages/ratransformers</div><div id='commit'> Commit Name: 87d3c27f618c060b396039f71734d515d3343a4b</div><div id='time'> Time: 2022-02-11</div><div id='author'> Author: joaop.glages@gmail.com</div><div id='file'> File Name: src/ratransformers/bart.py</div><div id='m_class'> M Class Name: BartRelationalAttention</div><div id='n_method'> N Class Name: BartRelationalAttention</div><div id='m_method'> M Method Name: forward(7)</div><div id='n_method'> N Method Name: forward(7)</div><div id='m_parent_class'> M Parent Class: BartAttention</div><div id='n_parent_class'> N Parent Class: BartAttention</div><div id='m_file'> M File Name: src/ratransformers/bart.py</div><div id='n_file'> N File Name: src/ratransformers/bart.py</div><div id='m_start'> M Start Line: 43</div><div id='m_end'> M End Line: 138</div><div id='n_start'> N Start Line: 43</div><div id='n_end'> N End Line: 139</div><BR>