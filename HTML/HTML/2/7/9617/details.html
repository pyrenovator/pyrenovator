<html><h3>Pattern ID :9617
</h3><img src='34720656.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    for idx, token in enumerate(tokens):
        merge_idxs.append(idx)

        <a id="change">if </a>&quot&lt;/w&gt;&quot in token:
            curr_token<a id="change"> += </a>token[:-4]

            if idx &gt;= word_idx and curr_token == word:
                <a id="change">break</a>

            curr_token = &quot&quot
            curr_idx<a id="change"> += </a>1
            merge_idxs.clear()
        else:
            curr_token += token</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 merge together all tokens in the word
            return [first_pos + i + offset_idx for i in range(0, token_len)]

        <a id="change">for </a>idx, w_token in <a id="change">enumerate(</a>word_tokens<a id="change">):
            &#47&#47 if the word contains more than one token
            </a>if len(w_token) &gt; len(search_tokens):
                &#47&#47 check to see if the extra tokens were from punctuation
                no_punc = [t for t in w_token if t not in punc_tokens]
                search_no_punc = [t for t in search_tokens if t not in punc_tokens]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/castorini/daam/commit/854e6ddfdae1781009b31b66b2d5bb15d852fccf#diff-ea4e615a144dec76002186f2cde018c58e9a14487f738b334af1572531829aaeL53' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 34720656</div><div id='project'> Project Name: castorini/daam</div><div id='commit'> Commit Name: 854e6ddfdae1781009b31b66b2d5bb15d852fccf</div><div id='time'> Time: 2022-12-08</div><div id='author'> Author: alotofcatz@gmail.com</div><div id='file'> File Name: daam/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: compute_token_merge_indices(5)</div><div id='n_method'> N Method Name: compute_token_merge_indices(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: daam/utils.py</div><div id='n_file'> N File Name: daam/utils.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 90</div><div id='n_start'> N Start Line: 54</div><div id='n_end'> N End Line: 91</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if word_idx is None:
        raise ValueError(f&quotCouldn\&quott find "{word}" in "{prompt}"&quot)

    for idx, <a id="change">token</a> in enumerate(tokens):
        merge_idxs.append(idx)

        if &quot&lt;/w&gt;&quot in token:
            curr_token += token[:-4]

            <a id="change">if </a>idx &gt;= word_idx and curr_token == word:
                <a id="change">break</a>

            curr_token<a id="change"> = </a>&quot&quot
            curr_idx<a id="change"> += </a>1
            merge_idxs.clear()
        else:
            curr_token += token</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 merge together all tokens in the word
            return [first_pos + i + offset_idx for i in range(0, token_len)]

        <a id="change">for </a>idx, w_token in <a id="change">enumerate(</a>word_tokens<a id="change">):
            &#47&#47 if the word contains more than one token
            </a>if len(w_token) &gt; len(search_tokens):
                &#47&#47 check to see if the extra tokens were from punctuation
                no_punc = [t for t in w_token if t not in punc_tokens]
                search_no_punc = [t for t in search_tokens if t not in punc_tokens]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/castorini/daam/commit/854e6ddfdae1781009b31b66b2d5bb15d852fccf#diff-ea4e615a144dec76002186f2cde018c58e9a14487f738b334af1572531829aaeL52' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 34720691</div><div id='project'> Project Name: castorini/daam</div><div id='commit'> Commit Name: 854e6ddfdae1781009b31b66b2d5bb15d852fccf</div><div id='time'> Time: 2022-12-08</div><div id='author'> Author: alotofcatz@gmail.com</div><div id='file'> File Name: daam/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: compute_token_merge_indices(5)</div><div id='n_method'> N Method Name: compute_token_merge_indices(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: daam/utils.py</div><div id='n_file'> N File Name: daam/utils.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 90</div><div id='n_start'> N Start Line: 54</div><div id='n_end'> N End Line: 91</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        confidences_indices_sorted = torch.argsort(
            word.token_confidences[label_index], dim=-1, descending=True
        )
        for <a id="change">confidence_index</a> in confidences_indices_sorted:
            confidence_val: float = word.token_confidences[label_index][confidence_index].item()
            <a id="change">if </a>self.threshold is not None:
                if confidence_val &gt; self.threshold:
                    bio_label = self.id2label[confidence_index.item()]
                    if bio_label == ENTITY_OUTSIDE_SYMBOL:
                        yield bio_label, None, confidence_val
                    else:
                        bio_label<a id="change">, class_label = </a>bio_label.split("-")
                        yield bio_label, class_label, confidence_val
                else:
                    break
            else:
                bio_label<a id="change"> = </a>self.id2label[confidence_index.item()]
                if bio_label == ENTITY_OUTSIDE_SYMBOL:
                    yield bio_label, None, confidence_val
                else:
                    bio_label, class_label = bio_label.split("-")
                    yield bio_label, class_label, confidence_val
                <a id="change">break</a>

    def span_continue_condition(
        self, word: TokenizedWord, bio_and_class_labels: Set[Tuple[str, Optional[str]]]
    ):</code></pre><h3>After Change</h3><pre><code class='java'>
        bio_and_class_labels: Set[Tuple[str, Optional[str]]] = set()
        token_confidences_sorted = torch.argsort(word.token_confidences, dim=1, descending=True)

        <a id="change">for </a>i, token_confidence_indices in <a id="change">enumerate(</a>token_confidences_sorted<a id="change">):
            </a>for confidence_index in token_confidence_indices:
                confidence_val: float = word.token_confidences[i][confidence_index].item()
                if confidence_val &gt; self.threshold:
                    bio_label = self.id2label[confidence_index.item()]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/astrazeneca/kazu/commit/422eb2bceb9b3988a63113d66d19b1298220cec1#diff-1ed01e16084b465052b00a2921f81152aeb1492e7e29cf6f1f8b12775c2e45cfL278' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 34720675</div><div id='project'> Project Name: astrazeneca/kazu</div><div id='commit'> Commit Name: 422eb2bceb9b3988a63113d66d19b1298220cec1</div><div id='time'> Time: 2022-11-30</div><div id='author'> Author: richard.jackson4@astrazeneca.com</div><div id='file'> File Name: kazu/steps/ner/tokenized_word_processor.py</div><div id='m_class'> M Class Name: SmartSpanFinder</div><div id='n_method'> N Class Name: SmartSpanFinder</div><div id='m_method'> M Method Name: get_labels(2)</div><div id='n_method'> N Method Name: get_labels(3)</div><div id='m_parent_class'> M Parent Class: SpanFinder</div><div id='n_parent_class'> N Parent Class: SpanFinder</div><div id='m_file'> M File Name: kazu/steps/ner/tokenized_word_processor.py</div><div id='n_file'> N File Name: kazu/steps/ner/tokenized_word_processor.py</div><div id='m_start'> M Start Line: 279</div><div id='m_end'> M End Line: 312</div><div id='n_start'> N Start Line: 246</div><div id='n_end'> N End Line: 272</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                        heuristic_count += 1
                        continue
                    should_skip = False
                    for <a id="change">q</a> in quote_values:
                        <a id="change">if </a>q not in all_input_columns:
                            heuristic_count<a id="change"> += </a>1
                            should_skip<a id="change"> = </a>True
                            <a id="change">break</a>
                    if should_skip:
                        continue
                if args.remove_duplicates:
                    normalized_example = re.sub(&quot\s+&quot, &quot&quot, &quot&quot.join([o[i] for i in args.no_duplication_columns]))</code></pre><h3>After Change</h3><pre><code class='java'>
            with open(args.thrown_away, &quotw&quot) as output_file:
                for o in all_thrown_away_rows:
                    output_row = ""
                    <a id="change">for </a>i, column in <a id="change">enumerate(</a>args.output_columns<a id="change">):
                        </a>output_row += o[column]
                        if i &lt; len(args.output_columns)-1:
                            output_row += &quot\t&quot
                    output_file.write(output_row + &quot\n&quot)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/d2eacd4e5c5347cb45907aea9e0a81a54b9fd5bf#diff-ee119052413383bfd6476efcd585c7782e225b9afadedd52e593204c70c2e120L15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 34720695</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: d2eacd4e5c5347cb45907aea9e0a81a54b9fd5bf</div><div id='time'> Time: 2020-05-26</div><div id='author'> Author: s.j.semnani@gmail.com</div><div id='file'> File Name: genienlp/paraphrase/scripts/transform_dataset.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: genienlp/paraphrase/scripts/transform_dataset.py</div><div id='n_file'> N File Name: genienlp/paraphrase/scripts/transform_dataset.py</div><div id='m_start'> M Start Line: 55</div><div id='m_end'> M End Line: 162</div><div id='n_start'> N Start Line: 31</div><div id='n_end'> N End Line: 196</div><BR>