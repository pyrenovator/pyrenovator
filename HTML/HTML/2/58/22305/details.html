<html><h3>Pattern ID :22305
</h3><img src='70346311.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

def adagrad(parameters):
    &#47&#47 pick defaults
    <a id="change">if not ("lr_decay" in parameters["optimizer"])</a>:
        <a id="change">parameters["optimizer"]["lr_decay"]</a><a id="change"> = 0</a>
    <a id="change">if not ("eps" in parameters["optimizer"])</a>:
        <a id="change">parameters["optimizer"]["eps"]</a><a id="change"> = 1e-6</a>
    <a id="change">if not ("weight_decay" in parameters["optimizer"])</a>:
        <a id="change">parameters["optimizer"]["weight_decay"]</a><a id="change"> = 0</a>

    <a id="change">return </a>Adagrad(
        <a id="change">parameters["model_parameters"]</a>,
        lr=parameters["learning_rate"],
        lr_decay=parameters["optimizer"]["lr_decay"],
        eps=parameters["optimizer"]["eps"],</code></pre><h3>After Change</h3><pre><code class='java'>

    
    &#47&#47 Set default values for optimizer parameters
    <a id="change">optimizer_params = parameters</a><a id="change">.get("optimizer"</a>, <a id="change">{})</a>
    lr_decay<a id="change"> = optimizer_params</a><a id="change">.get("lr_decay"</a>, <a id="change">0</a><a id="change">)</a>
    eps<a id="change"> = optimizer_params</a><a id="change">.get("eps"</a>, <a id="change">1e-6</a><a id="change">)</a>
    weight_decay<a id="change"> = optimizer_params</a><a id="change">.get("weight_decay"</a>, <a id="change">0</a><a id="change">)</a>
    
    &#47&#47 Create the optimizer using the input parameters
    return Adagrad(
        <a id="change">parameters["model_parameters"]</a>,
        lr=parameters.get("learning_rate"),
        lr_decay=lr_decay,
        eps=eps,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 42</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/cbica/gandlf/commit/bdc3fca6c47a77b03e92039928ba7d77a3b09057#diff-5085c3f8ae5e11fa9c8d71e95bf35b4a0ef05bb8245bedfd7ff03fcfdfb4dc22L149' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70346311</div><div id='project'> Project Name: cbica/gandlf</div><div id='commit'> Commit Name: bdc3fca6c47a77b03e92039928ba7d77a3b09057</div><div id='time'> Time: 2023-04-24</div><div id='author'> Author: sid.cre8er@gmail.com</div><div id='file'> File Name: GANDLF/optimizers/wrap_torch.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: adagrad(1)</div><div id='n_method'> N Method Name: adagrad(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: GANDLF/optimizers/wrap_torch.py</div><div id='n_file'> N File Name: GANDLF/optimizers/wrap_torch.py</div><div id='m_start'> M Start Line: 149</div><div id='m_end'> M End Line: 162</div><div id='n_start'> N Start Line: 232</div><div id='n_end'> N End Line: 244</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

def adagrad(parameters):
    &#47&#47 pick defaults
    <a id="change">if not ("lr_decay" in parameters["optimizer"])</a>:
        <a id="change">parameters["optimizer"]["lr_decay"]</a><a id="change"> = 0</a>
    <a id="change">if not ("eps" in parameters["optimizer"])</a>:
        <a id="change">parameters["optimizer"]["eps"]</a><a id="change"> = 1e-6</a>
    <a id="change">if not ("weight_decay" in parameters["optimizer"])</a>:
        <a id="change">parameters["optimizer"]["weight_decay"]</a><a id="change"> = 0</a>

    <a id="change">return </a>Adagrad(
        <a id="change">parameters["model_parameters"]</a>,
        lr=parameters["learning_rate"],
        lr_decay=parameters["optimizer"]["lr_decay"],
        eps=parameters["optimizer"]["eps"],</code></pre><h3>After Change</h3><pre><code class='java'>

    
    &#47&#47 Set default values for optimizer parameters
    <a id="change">optimizer_params = </a><a id="change">parameters.get("optimizer"</a>, <a id="change">{})</a>
    lr_decay<a id="change"> = </a><a id="change">optimizer_params.get("lr_decay"</a>, <a id="change">0</a><a id="change">)</a>
    eps<a id="change"> = </a><a id="change">optimizer_params.get("eps"</a>, <a id="change">1e-6</a><a id="change">)</a>
    weight_decay<a id="change"> = </a><a id="change">optimizer_params.get("weight_decay"</a>, <a id="change">0</a><a id="change">)</a>
    
    &#47&#47 Create the optimizer using the input parameters
    return Adagrad(
        <a id="change">parameters["model_parameters"]</a>,
        lr=parameters.get("learning_rate"),
        lr_decay=lr_decay,
        eps=eps,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mlcommons/gandlf/commit/bdc3fca6c47a77b03e92039928ba7d77a3b09057#diff-5085c3f8ae5e11fa9c8d71e95bf35b4a0ef05bb8245bedfd7ff03fcfdfb4dc22L147' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70346310</div><div id='project'> Project Name: mlcommons/gandlf</div><div id='commit'> Commit Name: bdc3fca6c47a77b03e92039928ba7d77a3b09057</div><div id='time'> Time: 2023-04-24</div><div id='author'> Author: sid.cre8er@gmail.com</div><div id='file'> File Name: GANDLF/optimizers/wrap_torch.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: adagrad(1)</div><div id='n_method'> N Method Name: adagrad(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: GANDLF/optimizers/wrap_torch.py</div><div id='n_file'> N File Name: GANDLF/optimizers/wrap_torch.py</div><div id='m_start'> M Start Line: 149</div><div id='m_end'> M End Line: 162</div><div id='n_start'> N Start Line: 232</div><div id='n_end'> N End Line: 244</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

def rmsprop(parameters):
    &#47&#47 pick defaults
    <a id="change">if not ("momentum" in parameters["optimizer"])</a>:
        <a id="change">parameters["optimizer"]["momentum"]</a><a id="change"> = 0</a>
    if not ("weight_decay" in parameters["optimizer"]):
        parameters["optimizer"]["weight_decay"] = 0
    <a id="change">if not ("alpha" in parameters["optimizer"])</a>:
        <a id="change">parameters["optimizer"]["alpha"]</a><a id="change"> = 0.99</a>
    <a id="change">if not ("eps" in parameters["optimizer"])</a>:
        <a id="change">parameters["optimizer"]["eps"]</a><a id="change"> = 1e-8</a>
    if not ("centered" in parameters["optimizer"]):
        parameters["optimizer"]["centered"] = False

    <a id="change">return </a>RMSprop(
        <a id="change">parameters["model_parameters"]</a>,
        lr=parameters["learning_rate"],
        alpha=parameters["optimizer"]["alpha"],
        eps=parameters["optimizer"]["eps"],</code></pre><h3>After Change</h3><pre><code class='java'>

    
    &#47&#47 Set default values for optimizer parameters
    <a id="change">optimizer_params = </a><a id="change">parameters.get("optimizer"</a>, <a id="change">{})</a>
    momentum<a id="change"> = </a><a id="change">optimizer_params.get("momentum"</a>, <a id="change">0</a><a id="change">)</a>
    weight_decay = optimizer_params.get("weight_decay", 0)
    alpha<a id="change"> = </a><a id="change">optimizer_params.get("alpha"</a>, <a id="change">0.99</a><a id="change">)</a>
    eps<a id="change"> = </a><a id="change">optimizer_params.get("eps"</a>, <a id="change">1e-8</a><a id="change">)</a>
    centered = optimizer_params.get("centered", False)
    
    &#47&#47 Create the optimizer using the input parameters
    return RMSprop(
        <a id="change">parameters["model_parameters"]</a>,
        lr=parameters.get("learning_rate"),
        alpha=alpha,
        eps=eps,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mlcommons/gandlf/commit/bdc3fca6c47a77b03e92039928ba7d77a3b09057#diff-5085c3f8ae5e11fa9c8d71e95bf35b4a0ef05bb8245bedfd7ff03fcfdfb4dc22L165' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70346312</div><div id='project'> Project Name: mlcommons/gandlf</div><div id='commit'> Commit Name: bdc3fca6c47a77b03e92039928ba7d77a3b09057</div><div id='time'> Time: 2023-04-24</div><div id='author'> Author: sid.cre8er@gmail.com</div><div id='file'> File Name: GANDLF/optimizers/wrap_torch.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: rmsprop(1)</div><div id='n_method'> N Method Name: rmsprop(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: GANDLF/optimizers/wrap_torch.py</div><div id='n_file'> N File Name: GANDLF/optimizers/wrap_torch.py</div><div id='m_start'> M Start Line: 167</div><div id='m_end'> M End Line: 186</div><div id='n_start'> N Start Line: 259</div><div id='n_end'> N End Line: 275</div><BR>