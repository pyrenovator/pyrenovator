<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        with torch.no_grad():
            if args.mlm:
                outputs = <a id="change">model(</a>inputs<a id="change">, masked_lm_labels=labels, position_ids=position_ids, token_type_ids=segment_ids)</a>
            else:
                if args.model_type == &quotbart&quot:
                    decoder_input_ids = labels[:, :-1].contiguous()
                    decoder_input_ids[decoder_input_ids == args.mlm_ignore_index] = tokenizer.pad_token_id</code></pre><h3>After Change</h3><pre><code class='java'>
            
            &#47&#47 Same behavior as modeling_bart.py, besides ignoring pad_token_id
            ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=args.mlm_ignore_index)
            loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), <a id="change">labels.view(-1</a><a id="change">)</a>)
            eval_loss += loss.mean().item()
            
        nb_eval_steps += 1</code></pre>