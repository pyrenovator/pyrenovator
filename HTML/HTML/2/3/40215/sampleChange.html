<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
      a = nn.Softmax()(outs)
    for ii in range(len(outs)):
      total += 1
      if outs[ii].tolist().index(max(<a id="change">outs[ii]</a>)) == y_batch[ii]:
        correct += 1
      pts.append([a[ii][1], y_batch[ii]])
  print((float(correct)/total))</code></pre><h3>After Change</h3><pre><code class='java'>

def test_MFM(model, test_dataloader, auprc=False, task="classification"):
  pred=[]
  true=<a id="change">[]</a>
  pts = []
  for j in test_dataloader:
    xes = [x.float().cuda() for x in j[:-1]]
    y_batch = j[-1].cuda()
    with torch.no_grad():
      _, outs = model(xes, training=False)
      if task=="classification":
        a = nn.Softmax()(outs)
    for ii in range(len(outs)):
      pts.append([a[ii][1], y_batch[ii]])
    if task == "classification":
      pred.append(torch.argmax(outs, 1))
    elif task == "multilabel":
      pred.append(torch.sigmoid(outs).round())
    true.append(j[-1])
  if pred:
    pred = torch.cat(pred, 0).cpu().numpy()
  true = torch.cat(true, 0).cpu().numpy()
  if auprc:
    print(AUPRC(pts))
  if task == "classification":
    print("acc: "+str(accuracy_score(true, pred)))
    return <a id="change">accuracy_score(</a>true, pred<a id="change">)</a>
  elif task == "multilabel":
    print(" f1_micro: "+str(f1_score(true, pred, average="micro"))+\
        " f1_macro: "+str(f1_score(true, pred, average="macro")))
    return f1_score(true, pred, average="micro"), f1_score(true, pred, average="macro")</code></pre>