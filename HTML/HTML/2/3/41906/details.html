<html><h3>Pattern ID :41906
</h3><img src='117455459.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    @staticmethod
    def _single_calc(fn_input, sequence_input, linear_param):
        out = fn_input - fn_input.mean(dim=0, keepdim=True)
        out0<a id="change">, out1</a> = torch.nn.functional.linear(torch.cat([out, sequence_input], 1),
                                                      linear_param,
                                                      None).chunk(2, 1)
        return torch.sigmoid(out0) * out1.tanh()</code></pre><h3>After Change</h3><pre><code class='java'>
        out = fn_input - fn_input.mean(dim=0, keepdim=True)
        features = out.size(1)
        out = torch.mm(out, linear_param[:features]) + torch.mm(sequence_input, linear_param[features:])
        return torch.nn.functional.relu6(out[:, :features])<a id="change"> * </a><a id="change">out[:, features:].tanh()</a>

    @staticmethod
    def _calc(fn_input, sequence_input, linear_param, depth):
        out = fn_input</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/homebrewnlp/homebrewnlp/commit/2c4b92319ccca8f3a6f7c2677b9f0fbf88f7b8db#diff-c98bba8dbdd18eb4e9fa8ae11c28e350c08ee816fce50f9fb86d61cbcd345276L7' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117455459</div><div id='project'> Project Name: homebrewnlp/homebrewnlp</div><div id='commit'> Commit Name: 2c4b92319ccca8f3a6f7c2677b9f0fbf88f7b8db</div><div id='time'> Time: 2020-08-05</div><div id='author'> Author: 39779310+ClashLuke@users.noreply.github.com</div><div id='file'> File Name: module.py</div><div id='m_class'> M Class Name: ReversibleRNNFunction</div><div id='n_method'> N Class Name: ReversibleRNNFunction</div><div id='m_method'> M Method Name: _single_calc(3)</div><div id='n_method'> N Method Name: _single_calc(3)</div><div id='m_parent_class'> M Parent Class: torch.autograd.Function</div><div id='n_parent_class'> N Parent Class: torch.autograd.Function</div><div id='m_file'> M File Name: module.py</div><div id='n_file'> N File Name: module.py</div><div id='m_start'> M Start Line: 8</div><div id='m_end'> M End Line: 12</div><div id='n_start'> N Start Line: 7</div><div id='n_end'> N End Line: 10</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        weight = torch.nn.functional.relu6(out1)
        out0 = out0 * weight
        print("C", out0.mean().item(), weight.mean().item())
        return out0<a id="change">, weight + 1</a>

    @staticmethod
    def _forward_pass(fn_input, sequence_input, linear_param0, linear_param1):
        inp = fn_input.chunk(2, 1)</code></pre><h3>After Change</h3><pre><code class='java'>
        out0, out1 = torch.nn.functional.linear(torch.cat([out, sequence_input], 1),
                                                linear_param,
                                                None).chunk(2, 1)
        return torch.nn.functional.relu6(out0)<a id="change"> * </a><a id="change">out1.tanh()</a>

    @staticmethod
    def _forward_pass(fn_input, sequence_input, linear_param0, linear_param1):
        inp = fn_input.chunk(2, 1)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/homebrewnlp/homebrewnlp/commit/50b0a36baa2c79ddc7d5f1fb6ef2e9d39988c1c4#diff-c98bba8dbdd18eb4e9fa8ae11c28e350c08ee816fce50f9fb86d61cbcd345276L35' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117455460</div><div id='project'> Project Name: homebrewnlp/homebrewnlp</div><div id='commit'> Commit Name: 50b0a36baa2c79ddc7d5f1fb6ef2e9d39988c1c4</div><div id='time'> Time: 2020-07-16</div><div id='author'> Author: 39779310+ClashLuke@users.noreply.github.com</div><div id='file'> File Name: module.py</div><div id='m_class'> M Class Name: ReversibleRNNFunction</div><div id='n_method'> N Class Name: ReversibleRNNFunction</div><div id='m_method'> M Method Name: _calc(3)</div><div id='n_method'> N Method Name: _calc(3)</div><div id='m_parent_class'> M Parent Class: torch.autograd.Function</div><div id='n_parent_class'> N Parent Class: torch.autograd.Function</div><div id='m_file'> M File Name: module.py</div><div id='n_file'> N File Name: module.py</div><div id='m_start'> M Start Line: 38</div><div id='m_end'> M End Line: 45</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 42</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        embedding = self.dropout(self.embed(x))
        conv_in = embedding.permute(0, 2, 1)
        conv_out = self.conv(conv_in)
        values<a id="change">, indices</a> = conv_out.max(dim=-1)
        conv_out = conv_out.permute(2, 0, 1)
        rnn_out, _ = self.rnn(conv_out)
        attention = (self.mask * rnn_out).mean(dim=0)</code></pre><h3>After Change</h3><pre><code class='java'>
        conv_out = self.conv(conv_in).permute(2, 0, 1)
        rnn_out, _ = self.rnn(conv_out)
        global_rnn_out = rnn_out.mean(dim=0)
        attention = <a id="change">torch.tanh(
            </a>self.local2attn(rnn_out) + self.global2attn(global_rnn_out)<a id="change">
        )</a>.permute(1, 0, 2)
        alpha = F.softmax(attention.matmul(self.attn_scale), dim=-1)
        rnn_out = rnn_out.permute(1, 0, 2)
        memory = (alpha<a id="change"> * </a>rnn_out).sum(dim=1)
        output = self.fc(memory).squeeze(1)
        return output
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jaketae/deep-malware-detection/commit/e2f5ae102005c60e7e0db3dc31a8d9c23fce276b#diff-dcfeaa5ac3dffd54264034760914588d92fc7395c81eaa9274715840dc28100bL185' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117455465</div><div id='project'> Project Name: jaketae/deep-malware-detection</div><div id='commit'> Commit Name: e2f5ae102005c60e7e0db3dc31a8d9c23fce276b</div><div id='time'> Time: 2020-11-26</div><div id='author'> Author: jaesungtae@gmail.com</div><div id='file'> File Name: models.py</div><div id='m_class'> M Class Name: AttentionRCNN</div><div id='n_method'> N Class Name: AttentionRCNN</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models.py</div><div id='n_file'> N File Name: models.py</div><div id='m_start'> M Start Line: 186</div><div id='m_end'> M End Line: 194</div><div id='n_start'> N Start Line: 196</div><div id='n_end'> N End Line: 206</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        action = action.tanh()

        return action<a id="change">, std</a>


if __name__ == &quot__main__&quot:
    use_cuda = torch.cuda.is_available()</code></pre><h3>After Change</h3><pre><code class='java'>
            log_prob = m.log_prob(action_base)
            log_prob.unsqueeze_(-1)

            action = <a id="change">action_base.tanh()</a>

            &#47&#47 According to "Soft Actor-Critic" (Haarnoja et. al) Appendix C
            action_bound_compensation = torch.log(1.<a id="change"> - action.tanh().pow(2) + </a>1e-6)
            action_bound_compensation = action_bound_compensation.sum(dim=-1, keepdim=True)
            log_prob.sub_(action_bound_compensation)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tmdt-buw/karolos/commit/e8ce439013ace3e3e9647de55ed22ddf38f35396#diff-29037086e0dfbb6a2262a556dce65661316ec86ddf4f52bf9de230586208ab9dL95' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117455469</div><div id='project'> Project Name: tmdt-buw/karolos</div><div id='commit'> Commit Name: e8ce439013ace3e3e9647de55ed22ddf38f35396</div><div id='time'> Time: 2020-04-23</div><div id='author'> Author: scheiderer@uni-wuppertal.de</div><div id='file'> File Name: agents/nnfactory/sac.py</div><div id='m_class'> M Class Name: Policy</div><div id='n_method'> N Class Name: Policy</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: agents/nnfactory/sac.py</div><div id='n_file'> N File Name: agents/nnfactory/sac.py</div><div id='m_start'> M Start Line: 103</div><div id='m_end'> M End Line: 115</div><div id='n_start'> N Start Line: 104</div><div id='n_end'> N End Line: 123</div><BR>