<html><h3>Pattern ID :24140
</h3><img src='74894134.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            if self.use_ema:
                self.ema_unets.append(EMA(unet, **ema_kwargs))

            scaler<a id="change"> = </a><a id="change">GradScaler(enabled = amp)</a>
            setattr(self, f&quotscaler{ind}&quot, scaler)

            scheduler = warmup_scheduler = None
</code></pre><h3>After Change</h3><pre><code class='java'>

        assert not (not self.single_gpu and not exists(only_train_unet_number)), &quotyou must set `only_train_unet_number` on your trainer class in a distributed environment, to make sure only one unet is trained at a time - this will be enforced automatically if not set&quot

        <a id="change">assert </a>self.single_gpu, &quotonly single gpu training is allowed at this time&quot

        &#47&#47 grad scaler must be managed outside of accelerator
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/5e2b82badff93a7feedffa07650a9499c7f86fc6#diff-db403ff86c6fb0812b3ce92a98fb7d76cc888c28dfa3e0a5421bde05febd47bbL185' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74894134</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: 5e2b82badff93a7feedffa07650a9499c7f86fc6</div><div id='time'> Time: 2022-07-12</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/trainer.py</div><div id='m_class'> M Class Name: ImagenTrainer</div><div id='n_method'> N Class Name: ImagenTrainer</div><div id='m_method'> M Method Name: __init__(18)</div><div id='n_method'> N Method Name: __init__(16)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imagen_pytorch/trainer.py</div><div id='n_file'> N File Name: imagen_pytorch/trainer.py</div><div id='m_start'> M Start Line: 185</div><div id='m_end'> M End Line: 264</div><div id='n_start'> N Start Line: 193</div><div id='n_end'> N End Line: 303</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        self.amp = amp

        self.scaler<a id="change"> = </a><a id="change">GradScaler(enabled = amp)</a>

        self.optim_kwargs = dict(lr=lr, wd=wd, eps=eps, group_wd_params=group_wd_params)

        self.optimizer = get_optimizer(</code></pre><h3>After Change</h3><pre><code class='java'>
                "no": torch.float
            }
            precision_type = cast_type_map[accelerator.mixed_precision]
            <a id="change">assert </a>precision_type == torch.float, "DeepSpeed currently only supports float32 precision when using on the fly embedding generation from clip"
            self.diffusion_prior.clip.to(precision_type)

        &#47&#47 optimizer stuff</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/f9423d308b6f36e51152c2c45045ff4ebb308287#diff-617450527162fa367141dbf45e8b201673573479820af0ffc56ba93b7f70947fL174' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74894135</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: f9423d308b6f36e51152c2c45045ff4ebb308287</div><div id='time'> Time: 2022-07-20</div><div id='author'> Author: 51308183+nousr@users.noreply.github.com</div><div id='file'> File Name: dalle2_pytorch/trainer.py</div><div id='m_class'> M Class Name: DiffusionPriorTrainer</div><div id='n_method'> N Class Name: DiffusionPriorTrainer</div><div id='m_method'> M Method Name: __init__(10)</div><div id='n_method'> N Method Name: __init__(12)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dalle2_pytorch/trainer.py</div><div id='n_file'> N File Name: dalle2_pytorch/trainer.py</div><div id='m_start'> M Start Line: 182</div><div id='m_end'> M End Line: 240</div><div id='n_start'> N Start Line: 177</div><div id='n_end'> N End Line: 246</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.step = 0

        self.amp = amp
        self.scaler<a id="change"> = </a><a id="change">GradScaler(enabled = amp)</a>

        self.results_folder = Path(results_folder)
        self.results_folder.mkdir(exist_ok = True)
</code></pre><h3>After Change</h3><pre><code class='java'>

        self.model = diffusion_model

        <a id="change">assert </a>has_int_squareroot(num_samples), &quotnumber of samples must have an integer square root&quot
        self.num_samples = num_samples
        self.save_and_sample_every = save_and_sample_every
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/denoising-diffusion-pytorch/commit/6b56af08a27e0601f5ac9bf74707ab0b24911b86#diff-1ef0846017d5c27bd277b66e5afcab8798667afd39675e6f9382fc7e87a1fe28L590' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74894136</div><div id='project'> Project Name: lucidrains/denoising-diffusion-pytorch</div><div id='commit'> Commit Name: 6b56af08a27e0601f5ac9bf74707ab0b24911b86</div><div id='time'> Time: 2022-07-06</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: denoising_diffusion_pytorch/denoising_diffusion_pytorch.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: denoising_diffusion_pytorch/denoising_diffusion_pytorch.py</div><div id='n_file'> N File Name: denoising_diffusion_pytorch/denoising_diffusion_pytorch.py</div><div id='m_start'> M Start Line: 608</div><div id='m_end'> M End Line: 631</div><div id='n_start'> N Start Line: 629</div><div id='n_end'> N End Line: 673</div><BR>