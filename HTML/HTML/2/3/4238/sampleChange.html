<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 State initialization
        for pg in self.optimizer.param_groups:
            for p in <a id="change">pg[&quotparams&quot]</a>:
                state = self.optimizer.state[p]
                if len(state) == 0:
                    state[&quotexp_avg&quot] = torch.zeros_like(</code></pre><h3>After Change</h3><pre><code class='java'>
                 from_grad=True):
         Apply Gap Aware on computed gradients 
        super().__init__(optimizer)
        self.running_avg_step = <a id="change">init_running_avg_step(</a>optimizer<a id="change">)</a>
        adam_init(optimizer)

        &#47&#47     &#47&#47 TODO: sched aware LR.
</code></pre>