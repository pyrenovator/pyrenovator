<html><h3>Pattern ID :12530
</h3><img src='42501768.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def __init__(self, num_classes, hidden_dim, nheads, num_encoder_layers):
        super().__init__()

        self.pos_encoding<a id="change"> = </a><a id="change">PositionalEncoding(</a>hidden_dim<a id="change">)</a>
        self.signal_encoder = SignalEncoder()

        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=nheads)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_encoder_layers)</code></pre><h3>After Change</h3><pre><code class='java'>
            nn.Linear(hidden_dim * projection_dim, mlp_head_dims[0]),
            nn.BatchNorm1d(mlp_head_dims[0]),
            nn.GELU(),
            <a id="change">nn.Dropout(</a>dropout<a id="change">)</a>,
            nn.Linear(mlp_head_dims[0], mlp_head_dims[1]),
            nn.BatchNorm1d(mlp_head_dims[1]),
            nn.GELU(),</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/kolaszko/haptic_transformer/commit/aed59ae5263f8f3490b9ead581d7b112589a9f27#diff-9a02f4e72f98b173cff993e361b8c108ffdd07649fe9a77c6611a0c5af9ecb4aL7' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 42501768</div><div id='project'> Project Name: kolaszko/haptic_transformer</div><div id='commit'> Commit Name: aed59ae5263f8f3490b9ead581d7b112589a9f27</div><div id='time'> Time: 2021-03-02</div><div id='author'> Author: mikolaj.lysakowski.bk@gmail.com</div><div id='file'> File Name: models/haptr.py</div><div id='m_class'> M Class Name: HAPTR</div><div id='n_method'> N Class Name: HAPTR</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/haptr.py</div><div id='n_file'> N File Name: models/haptr.py</div><div id='m_start'> M Start Line: 12</div><div id='m_end'> M End Line: 22</div><div id='n_start'> N Start Line: 7</div><div id='n_end'> N End Line: 28</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            return_attention=False,
        )

        positional_encoding = <a id="change">PositionalEncoding(</a>dropout<a id="change">)</a>
        transformer = Transformer(
            d_model,
            nhead,
            num_encoder_layers,
            num_decoder_layers,
            d_ffn,
            dropout,
            "gelu",
        )
        self.encoder = Encoder(positional_encoding, transformer.encoder)
        self.decoder<a id="change"> = </a>Decoder(positional_encoding, transformer.decoder)

        self.custom_src_module = Sequential(
            Linear(d_model, bias=True, combine_dims=False),</code></pre><h3>After Change</h3><pre><code class='java'>
        self.custom_src_module = Sequential(
            Linear(d_model, bias=True, combine_dims=False),
            LayerNorm(),
            <a id="change">torch.nn.Dropout(</a>dropout<a id="change">)</a>,
        )
        self.custom_tgt_module = Sequential(
            NormalizedEmbedding(d_model, tgt_vocab),</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/64ba22facd4b95278d1e4956d68017d08e325f16#diff-19a372777953c06666e35a28a4af6af17134112af4f3b9e8783bb187d1fbc50eL57' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 42501764</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 64ba22facd4b95278d1e4956d68017d08e325f16</div><div id='time'> Time: 2020-07-13</div><div id='author'> Author: jianyuan.zhong@server.mila.quebec</div><div id='file'> File Name: speechbrain/lobes/models/transformer/TransformerASR.py</div><div id='m_class'> M Class Name: TransformerASR</div><div id='n_method'> N Class Name: TransformerASR</div><div id='m_method'> M Method Name: __init__(11)</div><div id='n_method'> N Method Name: __init__(10)</div><div id='m_parent_class'> M Parent Class: TransformerInterface</div><div id='n_parent_class'> N Parent Class: TransformerInterface</div><div id='m_file'> M File Name: speechbrain/lobes/models/transformer/TransformerASR.py</div><div id='n_file'> N File Name: speechbrain/lobes/models/transformer/TransformerASR.py</div><div id='m_start'> M Start Line: 80</div><div id='m_end'> M End Line: 91</div><div id='n_start'> N Start Line: 66</div><div id='n_end'> N End Line: 83</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
		self.backbone = ResNet_FeatureExtractor(3, 320)
		encoder = nn.TransformerEncoderLayer(320, 4, dropout = 0.0)
		self.encoders = nn.TransformerEncoder(encoder, 3)
		self.pe<a id="change"> = </a><a id="change">PositionalEncoding(</a>320<a id="change">, max_len = max_len)</a>
		self.char_pred = nn.Sequential(nn.Linear(320, 320), nn.ReLU(), nn.Linear(320, self.dict_size))
		self.color_pred1 = nn.Sequential(nn.Linear(320, 64), nn.ReLU(), nn.Linear(64, 6))

	def forward(self,</code></pre><h3>After Change</h3><pre><code class='java'>
		self.backbone = ResNet_FeatureExtractor(3, 320)
		&#47&#47encoder = CustomTransformerEncoderLayer(320, 4, dropout = 0.02, batch_first = True)
		self.encoder1 = BidirectionalLSTM(320, 320, 320)
		self.char_pred = nn.Sequential(nn.Linear(320, 320), nn.ReLU(), <a id="change">nn.Dropout(</a>0.1<a id="change">)</a>, nn.Linear(320, self.dict_size))
		self.color_pred1 = nn.Sequential(nn.Linear(320, 64), nn.ReLU(), nn.Linear(64, 6))

	def decode(self, img: torch.Tensor, img_widths: List[int], blank, verbose = False) -&gt; List[List[Tuple[str, float, int, int, int, int, int, int]]] :</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/zyddnys/manga-image-translator/commit/028e20af903e17ea1d74a3c8dd71e60995c425c8#diff-abb0a66a6713892dc78680bb8975dc9cf3bca0e2f233937e310d6f00a8826562L182' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 42501767</div><div id='project'> Project Name: zyddnys/manga-image-translator</div><div id='commit'> Commit Name: 028e20af903e17ea1d74a3c8dd71e60995c425c8</div><div id='time'> Time: 2021-11-30</div><div id='author'> Author: zyddnys@outlook.com</div><div id='file'> File Name: ocr/model_48px_ctc.py</div><div id='m_class'> M Class Name: OCR</div><div id='n_method'> N Class Name: OCR</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: ocr/model_48px_ctc.py</div><div id='n_file'> N File Name: ocr/model_48px_ctc.py</div><div id='m_start'> M Start Line: 188</div><div id='m_end'> M End Line: 190</div><div id='n_start'> N Start Line: 188</div><div id='n_end'> N End Line: 189</div><BR>