<html><h3>Pattern ID :11685
</h3><img src='39518138.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                               langevin_steps=RUN.langevin_steps,
                               device=device)
    if is_stylegan:
        one_hot_fake_labels = <a id="change">F.one_hot(</a>fake_labels<a id="change">, num_classes=num_classes)</a>
        generator = misc.peel_model(generator)
        ws = generator.mapping(zs, one_hot_fake_labels)
        if style_mixing_p &gt; 0:
            cutoff = torch.empty([], dtype=torch.int64, device=ws.device).random_(1, ws.shape[1])
            cutoff<a id="change"> = </a>torch.where(torch.rand([], device=ws.device) &lt; style_mixing_p, cutoff, torch.full_like(cutoff, ws.shape[1]))
            ws[:, cutoff:] = generator.mapping(torch.randn_like(zs), one_hot_fake_labels, skip_w_avg_update=True)[:, cutoff:]
        fake_images = generator.synthesis(ws)
    else:</code></pre><h3>After Change</h3><pre><code class='java'>
                               langevin_steps=RUN.langevin_steps,
                               device=device)
    if is_stylegan:
        ws<a id="change">, fake_images</a> = stylegan_generate_images(zs=zs,
                                               fake_labels=fake_labels,
                                               num_classes=num_classes,
                                               style_mixing_p=style_mixing_p,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/postech-cvlab/pytorch-studiogan/commit/434cbf2212862f726f1e7cc9527bc42d08b947ee#diff-fddb696acb958630ae3f5c6d5e5d4d22da267a6fe006473de3e83fd9026153a3L87' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39518138</div><div id='project'> Project Name: postech-cvlab/pytorch-studiogan</div><div id='commit'> Commit Name: 434cbf2212862f726f1e7cc9527bc42d08b947ee</div><div id='time'> Time: 2021-10-04</div><div id='author'> Author: first287@naver.com</div><div id='file'> File Name: src/utils/sample.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: generate_images(18)</div><div id='n_method'> N Method Name: generate_images(16)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/utils/sample.py</div><div id='n_file'> N File Name: src/utils/sample.py</div><div id='m_start'> M Start Line: 131</div><div id='m_end'> M End Line: 144</div><div id='n_start'> N Start Line: 87</div><div id='n_end'> N End Line: 152</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if self.inputs_are_logits:
            if self.apply_transform:
                inputs = F.softmax(inputs, dim=1)
            targets<a id="change"> = </a><a id="change">F.one_hot(</a>targets.contiguous().view(-1), inputs.shape[1]<a id="change">)</a>.float()
        else:
            inputs = inputs.unsqueeze(1)
            targets = targets.unsqueeze(1)</code></pre><h3>After Change</h3><pre><code class='java'>
        Returns:
            Tanimoto distance loss (float)
        
        inputs<a id="change">, targets</a> = self.preprocess(inputs, targets)

        weights = torch.reciprocal(torch.square(self.volume))
        new_weights = torch.where(torch.isinf(weights), torch.zeros_like(weights), weights)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jgrss/cultionet/commit/f2182f120125c8e95ee3f5980c87042d8a2718a7#diff-e4873aeb9dca59f2016cc6e82d8cfb35829b95c3d7f748046ab7bfb264b17f6bL125' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39518136</div><div id='project'> Project Name: jgrss/cultionet</div><div id='commit'> Commit Name: f2182f120125c8e95ee3f5980c87042d8a2718a7</div><div id='time'> Time: 2022-11-09</div><div id='author'> Author: jgrss@users.noreply.github.com</div><div id='file'> File Name: src/cultionet/losses/losses.py</div><div id='m_class'> M Class Name: TanimotoDistanceLoss</div><div id='n_method'> N Class Name: TanimotoDistanceLoss</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: ClassifierPreprocessing</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: src/cultionet/losses/losses.py</div><div id='n_file'> N File Name: src/cultionet/losses/losses.py</div><div id='m_start'> M Start Line: 135</div><div id='m_end'> M End Line: 143</div><div id='n_start'> N Start Line: 77</div><div id='n_end'> N End Line: 77</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        bin_size = self.max_pixel_val / self.output_channel_bits
        channel_bins = torch.arange(bin_size, self.max_pixel_val, bin_size).to(avg_target.device)
        discretized_target = torch.bucketize(avg_target, channel_bins)
        discretized_target = <a id="change">F.one_hot(</a>discretized_target,
                                       self.output_channel_bits<a id="change">)</a>
        c, bi = self.channels, self.output_channel_bits
        discretized_target<a id="change"> = </a>rearrange(discretized_target,
                                       "b n c bi -&gt; b n (c bi)",
                                       c=c,
                                       bi=bi)</code></pre><h3>After Change</h3><pre><code class='java'>
        self.std = torch.tensor(std).view(-1, 1, 1) if std else None

    def forward(self, predicted_patches, target, mask):
        p, c, mpv, bits, device = self.patch_size<a id="change">, self.channels, self.max_pixel_val, self.output_channel_bits, target.device</a>
        bin_size = mpv / (2 ** bits)

        &#47&#47 un-normalize input
        if exists(self.mean) and exists(self.std):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/vit-pytorch/commit/64a2ef6462bde61db4dd8f0887ee71192b273692#diff-6b502c3fca9000d4ac485e72a6b6cb51b335fed8a8e158013b955ffed39c59abL51' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39518143</div><div id='project'> Project Name: lucidrains/vit-pytorch</div><div id='commit'> Commit Name: 64a2ef6462bde61db4dd8f0887ee71192b273692</div><div id='time'> Time: 2021-06-16</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: vit_pytorch/mpp.py</div><div id='m_class'> M Class Name: MPPLoss</div><div id='n_method'> N Class Name: MPPLoss</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: vit_pytorch/mpp.py</div><div id='n_file'> N File Name: vit_pytorch/mpp.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 82</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 72</div><BR>