<html><h3>Pattern ID :11943
</h3><img src='40496473.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    feature_extractor = tf.keras.Model(inputs=model.inputs, outputs=layer.output)
    print("&gt;&gt;&gt;&gt; Total filters for layer {}: {}".format(layer_name, layer.output_shape[-1]))

    input_shape = model.input_shape[:2]<a id="change"> if input_shape is None</a><a id="change"> else </a>input_shape[:2]
    image = model.input_shape[:2] if input_shape is None else input_shape[:2]

    &#47&#47 We run gradient ascent for [iterations] steps</code></pre><h3>After Change</h3><pre><code class='java'>
        filter_images.append(image)

    ax, _ = stack_and_plot_images(filter_images, base_size=base_size)
    return losses, <a id="change">np.stack(</a>filter_images<a id="change">)</a>, ax


def make_gradcam_heatmap(model, img_array, layer_name, pred_index=None):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/10b6b27744d9f2bcfdcfa74b6c0a3cdd0f72512c#diff-1ec9a19aafb9379c6e226dccc101dafcc65576f11136e0603301b13fca3f7db4L52' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 40496473</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: 10b6b27744d9f2bcfdcfa74b6c0a3cdd0f72512c</div><div id='time'> Time: 2021-12-23</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/visualizing/visualizing.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: visualize_filters(7)</div><div id='n_method'> N Method Name: visualize_filters(7)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/visualizing/visualizing.py</div><div id='n_file'> N File Name: keras_cv_attention_models/visualizing/visualizing.py</div><div id='m_start'> M Start Line: 52</div><div id='m_end'> M End Line: 73</div><div id='n_start'> N Start Line: 95</div><div id='n_end'> N End Line: 115</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.input_shape = input_shape[1:-1] if len(input_shape) == 4 else input_shape[:2]

    def __call__(self, image, resize_method="bilinear", resize_antialias=False, input_shape=None):
        input_shape = self.input_shape<a id="change"> if input_shape is None</a><a id="change"> else </a>input_shape[:2]
        image = tf.convert_to_tensor(image)
        if tf.reduce_max(image) &lt; 2:
            image *= 255</code></pre><h3>After Change</h3><pre><code class='java'>
            self.set_input_shape(input_shape)
        images = [image] if len(np.shape(image)) == 3 else image
        images = [np.array(Image.fromarray(image).resize(self.input_shape)) for image in images]
        images = (<a id="change">np.stack(</a>images<a id="change">)</a> - self.mean) / self.std

        images = images if backend.image_data_format() == "channels_last" else images.transpose([0, 3, 1, 2])
        return functional.convert_to_tensor(images)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/2f70b0d51c8f2b1f8664f32dc75ecc1001758946#diff-346aa59a353ab2958ad8559a1c05a8fc850eaead58fd103d6bcb5a5130b699ceL585' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 40496472</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: 2f70b0d51c8f2b1f8664f32dc75ecc1001758946</div><div id='time'> Time: 2023-01-29</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/common_layers.py</div><div id='m_class'> M Class Name: PreprocessInput</div><div id='n_method'> N Class Name: PreprocessInput</div><div id='m_method'> M Method Name: __call__(5)</div><div id='n_method'> N Method Name: __call__(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/common_layers.py</div><div id='n_file'> N File Name: keras_cv_attention_models/common_layers.py</div><div id='m_start'> M Start Line: 586</div><div id='m_end'> M End Line: 601</div><div id='n_start'> N Start Line: 609</div><div id='n_end'> N End Line: 616</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if self.training and self.layer_dropout &gt; 0:
            to_drop = torch.empty(len(self.blocks)).uniform_(0, 1) &lt; self.layer_dropout
            blocks = [block for block, drop in zip(self.blocks, to_drop) if not drop]
            blocks = self.blocks[:1]<a id="change"> if len(blocks) == 0</a><a id="change"> else </a>blocks

        block_args = list(map(lambda x: {&quotf_args&quot: x[0], &quotg_args&quot: x[1]}, block_args))
        return _ReversibleFunction.apply(x, blocks, block_args)</code></pre><h3>After Change</h3><pre><code class='java'>
            blocks, args = map(lambda ind: list(map(itemgetter(ind), layers_and_args)), (0, 1))

        out =  _ReversibleFunction.apply(x, blocks, args)
        return <a id="change">torch.stack(</a>out.chunk(2, dim=-1)<a id="change">)</a>.sum(dim=0)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/sinkhorn-transformer/commit/d5b9c649e59290b15c15f85d0bb182cb20b699fb#diff-27d52caf7b4f725ff9fe7d9e57172c62a7c8744ebafb23663512e7990a5ed131L132' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 40496475</div><div id='project'> Project Name: lucidrains/sinkhorn-transformer</div><div id='commit'> Commit Name: d5b9c649e59290b15c15f85d0bb182cb20b699fb</div><div id='time'> Time: 2020-04-15</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: sinkhorn_transformer/reversible.py</div><div id='m_class'> M Class Name: ReversibleSequence</div><div id='n_method'> N Class Name: ReversibleSequence</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: sinkhorn_transformer/reversible.py</div><div id='n_file'> N File Name: sinkhorn_transformer/reversible.py</div><div id='m_start'> M Start Line: 133</div><div id='m_end'> M End Line: 142</div><div id='n_start'> N Start Line: 161</div><div id='n_end'> N End Line: 174</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if self.transforms is not None:
            frames, masks = self.transforms(frames, masks)

        n_objects = video[&quotn_objects&quot]<a id="change"> if video[&quotn_objects&quot] &lt;= self.options[
            &quotn_max_objects&quot]</a><a id="change"> else </a>self.options[&quotn_max_objects&quot]
        return video[&quotname&quot], n_objects, frames, masks

    def _get_frame_indexes(self, n_frames, n_max_frames):</code></pre><h3>After Change</h3><pre><code class='java'>
            frames, masks = self.transforms(frames, masks, n_objects)

        &#47&#47 Masks to One Hot: (H, W) -&gt; (n_object, H, W)
        masks = <a id="change">torch.stack(
            </a>[utils.helpers.to_onehot(m, self.options[&quotn_max_objects&quot] + 1) for m in masks]<a id="change">, dim=0)</a>

        return video[&quotname&quot], n_objects, frames, masks

    def _get_frame_indexes(self, n_frames, n_max_frames):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hzxie/rmnet/commit/a843987e94bf3cb9e0c2df96cd284dfab77b80fe#diff-e9f8eead35b36d20cde9cdbb850fbd1eb7e964cad6df019818a0a9551507e42eL53' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 40496470</div><div id='project'> Project Name: hzxie/rmnet</div><div id='commit'> Commit Name: a843987e94bf3cb9e0c2df96cd284dfab77b80fe</div><div id='time'> Time: 2020-04-13</div><div id='author'> Author: root@haozhexie.com</div><div id='file'> File Name: utils/data_loaders.py</div><div id='m_class'> M Class Name: Dataset</div><div id='n_method'> N Class Name: Dataset</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: torch.utils.data.dataset.Dataset</div><div id='n_parent_class'> N Parent Class: torch.utils.data.dataset.Dataset</div><div id='m_file'> M File Name: utils/data_loaders.py</div><div id='n_file'> N File Name: utils/data_loaders.py</div><div id='m_start'> M Start Line: 54</div><div id='m_end'> M End Line: 73</div><div id='n_start'> N Start Line: 39</div><div id='n_end'> N End Line: 60</div><BR>