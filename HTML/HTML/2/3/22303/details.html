<html><h3>Pattern ID :22303
</h3><img src='70272105.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        bin_weight = min(((step - self.bin_start_steps) / self.bin_warmup_steps) / 2, 0.5)

        if self.include_forward_loss:
            l_forward = <a id="change">self.l_forward_func(</a>torch.log(soft_attention), in_lens, out_lens<a id="change">)</a>
            &#47&#47 this is not the proper way to get log_probs, but the forward attention complicates things.
            &#47&#47 Luckily the forward attention does about the same as CTC, so it&quots not too necessary to have this.
        else:
            l_forward = 0.0</code></pre><h3>After Change</h3><pre><code class='java'>
        forward_weight = min(((step - self.forward_start_steps) / self.bin_warmup_steps) / 10, 0.1)

        if self.include_forward_loss and self.forward_start_steps &lt; step:
            l_forward = forward_weight<a id="change"> * </a><a id="change">self.l_forward_func(</a>torch.log(soft_attention), in_lens, out_lens<a id="change">)</a>
        else:
            l_forward = 0.0

        if self.bin_start_steps &lt; step:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/eb3c68c49612b33edd8dea08d67a6141ecd8fc49#diff-9231482ca8ced623ea2ffc238083e8f3b850ead33a396e8ba1c359c2b20936cfL161' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70272105</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: eb3c68c49612b33edd8dea08d67a6141ecd8fc49</div><div id='time'> Time: 2021-09-29</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/AlignmentLoss.py</div><div id='m_class'> M Class Name: AlignmentLoss</div><div id='n_method'> N Class Name: AlignmentLoss</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/AlignmentLoss.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/AlignmentLoss.py</div><div id='m_start'> M Start Line: 161</div><div id='m_end'> M End Line: 162</div><div id='n_start'> N Start Line: 199</div><div id='n_end'> N End Line: 202</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        forward_weight = min(((step - self.forward_start_steps) / self.forward_start_steps) / 10, 0.01)

        if self.include_forward_loss and self.forward_start_steps &lt; step:
            l_forward = forward_weight * <a id="change">self.l_forward_func(</a>torch.log(soft_attention), in_lens, out_lens<a id="change">)</a>
        else:
            l_forward = 0.0

        if self.bin_start_steps &lt; step:</code></pre><h3>After Change</h3><pre><code class='java'>
        forward_weight = min(((step - self.forward_start_steps) / self.forward_start_steps) / 10, 0.01)

        if self.include_forward_loss and self.forward_start_steps &lt; step:
            l_forward = forward_weight<a id="change"> * self.l_forward_func(torch.log(soft_attention), in_lens, out_lens) * </a>50
        else:
            l_forward = 0.0
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/688a80e651234090b5107e02fe770e63c85367dd#diff-9231482ca8ced623ea2ffc238083e8f3b850ead33a396e8ba1c359c2b20936cfL186' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70272107</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 688a80e651234090b5107e02fe770e63c85367dd</div><div id='time'> Time: 2021-10-12</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/AlignmentLoss.py</div><div id='m_class'> M Class Name: AlignmentLoss</div><div id='n_method'> N Class Name: AlignmentLoss</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/AlignmentLoss.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/AlignmentLoss.py</div><div id='m_start'> M Start Line: 191</div><div id='m_end'> M End Line: 194</div><div id='n_start'> N Start Line: 191</div><div id='n_end'> N End Line: 194</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        bin_weight = min(((step - self.bin_start_steps) / self.bin_warmup_steps) / 100, 0.01)

        if self.include_forward_loss and self.forward_start_steps &lt; step:
            l_forward = <a id="change">self.l_forward_func(</a>torch.log(soft_attention), in_lens, out_lens<a id="change">)</a>
        else:
            l_forward = 0.0

        if self.bin_start_steps &lt; step:</code></pre><h3>After Change</h3><pre><code class='java'>
        bin_weight = min(((step - self.bin_start_steps) / self.bin_warmup_steps) / 100, 0.01)

        if self.include_forward_loss and self.forward_start_steps &lt; step:
            l_forward = <a id="change">self.l_forward_func(</a>torch.log(soft_attention), in_lens, out_lens<a id="change">) * </a>self.forward_loss_weight
        else:
            l_forward = 0.0
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/e0b827c22f4c9478846e5f22ebfa59e28321acb2#diff-9231482ca8ced623ea2ffc238083e8f3b850ead33a396e8ba1c359c2b20936cfL186' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70272109</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: e0b827c22f4c9478846e5f22ebfa59e28321acb2</div><div id='time'> Time: 2021-10-16</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/AlignmentLoss.py</div><div id='m_class'> M Class Name: AlignmentLoss</div><div id='n_method'> N Class Name: AlignmentLoss</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/AlignmentLoss.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/AlignmentLoss.py</div><div id='m_start'> M Start Line: 193</div><div id='m_end'> M End Line: 193</div><div id='n_start'> N Start Line: 195</div><div id='n_end'> N End Line: 195</div><BR>