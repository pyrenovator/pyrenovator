<html><h3>Pattern ID :32166
</h3><img src='94124494.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    bias_table[&quotexample_id&quot] = bias_table[&quotexample_id&quot].map(
        lambda x: eval(x).decode(&quotUTF-8&quot))  &#47&#47  pylint:disable=eval-used
    ids = np.concatenate(list(
        <a id="change">ds.map(</a>lambda example: example[&quotexample_id&quot]<a id="change">)</a>.batch(
            batch_size).as_numpy_iterator())).tolist()
    ids<a id="change"> = </a>list(map(lambda x: x.decode(&quotUTF-8&quot), ids))
    subgroup_labels = list(
        ds.map(lambda example: example[&quotsubgroup_label&quot]).batch(
            batch_size).as_numpy_iterator())</code></pre><h3>After Change</h3><pre><code class='java'>
        os.path.join(
            os.path.join(output_dir, f&quotround_{idx}&quot), &quotbias_table.csv&quot))
    predictions_merge = merge_subgroup_labels(ds, bias_table, batch_size)
    for subgroup_id in <a id="change">range(</a>num_subgroups<a id="change">)</a>:
      prob_i = (predictions_merge[&quotsubgroup_label&quot]
                == subgroup_id).sum() / len(predictions_merge)
      round_idx.append(idx)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/google/uncertainty-baselines/commit/f5b53459d654b40668528e806a24776b53864278#diff-898a1ff69c9d70117cfb7c75da053a4e8649b705ffef48bf652f1c38fc3a5858L34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 94124494</div><div id='project'> Project Name: google/uncertainty-baselines</div><div id='commit'> Commit Name: f5b53459d654b40668528e806a24776b53864278</div><div id='time'> Time: 2022-11-03</div><div id='author'> Author: no-reply@google.com</div><div id='file'> File Name: experimental/shoshin/evaluate_model_lib.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate_active_sampling(5)</div><div id='n_method'> N Method Name: evaluate_active_sampling(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: experimental/shoshin/evaluate_model_lib.py</div><div id='n_file'> N File Name: experimental/shoshin/evaluate_model_lib.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 59</div><div id='n_start'> N Start Line: 68</div><div id='n_end'> N End Line: 92</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            train_ds, batch_size=args.batch_size, shuffle=False, drop_last=True
        )

        dev_ds<a id="change"> = </a><a id="change">dev_ds.map(</a>trans_func<a id="change">, lazy=True)</a>
        dev_batch_sampler = BatchSampler(dev_ds, batch_size=args.batch_size, shuffle=False, drop_last=True)

        batchify_fn = DataCollatorWithPadding(tokenizer)
</code></pre><h3>After Change</h3><pre><code class='java'>

        train_ds = train_ds.map(trans_func, lazy=False)
        repeat_data = []
        for i in <a id="change">range(</a>10<a id="change">)</a>:
            repeat_data.extend(train_ds.new_data)
        train_ds.new_data = repeat_data
        train_batch_sampler = DistributedBatchSampler(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/a0699315b5f5e71472237852998cc1e970d361b4#diff-cdb4a1b0c3093e4bd54679532d91092baca9198417d5c62e35a52adf14e3ae2eL67' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 94124504</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: a0699315b5f5e71472237852998cc1e970d361b4</div><div id='time'> Time: 2023-02-13</div><div id='author'> Author: 50394665+JunnYu@users.noreply.github.com</div><div id='file'> File Name: tests/test_tipc/benchmark/modules/ernie3_for_sequence_classification.py</div><div id='m_class'> M Class Name: Ernie3ForSequenceClassificationBenchmark</div><div id='n_method'> N Class Name: Ernie3ForSequenceClassificationBenchmark</div><div id='m_method'> M Method Name: create_data_loader(2)</div><div id='n_method'> N Method Name: create_data_loader(2)</div><div id='m_parent_class'> M Parent Class: BenchmarkBase</div><div id='n_parent_class'> N Parent Class: BenchmarkBase</div><div id='m_file'> M File Name: tests/test_tipc/benchmark/modules/ernie3_for_sequence_classification.py</div><div id='n_file'> N File Name: tests/test_tipc/benchmark/modules/ernie3_for_sequence_classification.py</div><div id='m_start'> M Start Line: 72</div><div id='m_end'> M End Line: 95</div><div id='n_start'> N Start Line: 128</div><div id='n_end'> N End Line: 132</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            pkg_resources.resource_filename("bert-squeeze", f"data/{self.dataset_config.name}_dataset.py"),
            self.dataset_config.split
        )
        tokenized_dataset<a id="change"> = </a><a id="change">dataset.map(
            </a>lambda x: self.tokenizer(x[self.dataset_config.text_col], padding="max_length", max_length=self.max_length,
                                     truncation=True)<a id="change">
        )</a>
        tokenized_dataset.set_format(type=&quottorch&quot, columns=["input_ids", "token_type_ids", "attention_mask", "id"])
        return DataLoader(tokenized_dataset["train"], collate_fn=_collate_fn(), batch_size=self.batch_size,
                          drop_last=True, num_workers=0)
</code></pre><h3>After Change</h3><pre><code class='java'>
            )
        else:
            dataset = datasets.load_dataset(self.dataset_config.name, self.dataset_config.split)
        dataset = dataset["train"].select(<a id="change">range(</a>self.dataset_config.max_samples<a id="change">)</a>)

        logging.info("Featurizing hard dataset for labeling.")
        featurized_dataset = self.featurize(dataset)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/julesbelveze/bert-squeeze/commit/737c3ff9fbb4c2eaa195c8fd094ee417d6ec358c#diff-fa8fdef3517be3454ba0013e65f2024b55e16e1bbc66c76e55bd7f7bb9b675c4L24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 94124497</div><div id='project'> Project Name: julesbelveze/bert-squeeze</div><div id='commit'> Commit Name: 737c3ff9fbb4c2eaa195c8fd094ee417d6ec358c</div><div id='time'> Time: 2021-10-26</div><div id='author'> Author: 32683010+JulesBelveze@users.noreply.github.com</div><div id='file'> File Name: bert-squeeze/distillation/utils/labeler.py</div><div id='m_class'> M Class Name: HardLabeler</div><div id='n_method'> N Class Name: HardLabeler</div><div id='m_method'> M Method Name: get_dataloader(1)</div><div id='n_method'> N Method Name: get_dataloader(1)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: bert-squeeze/distillation/utils/labeler.py</div><div id='n_file'> N File Name: bert-squeeze/distillation/utils/labeler.py</div><div id='m_start'> M Start Line: 31</div><div id='m_end'> M End Line: 40</div><div id='n_start'> N Start Line: 64</div><div id='n_end'> N End Line: 77</div><BR>