<html><h3>Pattern ID :22233
</h3><img src='70223102.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        transforms.RandomGrayscale(p=0.1),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.ToTensor(),
        transforms.RandomApply(<a id="change">[</a><a id="change">transforms.Lambda(</a>lambda x: x + torch.randn(x.shape)*0.02<a id="change">)</a>], p=0.5)
    ]
    test_transform = [transforms.CenterCrop(160), resize_xform]
</code></pre><h3>After Change</h3><pre><code class='java'>
        transforms.ToTensor(),
        &#47&#47transforms.RandomApply([transforms.Lambda(lambda x: x + torch.randn(x.shape)*0.02)], p=0.5)
    ]
    test_transform = <a id="change">[</a>transforms.CenterCrop(args.image_size_override)<a id="change"></a>]
    loader_dict = {&quottrain_transform&quot: train_transform,
                   &quottest_transform&quot: test_transform,
                   **vars(args)}</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/jramapuram/byol/commit/8844cba583a0d3e8454ce97f0be5b5d04eff356e#diff-b10564ab7d2c520cdd0243874879fb0a782862c3c902ab535faabe57d5a505e1L192' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70223102</div><div id='project'> Project Name: jramapuram/byol</div><div id='commit'> Commit Name: 8844cba583a0d3e8454ce97f0be5b5d04eff356e</div><div id='time'> Time: 2020-04-26</div><div id='author'> Author: jason.ramapuram@gmail.com</div><div id='file'> File Name: main.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: build_loader_model_grapher(1)</div><div id='n_method'> N Method Name: build_loader_model_grapher(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: main.py</div><div id='n_file'> N File Name: main.py</div><div id='m_start'> M Start Line: 192</div><div id='m_end'> M End Line: 221</div><div id='n_start'> N Start Line: 245</div><div id='n_end'> N End Line: 252</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 scaled_dot_product_attention
    &#47&#47 print(f"&gt;&gt;&gt;&gt; {attn_query.shape = }, {key.shape = }, {value.shape = }, {kv_inp.shape = }, {pos_query.shape = }, {num_heads = }")
    &#47&#47 attention_scores = [batch, num_heads, hh, ww, query_block * query_block, kv_kernel * kv_kernel]
    attention_scores = <a id="change">keras.layers.Lambda(</a>lambda xx: tf.matmul(xx[0], xx[1], transpose_b=True)<a id="change">)</a>([attn_query, key])
    &#47&#47 pos = [batch, num_heads * hh * ww, query_block, query_block, kv_kernel, kv_kernel]
    pos = RelativePositionalEmbedding(position_height=kv_kernel, name=name and name + "pos_emb")(pos_query)
    &#47&#47 print(f"&gt;&gt;&gt;&gt; {pos.shape = }, {attention_scores.shape = }")
    pos = tf.reshape(pos, [-1, *attention_scores.shape[1:]])
    attention_scores = keras.layers.Add()([attention_scores, pos])
    &#47&#47 attention_scores = tf.nn.softmax(attention_scores, axis=-1)
    attention_scores = keras.layers.Softmax(axis=-1, name=name and name + "attention_scores")(attention_scores)

    if attn_dropout &gt; 0:
        attention_scores = keras.layers.Dropout(attn_dropout, name=name and name + "attn_drop")(attention_scores)

    &#47&#47 attention_output = [batch, num_heads, hh, ww, query_block * query_block, out_dim]
    attention_output = keras.layers.Lambda(lambda xx: tf.matmul(xx[0], xx[1]))(<a id="change">[</a>attention_scores, value<a id="change"></a>])
    &#47&#47 attention_output = rearrange(attention_output, "B hd h w (hb wb) c -&gt; B (h hb) (w wb) (hd c)", hb=query_block, wb=query_block)
    _, heads, hh_aa, ww_aa, patch, cc_aa = attention_output.shape
    attention_output = tf.reshape(attention_output, [-1, heads, hh_aa, ww_aa, query_block, query_block, cc_aa])</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 print(f"&gt;&gt;&gt;&gt; {attn_query.shape = }, {key.shape = }, {value.shape = }, {kv_inp.shape = }, {pos_query.shape = }, {num_heads = }")
    &#47&#47 attention_scores = [batch, num_heads, hh, ww, query_block * query_block, kv_kernel * kv_kernel]
    &#47&#47 attention_scores = layers.Lambda(lambda xx: functional.matmul(xx[0], xx[1], transpose_b=True))([attn_query, key])
    attention_scores = attn_query @ functional.transpose(key, <a id="change">[</a>0, 1, 2, 3, 5, 4<a id="change"></a>])
    &#47&#47 pos = [batch, num_heads * hh * ww, query_block, query_block, kv_kernel, kv_kernel]
    pos = RelativePositionalEmbedding(position_height=kv_kernel, name=name and name + "pos_emb")(pos_query)
    &#47&#47 print(f"&gt;&gt;&gt;&gt; {pos.shape = }, {attention_scores.shape = }")</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/e05e233f369a1d58f912872b1581a80d15cacc3f#diff-5a0036f02e35afe08c2170dc9b0e1131865080e554a879c04557e7a873330e74L18' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70223101</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: e05e233f369a1d58f912872b1581a80d15cacc3f</div><div id='time'> Time: 2023-02-07</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/halonet/halonet.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: halo_attention(11)</div><div id='n_method'> N Method Name: halo_attention(11)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/halonet/halonet.py</div><div id='n_file'> N File Name: keras_cv_attention_models/halonet/halonet.py</div><div id='m_start'> M Start Line: 23</div><div id='m_end'> M End Line: 98</div><div id='n_start'> N Start Line: 28</div><div id='n_end'> N End Line: 106</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 normalize using ImageNet&quots mean and std (VGG was trained on images normalized this way)
    &#47&#47 [0, 255] range works much better than [0, 1] range (VGG was again trained that way)
    if should_normalize:
        transform = transforms.Compose(<a id="change">[
            </a>transforms.ToTensor(),
            <a id="change">transforms.Lambda(</a>lambda x: x.mul(255)<a id="change">)</a>,
            transforms.Normalize(mean=IMAGENET_MEAN_255, std=IMAGENET_STD_NEUTRAL)<a id="change"></a>
        ])
    else:
        transform = transforms.Compose([
            transforms.ToTensor(),</code></pre><h3>After Change</h3><pre><code class='java'>
def prepare_img(img_path, target_shape, device, repeat=1, should_normalize=True, is_255_range=False):
    img = load_image(img_path, target_shape=target_shape)

    transform_list = <a id="change">[</a>transforms.ToTensor()<a id="change"></a>]
    if is_255_range:
        transform_list.append(transforms.Lambda(lambda x: x.mul(255)))
    if should_normalize:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/gordicaleksa/pytorch-neural-style-transfer-fast/commit/306aeccf646cae170968250b41a036c49416afe3#diff-9653b8c2ce917a6134298b00c8b3f7d4b7c4dc473a752303f37a870392742127L44' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70223099</div><div id='project'> Project Name: gordicaleksa/pytorch-neural-style-transfer-fast</div><div id='commit'> Commit Name: 306aeccf646cae170968250b41a036c49416afe3</div><div id='time'> Time: 2020-05-28</div><div id='author'> Author: gordicaleksa@gmail.com</div><div id='file'> File Name: utils/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: prepare_img(6)</div><div id='n_method'> N Method Name: prepare_img(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: utils/utils.py</div><div id='n_file'> N File Name: utils/utils.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 59</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 61</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        if augment:
            self.traintransform = transforms.Compose(
                <a id="change">[</a>transforms.ToPILImage(),
                 transforms.RandomApply([transforms.RandomAffine(0, translate=(0.2, 0.2))], p=0.5),
                 transforms.RandomHorizontalFlip(),
                 transforms.RandomApply([transforms.GaussianBlur(3)], p=0.5 if kwargs["gussian_blur"] else 0),
                 transforms.Pad(2),
                 transforms.TenCrop(kwargs["crop_size"]),
                 transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),
                 <a id="change">transforms.Lambda(
                     </a>lambda tensors: torch.stack(
                         [transforms.Normalize(mean=(self.mu,), std=(self.st,))(t) for t in tensors])<a id="change">)</a>,
                 transforms.Lambda(
                     lambda tensors: torch.stack(
                         [transforms.RandomErasing(p=0 if kwargs["cutmix"] else 0.5)(t) for t in tensors]))<a id="change"></a>,
                 ]
            )
        else:</code></pre><h3>After Change</h3><pre><code class='java'>

        if augment:
            self.traintransform = transforms.Compose(
                <a id="change">[</a>transforms.ToPILImage(),
                 &#47&#47 transforms.RandomApply([transforms.RandomAffine(0, translate=(0.2, 0.2))], p=0.5),
                 &#47&#47 transforms.RandomHorizontalFlip(),
                 &#47&#47 transforms.RandomApply([transforms.GaussianBlur(3)], p=0.5 if kwargs["gussian_blur"] else 0),
                 transforms.Pad(2),
                 transforms.TenCrop(kwargs["crop_size"]),
                 transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))<a id="change"></a>,
                 &#47&#47 transforms.Lambda(
                 &#47&#47     lambda tensors: torch.stack(
                 &#47&#47         [transforms.Normalize(mean=(self.mu,), std=(self.st,))(t) for t in tensors])),</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pooya-mohammadi/fer/commit/00bb4ab427ffc84682cfc14e7f66e7f659801158#diff-6dc067fcedfece1def61caec4879064a3a6cee757878979cea87efd63454057bL43' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70223098</div><div id='project'> Project Name: pooya-mohammadi/fer</div><div id='commit'> Commit Name: 00bb4ab427ffc84682cfc14e7f66e7f659801158</div><div id='time'> Time: 2021-08-18</div><div id='author'> Author: dor2ns@gmail.com</div><div id='file'> File Name: data/fer2013.py</div><div id='m_class'> M Class Name: RESCostumDataset</div><div id='n_method'> N Class Name: RESCostumDataset</div><div id='m_method'> M Method Name: __init__(7)</div><div id='n_method'> N Method Name: __init__(7)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: data/fer2013.py</div><div id='n_file'> N File Name: data/fer2013.py</div><div id='m_start'> M Start Line: 76</div><div id='m_end'> M End Line: 89</div><div id='n_start'> N Start Line: 76</div><div id='n_end'> N End Line: 89</div><BR>