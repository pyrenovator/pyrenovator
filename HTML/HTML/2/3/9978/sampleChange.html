<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        :return: Whether this is the best validation epoch so far.
        
        &#47&#47 The metric needs to be computed on all ranks to allow synchronisation
        metric_value = float(<a id="change">metrics_dict[self.primary_val_metric].compute()</a>)

        &#47&#47 Validation outputs and best metric should be saved only by the global rank-0 process
        if not is_global_rank_zero:</code></pre><h3>After Change</h3><pre><code class='java'>
            logging.warning("Encountered metric that hasn&quott been updated. Not saving.")
            return False
        &#47&#47 The metric needs to be computed on all ranks to allow synchronisation
        metric_value<a id="change"> = </a><a id="change">float(</a>metric.compute()<a id="change">)</a>

        &#47&#47 It seems to be necessary to reset the Accuracy metric after computing, else some processes get stuck here
        if isinstance(metric, Accuracy):
            metric.reset()</code></pre>