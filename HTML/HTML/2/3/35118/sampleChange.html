<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            else:
                for datapoint in tqdm(self.datapoints):
                    tensored_datapoints.append([torch.Tensor(datapoint[0]),
                                                <a id="change">torch.LongTensor(</a>datapoint[1]<a id="change">)</a>,
                                                torch.Tensor(datapoint[2]),
                                                torch.LongTensor(datapoint[3]),
                                                torch.LongTensor(datapoint[4]),</code></pre><h3>After Change</h3><pre><code class='java'>
                                rebuild_cache=True)
                datapoints = torch.load(os.path.join(cache_dir, "taco_train_cache.pt"), map_location=&quotcpu&quot)
            dataset = datapoints[0]
            norm_waves<a id="change"> = </a>datapoints[1]

            resource_manager = Manager()
            &#47&#47 build cache
            print("... building dataset cache ...")
            self.datapoints = resource_manager.list()
            &#47&#47 make processes
            datapoint_splits = list()
            norm_wave_splits = list()
            process_list = list()
            for i in range(loading_processes):
                datapoint_splits.append(dataset[i * len(dataset) // loading_processes:(i + 1) * len(dataset) // loading_processes])
                <a id="change">norm_wave_splits.append(</a>norm_waves[i * len(norm_waves) // loading_processes:(i + 1) * len(norm_waves) // loading_processes]<a id="change">)</a>
            for index, _ in enumerate(datapoint_splits):
                process_list.append(Process(target=self.cache_builder_process,
                                            args=(datapoint_splits[index],
                                                  norm_wave_splits[index],</code></pre>