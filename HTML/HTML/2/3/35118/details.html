<html><h3>Pattern ID :35118
</h3><img src='100173712.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            else:
                for datapoint in tqdm(self.datapoints):
                    tensored_datapoints.append([torch.Tensor(datapoint[0]),
                                                <a id="change">torch.LongTensor(</a>datapoint[1]<a id="change">)</a>,
                                                torch.Tensor(datapoint[2]),
                                                torch.LongTensor(datapoint[3]),
                                                torch.LongTensor(datapoint[4]),</code></pre><h3>After Change</h3><pre><code class='java'>
                                rebuild_cache=True)
                datapoints = torch.load(os.path.join(cache_dir, "taco_train_cache.pt"), map_location=&quotcpu&quot)
            dataset = datapoints[0]
            norm_waves<a id="change"> = </a>datapoints[1]

            resource_manager = Manager()
            &#47&#47 build cache
            print("... building dataset cache ...")
            self.datapoints = resource_manager.list()
            &#47&#47 make processes
            datapoint_splits = list()
            norm_wave_splits = list()
            process_list = list()
            for i in range(loading_processes):
                datapoint_splits.append(dataset[i * len(dataset) // loading_processes:(i + 1) * len(dataset) // loading_processes])
                <a id="change">norm_wave_splits.append(</a>norm_waves[i * len(norm_waves) // loading_processes:(i + 1) * len(norm_waves) // loading_processes]<a id="change">)</a>
            for index, _ in enumerate(datapoint_splits):
                process_list.append(Process(target=self.cache_builder_process,
                                            args=(datapoint_splits[index],
                                                  norm_wave_splits[index],</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/d75af2f091227a4695d4887a9a8f23dc5d22b12b#diff-528f1d1f9b65f826c6eec25f3934452fe1a81965d76a0070a71db9ef9ef36aa0L36' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 100173712</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: d75af2f091227a4695d4887a9a8f23dc5d22b12b</div><div id='time'> Time: 2021-09-15</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='m_class'> M Class Name: FastSpeechDataset</div><div id='n_method'> N Class Name: FastSpeechDataset</div><div id='m_method'> M Method Name: __init__(13)</div><div id='n_method'> N Method Name: __init__(13)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='m_start'> M Start Line: 36</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 36</div><div id='n_end'> N End Line: 109</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            users[i] = uid

            used_item_id = self.sampler.used_item_id[self.phase][uid]
            used_idx.append(<a id="change">torch.LongTensor(</a>list(used_item_id)<a id="change">)</a>)
            used_num = len(used_item_id)
            neg_num = tot_item_num - used_num
            neg_end = new_inter_num + pos_num + neg_num</code></pre><h3>After Change</h3><pre><code class='java'>
        pos_idx = []
        used_idx = []

        users<a id="change"> = </a>list(uid2items[uid_field])
        for i, row in enumerate(uid2items.itertuples()):
            uid = users[i]
            pos_item_id = getattr(row, iid_field)
            pos_idx.extend([_ + start_idx for _ in pos_item_id])
            pos_num = len(pos_item_id)

            used_item_id = self.sampler.used_item_id[self.phase][uid]
            used_idx.extend([_ + start_idx for _ in used_item_id])
            used_num = len(used_item_id)

            neg_num = tot_item_num - used_num
            <a id="change">neg_len_list.append(</a>neg_num<a id="change">)</a>

            pos_len_list.append(pos_num)
            user_len_list.append(pos_num + neg_num)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/recbole/commit/efaf2d8c84961b5042c0d42e08e56a59f064f267#diff-f41d5d93e76efa5638a691f8947c424c58ec3f51b884fc0d235ddd324dd574f2L335' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 100173717</div><div id='project'> Project Name: rucaibox/recbole</div><div id='commit'> Commit Name: efaf2d8c84961b5042c0d42e08e56a59f064f267</div><div id='time'> Time: 2020-08-05</div><div id='author'> Author: houyupeng@ruc.edu.cn</div><div id='file'> File Name: data/dataloader.py</div><div id='m_class'> M Class Name: GeneralFullDataLoader</div><div id='n_method'> N Class Name: GeneralFullDataLoader</div><div id='m_method'> M Method Name: _neg_sampling(2)</div><div id='n_method'> N Method Name: _neg_sampling(2)</div><div id='m_parent_class'> M Parent Class: GeneralGroupedDataLoader</div><div id='n_parent_class'> N Parent Class: GeneralGroupedDataLoader</div><div id='m_file'> M File Name: data/dataloader.py</div><div id='n_file'> N File Name: data/dataloader.py</div><div id='m_start'> M Start Line: 336</div><div id='m_end'> M End Line: 370</div><div id='n_start'> N Start Line: 341</div><div id='n_end'> N End Line: 377</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        unk_idx = self.data.word_field.vocab.stoi[self.data.word_field.unk_token]
        unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]
        &#47&#47 begin prediction
        token_tensor = <a id="change">torch.LongTensor(</a>numericalized_tokens<a id="change">)</a>
        token_tensor = token_tensor.unsqueeze(-1)
        predictions = self.model(token_tensor)
        &#47&#47 convert results to tags
        top_predictions = predictions.argmax(-1)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 tokenize sentence
        nlp = Indonesian()
        tokens = [token.text for token in nlp(sentence)]
        max_word_len<a id="change"> = </a>max([len(token) for token in tokens])
        &#47&#47 transform to indices based on corpus vocab
        numericalized_tokens = [self.data.word_field.vocab.stoi[token.lower()] for token in tokens]
        numericalized_chars = []
        char_pad_id = self.data.char_pad_idx
        for token in tokens:
            <a id="change">numericalized_chars.append(
                </a>[self.data.char_field.vocab.stoi[char] for char in token]
                + [char_pad_id for _ in range(max_word_len - len(token))]<a id="change">
            )</a>
        &#47&#47 find unknown words
        unk_idx = self.data.word_field.vocab.stoi[self.data.word_field.unk_token]
        unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]
        &#47&#47 begin prediction</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yoseflaw/nerindo/commit/a70e55e7c0489cba1290ebd51512a9e878c6e0ed#diff-8cab4f44e154e1111c4ee01fed014cbc93efbaa697c98a0f44a624cd8e8f013fL84' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 100173702</div><div id='project'> Project Name: yoseflaw/nerindo</div><div id='commit'> Commit Name: a70e55e7c0489cba1290ebd51512a9e878c6e0ed</div><div id='time'> Time: 2020-08-09</div><div id='author'> Author: yosefardhitowin@gmail.com</div><div id='file'> File Name: nerindo/trainer.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: infer(3)</div><div id='n_method'> N Method Name: infer(3)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: nerindo/trainer.py</div><div id='n_file'> N File Name: nerindo/trainer.py</div><div id='m_start'> M Start Line: 88</div><div id='m_end'> M End Line: 100</div><div id='n_start'> N Start Line: 184</div><div id='n_end'> N End Line: 205</div><BR>