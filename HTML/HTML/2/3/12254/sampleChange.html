<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                gr_truth_epoch = gr_truth
            else:
                pred_epoch = np.concatenate((pred_epoch, pred), axis = 0)
                gr_truth_epoch<a id="change"> = </a><a id="change">np.concatenate(</a>(gr_truth_epoch, gr_truth)<a id="change">, axis = 0)</a>
                
            &#47&#47the following line to empty the cache is helpful in order to
            &#47&#47reduce memory usage and avoid OOM error:
            torch.cuda.empty_cache()</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47Initialize numpy arrays for storing results. examples x labels
        &#47&#47Do NOT use concatenation, or else you will have memory fragmentation.
        num_examples = len(dataloader.dataset)
        num_labels = <a id="change">len(</a>self.label_meanings<a id="change">)</a>
        pred_epoch = np.zeros([num_examples,num_labels])
        gr_truth_epoch = np.zeros([num_examples,num_labels])        
        
        for batch_idx, batch in enumerate(dataloader):</code></pre>