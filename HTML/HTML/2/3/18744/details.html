<html><h3>Pattern ID :18744
</h3><img src='60962690.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def test_iter(self, metrics=None):
        self.synthesis_ema.eval()
        <a id="change">self.mapping_ema.eval()</a>

        z = self.input[&quotz&quot]

        class_idx = None</code></pre><h3>After Change</h3><pre><code class='java'>
        img = self.synthesis_ema(ws, noise_mode=noise_mode)

        img = img.permute((0, 2, 3, 1)) * 127.5 + 128
        img<a id="change"> = </a>img.clamp(0, 255)
        img = img.to(torch.uint8)
        img_rgb = <a id="change">img.cpu().detach()</a>.numpy()[0]
        img_bgr = img_rgb[:, :, [2, 1, 0]]
        return img_bgr
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/miemie2013/miemiegan/commit/c0604d858d8916f0f711432810ad1ec98036ca4b#diff-c3be3e49b4968a2ee433a8b0d38c7aa9f68d5116602220ff22567e41b765b44bL458' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60962690</div><div id='project'> Project Name: miemie2013/miemiegan</div><div id='commit'> Commit Name: c0604d858d8916f0f711432810ad1ec98036ca4b</div><div id='time'> Time: 2022-02-22</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_class'> M Class Name: StyleGANv2ADAModel</div><div id='n_method'> N Class Name: StyleGANv2ADAModel</div><div id='m_method'> M Method Name: test_iter(2)</div><div id='n_method'> N Method Name: test_iter(2)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='n_file'> N File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_start'> M Start Line: 458</div><div id='m_end'> M End Line: 486</div><div id='n_start'> N Start Line: 474</div><div id='n_end'> N End Line: 481</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        _, sr = sf.read(path_list[0])
        if speaker_embedding:
            wav2mel = torch.jit.load("Models/SpeakerEmbedding/wav2mel.pt")
            dvector = <a id="change">torch.jit.load("Models/SpeakerEmbedding/dvector-step250000.pt").eval()</a>
        ap = AudioPreprocessor(input_sr=sr, output_sr=16000, melspec_buckets=80, hop_length=256, n_fft=1024, cut_silence=cut_silences)
        for path in tqdm(path_list):
            transcript = self.path_to_transcript_dict[path]
            wave, sr = sf.read(path)</code></pre><h3>After Change</h3><pre><code class='java'>
            transcript = self.path_to_transcript_dict[path]
            wave, sr = sf.read(path)
            if min_len &lt;= len(wave) / sr &lt;= max_len:
                norm_wave<a id="change"> = </a>ap.audio_to_wave_tensor(normalize=True, audio=wave)
                cached_text = tf.string_to_tensor(transcript).squeeze(0).cpu().numpy()
                cached_text_len = torch.LongTensor([len(cached_text)]).numpy()
                cached_speech = ap.audio_to_mel_spec_tensor(audio=norm_wave, normalize=False).transpose(0, 1).cpu().numpy()
                cached_speech_len = torch.LongTensor([len(cached_speech)]).numpy()
                if speaker_embedding:
                    cached_speaker_embedding = <a id="change">speaker_embedding_function.encode_batch(norm_wave).squeeze(0).squeeze(0).detach()</a>.cpu().numpy()
                    process_internal_dataset_chunk.append([cached_text,
                                                           cached_text_len,
                                                           cached_speech,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/4705928bf2e8184d5b2bb1ef9dcc7213e398026d#diff-a49dac0d7d67877dcf8511175f18c0155a9aba98acf2e0ee7bfd3a2ed69fb144L78' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60962688</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 4705928bf2e8184d5b2bb1ef9dcc7213e398026d</div><div id='time'> Time: 2021-09-13</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/TacotronDataset.py</div><div id='m_class'> M Class Name: TacotronDataset</div><div id='n_method'> N Class Name: TacotronDataset</div><div id='m_method'> M Method Name: cache_builder_process(7)</div><div id='n_method'> N Method Name: cache_builder_process(7)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/TacotronDataset.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/TacotronDataset.py</div><div id='m_start'> M Start Line: 83</div><div id='m_end'> M End Line: 98</div><div id='n_start'> N Start Line: 83</div><div id='n_end'> N End Line: 96</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def get_outputs(self, args, dataloader, model):
        
        <a id="change">model.eval()</a>
        total_labels = torch.empty(0,dtype=torch.long).to(self.device)
        total_preds = torch.empty(0,dtype=torch.long).to(self.device)
        total_features = torch.empty((0,args.feat_dim)).to(self.device)
</code></pre><h3>After Change</h3><pre><code class='java'>

        self.model.eval()
        total_labels = torch.empty(0, dtype=torch.long).to(self.device)
        total_logits<a id="change"> = </a>torch.empty((0, args.num_labels)).to(self.device)
        total_features = torch.empty((0, args.feat_dim)).to(self.device)
        total_preds = torch.empty(0, dtype=torch.long).to(self.device)

        for batch in tqdm(dataloader, desc="Iteration"):
            batch = tuple(t.to(self.device) for t in batch)
            input_ids, input_mask, segment_ids, label_ids = batch

            with torch.set_grad_enabled(False):

                features, logits = self.model(input_ids, segment_ids, input_mask)  
                total_labels = torch.cat((total_labels, label_ids))
                total_logits = torch.cat((total_logits, logits))
                total_features = torch.cat((total_features, features))

        if get_feats:

            feats = total_features.cpu().numpy()
            return feats
        
        else:

            total_probs = F.softmax(<a id="change">total_logits.detach()</a>, dim = 1)
            total_maxprobs, total_preds = total_probs.max(dim = 1)

            y_true = total_labels.cpu().numpy()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuiar/textoir/commit/203370e17d2a3452b90670171b60c44cb1500bcd#diff-473639a4a577720e799b4a4695cd6fd7327cf5cf9528d09ba0ecbc00acd46b95L18' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60962695</div><div id='project'> Project Name: thuiar/textoir</div><div id='commit'> Commit Name: 203370e17d2a3452b90670171b60c44cb1500bcd</div><div id='time'> Time: 2021-08-03</div><div id='author'> Author: zhang-hl20@mails.tsinghua.edu.cn</div><div id='file'> File Name: open_intent_discovery/methods/semi_supervised/MCL_BERT/manager.py</div><div id='m_class'> M Class Name: MCLManager</div><div id='n_method'> N Class Name: MCLManager</div><div id='m_method'> M Method Name: get_outputs(4)</div><div id='n_method'> N Method Name: get_outputs(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: open_intent_discovery/methods/semi_supervised/MCL_BERT/manager.py</div><div id='n_file'> N File Name: open_intent_discovery/methods/semi_supervised/MCL_BERT/manager.py</div><div id='m_start'> M Start Line: 20</div><div id='m_end'> M End Line: 40</div><div id='n_start'> N Start Line: 93</div><div id='n_end'> N End Line: 130</div><BR>