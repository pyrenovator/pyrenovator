<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    test_loader = DataLoader(test_data, batch_size=1, shuffle=True, num_workers=4)

    i = 0
    loop = <a id="change">tqdm(</a>test_loader<a id="change">)</a>
    for batch_idx, frames in enumerate(loop):

        if i &gt;= 10: break

        frames = frames.to(DEVICE)  &#47&#47 [1, T, 3, h, w]
        frames_vis = postprocess_img(frames.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
        input = frames[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 3, h, w]

        pred_rgb = pred_rgb_model.pred_n(input, pred_length=VIDEO_PRED_LENGTH)  &#47&#47 [1, T, 3, h, w]
        pred_rgb_vis = postprocess_img(pred_rgb)  &#47&#47 [T, 3, h, w]

        pred_rgb = torch.cat([input, pred_rgb], dim=1)
        pred_rgb = torch.stack([seg_model(pred_rgb[:, i]) for i in range(pred_rgb.shape[1])], dim=1)
        pred_rgb = pred_rgb.argmax(dim=2).squeeze()  &#47&#47 [T, h, w]
        pred_then_colorized_vis = colorize_semseg(postprocess_mask(pred_rgb), num_classes=SYNPICK_CLASSES) &#47&#47 [T, 3, h, w]

        frames_seg = [seg_model(frames[:, i]).argmax(dim=1) for i in range(frames.shape[1])]
        frames_seg = torch.stack(frames_seg, dim=1)  &#47&#47 [1, 1, h, w]
        input_seg = frames_seg[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 1, h, w]

        pred_mask = pred_mask_model.pred_n(input_seg, pred_length=VIDEO_PRED_LENGTH)
        pred_mask = pred_mask.argmax(dim=2)  &#47&#47 [1, T, 1, h, w]
        pred_mask = postprocess_mask(torch.cat([input_seg, pred_mask], dim=1).squeeze())  &#47&#47 [T, h, w]
        pred_mask_vis = colorize_semseg(pred_mask, num_classes=SYNPICK_CLASSES)  &#47&#47 [T, 3, h, w]

        frames_colorized = colorize_semseg(postprocess_mask(frames_seg.squeeze()), num_classes=SYNPICK_CLASSES).unsqueeze(dim=0) &#47&#47 [1, T, 3, h, w]
        frames_colorized_vis<a id="change"> = </a>postprocess_img(frames_colorized.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
        input_colorized = frames_colorized[:VIDEO_IN_LENGTH]

        colorized_then_pred = pred_colorized_mask_model.pred_n(input_colorized, pred_length=VIDEO_PRED_LENGTH)</code></pre><h3>After Change</h3><pre><code class='java'>
            pred_then_colorized_vis = colorize_semseg(postprocess_mask(pred_rgb), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2) &#47&#47 [T, 3, h, w]

            frames_seg = torch.stack([seg_model(frames[:, i]) for i in range(frames.shape[1])], dim=1).argmax(dim=2)  &#47&#47 [1, T, 1, h, w]
            frames_seg_in = torch.stack([(frames_seg == i) for i in <a id="change">range(</a>SYNPICK_CLASSES<a id="change">)</a>], dim=2).float()  &#47&#47 [1, T, c, h, w] one-hot float
            input_seg = frames_seg_in[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, c, h, w]
            pred_mask = pred_mask_model.pred_n(input_seg, pred_length=VIDEO_PRED_LENGTH).argmax(dim=2)  &#47&#47 [1, n, 1, h, w]
            pred_mask = torch.cat([input_seg.argmax(dim=2), pred_mask], dim=1).squeeze()  &#47&#47 [T, h, w]</code></pre>