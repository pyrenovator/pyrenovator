<html><h3>Pattern ID :11313
</h3><img src='38469675.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    test_loader = DataLoader(test_data, batch_size=1, shuffle=True, num_workers=4)

    i = 0
    loop = <a id="change">tqdm(</a>test_loader<a id="change">)</a>
    for batch_idx, frames in enumerate(loop):

        if i &gt;= 10: break

        frames = frames.to(DEVICE)  &#47&#47 [1, T, 3, h, w]
        frames_vis = postprocess_img(frames.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
        input = frames[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 3, h, w]

        pred_rgb = pred_rgb_model.pred_n(input, pred_length=VIDEO_PRED_LENGTH)  &#47&#47 [1, T, 3, h, w]
        pred_rgb_vis = postprocess_img(pred_rgb)  &#47&#47 [T, 3, h, w]

        pred_rgb = torch.cat([input, pred_rgb], dim=1)
        pred_rgb = torch.stack([seg_model(pred_rgb[:, i]) for i in range(pred_rgb.shape[1])], dim=1)
        pred_rgb = pred_rgb.argmax(dim=2).squeeze()  &#47&#47 [T, h, w]
        pred_then_colorized_vis = colorize_semseg(postprocess_mask(pred_rgb), num_classes=SYNPICK_CLASSES) &#47&#47 [T, 3, h, w]

        frames_seg = [seg_model(frames[:, i]).argmax(dim=1) for i in range(frames.shape[1])]
        frames_seg = torch.stack(frames_seg, dim=1)  &#47&#47 [1, 1, h, w]
        input_seg = frames_seg[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 1, h, w]

        pred_mask = pred_mask_model.pred_n(input_seg, pred_length=VIDEO_PRED_LENGTH)
        pred_mask = pred_mask.argmax(dim=2)  &#47&#47 [1, T, 1, h, w]
        pred_mask = postprocess_mask(torch.cat([input_seg, pred_mask], dim=1).squeeze())  &#47&#47 [T, h, w]
        pred_mask_vis = colorize_semseg(pred_mask, num_classes=SYNPICK_CLASSES)  &#47&#47 [T, 3, h, w]

        frames_colorized = colorize_semseg(postprocess_mask(frames_seg.squeeze()), num_classes=SYNPICK_CLASSES).unsqueeze(dim=0) &#47&#47 [1, T, 3, h, w]
        frames_colorized_vis<a id="change"> = </a>postprocess_img(frames_colorized.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
        input_colorized = frames_colorized[:VIDEO_IN_LENGTH]

        colorized_then_pred = pred_colorized_mask_model.pred_n(input_colorized, pred_length=VIDEO_PRED_LENGTH)</code></pre><h3>After Change</h3><pre><code class='java'>
            pred_then_colorized_vis = colorize_semseg(postprocess_mask(pred_rgb), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2) &#47&#47 [T, 3, h, w]

            frames_seg = torch.stack([seg_model(frames[:, i]) for i in range(frames.shape[1])], dim=1).argmax(dim=2)  &#47&#47 [1, T, 1, h, w]
            frames_seg_in = torch.stack([(frames_seg == i) for i in <a id="change">range(</a>SYNPICK_CLASSES<a id="change">)</a>], dim=2).float()  &#47&#47 [1, T, c, h, w] one-hot float
            input_seg = frames_seg_in[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, c, h, w]
            pred_mask = pred_mask_model.pred_n(input_seg, pred_length=VIDEO_PRED_LENGTH).argmax(dim=2)  &#47&#47 [1, n, 1, h, w]
            pred_mask = torch.cat([input_seg.argmax(dim=2), pred_mask], dim=1).squeeze()  &#47&#47 [T, h, w]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ais-bonn/vp-suite/commit/13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3#diff-e07d70acfca9139cbf2c37b7a0074bdfbb966d41dc6c7edcc2cef05e78c00af0L16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38469675</div><div id='project'> Project Name: ais-bonn/vp-suite</div><div id='commit'> Commit Name: 13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3</div><div id='time'> Time: 2021-08-02</div><div id='author'> Author: boltres@ais.uni-bonn.de</div><div id='file'> File Name: scripts/visualize_4_way.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: visualize_4_way(1)</div><div id='n_method'> N Method Name: visualize_4_way(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/visualize_4_way.py</div><div id='n_file'> N File Name: scripts/visualize_4_way.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 73</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 74</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    features_id = None
    features_row = None

    for root, dirs, files in <a id="change">tqdm(</a>os.walk(feature_dir)<a id="change">)</a>:
        for name in files:
            path<a id="change"> = </a>os.path.join(root, name)
            features = np.load(path)
            centroid_dist = np.linalg.norm(features - centroid, axis=1)
            if np.min(centroid_dist) &lt; min_dist:</code></pre><h3>After Change</h3><pre><code class='java'>
    features_id = None
    features_row = None

    for i in tqdm(<a id="change">range(</a>counter<a id="change">)</a>):
        centroid_dist = np.linalg.norm(features[i] - centroid, axis=1)
        if np.min(centroid_dist) &lt; min_dist:
            path = feature_paths[i]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ammesatyajit/videobert/commit/e6cec027ebc3f4a4a2270a4e406ea9dc9fd16856#diff-1fe6549e10b9d64ba66aa03fb53a4593b5a8c238513694bbaf1f8a03f1852d20L24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38469689</div><div id='project'> Project Name: ammesatyajit/videobert</div><div id='commit'> Commit Name: e6cec027ebc3f4a4a2270a4e406ea9dc9fd16856</div><div id='time'> Time: 2021-01-01</div><div id='author'> Author: ammesatyajit@gmail.com</div><div id='file'> File Name: VideoBERT/data/centroid_to_img.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: img_path_from_centroid(3)</div><div id='n_method'> N Method Name: img_path_from_centroid(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: VideoBERT/data/centroid_to_img.py</div><div id='n_file'> N File Name: VideoBERT/data/centroid_to_img.py</div><div id='m_start'> M Start Line: 30</div><div id='m_end'> M End Line: 41</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 39</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            List of averaged scores
        
        self.model.eval()
        for (X, y, bias, X_mask, y_mask, time_stamps) in <a id="change">tqdm(</a>self.valid_dataloader<a id="change">)</a>:
            X = X.to(self.device)
            y = y.to(self.device)
            bias = bias.to(self.device)
            X_mask = X_mask.to(self.device)
            y_mask = y_mask.to(self.device)
            if time_stamps is not None:
                time_stamps = time_stamps.to(self.device)
            with torch.no_grad():
                Z = self.model(X, bias, X_mask, time_stamps)
            Z = self.scaler.inv_transform(Z)
            y<a id="change"> = </a>self.scaler.inv_transform(y)
            for metric in self.metrics:
                metric.update(Z, y, y_mask)
        ave_scores = []</code></pre><h3>After Change</h3><pre><code class='java'>
                    Z = self.model(X, bias, X_mask, time_stamps)
                batch_size = X.size(0)
                if self.denorm is True:
                    for i in <a id="change">range(</a>batch_size<a id="change">)</a>:
                        Z[i] = y_inv_transforms[i](Z[i])
                        y[i] = y_inv_transforms[i](y[i])
                for metric in self.metrics:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/takuyashintate/tsts/commit/e952ef63302c29b32c95e17f46dfcaabd2ad1b85#diff-38852a333fabc2d9fd8c03e25fb7cb67a9c31d255cc4c9f612c65b9ce2ed52e3L126' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38469670</div><div id='project'> Project Name: takuyashintate/tsts</div><div id='commit'> Commit Name: e952ef63302c29b32c95e17f46dfcaabd2ad1b85</div><div id='time'> Time: 2021-09-14</div><div id='author'> Author: kmdbn2hs@gmail.com</div><div id='file'> File Name: tsts/trainers/trainer.py</div><div id='m_class'> M Class Name: SupervisedTrainer</div><div id='n_method'> N Class Name: SupervisedTrainer</div><div id='m_method'> M Method Name: on_val(1)</div><div id='n_method'> N Method Name: on_val(1)</div><div id='m_parent_class'> M Parent Class: Trainer</div><div id='n_parent_class'> N Parent Class: Trainer</div><div id='m_file'> M File Name: tsts/trainers/trainer.py</div><div id='n_file'> N File Name: tsts/trainers/trainer.py</div><div id='m_start'> M Start Line: 135</div><div id='m_end'> M End Line: 149</div><div id='n_start'> N Start Line: 146</div><div id='n_end'> N End Line: 178</div><BR>