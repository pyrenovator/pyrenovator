<html><h3>Pattern ID :28939
</h3><img src='85183395.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        
        print("开始录音......")
        frames = []
        <a id="change">for </a>i in <a id="change">range(</a>0, int(self.rate / self.chunk * record_seconds)<a id="change">)</a><a id="change">:
            </a>data = self.stream.read(self.chunk)
            frames.append(data)

        print("录音已结束!")</code></pre><h3>After Change</h3><pre><code class='java'>
        
        print("开始录音......")
        num_frames = int(record_seconds * self.sample_rate)
        data = <a id="change">self.default_mic.record(samplerate=self.sample_rate, numframes=num_frames, channels=self.channels)</a>
        audio_data = data.squeeze()
        print("录音已结束!")
        if save_path is not None:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/yeyupiaoling/voiceprintrecognition-pytorch/commit/5c4517b82c3634a6908e35f143fb908e35fd71d8#diff-daa3f561c21def600c9ecfb843318cbd4498759e57be78a86047a8bba251d271L24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 85183395</div><div id='project'> Project Name: yeyupiaoling/voiceprintrecognition-pytorch</div><div id='commit'> Commit Name: 5c4517b82c3634a6908e35f143fb908e35fd71d8</div><div id='time'> Time: 2023-03-23</div><div id='author'> Author: yeyupiaoling@foxmail.com</div><div id='file'> File Name: mvector/utils/record.py</div><div id='m_class'> M Class Name: RecordAudio</div><div id='n_method'> N Class Name: RecordAudio</div><div id='m_method'> M Method Name: record(3)</div><div id='n_method'> N Method Name: record(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: mvector/utils/record.py</div><div id='n_file'> N File Name: mvector/utils/record.py</div><div id='m_start'> M Start Line: 31</div><div id='m_end'> M End Line: 45</div><div id='n_start'> N Start Line: 24</div><div id='n_end'> N End Line: 30</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        logging.debug(f"Training with {training_epochs} epochs and {training_batches} batches")
        logging.debug(f"Batch size is {self.batch_size}; dataset size is {len(dataset)}")

        <a id="change">for </a>epoch in <a id="change">range(</a>training_epochs<a id="change">)</a><a id="change">:

            </a>loss_meter = AverageMeter()
            dataiter = iter(dataloader)
            &#47&#47 Set encoder and decoder to be in training mode
</code></pre><h3>After Change</h3><pre><code class='java'>
                logger.record(&quotweight_norm&quot, weight_norm.item())
                logger.record(&quotepoch&quot, epochs_trained)
                logger.record(&quotwithin_epoch_step&quot, step)
                <a id="change">logger.record(</a>&quotbatches_trained&quot, batches_trained<a id="change">)</a>
                logger.dump(step=batches_trained)
                batches_trained += 1
                if batches_trained &gt;= training_batches:
                    logging.info(f"Breaking out of training in epoch {epochs_trained} because max batches "</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/406d01948fae64f0ec8b970402ffc13856832c28#diff-da75b71a2421881ac87f16bdedbc66a6eee21a60650cb052fb123cfe1436b72fL204' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 85183394</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: 406d01948fae64f0ec8b970402ffc13856832c28</div><div id='time'> Time: 2020-11-10</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: src/il_representations/algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: learn(4)</div><div id='n_method'> N Method Name: learn(4)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: src/il_representations/algos/representation_learner.py</div><div id='n_file'> N File Name: src/il_representations/algos/representation_learner.py</div><div id='m_start'> M Start Line: 224</div><div id='m_end'> M End Line: 332</div><div id='n_start'> N Start Line: 224</div><div id='n_end'> N End Line: 336</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        logging.debug(f"Training with {training_epochs} epochs and {training_batches} batches")
        logging.debug(f"Batch size is {self.batch_size}; dataset size is {len(dataset)}")

        <a id="change">for </a>epoch in <a id="change">range(</a>training_epochs<a id="change">)</a><a id="change">:

            </a>loss_meter = AverageMeter()
            dataiter = iter(dataloader)
            &#47&#47 Set encoder and decoder to be in training mode
</code></pre><h3>After Change</h3><pre><code class='java'>
                logger.record(&quotweight_norm&quot, weight_norm.item())
                logger.record(&quotepoch&quot, epochs_trained)
                logger.record(&quotwithin_epoch_step&quot, step)
                <a id="change">logger.record(</a>&quotbatches_trained&quot, batches_trained<a id="change">)</a>
                logger.dump(step=batches_trained)
                batches_trained += 1
                if batches_trained &gt;= training_batches:
                    logging.info(f"Breaking out of training in epoch {epochs_trained} because max batches "</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/a862749c9f67968ddec51d83ceb5ff286517ab57#diff-da75b71a2421881ac87f16bdedbc66a6eee21a60650cb052fb123cfe1436b72fL204' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 85183397</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: a862749c9f67968ddec51d83ceb5ff286517ab57</div><div id='time'> Time: 2020-11-10</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: src/il_representations/algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: learn(4)</div><div id='n_method'> N Method Name: learn(4)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: src/il_representations/algos/representation_learner.py</div><div id='n_file'> N File Name: src/il_representations/algos/representation_learner.py</div><div id='m_start'> M Start Line: 224</div><div id='m_end'> M End Line: 332</div><div id='n_start'> N Start Line: 224</div><div id='n_end'> N End Line: 336</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        print("开始录音......")
        frames = []
        <a id="change">for </a>i in <a id="change">range(</a>0, int(self.rate / self.chunk * record_seconds)<a id="change">)</a><a id="change">:
            </a>data = self.stream.read(self.chunk)
            frames.append(data)

        print("录音已结束!")</code></pre><h3>After Change</h3><pre><code class='java'>
        
        print("开始录音......")
        num_frames = int(record_seconds * self.sample_rate)
        data = <a id="change">self.default_mic.record(samplerate=self.sample_rate, numframes=num_frames, channels=self.channels)</a>
        audio_data = data.squeeze()
        print("录音已结束!")
        if save_path is not None:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yeyupiaoling/audioclassification-pytorch/commit/4e40d2876f4e146adf88a406af712366ff36d830#diff-372e3443ea76f582317c62a8b741bc051cfefd414fae0fda934132a60f131ef8L23' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 85183396</div><div id='project'> Project Name: yeyupiaoling/audioclassification-pytorch</div><div id='commit'> Commit Name: 4e40d2876f4e146adf88a406af712366ff36d830</div><div id='time'> Time: 2023-03-23</div><div id='author'> Author: yeyupiaoling@foxmail.com</div><div id='file'> File Name: macls/utils/record.py</div><div id='m_class'> M Class Name: RecordAudio</div><div id='n_method'> N Class Name: RecordAudio</div><div id='m_method'> M Method Name: record(3)</div><div id='n_method'> N Method Name: record(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: macls/utils/record.py</div><div id='n_file'> N File Name: macls/utils/record.py</div><div id='m_start'> M Start Line: 31</div><div id='m_end'> M End Line: 45</div><div id='n_start'> N Start Line: 24</div><div id='n_end'> N End Line: 30</div><BR>