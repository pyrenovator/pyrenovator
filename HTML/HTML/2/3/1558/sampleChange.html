<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            dist.barrier()
            return None, {}
        &#47&#47
        <a id="change">if </a>dataloader is None:
            return None, {}
        &#47&#47
        lmodel = self.lmodel
        device = self.device
        model_r = lmodel.model
        lmodel.model = de_parallel(lmodel.model)
        metrics_r: Dict[str, bool] = {k: m._to_sync for k, m in lmodel.metrics.items()}
        for m in lmodel.metrics.values():
            &#47&#47 torchmetrics(&gt;=0.9.3, &lt;=0.10.1已测试) private variable. I don&quott know whether it will be changed later.
            &#47&#47   You can raise issue if finding error.
            &#47&#47 default: sync_on_compute = True
            m._to_sync = False
            m.sync_on_compute = False
        &#47&#47
        if mode == "val":
            val_test_epoch_start = lmodel.validation_epoch_start
            val_test_step = lmodel.validation_step
            val_test_epoch_end = lmodel.validation_epoch_end
        elif mode == "test":
            val_test_epoch_start = lmodel.test_epoch_start
            val_test_step = lmodel.test_step
            val_test_epoch_end = lmodel.test_epoch_end
        else:
            raise ValueError(f"mode: {mode}")
        &#47&#47
        val_test_epoch_start()
        &#47&#47
        rec_mes: Dict[str, float] = {}  &#47&#47 Save the most recent mes. (for prog_bar)
        mean_metrics: Dict[str, MeanMetric] = {}
        prog_bar = tqdm(total=len(dataloader), desc=desc, dynamic_ncols=True)
        batch_idx = -1  &#47&#47 avoid unbound
        <a id="change">self.prog_bar_mean.clear()</a>
        for batch_idx, batch in enumerate(dataloader):
            self.new_mes.clear()
            with torch.no_grad():
                batch = lmodel.batch_to_device(batch, device)</code></pre><h3>After Change</h3><pre><code class='java'>
        if dataloader is not None:
            prog_bar = tqdm(total=len(dataloader), desc=desc, dynamic_ncols=True)
            batch_idx = -1  &#47&#47 avoid unbound
            <a id="change">self.prog_bar_mean.clear()</a>
            for batch_idx, batch in enumerate(dataloader):
                self.new_mes.clear()
                with torch.no_grad():
                    batch = lmodel.batch_to_device(batch, device)</code></pre>