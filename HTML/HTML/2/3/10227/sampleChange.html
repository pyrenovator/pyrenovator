<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def grad_denom(self, samples):
        Gradient normalization term for DataParallel training.
        <a id="change">raise </a>NotImplementedError

    def forward(self, model, sample, grad_denom):
        Compute the loss for the given sample and network output.</code></pre><h3>After Change</h3><pre><code class='java'>
    @staticmethod
    def grad_denom(sample_sizes):
        Compute the gradient denominator for a set of sample sizes.
        <a id="change">return </a><a id="change">sum(</a>sample_sizes<a id="change">)</a>
</code></pre>