<html><h3>Pattern ID :12950
</h3><img src='43617433.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 Cast inputs & grad outputs to backend dtype
        inputs = inputs.to(requested_backends[0].dtype)
        grads = <a id="change">grads.to(</a>requested_backends[-1].dtype<a id="change">)</a>

        &#47&#47 Run a forward chain to collect intermediate inputs
        &#47&#47 Note that we do not forward for the last module since we do not need its output
        inter_inputs = [inputs]</code></pre><h3>After Change</h3><pre><code class='java'>
        requested_uids = self._check_uids(request.uid)
        requested_backends = tuple(self.module_backends[uid] for uid in requested_uids)

        grads = <a id="change">await </a>_rpc_backward(*flat_tensors, requested_backends=requested_backends)

        &#47&#47 Modify grad_inputs_schema to support grad_prompts
        assert len(requested_backends[0].args_schema) == 1 and len(grads) in (1, 2)  &#47&#47 TODO generalize

        grad_inputs_schema_with_prompts = (
            requested_backends[0].args_schema * len(grads)<a id="change">,
            requested_backends[0].kwargs_schema</a>,
        )  &#47&#47 TODO generalize

        &#47&#47 Serialize the overall grad_input and respond</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/bigscience-workshop/distributed-bloom/commit/6095f58681bde14962c5023b75a2219c525cbe4c#diff-65ada620fb21ff82c2b88abea8bc2cf7fdd27241f03553f7e7d076339dbaab55L133' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 43617433</div><div id='project'> Project Name: bigscience-workshop/distributed-bloom</div><div id='commit'> Commit Name: 6095f58681bde14962c5023b75a2219c525cbe4c</div><div id='time'> Time: 2022-08-12</div><div id='author'> Author: dmitrybaranchuk@gmail.com</div><div id='file'> File Name: src/server/handler.py</div><div id='m_class'> M Class Name: TransformerConnectionHandler</div><div id='n_method'> N Class Name: TransformerConnectionHandler</div><div id='m_method'> M Method Name: rpc_backward(3)</div><div id='n_method'> N Method Name: rpc_backward(3)</div><div id='m_parent_class'> M Parent Class: ConnectionHandler</div><div id='n_parent_class'> N Parent Class: ConnectionHandler</div><div id='m_file'> M File Name: src/server/handler.py</div><div id='n_file'> N File Name: src/server/handler.py</div><div id='m_start'> M Start Line: 142</div><div id='m_end'> M End Line: 168</div><div id='n_start'> N Start Line: 133</div><div id='n_end'> N End Line: 145</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        requested_backends = tuple(self.module_backends[uid] for uid in requested_uids)

        &#47&#47 Cast inputs to backend dtype
        hidden_states = [<a id="change">tensor.to(</a>requested_backends[0].dtype<a id="change">)</a> for tensor in hidden_states]

        &#47&#47 Run a chain of requested backends
        for backend in requested_backends:</code></pre><h3>After Change</h3><pre><code class='java'>
        requested_uids = self._check_uids(uid_str)
        requested_backends = tuple(self.module_backends[uid] for uid in requested_uids)

        hidden_states = <a id="change">await </a>_rpc_forward(flat_inputs, requested_backends)
        assert isinstance(hidden_states, torch.Tensor) and hidden_states.ndim == 3

        &#47&#47 Serialize the overall output
        serialized_output = [
            serialize_torch_tensor(result.to(proto.dtype), proto.compression, allow_inplace=True)
            for result, proto in zip((hidden_states<a id="change"></a>,), nested_flatten(requested_backends[-1].outputs_schema))
        ]

        &#47&#47 Split the serialized_output for streaming and respond to client</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bigscience-workshop/distributed-bloom/commit/6095f58681bde14962c5023b75a2219c525cbe4c#diff-65ada620fb21ff82c2b88abea8bc2cf7fdd27241f03553f7e7d076339dbaab55L107' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 43617435</div><div id='project'> Project Name: bigscience-workshop/distributed-bloom</div><div id='commit'> Commit Name: 6095f58681bde14962c5023b75a2219c525cbe4c</div><div id='time'> Time: 2022-08-12</div><div id='author'> Author: dmitrybaranchuk@gmail.com</div><div id='file'> File Name: src/server/handler.py</div><div id='m_class'> M Class Name: TransformerConnectionHandler</div><div id='n_method'> N Class Name: TransformerConnectionHandler</div><div id='m_method'> M Method Name: rpc_forward_stream(3)</div><div id='n_method'> N Method Name: rpc_forward_stream(3)</div><div id='m_parent_class'> M Parent Class: ConnectionHandler</div><div id='n_parent_class'> N Parent Class: ConnectionHandler</div><div id='m_file'> M File Name: src/server/handler.py</div><div id='n_file'> N File Name: src/server/handler.py</div><div id='m_start'> M Start Line: 111</div><div id='m_end'> M End Line: 130</div><div id='n_start'> N Start Line: 111</div><div id='n_end'> N End Line: 121</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 Cast inputs & grad outputs to backend dtype
        inputs = inputs.to(requested_backends[0].dtype)
        grads = <a id="change">grads.to(</a>requested_backends[-1].dtype<a id="change">)</a>

        &#47&#47 Run a forward chain to collect intermediate inputs
        &#47&#47 Note that we do not forward for the last module since we do not need its outputs
        inter_inputs = [inputs]</code></pre><h3>After Change</h3><pre><code class='java'>
        requested_uids = self._check_uids(uids_header)
        requested_backends = tuple(self.module_backends[uid] for uid in requested_uids)

        grads = <a id="change">await </a>_rpc_backward(*flat_tensors, requested_backends=requested_backends)

        &#47&#47 Modify grad_inputs_schema to support grad_prompts
        assert len(requested_backends[0].args_schema) == 1 and len(grads) in (1, 2)  &#47&#47 TODO generalize
        grad_inputs_schema_with_prompts = (
            requested_backends[0].args_schema * len(grads)<a id="change">,
            requested_backends[0].kwargs_schema</a>,
        )  &#47&#47 TODO generalize

        &#47&#47 Serialize the overall grad_inputs</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bigscience-workshop/distributed-bloom/commit/6095f58681bde14962c5023b75a2219c525cbe4c#diff-65ada620fb21ff82c2b88abea8bc2cf7fdd27241f03553f7e7d076339dbaab55L175' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 43617434</div><div id='project'> Project Name: bigscience-workshop/distributed-bloom</div><div id='commit'> Commit Name: 6095f58681bde14962c5023b75a2219c525cbe4c</div><div id='time'> Time: 2022-08-12</div><div id='author'> Author: dmitrybaranchuk@gmail.com</div><div id='file'> File Name: src/server/handler.py</div><div id='m_class'> M Class Name: TransformerConnectionHandler</div><div id='n_method'> N Class Name: TransformerConnectionHandler</div><div id='m_method'> M Method Name: rpc_backward_stream(3)</div><div id='n_method'> N Method Name: rpc_backward_stream(3)</div><div id='m_parent_class'> M Parent Class: ConnectionHandler</div><div id='n_parent_class'> N Parent Class: ConnectionHandler</div><div id='m_file'> M File Name: src/server/handler.py</div><div id='n_file'> N File Name: src/server/handler.py</div><div id='m_start'> M Start Line: 179</div><div id='m_end'> M End Line: 208</div><div id='n_start'> N Start Line: 159</div><div id='n_end'> N End Line: 175</div><BR>