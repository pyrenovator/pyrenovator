<html><h3>Pattern ID :29671
</h3><img src='87944525.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        has_pretrained_rat_model = os.path.isfile(f&quot{pretrained_model_name_or_path}/pytorch_model.bin&quot)
        if has_pretrained_rat_model:
            if model_cls.__name__.startswith(&quotAutoModel&quot):
                <a id="change">raise NotImplementedError(
                    </a>"`model_cls` cannot be an AutoModel class when loading a pretrained RATransformer. "
                    "Please use a specific `model_cls` class. "
                    "For example, for T5 with AutoModelForSeq2SeqLM, use `model_cls=T5ForConditionalGeneration`"<a id="change">
                )</a>
            def model_cls_load_pretrained_model_prefix_function(function):
                @functools.wraps(function)
                def run(model, *args, **kwargs):
                    &#47&#47 change attention layers with relational ones, if not done before</code></pre><h3>After Change</h3><pre><code class='java'>

        pretrained_tokenizer_name_or_path = pretrained_tokenizer_name_or_path or pretrained_model_name_or_path
        if pretrained_tokenizer_name_or_path is not None:
            self.tokenizer = <a id="change">tokenizer_cls.from_pretrained(
                pretrained_model_name_or_path=pretrained_tokenizer_name_or_path, **tokenizer_kwargs
            )</a>
        else:
            logger.error(
                "`pretrained_model_name_or_path=None` and `pretrained_tokenizer_name_or_path=None` is not supported. "
                "Please pass at least `pretrained_tokenizer_name_or_path` to initialize the tokenizer"</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/joaolages/ratransformers/commit/36bd3147f14e9d87a89d1917f4313d3eb9954e39#diff-f18d42174dd6ac7632bfaa6eae4cb9a524e9429517cc0385e8b4f3fc70f34ff8L56' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87944525</div><div id='project'> Project Name: joaolages/ratransformers</div><div id='commit'> Commit Name: 36bd3147f14e9d87a89d1917f4313d3eb9954e39</div><div id='time'> Time: 2022-12-13</div><div id='author'> Author: joaop.glages@gmail.com</div><div id='file'> File Name: src/ratransformers/__init__.py</div><div id='m_class'> M Class Name: RATransformer</div><div id='n_method'> N Class Name: RATransformer</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/ratransformers/__init__.py</div><div id='n_file'> N File Name: src/ratransformers/__init__.py</div><div id='m_start'> M Start Line: 56</div><div id='m_end'> M End Line: 138</div><div id='n_start'> N Start Line: 120</div><div id='n_end'> N End Line: 218</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        return len(self._tokenizer)

    def load(self, save_dir):
        <a id="change">raise NotImplementedError()</a>

    def pad(self, batch):
        
        batch: a List of List of integers</code></pre><h3>After Change</h3><pre><code class='java'>
        return len(self._tokenizer)

    def load(self, save_dir):
        self._tokenizer = <a id="change">AutoTokenizer.from_pretrained(</a>save_dir<a id="change">, config=self.config, cache_dir=self._cache)</a>
        &#47&#47 HACK we cannot save the tokenizer without this
        del self._tokenizer.init_kwargs[&quotconfig&quot]

        if self.max_generative_vocab is not None:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/6dd8f5b221db4adc2f120bf8b5f07f6de8a3f838#diff-9af5dd141b0e34d2f5c949979780fee4bbcf029a9df5dbd3705907a7dc380d84L62' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87944527</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: 6dd8f5b221db4adc2f120bf8b5f07f6de8a3f838</div><div id='time'> Time: 2020-12-05</div><div id='author'> Author: gcampagn@cs.stanford.edu</div><div id='file'> File Name: genienlp/data_utils/numericalizer/transformer.py</div><div id='m_class'> M Class Name: TransformerNumericalizer</div><div id='n_method'> N Class Name: TransformerNumericalizer</div><div id='m_method'> M Method Name: load(2)</div><div id='n_method'> N Method Name: load(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: genienlp/data_utils/numericalizer/transformer.py</div><div id='n_file'> N File Name: genienlp/data_utils/numericalizer/transformer.py</div><div id='m_start'> M Start Line: 63</div><div id='m_end'> M End Line: 63</div><div id='n_start'> N Start Line: 60</div><div id='n_end'> N End Line: 68</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            ModelCheckpoint.load_objects(to_load=to_load,
                                         checkpoint=checkpoint)  &#47&#47 overwrite pretrained weights w/ fine-tuned weights
        else:
            <a id="change">raise NotImplementedError(</a>&quot"hf" and "ignite" values are supported for config field "mode_load".&quot<a id="change">)</a>

        res.forward_func = res.get_forward_func(name_model=res.name_model, model=res.model)
        res.pad_token_id = config[&quottokenizer&quot].pad_token_id
        res.special_token_ids = config[&quottokenizer&quot].all_special_ids</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 TODO: Assert that num_labels in dataset corresponds to classification head in model
            res.model = AutoModelForSequenceClassification.from_pretrained(res.name_model, num_labels=res.num_labels)
        else:
            res.model = <a id="change">getattr(transformers, config[&quotmodel&quot][&quotclass&quot]).from_pretrained(</a>res.name_model<a id="change">)</a>

        if &quotmode_load&quot in config[&quotmodel&quot]:
            res.mode_load = config[&quotmodel&quot][&quotmode_load&quot]
            if res.mode_load == &quotignite&quot:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/dfki-nlp/thermostat/commit/e427fdee254581ec50f1b2b47f3a07438fd8fd16#diff-6fb6e4fe005e505ca8a826041d4e8e8d7005d3899021e2562bc15da75997abf0L122' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87944526</div><div id='project'> Project Name: dfki-nlp/thermostat</div><div id='commit'> Commit Name: e427fdee254581ec50f1b2b47f3a07438fd8fd16</div><div id='time'> Time: 2021-07-10</div><div id='author'> Author: feldhusnlp@gmail.com</div><div id='file'> File Name: src/thermostat/explain.py</div><div id='m_class'> M Class Name: ExplainerAutoModelInitializer</div><div id='n_method'> N Class Name: ExplainerAutoModelInitializer</div><div id='m_method'> M Method Name: from_config(2)</div><div id='n_method'> N Method Name: from_config(2)</div><div id='m_parent_class'> M Parent Class: ExplainerCaptum</div><div id='n_parent_class'> N Parent Class: ExplainerCaptum</div><div id='m_file'> M File Name: src/thermostat/explain.py</div><div id='n_file'> N File Name: src/thermostat/explain.py</div><div id='m_start'> M Start Line: 123</div><div id='m_end'> M End Line: 151</div><div id='n_start'> N Start Line: 122</div><div id='n_end'> N End Line: 141</div><BR>