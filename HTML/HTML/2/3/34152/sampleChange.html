<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    args.n_gpu = torch.cuda.device_count()

    set_seed(args)
    args.model_type = <a id="change">args.model_type.lower()</a>

    if args.n_gpu &gt; 1:
        if args.input_file is None:
            raise ValueError(&quotCannot use multiple GPUs when reading from stdin. You should provide an --input_file&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 bart and mbart share the same config
        &#47&#47 check which model we are actually using
        if args.model_type == &quotbart&quot:
            <a id="change">if </a><a id="change">config.normalize_before and config.add_final_layer_norm and config.scale_embedding</a>:
                args.model_type = &quotmbart&quot
    else:
        raise ValueError(&quotModel should be either GPT2, BART, or MBART&quot)</code></pre>