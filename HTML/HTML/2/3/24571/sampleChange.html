<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    train_source_iter = ForeverDataIterator(train_source_loader)
    train_target_iter = ForeverDataIterator(train_target_loader)

    iters_per_epoch<a id="change"> = </a>args.iters_per_epoch

    &#47&#47 create model
    cudnn.benchmark = True
    print("=&gt; using pre-trained model &quot{}&quot".format(args.arch))
    backbone = models.__dict__[args.arch](pretrained=True)
    num_classes = train_source_dataset.num_classes
    classifier = adaptation.dan.Classifier(backbone, num_classes).cuda()

    all_parameters = classifier.get_parameters()
    classifier = torch.nn.DataParallel(classifier).cuda()

    &#47&#47 define optimizer
    optimizer = torch.optim.SGD(all_parameters, args.lr, momentum=args.momentum,
                                weight_decay=args.wd, nesterov=True)

    &#47&#47 define loss function
    mkmmd_loss = adaptation.dan.MultipleKernelMaximumMeanDiscrepancy(
        [adaptation.dan.GaussianKernel(alpha=2 ** k) for k in range(-3, 2)]
    )

    &#47&#47 start training
    best_acc1 = 0.
    for epoch in range(args.epochs):
        print("lr={:.5f}".format(optimizer.param_groups[0][&quotlr&quot]))
        &#47&#47 train for one epoch
        <a id="change">train(</a>train_source_iter, train_target_iter, classifier, optimizer, epoch, iters_per_epoch, mkmmd_loss, args<a id="change">)</a>

        &#47&#47 evaluate on validation set
        acc1 = validate(val_loader, classifier, args)
</code></pre><h3>After Change</h3><pre><code class='java'>
        normalize
    ])

    dataset = <a id="change">datasets.__dict__[args.data]</a>
    train_source_dataset = dataset(root=args.root, task=args.source, download=True, transform=train_transform)
    train_source_loader = DataLoader(train_source_dataset, batch_size=args.batch_size,
                                     shuffle=True, num_workers=args.workers, drop_last=True)
    train_target_dataset = dataset(root=args.root, task=args.target, download=True, transform=train_transform)</code></pre>