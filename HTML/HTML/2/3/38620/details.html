<html><h3>Pattern ID :38620
</h3><img src='110427121.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        self.loss_calculator = loss_calculator(device=self.device, **to_dict(loss_calculator_kwargs))

        self.optimizer = <a id="change">optimizer(</a>itertools.chain(self.encoder.parameters(), self.decoder.parameters())<a id="change">,
                                   **to_dict(optimizer_kwargs))</a>

        &#47&#47 TODO make the scheduler parameterizable
        self.scheduler = LinearWarmupCosine(self.optimizer, warmup_epochs, pretrain_epochs)
        self.writer = SummaryWriter(log_dir=os.path.join(log_dir, &quotcontrastive_tf_logs&quot), flush_secs=15)</code></pre><h3>After Change</h3><pre><code class='java'>
        trainable_encoder_params = [p for p in self.encoder.parameters() if p.requires_grad]
        trainable_decoder_params = [p for p in self.decoder.parameters() if p.requires_grad]
        import pdb; pdb.set_trace()
        self.optimizer<a id="change"> = </a><a id="change">optimizer(</a>trainable_encoder_params + trainable_decoder_params<a id="change">,
                                   **to_dict(optimizer_kwargs))</a>

        &#47&#47 TODO make the scheduler parameterizable
        self.scheduler = LinearWarmupCosine(self.optimizer, warmup_epochs, pretrain_epochs)
        self.writer = SummaryWriter(log_dir=os.path.join(log_dir, &quotcontrastive_tf_logs&quot), flush_secs=15)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/0af0c47ba401664b52de1db6b10a504c7d64ad2d#diff-11bd63b8ace5530605783f45e027231fff8e98dafa1dbb5675fe0c042e1f07dbL86' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110427121</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: 0af0c47ba401664b52de1db6b10a504c7d64ad2d</div><div id='time'> Time: 2020-07-17</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: __init__(24)</div><div id='n_method'> N Method Name: __init__(24)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: algos/representation_learner.py</div><div id='n_file'> N File Name: algos/representation_learner.py</div><div id='m_start'> M Start Line: 86</div><div id='m_end'> M End Line: 87</div><div id='n_start'> N Start Line: 86</div><div id='n_end'> N End Line: 90</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        self.loss_calculator = loss_calculator(device=self.device, **to_dict(loss_calculator_kwargs))

        self.optimizer = <a id="change">optimizer(</a>itertools.chain(self.encoder.parameters(), self.decoder.parameters())<a id="change">,
                                   **to_dict(optimizer_kwargs))</a>

        &#47&#47 TODO make the scheduler parameterizable
        self.scheduler = LinearWarmupCosine(self.optimizer, warmup_epochs, pretrain_epochs)
        self.writer = SummaryWriter(log_dir=os.path.join(log_dir, &quotcontrastive_tf_logs&quot), flush_secs=15)</code></pre><h3>After Change</h3><pre><code class='java'>
        trainable_encoder_params = [p for p in self.encoder.parameters() if p.requires_grad]
        trainable_decoder_params = [p for p in self.decoder.parameters() if p.requires_grad]
        import pdb; pdb.set_trace()
        self.optimizer<a id="change"> = </a><a id="change">optimizer(</a>trainable_encoder_params + trainable_decoder_params<a id="change">,
                                   **to_dict(optimizer_kwargs))</a>

        &#47&#47 TODO make the scheduler parameterizable
        self.scheduler = LinearWarmupCosine(self.optimizer, warmup_epochs, pretrain_epochs)
        self.writer = SummaryWriter(log_dir=os.path.join(log_dir, &quotcontrastive_tf_logs&quot), flush_secs=15)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/756ee795a10ea474daddd890ad61c62dfd9d5817#diff-11bd63b8ace5530605783f45e027231fff8e98dafa1dbb5675fe0c042e1f07dbL41' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110427119</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: 756ee795a10ea474daddd890ad61c62dfd9d5817</div><div id='time'> Time: 2020-07-17</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: __init__(24)</div><div id='n_method'> N Method Name: __init__(24)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: algos/representation_learner.py</div><div id='n_file'> N File Name: algos/representation_learner.py</div><div id='m_start'> M Start Line: 86</div><div id='m_end'> M End Line: 87</div><div id='n_start'> N Start Line: 86</div><div id='n_end'> N End Line: 90</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def _instantiate_the_optimizer(self, optimizer: Any) -&gt; Optimizer:
        model_parameters = list(self.model.parameters())
        return <a id="change">optimizer(</a>model_parameters<a id="change">, lr=0.001, momentum=0.9)</a>

    @staticmethod
    def _get_current_batch_size(features: to.Tensor) -&gt; int:
        return len(features)</code></pre><h3>After Change</h3><pre><code class='java'>
    def _instantiate_the_optimizer(self, optimizer: Any) -&gt; Optimizer:
        model_parameters = list(self.model.parameters())
        try:
            optimizer<a id="change"> = </a><a id="change">optimizer(</a>model_parameters<a id="change">, lr=0.001, momentum=0.9)</a>
        except:
            optimizer = optimizer(model_parameters, lr=0.001)
        return optimizer
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/kovanostra/message-passing-neural-network/commit/c8f90319564de072a46ef1d178e64d9323a1a6e3#diff-614e2c9f4bfaf42439d9422237607a3a8a7486013f341d78a405af3cc84434b7L100' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110427115</div><div id='project'> Project Name: kovanostra/message-passing-neural-network</div><div id='commit'> Commit Name: c8f90319564de072a46ef1d178e64d9323a1a6e3</div><div id='time'> Time: 2020-05-23</div><div id='author'> Author: kovanostra@gmail.com</div><div id='file'> File Name: message_passing_nn/trainer/model_trainer.py</div><div id='m_class'> M Class Name: ModelTrainer</div><div id='n_method'> N Class Name: ModelTrainer</div><div id='m_method'> M Method Name: _instantiate_the_optimizer(2)</div><div id='n_method'> N Method Name: _instantiate_the_optimizer(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: message_passing_nn/trainer/model_trainer.py</div><div id='n_file'> N File Name: message_passing_nn/trainer/model_trainer.py</div><div id='m_start'> M Start Line: 101</div><div id='m_end'> M End Line: 102</div><div id='n_start'> N Start Line: 101</div><div id='n_end'> N End Line: 106</div><BR>