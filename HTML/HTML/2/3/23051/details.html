<html><h3>Pattern ID :23051
</h3><img src='73042938.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    ws = w5 - torch.cumsum(w3s, dim=1)
    d = -(r * w)
    d.mul_((w.abs() &gt; 1e-8).float())
    s = torch.cat(((-w5.squeeze() * <a id="change">rs[:, 0]</a>).unsqueeze(1),
                   torch.cumsum((-rs2 + rs) * ws, dim=1) - w5 * rs[:, 0].unsqueeze(-1)), 1)

    c4 = s[:, 0] + c &lt; 0</code></pre><h3>After Change</h3><pre><code class='java'>
    c.mul_(ind2)

    r = torch.max(t / w, (t - 1) / w).clamp(min=-1e12, max=1e12)
    <a id="change">r.masked_fill_(</a>w.abs() &lt; 1e-8, 1e12<a id="change">)</a>
    r[r == -1e12] *= -1
    rs, indr = torch.sort(r, dim=1)
    rs2 = F.pad(rs[:, 1:], (0, 1))
    rs.masked_fill_(rs == 1e12, 0)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/jeromerony/adversarial-library/commit/1f51f51770105e045bf985ab7553d5480efc4dbe#diff-81c57b5177c60330f4c45eb30ac400e643d1c41217b2ea480d23ebc3b0bd3024L282' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73042938</div><div id='project'> Project Name: jeromerony/adversarial-library</div><div id='commit'> Commit Name: 1f51f51770105e045bf985ab7553d5480efc4dbe</div><div id='time'> Time: 2020-11-26</div><div id='author'> Author: jerome.rony@gmail.com</div><div id='file'> File Name: adv_lib/attacks/fast_adaptive_boundary/projections.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: projection_l2(3)</div><div id='n_method'> N Method Name: projection_l2(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: adv_lib/attacks/fast_adaptive_boundary/projections.py</div><div id='n_file'> N File Name: adv_lib/attacks/fast_adaptive_boundary/projections.py</div><div id='m_start'> M Start Line: 282</div><div id='m_end'> M End Line: 305</div><div id='n_start'> N Start Line: 283</div><div id='n_end'> N End Line: 305</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 mask diagonal to 0 dist 
    diag = np.arange(shape[-2])
    central = expand_dims_to(central, 3 - len(central.shape))
    <a id="change">central[:, diag, diag]</a> = 0.
    &#47&#47 provide weights
    if wide == "var":
        dispersion = (distogram * (n_bins - central.unsqueeze(-1))**2).sum(dim=-1)</code></pre><h3>After Change</h3><pre><code class='java'>
    diag_mask = torch.eye(shape[-2], device = device).bool()
    diag = np.arange(shape[-2])
    central = expand_dims_to(central, 3 - len(central.shape))
    <a id="change">central.masked_fill_(</a>diag_mask[None, ...], 0.<a id="change">)</a>
    &#47&#47 provide weights
    if wide == "var":
        dispersion = (distogram * (n_bins - central.unsqueeze(-1))**2).sum(dim=-1)
    elif wide == "std":</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/alphafold2/commit/63fe134dfb8b6c6b8102def8b0486de0cfb18172#diff-f9b2e05be1f80257f9a80ec7cc1290e3337a54fcc62aeee31b23a4cb827f12efL269' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73042943</div><div id='project'> Project Name: lucidrains/alphafold2</div><div id='commit'> Commit Name: 63fe134dfb8b6c6b8102def8b0486de0cfb18172</div><div id='time'> Time: 2021-03-01</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: alphafold2_pytorch/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: center_distogram_torch(5)</div><div id='n_method'> N Method Name: center_distogram_torch(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: alphafold2_pytorch/utils.py</div><div id='n_file'> N File Name: alphafold2_pytorch/utils.py</div><div id='m_start'> M Start Line: 297</div><div id='m_end'> M End Line: 299</div><div id='n_start'> N Start Line: 284</div><div id='n_end'> N End Line: 300</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            if not attn_mask.all_ones:
                QK = QK + attn_mask.additive_matrix
            
            QK = QK + <a id="change">key_lengths.additive_matrix[:, None, None]</a>

        &#47&#47 Compute the attention and the weighted average
        A = self.dropout(torch.softmax(scale * QK, dim=-1))
        V = torch.einsum("nhls,nshd-&gt;nlhd", A, values)</code></pre><h3>After Change</h3><pre><code class='java'>
            if attn_mask is None:
                attn_mask = TriangularCausalMask(B, L, device=queries.device)

            <a id="change">scores.masked_fill_(</a>attn_mask.mask, -np.inf<a id="change">)</a>

        A = self.dropout(torch.softmax(scale * scores, dim=-1))
        V = torch.einsum("bhls,bshd-&gt;blhd", A, values)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/zhouhaoyi/informer2020/commit/70524e942cdc80a07ea1caffa907d92544701cc5#diff-5a4c62511bcb230aabde06b4492839a39912e40a36708e5552a50c7e943073b6L17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73042940</div><div id='project'> Project Name: zhouhaoyi/informer2020</div><div id='commit'> Commit Name: 70524e942cdc80a07ea1caffa907d92544701cc5</div><div id='time'> Time: 2020-12-08</div><div id='author'> Author: 1095715895@qq.com</div><div id='file'> File Name: models/attn.py</div><div id='m_class'> M Class Name: FullAttention</div><div id='n_method'> N Class Name: FullAttention</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/attn.py</div><div id='n_file'> N File Name: models/attn.py</div><div id='m_start'> M Start Line: 17</div><div id='m_end'> M End Line: 33</div><div id='n_start'> N Start Line: 22</div><div id='n_end'> N End Line: 27</div><BR>