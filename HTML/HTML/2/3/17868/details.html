<html><h3>Pattern ID :17868
</h3><img src='58575196.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    if dataset_type in [&quotlfw&quot, &quotcfp_ff&quot, &quotcfp_fp&quot, &quotagedb_30&quot, &quotvgg2_fp&quot]:
        data, pairs = get_val_pair(path, dataset_type)
    else:
        path<a id="change"> = </a><a id="change">os.path.join(</a>path, dataset_type<a id="change">)</a>
        data, pairs = create_pairs(path, 2000)
    return data, pairs

</code></pre><h3>After Change</h3><pre><code class='java'>
    elif dataset_type == &quotimagefolder&quot:
        data, pairs = create_pairs(path, 2000)
    else:
        <a id="change">sys.exit(</a>&quotdataset_type should be of type imagefolder&quot<a id="change">)</a>
    return data, pairs


def separate_irse_bn_paras(modules):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/opendr-eu/opendr/commit/9e45e44a2e745c863f59e3e1743fe9872a129a3f#diff-1da59588ba941ed9ea3f05d2da01d3b7bd4986d0fed8c4e731b65b20d6fade31L97' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58575196</div><div id='project'> Project Name: opendr-eu/opendr</div><div id='commit'> Commit Name: 9e45e44a2e745c863f59e3e1743fe9872a129a3f</div><div id='time'> Time: 2020-10-21</div><div id='author'> Author: ptosidis@gmail.com</div><div id='file'> File Name: src/perception/face_recognition/algorithm/util/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: get_val_data(2)</div><div id='n_method'> N Method Name: get_val_data(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/perception/face_recognition/algorithm/util/utils.py</div><div id='n_file'> N File Name: src/perception/face_recognition/algorithm/util/utils.py</div><div id='m_start'> M Start Line: 97</div><div id='m_end'> M End Line: 98</div><div id='n_start'> N Start Line: 97</div><div id='n_end'> N End Line: 100</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.selected_text_emb_ids = None
        if reduce_subword_embbedding is not None:
            if not os.path.exists(reduce_subword_embbedding):
                reduce_subword_embbedding<a id="change"> = </a><a id="change">os.path.join(
                    </a>"/work/{}/atosystem/audio-visual-ssl/".format(os.environ["USER"]),
                    reduce_subword_embbedding<a id="change">,
                )</a>

            _data = np.load(reduce_subword_embbedding)
            self.selected_text_emb_ids = _data[:, 0]
            self.selected_text_emb_ids_dist = _data[:, 1]</code></pre><h3>After Change</h3><pre><code class='java'>
        if reduce_subword_embbedding is not None:
            if not os.path.exists(reduce_subword_embbedding):
                logger.error(f"File not found {reduce_subword_embbedding}")
                <a id="change">exit(</a>1<a id="change">)</a>

            _data = np.load(reduce_subword_embbedding)
            self.selected_text_emb_ids = _data[:, 0]
            self.selected_text_emb_ids_dist = _data[:, 1]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/atosystem/speechclip/commit/92334c9005448b4a5773f4a19c1b16f9ae34a4a0#diff-95f8b1f2d7743402bfbd00da10bd75754570978fc64f2e440316d8440da6dacfL29' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58575193</div><div id='project'> Project Name: atosystem/speechclip</div><div id='commit'> Commit Name: 92334c9005448b4a5773f4a19c1b16f9ae34a4a0</div><div id='time'> Time: 2022-08-13</div><div id='author'> Author: yjshih23@gmail.com</div><div id='file'> File Name: avssl/module/clip_official.py</div><div id='m_class'> M Class Name: ClipModel</div><div id='n_method'> N Class Name: ClipModel</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: avssl/module/clip_official.py</div><div id='n_file'> N File Name: avssl/module/clip_official.py</div><div id='m_start'> M Start Line: 35</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 67</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    split[&quottest&quot] = []
    split[&quotcv&quot] = []
    if dataset == &quoteyediap&quot:
        srcpath<a id="change"> = </a><a id="change">os.path.join(</a>eyediap_processed_data, &quotimages&quot<a id="change">)</a>
        videos = os.listdir(srcpath)
    elif dataset == &quotcolumbiagaze&quot:
        srcpath = os.path.join(columbiagaze_processed_data, &quotimages&quot)
        videos = os.listdir(srcpath)</code></pre><h3>After Change</h3><pre><code class='java'>
        path = dataset_paths[dataset]
    except KeyError:
        logging.error(&quotPath to dataset &quot + dataset + &quot not defined. Please define the same in config.py file&quot)
        <a id="change">sys.exit()</a>
    srcpath = os.path.join(path, &quotimages&quot)
    videos = os.listdir(srcpath)
    if type == &quotrandom&quot or dataset != &quoteyediap&quot:
        shuffle(videos)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neelabhsinha/flame/commit/c1f35a462a9eb152b8bf5045e35f71486daafa04#diff-797c2d5ac586195979b1d588f0d2b3a1528753298dc6492fc66bcd083499ce62L7' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58575192</div><div id='project'> Project Name: neelabhsinha/flame</div><div id='commit'> Commit Name: c1f35a462a9eb152b8bf5045e35f71486daafa04</div><div id='time'> Time: 2021-10-09</div><div id='author'> Author: neelabhsinha010@gmail.com</div><div id='file'> File Name: utils/data_split.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: split_data(3)</div><div id='n_method'> N Method Name: split_data(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: utils/data_split.py</div><div id='n_file'> N File Name: utils/data_split.py</div><div id='m_start'> M Start Line: 19</div><div id='m_end'> M End Line: 25</div><div id='n_start'> N Start Line: 20</div><div id='n_end'> N End Line: 26</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if len(os.listdir(stylized_frames_dump_dir)) == 0:
        print(&quot*&quot * 20, &quotFrame stylization stage started&quot, &quot*&quot * 20)
        for frame_name in os.listdir(frames_path):
            frame_path<a id="change"> = </a><a id="change">os.path.join(</a>frames_path, frame_name<a id="change">)</a>
            stylization_script_path = os.path.join(os.path.dirname(__file__), os.path.pardir, &quotpytorch-nst-feedforward&quot, &quotstylization_script.py&quot)
            subprocess.call([&quotpython&quot, stylization_script_path, &quot--content_img_name&quot, frame_path, &quot--img_width&quot, str(img_width), &quot--model_name&quot, model_name, &quot--should_not_display&quot, &quot--redirected_output&quot, stylized_frames_dump_dir])
            print(f&quotStylizing frame {frame_name} - batch size 1&quot)
    else:</code></pre><h3>After Change</h3><pre><code class='java'>
        except Exception as e:
            print(e)
            print(f&quotTry using smaller stylization batch size, currently = {stylization_batch_size} images in batch.&quot)
            <a id="change">exit(</a>-1<a id="change">)</a>
    else:
        print(&quotSkipping frame stylization, already done.&quot)

    return {"stylized_frames_path": stylized_frames_dump_dir}</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/gordicaleksa/pytorch-naive-video-neural-style-transfer/commit/6e631eb4ab84e249852e78ccaa314ac2b7484ac2#diff-03f3e9739e8188f6dcec53b64b6c62271002c6809737ef8b30d9963e0017fb0eL6' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58575191</div><div id='project'> Project Name: gordicaleksa/pytorch-naive-video-neural-style-transfer</div><div id='commit'> Commit Name: 6e631eb4ab84e249852e78ccaa314ac2b7484ac2</div><div id='time'> Time: 2020-08-07</div><div id='author'> Author: gordicaleksa@gmail.com</div><div id='file'> File Name: pipeline_components/nst_stylization.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: stylization(4)</div><div id='n_method'> N Method Name: stylization(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: pipeline_components/nst_stylization.py</div><div id='n_file'> N File Name: pipeline_components/nst_stylization.py</div><div id='m_start'> M Start Line: 12</div><div id='m_end'> M End Line: 17</div><div id='n_start'> N Start Line: 5</div><div id='n_end'> N End Line: 19</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    out_dir = Path("out/{}_pred_model".format(timestamp))
    out_dir.mkdir(parents=True)

    data_in_type<a id="change"> = </a><a id="change">&quot&quot.join(</a>s<a id="change"> for s in cfg.in_type if not s.isdigit())</a>
    num_channels = int(&quot&quot.join(i for i in cfg.in_type if i.isdigit()))
    num_classes = SYNPICK_CLASSES + 1 if cfg.include_gripper else SYNPICK_CLASSES
    vid_type = (data_in_type, num_channels)
</code></pre><h3>After Change</h3><pre><code class='java'>
                                     step=VID_STEP, allow_overlap=VID_DATA_ALLOW_OVERLAP, num_classes=num_classes)
    val_data = SynpickVideoDataset(data_dir=val_dir, num_frames=VIDEO_TOT_LENGTH,
                                   step=VID_STEP, allow_overlap=VID_DATA_ALLOW_OVERLAP, num_classes=num_classes)
    <a id="change">exit(</a>0<a id="change">)</a>
    train_loader = DataLoader(train_data, batch_size=VID_BATCH_SIZE, shuffle=True, num_workers=VID_BATCH_SIZE,
                              drop_last=True)
    valid_loader = DataLoader(val_data, batch_size=1, shuffle=False, num_workers=4, drop_last=True)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ais-bonn/vp-suite/commit/fad2f90c44c219d2af842dddbb66ecc4feae7d7c#diff-ae790e80446d6edc7fea49f259f7d4f0a3ea73438f2c7039c2b0e930160c2e41L18' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58575200</div><div id='project'> Project Name: ais-bonn/vp-suite</div><div id='commit'> Commit Name: fad2f90c44c219d2af842dddbb66ecc4feae7d7c</div><div id='time'> Time: 2021-09-01</div><div id='author'> Author: boltres@ais.uni-bonn.de</div><div id='file'> File Name: train_pred_model.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_pred_model.py</div><div id='n_file'> N File Name: train_pred_model.py</div><div id='m_start'> M Start Line: 26</div><div id='m_end'> M End Line: 149</div><div id='n_start'> N Start Line: 26</div><div id='n_end'> N End Line: 158</div><BR>