<html><h3>Pattern ID :27789
</h3><img src='82406859.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

            time_next += self.sample_time_delay

            img<a id="change">, x_start</a> = self.p_sample(img, time, time_next, x_start, clip_denoised = True)

        return bits_to_decimal(img)
</code></pre><h3>After Change</h3><pre><code class='java'>

            noise_cond = self.get_condition(time)

            x_start<a id="change"> = </a><a id="change">self.model(</a>img, noise_cond, x_start<a id="change">)</a>
            x_start.clamp_(-1., 1.)

            model_mean, _, posterior_log_variance = self.q_posterior(x_start = x_start, x_t = img, t = time, t_next = time_next)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/bit-diffusion/commit/70044d12755081b62303081a44ee196b783efd1b#diff-fa1704ed33520f9e00eadcb67b10c809ebe7cdd9d08435ae908b1c8126a28435L482' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 82406859</div><div id='project'> Project Name: lucidrains/bit-diffusion</div><div id='commit'> Commit Name: 70044d12755081b62303081a44ee196b783efd1b</div><div id='time'> Time: 2022-08-17</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: bit_diffusion/bit_diffusion.py</div><div id='m_class'> M Class Name: BitDiffusion</div><div id='n_method'> N Class Name: BitDiffusion</div><div id='m_method'> M Method Name: ddpm_sample(2)</div><div id='n_method'> N Method Name: ddpm_sample(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: bit_diffusion/bit_diffusion.py</div><div id='n_file'> N File Name: bit_diffusion/bit_diffusion.py</div><div id='m_start'> M Start Line: 508</div><div id='m_end'> M End Line: 518</div><div id='n_start'> N Start Line: 482</div><div id='n_end'> N End Line: 505</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        if labels is None:
            return (logits,)
        return loss<a id="change">, logits</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
        if labels is not None:
            use_cache = False

        outputs = <a id="change">self.model(
            </a>input_ids<a id="change">,
            attention_mask=attention_mask,
            decoder_input_ids=decoder_input_ids,
            decoder_attention_mask=decoder_attention_mask,
            head_mask=head_mask,
            decoder_head_mask=decoder_head_mask,
            cross_attn_head_mask=cross_attn_head_mask,
            encoder_outputs=encoder_outputs,
            inputs_embeds=inputs_embeds,
            decoder_inputs_embeds=decoder_inputs_embeds,
            use_cache=use_cache,
            output_attentions=output_attentions,
            output_hidden_states=output_hidden_states,
            return_dict=return_dict,
        )</a>

        hidden_states = outputs[0]  &#47&#47 last hidden state
        B, L, E = hidden_states.shape

        eos_mask = torch.eq(input_ids, self.config.eos_token_id)
        &#47&#47 Static tensor shape version of hidden_states[eos_mask, :]
        eos_indices = eos_mask * torch.arange(L).unsqueeze(0)
        last_eos_index, _ = torch.max(eos_indices, dim=1)
        &#47&#47 torch.index_select requires a 1D tensor of indices
        last_eos_index += torch.arange(B) * L
        hidden_states = hidden_states.view(B * L, E)
        sentence_representation = torch.index_select(hidden_states, 0, last_eos_index)

        logits = self.classification_head(sentence_representation)

        loss = None
        if labels is not None:
            if self.config.problem_type is None:
                if self.config.num_labels == 1:
                    self.config.problem_type = "regression"
                elif self.config.num_labels &gt; 1 and (labels.dtype == torch.long or labels.dtype == torch.int):
                    self.config.problem_type = "single_label_classification"
                else:
                    self.config.problem_type = "multi_label_classification"

            if self.config.problem_type == "regression":
                loss_fct = nn.MSELoss()
                if self.config.num_labels == 1:
                    loss = loss_fct(logits.squeeze(), labels.squeeze())
                else:
                    loss = loss_fct(logits, labels)
            elif self.config.problem_type == "single_label_classification":
                loss_fct = nn.CrossEntropyLoss()
                loss = loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))
            elif self.config.problem_type == "multi_label_classification":
                loss_fct = nn.BCEWithLogitsLoss()
                loss = loss_fct(logits, labels)

        if not return_dict:
            output<a id="change"> = </a>(logits,) + outputs[1:]
            return ((loss,) + output) if loss is not None else output

        return Seq2SeqSequenceClassifierOutput(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/optimum-graphcore/commit/14c3842bd5a259b70093f647a77e7e765687a6c0#diff-2a0ce0c122a2254b3cc4aba833d3736c3f53d34db82b9628984f2890c2cee711L825' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 82406847</div><div id='project'> Project Name: huggingface/optimum-graphcore</div><div id='commit'> Commit Name: 14c3842bd5a259b70093f647a77e7e765687a6c0</div><div id='time'> Time: 2022-10-06</div><div id='author'> Author: jamesbr@graphcore.ai</div><div id='file'> File Name: optimum/graphcore/models/bart/modeling_bart.py</div><div id='m_class'> M Class Name: PipelinedBartForSequenceClassification</div><div id='n_method'> N Class Name: PipelinedBartForSequenceClassification</div><div id='m_method'> M Method Name: forward(16)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: PipelineMixin,BartForSequenceClassification</div><div id='n_parent_class'> N Parent Class: PipelineMixin,BartForSequenceClassification</div><div id='m_file'> M File Name: optimum/graphcore/models/bart/modeling_bart.py</div><div id='n_file'> N File Name: optimum/graphcore/models/bart/modeling_bart.py</div><div id='m_start'> M Start Line: 825</div><div id='m_end'> M End Line: 872</div><div id='n_start'> N Start Line: 913</div><div id='n_end'> N End Line: 1007</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            for batch_idx, (inputs, targets) in enumerate(dataloader):
                start_slice = evaluated_instances
                end_slice = start_slice + inputs.shape[0]
                inputs, targets = inputs.to(self.device, non_blocking=True)<a id="change">, targets.to(self.device, non_blocking=True)</a>
                out, l1 = self.model(inputs, last=True, freeze=True)
            
                &#47&#47 Calculate loss as a sum, allowing for the calculation of the gradients using autograd wprt the outputs (bias gradients)</code></pre><h3>After Change</h3><pre><code class='java'>
                
                if type(inputs) == dict:
                    inputs = dict_to(inputs, self.device)
                    out<a id="change">, l1 = </a><a id="change">self.model(**inputs, last=True, freeze=True)</a>
                else:
                    inputs = inputs.to(self.device, non_blocking=True)
                    out, l1 = self.model(inputs, last=True, freeze=True)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/decile-team/distil/commit/345cfd1ce262878b1be79cc2f16fc3cba01723fb#diff-20b6fd35f401415c957935526e7387a7ad4828caf8d728b8ede097df6b9ec5c0L204' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 82406846</div><div id='project'> Project Name: decile-team/distil</div><div id='commit'> Commit Name: 345cfd1ce262878b1be79cc2f16fc3cba01723fb</div><div id='time'> Time: 2022-02-14</div><div id='author'> Author: nab170130@utdallas.edu</div><div id='file'> File Name: distil/active_learning_strategies/strategy.py</div><div id='m_class'> M Class Name: Strategy</div><div id='n_method'> N Class Name: Strategy</div><div id='m_method'> M Method Name: get_grad_embedding(4)</div><div id='n_method'> N Method Name: get_grad_embedding(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: distil/active_learning_strategies/strategy.py</div><div id='n_file'> N File Name: distil/active_learning_strategies/strategy.py</div><div id='m_start'> M Start Line: 221</div><div id='m_end'> M End Line: 262</div><div id='n_start'> N Start Line: 257</div><div id='n_end'> N End Line: 312</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 set default subgraph with 10 edges
        top_k = kwargs.get(&quottop_k&quot) if kwargs.get(&quottop_k&quot) is not None else 10
        y = kwargs.get(&quoty&quot)
        _<a id="change">, probs, embed</a> = self.get_model_output(x, edge_index, edge_mask=None)

        if self.explain_graph:
            &#47&#47 original value</code></pre><h3>After Change</h3><pre><code class='java'>
        y = y.to(self.device)

        self.__clear_masks__()
        logits = <a id="change">self.model(</a>x, edge_index<a id="change">)</a>
        probs<a id="change"> = </a>F.softmax(logits, dim=-1)
        embed = self.model.get_emb(x, edge_index)

        if self.explain_graph:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/divelab/dig/commit/ff80d071135716b458791b82064d91ffe0454e3e#diff-568d7f47b1c5fd2fa00b587179854781743fd9ce06a1713f6ce1d3ee14c5743fL451' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 82406849</div><div id='project'> Project Name: divelab/dig</div><div id='commit'> Commit Name: ff80d071135716b458791b82064d91ffe0454e3e</div><div id='time'> Time: 2021-04-26</div><div id='author'> Author: 1161283769@qq.com</div><div id='file'> File Name: dig/xgraph/method/pgexplainer.py</div><div id='m_class'> M Class Name: PGExplainer</div><div id='n_method'> N Class Name: PGExplainer</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dig/xgraph/method/pgexplainer.py</div><div id='n_file'> N File Name: dig/xgraph/method/pgexplainer.py</div><div id='m_start'> M Start Line: 463</div><div id='m_end'> M End Line: 487</div><div id='n_start'> N Start Line: 479</div><div id='n_end'> N End Line: 512</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        y = x.new_empty(r + horizon)
        y[:r] = x[-r:]  &#47&#47 Copy last `see` observations
        for h in range(r):
            _<a id="change">, queues</a> = self.model.forward_fast(y[h].view(1, 1, 1), queues)

        for h in range(horizon):
            p, queues = self.model.forward_fast(y[r + h - 1].view(1, 1, 1), queues)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 print([q.shape for q in queues])

        y[:r] = x[-r:]  &#47&#47 Copy last `see` observations
        _<a id="change">, outputs = </a><a id="change">self.model(</a>y[:r].view(1, 1, -1)<a id="change">, return_outputs=True)</a>
        queues = wave.create_fast_queues(self.model.wave.features, outputs)
        print(queues[2][0, :10, -1])

        &#47&#47 queues = wave.create_fast_queues(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/cheind/autoregressive/commit/895fe952e9a4de2bbdbf27e3b05cf99fad426c07#diff-3e8a2c64d2cb3e81bfd8c597008442cd13613c43a403979f7db33c71538bdd89L197' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 82406855</div><div id='project'> Project Name: cheind/autoregressive</div><div id='commit'> Commit Name: 895fe952e9a4de2bbdbf27e3b05cf99fad426c07</div><div id='time'> Time: 2021-10-20</div><div id='author'> Author: cheind@profactor.at</div><div id='file'> File Name: autoregressive/models.py</div><div id='m_class'> M Class Name: FastGeneration</div><div id='n_method'> N Class Name: FastGeneration</div><div id='m_method'> M Method Name: predict(4)</div><div id='n_method'> N Method Name: predict(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: autoregressive/models.py</div><div id='n_file'> N File Name: autoregressive/models.py</div><div id='m_start'> M Start Line: 200</div><div id='m_end'> M End Line: 209</div><div id='n_start'> N Start Line: 197</div><div id='n_end'> N End Line: 219</div><BR>