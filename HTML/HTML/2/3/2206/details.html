<html><h3>Pattern ID :2206
</h3><img src='9333711.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    dataset = self.env.get_dataset()
    N = dataset[&quotrewards&quot].shape[0]
    obs = dataset[&quotobservations&quot]
    next_obs<a id="change"> = </a><a id="change">np.roll(</a>obs, -1<a id="change">, axis=0)</a>
    dataset_out = {&quotstates&quot: torch.as_tensor(obs[:-1], dtype=torch.float32),
                   &quotactions&quot: torch.as_tensor(dataset[&quotactions&quot][:-1], dtype=torch.float32),
                   &quotrewards&quot: torch.as_tensor(dataset[&quotrewards&quot][:-1], dtype=torch.float32),</code></pre><h3>After Change</h3><pre><code class='java'>
    dataset_out = {&quotstates&quot: torch.as_tensor(dataset[&quotobservations&quot][:-1], dtype=torch.float32),
                   &quotactions&quot: torch.as_tensor(dataset[&quotactions&quot][:-1], dtype=torch.float32),
                   &quotrewards&quot: torch.as_tensor(dataset[&quotrewards&quot][:-1], dtype=torch.float32),
                   &quotnext_states&quot: torch.as_tensor(<a id="change">dataset[&quotobservations&quot]</a>[1:], dtype=torch.float32), 
                   &quotterminals&quot: torch.as_tensor(dataset[&quotterminals&quot][:-1], dtype=torch.float32)}
    &#47&#47 Postprocess
    if size &gt; 0 and size &lt; N:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/kaixhin/imitation-learning/commit/48793e91cc1823ba72c12c33980fc2ef8c79210c#diff-8ed23977d3772c377ed92c76a693948edb3c177c687080a18a49406244483c84L85' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9333711</div><div id='project'> Project Name: kaixhin/imitation-learning</div><div id='commit'> Commit Name: 48793e91cc1823ba72c12c33980fc2ef8c79210c</div><div id='time'> Time: 2021-05-02</div><div id='author'> Author: design@kaixhin.com</div><div id='file'> File Name: environments.py</div><div id='m_class'> M Class Name: D4RLEnv</div><div id='n_method'> N Class Name: D4RLEnv</div><div id='m_method'> M Method Name: get_dataset(3)</div><div id='n_method'> N Method Name: get_dataset(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: environments.py</div><div id='n_file'> N File Name: environments.py</div><div id='m_start'> M Start Line: 85</div><div id='m_end'> M End Line: 92</div><div id='n_start'> N Start Line: 85</div><div id='n_end'> N End Line: 90</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            bboxes = augmentations["bboxes"]

        if len(bboxes) &gt; 0:
            bboxes<a id="change"> = </a><a id="change">torch.tensor(bboxes).roll(dims=1, shifts=1)</a>
            &#47&#47yolo_xywh = coco_to_yolo_tensors(bboxes[..., 1:5], w0=tg_width, h0=tg_height)
            &#47&#47bboxes[..., 1:] = yolo_xywh
            out_bboxes = torch.zeros((bboxes.shape[0], 6))
            out_bboxes[..., 1:] = bboxes</code></pre><h3>After Change</h3><pre><code class='java'>
                labels[:, 1:] = xywhn2xyxy(labels[:, 1:], ratio[0] * sw, ratio[1] * sh, padw=pad[0], padh=pad[1])
            nl = len(labels)
            if nl:
                <a id="change">labels[:, 1:5]</a> = xyxy2xywhn(labels[:, 1:5], w=img.shape[1], h=img.shape[0], clip=True, eps=1E-3)

            &#47&#47 img = resize_image(img, (int(tg_width), int(tg_height)))
            &#47&#47 bboxes = rescale_bboxes(bboxes, [sw, sh], [tg_width, tg_height])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/alessandromondin/yolov5m/commit/67592bd2ca15b093b59ddd4a11287df9c55f48d0#diff-3c75bbc5e19f6e327e6c16638ad2413dc0d3200a9db147adecb096c4f05994faL82' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9333708</div><div id='project'> Project Name: alessandromondin/yolov5m</div><div id='commit'> Commit Name: 67592bd2ca15b093b59ddd4a11287df9c55f48d0</div><div id='time'> Time: 2022-11-21</div><div id='author'> Author: alessandromondin00@gmail.com</div><div id='file'> File Name: dataset_ultra.py</div><div id='m_class'> M Class Name: MS_COCO_2017</div><div id='n_method'> N Class Name: MS_COCO_2017</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: dataset_ultra.py</div><div id='n_file'> N File Name: dataset_ultra.py</div><div id='m_start'> M Start Line: 85</div><div id='m_end'> M End Line: 122</div><div id='n_start'> N Start Line: 87</div><div id='n_end'> N End Line: 133</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            if self.axis != 0:
                raise RuntimeError("Depth first means the depth axis should be 0.")
            &#47&#47 in here we assume the depth dimension was in the last dimension of "original_shape"
            original_shape<a id="change"> = </a><a id="change">np.roll(</a>original_shape, 1<a id="change">)</a>

        factor = np.array(current_shape) / original_shape

        &#47&#47 Creating guidance for all clicks</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 Assume channel is first and depth is last CHWD
        original_shape = d[meta_dict_key]["spatial_shape"]
        current_shape = <a id="change">list(d[self.ref_image].shape)[1:]</a>

        &#47&#47 in here we assume the depth dimension is in the last dimension of "original_shape" and "current_shape"
        factor = np.array(current_shape) / original_shape
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/project-monai/monailabel/commit/6ad3aaad098238115cba1e65df6726ca19a4e474#diff-ed3b5072b42bd705c8ea626ad811a82b2a44dc745e40038ead07bd4d32e4f64bL740' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9333724</div><div id='project'> Project Name: project-monai/monailabel</div><div id='commit'> Commit Name: 6ad3aaad098238115cba1e65df6726ca19a4e474</div><div id='time'> Time: 2021-11-11</div><div id='author'> Author: diazandr3s@gmail.com</div><div id='file'> File Name: monailabel/deepedit/multilabel/transforms.py</div><div id='m_class'> M Class Name: AddGuidanceFromPointsCustomd</div><div id='n_method'> N Class Name: AddGuidanceFromPointsCustomd</div><div id='m_method'> M Method Name: __call__(2)</div><div id='n_method'> N Method Name: __call__(2)</div><div id='m_parent_class'> M Parent Class: Transform</div><div id='n_parent_class'> N Parent Class: Transform</div><div id='m_file'> M File Name: monailabel/deepedit/multilabel/transforms.py</div><div id='n_file'> N File Name: monailabel/deepedit/multilabel/transforms.py</div><div id='m_start'> M Start Line: 747</div><div id='m_end'> M End Line: 766</div><div id='n_start'> N Start Line: 738</div><div id='n_end'> N End Line: 738</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    all_lengths = torch.linspace(near, far - resolution, point_num).to(target_device)
    lengths = all_lengths + torch.rand((ray_num, point_num)).to(target_device) * resolution
    &#47&#47 sampled coords is (row_id, col_id)
    ray_raw<a id="change"> = </a>(<a id="change">(sampled_coords[..., :-1] * torch.Tensor([-1., 1.]).to(target_device)).roll(shifts = 1, dims = 1)</a> + torch.Tensor([-w / 2, h / 2]).to(target_device)) / focal
    ray_raw = torch.sum(torch.cat([ray_raw, -torch.ones(ray_raw.shape[0], 1, dtype = torch.float32).to(target_device)], dim = -1).unsqueeze(-2) * cam_tfs[..., :-1], dim = -1)
    &#47&#47 return shape (ray_num, point_num, 3), (ray_num, point_num), rgb(ray_num, rgb), cams(ray_num, ray_dir, ray_t)
    pts = cam_tfs[:, :, -1].unsqueeze(-2) + lengths[:, :, None] * ray_raw[:, None, :]</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 return shape (ray_num, point_num, 3), (ray_num, point_num), rgb(ray_num, rgb), cams(ray_num, ray_dir, ray_t)
    pts = cam_tf[:, -1] + ray_raw[:, None, :] * lengths[:, :, None]
    &#47&#47 ray_raw is of shape (ray_num, 3)
    return torch.cat((pts, ray_raw.unsqueeze(-2).repeat(1, point_num, 1)), dim = -1), lengths, output_rgb, torch.cat((cam_tf[:, -1].unsqueeze(0).repeat(<a id="change">ray_raw.shape[0]</a>, 1), ray_raw), dim = -1)

def fov2Focal(fov:float, img_width:float) -&gt; float:
    return .5 * img_width / np.tan(.5 * fov)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/enigmatisms/nerf/commit/926e53d582b75b6d41aa6ffb38432e21706adc6f#diff-02847a575530271cafd549fcced1759b0b5f0561c2c608cac9054f1954992a7bL72' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9333706</div><div id='project'> Project Name: enigmatisms/nerf</div><div id='commit'> Commit Name: 926e53d582b75b6d41aa6ffb38432e21706adc6f</div><div id='time'> Time: 2022-04-14</div><div id='author'> Author: 984041003@qq.com</div><div id='file'> File Name: py/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: validSampler(10)</div><div id='n_method'> N Method Name: validSampler(10)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: py/utils.py</div><div id='n_file'> N File Name: py/utils.py</div><div id='m_start'> M Start Line: 73</div><div id='m_end'> M End Line: 89</div><div id='n_start'> N Start Line: 109</div><div id='n_end'> N End Line: 118</div><BR>