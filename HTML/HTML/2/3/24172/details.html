<html><h3>Pattern ID :24172
</h3><img src='74978843.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.to_logits = nn.Sequential(
            nn.LayerNorm(dim),
            nn.Linear(dim, num_tokens)
        ) if <a id="change">exists(</a>num_tokens<a id="change">)</a> else nn.Identity()

    def forward(self, x):
        x = self.to_embed(x)</code></pre><h3>After Change</h3><pre><code class='java'>
        self.to_embed = nn.Embedding(num_tokens, dim)

        window = cast_tuple(window, depth)
        layers = nn.ModuleList(<a id="change">[]</a>)

        for ind, w in zip(range(depth), window):
            layer_blocks = nn.ModuleList([
                PreNorm(dim, gMLPBlock(dim = dim, dim_ff = dim_ff, seq_len = seq_len, heads = heads, window = w))
            ])

            if reversible:
                layer_blocks.append(PreNorm(dim, gMLPBlock(dim = dim, dim_ff = dim_ff, seq_len = seq_len, heads = heads, window = w)))

            layers.append(layer_blocks)

        execute_klass = SequentialSequence if not reversible else ReversibleSequence
        self.net<a id="change"> = </a>execute_klass(layers)

        self.to_logits = nn.Sequential(
            nn.LayerNorm(dim),</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/g-mlp-gpt/commit/7642e36ff19c6b299a77e5c1ace038e9e6726202#diff-9e1c762f97dc7e52cf231d6bec8dbb8412bc9383faaf89eadd9b1c02e46fea80L188' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74978843</div><div id='project'> Project Name: lucidrains/g-mlp-gpt</div><div id='commit'> Commit Name: 7642e36ff19c6b299a77e5c1ace038e9e6726202</div><div id='time'> Time: 2021-05-20</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: g_mlp_gpt/g_mlp_gpt.py</div><div id='m_class'> M Class Name: gMLPGPT</div><div id='n_method'> N Class Name: gMLPGPT</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: g_mlp_gpt/g_mlp_gpt.py</div><div id='n_file'> N File Name: g_mlp_gpt/g_mlp_gpt.py</div><div id='m_start'> M Start Line: 188</div><div id='m_end'> M End Line: 195</div><div id='n_start'> N Start Line: 194</div><div id='n_end'> N End Line: 215</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    tracker_config = config.tracker
    init_config = {}

    if <a id="change">exists(</a>tracker_config.init_config<a id="change">)</a>:
        init_config["config"] = tracker_config.init_config

    if tracker_type == "console":</code></pre><h3>After Change</h3><pre><code class='java'>
        "NumProcesses": accelerator.num_processes,
        "MixedPrecision": accelerator.mixed_precision
    }
    init_config<a id="change"> = </a><a id="change">{ </a>"config": {**config.dict(), **accelerator_config}<a id="change"> }</a>
    data_path = data_path or tracker_config.data_path
    tracker_type = tracker_type or tracker_config.tracker_type

    if tracker_type == "dummy":</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/58892135d9bcf117921c885dda161c0b67452096#diff-1960fa4032117c7620576aea3bf67f017dd87a2077278af4c2f17abf549114b0L379' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74978845</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: 58892135d9bcf117921c885dda161c0b67452096</div><div id='time'> Time: 2022-06-19</div><div id='author'> Author: aidan.dempster@gmail.com</div><div id='file'> File Name: train_decoder.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: create_tracker(5)</div><div id='n_method'> N Method Name: create_tracker(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_decoder.py</div><div id='n_file'> N File Name: train_decoder.py</div><div id='m_start'> M Start Line: 383</div><div id='m_end'> M End Line: 406</div><div id='n_start'> N Start Line: 447</div><div id='n_end'> N End Line: 484</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            self.print(f&quotaccelerator not given, and device not specified: defaulting to device of diffusion prior parameters - {diffusion_prior_device}&quot)
            self.device = diffusion_prior_device
        else:
            self.device = accelerator.device if <a id="change">exists(</a>accelerator<a id="change">)</a> else device
            diffusion_prior.to(self.device)

        &#47&#47 save model</code></pre><h3>After Change</h3><pre><code class='java'>
            and self.diffusion_prior.clip is not None
            ):
            &#47&#47 Then we need to make sure clip is using the correct precision or else deepspeed will error
            cast_type_map<a id="change"> = </a><a id="change">{
                </a>"fp16": torch.half,
                "bf16": torch.bfloat16,
                "no": torch.float<a id="change">
            }</a>
            precision_type = cast_type_map[accelerator.mixed_precision]
            assert precision_type == torch.float, "DeepSpeed currently only supports float32 precision when using on the fly embedding generation from clip"
            self.diffusion_prior.clip.to(precision_type)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/f9423d308b6f36e51152c2c45045ff4ebb308287#diff-617450527162fa367141dbf45e8b201673573479820af0ffc56ba93b7f70947fL174' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74978847</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: f9423d308b6f36e51152c2c45045ff4ebb308287</div><div id='time'> Time: 2022-07-20</div><div id='author'> Author: 51308183+nousr@users.noreply.github.com</div><div id='file'> File Name: dalle2_pytorch/trainer.py</div><div id='m_class'> M Class Name: DiffusionPriorTrainer</div><div id='n_method'> N Class Name: DiffusionPriorTrainer</div><div id='m_method'> M Method Name: __init__(10)</div><div id='n_method'> N Method Name: __init__(12)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dalle2_pytorch/trainer.py</div><div id='n_file'> N File Name: dalle2_pytorch/trainer.py</div><div id='m_start'> M Start Line: 182</div><div id='m_end'> M End Line: 240</div><div id='n_start'> N Start Line: 177</div><div id='n_end'> N End Line: 246</div><BR>