<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    if len(cfg.device.gpu_ids) &gt; 1:
        print(&quotrank = &quot, local_rank)
        num_gpus = torch.cuda.device_count()
        <a id="change">torch.cuda.set_device(</a>local_rank % num_gpus<a id="change">)</a>
        dist.init_process_group(backend=&quotnccl&quot)
        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)
        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=cfg.device.batchsize_per_gpu,
                                                       num_workers=cfg.device.workers_per_gpu, pin_memory=True,</code></pre><h3>After Change</h3><pre><code class='java'>
            warnings.warn(&quotWarning! Old .pth checkpoint is deprecated. &quot
                          &quotConvert the checkpoint with tools/convert_old_checkpoint.py &quot)
            ckpt = convert_old_model(ckpt)
        task.load_state_dict(<a id="change">ckpt[&quotstate_dict&quot]</a>)

    model_resume_path = os.path.join(cfg.save_dir, &quotmodel_last.ckpt&quot) if &quotresume&quot in cfg.schedule else None
</code></pre>