<html><h3>Pattern ID :26137
</h3><img src='78730801.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 Get projection matrix for tgt camera frame to source pixel frame
    proj_cam_to_src_pixel = intrinsics @ rot_mat  &#47&#47 [B, 3, 3]

    src_pixel_coords<a id="change">, computed_depth</a> = cam2pixel2(
        cam_coords, proj_cam_to_src_pixel, None, padding_mode)  &#47&#47 [B,H,W,2]
    projected_img = F.grid_sample(
        img, src_pixel_coords, padding_mode=padding_mode, align_corners=True)</code></pre><h3>After Change</h3><pre><code class='java'>
    R = euler2mat(rot)  &#47&#47 [B, 3, 3]
    P = torch.matmul(intrinsics, R)

    world_points = depth_to_3d(<a id="change">torch.ones(B, 1, H, W).type_as(</a>img<a id="change">)</a>, intrinsics) &#47&#47 B 3 H W
    cam_points = torch.matmul(P, world_points.view(B, 3, -1))

    pix_coords = cam_points[:, :2, :] / (cam_points[:, 2, :].unsqueeze(1) + 1e-7)
    pix_coords = pix_coords.view(B, 2, H, W)
    pix_coords<a id="change"> = </a>pix_coords.permute(0, 2, 3, 1)
    pix_coords[..., 0] /= W - 1
    pix_coords[..., 1] /= H - 1
    pix_coords = (pix_coords - 0.5) * 2  </code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/jiawangbian/sc_depth_pl/commit/6a50fb9e99035b26acd8d44a2965c6a5b8eaa4da#diff-12ed95b9590ddbd0f5c333ed7040c3d303665bcf30f4e792d00566aaa13eb00cL129' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78730801</div><div id='project'> Project Name: jiawangbian/sc_depth_pl</div><div id='commit'> Commit Name: 6a50fb9e99035b26acd8d44a2965c6a5b8eaa4da</div><div id='time'> Time: 2022-08-18</div><div id='author'> Author: jiawang.bian@gmail.com</div><div id='file'> File Name: losses/inverse_warp.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: inverse_rotation_warp(4)</div><div id='n_method'> N Method Name: inverse_rotation_warp(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: losses/inverse_warp.py</div><div id='n_file'> N File Name: losses/inverse_warp.py</div><div id='m_start'> M Start Line: 275</div><div id='m_end'> M End Line: 284</div><div id='n_start'> N Start Line: 129</div><div id='n_end'> N End Line: 140</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        codevectors = codevectors.reshape(batch_size, sequence_length, -1)

        return codevectors<a id="change">, perplexity</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
                hidden_states
            )
        else:
            codevector_probs<a id="change"> = </a><a id="change">hard_probs.type_as(</a>hidden_states<a id="change">)</a>

        codevector_probs = codevector_probs.view(batch_size * sequence_length, self.num_groups, -1)
        codebook = self.codevectors[0, :, :]
        codebook = codebook.view(self.num_groups, self.num_vars, -1)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/optimum-graphcore/commit/2ec4ed72ea362414d20c9b112072f3aa7b3d399a#diff-b63bcc25111bbfe2539201f910ae754a6d8dd4b6bb244b4b94823ef62e6cc61dL63' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78730805</div><div id='project'> Project Name: huggingface/optimum-graphcore</div><div id='commit'> Commit Name: 2ec4ed72ea362414d20c9b112072f3aa7b3d399a</div><div id='time'> Time: 2022-07-29</div><div id='author'> Author: 91201457+thorinf@users.noreply.github.com</div><div id='file'> File Name: optimum/graphcore/models/wav2vec2/ipu_gumbel_vector_quantizer.py</div><div id='m_class'> M Class Name: IPUWav2Vec2GumbelVectorQuantizer</div><div id='n_method'> N Class Name: IPUWav2Vec2GumbelVectorQuantizer</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: Wav2Vec2GumbelVectorQuantizer</div><div id='n_parent_class'> N Parent Class: Wav2Vec2GumbelVectorQuantizer</div><div id='m_file'> M File Name: optimum/graphcore/models/wav2vec2/ipu_gumbel_vector_quantizer.py</div><div id='n_file'> N File Name: optimum/graphcore/models/wav2vec2/ipu_gumbel_vector_quantizer.py</div><div id='m_start'> M Start Line: 68</div><div id='m_end'> M End Line: 102</div><div id='n_start'> N Start Line: 80</div><div id='n_end'> N End Line: 110</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                loss = loss_fct(active_logits, active_labels)
            else:
                loss = loss_fct(logits.view(-1), labels.view(-1))
            outputs = (loss<a id="change"></a>,) + outputs

        return outputs  &#47&#47 (loss), scores, (hidden_states), (attentions)
</code></pre><h3>After Change</h3><pre><code class='java'>

        outputs = (logits,) + outputs[2:]  &#47&#47 add hidden states and attention if they are here
        if labels is not None:
            labels<a id="change"> = </a><a id="change">labels.type_as(</a>logits<a id="change">)</a>
            loss_fct = torch.nn.BCEWithLogitsLoss()
            &#47&#47 Only keep active parts of the loss
            if attention_mask is not None:
                active_loss = attention_mask.view(-1) == 1</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sleepychord/cogltx/commit/fa95d7ee6ce795f575e14dcde6ec26c9437107c0#diff-dcfeaa5ac3dffd54264034760914588d92fc7395c81eaa9274715840dc28100bL19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78730806</div><div id='project'> Project Name: sleepychord/cogltx</div><div id='commit'> Commit Name: fa95d7ee6ce795f575e14dcde6ec26c9437107c0</div><div id='time'> Time: 2020-03-05</div><div id='author'> Author: dm_thu@qq.com</div><div id='file'> File Name: models.py</div><div id='m_class'> M Class Name: Introspector</div><div id='n_method'> N Class Name: Introspector</div><div id='m_method'> M Method Name: forward(8)</div><div id='n_method'> N Method Name: forward(8)</div><div id='m_parent_class'> M Parent Class: BertPreTrainedModel</div><div id='n_parent_class'> N Parent Class: BertPreTrainedModel</div><div id='m_file'> M File Name: models.py</div><div id='n_file'> N File Name: models.py</div><div id='m_start'> M Start Line: 44</div><div id='m_end'> M End Line: 55</div><div id='n_start'> N Start Line: 43</div><div id='n_end'> N End Line: 57</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        B, P, N, _ = part_pcs.shape
        &#47&#47 shared-weight encoder
        pcs = part_pcs.flatten(0, 1)  &#47&#47 [B*P, N, 3]
        pc_feats = self.encoder(pcs).unflatten(0, (B<a id="change">, P</a>))  &#47&#47 [B, P, C]
        &#47&#47 transformer feature fusion
        pc_feats = self.corr_module(pc_feats, part_valids)  &#47&#47 [B, P, C]
        &#47&#47 MLP predict poses</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 shared-weight encoder
            valid_pcs = part_pcs[valid_mask]  &#47&#47 [n, N, 3]
            valid_feats = self.encoder(valid_pcs)  &#47&#47 [n, C]
            pc_feats<a id="change"> = </a><a id="change">torch.zeros(B, P, self.pc_feat_dim).type_as(</a>valid_feats<a id="change">)</a>
            pc_feats[valid_mask] = valid_feats
            &#47&#47 transformer feature fusion
            pc_feats = self.corr_module(pc_feats, valid_mask)  &#47&#47 [B, P, C]
            &#47&#47 MLP predict poses</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/wuziyi616/multi_part_assembly/commit/cb586c4febe6508914e90c32a5b69e70aecbbc4e#diff-a3ad4747602b92d4c95922c1168436b29f062f2b231f1c5c31a818c978e6bc4dL71' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78730808</div><div id='project'> Project Name: wuziyi616/multi_part_assembly</div><div id='commit'> Commit Name: cb586c4febe6508914e90c32a5b69e70aecbbc4e</div><div id='time'> Time: 2022-03-07</div><div id='author'> Author: dazitu616@gmail.com</div><div id='file'> File Name: multi_part_assembly/models/pn_transformer/network.py</div><div id='m_class'> M Class Name: PNTransformer</div><div id='n_method'> N Class Name: PNTransformer</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: pl.LightningModule</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: multi_part_assembly/models/pn_transformer/network.py</div><div id='n_file'> N File Name: multi_part_assembly/models/pn_transformer/network.py</div><div id='m_start'> M Start Line: 71</div><div id='m_end'> M End Line: 93</div><div id='n_start'> N Start Line: 83</div><div id='n_end'> N End Line: 107</div><BR>