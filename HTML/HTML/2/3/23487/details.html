<html><h3>Pattern ID :23487
</h3><img src='73725572.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

            &#47&#47 add noise to latents using the timesteps
            if device.type == "mps":
                noise = <a id="change">torch.randn(</a>shape<a id="change">, generator=generator, device="cpu", dtype=dtype)</a>.to(device)
            else:
                noise = torch.randn(shape, generator=generator, device=device, dtype=dtype)
            latents = self.scheduler.add_noise(init_latents, noise, timestep)</code></pre><h3>After Change</h3><pre><code class='java'>
            latents = latents * self.scheduler.init_noise_sigma
            return latents, None, None
        else:
            image = <a id="change">image.to(device=self.device, dtype=dtype)</a>
            init_latent_dist = self.vae.encode(image).latent_dist
            init_latents = init_latent_dist.sample(generator=generator)
            init_latents = self.vae.config.scaling_factor * init_latents

            &#47&#47 Expand init_latents for batch_size and num_images_per_prompt
            init_latents = torch.cat([init_latents] * num_images_per_prompt, dim=0)
            init_latents_orig = init_latents

            &#47&#47 add noise to latents using the timesteps
            noise = randn_tensor(init_latents.shape, generator=generator, device=self.device, dtype=dtype)
            init_latents = self.scheduler.add_noise(init_latents, noise, timestep)
            latents<a id="change"> = </a>init_latents
            return latents, init_latents_orig, noise

    @torch.no_grad()</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/2ced899cc7cff5c37f2186819c90538ce301908c#diff-137485cb3293be40e8fbae3f413853388988a06e9c6c73352686946677ad2eb3L628' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73725572</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: 2ced899cc7cff5c37f2186819c90538ce301908c</div><div id='time'> Time: 2023-04-27</div><div id='author'> Author: patrick.v.platen@gmail.com</div><div id='file'> File Name: examples/community/lpw_stable_diffusion.py</div><div id='m_class'> M Class Name: StableDiffusionLongPromptWeightingPipeline</div><div id='n_method'> N Class Name: StableDiffusionLongPromptWeightingPipeline</div><div id='m_method'> M Method Name: prepare_latents(12)</div><div id='n_method'> N Method Name: prepare_latents(10)</div><div id='m_parent_class'> M Parent Class: DiffusionPipeline,TextualInversionLoaderMixin,FromCkptMixin,LoraLoaderMixin</div><div id='n_parent_class'> N Parent Class: StableDiffusionPipeline</div><div id='m_file'> M File Name: examples/community/lpw_stable_diffusion.py</div><div id='n_file'> N File Name: examples/community/lpw_stable_diffusion.py</div><div id='m_start'> M Start Line: 628</div><div id='m_end'> M End Line: 662</div><div id='n_start'> N Start Line: 822</div><div id='n_end'> N End Line: 862</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            if latents is None:
                if device.type == "mps":
                    &#47&#47 randn does not work reproducibly on mps
                    latents = <a id="change">torch.randn(</a>shape<a id="change">, generator=generator, device="cpu", dtype=dtype)</a>.to(device)
                else:
                    latents = torch.randn(shape, generator=generator, device=device, dtype=dtype)
            else:</code></pre><h3>After Change</h3><pre><code class='java'>
            latents = latents * self.scheduler.init_noise_sigma
            return latents, None, None
        else:
            image = <a id="change">image.to(device=self.device, dtype=dtype)</a>
            init_latent_dist = self.vae.encode(image).latent_dist
            init_latents = init_latent_dist.sample(generator=generator)
            init_latents<a id="change"> = </a>self.vae.config.scaling_factor * init_latents

            &#47&#47 Expand init_latents for batch_size and num_images_per_prompt
            init_latents = torch.cat([init_latents] * num_images_per_prompt, dim=0)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/9965cb50eac12e397473f01535aab43aae76b4ab#diff-137485cb3293be40e8fbae3f413853388988a06e9c6c73352686946677ad2eb3L626' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73725568</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: 9965cb50eac12e397473f01535aab43aae76b4ab</div><div id='time'> Time: 2023-04-22</div><div id='author'> Author: SKYTNT@outlook.com</div><div id='file'> File Name: examples/community/lpw_stable_diffusion.py</div><div id='m_class'> M Class Name: StableDiffusionLongPromptWeightingPipeline</div><div id='n_method'> N Class Name: StableDiffusionLongPromptWeightingPipeline</div><div id='m_method'> M Method Name: prepare_latents(12)</div><div id='n_method'> N Method Name: prepare_latents(10)</div><div id='m_parent_class'> M Parent Class: DiffusionPipeline,TextualInversionLoaderMixin,FromCkptMixin,LoraLoaderMixin</div><div id='n_parent_class'> N Parent Class: StableDiffusionPipeline</div><div id='m_file'> M File Name: examples/community/lpw_stable_diffusion.py</div><div id='n_file'> N File Name: examples/community/lpw_stable_diffusion.py</div><div id='m_start'> M Start Line: 628</div><div id='m_end'> M End Line: 662</div><div id='n_start'> N Start Line: 822</div><div id='n_end'> N End Line: 862</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        :param current_device: (Int) Device to run the model
        :return: (Tensor)
        
        z = <a id="change">torch.randn(</a>num_samples,
                        self.latent_dim<a id="change">)</a>

        z = z.to(current_device)

        samples = self.decode(z)</code></pre><h3>After Change</h3><pre><code class='java'>
        z = torch.from_numpy(np_y)

        &#47&#47 z = self.sampling_dist.sample((num_samples * self.latent_dim, ))
        z<a id="change"> = </a><a id="change">z.view(num_samples, self.latent_dim * self.categorical_dim).to(</a>current_device<a id="change">)</a>
        samples = self.decode(z)
        return samples

    def generate(self, x: Tensor, **kwargs) -&gt; Tensor:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/antixk/pytorch-vae/commit/7f9df52e81b2f5028c956acb840d036e5b0d7f05#diff-68cf101edf1fbf18e41e4aaf88b240035f1e5e6f2ce42f210495db4e26a41467L175' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73725580</div><div id='project'> Project Name: antixk/pytorch-vae</div><div id='commit'> Commit Name: 7f9df52e81b2f5028c956acb840d036e5b0d7f05</div><div id='time'> Time: 2020-01-26</div><div id='author'> Author: anandkrish894@gmail.com</div><div id='file'> File Name: models/cat_vae.py</div><div id='m_class'> M Class Name: CategoricalVAE</div><div id='n_method'> N Class Name: CategoricalVAE</div><div id='m_method'> M Method Name: sample(3)</div><div id='n_method'> N Method Name: sample(3)</div><div id='m_parent_class'> M Parent Class: BaseVAE</div><div id='n_parent_class'> N Parent Class: BaseVAE</div><div id='m_file'> M File Name: models/cat_vae.py</div><div id='n_file'> N File Name: models/cat_vae.py</div><div id='m_start'> M Start Line: 185</div><div id='m_end'> M End Line: 188</div><div id='n_start'> N Start Line: 189</div><div id='n_end'> N End Line: 196</div><BR>