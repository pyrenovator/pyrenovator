<html><h3>Pattern ID :17787
</h3><img src='58535660.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    Uses hugginface generate (https://huggingface.co/transformers/main_classes/model.html?highlight=generate&#47&#47transformers.TFPreTrainedModel.generate)
    With tokenizer.padding size = left, otherwise generation is random (issue https://github.com/huggingface/transformers/issues/3021)
    
    encodings_dict<a id="change"> = </a><a id="change">tokenizer(
        </a>prompts<a id="change">, truncation=True, max_length=constants.MAX_SEQ_LEN)</a>
    prompts_ids = torch.tensor(
        encodings_dict[&quotinput_ids&quot], device=device, dtype=torch.long)
    first_idx = len(prompts_ids[0]) if first_idx else 0
</code></pre><h3>After Change</h3><pre><code class='java'>
    encodings_dict = tokenizer(
        prompts)
    &#47&#47 Truncates tokens from the end of the sequence.
    sliced_inputs = <a id="change">[</a>encodings_dict[&quotinput_ids&quot][0][-constants.MAX_SEQ_LEN:]<a id="change"></a>]
    prompts_ids = torch.tensor(
        sliced_inputs, device=device, dtype=torch.long)
    first_idx = len(prompts_ids[0]) if first_idx else 0</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/edenbd/multimodalstory-demo/commit/6417dcd958f24787fbfe75678705ccd8c5312f4a#diff-4c2116e7cd9352d743e0bed65f5a02f6fc208db101bc941a08ef87a3adfb8912L53' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58535660</div><div id='project'> Project Name: edenbd/multimodalstory-demo</div><div id='commit'> Commit Name: 6417dcd958f24787fbfe75678705ccd8c5312f4a</div><div id='time'> Time: 2021-04-21</div><div id='author'> Author: edenoosh15@gmail.com</div><div id='file'> File Name: backend/story_generator/generation_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _sample_demo_sequence(7)</div><div id='n_method'> N Method Name: _sample_demo_sequence(7)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: backend/story_generator/generation_utils.py</div><div id='n_file'> N File Name: backend/story_generator/generation_utils.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 56</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        session = InferenceSession(model, options)

        &#47&#47 Tokenize and cast to int64 to support all platforms
        tokens = <a id="change">tokenizer(</a>["cat"]<a id="change">, return_tensors="np")</a>
        tokens = {x: tokens[x].astype(np.int64) for x in tokens}

        &#47&#47 Run inference and validate
        outputs<a id="change"> = </a>session.run(None, dict(tokens))
        self.assertEqual(outputs[0].shape, (1, 384))
</code></pre><h3>After Change</h3><pre><code class='java'>
        onnx = HFOnnx()
        model = onnx(path, "pooling", quantize=True)

        embeddings = Embeddings(<a id="change">{</a>"path": model, "tokenizer": path<a id="change">}</a>)
        self.assertEqual(embeddings.similarity("animal", ["dog", "book", "rug"])[0][0], 0)

    def testQA(self):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neuml/txtai/commit/2ed7c7fec449cb6915ca040164d21248ab7427e2#diff-43df7e1f652b149a3b71960adb1e09d04673ebf493998844d4eed9ee174dc5f8L74' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58535663</div><div id='project'> Project Name: neuml/txtai</div><div id='commit'> Commit Name: 2ed7c7fec449cb6915ca040164d21248ab7427e2</div><div id='time'> Time: 2021-08-31</div><div id='author'> Author: 561939+davidmezzetti@users.noreply.github.com</div><div id='file'> File Name: test/python/testonnx.py</div><div id='m_class'> M Class Name: TestOnnx</div><div id='n_method'> N Class Name: TestOnnx</div><div id='m_method'> M Method Name: testPooling(1)</div><div id='n_method'> N Method Name: testPooling(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: test/python/testonnx.py</div><div id='n_file'> N File Name: test/python/testonnx.py</div><div id='m_start'> M Start Line: 81</div><div id='m_end'> M End Line: 94</div><div id='n_start'> N Start Line: 64</div><div id='n_end'> N End Line: 71</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        return_attention_mask=True,
        return_token_type_ids=False,
    )
    inputs = <a id="change">tokenizer(
        </a>source<a id="change">,
        max_length=max_source_length,
        truncation_strategy="longest_first",
        return_attention_mask=True,
        return_length=False,
    )</a>

    final = {}
    for k in outputs.keys():
        final[k]<a id="change"> = </a>inputs[k] + outputs[k]
        if k == "input_ids":
            final["labels"] = [tokenizer.pad_token_id] * len(inputs["input_ids"]) + outputs[k]
    return final</code></pre><h3>After Change</h3><pre><code class='java'>

    input_ids = tokenizer.convert_tokens_to_ids(tokens)

    return <a id="change">{
        </a>"input_ids": paddle.to_tensor(input_ids, dtype="int64"),
        "labels": paddle.to_tensor(labels, dtype="int64")<a id="change">,
    }</a>


@paddle.no_grad()
def run_evaluate(args, data_loader, model, iter_steps, log_writer, global_step, task_name="valid"):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/cd9b90e2339a664617b607015d8735e0d430dce2#diff-9e01507f31a8cef3a50b864311e1088183748ed637f785df03a0d0dad8009454L57' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58535657</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: cd9b90e2339a664617b607015d8735e0d430dce2</div><div id='time'> Time: 2023-03-29</div><div id='author'> Author: 1435130236@qq.com</div><div id='file'> File Name: examples/language_model/bloom/finetune_generation.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: convert_example(6)</div><div id='n_method'> N Method Name: convert_example(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/language_model/bloom/finetune_generation.py</div><div id='n_file'> N File Name: examples/language_model/bloom/finetune_generation.py</div><div id='m_start'> M Start Line: 68</div><div id='m_end'> M End Line: 106</div><div id='n_start'> N Start Line: 68</div><div id='n_end'> N End Line: 105</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>


def predict_sentiment(text: str) -&gt; List[float]:
    model_input<a id="change"> = </a><a id="change">tokenizer(</a>text<a id="change">, return_tensors="pt")</a>
    model_output = model(**model_input)[0]
    return list(map(float, torch.softmax(model_output, dim=1).tolist()[0]))
</code></pre><h3>After Change</h3><pre><code class='java'>
    if not text:
        return Prediction(prediction_id=uuid.uuid4(), prediction=[0.0] * 5)

    model_input = torch.tensor(<a id="change">[</a>tokenizer.encode(text, add_special_tokens=False)<a id="change"></a>], dtype=torch.int64)
    model_output = sentiment_forward(model_input)
    return Prediction(prediction_id=uuid.uuid4(),
                      prediction=list(map(float, model_output.tolist()[0])))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/xai-demonstrator/xai-demonstrator/commit/ef1e02dc6d8891582fa2a7dac75c70cddaa456dc#diff-28cd48defa075ba0e5d1fc8e5e0b45eb10b7052636b969ede81966a74f49b0e7L29' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58535658</div><div id='project'> Project Name: xai-demonstrator/xai-demonstrator</div><div id='commit'> Commit Name: ef1e02dc6d8891582fa2a7dac75c70cddaa456dc</div><div id='time'> Time: 2020-10-24</div><div id='author'> Author: kilian.kluge@gmail.com</div><div id='file'> File Name: test-service/sentiment/model/model.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: predict_sentiment(1)</div><div id='n_method'> N Method Name: predict_sentiment(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: test-service/sentiment/model/model.py</div><div id='n_file'> N File Name: test-service/sentiment/model/model.py</div><div id='m_start'> M Start Line: 30</div><div id='m_end'> M End Line: 32</div><div id='n_start'> N Start Line: 31</div><div id='n_end'> N End Line: 37</div><BR>