<html><h3>Pattern ID :25536
</h3><img src='77727380.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.scale = dim ** -0.5

        self.slots_mu = nn.Parameter(torch.randn(1, 1, dim))
        self.slots_sigma = nn.Parameter(<a id="change">torch.randn(</a>1, 1, dim<a id="change">) * </a>self.scale)

        self.to_q = nn.Linear(dim, dim)
        self.to_k = nn.Linear(dim, dim)</code></pre><h3>After Change</h3><pre><code class='java'>

        self.slots_mu = nn.Parameter(torch.randn(1, 1, dim))

        self.slots_logsigma = nn.Parameter(<a id="change">torch.zeros(</a>1, 1, dim<a id="change">)</a>)
        init.xavier_uniform_(self.slots_logsigma)

        self.to_q = nn.Linear(dim, dim)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/slot-attention/commit/94b3390a76d8a1a50890bccad49787bcf4393a0b#diff-ea210a143be973f8231bd45fec44d510779fc7ea939ae9722a7f217cccdf8138L10' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 77727380</div><div id='project'> Project Name: lucidrains/slot-attention</div><div id='commit'> Commit Name: 94b3390a76d8a1a50890bccad49787bcf4393a0b</div><div id='time'> Time: 2021-01-30</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: slot_attention/slot_attention.py</div><div id='m_class'> M Class Name: SlotAttention</div><div id='n_method'> N Class Name: SlotAttention</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: slot_attention/slot_attention.py</div><div id='n_file'> N File Name: slot_attention/slot_attention.py</div><div id='m_start'> M Start Line: 10</div><div id='m_end'> M End Line: 13</div><div id='n_start'> N Start Line: 15</div><div id='n_end'> N End Line: 16</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.norm_inputs = nn.LayerNorm(dim)

        self.slots_mu = nn.Parameter(torch.randn(1, 1, dim))
        self.slots_sigma = nn.Parameter(<a id="change">torch.randn(</a>1, 1, dim<a id="change">) * </a>scale)

        self.slots_to_inputs_attn = GatedResidual(dim, WeightedAttention(dim, eps = eps))
        self.slots_ff = GatedResidual(dim, FeedForward(dim, hidden_dim))</code></pre><h3>After Change</h3><pre><code class='java'>

        self.slots_mu = nn.Parameter(torch.randn(1, 1, dim))

        self.slots_logsigma = nn.Parameter(<a id="change">torch.zeros(</a>1, 1, dim<a id="change">)</a>)
        init.xavier_uniform_(self.slots_logsigma)

        self.slots_to_inputs_attn = GatedResidual(dim, WeightedAttention(dim, eps = eps))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/slot-attention/commit/94b3390a76d8a1a50890bccad49787bcf4393a0b#diff-d0e7017f0e7bf2af3da617f9f6a20826487ebb6441d2161083ffeb31042e07faL76' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 77727381</div><div id='project'> Project Name: lucidrains/slot-attention</div><div id='commit'> Commit Name: 94b3390a76d8a1a50890bccad49787bcf4393a0b</div><div id='time'> Time: 2021-01-30</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: slot_attention/slot_attention_experimental.py</div><div id='m_class'> M Class Name: SlotAttentionExperimental</div><div id='n_method'> N Class Name: SlotAttentionExperimental</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: slot_attention/slot_attention_experimental.py</div><div id='n_file'> N File Name: slot_attention/slot_attention_experimental.py</div><div id='m_start'> M Start Line: 78</div><div id='m_end'> M End Line: 85</div><div id='n_start'> N Start Line: 87</div><div id='n_end'> N End Line: 88</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                self.b_gru_update_gate)).long()

    def _get_parameter(self, tensor_shape: List[int], number_of_nodes: int) -&gt; nn.Parameter:
        return nn.Parameter(math.sqrt(1 / number_of_nodes)<a id="change"> * </a><a id="change">to.randn(</a>tensor_shape<a id="change">, device=self.device)</a>,
                            requires_grad=True)

    @staticmethod</code></pre><h3>After Change</h3><pre><code class='java'>
                self.b_gru_update_gate)).long()

    def _get_parameter(self, tensor_shape: List[int]) -&gt; nn.Parameter:
        return nn.Parameter(nn.init.kaiming_normal_(<a id="change">to.zeros(</a>tensor_shape<a id="change">, device=self.device)</a>), requires_grad=True)

    @staticmethod
    def _create_node(node_features: to.Tensor, adjacency_matrix: to.Tensor, node_id: int) -&gt; Node:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/kovanostra/message-passing-neural-network/commit/d5d530891581e5382ce7f034b82628d1aba962c5#diff-88565ec22ea3ee1d765c1c30f9823c95122d557f9ea7595fa4d4025cca4668ceL191' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 77727384</div><div id='project'> Project Name: kovanostra/message-passing-neural-network</div><div id='commit'> Commit Name: d5d530891581e5382ce7f034b82628d1aba962c5</div><div id='time'> Time: 2020-05-04</div><div id='author'> Author: kovanostra@gmail.com</div><div id='file'> File Name: message_passing_nn/model/graph_encoder.py</div><div id='m_class'> M Class Name: GraphEncoder</div><div id='n_method'> N Class Name: GraphEncoder</div><div id='m_method'> M Method Name: _get_parameter(2)</div><div id='n_method'> N Method Name: _get_parameter(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: message_passing_nn/model/graph_encoder.py</div><div id='n_file'> N File Name: message_passing_nn/model/graph_encoder.py</div><div id='m_start'> M Start Line: 191</div><div id='m_end'> M End Line: 192</div><div id='n_start'> N Start Line: 199</div><div id='n_end'> N End Line: 199</div><BR>