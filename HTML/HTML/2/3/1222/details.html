<html><h3>Pattern ID :1222
</h3><img src='6239468.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 Text as sequence of sentencepiece ID"s.
    context =[]
    question = []
    <a id="change">for </a>i in inputs<a id="change">:
        </a>question.append(i[&quotquestion&quot])
        context.append(i[&quotcontext&quot])

    prediction_output = []</code></pre><h3>After Change</h3><pre><code class='java'>
    prediction_output = []
    for inp in inputs:
      tokenized = self.tokenizer(inp[&quotquestion&quot], inp[&quotcontext&quot], return_tensors="jax", padding=True)
      output<a id="change"> = </a><a id="change">self.model(**tokenized)</a>
      answer_start_index = output.start_logits.argmax()
      answer_end_index = output.end_logits.argmax()
      predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]
      prediction_output.append({</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pair-code/lit/commit/91a22d65b7165cea1ad68dfffce0769ec9a2c966#diff-e66e2ed65042046b3905d9bc4b44fa2c3bb19cb8c07da5a9540002725714fab0L130' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6239468</div><div id='project'> Project Name: pair-code/lit</div><div id='commit'> Commit Name: 91a22d65b7165cea1ad68dfffce0769ec9a2c966</div><div id='time'> Time: 2022-06-16</div><div id='author'> Author: 31214277+aryan1107@users.noreply.github.com</div><div id='file'> File Name: lit_nlp/examples/models/tydi.py</div><div id='m_class'> M Class Name: TydiModel</div><div id='n_method'> N Class Name: TydiModel</div><div id='m_method'> M Method Name: predict_minibatch(2)</div><div id='n_method'> N Method Name: predict_minibatch(2)</div><div id='m_parent_class'> M Parent Class: lit_model.Model</div><div id='n_parent_class'> N Parent Class: lit_model.Model</div><div id='m_file'> M File Name: lit_nlp/examples/models/tydi.py</div><div id='n_file'> N File Name: lit_nlp/examples/models/tydi.py</div><div id='m_start'> M Start Line: 134</div><div id='m_end'> M End Line: 156</div><div id='n_start'> N Start Line: 130</div><div id='n_end'> N End Line: 138</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        expanded_logits = Perturbation.get_expanded_logits(logits, self.reg_params.n_samples)

        inf_inputs = []
        <a id="change">for </a>i in inputs<a id="change">:
            </a>inf_inputs.append(Perturbation.perturb_tensor(i, self.reg_params.n_samples).float().cuda())

        inf_output = self.model(inf_inputs)
        inf_loss = torch.nn.functional.binary_cross_entropy_with_logits(inf_output, expanded_logits)</code></pre><h3>After Change</h3><pre><code class='java'>
            inf_inputs.append(Perturbation.perturb_tensor(i, self.reg_params.n_samples).float().cuda())
            inf_inputs_len.append(Perturbation.perturb_tensor(inputs[1][ind], self.reg_params.n_samples,False))

        inf_output<a id="change"> = </a><a id="change">self.model(</a>[inf_inputs, inf_inputs_len]<a id="change">, training=True)</a>
        inf_loss = torch.nn.functional.binary_cross_entropy_with_logits(inf_output, expanded_logits)

        gradients = torch.autograd.grad(inf_loss, inf_inputs, create_graph=True)
        grads = [Regularization.get_batch_norm(gradients[k], loss=inf_loss,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pliang279/multibench/commit/0e0c7a49dc117cdb06f01380158e60a7ab4e0040#diff-f4bce8db7d62d54b2e245f6f2fd4f98ade42a4c0b4cea1530884e70b1042de26L224' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6239466</div><div id='project'> Project Name: pliang279/multibench</div><div id='commit'> Commit Name: 0e0c7a49dc117cdb06f01380158e60a7ab4e0040</div><div id='time'> Time: 2021-04-07</div><div id='author'> Author: ztwu_nil@zju.edu.cn</div><div id='file'> File Name: objective_functions/regularization.py</div><div id='m_class'> M Class Name: RegularizationLoss</div><div id='n_method'> N Class Name: RegularizationLoss</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: objective_functions/regularization.py</div><div id='n_file'> N File Name: objective_functions/regularization.py</div><div id='m_start'> M Start Line: 228</div><div id='m_end'> M End Line: 243</div><div id='n_start'> N Start Line: 233</div><div id='n_end'> N End Line: 250</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        r = self.model.receptive_field
        y = x.new_empty(r + horizon)
        y[:r] = x[-r:]  &#47&#47 Copy last `see` observations
        <a id="change">for </a>h in range(r)<a id="change">:
            </a>_, queues = self.model.forward_fast(y[h].view(1, 1, 1), queues)

        for h in range(horizon):
            p, queues = self.model.forward_fast(y[r + h - 1].view(1, 1, 1), queues)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 print([q.shape for q in queues])

        y[:r] = x[-r:]  &#47&#47 Copy last `see` observations
        _<a id="change">, outputs = </a><a id="change">self.model(</a>y[:r].view(1, 1, -1)<a id="change">, return_outputs=True)</a>
        queues = wave.create_fast_queues(self.model.wave.features, outputs)
        print(queues[2][0, :10, -1])

        &#47&#47 queues = wave.create_fast_queues(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/cheind/autoregressive/commit/895fe952e9a4de2bbdbf27e3b05cf99fad426c07#diff-3e8a2c64d2cb3e81bfd8c597008442cd13613c43a403979f7db33c71538bdd89L197' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6239465</div><div id='project'> Project Name: cheind/autoregressive</div><div id='commit'> Commit Name: 895fe952e9a4de2bbdbf27e3b05cf99fad426c07</div><div id='time'> Time: 2021-10-20</div><div id='author'> Author: cheind@profactor.at</div><div id='file'> File Name: autoregressive/models.py</div><div id='m_class'> M Class Name: FastGeneration</div><div id='n_method'> N Class Name: FastGeneration</div><div id='m_method'> M Method Name: predict(4)</div><div id='n_method'> N Method Name: predict(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: autoregressive/models.py</div><div id='n_file'> N File Name: autoregressive/models.py</div><div id='m_start'> M Start Line: 200</div><div id='m_end'> M End Line: 209</div><div id='n_start'> N Start Line: 197</div><div id='n_end'> N End Line: 219</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                n = y[0].shape[0]

            scores = self.model.evaluate(X, y, batch_size=n, verbose=0)
            <a id="change">for </a>metric, score in zip(streaming_metrics, scores)<a id="change">:
                </a>metric.update(score, n)
        for metric in streaming_metrics:
            logs["val_" + metric.name] = metric.value
        return logs</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 do scoring this way since model methods complain
            &#47&#47 about non-matching input shapes due to multi-hot
            for metric, streaming_metric in zip(self.model.metrics, streaming_metrics):
                y_pred<a id="change"> = </a><a id="change">self.model(</a>X<a id="change">)</a>
                score = metric(y, y_pred)
                streaming_metric.update(score, n)

        for metric in streaming_metrics:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nvidia/nvtabular/commit/6b668bbd884073cbaf03837cbce5df0810d18a00#diff-5370fdee81817626cc493a473693f5aab4cf69e6b4b1fdbc6fe743789c28a0d1L330' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6239464</div><div id='project'> Project Name: nvidia/nvtabular</div><div id='commit'> Commit Name: 6b668bbd884073cbaf03837cbce5df0810d18a00</div><div id='time'> Time: 2020-11-03</div><div id='author'> Author: amacgunny@gmail.com</div><div id='file'> File Name: nvtabular/loader/tensorflow.py</div><div id='m_class'> M Class Name: KerasSequenceValidater</div><div id='n_method'> N Class Name: KerasSequenceValidater</div><div id='m_method'> M Method Name: on_epoch_end(3)</div><div id='n_method'> N Method Name: on_epoch_end(3)</div><div id='m_parent_class'> M Parent Class: tf.keras.callbacks.Callback</div><div id='n_parent_class'> N Parent Class: tf.keras.callbacks.Callback</div><div id='m_file'> M File Name: nvtabular/loader/tensorflow.py</div><div id='n_file'> N File Name: nvtabular/loader/tensorflow.py</div><div id='m_start'> M Start Line: 331</div><div id='m_end'> M End Line: 341</div><div id='n_start'> N Start Line: 365</div><div id='n_end'> N End Line: 379</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        expanded_logits = Perturbation.get_expanded_logits(logits, self.reg_params.n_samples)

        inf_inputs = []
        <a id="change">for </a>i in inputs<a id="change">:
            </a>inf_inputs.append(Perturbation.perturb_tensor(i, self.reg_params.n_samples).float().cuda())

        inf_output = self.model(inf_inputs)
        inf_loss = torch.nn.functional.binary_cross_entropy_with_logits(inf_output, expanded_logits)</code></pre><h3>After Change</h3><pre><code class='java'>
            inf_inputs.append(Perturbation.perturb_tensor(i, self.reg_params.n_samples).float().cuda())
            inf_inputs_len.append(Perturbation.perturb_tensor(inputs[1][ind], self.reg_params.n_samples,False))

        inf_output<a id="change"> = </a><a id="change">self.model(</a>[inf_inputs, inf_inputs_len]<a id="change">, training=True)</a>
        inf_loss = torch.nn.functional.binary_cross_entropy_with_logits(inf_output, expanded_logits)

        gradients = torch.autograd.grad(inf_loss, inf_inputs, create_graph=True)
        grads = [Regularization.get_batch_norm(gradients[k], loss=inf_loss,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pliang279/multibench/commit/c54605f2e0f9be6777682e7598449cf2b1cd3898#diff-f4bce8db7d62d54b2e245f6f2fd4f98ade42a4c0b4cea1530884e70b1042de26L224' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6239461</div><div id='project'> Project Name: pliang279/multibench</div><div id='commit'> Commit Name: c54605f2e0f9be6777682e7598449cf2b1cd3898</div><div id='time'> Time: 2021-04-07</div><div id='author'> Author: ztwu_nil@zju.edu.cn</div><div id='file'> File Name: objective_functions/regularization.py</div><div id='m_class'> M Class Name: RegularizationLoss</div><div id='n_method'> N Class Name: RegularizationLoss</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: objective_functions/regularization.py</div><div id='n_file'> N File Name: objective_functions/regularization.py</div><div id='m_start'> M Start Line: 228</div><div id='m_end'> M End Line: 243</div><div id='n_start'> N Start Line: 233</div><div id='n_end'> N End Line: 250</div><BR>