<html><h3>Pattern ID :13711
</h3><img src='45827035.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def forward(self, sparse_features):
        x = reshape_sparse_features(sparse_features)
        output_<a id="change"> = </a><a id="change">self.embed(</a>x + self.offsets<a id="change">)</a>
        if self.output_device_type == "cuda" and self.offsets.device.type == "cpu":
            output_ = output_.cuda()
            output_.spec.dist_spec.process_group = self.process_group
        output = output_.convert_to_dist_spec(distspec.shard(self.process_group, [0], [self.world_size]))</code></pre><h3>After Change</h3><pre><code class='java'>

        sparse_dict = sparse_features.to_dict()
        flattened_sparse_features = torch.cat(
            [<a id="change">sparse_dict[key]</a>.values() + offset for key, offset in zip(keys, self.offsets)])
        batch_offsets = sparse_features.offsets()

        batch_size = len(sparse_features.lengths()) // len(keys)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/hpcaitech/cachedembedding/commit/54937021916b3d17347b193c2dddbace875ec95f#diff-51b25fbeb15d0629aa2192982cd705f7df76644d237674b1143984f99f7a1d4fL100' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45827035</div><div id='project'> Project Name: hpcaitech/cachedembedding</div><div id='commit'> Commit Name: 54937021916b3d17347b193c2dddbace875ec95f</div><div id='time'> Time: 2022-06-23</div><div id='author'> Author: zhangg1998@outlook.com</div><div id='file'> File Name: colo_recsys/models/colossal_dlrm.py</div><div id='m_class'> M Class Name: FusedSparseModules</div><div id='n_method'> N Class Name: FusedSparseModules</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: SparseArch</div><div id='m_file'> M File Name: colo_recsys/models/colossal_dlrm.py</div><div id='n_file'> N File Name: colo_recsys/models/colossal_dlrm.py</div><div id='m_start'> M Start Line: 100</div><div id='m_end'> M End Line: 106</div><div id='n_start'> N Start Line: 135</div><div id='n_end'> N End Line: 156</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        tags = self.massdiff_embedder(tags)

        &#47&#47 The input embedding:
        Y<a id="change"> = </a><a id="change">self.embed(</a>tokens<a id="change">)</a>
        Y = einops.repeat(Y, "n f -&gt; n b f", b=Y.shape[0])
        Y = torch.cat([tags, Y], dim=0)
        X = einops.repeat(memory, "n f -&gt; n b f", b=Y.shape[0])
        mask = self.decoder.generate_square_subsequent_mask(Y.shape[0])</code></pre><h3>After Change</h3><pre><code class='java'>
        tgt = tgt.replace("I", "L")
        seq = list(reversed(re.split(r"(?&lt;=.)(?=[A-Z])", tgt)))
        tokens = [self._aa2idx[aa] for aa in seq + ["&lt;eop&gt;"]]
        tokens = <a id="change">torch.tensor(tokens, device=self._device)[None, :]</a>

        &#47&#47 Calculate the remaining mass at each step:
        &#47&#47 Dims should be position (n) x batch (b) x feature (f) for input into
        &#47&#47 the transformer.</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/wfondrie/depthcharge/commit/ca2a0b5e356ae0cff0020cf44a66e3193cc2c911#diff-7033740cfab4565d25dc2511e3fb9373335c2dafc225b27dd0df7500cc3915a3L238' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45827033</div><div id='project'> Project Name: wfondrie/depthcharge</div><div id='commit'> Commit Name: ca2a0b5e356ae0cff0020cf44a66e3193cc2c911</div><div id='time'> Time: 2021-06-10</div><div id='author'> Author: fondriew@gmail.com</div><div id='file'> File Name: depthcharge/denovo/model.py</div><div id='m_class'> M Class Name: Spec2Pep</div><div id='n_method'> N Class Name: Spec2Pep</div><div id='m_method'> M Method Name: _force_feed(5)</div><div id='n_method'> N Method Name: _force_feed(4)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: depthcharge/denovo/model.py</div><div id='n_file'> N File Name: depthcharge/denovo/model.py</div><div id='m_start'> M Start Line: 241</div><div id='m_end'> M End Line: 264</div><div id='n_start'> N Start Line: 239</div><div id='n_end'> N End Line: 269</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        for pos in range(self.config[&quotmax_len&quot]):
            if self.config[&quotmodel_type&quot] == &quotgru&quot:
                trg_emb<a id="change"> = </a><a id="change">self.model.embed(</a>trg_input<a id="change">)</a>  &#47&#47 (B, L, d_model)
            elif self.config[&quotmodel_type&quot] == &quotrecosa&quot:
                trg_emb = self.model.trg_embed(trg_input)  &#47&#47 (B, L, 2*d_model)
            d_mask = self.model.make_decoder_mask(trg_input)  &#47&#47 (B, L, L)</code></pre><h3>After Change</h3><pre><code class='java'>
            trg_emb = self.model.trg_embed(trg_input)  &#47&#47 (B, L, 2*d_model)
            
            d_mask = (trg_input != self.config[&quotpad_id&quot]).unsqueeze(1)  &#47&#47 (N, 1, L)
            nopeak_mask = torch.ones([1, self.config[&quotmax_len&quot], <a id="change">self.config[&quotmax_len&quot]</a>], dtype=torch.bool)  &#47&#47 (1, L, L)
            nopeak_mask = torch.tril(nopeak_mask).to(self.config[&quotdevice&quot])  &#47&#47 (1, L, L) to triangular shape
            d_mask = d_mask & nopeak_mask  &#47&#47 (N, L, L) padding false
            </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/devjwsong/recosa-dialogue-generation-pytorch/commit/4ba6cfb1f4124e3ebc6a0f741253b4901ef2b0b0#diff-2e5ad92c43aa96cc3a9cef6c6aec998b216f1379c43b1f651013d25e55989312L229' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45827039</div><div id='project'> Project Name: devjwsong/recosa-dialogue-generation-pytorch</div><div id='commit'> Commit Name: 4ba6cfb1f4124e3ebc6a0f741253b4901ef2b0b0</div><div id='time'> Time: 2020-10-02</div><div id='author'> Author: enflwodn@gmail.com</div><div id='file'> File Name: src/main.py</div><div id='m_class'> M Class Name: Manager</div><div id='n_method'> N Class Name: Manager</div><div id='m_method'> M Method Name: nucleus_sampling(3)</div><div id='n_method'> N Method Name: nucleus_sampling(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/main.py</div><div id='n_file'> N File Name: src/main.py</div><div id='m_start'> M Start Line: 232</div><div id='m_end'> M End Line: 268</div><div id='n_start'> N Start Line: 233</div><div id='n_end'> N End Line: 243</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            for i, entity in enumerate(link_list_copy):
                list_point = i - unaligned_num
                entity_embedding = self.wikipedia_embedder.embed(entity["title"])["entity_embedding"]
                similar_entities<a id="change"> = </a><a id="change">self.wikipedia_embedder.embed(</a>entity["title"]<a id="change">)</a>["similar_entities"]
                if entity_embedding == np.array(100).tolist():
                    &#47&#47 Delete unaligned entity title
                    del link_list[list_point]</code></pre><h3>After Change</h3><pre><code class='java'>
                else:
                    link_dict["spans"][list_point]["entity_embedding"] = entity_embedding

        knowledge_dict["wikipedia_desc"] = <a id="change">link_dict["spans"]</a>

        return knowledge_dict

    def _enhance(self, datable, enhanced_key_1="sentence", enhanced_key_2=None, dict_name=None):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/cognlp/cogktr/commit/989419adb2fca6382150378237449d5b25aae02d#diff-28138ceb22a84e88b672343169c60cf494c3d41cd6c2320695b30a56a73b2123L119' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45827037</div><div id='project'> Project Name: cognlp/cogktr</div><div id='commit'> Commit Name: 989419adb2fca6382150378237449d5b25aae02d</div><div id='time'> Time: 2022-06-10</div><div id='author'> Author: 2113809110@qq.com</div><div id='file'> File Name: cogktr/enhancers/enhancer.py</div><div id='m_class'> M Class Name: Enhancer</div><div id='n_method'> N Class Name: Enhancer</div><div id='m_method'> M Method Name: get_knowledge(2)</div><div id='n_method'> N Method Name: get_knowledge(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: cogktr/enhancers/enhancer.py</div><div id='n_file'> N File Name: cogktr/enhancers/enhancer.py</div><div id='m_start'> M Start Line: 121</div><div id='m_end'> M End Line: 148</div><div id='n_start'> N Start Line: 121</div><div id='n_end'> N End Line: 146</div><BR>