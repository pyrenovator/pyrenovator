<html><h3>Pattern ID :10426
</h3><img src='36425753.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        st, en = self._check_length(st, en)
        attrs = check_attributes(dynamic_attributes, self.dynamic_attributes)

        nc<a id="change"> = </a>netCDF4.Dataset(os.path.join(self.ds_dir, f&quotHYSETS_2020_{self.source}.nc&quot))

        stn_df = pd.DataFrame(columns=attrs)

        for var in nc.variables:
            if var in attrs:
                ma = np.array(nc[var][:])
                ma[ma == nc[var]._FillValue] = np.nan
                ta = ma[station, :]  &#47&#47 target array of on station
                s = pd.Series(ta, index=pd.date_range(self.start, self.end, freq=&quotD&quot), name=var)
                stn_df[var] = s[st:en]
        <a id="change">nc.close()</a>

        return

    def fetch_static_attributes(self,</code></pre><h3>After Change</h3><pre><code class='java'>
                                 en=None,
                                 to_dataframe=False):
        Fetches dynamic attributes of one station.
        station = [<a id="change">int(</a>station<a id="change">)</a>]
        return self._fetch_dynamic_attributes(stations=station,
                                              dynamic_attributes=dynamic_attributes,
                                              st=st,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/atrcheema/ai4water/commit/518f536a9edfbd2de387303c829d38a8757ee33e#diff-4d7cf961d7f8c2debefa238d402177be13376b56057f8ba0b2722c4b7411450aL459' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 36425753</div><div id='project'> Project Name: atrcheema/ai4water</div><div id='commit'> Commit Name: 518f536a9edfbd2de387303c829d38a8757ee33e</div><div id='time'> Time: 2021-06-15</div><div id='author'> Author: ather_abbas786@yahoo.com</div><div id='file'> File Name: AI4Water/utils/datasets/camels.py</div><div id='m_class'> M Class Name: HYSETS</div><div id='n_method'> N Class Name: HYSETS</div><div id='m_method'> M Method Name: fetch_dynamic_attributes(6)</div><div id='n_method'> N Method Name: fetch_dynamic_attributes(5)</div><div id='m_parent_class'> M Parent Class: Camels</div><div id='n_parent_class'> N Parent Class: Camels</div><div id='m_file'> M File Name: AI4Water/utils/datasets/camels.py</div><div id='n_file'> N File Name: AI4Water/utils/datasets/camels.py</div><div id='m_start'> M Start Line: 459</div><div id='m_end'> M End Line: 475</div><div id='n_start'> N Start Line: 648</div><div id='n_end'> N End Line: 653</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        audio_data = b&quot&quot.join(frames)
        if save_path is not None:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            wf<a id="change"> = </a>wave.open(save_path, &quotwb&quot)
            wf.setnchannels(self.channels)
            wf.setsampwidth(self.p.get_sample_size(self.format))
            wf.setframerate(self.rate)
            wf.writeframes(b&quot&quot.join(frames))
            <a id="change">wf.close()</a>
        return audio_data

    def close(self):
        self.stream.close()</code></pre><h3>After Change</h3><pre><code class='java'>
        :return: 音频的numpy数据
        
        print("开始录音......")
        num_frames = <a id="change">int(</a>record_seconds * self.sample_rate<a id="change">)</a>
        data = self.default_mic.record(samplerate=self.sample_rate, numframes=num_frames, channels=self.channels)
        audio_data = data.squeeze()
        print("录音已结束!")
        if save_path is not None:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yeyupiaoling/voiceprintrecognition-pytorch/commit/5c4517b82c3634a6908e35f143fb908e35fd71d8#diff-daa3f561c21def600c9ecfb843318cbd4498759e57be78a86047a8bba251d271L23' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 36425752</div><div id='project'> Project Name: yeyupiaoling/voiceprintrecognition-pytorch</div><div id='commit'> Commit Name: 5c4517b82c3634a6908e35f143fb908e35fd71d8</div><div id='time'> Time: 2023-03-23</div><div id='author'> Author: yeyupiaoling@foxmail.com</div><div id='file'> File Name: mvector/utils/record.py</div><div id='m_class'> M Class Name: RecordAudio</div><div id='n_method'> N Class Name: RecordAudio</div><div id='m_method'> M Method Name: record(3)</div><div id='n_method'> N Method Name: record(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: mvector/utils/record.py</div><div id='n_file'> N File Name: mvector/utils/record.py</div><div id='m_start'> M Start Line: 31</div><div id='m_end'> M End Line: 45</div><div id='n_start'> N Start Line: 24</div><div id='n_end'> N End Line: 30</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        audio_data = b&quot&quot.join(frames)
        if save_path is not None:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            wf<a id="change"> = </a>wave.open(save_path, &quotwb&quot)
            wf.setnchannels(self.channels)
            wf.setsampwidth(self.p.get_sample_size(self.format))
            wf.setframerate(self.rate)
            wf.writeframes(b&quot&quot.join(frames))
            <a id="change">wf.close()</a>
        return audio_data

    def close(self):
        self.stream.close()</code></pre><h3>After Change</h3><pre><code class='java'>
        :return: 音频的numpy数据
        
        print("开始录音......")
        num_frames = <a id="change">int(</a>record_seconds * self.sample_rate<a id="change">)</a>
        data = self.default_mic.record(samplerate=self.sample_rate, numframes=num_frames, channels=self.channels)
        audio_data = data.squeeze()
        print("录音已结束!")
        if save_path is not None:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yeyupiaoling/audioclassification-pytorch/commit/4e40d2876f4e146adf88a406af712366ff36d830#diff-372e3443ea76f582317c62a8b741bc051cfefd414fae0fda934132a60f131ef8L23' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 36425750</div><div id='project'> Project Name: yeyupiaoling/audioclassification-pytorch</div><div id='commit'> Commit Name: 4e40d2876f4e146adf88a406af712366ff36d830</div><div id='time'> Time: 2023-03-23</div><div id='author'> Author: yeyupiaoling@foxmail.com</div><div id='file'> File Name: macls/utils/record.py</div><div id='m_class'> M Class Name: RecordAudio</div><div id='n_method'> N Class Name: RecordAudio</div><div id='m_method'> M Method Name: record(3)</div><div id='n_method'> N Method Name: record(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: macls/utils/record.py</div><div id='n_file'> N File Name: macls/utils/record.py</div><div id='m_start'> M Start Line: 31</div><div id='m_end'> M End Line: 45</div><div id='n_start'> N Start Line: 24</div><div id='n_end'> N End Line: 30</div><BR>