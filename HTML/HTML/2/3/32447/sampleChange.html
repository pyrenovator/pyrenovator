<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        objPts_w = np.array(self.objPts).transpose()[0]
        mat_objPts_w = np.concatenate((objPts_w, np.array([np.ones((self.n))])), axis=0)
        contPts_w = self.contPts_w.transpose()
        mat_contPts_w = np.concatenate((contPts_w, <a id="change">np.array([</a>np.ones((4))<a id="change"></a>]<a id="change">)</a>), axis=0)
        
        &#47&#47 Calculate Alpha
        Alpha = np.matmul(np.linalg.inv(mat_contPts_w), mat_objPts_w) &#47&#47 simple method</code></pre><h3>After Change</h3><pre><code class='java'>
        if linear_least_square:
            NotImplementedError("Linear least square method is not implemented yet.")
            &#47&#47 Calculate Alpha TODO: CHECK if logic is correct, or change to general method
            alpha = <a id="change">torch.bmm(</a>torch.linalg.inv(contPts_w), objPts<a id="change">)</a> &#47&#47 simple method
            alpha = alpha.transpose()
        else:
            alpha = torch.linalg.solve(contPts_w, objPts, left=False) &#47&#47 General method</code></pre>