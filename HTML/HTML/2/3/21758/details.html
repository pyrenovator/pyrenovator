<html><h3>Pattern ID :21758
</h3><img src='69394435.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    temp = torch.ones(x.size(0), 1, x.size(2), x.size(3))
    for i in range(x.size(0)):
        mask_temp = Masks.get_ff_mask(height, width)
        mask_temp<a id="change"> = </a><a id="change">torch.from_numpy(</a>mask_temp<a id="change">)</a>
        mask[i,:,:,:] = temp[i,:,:,:] * mask_temp
    if x.is_cuda:
        mask = mask.cuda()
    result = x * (1. - mask)</code></pre><h3>After Change</h3><pre><code class='java'>
    elif config[&quotmask_type&quot] == &quotmosaic&quot:
        &#47&#47 TODO: Matching the mosaic patch size and the mask size
        mosaic_unit_size = config[&quotmosaic_unit_size&quot]
        downsampled_image = <a id="change">F.interpolate(</a>x<a id="change">, scale_factor=1. / mosaic_unit_size, mode=&quotnearest&quot)</a>
        upsampled_image = F.interpolate(downsampled_image, size=(height, width), mode=&quotnearest&quot)
        result = upsampled_image * mask + x * (1. - mask)
    else:
        raise NotImplementedError(&quotNot implemented mask type.&quot)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/sayednadim/global-and-local-attention-based-free-form-image-inpainting/commit/2e453ae0b658395a88acb8db67115db86d9274ea#diff-4a9d05cc3eadd7aa0b347854fe63c55a626198aae56f6d3482457196186e5d60L40' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69394435</div><div id='project'> Project Name: sayednadim/global-and-local-attention-based-free-form-image-inpainting</div><div id='commit'> Commit Name: 2e453ae0b658395a88acb8db67115db86d9274ea</div><div id='time'> Time: 2020-08-16</div><div id='author'> Author: smnadimuddin@gmail.com</div><div id='file'> File Name: model/mask.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mask_image(2)</div><div id='n_method'> N Method Name: mask_image(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model/mask.py</div><div id='n_file'> N File Name: model/mask.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 48</div><div id='n_start'> N Start Line: 56</div><div id='n_end'> N End Line: 72</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    for i in range(x.size(0)):
        mask = Masks.get_ff_mask(height, width)
        mask_all.append(mask)
    mask<a id="change"> = </a><a id="change">torch.from_numpy(</a>np.asarray(mask_all)<a id="change">)</a>.unsqueeze(1).float()
    ones = torch.ones(x.size(0), 1, x.size(2), x.size(3))
    mask = ones * mask
    if x.is_cuda:</code></pre><h3>After Change</h3><pre><code class='java'>
    elif config[&quotmask_type&quot] == &quotmosaic&quot:
        &#47&#47 TODO: Matching the mosaic patch size and the mask size
        mosaic_unit_size = config[&quotmosaic_unit_size&quot]
        downsampled_image = <a id="change">F.interpolate(</a>x<a id="change">, scale_factor=1. / mosaic_unit_size, mode=&quotnearest&quot)</a>
        upsampled_image = F.interpolate(downsampled_image, size=(height, width), mode=&quotnearest&quot)
        result = upsampled_image * mask + x * (1. - mask)
    else:
        raise NotImplementedError(&quotNot implemented mask type.&quot)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sayednadim/global-and-local-attention-based-free-form-image-inpainting/commit/aaa17ed332dc95db0f5900a43be179e26569b50c#diff-4a9d05cc3eadd7aa0b347854fe63c55a626198aae56f6d3482457196186e5d60L38' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69394448</div><div id='project'> Project Name: sayednadim/global-and-local-attention-based-free-form-image-inpainting</div><div id='commit'> Commit Name: aaa17ed332dc95db0f5900a43be179e26569b50c</div><div id='time'> Time: 2020-08-16</div><div id='author'> Author: smnadimuddin@gmail.com</div><div id='file'> File Name: model/mask.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mask_image(2)</div><div id='n_method'> N Method Name: mask_image(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model/mask.py</div><div id='n_file'> N File Name: model/mask.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 49</div><div id='n_start'> N Start Line: 56</div><div id='n_end'> N End Line: 72</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        scale = min(scale1, scale2)
        out_h, out_w = in_h * scale, in_w * scale
        img = sktsf.resize(img, (in_c, out_h, out_w), mode=&quotreflect&quot, anti_aliasing=False)  &#47&#47 np.float64
        img<a id="change"> = </a>self.normalize(<a id="change">torch.from_numpy(</a>img<a id="change">)</a>).numpy()
        &#47&#47 img = F.interpolate(img.unsqueeze(0), size=(round(in_h * scale), round(in_w * scale)), mode="nearest").squeeze(0)
        &#47&#47 img = tvtsf.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)
        return img_path, img, img.shape[1:]</code></pre><h3>After Change</h3><pre><code class='java'>
        scale1 = 600 / min(in_h, in_w)
        scale2 = 1000 / max(in_h, in_w)
        scale = min(scale1, scale2)
        img = <a id="change">F.interpolate(</a>img.unsqueeze(0)<a id="change">, size=(round(in_h * scale), round(in_w * scale)), mode="nearest")</a>.squeeze(0)
        img = tvtsf.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)
        return img_path, img, img.shape[1:]
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pangkun248/faster-rcnn-pytorch/commit/9f846e1554bc021a8736389744969d0dd7f97321#diff-11bb3b632c84e01e0bf1b576e72c513fd062811e900ebcb5f22df0eac7d3b0d9L105' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69394440</div><div id='project'> Project Name: pangkun248/faster-rcnn-pytorch</div><div id='commit'> Commit Name: 9f846e1554bc021a8736389744969d0dd7f97321</div><div id='time'> Time: 2021-08-30</div><div id='author'> Author: 39581901+pangkun248@users.noreply.github.com</div><div id='file'> File Name: dataset.py</div><div id='m_class'> M Class Name: ImageFolder</div><div id='n_method'> N Class Name: ImageFolder</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: dataset.py</div><div id='n_file'> N File Name: dataset.py</div><div id='m_start'> M Start Line: 110</div><div id='m_end'> M End Line: 119</div><div id='n_start'> N Start Line: 91</div><div id='n_end'> N End Line: 99</div><BR>