<html><h3>Pattern ID :12209
</h3><img src='41342352.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def forward(self, input):
        if not input.is_cuda or not HAS_LAYER_NORM:
            <a id="change">return </a><a id="change">F.layer_norm(
                </a>input, self.normalized_shape, self.weight, self.bias, self.eps<a id="change">)</a>
        return FusedLayerNormFastFunction.apply(
            input, self.weight, self.bias, self.normalized_shape, self.eps)

    def extra_repr(self):</code></pre><h3>After Change</h3><pre><code class='java'>
        init.zeros_(self.bias)

    def forward(self, input):
        <a id="change">return </a>self.func(input)

    def extra_repr(self):
        return &quot{normalized_shape}, eps={eps}, &quot \</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/dptech-corp/uni-core/commit/cf5037607df38e4a817918c7ae566f7a815ba58b#diff-00713d68e9e0f3f7ae4bd54f512c9e270ddd5480a72fbf9d6a50bb117a894dabL66' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41342352</div><div id='project'> Project Name: dptech-corp/uni-core</div><div id='commit'> Commit Name: cf5037607df38e4a817918c7ae566f7a815ba58b</div><div id='time'> Time: 2022-08-24</div><div id='author'> Author: guolin.ke@outlook.com</div><div id='file'> File Name: unicore/modules/layer_norm.py</div><div id='m_class'> M Class Name: LayerNorm</div><div id='n_method'> N Class Name: LayerNorm</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: unicore/modules/layer_norm.py</div><div id='n_file'> N File Name: unicore/modules/layer_norm.py</div><div id='m_start'> M Start Line: 66</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 78</div><div id='n_end'> N End Line: 78</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        x = self.fc(x)
        x = self.dropout(x)
        x = x + projected
        x = <a id="change">self.layer_norm(</a>x<a id="change">)</a>
        <a id="change">return </a>x


class CLIPModel(nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>

    def forward(self, x):
        projected = self.projection(x)
        <a id="change">return </a>projected


class CLIPModel(nn.Module):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/kr-happyface/kodalle/commit/b5e3b335a94fb2a32a1ba9925f29af7aad45aa93#diff-ce6de8a2bc87f5200f1d89a87d19b2823e7575a63d7119104ab57cbe4163b8e4L86' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41342350</div><div id='project'> Project Name: kr-happyface/kodalle</div><div id='commit'> Commit Name: b5e3b335a94fb2a32a1ba9925f29af7aad45aa93</div><div id='time'> Time: 2021-12-21</div><div id='author'> Author: shawn.khs1208@gmail.com</div><div id='file'> File Name: clipmodel.py</div><div id='m_class'> M Class Name: ProjectionHead</div><div id='n_method'> N Class Name: ProjectionHead</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: clipmodel.py</div><div id='n_file'> N File Name: clipmodel.py</div><div id='m_start'> M Start Line: 87</div><div id='m_end'> M End Line: 93</div><div id='n_start'> N Start Line: 48</div><div id='n_end'> N End Line: 49</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

def layer_norm(input_tensor, name=None):
  Run layer normalization on the last dimension of the tensor.
  <a id="change">return </a><a id="change">tf.contrib.layers.layer_norm(
      inputs=input_tensor, begin_norm_axis=-1, begin_params_axis=-1, scope=name)</a>


def layer_norm_and_dropout(input_tensor, dropout_prob, name=None):
  Runs layer normalization followed by dropout.</code></pre><h3>After Change</h3><pre><code class='java'>
def layer_norm(input_tensor, name=None):
  Run layer normalization on the last dimension of the tensor.
  layer_norm = tf.keras.layers.LayerNormalization(-1)
  <a id="change">return </a>layer_norm(input_tensor)


def layer_norm_and_dropout(input_tensor, dropout_prob, name=None):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ppashakhanloo/codetrek/commit/8ab8d064bef0bf0ad2920aae9003b3141f51b40d#diff-2403f2dd5afe92ec4741967e481923f717d821f2ae01634334aa39b672d923ccL345' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41342351</div><div id='project'> Project Name: ppashakhanloo/codetrek</div><div id='commit'> Commit Name: 8ab8d064bef0bf0ad2920aae9003b3141f51b40d</div><div id='time'> Time: 2021-07-08</div><div id='author'> Author: ppashakhanloo@gmail.com</div><div id='file'> File Name: data_prep/baselines/CuBERT/model/modeling.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: layer_norm(2)</div><div id='n_method'> N Method Name: layer_norm(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: data_prep/baselines/CuBERT/model/modeling.py</div><div id='n_file'> N File Name: data_prep/baselines/CuBERT/model/modeling.py</div><div id='m_start'> M Start Line: 347</div><div id='m_end'> M End Line: 348</div><div id='n_start'> N Start Line: 347</div><div id='n_end'> N End Line: 348</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.register_buffer(&quotbeta&quot, torch.zeros(dim))

    def forward(self, x):
        <a id="change">return </a><a id="change">F.layer_norm(</a>x, x.shape[-1:], self.gamma, self.beta<a id="change">)</a>


class ChanLayerNorm(nn.Module):
    def __init__(self, dim, eps = 1e-5):</code></pre><h3>After Change</h3><pre><code class='java'>

        var = torch.var(x, dim = -1, unbiased = False, keepdim = True)
        mean = torch.mean(x, dim = -1, keepdim = True)
        <a id="change">return </a>(x - mean) * (var + self.eps).rsqrt() * self.g

class ChanLayerNorm(nn.Module):
    def __init__(self, dim, eps = 1e-5, stable = False):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/5fca6872dad964bc20f6213aec267487cafc1a77#diff-edef3c5fe92797a22c0b8fc6cca1d57b4b84ef03dfdfe802ed9147e21fc88109L379' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41342349</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: 5fca6872dad964bc20f6213aec267487cafc1a77</div><div id='time'> Time: 2022-07-18</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_class'> M Class Name: LayerNorm</div><div id='n_method'> N Class Name: LayerNorm</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imagen_pytorch/imagen_pytorch.py</div><div id='n_file'> N File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_start'> M Start Line: 380</div><div id='m_end'> M End Line: 380</div><div id='n_start'> N Start Line: 381</div><div id='n_end'> N End Line: 386</div><BR>