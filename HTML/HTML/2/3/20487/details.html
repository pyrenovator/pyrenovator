<html><h3>Pattern ID :20487
</h3><img src='66226483.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            outputs = self.model(data)
            loss = self.loss(outputs, labels)

            shared_grads<a id="change"> += </a><a id="change">[</a>torch.autograd.grad(loss, self.model.parameters())<a id="change"></a>]
            shared_buffers += [[b.clone().detach() for b in self.model.buffers()]]

        shared_data = dict(gradients=shared_grads, buffers=shared_buffers,</code></pre><h3>After Change</h3><pre><code class='java'>
                seen_data_idx += self.num_data_per_local_update_step
                seen_data_idx = seen_data_idx % self.num_data_points

                <a id="change">optimizer.zero_grad()</a>
                &#47&#47 Compute the forward pass
                outputs = self.model(data)
                loss = self.loss(outputs, labels)
                loss.backward()</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/jonasgeiping/breaching/commit/1ab2867fea20551797c9aea8ae67099093ec7180#diff-222118a39af19077a8b428b60923841d31a00f445f3963533670a0eaa87a9924L151' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66226483</div><div id='project'> Project Name: jonasgeiping/breaching</div><div id='commit'> Commit Name: 1ab2867fea20551797c9aea8ae67099093ec7180</div><div id='time'> Time: 2021-10-01</div><div id='author'> Author: jonas.geiping@googlemail.com</div><div id='file'> File Name: breaching/cases/users.py</div><div id='m_class'> M Class Name: UserMultiStep</div><div id='n_method'> N Class Name: UserMultiStep</div><div id='m_method'> M Method Name: compute_local_updates(2)</div><div id='n_method'> N Method Name: compute_local_updates(2)</div><div id='m_parent_class'> M Parent Class: UserSingleStep</div><div id='n_parent_class'> N Parent Class: UserSingleStep</div><div id='m_file'> M File Name: breaching/cases/users.py</div><div id='n_file'> N File Name: breaching/cases/users.py</div><div id='m_start'> M Start Line: 151</div><div id='m_end'> M End Line: 187</div><div id='n_start'> N Start Line: 158</div><div id='n_end'> N End Line: 200</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.zero_grad()
        psi = self.defaults[&quotwf&quot](pos)

        inp = <a id="change">[]</a>
        for group in self.param_groups:
            for p in group[&quotparams&quot]:
                if p.requires_grad:
                    inp.append(p)

        for ibatch in range(psi.shape[0]):
            grads<a id="change"> = </a>torch.autograd.grad(psi[ibatch], inp, retain_graph=True)
            grads = torch.cat([g.view(-1)/psi[ibatch] for g in grads])
            if ibatch == 0:
                S = grads * grads.view(-1, 1)</code></pre><h3>After Change</h3><pre><code class='java'>
            grads = self._collect_grad() / psi[ibatch]
            S += grads.reshape(-1, 1) @ grads.reshape(1, -1)
            sum_grads += grads
            <a id="change">self.zero_grad()</a>

        sum_grads /= nbatch
        S -= sum_grads.reshape(-1, 1) @ sum_grads.reshape(1, -1)
        return S</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nlesc-jcer/qmctorch/commit/9f40f526749f6a91afacd7fa260c5e0c7e934715#diff-cefdd5d413077f5a707bb83bf6ebbac113eb5193728a62f34d612924494720f3L39' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66226478</div><div id='project'> Project Name: nlesc-jcer/qmctorch</div><div id='commit'> Commit Name: 9f40f526749f6a91afacd7fa260c5e0c7e934715</div><div id='time'> Time: 2020-02-07</div><div id='author'> Author: nicolas.gm.renaud@gmail.com</div><div id='file'> File Name: deepqmc/optim/sr.py</div><div id='m_class'> M Class Name: StochasticReconfiguration</div><div id='n_method'> N Class Name: StochasticReconfiguration</div><div id='m_method'> M Method Name: get_overlap_matrix(2)</div><div id='n_method'> N Method Name: get_overlap_matrix(2)</div><div id='m_parent_class'> M Parent Class: Optimizer</div><div id='n_parent_class'> N Parent Class: Optimizer</div><div id='m_file'> M File Name: deepqmc/optim/sr.py</div><div id='n_file'> N File Name: deepqmc/optim/sr.py</div><div id='m_start'> M Start Line: 42</div><div id='m_end'> M End Line: 58</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 57</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    bagua_model = bagua_model.with_bagua([bagua_optimizer], algorithm)
    try:
        bagua_model<a id="change"> = </a>bagua_model.with_bagua(<a id="change">[</a>bagua_optimizer<a id="change"></a>], algorithm)
    except Exception:
        time.sleep(0.1)
</code></pre><h3>After Change</h3><pre><code class='java'>
            data = torch.randn(4, 2).cuda()
            target = torch.randn(4, 4).cuda()

            <a id="change">bagua_optimizer.zero_grad()</a>
            output = bagua_model(data)
            loss = nn.MSELoss()(output, target)

            loss.backward()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/baguasys/bagua/commit/88d374c2316a6a4a4a420fbc2bbb566d69869999#diff-a5d7ee32ab8d93a59290923aeb9597cae5becc8fb682daeac373c91bce6061f3L68' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66226495</div><div id='project'> Project Name: baguasys/bagua</div><div id='commit'> Commit Name: 88d374c2316a6a4a4a420fbc2bbb566d69869999</div><div id='time'> Time: 2021-10-19</div><div id='author'> Author: 52795221+Tengxu-Sun@users.noreply.github.com</div><div id='file'> File Name: tests/torch_api/test_broadcast_state.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: run_bagua_broad(6)</div><div id='n_method'> N Method Name: run_bagua_broad(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/torch_api/test_broadcast_state.py</div><div id='n_file'> N File Name: tests/torch_api/test_broadcast_state.py</div><div id='m_start'> M Start Line: 77</div><div id='m_end'> M End Line: 85</div><div id='n_start'> N Start Line: 86</div><div id='n_end'> N End Line: 100</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 now we save the output and parameter gradients that we will use for comparison purposes with
        &#47&#47 the non-checkpointed run.
        output_checkpointed = out.data.clone()
        grad_checkpointed<a id="change"> = </a><a id="change">{}</a>
        for name, param in model.named_parameters():
            grad_checkpointed[name] = param.grad.data.clone()

        &#47&#47 compare the output and parameters gradients</code></pre><h3>After Change</h3><pre><code class='java'>
        out_2 = model_2(**inputs_dict).sample
        &#47&#47 run the backwards pass on the model. For backwards pass, for simplicity purpose,
        &#47&#47 we won&quott calculate the loss and rather backprop on out.sum()
        <a id="change">model_2.zero_grad()</a>
        loss_2 = (out_2 - labels).mean()
        loss_2.backward()

        &#47&#47 compare the output and parameters gradients</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/22963ed82682465b5fdfd1bd474e1b0f2579b4db#diff-e65cd8679b47855997f7a1e7b0bc1db8231acd2168d2cb6616d03d1fc201c1d7L270' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66226476</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: 22963ed82682465b5fdfd1bd474e1b0f2579b4db</div><div id='time'> Time: 2022-10-10</div><div id='author'> Author: patrick.v.platen@gmail.com</div><div id='file'> File Name: tests/test_models_unet.py</div><div id='m_class'> M Class Name: UNet2DConditionModelTests</div><div id='n_method'> N Class Name: UNet2DConditionModelTests</div><div id='m_method'> M Method Name: test_gradient_checkpointing(1)</div><div id='n_method'> N Method Name: test_gradient_checkpointing(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase,ModelTesterMixin</div><div id='n_parent_class'> N Parent Class: unittest.TestCase,ModelTesterMixin</div><div id='m_file'> M File Name: tests/test_models_unet.py</div><div id='n_file'> N File Name: tests/test_models_unet.py</div><div id='m_start'> M Start Line: 273</div><div id='m_end'> M End Line: 333</div><div id='n_start'> N Start Line: 273</div><div id='n_end'> N End Line: 308</div><BR>