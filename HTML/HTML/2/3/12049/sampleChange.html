<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        batch_size, seq_length = input_["input_ids"].shape
        seq_lengths = None
        if "attention_mask" in input_:
            seq_lengths<a id="change"> = </a><a id="change">torch.sum(</a>input_["attention_mask"]<a id="change">, dim=-1)</a>
        &#47&#47 TODO: Why is this not happening in TransformerSpanClassificationTaskModule.collate?
        target = self._expand_target_tuples(
            target_tuples=target_tuples,
            batch_size=batch_size,</code></pre><h3>After Change</h3><pre><code class='java'>
        return loss

    def training_step(self, batch: TransformerSpanClassificationModelStepBatchEncoding, batch_idx: int):  &#47&#47 type: ignore
        return <a id="change">self.step(stage=TRAINING, batch=batch, batch_idx=batch_idx)</a>

    def validation_step(self, batch: TransformerSpanClassificationModelStepBatchEncoding, batch_idx: int):  &#47&#47 type: ignore
        return self.step(stage=VALIDATION, batch=batch, batch_idx=batch_idx)
</code></pre>