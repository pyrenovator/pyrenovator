<html><h3>Pattern ID :13307
</h3><img src='45087559.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                self.temporery_short_term_buff.append(
                    self._create_current_cloned_buff())

            buff<a id="change"> = </a><a id="change">self.theta_buffer.pop(</a>batch_index<a id="change">)</a>
            self._restore_from_buff(buff)
        elif self.has_weight_predictor:
            &#47&#47 THAN every micro batch can have its own stashed weight -&gt; restore it.
            &#47&#47 Note: we don&quott need to restore from top.</code></pre><h3>After Change</h3><pre><code class='java'>
        
        &#47&#47 print(f"popped {batch_index} rank {rank}")
        is_dirty = self.dirty_mark.pop(batch_index)
        if <a id="change">is_dirty and (self.get_micro_batch_backward(batch_index) == 0)</a>:
            &#47&#47 Ensure correct post resotore:
            &#47&#47 create temporary buffer -&gt; (do backward) -&gt; ... -&gt; (do step)-&gt; then restore it
            &#47&#47 Same versions as backward!</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/saareliad/ftpipe/commit/effbb50dd3a6ccfe8e27b767f81fe72ab20a0f6e#diff-91443611e3171fe45749c4d584cc3fa7d8288a10a382a8894e9054d966fdfea7L154' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45087559</div><div id='project'> Project Name: saareliad/ftpipe</div><div id='commit'> Commit Name: effbb50dd3a6ccfe8e27b767f81fe72ab20a0f6e</div><div id='time'> Time: 2020-02-09</div><div id='author'> Author: saareliad@campus.technion.ac.il</div><div id='file'> File Name: pipeline/weight_stashing/weight_stashing.py</div><div id='m_class'> M Class Name: WeightStasher</div><div id='n_method'> N Class Name: WeightStasher</div><div id='m_method'> M Method Name: pop_restore_stashed(2)</div><div id='n_method'> N Method Name: pop_restore_stashed(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: pipeline/weight_stashing/weight_stashing.py</div><div id='n_file'> N File Name: pipeline/weight_stashing/weight_stashing.py</div><div id='m_start'> M Start Line: 154</div><div id='m_end'> M End Line: 171</div><div id='n_start'> N Start Line: 166</div><div id='n_end'> N End Line: 178</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                ),
            )

            step_name<a id="change"> = </a><a id="change">kwargs.pop(</a>"name"<a id="change">)</a>
        else:
            raise RuntimeError(
                "No step specified to get from "
                "`PipelineRunView`. Please set a `step` "</code></pre><h3>After Change</h3><pre><code class='java'>
        step_name = kwargs.get("name", None)

        &#47&#47 Raise an error if neither `step` nor `name` args were provided.
        if <a id="change">not step and not isinstance(step_name, str)</a>:
            raise RuntimeError(
                "No step specified. Please specify a step using "
                "pipeline_run_view.get_step(step=`step_name`). "</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/maiot-io/zenml/commit/771bddac97bf99e5a1c9bad3b0227a187c592c51#diff-aaa0c071258bae9198bb3833d691e37565f3b6214fc5c3ff526879bdad857c24L161' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45087556</div><div id='project'> Project Name: maiot-io/zenml</div><div id='commit'> Commit Name: 771bddac97bf99e5a1c9bad3b0227a187c592c51</div><div id='time'> Time: 2022-08-02</div><div id='author'> Author: felix@zenml.io</div><div id='file'> File Name: src/zenml/post_execution/pipeline_run.py</div><div id='m_class'> M Class Name: PipelineRunView</div><div id='n_method'> N Class Name: PipelineRunView</div><div id='m_method'> M Method Name: get_step(2)</div><div id='n_method'> N Method Name: get_step(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/zenml/post_execution/pipeline_run.py</div><div id='n_file'> N File Name: src/zenml/post_execution/pipeline_run.py</div><div id='m_start'> M Start Line: 163</div><div id='m_end'> M End Line: 236</div><div id='n_start'> N Start Line: 161</div><div id='n_end'> N End Line: 224</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            input_mask = torch.full_like(out, True, dtype=torch.bool, device=out.device)
        
        &#47&#47 in case of conditional generation, if enc_mask is not provided use the correct context_mask
        context<a id="change"> = </a><a id="change">kwargs.pop(</a>&quotcontext&quot, None<a id="change">)</a>
        context_mask = kwargs.pop(&quotcontext_mask&quot, None)
        if context is not None and context_mask is None:
            context_mask = torch.full(context.shape[:2], True, dtype=torch.bool, device=out.device)
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 in case of conditional generation, if enc_mask is not provided use the correct context_mask
        context_mask = kwargs.pop(&quotcontext_mask&quot, None)

        if <a id="change">&quotcontext&quot in kwargs and not exists(context_mask)</a>:
            context = kwargs[&quotcontext&quot]
            context_mask = torch.full(context.shape[:2], True, dtype=torch.bool, device=out.device)
            kwargs.update(context_mask = context_mask)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/performer-pytorch/commit/e10ec182c2aba2eba66b59a175ed767251aa3889#diff-192164ea998deaff038129dced1fc9dbccf034f70eaf2ffa88b31af860963378L35' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45087554</div><div id='project'> Project Name: lucidrains/performer-pytorch</div><div id='commit'> Commit Name: e10ec182c2aba2eba66b59a175ed767251aa3889</div><div id='time'> Time: 2020-12-08</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: performer_pytorch/autoregressive_wrapper.py</div><div id='m_class'> M Class Name: AutoregressiveWrapper</div><div id='n_method'> N Class Name: AutoregressiveWrapper</div><div id='m_method'> M Method Name: generate(7)</div><div id='n_method'> N Method Name: generate(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: performer_pytorch/autoregressive_wrapper.py</div><div id='n_file'> N File Name: performer_pytorch/autoregressive_wrapper.py</div><div id='m_start'> M Start Line: 52</div><div id='m_end'> M End Line: 57</div><div id='n_start'> N Start Line: 55</div><div id='n_end'> N End Line: 62</div><BR>