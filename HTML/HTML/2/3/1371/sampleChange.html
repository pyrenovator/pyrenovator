<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 [batch, num_heads, hh * ww, hh * ww]
    attention_scores = keras.layers.Lambda(lambda xx: tf.matmul(xx[0], xx[1]))([query, key])
    attention_scores = MultiHeadRelativePositionalEmbedding(name=name and name + "pos_emb")(attention_scores)
    attention_scores = <a id="change">tf.nn.softmax(</a>attention_scores<a id="change">, axis=-1)</a>

    if attn_dropout &gt; 0:
        attention_scores = keras.layers.Dropout(attn_dropout, name=name and name + "attn_drop")(attention_scores)
    &#47&#47 value = [batch, num_heads, hh * ww, key_dim]</code></pre><h3>After Change</h3><pre><code class='java'>
    attention_scores = keras.layers.Lambda(lambda xx: tf.matmul(xx[0], xx[1]))([query, key])
    attention_scores = MultiHeadRelativePositionalEmbedding(name=name and name + "pos_emb")(attention_scores)
    &#47&#47 attention_scores = tf.nn.softmax(attention_scores, axis=-1, name=name and name + "_attention_scores")
    attention_scores = <a id="change">keras.layers.Softmax(axis=-1, name=name and name + "attention_scores")(</a>attention_scores<a id="change">)</a>

    if attn_dropout &gt; 0:
        attention_scores = keras.layers.Dropout(attn_dropout, name=name and name + "attn_drop")(attention_scores)
    &#47&#47 value = [batch, num_heads, hh * ww, key_dim]</code></pre>