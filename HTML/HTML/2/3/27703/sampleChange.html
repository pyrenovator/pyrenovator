<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.to_k = nn.Linear(dim, qk_dim, bias=False)
        self.to_v = nn.Linear(dim, v_dim, bias=False)

        self.dropout = <a id="change">nn.Dropout(</a>dropout<a id="change">)</a>
        self.attn_fn = F.softmax
        self.to_out = nn.Linear(v_dim, dim)

    @typechecked</code></pre><h3>After Change</h3><pre><code class='java'>

        if use_previous_attention:
            &#47&#47 If we use the attention pattern from the last attention layer, we don&quott need queries and keys
            self.to_v<a id="change"> = </a><a id="change">nn.Linear(</a>dim, v_dim<a id="change">, bias=False)</a>

        else:
            &#47&#47 Standard attention layer that will calculate the attention pattern from queries and keys
            self.to_q = nn.Linear(dim, qk_dim, bias=False)</code></pre>