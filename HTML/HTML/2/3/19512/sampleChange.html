<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                score = metric(link_labels.cpu(), link_logits.cpu())
                mae.append(mean_absolute_error(link_labels.cpu(), link_logits.cpu()))
                rmse.append(mean_squared_error(link_labels.cpu(), link_logits.cpu(), squared=False))
                <a id="change">mse.append(</a>mean_squared_error(link_labels.cpu(), link_logits.cpu())<a id="change">)</a>
        return score, model, mae, rmse, mse

    def test_all(self, train_data_local_dict, test_data_local_dict, device, args) -&gt; bool:
        logging.info("----------test_on_the_server--------")</code></pre><h3>After Change</h3><pre><code class='java'>
                out = model.decode(z, batch.edge_index, neg_edge_index).view(-1).sigmoid()
                pred = (out &gt; threshold).float() * 1
            
            cum_score<a id="change"> += </a>average_precision_score(<a id="change">np.ones(</a>pred.numel()<a id="change">)</a>, pred.cpu())
            print(cum_score)
            ngraphs += batch.num_graphs
</code></pre>