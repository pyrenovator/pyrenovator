<html><h3>Pattern ID :28249
</h3><img src='83412664.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                    {"params": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 
                                    "weight_decay": 0.0}]
    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)
    <a id="change">optimizer.zero_grad()</a>

    if args.use_scheduler:
        steps = len(train_loader) * args.epochs // args.accumulation
        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(steps * args.warmup_pct), num_training_steps=steps)</code></pre><h3>After Change</h3><pre><code class='java'>
        study = optuna.create_study(direction=&quotmaximize&quot)
        study.optimize(objective, n_trials=args.opt_n_trials)

        pruned_trials = [t for t in study.trials if <a id="change">t.state == optuna.trial.TrialState.PRUNED</a>]
        complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]

        print("Study statistics: ")</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 6</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/jcblaisecruz02/filipino-text-benchmarks/commit/15609e90770528e9ab579af62caf962d30560f76#diff-ed183d67207df065a11e1289f19d34cc2abbc5448dea952683cfe9728c342b95L55' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83412664</div><div id='project'> Project Name: jcblaisecruz02/filipino-text-benchmarks</div><div id='commit'> Commit Name: 15609e90770528e9ab579af62caf962d30560f76</div><div id='time'> Time: 2020-06-06</div><div id='author'> Author: jan_christian_cruz@dlsu.edu.ph</div><div id='file'> File Name: train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: finetune(1)</div><div id='n_method'> N Method Name: finetune(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train.py</div><div id='n_file'> N File Name: train.py</div><div id='m_start'> M Start Line: 55</div><div id='m_end'> M End Line: 115</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 166</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 another function can then call step
    def train(self, x: torch.FloatTensor):
        self.net.train()
        <a id="change">self.opt.zero_grad()</a>
        with torch.cuda.amp.autocast(enabled=self.scaler.is_enabled()):
            loss, r_loss, l_loss, _ = self._calculate_loss(x)
        self.scaler.scale(loss).backward()
        self.scaler.step(self.opt)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 self.scaler.update()

        self.train_steps += 1
        <a id="change">if self.train_steps % self.update_frequency == 0</a>:
            self._update_parameters()

        return loss.item(), r_loss.item(), l_loss.item()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/vvvm23/vqvae-2/commit/d66f670f9b0b0c60e1c71597999ca30721496478#diff-9f1d8e92cd6ea2024cda543185e6c91bbc5cd7377d0eb7d5b071abee5e466410L28' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83412652</div><div id='project'> Project Name: vvvm23/vqvae-2</div><div id='commit'> Commit Name: d66f670f9b0b0c60e1c71597999ca30721496478</div><div id='time'> Time: 2021-05-06</div><div id='author'> Author: alexander.f.mckinney@durham.ac.uk</div><div id='file'> File Name: trainer.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: train(2)</div><div id='n_method'> N Method Name: train(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: trainer.py</div><div id='n_file'> N File Name: trainer.py</div><div id='m_start'> M Start Line: 30</div><div id='m_end'> M End Line: 35</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 46</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            
            self.optimizer.zero_grad()
            self.Generator_opt.zero_grad()
            <a id="change">self.Discriminator_opt.zero_grad()</a>
            
            &#47&#47 train D
            &#47&#47 Y_fake,dis_fake = self.model(X)
            &#47&#47 dis_real = self.model.module.discriminator(Y)</code></pre><h3>After Change</h3><pre><code class='java'>

        if self.lr_scheduler_D is not None:
            self.lr_scheduler_D.step()
        <a id="change">if self.lr_scheduler_G is not None</a>:
            self.lr_scheduler_G.step()
        return log
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/zxpzhong/3d-recgan-pytorch/commit/6c6bd5dd1919d9a3d4f3d51d64626dac813e300e#diff-0564ece5aadc13d5923043addc422a8058c6d96026493e84652cedc2f1bdca99L41' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83412653</div><div id='project'> Project Name: zxpzhong/3d-recgan-pytorch</div><div id='commit'> Commit Name: 6c6bd5dd1919d9a3d4f3d51d64626dac813e300e</div><div id='time'> Time: 2020-06-26</div><div id='author'> Author: zxpzhong@qq.com</div><div id='file'> File Name: trainer/trainer.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: _train_epoch(2)</div><div id='n_method'> N Method Name: _train_epoch(2)</div><div id='m_parent_class'> M Parent Class: BaseTrainer</div><div id='n_parent_class'> N Parent Class: BaseTrainer</div><div id='m_file'> M File Name: trainer/trainer.py</div><div id='n_file'> N File Name: trainer/trainer.py</div><div id='m_start'> M Start Line: 58</div><div id='m_end'> M End Line: 58</div><div id='n_start'> N Start Line: 106</div><div id='n_end'> N End Line: 108</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            
        global_step = 0
        writer_step = 0
        <a id="change">self.model_S.zero_grad()</a>
        while global_step &lt; num_steps:
            global_step += 1
            for _ in range(self.t_config.gradient_accumulation_steps):
                &#47&#47sampling taskname</code></pre><h3>After Change</h3><pre><code class='java'>
                scalar_total_loss = total_loss.cpu().item() * self.t_config.gradient_accumulation_steps
                self.tb_writer.add_scalar(&quotscalar/total_loss&quot, scalar_total_loss, writer_step)
                writer_step += 1
            <a id="change">if max_grad_norm &gt; 0</a>:
                torch.nn.utils.clip_grad_norm_(self.model_S.parameters(), max_grad_norm) 
            optimizer.step()
            if scheduler is not None:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/airaria/textbrewer/commit/7a8d3c7e324b4b05dbce0b1fc5025bfda6d1cfc0#diff-a0df517a14c387489a167be94325fce9e4eceac1f693d479ceaa7822801fdf1aL36' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83412656</div><div id='project'> Project Name: airaria/textbrewer</div><div id='commit'> Commit Name: 7a8d3c7e324b4b05dbce0b1fc5025bfda6d1cfc0</div><div id='time'> Time: 2020-04-14</div><div id='author'> Author: yangziqing@163.com</div><div id='file'> File Name: src/textbrewer/distiller_multitask.py</div><div id='m_class'> M Class Name: MultiTaskDistiller</div><div id='n_method'> N Class Name: MultiTaskDistiller</div><div id='m_method'> M Method Name: train(11)</div><div id='n_method'> N Method Name: train(8)</div><div id='m_parent_class'> M Parent Class: BasicDistiller</div><div id='n_parent_class'> N Parent Class: BasicDistiller</div><div id='m_file'> M File Name: src/textbrewer/distiller_multitask.py</div><div id='n_file'> N File Name: src/textbrewer/distiller_multitask.py</div><div id='m_start'> M Start Line: 36</div><div id='m_end'> M End Line: 94</div><div id='n_start'> N Start Line: 36</div><div id='n_end'> N End Line: 106</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            print(&quotEPOCH {:d} / {:d}&quot.format(epoch, self.num_epochs))
            for iter_index, data in enumerate(self.train_data_loader):
                loss = self.run_iters(epoch, iter_index, data)
                <a id="change">self.optim.zero_grad()</a>
                loss.backward()
                self.optim.step()
            &#47&#47 update lr_scheduler
            if self.scheduler is not None:</code></pre><h3>After Change</h3><pre><code class='java'>
            print(&quotEPOCH {:d} / {:d}&quot.format(epoch, self.num_epochs))
            for iter_index, data in enumerate(self.train_data_loader):
                loss = self.run_iters(epoch, iter_index, data)
                <a id="change">if loss is not None</a>:
                    self.backward(loss)
            &#47&#47 update lr_scheduler
            if self.scheduler is not None:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/cnstark/easytorch/commit/18351dbd2f98593556c9254bb2e03a8e299d1bec#diff-b9082a42e236d48692450505abbe51e3ecce3ae7138cf60c15871bf1344d11d9L115' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83412660</div><div id='project'> Project Name: cnstark/easytorch</div><div id='commit'> Commit Name: 18351dbd2f98593556c9254bb2e03a8e299d1bec</div><div id='time'> Time: 2020-12-26</div><div id='author'> Author: yuhaow97@gmail.com</div><div id='file'> File Name: easytorch.py</div><div id='m_class'> M Class Name: EasyTraining</div><div id='n_method'> N Class Name: EasyTraining</div><div id='m_method'> M Method Name: train(1)</div><div id='n_method'> N Method Name: train(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: easytorch.py</div><div id='n_file'> N File Name: easytorch.py</div><div id='m_start'> M Start Line: 120</div><div id='m_end'> M End Line: 123</div><div id='n_start'> N Start Line: 125</div><div id='n_end'> N End Line: 129</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        loss = (self.entropy_coeff * log_probs - values).mean()

        <a id="change">optimizer.zero_grad()</a>
        loss.backward()
        if self.max_grad &gt; 0:
            T.nn.utils.clip_grad_norm_(actor.parameters(), self.max_grad)
        optimizer.step()</code></pre><h3>After Change</h3><pre><code class='java'>
        actor_parameters = actor.parameters()
        optimizer = self.optimizer_class(actor_parameters, lr=self.lr)
        &#47&#47 make sure critic isn&quott updated!
        <a id="change">if critic2 is not None</a>:
            critic_variables = critic1.parameters() + critic2.parameters()
        else:
            critic_variables = critic1.parameters()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/londonnode/pearl/commit/5c22c7fc250069e06ba0836af2978123ce60e6a8#diff-b68c703d61b55535b734b62646c41dc40f50b287ada3402dbf6b5a6cd37fddceL241' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83412662</div><div id='project'> Project Name: londonnode/pearl</div><div id='commit'> Commit Name: 5c22c7fc250069e06ba0836af2978123ce60e6a8</div><div id='time'> Time: 2021-09-24</div><div id='author'> Author: rohan.tangri@gmail.com</div><div id='file'> File Name: anvil/updaters/actors.py</div><div id='m_class'> M Class Name: SoftPolicyGradient</div><div id='n_method'> N Class Name: SoftPolicyGradient</div><div id='m_method'> M Method Name: __call__(5)</div><div id='n_method'> N Method Name: __call__(5)</div><div id='m_parent_class'> M Parent Class: BaseActorUpdater</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: anvil/updaters/actors.py</div><div id='n_file'> N File Name: anvil/updaters/actors.py</div><div id='m_start'> M Start Line: 256</div><div id='m_end'> M End Line: 290</div><div id='n_start'> N Start Line: 275</div><div id='n_end'> N End Line: 309</div><BR>