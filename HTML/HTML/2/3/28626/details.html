<html><h3>Pattern ID :28626
</h3><img src='84533101.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def _allgather_param(self, param, async_op=False, hierarchy=0):

        partition_size = <a id="change">param.ds_tensor.numel()</a>

        tensor_size = partition_size * self.world_size
        aligned_param_size = self._aligned_size(param)
        assert tensor_size == aligned_param_size, f&quotparam id {param.ds_id} aligned size {aligned_param_size} does not match tensor size {tensor_size}&quot</code></pre><h3>After Change</h3><pre><code class='java'>
        flat_tensor = torch.zeros(aligned_param_size,
                                  dtype=param.dtype,
                                  device=param.device).view(-1)
        <a id="change">see_memory_usage(
            f&quotAfter allocate allgather param {param.ds_id} {param.ds_status} {aligned_param_size} {partition_size} {param.ds_shape}&quot</a><a id="change">,
            force=False)</a>

        torch.cuda.synchronize()

        print_rank_0(</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 2</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/0d4a54a04d658db40a120bc10c6f1f1a4478f6f1#diff-bc45426db58250294594100cfdf3d73ecb653d879cabee404e38edc4eb4c9ecbL605' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84533101</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: 0d4a54a04d658db40a120bc10c6f1f1a4478f6f1</div><div id='time'> Time: 2021-04-18</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/runtime/zero/partition_parameters.py</div><div id='m_class'> M Class Name: Init</div><div id='n_method'> N Class Name: Init</div><div id='m_method'> M Method Name: _allgather_param(4)</div><div id='n_method'> N Method Name: _allgather_param(4)</div><div id='m_parent_class'> M Parent Class: InsertPostInitMethodToModuleSubClasses</div><div id='n_parent_class'> N Parent Class: InsertPostInitMethodToModuleSubClasses</div><div id='m_file'> M File Name: deepspeed/runtime/zero/partition_parameters.py</div><div id='n_file'> N File Name: deepspeed/runtime/zero/partition_parameters.py</div><div id='m_start'> M Start Line: 605</div><div id='m_end'> M End Line: 605</div><div id='n_start'> N Start Line: 743</div><div id='n_end'> N End Line: 761</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def initialize_optimizer_states(self):
        num_subgroups = len(self.fp16_groups)

        largest_numel = max([<a id="change">t.numel()</a> for t in self.fp16_partitioned_groups_flat])
        gradient_dtype = self.fp32_partitioned_groups_flat[0].dtype
        gradient_buffer = torch.zeros(int(largest_numel),
                                      dtype=gradient_dtype,</code></pre><h3>After Change</h3><pre><code class='java'>
            if swappable_param_subgroup:
                self._partitioned_params_swap_out(i)

            <a id="change">see_memory_usage(
                f&quot[End] Initialize optimizer states {i} / {num_subgroups} subgroups, num_elems: {num_elements}, swappable opt/param:{swappable_optimizer_subgroup}/{swappable_param_subgroup}&quot</a><a id="change">,
                force=False)</a>

        self.stop_timers([INIT_OPTIMIZER_TIMER])
        self.log_timers(timer_names)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/0d4a54a04d658db40a120bc10c6f1f1a4478f6f1#diff-1ad5daa1b31aa5573616024068d646f0c38e88d4d3a71d3d0e4bc352ea232178L1173' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84533100</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: 0d4a54a04d658db40a120bc10c6f1f1a4478f6f1</div><div id='time'> Time: 2021-04-18</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/runtime/zero/stage3.py</div><div id='m_class'> M Class Name: FP16_DeepSpeedZeroOptimizer_Stage3</div><div id='n_method'> N Class Name: FP16_DeepSpeedZeroOptimizer_Stage3</div><div id='m_method'> M Method Name: initialize_optimizer_states(1)</div><div id='n_method'> N Method Name: initialize_optimizer_states(1)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: deepspeed/runtime/zero/stage3.py</div><div id='n_file'> N File Name: deepspeed/runtime/zero/stage3.py</div><div id='m_start'> M Start Line: 1176</div><div id='m_end'> M End Line: 1214</div><div id='n_start'> N Start Line: 1625</div><div id='n_end'> N End Line: 1690</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                        force=False)
                else:
                    total_elements = sum(
                        [<a id="change">t.numel()</a> for t in self.fp16_partitioned_groups[i]])
                    fp16_partitioned_group_flat = self.param_groups_fp16_flat_cpu_memory[
                        j].narrow(0,
                                  flat_offset,</code></pre><h3>After Change</h3><pre><code class='java'>
                        device=&quotcpu&quot,
                        pin_memory=True)

                <a id="change">see_memory_usage(f"After Flattening param subgroup {i}"</a><a id="change">, force=False)</a>

    def _swap_in_sub_group_to_flat_buffer(self, flat_buffer, sub_group_id):
        offset = 0</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/0d4a54a04d658db40a120bc10c6f1f1a4478f6f1#diff-1ad5daa1b31aa5573616024068d646f0c38e88d4d3a71d3d0e4bc352ea232178L879' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84533102</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: 0d4a54a04d658db40a120bc10c6f1f1a4478f6f1</div><div id='time'> Time: 2021-04-18</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/runtime/zero/stage3.py</div><div id='m_class'> M Class Name: FP16_DeepSpeedZeroOptimizer_Stage3</div><div id='n_method'> N Class Name: FP16_DeepSpeedZeroOptimizer_Stage3</div><div id='m_method'> M Method Name: _create_fp16_partitions_with_defragmentation(1)</div><div id='n_method'> N Method Name: _create_fp16_partitions_with_defragmentation(1)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: deepspeed/runtime/zero/stage3.py</div><div id='n_file'> N File Name: deepspeed/runtime/zero/stage3.py</div><div id='m_start'> M Start Line: 884</div><div id='m_end'> M End Line: 944</div><div id='n_start'> N Start Line: 1079</div><div id='n_end'> N End Line: 1177</div><BR>