<html><h3>Pattern ID :2123
</h3><img src='9104066.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    c, r = torch.meshgrid(torch.arange(cols), torch.arange(rows))

    c = torch.transpose(c.cuda(), 0, 1)
    r = torch.transpose(<a id="change">r.cuda()</a>, 0, 1)
    points = torch.stack([c, r, depth])
    points<a id="change"> = </a>points.reshape((3, -1)).T
    points = points[mask.reshape(-1)] &#47&#47 shape = n_points, 3

    &#47&#47 (5 - 10 ms)</code></pre><h3>After Change</h3><pre><code class='java'>
    c, r = torch.meshgrid(torch.arange(cols, device=device), torch.arange(rows, device=device))
    c = c.T.reshape(-1) * mask
    r = r.T.reshape(-1) * mask
    depth = <a id="change">depth.reshape(</a>-1<a id="change">)</a> * mask
    points = torch.stack([c, r, depth])
    points = points.T
    &#47&#47 points = points[mask]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/amrelsersy/stereo-3d-detection/commit/02583fa0a7bd1e3d1c8632688113329b81157122#diff-676f7650f3dec930afb7a8b546d68697e7bb37d3f22568134acd31287ed33b07L21' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9104066</div><div id='project'> Project Name: amrelsersy/stereo-3d-detection</div><div id='commit'> Commit Name: 02583fa0a7bd1e3d1c8632688113329b81157122</div><div id='time'> Time: 2021-05-24</div><div id='author'> Author: mamoanwar97@gmail.com</div><div id='file'> File Name: Models/AnyNet/preprocessing/generate_lidar.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: project_disp_to_points(3)</div><div id='n_method'> N Method Name: project_disp_to_points(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: Models/AnyNet/preprocessing/generate_lidar.py</div><div id='n_file'> N File Name: Models/AnyNet/preprocessing/generate_lidar.py</div><div id='m_start'> M Start Line: 21</div><div id='m_end'> M End Line: 42</div><div id='n_start'> N Start Line: 21</div><div id='n_end'> N End Line: 33</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

            &#47&#47 chenyun版本的代码中是有对训练阶段的roi_locs进行归一化的,然后再在非训练状态下进行逆向归一化
            mean = torch.Tensor(self.loc_normalize_mean).cuda().repeat(self.n_class)[None]
            std<a id="change"> = </a><a id="change">torch.Tensor(self.loc_normalize_std).cuda()</a>.repeat(self.n_class)[None]
            roi_locs = (roi_locs * std + mean)  &#47&#47 减均值除以方差的逆过程

            roi_locs = roi_locs.view(-1, self.n_class, 4)  &#47&#47 [300, self.n_class*4] -&gt; [300, self.n_class, 4]</code></pre><h3>After Change</h3><pre><code class='java'>
            roi_locs = roi_locs.view(-1, self.n_class, 4)  &#47&#47 [300, self.n_class*4] -&gt; [300, self.n_class, 4]
            roi = roi.view(-1, 1, 4).expand_as(roi_locs)   &#47&#47 [300, 1, 4] -&gt; [300, self.n_class, 4]
            &#47&#47 pred_boxes = loc2box(at.tonumpy(roi).reshape((-1, 4)),at.tonumpy(roi_locs).reshape((-1, 4)))
            pred_boxes = loc2box_torch(<a id="change">roi.reshape(</a>-1, 4<a id="change">)</a>,roi_locs.reshape(-1, 4))
            pred_boxes = at.totensor(pred_boxes)  &#47&#47 torch.Size([5700, 4])
            pred_boxes = pred_boxes.view(-1, self.n_class, 4)   &#47&#47 (300*self.n_class, 4) -&gt; (300, self.n_class, 4)
            &#47&#47 限制预测框的坐标范围</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pangkun248/faster-rcnn-pytorch/commit/039ff4a5e5951cf78a03f81db4cb0094623eb8de#diff-fada037ad086638e65c7ae77e3d223963e9afaa26326aab0ea718f4013176e43L125' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9104042</div><div id='project'> Project Name: pangkun248/faster-rcnn-pytorch</div><div id='commit'> Commit Name: 039ff4a5e5951cf78a03f81db4cb0094623eb8de</div><div id='time'> Time: 2021-08-26</div><div id='author'> Author: 39581901+pangkun248@users.noreply.github.com</div><div id='file'> File Name: model.py</div><div id='m_class'> M Class Name: FasterRCNN</div><div id='n_method'> N Class Name: FasterRCNN</div><div id='m_method'> M Method Name: predict(3)</div><div id='n_method'> N Method Name: predict(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model.py</div><div id='n_file'> N File Name: model.py</div><div id='m_start'> M Start Line: 150</div><div id='m_end'> M End Line: 156</div><div id='n_start'> N Start Line: 153</div><div id='n_end'> N End Line: 158</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        update_list_avg = [tb_exp_averager.forward("Loss_average", _) for _ in update_list]
        &#47&#47 Computing gradients for fnet and updating weights
        fnet_loss = FLAGS.warp_scaling * warp_loss + fnet_loss.detach()
        fnet_loss<a id="change"> = </a><a id="change">fnet_loss.cuda()</a>
        fnet_optimizer.zero_grad()
        fnet_loss.backward()
        fnet_optimizer.step()
        update_list_avg += [tb, dt_ratio]</code></pre><h3>After Change</h3><pre><code class='java'>
                                  FLAGS.crop_size))
    s_input_warp = F.grid_sample(torch.reshape(Frame_t_pre, (
        FLAGS.batch_size * (inputimages - 1), output_channel, FLAGS.crop_size, FLAGS.crop_size)),
                                 <a id="change">torch.reshape(</a>Frame_t[:, :, 0:2], (FLAGS.batch_size * (inputimages - 1), 32, 32, 2)<a id="change">)</a>)

    input0 = torch.cat(
        (r_inputs[:, 0, :, :, :], torch.zeros(size=(FLAGS.batch_size, 3 * 4 * 4, FLAGS.crop_size, FLAGS.crop_size),</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/dwightfoster/pytorch-tecogan/commit/b64afd58ac37b8b9ed21dc91b415612572cfa585#diff-f5a7fdedd2c0ddebef9c8da0be135c2dfddb9e5339087d894cdd812cea93a47eL47' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9104038</div><div id='project'> Project Name: dwightfoster/pytorch-tecogan</div><div id='commit'> Commit Name: b64afd58ac37b8b9ed21dc91b415612572cfa585</div><div id='time'> Time: 2021-03-11</div><div id='author'> Author: dwightfoster03@gmail.com</div><div id='file'> File Name: code/train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: TecoGAN(11)</div><div id='n_method'> N Method Name: TecoGAN(13)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: code/train.py</div><div id='n_file'> N File Name: code/train.py</div><div id='m_start'> M Start Line: 47</div><div id='m_end'> M End Line: 347</div><div id='n_start'> N Start Line: 66</div><div id='n_end'> N End Line: 145</div><BR>