<html><h3>Pattern ID :39957
</h3><img src='113695114.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            )
            loss.backward()
            optimizer.step()
            <a id="change">optimizer.zero_grad()</a>

        return loss.detach()

    def evaluate_batch(self, batch, stage):</code></pre><h3>After Change</h3><pre><code class='java'>
        self.g_optimizer.step()
        self.g_optimizer.zero_grad()

        predictions<a id="change"> = </a>self.compute_forward(inputs, sb.Stage.TRAIN)
        d_loss = self.compute_objectives(
            predictions, inputs, sb.Stage.TRAIN, "discriminator"
        )
        <a id="change">d_loss.backward()</a>
        self.d_optimizer.step()
        self.d_optimizer.zero_grad()

        return g_loss.detach() + d_loss.detach()</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/de699fa49ebc3f5b1cca4061a41ddf44e8770c66#diff-3c0b8827ddfccfad16b32e2bf9ec374784d77df413a473dd95d09500436f12b0L45' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113695114</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: de699fa49ebc3f5b1cca4061a41ddf44e8770c66</div><div id='time'> Time: 2020-09-24</div><div id='author'> Author: plantinga.peter@protonmail.com</div><div id='file'> File Name: recipes/minimal_examples/neural_networks/enhance_GAN/example_enhance_gan_experiment.py</div><div id='m_class'> M Class Name: EnhanceGanBrain</div><div id='n_method'> N Class Name: EnhanceGanBrain</div><div id='m_method'> M Method Name: fit_batch(2)</div><div id='n_method'> N Method Name: fit_batch(2)</div><div id='m_parent_class'> M Parent Class: sb.Brain</div><div id='n_parent_class'> N Parent Class: sb.Brain</div><div id='m_file'> M File Name: recipes/minimal_examples/neural_networks/enhance_GAN/example_enhance_gan_experiment.py</div><div id='n_file'> N File Name: recipes/minimal_examples/neural_networks/enhance_GAN/example_enhance_gan_experiment.py</div><div id='m_start'> M Start Line: 48</div><div id='m_end'> M End Line: 57</div><div id='n_start'> N Start Line: 45</div><div id='n_end'> N End Line: 63</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
  &#47&#47 Update the policy by maximising the clipped PPO objective
  policy_ratio = (trajectories[&quotlog_prob_actions&quot] - trajectories[&quotold_log_prob_actions&quot]).exp()
  policy_loss = -torch.min(policy_ratio * trajectories[&quotadvantages&quot], torch.clamp(policy_ratio, min=1 - ppo_clip, max=1 + ppo_clip) * trajectories[&quotadvantages&quot]).mean()
  <a id="change">actor_optimiser.zero_grad()</a>
  policy_loss.backward()
  actor_optimiser.step()
</code></pre><h3>After Change</h3><pre><code class='java'>
  &#47&#47 Fit value function by regression on mean squared error
  value_loss = F.mse_loss(trajectories[&quotvalues&quot], trajectories[&quotrewards_to_go&quot])
  &#47&#47 Add entropy regularisation
  entropy_loss<a id="change"> = </a>-trajectories[&quotentropies&quot].mean()  
  
  agent_optimiser.zero_grad()
  <a id="change">(policy_loss + value_loss_coeff * value_loss + entropy_loss_coeff * entropy_loss).backward()</a>
  clip_grad_norm_(agent.parameters(), 1)  &#47&#47 Clamp norm of gradients
  agent_optimiser.step()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/kaixhin/imitation-learning/commit/fd3ee1838359dcc6da9836b6249396e595ff90db#diff-2b28d1dcda2cd70d29d3251359adce0fbfde60edb53108cba1a284ee0d39e256L33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113695112</div><div id='project'> Project Name: kaixhin/imitation-learning</div><div id='commit'> Commit Name: fd3ee1838359dcc6da9836b6249396e595ff90db</div><div id='time'> Time: 2020-04-16</div><div id='author'> Author: design@kaixhin.com</div><div id='file'> File Name: training.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: ppo_update(7)</div><div id='n_method'> N Method Name: ppo_update(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: training.py</div><div id='n_file'> N File Name: training.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 50</div><div id='n_start'> N Start Line: 34</div><div id='n_end'> N End Line: 51</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        out = model(**inputs_dict).sample
        &#47&#47 run the backwards pass on the model. For backwards pass, for simplicity purpose,
        &#47&#47 we won&quott calculate the loss and rather backprop on out.sum()
        <a id="change">model.zero_grad()</a>
        out.sum().backward()

        &#47&#47 now we save the output and parameter gradients that we will use for comparison purposes with
        &#47&#47 the non-checkpointed run.</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 run the backwards pass on the model. For backwards pass, for simplicity purpose,
        &#47&#47 we won&quott calculate the loss and rather backprop on out.sum()
        model_2.zero_grad()
        loss_2<a id="change"> = </a>(out_2 - labels).mean()
        <a id="change">loss_2.backward()</a>

        &#47&#47 compare the output and parameters gradients
        self.assertTrue((loss - loss_2).abs() &lt; 1e-5)
        named_params = dict(model.named_parameters())</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/22963ed82682465b5fdfd1bd474e1b0f2579b4db#diff-e65cd8679b47855997f7a1e7b0bc1db8231acd2168d2cb6616d03d1fc201c1d7L270' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113695113</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: 22963ed82682465b5fdfd1bd474e1b0f2579b4db</div><div id='time'> Time: 2022-10-10</div><div id='author'> Author: patrick.v.platen@gmail.com</div><div id='file'> File Name: tests/test_models_unet.py</div><div id='m_class'> M Class Name: UNet2DConditionModelTests</div><div id='n_method'> N Class Name: UNet2DConditionModelTests</div><div id='m_method'> M Method Name: test_gradient_checkpointing(1)</div><div id='n_method'> N Method Name: test_gradient_checkpointing(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase,ModelTesterMixin</div><div id='n_parent_class'> N Parent Class: unittest.TestCase,ModelTesterMixin</div><div id='m_file'> M File Name: tests/test_models_unet.py</div><div id='n_file'> N File Name: tests/test_models_unet.py</div><div id='m_start'> M Start Line: 273</div><div id='m_end'> M End Line: 333</div><div id='n_start'> N Start Line: 273</div><div id='n_end'> N End Line: 308</div><BR>