<html><h3>Pattern ID :34297
</h3><img src='98292010.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        :param pipelines: Different buckets to be used
        :return: The correct Pipeline object (or Bucket) to route input to
        
        <a id="change">if </a>isinstance(input_schema.inputs, str):
            current_seq_len = len(input_schema.inputs.split())
        elif isinstance(input_schema.inputs, list):
            current_seq_len = max(len(_input.split()) for _input in input_schema.inputs)</code></pre><h3>After Change</h3><pre><code class='java'>
        :return: The correct Pipeline object (or Bucket) to route input to
        
        tokenizer = pipelines[0].tokenizer
        tokens = <a id="change">tokenizer(
            </a>input_schema.inputs<a id="change">,
            add_special_tokens=True,
            return_tensors="np",
            padding=False,
            truncation=False,
        )</a>
        input_seq_len<a id="change"> = </a>len(tokens)
        return TransformersPipeline.select_bucket_by_seq_len(input_seq_len, pipelines)

    &#47&#47 utilities below adapted from transformers</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/neuralmagic/deepsparse/commit/20f708e7d739d5395b74dcbdcca1e48811d4bda1#diff-79e61bee1aadf04d6fd38371cf45def5472039227cde7f4e9bd194e76fe373bcL408' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 98292010</div><div id='project'> Project Name: neuralmagic/deepsparse</div><div id='commit'> Commit Name: 20f708e7d739d5395b74dcbdcca1e48811d4bda1</div><div id='time'> Time: 2022-07-28</div><div id='author'> Author: rahul@neuralmagic.com</div><div id='file'> File Name: src/deepsparse/transformers/pipelines/token_classification.py</div><div id='m_class'> M Class Name: TokenClassificationPipeline</div><div id='n_method'> N Class Name: TokenClassificationPipeline</div><div id='m_method'> M Method Name: route_input_to_bucket(0)</div><div id='n_method'> N Method Name: route_input_to_bucket(0)</div><div id='m_parent_class'> M Parent Class: TransformersPipeline</div><div id='n_parent_class'> N Parent Class: TransformersPipeline</div><div id='m_file'> M File Name: src/deepsparse/transformers/pipelines/token_classification.py</div><div id='n_file'> N File Name: src/deepsparse/transformers/pipelines/token_classification.py</div><div id='m_start'> M Start Line: 408</div><div id='m_end'> M End Line: 421</div><div id='n_start'> N Start Line: 408</div><div id='n_end'> N End Line: 417</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    source = "答案：" + title + tokenizer.eos_token + "上下文：" + source + "。" + tokenizer.eos_token + "在已知答案的前提下，问题："

    <a id="change">if </a>target:
        target += tokenizer.eos_token

    &#47&#47 1. tokenize input-tokens</code></pre><h3>After Change</h3><pre><code class='java'>
    )
    target_input_ids_len = (np.array(target_tokenized["input_ids"]) != tokenizer.pad_token_id).sum()

    source_tokenized<a id="change"> = </a><a id="change">tokenizer(
        </a>source<a id="change">,
        max_length=(max_source_length + max_target_length - target_input_ids_len),
        padding="max_length",
        truncation=True,
    )</a>

    input_ids = source_tokenized["input_ids"] + target_tokenized["input_ids"]
    labels = (len(input_ids) - target_input_ids_len) * [tokenizer.pad_token_id] + target_tokenized["input_ids"]
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/0d1cba43ca0eb4984715f3c807fde7345e80ca40#diff-9e01507f31a8cef3a50b864311e1088183748ed637f785df03a0d0dad8009454L57' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 98292015</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 0d1cba43ca0eb4984715f3c807fde7345e80ca40</div><div id='time'> Time: 2023-04-06</div><div id='author'> Author: fangzeyang0904@hotmail.com</div><div id='file'> File Name: examples/language_model/bloom/finetune_generation.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: convert_example(6)</div><div id='n_method'> N Method Name: convert_example(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/language_model/bloom/finetune_generation.py</div><div id='n_file'> N File Name: examples/language_model/bloom/finetune_generation.py</div><div id='m_start'> M Start Line: 68</div><div id='m_end'> M End Line: 105</div><div id='n_start'> N Start Line: 73</div><div id='n_end'> N End Line: 114</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        )

        for pipeline in pipelines:
            <a id="change">if </a>pipeline.sequence_length &gt; current_seq_len:
                return pipeline
        return pipelines[-1]
</code></pre><h3>After Change</h3><pre><code class='java'>
        :return: The correct Pipeline object (or Bucket) to route input to
        
        tokenizer = pipelines[0].tokenizer
        tokens<a id="change"> = </a><a id="change">tokenizer(
            </a>input_schema.sequences<a id="change">,
            add_special_tokens=True,
            return_tensors="np",
            padding=False,
            truncation=False,
        )</a>
        input_seq_len = len(tokens)
        return TransformersPipeline.select_bucket_by_seq_len(input_seq_len, pipelines)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neuralmagic/deepsparse/commit/20f708e7d739d5395b74dcbdcca1e48811d4bda1#diff-34d1b69d4854619e33f49d324826752e0354b65434899ce3e161cbd5e5c841e4L300' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 98292017</div><div id='project'> Project Name: neuralmagic/deepsparse</div><div id='commit'> Commit Name: 20f708e7d739d5395b74dcbdcca1e48811d4bda1</div><div id='time'> Time: 2022-07-28</div><div id='author'> Author: rahul@neuralmagic.com</div><div id='file'> File Name: src/deepsparse/transformers/pipelines/text_classification.py</div><div id='m_class'> M Class Name: TextClassificationPipeline</div><div id='n_method'> N Class Name: TextClassificationPipeline</div><div id='m_method'> M Method Name: route_input_to_bucket(0)</div><div id='n_method'> N Method Name: route_input_to_bucket(0)</div><div id='m_parent_class'> M Parent Class: TransformersPipeline</div><div id='n_parent_class'> N Parent Class: TransformersPipeline</div><div id='m_file'> M File Name: src/deepsparse/transformers/pipelines/text_classification.py</div><div id='n_file'> N File Name: src/deepsparse/transformers/pipelines/text_classification.py</div><div id='m_start'> M Start Line: 308</div><div id='m_end'> M End Line: 315</div><div id='n_start'> N Start Line: 308</div><div id='n_end'> N End Line: 317</div><BR>