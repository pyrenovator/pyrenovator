<html><h3>Pattern ID :33492
</h3><img src='96429565.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 assert the input shape is : batch_seq_size x entities_size x embeding_size
        &#47&#47 note: because the feature size of entity is not equal to 256, so it can not fed into transformer directly.
        &#47&#47 thus, we add a embedding layer to transfer it to right size.
        <a id="change">print(</a>&quotentity_input is nan:&quot, <a id="change">torch.isnan(</a>x<a id="change">)</a>.any()<a id="change">)</a> if debug else None

        &#47&#47 calculate there are how many real entities in each batch
        tmp_x = torch.mean(x, dim=2, keepdim=False)</code></pre><h3>After Change</h3><pre><code class='java'>
        mask = mask.repeat(batch_size, 1)
        mask = mask &lt; entity_num.unsqueeze(dim=1)

        <a id="change">print(</a>&quotmask:&quot, mask<a id="change">)</a> if debug else None
        print(&quotmask.shape:&quot, mask.shape) if debug else None

        &#47&#47 mask: [batch_size, max_entities]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/liuruoze/mini-alphastar/commit/612d42a7bf5ef827e1e919198d839fce106155cd#diff-71869e70f9cb835282d541d2d3529d25b6ed6795c79bc770e860e9318619f6b1L716' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 96429565</div><div id='project'> Project Name: liuruoze/mini-alphastar</div><div id='commit'> Commit Name: 612d42a7bf5ef827e1e919198d839fce106155cd</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: liuruoze@163.com</div><div id='file'> File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_class'> M Class Name: EntityEncoder</div><div id='n_method'> N Class Name: EntityEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='n_file'> N File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_start'> M Start Line: 721</div><div id='m_end'> M End Line: 758</div><div id='n_start'> N Start Line: 716</div><div id='n_end'> N End Line: 778</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            real, imag = sources[...,0], sources[...,1]
            sources_amplitude = torch.sqrt(real**2+imag**2)
            
            <a id="change">print(</a>torch.isnan(mixture_amplitude).any(), <a id="change">torch.isnan(</a>assignment<a id="change">)</a>.any(), torch.isnan(threshold_weight).any()<a id="change">, flush=True)</a>
            estimated_sources_amplitude = self.model(mixture_amplitude, assignment=assignment, threshold_weight=threshold_weight, n_sources=sources.size(1))
            print("estimated_sources_amplitude", torch.isnan(estimated_sources_amplitude).any(), flush=True)
            loss = self.criterion(estimated_sources_amplitude, sources_amplitude)
            print("loss", torch.isnan(loss).any(), flush=True)</code></pre><h3>After Change</h3><pre><code class='java'>
            real, imag = sources[...,0], sources[...,1]
            sources_amplitude = torch.sqrt(real**2+imag**2)
            
            <a id="change">print(</a>mixture_amplitude.size()<a id="change">)</a>
            estimated_sources_amplitude = self.model(mixture_amplitude, assignment=assignment, threshold_weight=threshold_weight, n_sources=sources.size(1))
            print("estimated_sources_amplitude", torch.isnan(estimated_sources_amplitude).any(), flush=True)
            loss = self.criterion(estimated_sources_amplitude, sources_amplitude)
            print("loss", torch.isnan(loss).any(), flush=True)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tky823/dnn-based_source_separation/commit/deaa5934ad98fea96c3190cef52f059ff99da3fc#diff-cd4335d0f9003fe8ab5982322db0eec7a82ee864f5925e3755f34f150ebfe050L29' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 96429564</div><div id='project'> Project Name: tky823/dnn-based_source_separation</div><div id='commit'> Commit Name: deaa5934ad98fea96c3190cef52f059ff99da3fc</div><div id='time'> Time: 2021-01-29</div><div id='author'> Author: 40362510+tky823@users.noreply.github.com</div><div id='file'> File Name: egs/wsj0-mix/danet/src/adhoc_driver.py</div><div id='m_class'> M Class Name: AdhocTrainer</div><div id='n_method'> N Class Name: AdhocTrainer</div><div id='m_method'> M Method Name: run_one_epoch_train(2)</div><div id='n_method'> N Method Name: run_one_epoch_train(2)</div><div id='m_parent_class'> M Parent Class: TrainerBase</div><div id='n_parent_class'> N Parent Class: TrainerBase</div><div id='m_file'> M File Name: egs/wsj0-mix/danet/src/adhoc_driver.py</div><div id='n_file'> N File Name: egs/wsj0-mix/danet/src/adhoc_driver.py</div><div id='m_start'> M Start Line: 47</div><div id='m_end'> M End Line: 51</div><div id='n_start'> N Start Line: 47</div><div id='n_end'> N End Line: 51</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 seq - [batch_size, seq_len]
        pos = torch.arange(0, seq.shape[1]).unsqueeze(0).repeat(seq.shape[0], 1).to(self.args.device)
        seq = self.dropout((self.tok_embed(seq) * self.scale) + self.pos_encoding(pos))
        <a id="change">print(</a>any(<a id="change">torch.isnan(</a>seq<a id="change">)</a>.view(-1))<a id="change">)</a>
        seq = seq.transpose(0, 1)
        out = self.transformer(seq, seq).transpose(0, 1)
        print(seq, &quot\n&quot, out)
        return self.fc_out(out)</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, seq):
        &#47&#47 seq - [batch_size, seq_len]
        mask = self._generate_square_subsequent_mask(seq.shape[1])
        <a id="change">print(</a>mask<a id="change">)</a>
        pos = torch.arange(0, seq.shape[1]).unsqueeze(0).repeat(seq.shape[0], 1).to(self.args.device)
        seq = (self.tok_embed(seq) * self.scale) + self.pos_encoding(pos)
        seq = seq.transpose(0, 1)
        out = self.transformer(seq, seq).transpose(0, 1)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ammesatyajit/videobert/commit/da701dd8f2ec37d38cc5c66982a1894cda0fef86#diff-bfbdfcab00b44379d0d84330903c598d633961fc4e68d6adc21c8b9cea49fc5aL154' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 96429563</div><div id='project'> Project Name: ammesatyajit/videobert</div><div id='commit'> Commit Name: da701dd8f2ec37d38cc5c66982a1894cda0fef86</div><div id='time'> Time: 2020-09-19</div><div id='author'> Author: ammesatyajit@gmail.com</div><div id='file'> File Name: VideoBERT/train/custom_vid_transformer.py</div><div id='m_class'> M Class Name: VideoTransformer</div><div id='n_method'> N Class Name: VideoTransformer</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: VideoBERT/train/custom_vid_transformer.py</div><div id='n_file'> N File Name: VideoBERT/train/custom_vid_transformer.py</div><div id='m_start'> M Start Line: 157</div><div id='m_end'> M End Line: 161</div><div id='n_start'> N Start Line: 156</div><div id='n_end'> N End Line: 159</div><BR>