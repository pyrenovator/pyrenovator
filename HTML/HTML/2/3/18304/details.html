<html><h3>Pattern ID :18304
</h3><img src='59977265.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    columns_ctx["categorical"]["base"] = cat_names

    &#47&#47 check sums for determinancy
    checksums = <a id="change">[]</a>
    for gdf in dataset.to_iter():
        new_gdf = hash_bucket_op.apply_op(gdf, columns_ctx, "categorical")
        assert np.all(new_gdf[cat_names].values &gt;= 0)
        assert np.all(new_gdf[cat_names].values &lt;= 9)
        <a id="change">checksums.append(</a>new_gdf[cat_names].sum().values<a id="change">)</a>

    for checksum, gdf in zip(checksums, dataset.to_iter()):
        new_gdf = hash_bucket_op.apply_op(gdf, columns_ctx, "categorical")
        assert np.all(new_gdf[cat_names].sum().values == checksum)</code></pre><h3>After Change</h3><pre><code class='java'>
    hash_features = cat_names &gt;&gt; ops.HashBucket(num_buckets)
    processor = nvt.Workflow(hash_features)
    processor.fit(dataset)
    new_gdf = <a id="change">processor.transform(dataset).to_ddf().compute()</a>

    &#47&#47 check sums for determinancy
    assert np.all(new_gdf[cat_names].values &gt;= 0)
    assert np.all(new_gdf[cat_names].values &lt;= 9)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/nvidia/nvtabular/commit/4c92dffac4354d816178264bcfcdec722db2ec1c#diff-e4d18001a1d407273320606db51ffe8ef20709522220cdc6e3cde2070f06b246L161' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59977265</div><div id='project'> Project Name: nvidia/nvtabular</div><div id='commit'> Commit Name: 4c92dffac4354d816178264bcfcdec722db2ec1c</div><div id='time'> Time: 2021-01-05</div><div id='author'> Author: github@benfrederickson.com</div><div id='file'> File Name: tests/unit/test_ops.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_hash_bucket(6)</div><div id='n_method'> N Method Name: test_hash_bucket(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/unit/test_ops.py</div><div id='n_file'> N File Name: tests/unit/test_ops.py</div><div id='m_start'> M Start Line: 331</div><div id='m_end'> M End Line: 355</div><div id='n_start'> N Start Line: 161</div><div id='n_end'> N End Line: 178</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        num_batches = 0
        current_epoch_losses = []
        current_epoch_reg_losses = <a id="change">[]</a>
        for inputs, targets in loader:
            &#47&#47 Run forward calculation
            predicted = self.model.forward(**inputs)

            &#47&#47 Compute loss.
            loss = self.loss_fn(predicted, targets)
            current_epoch_losses.append(loss.data.item())
            &#47&#47 Regularize.
            loss, reg_loss = self._add_batch_regualarizations(loss, reg_lambda_ar)
            <a id="change">current_epoch_reg_losses.append(</a>reg_loss.data.item()<a id="change">)</a>

            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()</code></pre><h3>After Change</h3><pre><code class='java'>

        self.scheduler.step()
        for metric in self.metrics: metric.compute(save=True)
        for metric in self.value_metrics.values(): <a id="change">metric.compute(save=True)</a>

    def _add_batch_regualarizations(self, loss, reg_lambda_ar):
        Add regulatization terms to loss, if applicable
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ourownstory/neural_prophet/commit/ea05689f7ccca059223f80c7bd85f8b7943e69d0#diff-2f9d256a00b87e584a2550e159cce3c51e4c971b3b1d4b4beb928d598e1f43a0L304' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59977281</div><div id='project'> Project Name: ourownstory/neural_prophet</div><div id='commit'> Commit Name: ea05689f7ccca059223f80c7bd85f8b7943e69d0</div><div id='time'> Time: 2020-06-16</div><div id='author'> Author: oskar.triebe@merantix.com</div><div id='file'> File Name: neuralprophet/neural_prophet.py</div><div id='m_class'> M Class Name: NeuralProphet</div><div id='n_method'> N Class Name: NeuralProphet</div><div id='m_method'> M Method Name: _train_epoch(3)</div><div id='n_method'> N Method Name: _train_epoch(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: neuralprophet/neural_prophet.py</div><div id='n_file'> N File Name: neuralprophet/neural_prophet.py</div><div id='m_start'> M Start Line: 322</div><div id='m_end'> M End Line: 345</div><div id='n_start'> N Start Line: 291</div><div id='n_end'> N End Line: 319</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    columns_ctx["categorical"]["base"] = list(cat_names)

    &#47&#47 check sums for determinancy
    checksums = <a id="change">[]</a>
    for gdf in dataset.to_iter():
        new_gdf = hashed_cross_op.apply_op(gdf, columns_ctx, "categorical")
        new_column_name = "_X_".join(cat_names)
        assert np.all(new_gdf[new_column_name].values &gt;= 0)
        assert np.all(new_gdf[new_column_name].values &lt;= 9)
        <a id="change">checksums.append(</a>new_gdf[new_column_name].sum()<a id="change">)</a>

    for checksum, gdf in zip(checksums, dataset.to_iter()):
        new_gdf = hashed_cross_op.apply_op(gdf, columns_ctx, "categorical")
        assert new_gdf[new_column_name].sum() == checksum</code></pre><h3>After Change</h3><pre><code class='java'>
    assert np.all(new_gdf[new_column_name].values &gt;= 0)
    assert np.all(new_gdf[new_column_name].values &lt;= 9)
    checksum = new_gdf[new_column_name].sum()
    new_gdf = <a id="change">processor.transform(dataset).to_ddf().compute()</a>
    assert new_gdf[new_column_name].sum() == checksum


@pytest.mark.parametrize("gpu_memory_frac", [0.01, 0.1])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nvidia/nvtabular/commit/4c92dffac4354d816178264bcfcdec722db2ec1c#diff-e4d18001a1d407273320606db51ffe8ef20709522220cdc6e3cde2070f06b246L1058' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59977273</div><div id='project'> Project Name: nvidia/nvtabular</div><div id='commit'> Commit Name: 4c92dffac4354d816178264bcfcdec722db2ec1c</div><div id='time'> Time: 2021-01-05</div><div id='author'> Author: github@benfrederickson.com</div><div id='file'> File Name: tests/unit/test_ops.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_hashed_cross(5)</div><div id='n_method'> N Method Name: test_hashed_cross(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/unit/test_ops.py</div><div id='n_file'> N File Name: tests/unit/test_ops.py</div><div id='m_start'> M Start Line: 1058</div><div id='m_end'> M End Line: 1085</div><div id='n_start'> N Start Line: 659</div><div id='n_end'> N End Line: 674</div><BR>