<html><h3>Pattern ID :37737
</h3><img src='108376517.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        reg_backbone = FeatureRegularization()
    elif args.regularization_type == &quotattention_feature_map&quot:
        if not os.path.exists(args.channel_weight):
            temporary_classifier = <a id="change">Classifier(backbone, num_classes).to(</a>device<a id="change">)</a>
            temporary_optimizer<a id="change"> = </a>SGD(temporary_classifier.get_parameters(args.lr), momentum=args.momentum, weight_decay=args.wd, nesterov=True)
            temporary_loader = DataLoader(train_dataset, batch_size=args.batch_size_channel_weight, shuffle=True, num_workers=args.workers, drop_last=False)
            temporary_scheduler = torch.optim.lr_scheduler.ExponentialLR(temporary_optimizer, gamma=math.exp(math.log(0.1) / args.lr_decay_epochs_channel_weight))
            criterion = nn.CrossEntropyLoss()</code></pre><h3>After Change</h3><pre><code class='java'>
        attention_file = os.path.join(logger.root, args.attention_file)
        if not os.path.exists(attention_file):
            attention = calculate_channel_attention(train_dataset, return_layers, args)
            <a id="change">torch.save(</a>attention, attention_file<a id="change">)</a>
        else:
            print("Loading channel attention from", attention_file)
            attention = torch.load(attention_file)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/ce38964ed6fc09262ae95c971acef5a616e106f1#diff-7cdf67761ea39e5e8f0139f0f91c8961a882bb4f95be3331d5cb6f9893799071L33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 108376517</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: ce38964ed6fc09262ae95c971acef5a616e106f1</div><div id='time'> Time: 2021-03-18</div><div id='author'> Author: 13126830206@163.com</div><div id='file'> File Name: examples-ft/classification/delta.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples-ft/classification/delta.py</div><div id='n_file'> N File Name: examples-ft/classification/delta.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 147</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 122</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            total_loss = 0
            for padded_text, lengths, labels in train_loader_poison:

                padded_text = <a id="change">padded_text.to(</a>device<a id="change">)</a>
                labels = labels.to(device)
                output = model(padded_text, lengths).squeeze()
                if data_selected == &quotag&quot:
                    loss = criterion(output, labels)
                else:
                    loss<a id="change"> = </a>criterion(output, labels.float())
                optimizer.zero_grad()
                loss.backward()
                clip_grad_norm_(model.parameters(), max_norm=1)</code></pre><h3>After Change</h3><pre><code class='java'>
    print(&quot*&quot * 89)
    print(&quotfinish all, success rate in test: {}, clean acc: {}&quot.format(poison_success_rate_test, clean_acc))
    if args.save_path != &quot&quot:
        <a id="change">torch.save(</a>model.module, args.save_path<a id="change">)</a>


if __name__ == &quot__main__&quot:
    train()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thunlp/hiddenkiller/commit/9a7b32039f64ade7ff805db0334c232d147b245d#diff-4d1f76a263b960b20f8bddb2fea7d7d157c96def80cca6e14e4783db514fab0cL102' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 108376519</div><div id='project'> Project Name: thunlp/hiddenkiller</div><div id='commit'> Commit Name: 9a7b32039f64ade7ff805db0334c232d147b245d</div><div id='time'> Time: 2021-09-24</div><div id='author'> Author: yangyichen6666@gmail.com</div><div id='file'> File Name: experiments/run_poison_lstm.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(0)</div><div id='n_method'> N Method Name: train(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: experiments/run_poison_lstm.py</div><div id='n_file'> N File Name: experiments/run_poison_lstm.py</div><div id='m_start'> M Start Line: 109</div><div id='m_end'> M End Line: 130</div><div id='n_start'> N Start Line: 108</div><div id='n_end'> N End Line: 141</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            total_loss = 0
            for padded_text, attention_masks, labels in train_loader_poison:
                padded_text = padded_text.to(device)
                attention_masks<a id="change"> = </a><a id="change">attention_masks.to(</a>device<a id="change">)</a>
                labels = labels.to(device)
                output = model(padded_text, attention_masks).squeeze()
                loss = criterion(output, labels)
                optimizer.zero_grad()</code></pre><h3>After Change</h3><pre><code class='java'>
    print(&quot*&quot * 89)
    print(&quotfinish all, attack success rate in test: {}, clean acc in test: {}&quot.format(poison_success_rate_test, clean_acc))
    if args.save_path != &quot&quot:
        <a id="change">torch.save(</a>model.module, args.save_path<a id="change">)</a>



def transfer_bert():</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thunlp/hiddenkiller/commit/2331b23dd09588c3330e5009870e2aaf2d983d04#diff-cd32ec43c987cdc2ea1951a94dc34eaf0cecfe536a71e4fde31134b08e4ad6e6L114' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 108376518</div><div id='project'> Project Name: thunlp/hiddenkiller</div><div id='commit'> Commit Name: 2331b23dd09588c3330e5009870e2aaf2d983d04</div><div id='time'> Time: 2021-09-23</div><div id='author'> Author: yangyichen6666@gmail.com</div><div id='file'> File Name: experiments/run_poison_bert.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(0)</div><div id='n_method'> N Method Name: train(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: experiments/run_poison_bert.py</div><div id='n_file'> N File Name: experiments/run_poison_bert.py</div><div id='m_start'> M Start Line: 115</div><div id='m_end'> M End Line: 154</div><div id='n_start'> N Start Line: 52</div><div id='n_end'> N End Line: 90</div><BR>