<html><h3>Pattern ID :17824
</h3><img src='58555759.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        x_masks = self._source_mask(ilens)
        hs, _ = self.encoder(xs, x_masks)

        d_masks = <a id="change">make_pad_mask(ilens).to(</a>xs.device<a id="change">)</a>
        if self.stop_gradient_from_pitch_predictor:
            p_outs = self.pitch_predictor(hs.detach(), d_masks.unsqueeze(-1))
        else:
            p_outs = self.pitch_predictor(hs, d_masks.unsqueeze(-1))</code></pre><h3>After Change</h3><pre><code class='java'>
        encoded_texts, _ = self.encoder(text_tensors, text_masks, utterance_embedding=utterance_embedding)  &#47&#47 (B, Tmax, adim)

        &#47&#47 forward duration predictor and variance predictors
        d_masks = <a id="change">make_pad_mask(</a>text_lens<a id="change">, device=text_lens.device)</a>

        if self.stop_gradient_from_pitch_predictor:
            pitch_predictions = self.pitch_predictor(encoded_texts.detach(), d_masks.unsqueeze(-1))
        else:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/30192b7e37d15dea00356e6bfda8808c46928f6b#diff-2034c4e39d404e1d246a9b80df1a67dbd70b4e05397a70b07d2ee3dcc526d7c3L138' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58555759</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 30192b7e37d15dea00356e6bfda8808c46928f6b</div><div id='time'> Time: 2022-01-11</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/InferenceArchitectures/InferenceFastSpeech2.py</div><div id='m_class'> M Class Name: FastSpeech2</div><div id='n_method'> N Class Name: FastSpeech2</div><div id='m_method'> M Method Name: _forward(11)</div><div id='n_method'> N Method Name: _forward(10)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module,ABC</div><div id='n_parent_class'> N Parent Class: torch.nn.Module,ABC</div><div id='m_file'> M File Name: InferenceInterfaces/InferenceArchitectures/InferenceFastSpeech2.py</div><div id='n_file'> N File Name: InferenceInterfaces/InferenceArchitectures/InferenceFastSpeech2.py</div><div id='m_start'> M Start Line: 155</div><div id='m_end'> M End Line: 175</div><div id='n_start'> N Start Line: 138</div><div id='n_end'> N End Line: 171</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        encoded_texts, _ = self.encoder(text_tensors, text_masks)  &#47&#47 (B, Tmax, adim)

        &#47&#47 forward duration predictor and variance predictors
        d_masks = <a id="change">make_pad_mask(text_lens).to(</a>text_tensors.device<a id="change">)</a>

        if self.stop_gradient_from_pitch_predictor:
            pitch_predictions = self.pitch_predictor(encoded_texts.detach(), d_masks.unsqueeze(-1))
        else:</code></pre><h3>After Change</h3><pre><code class='java'>
        encoded_texts, _ = self.encoder(text_tensors, text_masks)  &#47&#47 (B, Tmax, adim)

        &#47&#47 forward duration predictor and variance predictors
        d_masks = <a id="change">make_pad_mask(</a>text_lens<a id="change">, device=text_tensors.device)</a>

        if self.stop_gradient_from_pitch_predictor:
            pitch_predictions = self.pitch_predictor(encoded_texts.detach(), d_masks.unsqueeze(-1))
        else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/623d6b656b7f9dcdf6a75be596f91342c70d268b#diff-fc20234ea01b4d6bd4139e99f37d4600b67e7eb8e5cb517dd771c890b29f17efL220' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58555758</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 623d6b656b7f9dcdf6a75be596f91342c70d268b</div><div id='time'> Time: 2021-10-20</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeech2.py</div><div id='m_class'> M Class Name: FastSpeech2</div><div id='n_method'> N Class Name: FastSpeech2</div><div id='m_method'> M Method Name: _forward(10)</div><div id='n_method'> N Method Name: _forward(10)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module,ABC</div><div id='n_parent_class'> N Parent Class: torch.nn.Module,ABC</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeech2.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeech2.py</div><div id='m_start'> M Start Line: 228</div><div id='m_end'> M End Line: 228</div><div id='n_start'> N Start Line: 230</div><div id='n_end'> N End Line: 230</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        olens = speech_lengths

        &#47&#47 make labels for stop prediction
        labels = <a id="change">make_pad_mask(olens - 1).to(</a>ys.device, ys.dtype<a id="change">)</a>
        labels = F.pad(labels, [0, 1], "constant", 1.0)

        &#47&#47 calculate tacotron2 outputs
        after_outs, before_outs, logits, att_ws = self._forward(xs, ilens, ys, olens, speaker_embeddings)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 eos is [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

        &#47&#47 make labels for stop prediction
        labels = <a id="change">make_pad_mask(</a>speech_lengths - 1<a id="change">)</a>.to(speech.device, speech.dtype)
        labels = F.pad(labels, [0, 1], "constant", 1.0)

        &#47&#47 calculate tacotron2 outputs</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/24ca2ac33029f434e47969661b0a878773639ab8#diff-f8d05eb08ac38b212e3d3c6104a5e5618a8484d7eb2df04df282d6599e5473daL158' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58555761</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 24ca2ac33029f434e47969661b0a878773639ab8</div><div id='time'> Time: 2021-08-12</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/Tacotron2.py</div><div id='m_class'> M Class Name: Tacotron2</div><div id='n_method'> N Class Name: Tacotron2</div><div id='m_method'> M Method Name: forward(6)</div><div id='n_method'> N Method Name: forward(6)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/Tacotron2.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/Tacotron2.py</div><div id='m_start'> M Start Line: 179</div><div id='m_end'> M End Line: 208</div><div id='n_start'> N Start Line: 183</div><div id='n_end'> N End Line: 199</div><BR>