<html><h3>Pattern ID :34680
</h3><img src='99575631.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>


def main():
    conf = <a id="change">load_conf()[&quotversions&quot]</a>[&quot0&quot]
    device = load_device()
    bert_model = conf[&quotbert_model&quot]
    wisdoms = conf[&quotwisdoms&quot]</code></pre><h3>After Change</h3><pre><code class='java'>
    lefts = [left for left, _ in BATCH]
    rights = [right for _, right in BATCH]

    encoded = <a id="change">tokenizer(text=lefts,
                        text_pair=rights,
                        &#47&#47 return them as pytorch tensors
                        return_tensors="pt",
                        add_special_tokens=True,
                        &#47&#47 align the lengths by padding the short ones with [PAD] tokens.
                        truncation=True,
                        padding=True)</a>
    N, L = encoded[&quotinput_ids&quot].size()
    &#47&#47 30000이 무엇을 의미하는가? - 어휘의 크기/
    inputs = word_embeddings(encoded[&quotinput_ids&quot])  &#47&#47 (N, L) -&gt; (N, L, E=H)
    token_types<a id="change"> = </a>token_type_embeddings(encoded[&quottoken_type_ids&quot])  &#47&#47 (N, L) -&gt; (N, L, E=H)
    positions = position_embeddings(torch.arange(L).expand(N, L))
    fused = inputs + token_types + positions
    print(fused)  &#47&#47 이것이 bert의 입력으로 들어간다.</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/eubinecto/wisdomify/commit/5a03b27e6f81452ba455ffd3a19daabc799e91f9#diff-d0b0f2e910a08437939a98f9c38292bfe2c8a710de76c8d8032660c9a4563b8aL8' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 99575631</div><div id='project'> Project Name: eubinecto/wisdomify</div><div id='commit'> Commit Name: 5a03b27e6f81452ba455ffd3a19daabc799e91f9</div><div id='time'> Time: 2021-10-12</div><div id='author'> Author: eubinecto</div><div id='file'> File Name: wisdomify/examples/explore_bert_embeddings.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: wisdomify/examples/explore_bert_embeddings.py</div><div id='n_file'> N File Name: wisdomify/examples/explore_bert_embeddings.py</div><div id='m_start'> M Start Line: 8</div><div id='m_end'> M End Line: 26</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 55</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    input_tokens = tokenizer.tokenize(source)[:max_source_length]

    &#47&#47 2. tokenize output tokens
    output_tokens = <a id="change">tokenizer.tokenize(target)[:max_target_length]</a>

    &#47&#47 3. concat the inputs
    tokens = input_tokens + output_tokens
</code></pre><h3>After Change</h3><pre><code class='java'>
    )
    target_input_ids_len = (np.array(target_tokenized["input_ids"]) != tokenizer.pad_token_id).sum()

    source_tokenized<a id="change"> = </a><a id="change">tokenizer(
        </a>source<a id="change">,
        max_length=(max_source_length + max_target_length - target_input_ids_len),
        padding="max_length",
        truncation=True,
    )</a>

    input_ids = source_tokenized["input_ids"] + target_tokenized["input_ids"]
    labels = (len(input_ids) - target_input_ids_len) * [tokenizer.pad_token_id] + target_tokenized["input_ids"]
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/0d1cba43ca0eb4984715f3c807fde7345e80ca40#diff-9e01507f31a8cef3a50b864311e1088183748ed637f785df03a0d0dad8009454L57' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 99575625</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 0d1cba43ca0eb4984715f3c807fde7345e80ca40</div><div id='time'> Time: 2023-04-06</div><div id='author'> Author: fangzeyang0904@hotmail.com</div><div id='file'> File Name: examples/language_model/bloom/finetune_generation.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: convert_example(6)</div><div id='n_method'> N Method Name: convert_example(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/language_model/bloom/finetune_generation.py</div><div id='n_file'> N File Name: examples/language_model/bloom/finetune_generation.py</div><div id='m_start'> M Start Line: 68</div><div id='m_end'> M End Line: 105</div><div id='n_start'> N Start Line: 73</div><div id='n_end'> N End Line: 114</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for pipeline in pipelines:
            if pipeline.sequence_length &gt; current_seq_len:
                return pipeline
        return <a id="change">pipelines[-1]</a>

    @staticmethod
    def _get_current_sequence_length(input_schema):
        if isinstance(input_schema.inputs, str):</code></pre><h3>After Change</h3><pre><code class='java'>
        :return: The correct Pipeline object (or Bucket) to route input to
        
        tokenizer = pipelines[0].tokenizer
        tokens<a id="change"> = </a><a id="change">tokenizer(
            </a>input_schema.sequences<a id="change">,
            add_special_tokens=True,
            return_tensors="np",
            padding=False,
            truncation=False,
        )</a>
        input_seq_len = len(tokens)
        return TransformersPipeline.select_bucket_by_seq_len(input_seq_len, pipelines)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neuralmagic/deepsparse/commit/20f708e7d739d5395b74dcbdcca1e48811d4bda1#diff-34d1b69d4854619e33f49d324826752e0354b65434899ce3e161cbd5e5c841e4L300' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 99575637</div><div id='project'> Project Name: neuralmagic/deepsparse</div><div id='commit'> Commit Name: 20f708e7d739d5395b74dcbdcca1e48811d4bda1</div><div id='time'> Time: 2022-07-28</div><div id='author'> Author: rahul@neuralmagic.com</div><div id='file'> File Name: src/deepsparse/transformers/pipelines/text_classification.py</div><div id='m_class'> M Class Name: TextClassificationPipeline</div><div id='n_method'> N Class Name: TextClassificationPipeline</div><div id='m_method'> M Method Name: route_input_to_bucket(0)</div><div id='n_method'> N Method Name: route_input_to_bucket(0)</div><div id='m_parent_class'> M Parent Class: TransformersPipeline</div><div id='n_parent_class'> N Parent Class: TransformersPipeline</div><div id='m_file'> M File Name: src/deepsparse/transformers/pipelines/text_classification.py</div><div id='n_file'> N File Name: src/deepsparse/transformers/pipelines/text_classification.py</div><div id='m_start'> M Start Line: 308</div><div id='m_end'> M End Line: 315</div><div id='n_start'> N Start Line: 308</div><div id='n_end'> N End Line: 317</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for pipeline in pipelines:
            if pipeline.sequence_length &gt; current_seq_len:
                return pipeline
        return <a id="change">pipelines[-1]</a>

    &#47&#47 utilities below adapted from transformers

    def _gather_pre_entities(</code></pre><h3>After Change</h3><pre><code class='java'>
        :return: The correct Pipeline object (or Bucket) to route input to
        
        tokenizer = pipelines[0].tokenizer
        tokens = <a id="change">tokenizer(
            </a>input_schema.inputs<a id="change">,
            add_special_tokens=True,
            return_tensors="np",
            padding=False,
            truncation=False,
        )</a>
        input_seq_len<a id="change"> = </a>len(tokens)
        return TransformersPipeline.select_bucket_by_seq_len(input_seq_len, pipelines)

    &#47&#47 utilities below adapted from transformers</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neuralmagic/deepsparse/commit/20f708e7d739d5395b74dcbdcca1e48811d4bda1#diff-79e61bee1aadf04d6fd38371cf45def5472039227cde7f4e9bd194e76fe373bcL400' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 99575635</div><div id='project'> Project Name: neuralmagic/deepsparse</div><div id='commit'> Commit Name: 20f708e7d739d5395b74dcbdcca1e48811d4bda1</div><div id='time'> Time: 2022-07-28</div><div id='author'> Author: rahul@neuralmagic.com</div><div id='file'> File Name: src/deepsparse/transformers/pipelines/token_classification.py</div><div id='m_class'> M Class Name: TokenClassificationPipeline</div><div id='n_method'> N Class Name: TokenClassificationPipeline</div><div id='m_method'> M Method Name: route_input_to_bucket(0)</div><div id='n_method'> N Method Name: route_input_to_bucket(0)</div><div id='m_parent_class'> M Parent Class: TransformersPipeline</div><div id='n_parent_class'> N Parent Class: TransformersPipeline</div><div id='m_file'> M File Name: src/deepsparse/transformers/pipelines/token_classification.py</div><div id='n_file'> N File Name: src/deepsparse/transformers/pipelines/token_classification.py</div><div id='m_start'> M Start Line: 408</div><div id='m_end'> M End Line: 421</div><div id='n_start'> N Start Line: 408</div><div id='n_end'> N End Line: 417</div><BR>