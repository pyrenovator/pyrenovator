<html><h3>Pattern ID :18207
</h3><img src='59850737.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    for i in range(x.size(0)):
        mask = Masks.get_ff_mask(height, width)
        mask_all.append(mask)
    mask = <a id="change">torch.from_numpy(np.asarray(mask_all)).unsqueeze(1).float()</a>
    ones = torch.ones(x.size(0), 1, x.size(2), x.size(3))
    mask = ones * mask
    if x.is_cuda:
        mask = mask.cuda()</code></pre><h3>After Change</h3><pre><code class='java'>

    if config[&quotmask_type&quot] == &quothole&quot:
        result = x * (1. - mask)
    elif <a id="change"></a>config[&quotmask_type&quot] == &quotmosaic&quot:
        &#47&#47 TODO: Matching the mosaic patch size and the mask size
        mosaic_unit_size = config[&quotmosaic_unit_size&quot]
        downsampled_image = F.interpolate(x, scale_factor=1. / mosaic_unit_size, mode=&quotnearest&quot)
        upsampled_image = F.interpolate(downsampled_image, size=(height, width), mode=&quotnearest&quot)
        result = upsampled_image * mask + x * (1. - mask)
    else:
        <a id="change">raise </a>NotImplementedError(&quotNot implemented mask type.&quot)

    return result, mask</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/sayednadim/global-and-local-attention-based-free-form-image-inpainting/commit/aaa17ed332dc95db0f5900a43be179e26569b50c#diff-4a9d05cc3eadd7aa0b347854fe63c55a626198aae56f6d3482457196186e5d60L40' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59850737</div><div id='project'> Project Name: sayednadim/global-and-local-attention-based-free-form-image-inpainting</div><div id='commit'> Commit Name: aaa17ed332dc95db0f5900a43be179e26569b50c</div><div id='time'> Time: 2020-08-16</div><div id='author'> Author: smnadimuddin@gmail.com</div><div id='file'> File Name: model/mask.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mask_image(2)</div><div id='n_method'> N Method Name: mask_image(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model/mask.py</div><div id='n_file'> N File Name: model/mask.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 49</div><div id='n_start'> N Start Line: 56</div><div id='n_end'> N End Line: 72</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 this modification will not affect the minimum computation
        check_values(xs)
        xs = torch.where(torch.isnan(xs), 1., xs.double())
        out = torch.amin(<a id="change">xs.float()</a>, dim=dim, keepdim=keepdim)
        return out

</code></pre><h3>After Change</h3><pre><code class='java'>
            Raises when the &quotmask&quot is not boolean.
        
        if mask is not None:
            <a id="change">if </a>mask.shape != xs.shape:
                raise ValueError("&quotxs&quot and &quotmask&quot must have the same shape.")
            if not isinstance(mask, torch.BoolTensor):
                <a id="change">raise </a>ValueError("&quotmask&quot must be a torch.BoolTensor.")
            &#47&#47 here, we put 1 where the mask is not satisfied, since 1 is the maximum value for a truth value.
            &#47&#47 this is a way to exclude values from the minimum computation
            xs = torch.where(~mask, 1., xs.double())</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bmxitalia/ltntorch/commit/158a1091d2819aed893737d67a9b902afc5ac10e#diff-750caba7cb5811e224d2f3f344867f5b1c4695249e360c7ed91af683b1f63435L1240' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59850739</div><div id='project'> Project Name: bmxitalia/ltntorch</div><div id='commit'> Commit Name: 158a1091d2819aed893737d67a9b902afc5ac10e</div><div id='time'> Time: 2022-03-28</div><div id='author'> Author: tommasocarraro96@gmail.com</div><div id='file'> File Name: ltn/fuzzy_ops.py</div><div id='m_class'> M Class Name: AggregMin</div><div id='n_method'> N Class Name: AggregMin</div><div id='m_method'> M Method Name: __call__(5)</div><div id='n_method'> N Method Name: __call__(4)</div><div id='m_parent_class'> M Parent Class: AggregationOperator</div><div id='n_parent_class'> N Parent Class: AggregationOperator</div><div id='m_file'> M File Name: ltn/fuzzy_ops.py</div><div id='n_file'> N File Name: ltn/fuzzy_ops.py</div><div id='m_start'> M Start Line: 1273</div><div id='m_end'> M End Line: 1275</div><div id='n_start'> N Start Line: 1156</div><div id='n_end'> N End Line: 1194</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        torch.tensor
    
    &#47&#47
    return <a id="change">torch.from_numpy(img.transpose(2, 0, 1)).float()</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
    Returns:
        torch.tensor
    
    <a id="change">if </a>is_torch_available():
        import torch

        img = img.transpose((2, 0, 1))
        img = torch.from_numpy(img).float()
        if img.max() &gt; 1:
            img /= 255

        return img

    else:
        <a id="change">raise </a>ImportError("You need to install PyTorch to use this method.")


def torch_to_numpy(img):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/obss/sahi/commit/1666b4b318ac7bf2ce857a98e4528705ba1e802f#diff-61ab347af46649ae67bc93dd55bdc913b2a12b6ba0b026c3a5b7312c624c6ba3L10' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 59850744</div><div id='project'> Project Name: obss/sahi</div><div id='commit'> Commit Name: 1666b4b318ac7bf2ce857a98e4528705ba1e802f</div><div id='time'> Time: 2022-05-28</div><div id='author'> Author: 34196005+fcakyon@users.noreply.github.com</div><div id='file'> File Name: sahi/utils/torch.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: to_float_tensor(1)</div><div id='n_method'> N Method Name: to_float_tensor(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: sahi/utils/torch.py</div><div id='n_file'> N File Name: sahi/utils/torch.py</div><div id='m_start'> M Start Line: 21</div><div id='m_end'> M End Line: 21</div><div id='n_start'> N Start Line: 44</div><div id='n_end'> N End Line: 57</div><BR>