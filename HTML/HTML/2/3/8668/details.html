<html><h3>Pattern ID :8668
</h3><img src='30071498.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    test_loader = DataLoader(test_data, batch_size=1, shuffle=True, num_workers=4)

    i = 0
    loop = <a id="change">tqdm(</a>test_loader<a id="change">)</a>
    for batch_idx, frames in enumerate(loop):

        if i &gt;= 10: break
</code></pre><h3>After Change</h3><pre><code class='java'>
    with torch.no_grad():
        for i in tqdm(range(10)):

            frames = <a id="change">next(iter_loader).to(</a>DEVICE<a id="change">)</a>  &#47&#47 [1, T, 3, h, w]
            frames_vis = postprocess_img(frames.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
            input = frames[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 3, h, w]

            pred_rgb = pred_rgb_model.pred_n(input, pred_length=VIDEO_PRED_LENGTH)
            pred_rgb = torch.cat([input, pred_rgb], dim=1)  &#47&#47 [1, T, 3, h, w]
            pred_rgb_vis = postprocess_img(pred_rgb.squeeze(dim=0))  &#47&#47 [T, 3, h, w]

            pred_rgb = torch.stack([seg_model(pred_rgb[:, i]) for i in range(pred_rgb.shape[1])], dim=1)
            pred_rgb = pred_rgb.argmax(dim=2).squeeze()  &#47&#47 [T, h, w]
            pred_then_colorized_vis = colorize_semseg(postprocess_mask(pred_rgb), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2) &#47&#47 [T, 3, h, w]

            frames_seg = torch.stack([seg_model(frames[:, i]) for i in range(frames.shape[1])], dim=1).argmax(dim=2)  &#47&#47 [1, T, 1, h, w]
            frames_seg_in<a id="change"> = </a>torch.stack([(frames_seg == i) for i in range(SYNPICK_CLASSES)], dim=2).float()  &#47&#47 [1, T, c, h, w] one-hot float
            input_seg = frames_seg_in[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, c, h, w]
            pred_mask = pred_mask_model.pred_n(input_seg, pred_length=VIDEO_PRED_LENGTH).argmax(dim=2)  &#47&#47 [1, n, 1, h, w]
            pred_mask = torch.cat([input_seg.argmax(dim=2), pred_mask], dim=1).squeeze()  &#47&#47 [T, h, w]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ais-bonn/vp-suite/commit/13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3#diff-e07d70acfca9139cbf2c37b7a0074bdfbb966d41dc6c7edcc2cef05e78c00af0L16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 30071498</div><div id='project'> Project Name: ais-bonn/vp-suite</div><div id='commit'> Commit Name: 13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3</div><div id='time'> Time: 2021-08-02</div><div id='author'> Author: boltres@ais.uni-bonn.de</div><div id='file'> File Name: scripts/visualize_4_way.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: visualize_4_way(1)</div><div id='n_method'> N Method Name: visualize_4_way(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/visualize_4_way.py</div><div id='n_file'> N File Name: scripts/visualize_4_way.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 73</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 74</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    train_running_loss = 0.0
    loss_count = 0
    for index, (frames, caption) in enumerate(
            <a id="change">tqdm(</a>train_loader<a id="change">, desc="epoch:{}".format(epoch))</a>):
        optimizer.zero_grad()
        model.train()
</code></pre><h3>After Change</h3><pre><code class='java'>

    for src, tgt, src_padding_mask, tgt_padding_mask in tqdm(train_dataloader):
        src = src.to(device)
        tgt = <a id="change">tgt.to(</a>device<a id="change">)</a>
        tgt_padding_mask = tgt_padding_mask.to(device)[:, :-1]
        src_padding_mask = src_padding_mask.to(device)

        tgt_input = tgt[:, :-1]  &#47&#47 N T-1
        tgt_mask = generate_square_subsequent_mask(tgt_input.shape[1])

        logits<a id="change"> = </a>model(src, tgt_input,
                       tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask,
                       src_mask=None, src_padding_mask=src_padding_mask)  &#47&#47 N T-1 vocab_szie
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/kamino666/video-captioning-transformer/commit/6560c19b1b21061f61b9959ba32fbc20aa4d44a0#diff-ed183d67207df065a11e1289f19d34cc2abbc5448dea952683cfe9728c342b95L128' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 30071502</div><div id='project'> Project Name: kamino666/video-captioning-transformer</div><div id='commit'> Commit Name: 6560c19b1b21061f61b9959ba32fbc20aa4d44a0</div><div id='time'> Time: 2021-10-01</div><div id='author'> Author: 516015417@qq.com</div><div id='file'> File Name: train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train_epoch(3)</div><div id='n_method'> N Method Name: train_epoch(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train.py</div><div id='n_file'> N File Name: train.py</div><div id='m_start'> M Start Line: 128</div><div id='m_end'> M End Line: 151</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 79</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>


        &#47&#47 Compute anomaly map of normal images
        for i, (img, mask) in <a id="change">tqdm(</a>enumerate(self.test_normal_dataloader)<a id="change">)</a>:
            
            img.to(self.cfg.device)
            h, w, c = img.shape</code></pre><h3>After Change</h3><pre><code class='java'>
                for k in range(0, w-patch_size):

                    patch = img[:, :, j:j+patch_size, k:k+patch_size]
                    patch<a id="change"> = </a><a id="change">patch.to(</a>self.cfg.device<a id="change">)</a>
                    surrogate_label, pred = self.school(patch)
                    loss = self.criterion(pred, surrogate_label)
                    anomaly_map[j:j+patch_size, k:k+patch_size] = loss.item()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/taikiinoue/stad/commit/fa86afcb446f6f9853f81d36632e9b83d767e1f9#diff-b29b28f1ad780fa199366aab98611397f2d066c70a058eb15b54f8cf0455871dL133' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 30071487</div><div id='project'> Project Name: taikiinoue/stad</div><div id='commit'> Commit Name: fa86afcb446f6f9853f81d36632e9b83d767e1f9</div><div id='time'> Time: 2020-07-07</div><div id='author'> Author: taikiinoue45@gmail.com</div><div id='file'> File Name: stad/trainer/trainer.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: run_inference(1)</div><div id='n_method'> N Method Name: run_inference(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: stad/trainer/trainer.py</div><div id='n_file'> N File Name: stad/trainer/trainer.py</div><div id='m_start'> M Start Line: 141</div><div id='m_end'> M End Line: 179</div><div id='n_start'> N Start Line: 140</div><div id='n_end'> N End Line: 184</div><BR>