<html><h3>Pattern ID :25640
</h3><img src='77897188.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                arg = getattr(args, path)
                if arg is not None:
                    assert arg.exists() is True and arg.is_file() is True
                    <a id="change">setattr(</a>args, path, str(arg.absolute())<a id="change">)</a>

        config = parser.convert_args_to_config(args)

        return config</code></pre><h3>After Change</h3><pre><code class='java'>
    @classmethod
    def parse_args_config(cls, parser, args):
        if parser._inited:
            cname<a id="change"> = </a>"config_filepath"
            &#47&#47 arg: a list of pathlib.Path
            cpaths = getattr(args, cname)
            if cpaths is not None:
                <a id="change">for </a>path in cpaths<a id="change">:
                    </a>assert path.exists() is True and path.is_file() is True
                setattr(args, cname, [str(path.absolute()) for path in cpaths])

        config = parser.convert_args_to_config(args)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/spico197/rex/commit/d89f3ca2f5c2d87e8a4cfbcbf34b82ba08b52c78#diff-2382e7de4755221f6ff1d5a3ff68834d7b277846e904fea3689ef92c857df5f4L82' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 77897188</div><div id='project'> Project Name: spico197/rex</div><div id='commit'> Commit Name: d89f3ca2f5c2d87e8a4cfbcbf34b82ba08b52c78</div><div id='time'> Time: 2022-12-27</div><div id='author'> Author: tzhu1997@outlook.com</div><div id='file'> File Name: rex/utils/config.py</div><div id='m_class'> M Class Name: ConfigParser</div><div id='n_method'> N Class Name: ConfigParser</div><div id='m_method'> M Method Name: parse_args_config(3)</div><div id='n_method'> N Method Name: parse_args_config(3)</div><div id='m_parent_class'> M Parent Class: argparse.ArgumentParser</div><div id='n_parent_class'> N Parent Class: argparse.ArgumentParser</div><div id='m_file'> M File Name: rex/utils/config.py</div><div id='n_file'> N File Name: rex/utils/config.py</div><div id='m_start'> M Start Line: 87</div><div id='m_end'> M End Line: 94</div><div id='n_start'> N Start Line: 82</div><div id='n_end'> N End Line: 90</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                **kwargs
            )

            <a id="change">setattr(</a>self, f&quotoptim{ind}&quot, optimizer<a id="change">)</a> &#47&#47 cannot use pytorch ModuleList for some reason with optimizers

            if self.use_ema:
                self.ema_unets.append(EMA(unet, **ema_kwargs))</code></pre><h3>After Change</h3><pre><code class='java'>

        lr, wd, eps = map(partial(cast_tuple, length = self.num_unets), (lr, wd, eps))

        optimizers<a id="change"> = </a>[]

        for unet, unet_lr, unet_wd, unet_eps in zip(decoder.unets, lr, wd, eps):
            optimizer = get_optimizer(
                unet.parameters(),
                lr = unet_lr,
                wd = unet_wd,
                eps = unet_eps,
                group_wd_params = group_wd_params,
                **kwargs
            )

            optimizers.append(optimizer)

            if self.use_ema:
                self.ema_unets.append(EMA(unet, **ema_kwargs))

        &#47&#47 gradient clipping if needed

        self.max_grad_norm = max_grad_norm

        self.register_buffer(&quotstep&quot, torch.tensor([0.]))
        results = list(self.accelerator.prepare(decoder, *optimizers))
        self.decoder = results.pop(0)
        <a id="change">for </a>opt_ind in range(len(optimizers))<a id="change">:
            </a>setattr(self, f&quotoptim{opt_ind}&quot, results.pop(0))

    def save(self, path, overwrite = True, **kwargs):
        path = Path(path)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/58892135d9bcf117921c885dda161c0b67452096#diff-617450527162fa367141dbf45e8b201673573479820af0ffc56ba93b7f70947fL575' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 77897174</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: 58892135d9bcf117921c885dda161c0b67452096</div><div id='time'> Time: 2022-06-19</div><div id='author'> Author: aidan.dempster@gmail.com</div><div id='file'> File Name: dalle2_pytorch/trainer.py</div><div id='m_class'> M Class Name: DecoderTrainer</div><div id='n_method'> N Class Name: DecoderTrainer</div><div id='m_method'> M Method Name: __init__(10)</div><div id='n_method'> N Method Name: __init__(9)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dalle2_pytorch/trainer.py</div><div id='n_file'> N File Name: dalle2_pytorch/trainer.py</div><div id='m_start'> M Start Line: 591</div><div id='m_end'> M End Line: 620</div><div id='n_start'> N Start Line: 577</div><div id='n_end'> N End Line: 633</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    _schema[field_name]
                ).merge_doc(other)
                field = doc.to_field()
                <a id="change">setattr(</a>cls, field_name, _schema[field_name]<a id="change">)</a>
                cls._declare_field(field, field_name)
                dataset_field_docs = cls._dataset_doc()[cls._fields_attr()]
                docs = dataset_field_docs
</code></pre><h3>After Change</h3><pre><code class='java'>

        dataset_field_docs = cls._dataset_doc()[cls._fields_attr()]
        parent_docs = dataset_field_docs
        docs<a id="change"> = </a>parent_docs

        for k in keys:
            for f in docs:
                if k == f.name:
                    docs = f.fields
                    break

        updated_docs = {doc.name: doc for doc in docs}
        for doc in new_docs:
            updated_docs[doc.name] = doc

        if not keys:
            cls._dataset_doc()[cls._fields_attr()] = list(
                updated_docs.values()
            )
        else:
            docs = parent_docs
            for k in keys:
                <a id="change">for </a>f in docs<a id="change">:
                    </a>if k == f.name:
                        field = f
                        docs = field.fields
                        break</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/voxel51/fiftyone/commit/e9fbeb57e709499a6d69bd4c54fa77e5e8b1a852#diff-b4e92a2491c17c73053ef81d1f4550849068f80a672bdb4c89ec7fa52439f7b0L257' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 77897184</div><div id='project'> Project Name: voxel51/fiftyone</div><div id='commit'> Commit Name: e9fbeb57e709499a6d69bd4c54fa77e5e8b1a852</div><div id='time'> Time: 2022-04-04</div><div id='author'> Author: ben@voxel51.com</div><div id='file'> File Name: fiftyone/core/odm/mixins.py</div><div id='m_class'> M Class Name: DatasetMixin</div><div id='n_method'> N Class Name: DatasetMixin</div><div id='m_method'> M Method Name: merge_field_schema(4)</div><div id='n_method'> N Method Name: merge_field_schema(4)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: fiftyone/core/odm/mixins.py</div><div id='n_file'> N File Name: fiftyone/core/odm/mixins.py</div><div id='m_start'> M Start Line: 278</div><div id='m_end'> M End Line: 320</div><div id='n_start'> N Start Line: 280</div><div id='n_end'> N End Line: 327</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    self._env,
                    self.device,
                )
                <a id="change">setattr(</a>module, name, sharded_child<a id="change">)</a>
                if isinstance(sharded_child, FusedOptimizerModule):
                    fused_optims.append((curr_path, sharded_child.fused_optimizer))
            else:
                self._shard_modules_impl(</code></pre><h3>After Change</h3><pre><code class='java'>
            )
            if path:
                leaf_module = self._dmp_wrapped_module
                split_path<a id="change"> = </a>path.split(".")
                <a id="change">for </a>name in split_path[:-1]<a id="change">:
                    </a>leaf_module = getattr(leaf_module, name)
                setattr(leaf_module, split_path[-1], sharded_module)
            else:
                self._dmp_wrapped_module = sharded_module</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/facebookresearch/torchrec/commit/b72ed51545d0682547e903f4a921f8d3082ef888#diff-088378575010e7b9e27ea06507ba52fcc8604bcf9cb107f4939a9a49b0d52c89L303' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 77897162</div><div id='project'> Project Name: facebookresearch/torchrec</div><div id='commit'> Commit Name: b72ed51545d0682547e903f4a921f8d3082ef888</div><div id='time'> Time: 2022-03-12</div><div id='author'> Author: jasonjk@fb.com</div><div id='file'> File Name: torchrec/distributed/model_parallel.py</div><div id='m_class'> M Class Name: DistributedModelParallel</div><div id='n_method'> N Class Name: DistributedModelParallel</div><div id='m_method'> M Method Name: _shard_modules_impl(4)</div><div id='n_method'> N Method Name: _shard_modules_impl(4)</div><div id='m_parent_class'> M Parent Class: FusedOptimizerModule,nn.Module</div><div id='n_parent_class'> N Parent Class: FusedOptimizerModule,nn.Module</div><div id='m_file'> M File Name: torchrec/distributed/model_parallel.py</div><div id='n_file'> N File Name: torchrec/distributed/model_parallel.py</div><div id='m_start'> M Start Line: 309</div><div id='m_end'> M End Line: 330</div><div id='n_start'> N Start Line: 309</div><div id='n_end'> N End Line: 336</div><BR>