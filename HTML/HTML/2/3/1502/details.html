<html><h3>Pattern ID :1502
</h3><img src='6797380.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            n_channels = smap.shape[0]
            kernel = torch.tensor([[0., 1., 0.],
                                    [1., -4., 1.],
                                    <a id="change">[</a>0., 1., 0.<a id="change"></a>]])
            kernel = kernel.view(1, 1, 3, 3).repeat(1, n_channels, 1, 1)
            smooth_feat = torch.sum(torch.abs(F.conv2d(smap, kernel)))
</code></pre><h3>After Change</h3><pre><code class='java'>

    def cal_explanation_feature(self, saliency_maps: torch.Tensor) -&gt; float:
        sparse_feats = saliency_maps.flatten(start_dim=1).norm(p=1)    &#47&#47 (N)
        smooth_feats = <a id="change">self.conv2d(</a>saliency_maps<a id="change">)</a>.flatten(start_dim=1).norm(p=1)    &#47&#47 (N)
        persist_feats = 0.0  &#47&#47 todo (N)

        exp_feats<a id="change"> = </a>self.lambd_sp * sparse_feats + self.lambd_sm * smooth_feats + self.lambd_pe * persist_feats
        return exp_feats.median()
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ain-soph/trojanzoo/commit/afe7bbd2d2e9f901ee8cf56c3b9320b9272a81af#diff-5528b4636bddd4d9ccc9486227970324e4344e01059ddca8b9863336ce85d70cL68' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6797380</div><div id='project'> Project Name: ain-soph/trojanzoo</div><div id='commit'> Commit Name: afe7bbd2d2e9f901ee8cf56c3b9320b9272a81af</div><div id='time'> Time: 2020-07-22</div><div id='author'> Author: ain-soph@live.com</div><div id='file'> File Name: trojanzoo/defense/backdoor/neuron_inspect.py</div><div id='m_class'> M Class Name: Neuron_Inspect</div><div id='n_method'> N Class Name: Neuron_Inspect</div><div id='m_method'> M Method Name: cal_explanation_feature(2)</div><div id='n_method'> N Method Name: cal_explanation_feature(2)</div><div id='m_parent_class'> M Parent Class: Defense_Backdoor</div><div id='n_parent_class'> N Parent Class: Defense_Backdoor</div><div id='m_file'> M File Name: trojanzoo/defense/backdoor/neuron_inspect.py</div><div id='n_file'> N File Name: trojanzoo/defense/backdoor/neuron_inspect.py</div><div id='m_start'> M Start Line: 68</div><div id='m_end'> M End Line: 84</div><div id='n_start'> N Start Line: 68</div><div id='n_end'> N End Line: 73</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            self.integrate_model(working_image, self.integrate_window(working_image, "center"), self.integrate_recursion_depth)
            &#47&#47 Convolve the PSF
            LL = _shift_Lanczos_kernel_torch(-center_shift[0]/working_image.pixelscale, -center_shift[1]/working_image.pixelscale, 10, AP_config.ap_dtype, AP_config.ap_device)
            working_image.data = fft_convolve_multi_torch(working_image.data, <a id="change">[</a>self.target.psf, LL<a id="change"></a>], img_prepadded = True) &#47&#47fft_convolve_torch(working_image.data, self.target.psf, img_prepadded = True)
            &#47&#47 Shift image back to align with original pixel grid
            working_image.window.shift_origin(-center_shift)
            &#47&#47 Add the sampled/integrated/convolved pixels to the requested image</code></pre><h3>After Change</h3><pre><code class='java'>
            self.integrate_model(working_image, self.integrate_window(working_image, "center"), self.integrate_recursion_depth)
            &#47&#47 Convolve the PSF
            LL = _shift_Lanczos_kernel_torch(-center_shift[0]/working_image.pixelscale, -center_shift[1]/working_image.pixelscale, 3, AP_config.ap_dtype, AP_config.ap_device)
            shift_psf<a id="change"> = </a><a id="change">torch.nn.functional.conv2d(</a>self.target.psf.view(1,1,*self.target.psf.shape), LL.view(1,1,*LL.shape)<a id="change">, padding = "same")</a>[0][0]
            working_image.data = fft_convolve_torch(working_image.data, shift_psf/torch.sum(shift_psf), img_prepadded = True)
            &#47&#47 Shift image back to align with original pixel grid
            working_image.window.shift_origin(-center_shift)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/connorstoneastro/autoprof/commit/a0ad8000781a5d54daec1ff2d1051f727c29dd36#diff-f06fdcf833023ba6b66916fb365b98f3ce65835dad56f16831c389160cc0653bL138' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6797396</div><div id='project'> Project Name: connorstoneastro/autoprof</div><div id='commit'> Commit Name: a0ad8000781a5d54daec1ff2d1051f727c29dd36</div><div id='time'> Time: 2023-01-11</div><div id='author'> Author: connorstone628@gmail.com</div><div id='file'> File Name: build/lib/autoprof/models/model_object.py</div><div id='m_class'> M Class Name: BaseModel</div><div id='n_method'> N Class Name: BaseModel</div><div id='m_method'> M Method Name: sample(3)</div><div id='n_method'> N Method Name: sample(3)</div><div id='m_parent_class'> M Parent Class: AutoProf_Model</div><div id='n_parent_class'> N Parent Class: AutoProf_Model</div><div id='m_file'> M File Name: build/lib/autoprof/models/model_object.py</div><div id='n_file'> N File Name: build/lib/autoprof/models/model_object.py</div><div id='m_start'> M Start Line: 168</div><div id='m_end'> M End Line: 178</div><div id='n_start'> N Start Line: 168</div><div id='n_end'> N End Line: 179</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            self.integrate_model(working_image, self.integrate_window(working_image, "center"), self.integrate_recursion_depth)
            &#47&#47 Convolve the PSF
            LL = _shift_Lanczos_kernel_torch(-center_shift[0]/working_image.pixelscale, -center_shift[1]/working_image.pixelscale, 10, AP_config.ap_dtype, AP_config.ap_device)
            working_image.data = fft_convolve_multi_torch(working_image.data, <a id="change">[</a>self.target.psf, LL<a id="change"></a>], img_prepadded = True) &#47&#47fft_convolve_torch(working_image.data, self.target.psf, img_prepadded = True)
            &#47&#47 Shift image back to align with original pixel grid
            working_image.window.shift_origin(-center_shift)
            &#47&#47 Add the sampled/integrated/convolved pixels to the requested image</code></pre><h3>After Change</h3><pre><code class='java'>
            self.integrate_model(working_image, self.integrate_window(working_image, "center"), self.integrate_recursion_depth)
            &#47&#47 Convolve the PSF
            LL = _shift_Lanczos_kernel_torch(-center_shift[0]/working_image.pixelscale, -center_shift[1]/working_image.pixelscale, 3, AP_config.ap_dtype, AP_config.ap_device)
            shift_psf<a id="change"> = </a><a id="change">torch.nn.functional.conv2d(</a>self.target.psf.view(1,1,*self.target.psf.shape), LL.view(1,1,*LL.shape)<a id="change">, padding = "same")</a>[0][0]
            working_image.data = fft_convolve_torch(working_image.data, shift_psf/torch.sum(shift_psf), img_prepadded = True)
            &#47&#47 Shift image back to align with original pixel grid
            working_image.window.shift_origin(-center_shift)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/connorstoneastro/autoprof/commit/c470a85d1d5174a01e42cea82ad90447d70035d5#diff-f48e7e4f4617c56a91cecf87400e1b8c67ec5491c53dceae61328526ff99ebfeL138' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6797395</div><div id='project'> Project Name: connorstoneastro/autoprof</div><div id='commit'> Commit Name: c470a85d1d5174a01e42cea82ad90447d70035d5</div><div id='time'> Time: 2023-01-11</div><div id='author'> Author: connorstone628@gmail.com</div><div id='file'> File Name: autoprof/models/model_object.py</div><div id='m_class'> M Class Name: BaseModel</div><div id='n_method'> N Class Name: BaseModel</div><div id='m_method'> M Method Name: sample(3)</div><div id='n_method'> N Method Name: sample(3)</div><div id='m_parent_class'> M Parent Class: AutoProf_Model</div><div id='n_parent_class'> N Parent Class: AutoProf_Model</div><div id='m_file'> M File Name: autoprof/models/model_object.py</div><div id='n_file'> N File Name: autoprof/models/model_object.py</div><div id='m_start'> M Start Line: 171</div><div id='m_end'> M End Line: 178</div><div id='n_start'> N Start Line: 171</div><div id='n_end'> N End Line: 179</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        batch_list = {
            &quotk4e&quot: [],
            &quotv4e&quot: [],
            &quotr3e&quot: <a id="change">[]</a>,
            &quotr2e&quot: [],
            &quotkey&quot: [],
            &quotvalue&quot: [],</code></pre><h3>After Change</h3><pre><code class='java'>

            _r4t, _, _, _, _ = self.encoder_query(target_objects[i])
            &#47&#47 print(_r4t.shape)    &#47&#47 torch.Size([n_objects, 1024, 7, 7])
            _correlation_r4<a id="change"> = </a><a id="change">F.conv2d(</a>r4[i].unsqueeze(dim=0), _r4t<a id="change">, padding=3)</a>.permute(1, 0, 2, 3)
            &#47&#47 print(_correlation_r4.shape) &#47&#47 torch.Size([n_objects, 1, 30, 57])
            k4, v4 = self.kv_query(torch.cat([_r4e, _correlation_r4], dim=1))
            &#47&#47 print(k4.shape)   &#47&#47 torch.Size([n_objects, 128, 30, 57])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hzxie/rmnet/commit/69815437b1b170901900d8efd3933ae5b815c928#diff-086109d7d67f119dd8c55e6ca645e7f71af66a013cd5dbfe1c453292f58a01bfL278' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6797389</div><div id='project'> Project Name: hzxie/rmnet</div><div id='commit'> Commit Name: 69815437b1b170901900d8efd3933ae5b815c928</div><div id='time'> Time: 2020-04-28</div><div id='author'> Author: root@haozhexie.com</div><div id='file'> File Name: models/stm.py</div><div id='m_class'> M Class Name: STM</div><div id='n_method'> N Class Name: STM</div><div id='m_method'> M Method Name: segment(6)</div><div id='n_method'> N Method Name: segment(5)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: models/stm.py</div><div id='n_file'> N File Name: models/stm.py</div><div id='m_start'> M Start Line: 288</div><div id='m_end'> M End Line: 312</div><div id='n_start'> N Start Line: 278</div><div id='n_end'> N End Line: 317</div><BR>