<html><h3>Pattern ID :22054
</h3><img src='69877594.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            attn_mask.append(encodings_dict[&quotattention_mask&quot])
        max_length = max([len(idx) for idx in text_idx])
        text_idx = [idx + [self.padding_token_idx] * (max_length - len(idx)) for idx in text_idx]
        attn_mask<a id="change"> = </a>[mask + <a id="change">[</a>0<a id="change"></a>] * (max_length - len(mask)) for mask in attn_mask]
        text_idx = torch.LongTensor(text_idx).to(self.device)
        attn_mask = torch.LongTensor(attn_mask).to(self.device)
</code></pre><h3>After Change</h3><pre><code class='java'>
        attn_masks = []
        for text in text_sequence:
            sentence = &quot &quot.join([self.sos_token] + text + [self.eos_token])
            encoding_dict = <a id="change">self.tokenizer(</a>sentence<a id="change">,
                                           max_length=self.max_seq_length,
                                           padding="max_length",
                                           truncation=True,
                                           return_tensors="pt")</a>
            input_ids.append(encoding_dict[&quotinput_ids&quot])
            attn_masks.append(encoding_dict[&quotattention_mask&quot])
        input_ids = torch.cat(input_ids, dim=0).to(self.device)
        attn_masks = torch.cat(attn_masks, dim=0).to(self.device)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/9c7994602989cced6709bf6ec43a092f69a1d6cd#diff-da9020b7921d1fba6b2fab2060235123581b65e72d8336411bd2530895ce313fL67' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69877594</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 9c7994602989cced6709bf6ec43a092f69a1d6cd</div><div id='time'> Time: 2020-12-08</div><div id='author'> Author: lijunyi@ruc.edu.cn</div><div id='file'> File Name: textbox/model/LM/gpt2.py</div><div id='m_class'> M Class Name: GPT2</div><div id='n_method'> N Class Name: GPT2</div><div id='m_method'> M Method Name: calculate_loss(3)</div><div id='n_method'> N Method Name: calculate_loss(3)</div><div id='m_parent_class'> M Parent Class: UnconditionalGenerator</div><div id='n_parent_class'> N Parent Class: UnconditionalGenerator</div><div id='m_file'> M File Name: textbox/model/LM/gpt2.py</div><div id='n_file'> N File Name: textbox/model/LM/gpt2.py</div><div id='m_start'> M Start Line: 67</div><div id='m_end'> M End Line: 91</div><div id='n_start'> N Start Line: 72</div><div id='n_end'> N End Line: 95</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            attn_mask.append(encodings_dict[&quotattention_mask&quot])
        max_length = max([len(idx) for idx in text_idx])
        text_idx = [idx + [self.padding_token_idx] * (max_length - len(idx)) for idx in text_idx]
        attn_mask<a id="change"> = </a>[mask + <a id="change">[</a>0<a id="change"></a>] * (max_length - len(mask)) for mask in attn_mask]
        text_idx = torch.LongTensor(text_idx).to(self.device)
        attn_mask = torch.LongTensor(attn_mask).to(self.device)
</code></pre><h3>After Change</h3><pre><code class='java'>
        attn_masks = []
        for text in text_sequence:
            sentence = &quot &quot.join([self.sos_token] + text + [self.eos_token])
            encodings_dict = <a id="change">self.tokenizer(</a>sentence<a id="change">,
                                            max_length=self.max_seq_length,
                                            padding="max_length",
                                            truncation=True,
                                            return_tensors="pt")</a>
            input_ids.append(encodings_dict[&quotinput_ids&quot])
            attn_masks.append(encodings_dict[&quotattention_mask&quot])
        input_ids = torch.cat(input_ids, dim=0).to(self.device)
        attn_masks = torch.cat(attn_masks, dim=0).to(self.device)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/9c7994602989cced6709bf6ec43a092f69a1d6cd#diff-da9020b7921d1fba6b2fab2060235123581b65e72d8336411bd2530895ce313fL95' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69877592</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 9c7994602989cced6709bf6ec43a092f69a1d6cd</div><div id='time'> Time: 2020-12-08</div><div id='author'> Author: lijunyi@ruc.edu.cn</div><div id='file'> File Name: textbox/model/LM/gpt2.py</div><div id='m_class'> M Class Name: GPT2</div><div id='n_method'> N Class Name: GPT2</div><div id='m_method'> M Method Name: calculate_nll_test(3)</div><div id='n_method'> N Method Name: calculate_nll_test(3)</div><div id='m_parent_class'> M Parent Class: UnconditionalGenerator</div><div id='n_parent_class'> N Parent Class: UnconditionalGenerator</div><div id='m_file'> M File Name: textbox/model/LM/gpt2.py</div><div id='n_file'> N File Name: textbox/model/LM/gpt2.py</div><div id='m_start'> M Start Line: 97</div><div id='m_end'> M End Line: 118</div><div id='n_start'> N Start Line: 104</div><div id='n_end'> N End Line: 124</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.converter = MusicConverter()

    def __call__(self, mode: str, to_score: bool = False):
        modes<a id="change"> = </a><a id="change">[</a>&quotconditional&quot, &quotunconditional-greedy&quot, &quotunconditional-topk&quot<a id="change"></a>]
        assert mode in modes, f&quotInvalid mode: expect one of {logi(modes)}, got ({logi(mode)})&quot

        &#47&#47 ic(tokenizer, tokenizer.pad_token_id, tokenizer.eos_token_id)</code></pre><h3>After Change</h3><pre><code class='java'>
            assert prompt is not None or path is not None, f&quotExpect either {logi("prompt")} or {logi("path")}&quot
            if prompt is None:
                prompt = self.converter.mxl2str(path)
            inputs = <a id="change">self.tokenizer(</a>prompt<a id="change">, return_tensors=&quotpt&quot)</a>
            outputs = self.model.generate(
                **inputs, max_length=self.max_len
            )
        ic(outputs.shape)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stefanheng/symbolic-music-generation/commit/270b454271f507d9144a8de7bac33f6ca7c46722#diff-4cf244d223799c9afa01462f39ee7bfadbee5ce5f29520f673bc480cb9f17ec0L30' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69877598</div><div id='project'> Project Name: stefanheng/symbolic-music-generation</div><div id='commit'> Commit Name: 270b454271f507d9144a8de7bac33f6ca7c46722</div><div id='time'> Time: 2022-04-02</div><div id='author'> Author: 43276957+SpongeBobBang@users.noreply.github.com</div><div id='file'> File Name: musicnlp/models/evaluate.py</div><div id='m_class'> M Class Name: MusicGenerator</div><div id='n_method'> N Class Name: MusicGenerator</div><div id='m_method'> M Method Name: __call__(4)</div><div id='n_method'> N Method Name: __call__(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: musicnlp/models/evaluate.py</div><div id='n_file'> N File Name: musicnlp/models/evaluate.py</div><div id='m_start'> M Start Line: 31</div><div id='m_end'> M End Line: 58</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 69</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def preprocess(self, input_text):
        inputs = self.tokenizer(input_text)
        inputs = left_padding(inputs, self.tokenizer.pad_token_id)
        input_map<a id="change"> = </a><a id="change">{
            </a>"input_ids": np.array(inputs["input_ids"], dtype="int64")<a id="change">,
        }</a>
        return input_map

    def infer(self, input_map):
        results = self.model(paddle.to_tensor(input_map["input_ids"]))</code></pre><h3>After Change</h3><pre><code class='java'>
        self.model.eval()

    def preprocess(self, input_text):
        inputs = <a id="change">self.tokenizer(
            </a>input_text<a id="change">,
            return_tensors="np",
            padding=True,
            max_length="max_length",
            return_attention_mask=False,
            return_token_type_ids=False,
        )</a>
        inputs_tensor = {}
        for key, value in inputs.items():
            inputs_tensor[key] = paddle.to_tensor(value)
        return inputs_tensor</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/cd9b90e2339a664617b607015d8735e0d430dce2#diff-cd00f80dd03a3ed842ea7cf92f601c94c438d3f675d298a31bbb01f65f418ab8L96' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69877596</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: cd9b90e2339a664617b607015d8735e0d430dce2</div><div id='time'> Time: 2023-03-29</div><div id='author'> Author: 1435130236@qq.com</div><div id='file'> File Name: examples/language_model/bloom/predict_generation.py</div><div id='m_class'> M Class Name: Predictor</div><div id='n_method'> N Class Name: Predictor</div><div id='m_method'> M Method Name: preprocess(2)</div><div id='n_method'> N Method Name: preprocess(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: examples/language_model/bloom/predict_generation.py</div><div id='n_file'> N File Name: examples/language_model/bloom/predict_generation.py</div><div id='m_start'> M Start Line: 97</div><div id='m_end'> M End Line: 101</div><div id='n_start'> N Start Line: 55</div><div id='n_end'> N End Line: 66</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)

        &#47&#47 Convert inputs to PyTorch tensors
        preprocessed_sentence<a id="change"> = </a>torch.tensor(<a id="change">[</a>indexed_tokens<a id="change"></a>]).to(self.device)

        return preprocessed_sentence
</code></pre><h3>After Change</h3><pre><code class='java'>
        https://huggingface.co/transformers/model_doc/bert.html&#47&#47transformers.BertTokenizer

        
        encoding = <a id="change">self.tokenizer(</a>raw_sentence<a id="change">,
                                  pad_to_max_length=True,
                                  return_tensors=&quotpt&quot
                                  )</a>
        return encoding

    def preprocess_many(self, raw_sentences):
        Preprocess multiple sentences - tokenization and determining of token ids.</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bluebrain/search/commit/6eb30c8b3e77791ee4e407dd19d7a5e08fe5e132#diff-6a370a606e89902d9cea7c7edf876b91c643d1c115291d5912b04e3bd88cf446L80' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69877601</div><div id='project'> Project Name: bluebrain/search</div><div id='commit'> Commit Name: 6eb30c8b3e77791ee4e407dd19d7a5e08fe5e132</div><div id='time'> Time: 2020-09-04</div><div id='author'> Author: jankrepl@yahoo.com</div><div id='file'> File Name: src/bbsearch/embedding_models.py</div><div id='m_class'> M Class Name: SBioBERT</div><div id='n_method'> N Class Name: SBioBERT</div><div id='m_method'> M Method Name: preprocess(2)</div><div id='n_method'> N Method Name: preprocess(2)</div><div id='m_parent_class'> M Parent Class: EmbeddingModel</div><div id='n_parent_class'> N Parent Class: EmbeddingModel</div><div id='m_file'> M File Name: src/bbsearch/embedding_models.py</div><div id='n_file'> N File Name: src/bbsearch/embedding_models.py</div><div id='m_start'> M Start Line: 94</div><div id='m_end'> M End Line: 105</div><div id='n_start'> N Start Line: 141</div><div id='n_end'> N End Line: 145</div><BR>