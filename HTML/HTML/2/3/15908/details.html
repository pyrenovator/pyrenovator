<html><h3>Pattern ID :15908
</h3><img src='53683522.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            attn_mask.append(encodings_dict[&quotattention_mask&quot])
        max_length = max([len(idx) for idx in text_idx])
        text_idx = [idx + [self.padding_token_idx] * (max_length - len(idx)) for idx in text_idx]
        attn_mask = <a id="change">[mask + [0] * (max_length - len(mask)) for mask in attn_mask]</a>
        text_idx = torch.LongTensor(text_idx).to(self.device)
        attn_mask = torch.LongTensor(attn_mask).to(self.device)

        input_text = text_idx[:, :-1]</code></pre><h3>After Change</h3><pre><code class='java'>
        attn_masks = []
        for text in text_sequence:
            sentence = &quot &quot.join([self.sos_token] + text + [self.eos_token])
            encoding_dict = <a id="change">self.tokenizer(</a>sentence<a id="change">,
                                           max_length=self.max_seq_length,
                                           padding="max_length",
                                           truncation=True,
                                           return_tensors="pt")</a>
            input_ids.append(encoding_dict[&quotinput_ids&quot])
            attn_masks.append(encoding_dict[&quotattention_mask&quot])
        input_ids = torch.cat(input_ids, dim=0).to(self.device)
        attn_masks = torch.cat(attn_masks, dim=0).to(self.device)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/9c7994602989cced6709bf6ec43a092f69a1d6cd#diff-da9020b7921d1fba6b2fab2060235123581b65e72d8336411bd2530895ce313fL67' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 53683522</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 9c7994602989cced6709bf6ec43a092f69a1d6cd</div><div id='time'> Time: 2020-12-08</div><div id='author'> Author: lijunyi@ruc.edu.cn</div><div id='file'> File Name: textbox/model/LM/gpt2.py</div><div id='m_class'> M Class Name: GPT2</div><div id='n_method'> N Class Name: GPT2</div><div id='m_method'> M Method Name: calculate_loss(3)</div><div id='n_method'> N Method Name: calculate_loss(3)</div><div id='m_parent_class'> M Parent Class: UnconditionalGenerator</div><div id='n_parent_class'> N Parent Class: UnconditionalGenerator</div><div id='m_file'> M File Name: textbox/model/LM/gpt2.py</div><div id='n_file'> N File Name: textbox/model/LM/gpt2.py</div><div id='m_start'> M Start Line: 67</div><div id='m_end'> M End Line: 91</div><div id='n_start'> N Start Line: 72</div><div id='n_end'> N End Line: 95</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            text_idx.append(encodings_dict[&quotinput_ids&quot])
            attn_mask.append(encodings_dict[&quotattention_mask&quot])
        max_length = max([len(idx) for idx in text_idx])
        text_idx = <a id="change">[idx + [self.padding_token_idx] * (max_length - len(idx)) for idx in text_idx]</a>
        attn_mask = [mask + [0] * (max_length - len(mask)) for mask in attn_mask]
        text_idx = torch.LongTensor(text_idx).to(self.device)
        attn_mask = torch.LongTensor(attn_mask).to(self.device)
</code></pre><h3>After Change</h3><pre><code class='java'>
        attn_masks = []
        for text in text_sequence:
            sentence = &quot &quot.join([self.sos_token] + text + [self.eos_token])
            encodings_dict = <a id="change">self.tokenizer(</a>sentence<a id="change">,
                                            max_length=self.max_seq_length,
                                            padding="max_length",
                                            truncation=True,
                                            return_tensors="pt")</a>
            input_ids.append(encodings_dict[&quotinput_ids&quot])
            attn_masks.append(encodings_dict[&quotattention_mask&quot])
        input_ids = torch.cat(input_ids, dim=0).to(self.device)
        attn_masks = torch.cat(attn_masks, dim=0).to(self.device)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/9c7994602989cced6709bf6ec43a092f69a1d6cd#diff-da9020b7921d1fba6b2fab2060235123581b65e72d8336411bd2530895ce313fL95' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 53683520</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 9c7994602989cced6709bf6ec43a092f69a1d6cd</div><div id='time'> Time: 2020-12-08</div><div id='author'> Author: lijunyi@ruc.edu.cn</div><div id='file'> File Name: textbox/model/LM/gpt2.py</div><div id='m_class'> M Class Name: GPT2</div><div id='n_method'> N Class Name: GPT2</div><div id='m_method'> M Method Name: calculate_nll_test(3)</div><div id='n_method'> N Method Name: calculate_nll_test(3)</div><div id='m_parent_class'> M Parent Class: UnconditionalGenerator</div><div id='n_parent_class'> N Parent Class: UnconditionalGenerator</div><div id='m_file'> M File Name: textbox/model/LM/gpt2.py</div><div id='n_file'> N File Name: textbox/model/LM/gpt2.py</div><div id='m_start'> M Start Line: 97</div><div id='m_end'> M End Line: 118</div><div id='n_start'> N Start Line: 104</div><div id='n_end'> N End Line: 124</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def generate(self, eval_dataloader):
        generate_corpus = []
        for batch_data in eval_dataloader:
            source_text_list = <a id="change">[&quot &quot.join(token_list) for token_list in batch_data[&quotsource_text&quot]]</a>
            sample_outputs = self.decoder.generate(
                source_text_list,
                num_beams=4,
                max_length=self.max_target_length,</code></pre><h3>After Change</h3><pre><code class='java'>
                source_text = batch_data["source_text"]
                for text in source_text:
                    sentence = &quot &quot.join(text)
                    encoding_dict = <a id="change">self.tokenizer(</a>sentence<a id="change">, return_tensors="pt")</a>
                    input_ids = encoding_dict[&quotinput_ids&quot].to(self.device)
                    sample_outputs = self.decoder.generate(input_ids,
                                                           num_beams=4,
                                                           max_length=self.max_target_length,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/98f1b699c360e68b85477e671450399a5f68eca4#diff-cb6154a8f614953fc099f2d791b0b41c862387b24dc8dc538bfe98ebbaa4a3b7L44' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 53683527</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 98f1b699c360e68b85477e671450399a5f68eca4</div><div id='time'> Time: 2020-12-09</div><div id='author'> Author: lijunyi@ruc.edu.cn</div><div id='file'> File Name: textbox/model/Seq2Seq/bart.py</div><div id='m_class'> M Class Name: BART</div><div id='n_method'> N Class Name: BART</div><div id='m_method'> M Method Name: generate(2)</div><div id='n_method'> N Method Name: generate(2)</div><div id='m_parent_class'> M Parent Class: ConditionalGenerator</div><div id='n_parent_class'> N Parent Class: ConditionalGenerator</div><div id='m_file'> M File Name: textbox/model/Seq2Seq/bart.py</div><div id='n_file'> N File Name: textbox/model/Seq2Seq/bart.py</div><div id='m_start'> M Start Line: 46</div><div id='m_end'> M End Line: 57</div><div id='n_start'> N Start Line: 46</div><div id='n_end'> N End Line: 61</div><BR>