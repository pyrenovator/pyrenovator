<html><h3>Pattern ID :26316
</h3><img src='79073748.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        num_buckets = {column: 10 for column in op_columns}
    hash_bucket_op = ops.HashBucket(num_buckets)

    columns_ctx = <a id="change">{}</a>
    <a id="change">columns_ctx["categorical"]</a> = <a id="change">{}</a>
    <a id="change">columns_ctx["categorical"]["base"]</a> = cat_names

    &#47&#47 check sums for determinancy
    checksums = []
    <a id="change">for </a><a id="change">gdf</a> in <a id="change">dataset.to_iter():
        </a>new_gdf<a id="change"> = </a><a id="change">hash_bucket_op.apply_op(gdf</a>, <a id="change">columns_ctx</a>, <a id="change">"categorical"</a><a id="change">)</a>
        assert np.all(new_gdf[cat_names].values &gt;= 0)
        assert np.all(new_gdf[cat_names].values &lt;= 9)
        checksums.append(new_gdf[cat_names].sum().values)
</code></pre><h3>After Change</h3><pre><code class='java'>
    else:
        num_buckets = {column: 10 for column in op_columns}

    hash_features = cat_names<a id="change"> &gt;&gt; </a>ops.HashBucket(num_buckets)
    processor = <a id="change">nvt.Workflow(</a>hash_features<a id="change">)</a>
    <a id="change">processor.fit(dataset</a><a id="change">)</a>
    new_gdf = processor.transform(dataset).to_ddf().compute()

    &#47&#47 check sums for determinancy
    assert np.all(new_gdf[cat_names].values &gt;= 0)
    assert np.all(new_gdf[cat_names].values &lt;= 9)
    checksum = new_gdf[cat_names].sum().values
    new_gdf<a id="change"> = </a><a id="change">processor.transform(dataset).to_ddf().compute()</a>
    np.all(new_gdf[cat_names].sum().values == checksum)


def test_hash_bucket_lists(tmpdir):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 17</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/nvidia/nvtabular/commit/4c92dffac4354d816178264bcfcdec722db2ec1c#diff-e4d18001a1d407273320606db51ffe8ef20709522220cdc6e3cde2070f06b246L161' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 79073748</div><div id='project'> Project Name: nvidia/nvtabular</div><div id='commit'> Commit Name: 4c92dffac4354d816178264bcfcdec722db2ec1c</div><div id='time'> Time: 2021-01-05</div><div id='author'> Author: github@benfrederickson.com</div><div id='file'> File Name: tests/unit/test_ops.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_hash_bucket(6)</div><div id='n_method'> N Method Name: test_hash_bucket(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/unit/test_ops.py</div><div id='n_file'> N File Name: tests/unit/test_ops.py</div><div id='m_start'> M Start Line: 331</div><div id='m_end'> M End Line: 355</div><div id='n_start'> N Start Line: 161</div><div id='n_end'> N End Line: 178</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        num_buckets = {column: 10 for column in op_columns}
    hash_bucket_op = ops.HashBucket(num_buckets)

    columns_ctx = <a id="change">{}</a>
    <a id="change">columns_ctx["categorical"]</a> = <a id="change">{}</a>
    <a id="change">columns_ctx["categorical"]["base"]</a> = cat_names

    &#47&#47 check sums for determinancy
    checksums = []
    for gdf in dataset.to_iter():
        new_gdf = hash_bucket_op.apply_op(gdf, columns_ctx, "categorical")
        assert np.all(new_gdf[cat_names].values &gt;= 0)
        assert np.all(new_gdf[cat_names].values &lt;= 9)
        checksums.append(new_gdf[cat_names].sum().values)

    <a id="change">for </a>checksum, <a id="change">gdf</a> in zip(checksums, <a id="change">dataset.to_iter()</a>)<a id="change">:
        </a>new_gdf<a id="change"> = </a><a id="change">hash_bucket_op.apply_op(</a>gdf, columns_ctx, <a id="change">"categorical"</a><a id="change">)</a>
        assert np.all(new_gdf[cat_names].sum().values == checksum)


def test_hash_bucket_lists(tmpdir):</code></pre><h3>After Change</h3><pre><code class='java'>
    else:
        num_buckets = {column: 10 for column in op_columns}

    hash_features = cat_names<a id="change"> &gt;&gt; </a>ops.HashBucket(num_buckets)
    processor = <a id="change">nvt.Workflow(</a>hash_features<a id="change">)</a>
    <a id="change">processor.fit(</a>dataset<a id="change">)</a>
    new_gdf = <a id="change">processor.transform(dataset).to_ddf().compute()</a>

    &#47&#47 check sums for determinancy
    assert np.all(new_gdf[cat_names].values &gt;= 0)
    assert np.all(new_gdf[cat_names].values &lt;= 9)
    checksum<a id="change"> = </a>new_gdf[cat_names].sum().values
    new_gdf = processor.transform(dataset).to_ddf().compute()
    np.all(new_gdf[cat_names].sum().values == checksum)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nvidia/nvtabular/commit/4c92dffac4354d816178264bcfcdec722db2ec1c#diff-e4d18001a1d407273320606db51ffe8ef20709522220cdc6e3cde2070f06b246L330' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 79073810</div><div id='project'> Project Name: nvidia/nvtabular</div><div id='commit'> Commit Name: 4c92dffac4354d816178264bcfcdec722db2ec1c</div><div id='time'> Time: 2021-01-05</div><div id='author'> Author: github@benfrederickson.com</div><div id='file'> File Name: tests/unit/test_ops.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_hash_bucket(6)</div><div id='n_method'> N Method Name: test_hash_bucket(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/unit/test_ops.py</div><div id='n_file'> N File Name: tests/unit/test_ops.py</div><div id='m_start'> M Start Line: 331</div><div id='m_end'> M End Line: 355</div><div id='n_start'> N Start Line: 161</div><div id='n_end'> N End Line: 178</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    else:
        hashed_cross_op = ops.HashedCross([cat_names], [num_buckets])

    columns_ctx = <a id="change">{}</a>
    <a id="change">columns_ctx["categorical"]</a> = <a id="change">{}</a>
    <a id="change">columns_ctx["categorical"]["base"]</a> = list(cat_names)

    &#47&#47 check sums for determinancy
    checksums = []
    <a id="change">for </a><a id="change">gdf</a> in <a id="change">dataset.to_iter():
        </a>new_gdf<a id="change"> = </a><a id="change">hashed_cross_op.apply_op(</a>gdf, columns_ctx, <a id="change">"categorical"</a><a id="change">)</a>
        new_column_name = "_X_".join(cat_names)
        assert np.all(new_gdf[new_column_name].values &gt;= 0)
        assert np.all(new_gdf[new_column_name].values &lt;= 9)
        checksums.append(new_gdf[new_column_name].sum())</code></pre><h3>After Change</h3><pre><code class='java'>
    cat_names = [["name-string", "id"]]
    num_buckets = 10

    hashed_cross = cat_names<a id="change"> &gt;&gt; </a>ops.HashedCross(num_buckets)
    <a id="change">dataset</a> = nvt.Dataset(df)
    processor = <a id="change">nvtabular.Workflow(</a>hashed_cross<a id="change">)</a>
    <a id="change">processor.fit(</a>dataset<a id="change">)</a>
    new_gdf = <a id="change">processor.transform(dataset).to_ddf().compute()</a>

    &#47&#47 check sums for determinancy
    new_column_name = "_X_".join(cat_names[0])
    assert np.all(new_gdf[new_column_name].values &gt;= 0)
    assert np.all(new_gdf[new_column_name].values &lt;= 9)
    checksum<a id="change"> = </a>new_gdf[new_column_name].sum()
    new_gdf = processor.transform(dataset).to_ddf().compute()
    assert new_gdf[new_column_name].sum() == checksum
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nvidia/nvtabular/commit/4c92dffac4354d816178264bcfcdec722db2ec1c#diff-e4d18001a1d407273320606db51ffe8ef20709522220cdc6e3cde2070f06b246L1058' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 79073777</div><div id='project'> Project Name: nvidia/nvtabular</div><div id='commit'> Commit Name: 4c92dffac4354d816178264bcfcdec722db2ec1c</div><div id='time'> Time: 2021-01-05</div><div id='author'> Author: github@benfrederickson.com</div><div id='file'> File Name: tests/unit/test_ops.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_hashed_cross(5)</div><div id='n_method'> N Method Name: test_hashed_cross(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/unit/test_ops.py</div><div id='n_file'> N File Name: tests/unit/test_ops.py</div><div id='m_start'> M Start Line: 1058</div><div id='m_end'> M End Line: 1085</div><div id='n_start'> N Start Line: 659</div><div id='n_end'> N End Line: 674</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        drop_duplicates_ext=drop_duplicates,
    )
    columns = mycols_pq if engine == "parquet" else mycols_csv
    columns_ctx = <a id="change">{}</a>
    <a id="change">columns_ctx["all"]</a> = <a id="change">{}</a>
    <a id="change">columns_ctx["all"]["base"]</a> = columns

    &#47&#47 Iterate, apply op, and check result
    <a id="change">for </a><a id="change">gdf</a> in <a id="change">dataset.to_iter():
        </a>new_gdf<a id="change"> = </a><a id="change">merge_op.apply_op(</a>gdf, columns_ctx, <a id="change">"all"</a><a id="change">)</a>
        check_gdf = gdf.merge(df_ext_check, how=how, on=on)
        assert len(check_gdf) == len(new_gdf)
        assert (new_gdf["id"] + shift).all() == new_gdf["new_col"].all()
        assert gdf["id"].all() == new_gdf["id"].all()</code></pre><h3>After Change</h3><pre><code class='java'>
    df_ext_check = df_ext_check[columns_ext]
    if drop_duplicates:
        df_ext_check.drop_duplicates(ignore_index=True, inplace=True)
    joined = nvt.ColumnGroup(columns_left)<a id="change"> &gt;&gt; </a>nvt.ops.JoinExternal(
        df_ext,
        on,
        how=how,
        columns_ext=columns_ext,
        cache=cache,
        drop_duplicates_ext=drop_duplicates,
    )

    gdf = df.reset_index()
    <a id="change">dataset</a> = nvt.Dataset(gdf)
    processor = <a id="change">nvt.Workflow(</a>joined<a id="change">)</a>
    <a id="change">processor.fit(</a>dataset<a id="change">)</a>
    new_gdf<a id="change"> = </a><a id="change">processor.transform(dataset).to_ddf().compute()</a>.reset_index()

    check_gdf = gdf.merge(df_ext_check, how=how, on=on)
    assert len(check_gdf) == len(new_gdf)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nvidia/nvtabular/commit/4c92dffac4354d816178264bcfcdec722db2ec1c#diff-e4d18001a1d407273320606db51ffe8ef20709522220cdc6e3cde2070f06b246L937' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 79073755</div><div id='project'> Project Name: nvidia/nvtabular</div><div id='commit'> Commit Name: 4c92dffac4354d816178264bcfcdec722db2ec1c</div><div id='time'> Time: 2021-01-05</div><div id='author'> Author: github@benfrederickson.com</div><div id='file'> File Name: tests/unit/test_ops.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_join_external(8)</div><div id='n_method'> N Method Name: test_join_external(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/unit/test_ops.py</div><div id='n_file'> N File Name: tests/unit/test_ops.py</div><div id='m_start'> M Start Line: 944</div><div id='m_end'> M End Line: 988</div><div id='n_start'> N Start Line: 548</div><div id='n_end'> N End Line: 590</div><BR>