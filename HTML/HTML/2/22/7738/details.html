<html><h3>Pattern ID :7738
</h3><img src='26382354.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    generator.train()

    end = time.time()
    <a id="change">for </a>index, (lr, hr) in <a id="change">enumerate(</a>train_dataloader<a id="change">):
        &#47&#47 measure data loading time
        </a>data_time.update(time.time() - end)

        &#47&#47 Send data to designated device
        lr = lr.to(config.device, non_blocking=True)
        hr<a id="change"> = </a>hr.to(config.device, non_blocking=True)

        &#47&#47 Set the real sample label to 1, and the false sample label to 0
        real_label<a id="change"> = </a>torch.full([lr.size(0), 1], 1.0, dtype=lr.dtype, device=config.device)
        fake_label = torch.full([lr.size(0), 1], 0.0, dtype=lr.dtype, device=config.device)

        &#47&#47 Use generators to create super-resolution images
        sr = generator(lr)

        &#47&#47 Start training discriminator
        &#47&#47 At this stage, the discriminator needs to require a derivative gradient
        for p in discriminator.parameters():
            p.requires_grad = True

        &#47&#47 Initialize the discriminator optimizer gradient
        d_optimizer.zero_grad()

        &#47&#47 Calculate the loss of the discriminator on the high-resolution image
        with amp.autocast():
            hr_output = discriminator(hr)
            sr_output = discriminator(sr.detach())
            d_loss_hr = adversarial_criterion(hr_output - torch.mean(sr_output), real_label)
            d_loss_sr = adversarial_criterion(sr_output - torch.mean(hr_output), fake_label)
        &#47&#47 Gradient zoom
        scaler.scale(d_loss_hr).backward(retain_graph=True)
        scaler.scale(d_loss_sr).backward()

        &#47&#47 Update gradient
        scaler.step(d_optimizer)
        scaler.update()

        &#47&#47 Count discriminator total loss
        d_loss = d_loss_hr + d_loss_sr
        &#47&#47 End training discriminator

        &#47&#47 Start training generator
        &#47&#47 At this stage, the discriminator no needs to require a derivative gradient
        for p in discriminator.parameters():
            p.requires_grad = False

        &#47&#47 Initialize the generator optimizer gradient
        g_optimizer.zero_grad()

        &#47&#47 Calculate the loss of the generator on the super-resolution image
        with amp.autocast():
            hr_output = discriminator(hr.detach())
            sr_output = discriminator(sr)
            pixel_loss = config.pixel_weight * pixel_criterion(sr, hr.detach())
            content_loss = config.content_weight * content_criterion(sr, hr.detach())
            adversarial_loss = config.adversarial_weight * adversarial_criterion(sr_output - torch.mean(hr_output), real_label)
        &#47&#47 Count discriminator total loss
        g_loss<a id="change"> = </a>pixel_loss + content_loss + adversarial_loss
        &#47&#47 Gradient zoom
        scaler.scale(g_loss).backward()
        &#47&#47 Update generator parameters
        scaler.step(g_optimizer)
        scaler.update()

        &#47&#47 End training generator

        &#47&#47 Calculate the scores of the two images on the discriminator
        d_hr_probability = torch.sigmoid(torch.mean(hr_output))
        d_sr_probability<a id="change"> = </a>torch.sigmoid(torch.mean(sr_output))

        &#47&#47 measure accuracy and record loss
        psnr = 10. * torch.log10(1. / psnr_criterion(sr, hr))
        pixel_losses.update(pixel_loss.item(), lr.size(0))
        content_losses.update(content_loss.item(), lr.size(0))
        adversarial_losses.update(adversarial_loss.item(), lr.size(0))
        d_hr_probabilities.update(d_hr_probability.item(), lr.size(0))
        d_sr_probabilities.update(d_sr_probability.item(), lr.size(0))
        psnres.update(psnr.item(), lr.size(0))

        &#47&#47 measure elapsed time
        batch_time.update(time.time() - end)
        end = time.time()

        iters<a id="change"> = </a>index + epoch * batches + 1
        writer.add_scalar("Train/D_Loss", d_loss.item(), iters)
        writer.add_scalar("Train/G_Loss", g_loss.item(), iters)
        writer.add_scalar("Train/Pixel_Loss", pixel_loss.item(), iters)
        writer.add_scalar("Train/Content_Loss", content_loss.item(), iters)
        writer.add_scalar("Train/Adversarial_Loss", adversarial_loss.item(), iters)
        writer.add_scalar("Train/D(HR)_Probability", d_hr_probability.item(), iters)
        writer.add_scalar("Train/D(SR)_Probability", d_sr_probability.item(), iters)
        <a id="change">if </a>index % config.print_frequency == 0 and <a id="change">index != 0</a>:
            progress.display(index)

</code></pre><h3>After Change</h3><pre><code class='java'>
    end = time.time()
    &#47&#47 enable preload
    train_prefetcher.reset()
    batch_data<a id="change"> = </a>train_prefetcher.next()
    <a id="change">while batch_data is not None</a><a id="change">:
        &#47&#47 measure data loading time
        </a>data_time.update(time.time() - end)

        &#47&#47 Send data to designated device
        lr = batch_data["lr"].to(config.device, non_blocking=True)
        hr<a id="change"> = </a>batch_data["hr"].to(config.device, non_blocking=True)

        &#47&#47 Set the real sample label to 1, and the false sample label to 0
        real_label<a id="change"> = </a>torch.full([lr.size(0), 1], 1.0, dtype=lr.dtype, device=config.device)
        fake_label = torch.full([lr.size(0), 1], 0.0, dtype=lr.dtype, device=config.device)

        &#47&#47 Use generators to create super-resolution images
        sr = generator(lr)

        &#47&#47 Start training discriminator
        &#47&#47 At this stage, the discriminator needs to require a derivative gradient
        for p in discriminator.parameters():
            p.requires_grad = True

        &#47&#47 Initialize the discriminator optimizer gradient
        d_optimizer.zero_grad()

        &#47&#47 Calculate the loss of the discriminator on the high-resolution image
        with amp.autocast():
            hr_output = discriminator(hr)
            sr_output = discriminator(sr.detach())
            d_loss_hr = adversarial_criterion(hr_output - torch.mean(sr_output), real_label)
            d_loss_sr = adversarial_criterion(sr_output - torch.mean(hr_output), fake_label)
        &#47&#47 Gradient zoom
        scaler.scale(d_loss_hr).backward(retain_graph=True)
        scaler.scale(d_loss_sr).backward()

        &#47&#47 Update gradient
        scaler.step(d_optimizer)
        scaler.update()

        &#47&#47 Count discriminator total loss
        d_loss = d_loss_hr + d_loss_sr
        &#47&#47 End training discriminator

        &#47&#47 Start training generator
        &#47&#47 At this stage, the discriminator no needs to require a derivative gradient
        for p in discriminator.parameters():
            p.requires_grad = False

        &#47&#47 Initialize the generator optimizer gradient
        g_optimizer.zero_grad()

        &#47&#47 Calculate the loss of the generator on the super-resolution image
        with amp.autocast():
            hr_output = discriminator(hr.detach())
            sr_output = discriminator(sr)
            pixel_loss = config.pixel_weight * pixel_criterion(sr, hr.detach())
            content_loss = config.content_weight * content_criterion(sr, hr.detach())
            adversarial_loss = config.adversarial_weight * adversarial_criterion(sr_output - torch.mean(hr_output), real_label)
        &#47&#47 Count discriminator total loss
        g_loss<a id="change"> = </a>pixel_loss + content_loss + adversarial_loss
        &#47&#47 Gradient zoom
        scaler.scale(g_loss).backward()
        &#47&#47 Update generator parameters
        scaler.step(g_optimizer)
        scaler.update()

        &#47&#47 End training generator

        &#47&#47 Calculate the scores of the two images on the discriminator
        d_hr_probability = torch.sigmoid(torch.mean(hr_output))
        d_sr_probability<a id="change"> = </a>torch.sigmoid(torch.mean(sr_output))

        &#47&#47 measure accuracy and record loss
        psnr = 10. * torch.log10(1. / psnr_criterion(sr, hr))
        pixel_losses.update(pixel_loss.item(), lr.size(0))
        content_losses.update(content_loss.item(), lr.size(0))
        adversarial_losses.update(adversarial_loss.item(), lr.size(0))
        d_hr_probabilities.update(d_hr_probability.item(), lr.size(0))
        d_sr_probabilities.update(d_sr_probability.item(), lr.size(0))
        psnres.update(psnr.item(), lr.size(0))

        &#47&#47 measure elapsed time
        batch_time.update(time.time() - end)
        end = time.time()

        &#47&#47 Record training log information
        <a id="change">if </a>batch_index % config.print_frequency == 0:
            &#47&#47 Writer Loss to file
            iters<a id="change"> = </a>batch_index<a id="change"> + epoch * batches + </a>1
            writer.add_scalar("Train/D_Loss", d_loss.item(), iters)
            writer.add_scalar("Train/G_Loss", g_loss.item(), iters)
            writer.add_scalar("Train/Pixel_Loss", pixel_loss.item(), iters)
            writer.add_scalar("Train/Content_Loss", content_loss.item(), iters)
            writer.add_scalar("Train/Adversarial_Loss", adversarial_loss.item(), iters)
            writer.add_scalar("Train/D(HR)_Probability", d_hr_probability.item(), iters)
            writer.add_scalar("Train/D(SR)_Probability", d_sr_probability.item(), iters)
            progress.display(batch_index)

        &#47&#47 Preload the next batch of data
        batch_data<a id="change"> = </a>train_prefetcher.next()

        &#47&#47 After a batch of data is calculated, add 1 to the number of batches
        batch_index<a id="change"> += </a>1


def validate(model, valid_prefetcher, psnr_criterion, epoch, writer, mode) -&gt; float:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 22</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lornatang/esrgan-pytorch/commit/087e0c9bc621989889918b52b7c0dba9485c5fd6#diff-d62cd92dbb6c2541c1742737f637aeab1aa9fcc576e3af108f8ef0c1fd28c8f8L194' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 26382354</div><div id='project'> Project Name: lornatang/esrgan-pytorch</div><div id='commit'> Commit Name: 087e0c9bc621989889918b52b7c0dba9485c5fd6</div><div id='time'> Time: 2022-03-06</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: train_esrgan.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(12)</div><div id='n_method'> N Method Name: train(12)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_esrgan.py</div><div id='n_file'> N File Name: train_esrgan.py</div><div id='m_start'> M Start Line: 194</div><div id='m_end'> M End Line: 310</div><div id='n_start'> N Start Line: 240</div><div id='n_end'> N End Line: 369</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        is_last_special = False
        is_last_cjk = False
        is_last_num_or_alphabet = False
        <a id="change">for </a>i,ch in <a id="change">enumerate(</a>text<a id="change">):
            </a>if is_last_special == True:
                tokenized<a id="change"> += </a>ch
                <a id="change">if is_special(ch) == True</a>:
                    tokenized += " "
                    is_last_special = False
            elif is_cjk(ch):
                if is_last_cjk == True:
                    tokenized += (ch) 
                else:
                    tokenized += (" " + ch)
                is_last_cjk = True
                is_last_num_or_alphabet = False
            elif is_num(ch) or is_alphabet(ch):                
                if is_last_num_or_alphabet == True:
                    tokenized += ch
                else:
                    tokenized += (" " + ch)
                is_last_cjk<a id="change"> = </a>False
                is_last_num_or_alphabet<a id="change"> = </a>True
            elif is_special(ch):
                tokenized += (" " + ch)
                is_last_special = True
                is_last_cjk<a id="change"> = </a>False
                is_last_num_or_alphabet<a id="change"> = </a>True
            elif is_useless(ch):
                is_last_cjk = False
                is_last_num_or_alphabet = False                  </code></pre><h3>After Change</h3><pre><code class='java'>
        
        text = re.sub("[ ]+", " ", text)
        
        i<a id="change"> = </a>0
        tokenized = ""
        is_last_cjk = False
        is_last_num_or_alphabet = False
        <a id="change">while i &lt; len(text)</a><a id="change">:
            </a>ch = text[i]
            if is_special(ch):
                matched = self.prefix_match(text[i:]) 
                <a id="change">if </a>len(matched) &gt; 0:
                    tokenized<a id="change"> += </a>(" "<a id="change"> + matched + </a>" ")
                    i += len(matched)
                else:
                    tokenized += (" " + ch + " ")
                    i += 1
                is_last_cjk<a id="change"> = </a>False
                is_last_num_or_alphabet<a id="change"> = </a>True
            elif is_cjk(ch):
                if is_last_cjk == True:
                    tokenized += (ch) 
                else:
                    tokenized += (" " + ch)
                is_last_cjk = True
                is_last_num_or_alphabet = False
                i += 1
            elif is_num(ch) or is_alphabet(ch):                
                if is_last_num_or_alphabet == True:
                    tokenized += ch
                else:
                    tokenized += (" " + ch)
                is_last_cjk<a id="change"> = </a>False
                is_last_num_or_alphabet<a id="change"> = </a>True
                i += 1
            elif is_useless(ch):
                is_last_cjk = False
                is_last_num_or_alphabet = False  
                i<a id="change"> += </a>1
            elif is_space(ch):
                if is_alphabet(text[i-1]) and is_alphabet(text[i+1]): 
                    tokenized += " "
                elif is_special(text[i-1]) or is_special(text[i+1]): 
                    tokenized += " "
                else:
                    tokenized += " _s_ "
                is_last_cjk = False
                is_last_num_or_alphabet = False   
                i<a id="change"> += </a>1
            else:
                tokenized += (" " + ch + " ") 
                is_last_cjk = False</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yaoxiaoyuan/mimix/commit/d6945a07acf4cd73820dba564853047ec75525b2#diff-775a817e551168ab6fb8afe296f1ba7cc22a686dde74fd61244d304bb492c69bL245' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 26382288</div><div id='project'> Project Name: yaoxiaoyuan/mimix</div><div id='commit'> Commit Name: d6945a07acf4cd73820dba564853047ec75525b2</div><div id='time'> Time: 2022-08-15</div><div id='author'> Author: sbsbsbsbsb945@gmail.com</div><div id='file'> File Name: src/tokenization.py</div><div id='m_class'> M Class Name: MimixTokenizer</div><div id='n_method'> N Class Name: MimixTokenizer</div><div id='m_method'> M Method Name: tokenize(2)</div><div id='n_method'> N Method Name: tokenize(2)</div><div id='m_parent_class'> M Parent Class: Tokenizer</div><div id='n_parent_class'> N Parent Class: Tokenizer</div><div id='m_file'> M File Name: src/tokenization.py</div><div id='n_file'> N File Name: src/tokenization.py</div><div id='m_start'> M Start Line: 250</div><div id='m_end'> M End Line: 298</div><div id='n_start'> N Start Line: 283</div><div id='n_end'> N End Line: 337</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    generator.train()

    end = time.time()
    <a id="change">for </a>index, (lr, hr) in <a id="change">enumerate(</a>train_dataloader<a id="change">):
        &#47&#47 measure data loading time
        </a>data_time.update(time.time() - end)

        &#47&#47 Send data to designated device
        lr = lr.to(config.device, non_blocking=True)
        hr = hr.to(config.device, non_blocking=True)

        &#47&#47 Set the real sample label to 1, and the false sample label to 0
        real_label<a id="change"> = </a>torch.full([lr.size(0), 1], 1.0, dtype=lr.dtype, device=config.device)
        fake_label = torch.full([lr.size(0), 1], 0.0, dtype=lr.dtype, device=config.device)

        &#47&#47 Use generators to create super-resolution images
        sr = generator(lr)

        &#47&#47 Start training discriminator
        &#47&#47 At this stage, the discriminator needs to require a derivative gradient
        for p in discriminator.parameters():
            p.requires_grad = True

        &#47&#47 Initialize the discriminator optimizer gradient
        d_optimizer.zero_grad()

        &#47&#47 Calculate the loss of the discriminator on the high-resolution image
        with amp.autocast():
            hr_output = discriminator(hr)
            d_loss_hr = adversarial_criterion(hr_output, real_label)
        &#47&#47 Gradient zoom
        scaler.scale(d_loss_hr).backward()

        &#47&#47 Calculate the loss of the discriminator on the super-resolution image.
        with amp.autocast():
            sr_output = discriminator(sr.detach())
            d_loss_sr = adversarial_criterion(sr_output, fake_label)
        &#47&#47 Gradient zoom
        scaler.scale(d_loss_sr).backward()
        &#47&#47 Update discriminator parameters
        scaler.step(d_optimizer)
        scaler.update()

        &#47&#47 Count discriminator total loss
        d_loss<a id="change"> = </a>d_loss_hr + d_loss_sr
        &#47&#47 End training discriminator

        &#47&#47 Start training generator
        &#47&#47 At this stage, the discriminator no needs to require a derivative gradient
        for p in discriminator.parameters():
            p.requires_grad = False

        &#47&#47 Initialize the generator optimizer gradient
        g_optimizer.zero_grad()

        &#47&#47 Calculate the loss of the generator on the super-resolution image
        with amp.autocast():
            output = discriminator(sr)
            pixel_loss = config.pixel_weight * pixel_criterion(sr, hr.detach())
            content_loss = config.content_weight * content_criterion(sr, hr.detach())
            adversarial_loss = config.adversarial_weight * adversarial_criterion(output, real_label)
        &#47&#47 Count discriminator total loss
        g_loss = pixel_loss + content_loss + adversarial_loss
        &#47&#47 Gradient zoom
        scaler.scale(g_loss).backward()
        &#47&#47 Update generator parameters
        scaler.step(g_optimizer)
        scaler.update()

        &#47&#47 End training generator

        &#47&#47 Calculate the scores of the two images on the discriminator
        d_hr_probability = torch.sigmoid(torch.mean(hr_output))
        d_sr_probability = torch.sigmoid(torch.mean(sr_output))

        &#47&#47 measure accuracy and record loss
        psnr<a id="change"> = </a>10. * torch.log10(1. / psnr_criterion(sr, hr))
        pixel_losses.update(pixel_loss.item(), lr.size(0))
        content_losses.update(content_loss.item(), lr.size(0))
        adversarial_losses.update(adversarial_loss.item(), lr.size(0))
        d_hr_probabilities.update(d_hr_probability.item(), lr.size(0))
        d_sr_probabilities.update(d_sr_probability.item(), lr.size(0))
        psnres.update(psnr.item(), lr.size(0))

        &#47&#47 measure elapsed time
        batch_time.update(time.time() - end)
        end<a id="change"> = </a>time.time()

        iters<a id="change"> = </a>index + epoch * batches + 1
        writer.add_scalar("Train/D_Loss", d_loss.item(), iters)
        writer.add_scalar("Train/G_Loss", g_loss.item(), iters)
        writer.add_scalar("Train/Pixel_Loss", pixel_loss.item(), iters)
        writer.add_scalar("Train/Content_Loss", content_loss.item(), iters)
        writer.add_scalar("Train/Adversarial_Loss", adversarial_loss.item(), iters)
        writer.add_scalar("Train/D(HR)_Probability", d_hr_probability.item(), iters)
        writer.add_scalar("Train/D(SR)_Probability", d_sr_probability.item(), iters)
        <a id="change">if </a>index % config.print_frequency == 0 and <a id="change">index != 0</a>:
            progress.display(index)

</code></pre><h3>After Change</h3><pre><code class='java'>
    end = time.time()
    &#47&#47 enable preload
    train_prefetcher.reset()
    batch_data<a id="change"> = </a>train_prefetcher.next()

    <a id="change">while batch_data is not None</a><a id="change">:
        &#47&#47 measure data loading time
        </a>data_time.update(time.time() - end)

        &#47&#47 Send data to designated device
        lr = batch_data["lr"].to(config.device, non_blocking=True)
        hr = batch_data["hr"].to(config.device, non_blocking=True)

        &#47&#47 Set the real sample label to 1, and the false sample label to 0
        real_label<a id="change"> = </a>torch.full([lr.size(0), 1], 1.0, dtype=lr.dtype, device=config.device)
        fake_label = torch.full([lr.size(0), 1], 0.0, dtype=lr.dtype, device=config.device)

        &#47&#47 Use generators to create super-resolution images
        sr = generator(lr)

        &#47&#47 Start training discriminator
        &#47&#47 At this stage, the discriminator needs to require a derivative gradient
        for p in discriminator.parameters():
            p.requires_grad = True

        &#47&#47 Initialize the discriminator optimizer gradient
        d_optimizer.zero_grad()

        &#47&#47 Calculate the loss of the discriminator on the high-resolution image
        with amp.autocast():
            hr_output = discriminator(hr)
            d_loss_hr = adversarial_criterion(hr_output, real_label)
        &#47&#47 Gradient zoom
        scaler.scale(d_loss_hr).backward()

        &#47&#47 Calculate the loss of the discriminator on the super-resolution image.
        with amp.autocast():
            sr_output = discriminator(sr.detach())
            d_loss_sr = adversarial_criterion(sr_output, fake_label)
        &#47&#47 Gradient zoom
        scaler.scale(d_loss_sr).backward()
        &#47&#47 Update discriminator parameters
        scaler.step(d_optimizer)
        scaler.update()

        &#47&#47 Count discriminator total loss
        d_loss<a id="change"> = </a>d_loss_hr + d_loss_sr
        &#47&#47 End training discriminator

        &#47&#47 Start training generator
        &#47&#47 At this stage, the discriminator no needs to require a derivative gradient
        for p in discriminator.parameters():
            p.requires_grad = False

        &#47&#47 Initialize the generator optimizer gradient
        g_optimizer.zero_grad()

        &#47&#47 Calculate the loss of the generator on the super-resolution image
        with amp.autocast():
            output = discriminator(sr)
            pixel_loss = config.pixel_weight * pixel_criterion(sr, hr.detach())
            content_loss = config.content_weight * content_criterion(sr, hr.detach())
            adversarial_loss = config.adversarial_weight * adversarial_criterion(output, real_label)
        &#47&#47 Count discriminator total loss
        g_loss = pixel_loss + content_loss + adversarial_loss
        &#47&#47 Gradient zoom
        scaler.scale(g_loss).backward()
        &#47&#47 Update generator parameters
        scaler.step(g_optimizer)
        scaler.update()

        &#47&#47 End training generator

        &#47&#47 Calculate the scores of the two images on the discriminator
        d_hr_probability = torch.sigmoid(torch.mean(hr_output))
        d_sr_probability = torch.sigmoid(torch.mean(sr_output))

        &#47&#47 measure accuracy and record loss
        psnr<a id="change"> = </a>10. * torch.log10(1. / psnr_criterion(sr, hr))
        pixel_losses.update(pixel_loss.item(), lr.size(0))
        content_losses.update(content_loss.item(), lr.size(0))
        adversarial_losses.update(adversarial_loss.item(), lr.size(0))
        d_hr_probabilities.update(d_hr_probability.item(), lr.size(0))
        d_sr_probabilities.update(d_sr_probability.item(), lr.size(0))
        psnres.update(psnr.item(), lr.size(0))

        &#47&#47 measure elapsed time
        batch_time.update(time.time() - end)
        end<a id="change"> = </a>time.time()

        &#47&#47 Record training log information
        <a id="change">if </a>batch_index % config.print_frequency == 0:
            &#47&#47 Writer Loss to file
            iters<a id="change"> = </a>batch_index<a id="change"> + epoch * batches + </a>1
            writer.add_scalar("Train/D_Loss", d_loss.item(), iters)
            writer.add_scalar("Train/G_Loss", g_loss.item(), iters)
            writer.add_scalar("Train/Pixel_Loss", pixel_loss.item(), iters)
            writer.add_scalar("Train/Content_Loss", content_loss.item(), iters)
            writer.add_scalar("Train/Adversarial_Loss", adversarial_loss.item(), iters)
            writer.add_scalar("Train/D(HR)_Probability", d_hr_probability.item(), iters)
            writer.add_scalar("Train/D(SR)_Probability", d_sr_probability.item(), iters)
            progress.display(batch_index)

        &#47&#47 Preload the next batch of data
        batch_data<a id="change"> = </a>train_prefetcher.next()

        &#47&#47 After a batch of data is calculated, add 1 to the number of batches
        batch_index<a id="change"> += </a>1


def validate(model, valid_prefetcher, psnr_criterion, epoch, writer, mode) -&gt; float:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/srgan-pytorch/commit/231bd74d21d7f532fd746f4a1cb8fb3bc008c933#diff-61221f69809c16ee47dd4cd294d775f91cf98ef417745afe77eab4e2716dfaceL180' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 26382358</div><div id='project'> Project Name: lornatang/srgan-pytorch</div><div id='commit'> Commit Name: 231bd74d21d7f532fd746f4a1cb8fb3bc008c933</div><div id='time'> Time: 2022-03-03</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: train_srgan.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(12)</div><div id='n_method'> N Method Name: train(12)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_srgan.py</div><div id='n_file'> N File Name: train_srgan.py</div><div id='m_start'> M Start Line: 193</div><div id='m_end'> M End Line: 311</div><div id='n_start'> N Start Line: 231</div><div id='n_end'> N End Line: 363</div><BR>