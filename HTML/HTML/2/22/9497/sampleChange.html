<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        env_fn=[partial(wrapped_env, cfg.env, cfg.env_wrapper.train, *tcp_list[i]) for i in range(env_num)],
        cfg=cfg.env_manager,
    )
    evaluate_env = ContinuousBenchmarkEnvWrapper(<a id="change">SimpleCarlaEnv(</a>cfg.env, *<a id="change">tcp_list[env_num])</a>, cfg.env_wrapper.eval)
    collector_env.seed(seed)
    evaluate_env.seed(seed)
    set_pkg_seed(seed)

    model = DDPGRLModel()
    policy = DDPGPolicy(cfg.policy, model=model)

    tb_logger = SummaryWriter(os.path.join(&quot./log/&quot, cfg.exp_name))
    learner = BaseLearner(cfg.policy.learn.learner, policy.learn_mode, tb_logger)
    collector = SampleCollector(cfg.policy.collect.collector, collector_env, policy.collect_mode, tb_logger)
    evaluator = SingleCarlaEvaluator(cfg.eval, evaluate_env, policy.eval_mode)
    replay_buffer = NaiveReplayBuffer(cfg.policy.other.replay_buffer, tb_logger)

    learner._instance_name = cfg.exp_name + &quot_&quot + time.ctime().replace(&quot &quot, &quot_&quot).replace(&quot:&quot, &quot_&quot)
    learner.call_hook(&quotbefore_run&quot)
    new_data = collector.collect(n_sample=10000, train_iter=learner.train_iter)
    replay_buffer.push(new_data, cur_collector_envstep=collector.envstep)

    while True:
        if evaluator.should_eval(learner.train_iter):
            <a id="change">results_list = </a><a id="change">[]</a>
            <a id="change">for </a><a id="change">_</a> in <a id="change">range(</a>cfg.eval.eval_num<a id="change">):
                results_list</a><a id="change">.append(evaluator.eval()</a><a id="change">)</a>
            <a id="change">success_rate</a><a id="change"> = </a><a id="change">sum(results_list</a><a id="change">) / len(results_list</a><a id="change">)</a>
            if <a id="change">success_rate &gt; cfg.eval.success_rate</a>:
                break
            <a id="change">print("Evaluate success rate: {:.2f}%".format(success_rate</a><a id="change">*100</a><a id="change">)</a><a id="change">)</a>
        &#47&#47 Sampling data from environments
        new_data = collector.collect(n_sample=3000, train_iter=learner.train_iter)
        update_per_collect = len(new_data) // 32
        replay_buffer.push(new_data, cur_collector_envstep=collector.envstep)</code></pre><h3>After Change</h3><pre><code class='java'>

    while True:
        if evaluator.should_eval(learner.train_iter):
            stop<a id="change">, rate = </a><a id="change">evaluator.eval(</a>learner.save_checkpoint, learner.train_iter, collector.envstep<a id="change">)</a>
            if stop:
                break
        &#47&#47 Sampling data from environments
        new_data = collector.collect(train_iter=learner.train_iter)</code></pre>