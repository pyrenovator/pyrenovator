<html><h3>Pattern ID :1076
</h3><img src='5373281.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        loss = self.loss_func(outputs.view(-1, self.args.vocab_size), trg_idxs[:, 1:].view(-1))
        ppl = torch.exp(loss)
        
        <a id="change">return </a><a id="change">{</a>&quotloss&quot: loss, &quotppl&quot: ppl<a id="change">}</a>
    
    def training_epoch_end(self, training_step_outputs):
        train_ppls = [], []
        for result in training_step_outputs:</code></pre><h3>After Change</h3><pre><code class='java'>
    
    def training_step(self, batch, batch_idx):
        src_idxs, num_valid_turns, trg_idxs = batch  &#47&#47 src_idxs: (B, T, S_L), num_valid_turns: (B), trg_idxs: (B, T_L)
        <a id="change">batch_size</a><a id="change">, num_contexts, trg_len</a> = src_idxs.shape[0], src_idxs.shape[1], trg_idxs.shape[1]
        e_masks = self.make_encoder_mask(num_valid_turns, num_contexts)  &#47&#47 (B, 1, T)
        d_masks = self.make_decoder_mask(trg_idxs[:, :-1], self.args.pad_id)  &#47&#47 (B, T_L, T_L)
        src_poses<a id="change"> = torch</a><a id="change">.arange(num_contexts, device=src_idxs.device).unsqueeze(0).expand(batch_size</a>, <a id="change">num_contexts</a><a id="change">)</a>  &#47&#47 (B, T)
        trg_poses<a id="change"> = torch.arange(trg_len-1, device=trg_idxs.device).unsqueeze(0</a><a id="change">).expand(batch_size</a>, <a id="change">trg_len</a><a id="change">-1</a><a id="change">)</a>  &#47&#47 (B, T_L)
        
        outputs = self.model(src_idxs, trg_idxs[:, :-1], src_poses, trg_poses, e_masks, d_masks)  &#47&#47 (B, T_L, V)
        
        preds = torch.max(outputs, dim=-1).indices  &#47&#47 (B, T_L)
        loss = self.loss_func(outputs.contiguous().view(-1, self.args.vocab_size), trg_idxs[:, 1:].contiguous().view(-1))
        ppl = torch.exp(loss)
        
        return {&quotloss&quot: loss, &quotppl&quot: <a id="change">ppl.detach()</a>}
    
    def training_epoch_end(self, training_step_outputs):
        train_ppls = []</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 14</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/devjwsong/recosa-dialogue-generation-pytorch/commit/63e2cd90ddb124ac7820f917a35ddac3b7b21156#diff-9c76ec515f33a5bc979def5f1ec500aacc68f6f2dad870710d4138bc608bd82eL64' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5373281</div><div id='project'> Project Name: devjwsong/recosa-dialogue-generation-pytorch</div><div id='commit'> Commit Name: 63e2cd90ddb124ac7820f917a35ddac3b7b21156</div><div id='time'> Time: 2021-10-21</div><div id='author'> Author: devjwsong@gmail.com</div><div id='file'> File Name: src/train_module.py</div><div id='m_class'> M Class Name: TrainModule</div><div id='n_method'> N Class Name: TrainModule</div><div id='m_method'> M Method Name: training_step(3)</div><div id='n_method'> N Method Name: training_step(3)</div><div id='m_parent_class'> M Parent Class: pl.LightningModule</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: src/train_module.py</div><div id='n_file'> N File Name: src/train_module.py</div><div id='m_start'> M Start Line: 65</div><div id='m_end'> M End Line: 71</div><div id='n_start'> N Start Line: 64</div><div id='n_end'> N End Line: 76</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        loss = self.loss_func(outputs.view(-1, self.args.vocab_size), trg_idxs[:, 1:].view(-1))
        ppl = torch.exp(loss)
        
        <a id="change">return </a><a id="change">{</a>&quotloss&quot: loss, &quotppl&quot: ppl<a id="change">}</a>
    
    def test_epoch_end(self, test_step_outputs):
        test_ppls = [], []
        for result in test_step_outputs:</code></pre><h3>After Change</h3><pre><code class='java'>
        
    def test_step(self, batch, batch_idx):
        src_idxs, num_valid_turns, trg_idxs = batch  &#47&#47 src_idxs: (B, T, S_L), num_valid_turns: (B), trg_idxs: (B, T_L)
        batch_size<a id="change">, num_contexts, trg_len</a> = src_idxs.shape[0], src_idxs.shape[1], trg_idxs.shape[1]
        e_masks = self.make_encoder_mask(num_valid_turns, num_contexts)  &#47&#47 (B, 1, T)
        d_masks = self.make_decoder_mask(trg_idxs[:, :-1], self.args.pad_id)  &#47&#47 (B, T_L, T_L)
        src_poses<a id="change"> = </a><a id="change">torch.arange(num_contexts, device=src_idxs.device).unsqueeze(0).expand(</a>batch_size, num_contexts<a id="change">)</a>  &#47&#47 (B, T)
        trg_poses<a id="change"> = torch.arange(trg_len-1, device=trg_idxs.device).unsqueeze(0</a><a id="change">).expand(</a>batch_size, trg_len<a id="change">-1</a><a id="change">)</a>  &#47&#47 (B, T_L)
        
        outputs = self.model(src_idxs, trg_idxs[:, :-1], src_poses, trg_poses, e_masks, d_masks)  &#47&#47 (B, T_L, V)
        
        preds = torch.max(outputs, dim=-1).indices  &#47&#47 (B, T_L)
        loss = self.loss_func(outputs.view(-1, self.args.vocab_size), trg_idxs[:, 1:].view(-1))
        ppl = torch.exp(loss)
        
        return {&quotloss&quot: loss.detach(), &quotppl&quot: <a id="change">ppl.detach()</a>}
    
    def test_epoch_end(self, test_step_outputs):
        test_ppls = [] </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/devjwsong/recosa-dialogue-generation-pytorch/commit/63e2cd90ddb124ac7820f917a35ddac3b7b21156#diff-9c76ec515f33a5bc979def5f1ec500aacc68f6f2dad870710d4138bc608bd82eL112' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5373280</div><div id='project'> Project Name: devjwsong/recosa-dialogue-generation-pytorch</div><div id='commit'> Commit Name: 63e2cd90ddb124ac7820f917a35ddac3b7b21156</div><div id='time'> Time: 2021-10-21</div><div id='author'> Author: devjwsong@gmail.com</div><div id='file'> File Name: src/train_module.py</div><div id='m_class'> M Class Name: TrainModule</div><div id='n_method'> N Class Name: TrainModule</div><div id='m_method'> M Method Name: test_step(3)</div><div id='n_method'> N Method Name: test_step(3)</div><div id='m_parent_class'> M Parent Class: pl.LightningModule</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: src/train_module.py</div><div id='n_file'> N File Name: src/train_module.py</div><div id='m_start'> M Start Line: 120</div><div id='m_end'> M End Line: 123</div><div id='n_start'> N Start Line: 122</div><div id='n_end'> N End Line: 134</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        loss = self.loss_func(outputs.view(-1, self.args.vocab_size), trg_idxs[:, 1:].view(-1))
        ppl = torch.exp(loss)
        
        <a id="change">return </a><a id="change">{</a>&quotloss&quot: loss, &quotppl&quot: ppl<a id="change">}</a>
    
    def validation_epoch_end(self, validation_step_outputs):
        valid_ppls = [], []
        for result in validation_step_outputs:</code></pre><h3>After Change</h3><pre><code class='java'>
        
    def validation_step(self, batch, batch_idx):
        src_idxs, num_valid_turns, trg_idxs = batch  &#47&#47 src_idxs: (B, T, S_L), num_valid_turns: (B), trg_idxs: (B, T_L)
        batch_size<a id="change">, num_contexts, trg_len</a> = src_idxs.shape[0], src_idxs.shape[1], trg_idxs.shape[1]
        e_masks = self.make_encoder_mask(num_valid_turns, num_contexts)  &#47&#47 (B, 1, T)
        d_masks = self.make_decoder_mask(trg_idxs[:, :-1], self.args.pad_id)  &#47&#47 (B, T_L, T_L)
        src_poses<a id="change"> = </a><a id="change">torch.arange(num_contexts, device=src_idxs.device).unsqueeze(0).expand(</a>batch_size, num_contexts<a id="change">)</a>  &#47&#47 (B, T)
        trg_poses<a id="change"> = torch.arange(trg_len-1, device=trg_idxs.device).unsqueeze(0</a><a id="change">).expand(</a>batch_size, trg_len<a id="change">-1</a><a id="change">)</a>  &#47&#47 (B, T_L)
        
        outputs = self.model(src_idxs, trg_idxs[:, :-1], src_poses, trg_poses, e_masks, d_masks)  &#47&#47 (B, T_L, V)
        
        preds = torch.max(outputs, dim=-1).indices  &#47&#47 (B, T_L)
        loss = self.loss_func(outputs.view(-1, self.args.vocab_size), trg_idxs[:, 1:].view(-1))
        ppl = torch.exp(loss)
        
        return {&quotloss&quot: <a id="change">loss.detach()</a>, &quotppl&quot: ppl.detach()}
    
    def validation_epoch_end(self, validation_step_outputs):
        valid_ppls = []</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/devjwsong/recosa-dialogue-generation-pytorch/commit/63e2cd90ddb124ac7820f917a35ddac3b7b21156#diff-9c76ec515f33a5bc979def5f1ec500aacc68f6f2dad870710d4138bc608bd82eL86' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5373282</div><div id='project'> Project Name: devjwsong/recosa-dialogue-generation-pytorch</div><div id='commit'> Commit Name: 63e2cd90ddb124ac7820f917a35ddac3b7b21156</div><div id='time'> Time: 2021-10-21</div><div id='author'> Author: devjwsong@gmail.com</div><div id='file'> File Name: src/train_module.py</div><div id='m_class'> M Class Name: TrainModule</div><div id='n_method'> N Class Name: TrainModule</div><div id='m_method'> M Method Name: validation_step(3)</div><div id='n_method'> N Method Name: validation_step(3)</div><div id='m_parent_class'> M Parent Class: pl.LightningModule</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: src/train_module.py</div><div id='n_file'> N File Name: src/train_module.py</div><div id='m_start'> M Start Line: 94</div><div id='m_end'> M End Line: 97</div><div id='n_start'> N Start Line: 93</div><div id='n_end'> N End Line: 105</div><BR>