<html><h3>Pattern ID :1733
</h3><img src='8153444.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        
        Test VPG with Pendulum environment (continuous action spaces)
        
        seed_manager<a id="change">: SeedManager = SeedManager(0</a><a id="change">)</a>
        <a id="change">seed_manager.set_seed_for_libraries()</a>

        env = gym.make("Pendulum-v1")
        env.action_space.seed(seed_manager.seed)

        evaluation_env: Env = copy.deepcopy(env)

        model: VPG = self.create_vpg(env, seed_manager)

        model.learn(
            num_epochs=3,
            batch_size=100,
            model_saving_interval=100,
            output_dir="/tmp/rl_replicas_tests/vpg-"
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed_manager.seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(-1021.275, 0.01)</code></pre><h3>After Change</h3><pre><code class='java'>
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(-1021.275, 0.01)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 8</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/yamatokataoka/reinforcement-learning-replications/commit/61d5a71b19caad93316246cb1a4607a47c058ce9#diff-1b0e813e38d2d530485c451190dc45d99a8ca96c643615481625c9a17c30104bL50' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8153444</div><div id='project'> Project Name: yamatokataoka/reinforcement-learning-replications</div><div id='commit'> Commit Name: 61d5a71b19caad93316246cb1a4607a47c058ce9</div><div id='time'> Time: 2022-08-19</div><div id='author'> Author: 34284486+yamatokataoka@users.noreply.github.com</div><div id='file'> File Name: tests/integration_tests/test_vpg.py</div><div id='m_class'> M Class Name: TestVPG</div><div id='n_method'> N Class Name: TestVPG</div><div id='m_method'> M Method Name: test_vpg_with_pendulum(2)</div><div id='n_method'> N Method Name: test_vpg_with_pendulum(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/integration_tests/test_vpg.py</div><div id='n_file'> N File Name: tests/integration_tests/test_vpg.py</div><div id='m_start'> M Start Line: 58</div><div id='m_end'> M End Line: 76</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 69</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        Test TRPO with Pendulum environment (continuous action spaces)
        
        seed_manager<a id="change">: SeedManager = SeedManager(0</a><a id="change">)</a>
        <a id="change">seed_manager.set_seed_for_libraries()</a>

        env = gym.make("Pendulum-v1")
        env.action_space.seed(seed_manager.seed)

        evaluation_env: Env = copy.deepcopy(env)

        model: TRPO = self.create_trpo(env, seed_manager)

        model.learn(
            num_epochs=3,
            batch_size=100,
            model_saving_interval=100,
            output_dir="/tmp/rl_replicas_tests/trpo-"
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed_manager.seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(-1496.463, 0.01)</code></pre><h3>After Change</h3><pre><code class='java'>
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(-1496.463, 0.01)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yamatokataoka/reinforcement-learning-replications/commit/61d5a71b19caad93316246cb1a4607a47c058ce9#diff-1dbe027c40a154ba85006ff8c54cf8b9f019408b33206657b296da56d84d2090L55' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8153445</div><div id='project'> Project Name: yamatokataoka/reinforcement-learning-replications</div><div id='commit'> Commit Name: 61d5a71b19caad93316246cb1a4607a47c058ce9</div><div id='time'> Time: 2022-08-19</div><div id='author'> Author: 34284486+yamatokataoka@users.noreply.github.com</div><div id='file'> File Name: tests/integration_tests/test_trpo.py</div><div id='m_class'> M Class Name: TestTRPO</div><div id='n_method'> N Class Name: TestTRPO</div><div id='m_method'> M Method Name: test_trpo_with_pendulum(2)</div><div id='n_method'> N Method Name: test_trpo_with_pendulum(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/integration_tests/test_trpo.py</div><div id='n_file'> N File Name: tests/integration_tests/test_trpo.py</div><div id='m_start'> M Start Line: 59</div><div id='m_end'> M End Line: 77</div><div id='n_start'> N Start Line: 51</div><div id='n_end'> N End Line: 70</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        Test DDPG with Pendulum environment (continuous action spaces)
        
        seed_manager<a id="change">: SeedManager = SeedManager(0</a><a id="change">)</a>
        <a id="change">seed_manager.set_seed_for_libraries()</a>

        env = gym.make("Pendulum-v1")
        env.action_space.seed(seed_manager.seed)

        evaluation_env: Env = copy.deepcopy(env)

        observation_size: int = env.observation_space.shape[0]
        action_size: int = env.action_space.shape[0]

        policy_network: nn.Module = MLP(
            sizes=[observation_size] + [256, 256] + [action_size],
            activation_function=nn.ReLU,
            output_activation_function=nn.Tanh,
        )

        q_function_network: nn.Module = MLP(
            sizes=[observation_size + action_size] + [256, 256] + [1],
            activation_function=nn.ReLU,
        )

        model: DDPG = DDPG(
            DeterministicPolicy(
                network=policy_network,
                optimizer=torch.optim.Adam(policy_network.parameters(), lr=1e-3),
            ),
            RandomPolicy(env.action_space),
            QFunction(
                network=q_function_network,
                optimizer=torch.optim.Adam(q_function_network.parameters(), lr=1e-3),
            ),
            env,
            BatchSampler(env, seed_manager.seed, is_continuous=True),
            ReplayBuffer(int(1e6)),
            Evaluator(seed_manager.seed),
        )

        model.learn(
            num_epochs=6,
            num_start_steps=100,
            num_steps_before_update=200,
            evaluation_interval=100,
            model_saving_interval=100,
            output_dir="/tmp/rl_replicas_tests/ddpg-"
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed_manager.seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(-1597.741, 0.01)</code></pre><h3>After Change</h3><pre><code class='java'>
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(-1597.741, 0.01)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yamatokataoka/reinforcement-learning-replications/commit/61d5a71b19caad93316246cb1a4607a47c058ce9#diff-6fcd8373fa7e26aee231921de31fb9b555cdb4163c4778f0c0d8aa2fe6e6dbd4L26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8153446</div><div id='project'> Project Name: yamatokataoka/reinforcement-learning-replications</div><div id='commit'> Commit Name: 61d5a71b19caad93316246cb1a4607a47c058ce9</div><div id='time'> Time: 2022-08-19</div><div id='author'> Author: 34284486+yamatokataoka@users.noreply.github.com</div><div id='file'> File Name: tests/integration_tests/test_ddpg.py</div><div id='m_class'> M Class Name: TestDDPG</div><div id='n_method'> N Class Name: TestDDPG</div><div id='m_method'> M Method Name: test_ddpg_with_pendulum(2)</div><div id='n_method'> N Method Name: test_ddpg_with_pendulum(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/integration_tests/test_ddpg.py</div><div id='n_file'> N File Name: tests/integration_tests/test_ddpg.py</div><div id='m_start'> M Start Line: 30</div><div id='m_end'> M End Line: 78</div><div id='n_start'> N Start Line: 25</div><div id='n_end'> N End Line: 74</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        Test TRPO with CartPole environment (discrete action spaces)
        
        seed_manager<a id="change">: SeedManager = SeedManager(0</a><a id="change">)</a>
        <a id="change">seed_manager.set_seed_for_libraries()</a>

        env = gym.make("CartPole-v0")
        env.action_space.seed(seed_manager.seed)

        evaluation_env: Env = copy.deepcopy(env)

        model: TRPO = self.create_trpo(env, seed_manager)

        model.learn(
            num_epochs=3,
            batch_size=100,
            model_saving_interval=100,
            output_dir="/tmp/rl_replicas_tests/trpo-"
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed_manager.seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(21.0, 0.01)</code></pre><h3>After Change</h3><pre><code class='java'>
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(21.0, 0.01)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yamatokataoka/reinforcement-learning-replications/commit/61d5a71b19caad93316246cb1a4607a47c058ce9#diff-1dbe027c40a154ba85006ff8c54cf8b9f019408b33206657b296da56d84d2090L27' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8153447</div><div id='project'> Project Name: yamatokataoka/reinforcement-learning-replications</div><div id='commit'> Commit Name: 61d5a71b19caad93316246cb1a4607a47c058ce9</div><div id='time'> Time: 2022-08-19</div><div id='author'> Author: 34284486+yamatokataoka@users.noreply.github.com</div><div id='file'> File Name: tests/integration_tests/test_trpo.py</div><div id='m_class'> M Class Name: TestTRPO</div><div id='n_method'> N Class Name: TestTRPO</div><div id='m_method'> M Method Name: test_trpo_with_cartpole(2)</div><div id='n_method'> N Method Name: test_trpo_with_cartpole(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/integration_tests/test_trpo.py</div><div id='n_file'> N File Name: tests/integration_tests/test_trpo.py</div><div id='m_start'> M Start Line: 31</div><div id='m_end'> M End Line: 49</div><div id='n_start'> N Start Line: 26</div><div id='n_end'> N End Line: 45</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        Test PPO with Pendulum environment (continuous action spaces)
        
        seed_manager<a id="change">: SeedManager = SeedManager(0</a><a id="change">)</a>
        <a id="change">seed_manager.set_seed_for_libraries()</a>

        env = gym.make("Pendulum-v1")
        env.action_space.seed(seed_manager.seed)

        evaluation_env: Env = copy.deepcopy(env)

        model: PPO = self.create_ppo(env, seed_manager)

        model.learn(
            num_epochs=3,
            batch_size=100,
            model_saving_interval=100,
            output_dir="/tmp/rl_replicas_tests/ppo-"
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed_manager.seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(-876.280, 0.01)</code></pre><h3>After Change</h3><pre><code class='java'>
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(-876.280, 0.01)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yamatokataoka/reinforcement-learning-replications/commit/61d5a71b19caad93316246cb1a4607a47c058ce9#diff-c643c871d5fdd65c42e1672673d936f8a689d6b6173bcc4d1ed5b49d11f6d4bfL54' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8153440</div><div id='project'> Project Name: yamatokataoka/reinforcement-learning-replications</div><div id='commit'> Commit Name: 61d5a71b19caad93316246cb1a4607a47c058ce9</div><div id='time'> Time: 2022-08-19</div><div id='author'> Author: 34284486+yamatokataoka@users.noreply.github.com</div><div id='file'> File Name: tests/integration_tests/test_ppo.py</div><div id='m_class'> M Class Name: TestPPO</div><div id='n_method'> N Class Name: TestPPO</div><div id='m_method'> M Method Name: test_ppo_with_pendulum(2)</div><div id='n_method'> N Method Name: test_ppo_with_pendulum(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/integration_tests/test_ppo.py</div><div id='n_file'> N File Name: tests/integration_tests/test_ppo.py</div><div id='m_start'> M Start Line: 58</div><div id='m_end'> M End Line: 76</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 69</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        Test VPG with CartPole environment (discrete action spaces)
        
        seed_manager<a id="change">: SeedManager = SeedManager(0</a><a id="change">)</a>
        <a id="change">seed_manager.set_seed_for_libraries()</a>

        env = gym.make("CartPole-v0")
        env.action_space.seed(seed_manager.seed)

        evaluation_env: Env = copy.deepcopy(env)

        model: VPG = self.create_vpg(env, seed_manager)

        model.learn(
            num_epochs=3,
            batch_size=100,
            model_saving_interval=100,
            output_dir="/tmp/rl_replicas_tests/vpg-"
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed_manager.seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(18.0, 0.01)</code></pre><h3>After Change</h3><pre><code class='java'>
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(18.0, 0.01)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yamatokataoka/reinforcement-learning-replications/commit/61d5a71b19caad93316246cb1a4607a47c058ce9#diff-1b0e813e38d2d530485c451190dc45d99a8ca96c643615481625c9a17c30104bL26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8153441</div><div id='project'> Project Name: yamatokataoka/reinforcement-learning-replications</div><div id='commit'> Commit Name: 61d5a71b19caad93316246cb1a4607a47c058ce9</div><div id='time'> Time: 2022-08-19</div><div id='author'> Author: 34284486+yamatokataoka@users.noreply.github.com</div><div id='file'> File Name: tests/integration_tests/test_vpg.py</div><div id='m_class'> M Class Name: TestVPG</div><div id='n_method'> N Class Name: TestVPG</div><div id='m_method'> M Method Name: test_vpg_with_cartpole(2)</div><div id='n_method'> N Method Name: test_vpg_with_cartpole(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/integration_tests/test_vpg.py</div><div id='n_file'> N File Name: tests/integration_tests/test_vpg.py</div><div id='m_start'> M Start Line: 30</div><div id='m_end'> M End Line: 48</div><div id='n_start'> N Start Line: 25</div><div id='n_end'> N End Line: 44</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        Test PPO with CartPole environment (discrete action spaces)
        
        seed_manager<a id="change">: SeedManager = SeedManager(0</a><a id="change">)</a>
        <a id="change">seed_manager.set_seed_for_libraries()</a>

        env = gym.make("CartPole-v0")
        env.action_space.seed(seed_manager.seed)

        evaluation_env: Env = copy.deepcopy(env)

        model: PPO = self.create_ppo(env, seed_manager)

        model.learn(
            num_epochs=3,
            batch_size=100,
            model_saving_interval=100,
            output_dir="/tmp/rl_replicas_tests/ppo-"
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed_manager.seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(52.0, 0.01)</code></pre><h3>After Change</h3><pre><code class='java'>
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(52.0, 0.01)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yamatokataoka/reinforcement-learning-replications/commit/61d5a71b19caad93316246cb1a4607a47c058ce9#diff-c643c871d5fdd65c42e1672673d936f8a689d6b6173bcc4d1ed5b49d11f6d4bfL26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8153442</div><div id='project'> Project Name: yamatokataoka/reinforcement-learning-replications</div><div id='commit'> Commit Name: 61d5a71b19caad93316246cb1a4607a47c058ce9</div><div id='time'> Time: 2022-08-19</div><div id='author'> Author: 34284486+yamatokataoka@users.noreply.github.com</div><div id='file'> File Name: tests/integration_tests/test_ppo.py</div><div id='m_class'> M Class Name: TestPPO</div><div id='n_method'> N Class Name: TestPPO</div><div id='m_method'> M Method Name: test_ppo_with_cartpole(2)</div><div id='n_method'> N Method Name: test_ppo_with_cartpole(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/integration_tests/test_ppo.py</div><div id='n_file'> N File Name: tests/integration_tests/test_ppo.py</div><div id='m_start'> M Start Line: 30</div><div id='m_end'> M End Line: 48</div><div id='n_start'> N Start Line: 25</div><div id='n_end'> N End Line: 44</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        Test TD3 with Pendulum environment (continuous action spaces)
        
        seed_manager<a id="change">: SeedManager = SeedManager(0</a><a id="change">)</a>
        <a id="change">seed_manager.set_seed_for_libraries()</a>

        env = gym.make("Pendulum-v1")
        env.action_space.seed(seed_manager.seed)

        evaluation_env: Env = copy.deepcopy(env)

        observation_size: int = env.observation_space.shape[0]
        action_size: int = env.action_space.shape[0]

        policy_network: nn.Module = MLP(
            sizes=[observation_size] + [256, 256] + [action_size],
            activation_function=nn.ReLU,
            output_activation_function=nn.Tanh,
        )

        q_function_learning_rate: float = 1e-3
        q_function_network_sizes = [observation_size + action_size] + [256, 256] + [1]
        q_function_1_network: nn.Module = MLP(
            sizes=q_function_network_sizes, activation_function=nn.ReLU
        )
        q_function_2_network: nn.Module = MLP(
            sizes=q_function_network_sizes, activation_function=nn.ReLU
        )

        model: TD3 = TD3(
            DeterministicPolicy(
                network=policy_network,
                optimizer=torch.optim.Adam(policy_network.parameters(), lr=1e-3),
            ),
            RandomPolicy(env.action_space),
            QFunction(
                network=q_function_1_network,
                optimizer=torch.optim.Adam(
                    q_function_1_network.parameters(), lr=q_function_learning_rate
                ),
            ),
            QFunction(
                network=q_function_2_network,
                optimizer=torch.optim.Adam(
                    q_function_2_network.parameters(), lr=q_function_learning_rate
                ),
            ),
            env,
            BatchSampler(env, seed_manager.seed, is_continuous=True),
            ReplayBuffer(int(1e6)),
            Evaluator(seed_manager.seed),
        )

        model.learn(
            num_epochs=6,
            num_start_steps=100,
            num_steps_before_update=200,
            evaluation_interval=100,
            model_saving_interval=100,
            output_dir="/tmp/rl_replicas_tests/td3-"
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed_manager.seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(-1374.495, 0.01)</code></pre><h3>After Change</h3><pre><code class='java'>
            + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"),
        )

        evaluator<a id="change">: Evaluator = </a><a id="change">Evaluator(</a>seed<a id="change">)</a>
        episode_returns: List[float]
        episode_returns, _ = evaluator.evaluate(model.policy, evaluation_env, 1)

        assert episode_returns[0] == approx(-1374.495, 0.01)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yamatokataoka/reinforcement-learning-replications/commit/61d5a71b19caad93316246cb1a4607a47c058ce9#diff-d341a41189b67110a49ffb08f156783c68800180fafed5d8885d0296172341fdL26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8153443</div><div id='project'> Project Name: yamatokataoka/reinforcement-learning-replications</div><div id='commit'> Commit Name: 61d5a71b19caad93316246cb1a4607a47c058ce9</div><div id='time'> Time: 2022-08-19</div><div id='author'> Author: 34284486+yamatokataoka@users.noreply.github.com</div><div id='file'> File Name: tests/integration_tests/test_td3.py</div><div id='m_class'> M Class Name: TestTD3</div><div id='n_method'> N Class Name: TestTD3</div><div id='m_method'> M Method Name: test_td3_with_pendulum(2)</div><div id='n_method'> N Method Name: test_td3_with_pendulum(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/integration_tests/test_td3.py</div><div id='n_file'> N File Name: tests/integration_tests/test_td3.py</div><div id='m_start'> M Start Line: 30</div><div id='m_end'> M End Line: 90</div><div id='n_start'> N Start Line: 25</div><div id='n_end'> N End Line: 86</div><BR>