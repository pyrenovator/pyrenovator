<html><h3>Pattern ID :40200
</h3><img src='114188495.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        loss = self.cal_loss(outputs, targets, output_lengths, target_lengths)

        predicts = self.forward(inputs, input_lengths)
        predicts<a id="change"> = </a>[self.text_process.int2text(sent) for sent in predicts]
        targets = [self.text_process.int2text(sent) for sent in targets]

        list_wer<a id="change"> = </a>torch.tensor(
            [self.cal_wer(i, j).item() for i, j in zip(predicts, targets)]
        )
        wer<a id="change"> = </a><a id="change">torch.mean(</a>list_wer<a id="change">)</a>

        if batch_idx % 100 == 0:
            self.log_output(predicts[0], targets[0], wer)
</code></pre><h3>After Change</h3><pre><code class='java'>
        outputs, output_lengths = self(inputs, input_lengths)

        loss = self.criterion(
            <a id="change">outputs.permute(1</a>, <a id="change">0</a>, <a id="change">2</a><a id="change">)</a>, targets_ctc, output_lengths, target_lengths
        )

        self.log("test loss", loss)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/manhph2211/vistt/commit/742be9424d91058a3c3e25adc4db742534fffab3#diff-f1b082241219fb0667a5be1d3cebcfabcdd9c3c48ba0ce5ec9a10fce9cd7c01aL105' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 114188495</div><div id='project'> Project Name: manhph2211/vistt</div><div id='commit'> Commit Name: 742be9424d91058a3c3e25adc4db742534fffab3</div><div id='time'> Time: 2022-08-30</div><div id='author'> Author: manhph5@vingroup.net</div><div id='file'> File Name: VASR/local/src/engine/trainer.py</div><div id='m_class'> M Class Name: ConformerModule</div><div id='n_method'> N Class Name: ConformerModule</div><div id='m_method'> M Method Name: test_step(3)</div><div id='n_method'> N Method Name: test_step(3)</div><div id='m_parent_class'> M Parent Class: BaseModel</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: VASR/local/src/engine/trainer.py</div><div id='n_file'> N File Name: VASR/local/src/engine/trainer.py</div><div id='m_start'> M Start Line: 105</div><div id='m_end'> M End Line: 136</div><div id='n_start'> N Start Line: 128</div><div id='n_end'> N End Line: 148</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        loss = self.cal_loss(outputs, targets, output_lengths, target_lengths)

        predicts = self.forward(inputs, input_lengths)
        predicts<a id="change"> = </a>[self.text_process.int2text(sent) for sent in predicts]
        targets = [self.text_process.int2text(sent) for sent in targets]

        list_wer<a id="change"> = </a>torch.tensor(
            [self.cal_wer(i, j).item() for i, j in zip(predicts, targets)]
        )
        wer<a id="change"> = </a><a id="change">torch.mean(</a>list_wer<a id="change">)</a>

        if batch_idx % 100 == 0:
            self.log_output(predicts[0], targets[0], wer)
</code></pre><h3>After Change</h3><pre><code class='java'>
        outputs, output_lengths = self(inputs, input_lengths)

        loss = self.criterion(
            <a id="change">outputs.permute(1</a>, <a id="change">0</a>, <a id="change">2</a><a id="change">)</a>, targets_ctc, output_lengths, target_lengths
        )

        self.log("test loss", loss)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/manhph2211/vistt/commit/742be9424d91058a3c3e25adc4db742534fffab3#diff-f1b082241219fb0667a5be1d3cebcfabcdd9c3c48ba0ce5ec9a10fce9cd7c01aL72' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 114188383</div><div id='project'> Project Name: manhph2211/vistt</div><div id='commit'> Commit Name: 742be9424d91058a3c3e25adc4db742534fffab3</div><div id='time'> Time: 2022-08-30</div><div id='author'> Author: manhph5@vingroup.net</div><div id='file'> File Name: VASR/local/src/engine/trainer.py</div><div id='m_class'> M Class Name: ConformerModule</div><div id='n_method'> N Class Name: ConformerModule</div><div id='m_method'> M Method Name: validation_step(3)</div><div id='n_method'> N Method Name: validation_step(3)</div><div id='m_parent_class'> M Parent Class: BaseModel</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: VASR/local/src/engine/trainer.py</div><div id='n_file'> N File Name: VASR/local/src/engine/trainer.py</div><div id='m_start'> M Start Line: 72</div><div id='m_end'> M End Line: 103</div><div id='n_start'> N Start Line: 106</div><div id='n_end'> N End Line: 126</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        frequencies = librosa.fft_frequencies(sr=sample_rate, n_fft=n_fft)
        a_weighting = librosa.A_weighting(frequencies)[None, :, None]
        a_weighting = torch.from_numpy(a_weighting.astype(np.float32)).to(audio.device)
    loudness<a id="change"> = </a>power_db + a_weighting

    &#47&#47 Set dynamic range.
    loudness -= ref_db
    loudness<a id="change"> = </a>torch.clamp(loudness, min=-range_db)

    &#47&#47 Average over frequency bins.
    loudness<a id="change"> = </a><a id="change">torch.mean(</a>loudness<a id="change">, dim=1)</a>

    &#47&#47 Remove temporary batch dimension.
    loudness = loudness[0] if is_1d else loudness
</code></pre><h3>After Change</h3><pre><code class='java'>
    hop_length = sample_rate // frame_rate
    s = torch.stft(audio, n_fft=n_fft, hop_length=hop_length, return_complex=True, center=center)
    &#47&#47 batch, frequency_bins, n_frames
    s = <a id="change">s.permute(0</a>, <a id="change">2</a>, <a id="change">1</a><a id="change">)</a>
    if a_weighting is None:
        frequencies = librosa.fft_frequencies(sr=sample_rate, n_fft=n_fft)
        a_weighting = librosa.A_weighting(frequencies)
        a_weighting = torch.from_numpy(a_weighting.astype(np.float32)).to(audio.device)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hyakuchiki/realtimeddsp/commit/18a14dbae33c975de26b9dcd41d02e5a59d0d5f9#diff-7feaabfc7b8853c68cdbb29906c1b84649e4903e97c946b9cfe902e2cee7f010L128' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 114188482</div><div id='project'> Project Name: hyakuchiki/realtimeddsp</div><div id='commit'> Commit Name: 18a14dbae33c975de26b9dcd41d02e5a59d0d5f9</div><div id='time'> Time: 2022-05-16</div><div id='author'> Author: naotakemasuda@g.ecc.u-tokyo.ac.jp</div><div id='file'> File Name: diffsynth/spectral.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: compute_loudness(8)</div><div id='n_method'> N Method Name: compute_loudness(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: diffsynth/spectral.py</div><div id='n_file'> N File Name: diffsynth/spectral.py</div><div id='m_start'> M Start Line: 149</div><div id='m_end'> M End Line: 170</div><div id='n_start'> N Start Line: 164</div><div id='n_end'> N End Line: 171</div><BR>