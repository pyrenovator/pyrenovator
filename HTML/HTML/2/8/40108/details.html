<html><h3>Pattern ID :40108
</h3><img src='113945034.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 invert noise for bright regions (bright regions are considered being on average &gt; 0.33 * 255)
        generated_noise = generated_noise.int()
        bright_regions = img.sum(1) &gt; brightness_threshold * img.shape[1]
        <a id="change">for </a>ch in range(img.shape[1])<a id="change">:
            </a>gnch<a id="change"> = </a>generated_noise[:, ch]
            gnch[bright_regions]<a id="change"> = </a>gnch[bright_regions] * -1
            generated_noise[:, ch] = gnch

        anom = (anom.int() + generated_noise).clamp(0, 255).byte()</code></pre><h3>After Change</h3><pre><code class='java'>
        diff = ((anom.int() + generated_noise).clamp(0, 255) - anom.int())
        diff = diff.reshape(anom.size(0), -1).sum(1).float().div(np.prod(anom.shape)).abs()
        diffi = ((anom.int() - generated_noise).clamp(0, 255) - anom.int())
        diffi = <a id="change">diffi.reshape(anom.size(0), -1).sum(1).float()</a>.div(np.prod(anom.shape)).abs()
        inv<a id="change"> = </a>[i for i, (d, di) in enumerate(zip(diff, diffi)) if d &lt; invert_threshold and di &gt; d]
        generated_noise[inv]<a id="change"> = </a><a id="change">-generated_noise[inv]</a>

        anom = (anom.int() + generated_noise).clamp(0, 255).byte()

        t = 1 if not hasattr(ds, &quotanomalous_label&quot) else ds.anomalous_label  &#47&#47 target transform has already been applied</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/liznerski/fcdd/commit/d110aa8b141dc13f47156da913a6b4f9d64ddc74#diff-fb7d9650a48b1de740043527c5d5e928e02fb69b57694006eafa311d213e906cL139' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113945034</div><div id='project'> Project Name: liznerski/fcdd</div><div id='commit'> Commit Name: d110aa8b141dc13f47156da913a6b4f9d64ddc74</div><div id='time'> Time: 2020-10-12</div><div id='author'> Author: p_liznersk13@cs.uni-kl.de</div><div id='file'> File Name: python/fcdd/datasets/online_superviser.py</div><div id='m_class'> M Class Name: OnlineSuperviser</div><div id='n_method'> N Class Name: OnlineSuperviser</div><div id='m_method'> M Method Name: __malformed_normal(8)</div><div id='n_method'> N Method Name: __malformed_normal(8)</div><div id='m_parent_class'> M Parent Class: ImgGTTargetTransform</div><div id='n_parent_class'> N Parent Class: ImgGTTargetTransform</div><div id='m_file'> M File Name: python/fcdd/datasets/online_superviser.py</div><div id='n_file'> N File Name: python/fcdd/datasets/online_superviser.py</div><div id='m_start'> M Start Line: 139</div><div id='m_end'> M End Line: 146</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 151</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        else:
            raise ValueError(&quotThis similarity is not implemented.&quot)
        loss = list()
        <a id="change">for i</a> in range(batch_size)<a id="change">:
            </a>pos_index<a id="change"> = </a>labels == labels[i]
            pos_index[i] = 0
            neg_index = labels != labels[i]
            pos_pair_<a id="change"> = </a>sim_mat[i][pos_index]
            neg_pair_ = sim_mat[i][neg_index]

            alpha_p = torch.relu(-pos_pair_ + 1 + self.margin)</code></pre><h3>After Change</h3><pre><code class='java'>
            f"feats.size(0): {feats.size(0)} is not equal to labels.size(0): {labels.size(0)}"

        m = labels.size(0)
        mask<a id="change"> = </a><a id="change">labels.expand(m, m).t().eq(labels.expand(m, m)).float()</a>
        pos_mask = mask.triu(diagonal=1)
        neg_mask = (mask<a id="change"> - </a>1).abs_().triu(diagonal=1)
        if self.similarity == &quotdot&quot:
            sim_mat = torch.matmul(feats, torch.t(feats))
        elif self.similarity == &quotcos&quot:
            feats = F.normalize(feats)
            sim_mat = feats.mm(feats.t())
        else:
            raise ValueError(&quotThis similarity is not implemented.&quot)

        pos_pair_ = sim_mat[pos_mask == 1]
        neg_pair_<a id="change"> = </a>sim_mat[neg_mask == 1]

        alpha_p = torch.relu(-pos_pair_ + 1 + self.margin)
        alpha_n = torch.relu(neg_pair_ + self.margin)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/qianjinhao/circle-loss/commit/55a6035c552f781d6c761475f88b33b8f684fbe7#diff-ee4498af95089c1dacb3bbdedbf8cffa6eecc60617a8a1d405b07f6f81510abbL13' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113944776</div><div id='project'> Project Name: qianjinhao/circle-loss</div><div id='commit'> Commit Name: 55a6035c552f781d6c761475f88b33b8f684fbe7</div><div id='time'> Time: 2020-04-02</div><div id='author'> Author: qianjinhao@126.com</div><div id='file'> File Name: circle_loss.py</div><div id='m_class'> M Class Name: CircleLoss</div><div id='n_method'> N Class Name: CircleLoss</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: circle_loss.py</div><div id='n_file'> N File Name: circle_loss.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 40</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 38</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 invert noise for bright regions (bright regions are considered being on average &gt; 0.33 * 255)
        generated_noise = generated_noise.int()
        bright_regions = img.sum(1) &gt; brightness_threshold * img.shape[1]
        <a id="change">for ch</a> in range(img.shape[1])<a id="change">:
            </a>gnch<a id="change"> = </a>generated_noise[:, ch]
            gnch[bright_regions] = gnch[bright_regions] * -1
            generated_noise[:, ch]<a id="change"> = </a>gnch

        anom = (anom.int() + generated_noise).clamp(0, 255).byte()
</code></pre><h3>After Change</h3><pre><code class='java'>
        diff = ((anom.int() + generated_noise).clamp(0, 255) - anom.int())
        diff = diff.reshape(anom.size(0), -1).sum(1).float().div(np.prod(anom.shape)).abs()
        diffi = ((anom.int() - generated_noise).clamp(0, 255) - anom.int())
        diffi = <a id="change">diffi.reshape(anom.size(0), -1).sum(1).float()</a>.div(np.prod(anom.shape)).abs()
        inv<a id="change"> = </a>[i for i, (d, di) in enumerate(zip(diff, diffi)) if d &lt; invert_threshold and di &gt; d]
        generated_noise[inv]<a id="change"> = </a><a id="change">-generated_noise[inv]</a>

        anom = (anom.int() + generated_noise).clamp(0, 255).byte()

        t = 1 if not hasattr(ds, &quotanomalous_label&quot) else ds.anomalous_label  &#47&#47 target transform has already been applied</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/liznerski/fcdd/commit/d110aa8b141dc13f47156da913a6b4f9d64ddc74#diff-fb7d9650a48b1de740043527c5d5e928e02fb69b57694006eafa311d213e906cL133' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113945036</div><div id='project'> Project Name: liznerski/fcdd</div><div id='commit'> Commit Name: d110aa8b141dc13f47156da913a6b4f9d64ddc74</div><div id='time'> Time: 2020-10-12</div><div id='author'> Author: p_liznersk13@cs.uni-kl.de</div><div id='file'> File Name: python/fcdd/datasets/online_superviser.py</div><div id='m_class'> M Class Name: OnlineSuperviser</div><div id='n_method'> N Class Name: OnlineSuperviser</div><div id='m_method'> M Method Name: __malformed_normal(8)</div><div id='n_method'> N Method Name: __malformed_normal(8)</div><div id='m_parent_class'> M Parent Class: ImgGTTargetTransform</div><div id='n_parent_class'> N Parent Class: ImgGTTargetTransform</div><div id='m_file'> M File Name: python/fcdd/datasets/online_superviser.py</div><div id='n_file'> N File Name: python/fcdd/datasets/online_superviser.py</div><div id='m_start'> M Start Line: 139</div><div id='m_end'> M End Line: 146</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 151</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 masked by the missing entries
        &#47&#47 note, different batch may contain different number of real entities
        tensor_list = []
        <a id="change">for </a>i, <a id="change">batch</a> in enumerate(out)<a id="change">:
            </a>mean_entity<a id="change"> = </a>0.
            real_number = real_number_tensor[i]
            real_number = real_number if real_number != 0 else 1
            for j, entity in enumerate(batch):
                if j &gt;= real_number_tensor[i]:
                    break        
                mean_entity = mean_entity + entity
            mean_entity<a id="change"> = </a>mean_entity / (real_number)
            tensor_list.append(mean_entity.reshape(1, -1))
        tensor_mean = torch.cat(tensor_list, dim=0)
        print(&quottensor_mean:&quot, tensor_mean) if debug else None</code></pre><h3>After Change</h3><pre><code class='java'>
        print(&quotentity_num:&quot, entity_num) if debug else None

        &#47&#47 generate the mask for transformer
        mask = <a id="change">torch.arange(0, self.max_entities).float()</a>
        mask = mask.repeat(batch_size, 1)
        mask<a id="change"> = </a>mask &lt; entity_num.unsqueeze(dim=1)

        print(&quotmask:&quot, mask) if debug else None
        print(&quotmask.shape:&quot, mask.shape) if debug else None

        &#47&#47 mask: [batch_size, max_entities]
        device = next(self.parameters()).device
        mask = mask.to(device)

        &#47&#47 assert the input shape is : batch_seq_size x entities_size x embeding_size
        &#47&#47 note: because the feature size of entity is not equal to 256, so it can not fed into transformer directly.
        &#47&#47 thus, we add a embedding layer to transfer it to right size.
        &#47&#47 x is batch_entities_tensor (dim = 3). Shape: batch_seq_size x entities_size x embeding_size
        x = self.embedd(x)
        print(&quotx.shape:&quot, x.shape) if debug else None

        &#47&#47 mask for transformer need a special format
        mask_seq_len = mask.shape[-1]
        tran_mask = mask.unsqueeze(1)

        &#47&#47 tran_mask: [batch_seq_size x max_entities x max_entities]
        tran_mask = tran_mask.repeat(1, mask_seq_len, 1)

        &#47&#47 out: [batch_seq_size x entities_size x embeding_size]
        out = self.transformer(x, mask=tran_mask)
        print(&quotout.shape:&quot, out.shape) if debug else None

        &#47&#47 entity_embeddings: [batch_seq_size x entities_size x conv1_output_size]
        entity_embeddings = F.relu(self.conv1(F.relu(out).transpose(1, 2))).transpose(1, 2)
        print(&quotentity_embeddings.shape:&quot, entity_embeddings.shape) if debug else None

        &#47&#47 AlphaStar: The mean of the transformer output across across the units (masked by the missing entries) 
        &#47&#47 is fed through a linear layer of size 256 and a ReLU to yield `embedded_entity`
        masked_out = out<a id="change"> * </a>mask.unsqueeze(2)

        &#47&#47 sum over across the units
        &#47&#47 masked_out: [batch_seq_size x entities_size x embeding_size]
        &#47&#47 z: [batch_size, embeding_size]
        z<a id="change"> = </a>masked_out.sum(dim=1, keepdim=False)

        &#47&#47 here we should dived by the entity_num, not the cls.max_entities
        &#47&#47 z: [batch_size, embeding_size]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/liuruoze/mini-alphastar/commit/612d42a7bf5ef827e1e919198d839fce106155cd#diff-71869e70f9cb835282d541d2d3529d25b6ed6795c79bc770e860e9318619f6b1L717' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113945027</div><div id='project'> Project Name: liuruoze/mini-alphastar</div><div id='commit'> Commit Name: 612d42a7bf5ef827e1e919198d839fce106155cd</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: liuruoze@163.com</div><div id='file'> File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_class'> M Class Name: EntityEncoder</div><div id='n_method'> N Class Name: EntityEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='n_file'> N File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_start'> M Start Line: 721</div><div id='m_end'> M End Line: 758</div><div id='n_start'> N Start Line: 716</div><div id='n_end'> N End Line: 778</div><BR>