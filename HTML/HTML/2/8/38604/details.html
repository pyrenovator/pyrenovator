<html><h3>Pattern ID :38604
</h3><img src='110424070.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                )

    def _reduce_and_log_stats(self, logging_outputs, sample_size):
        if logging_outputs is None or <a id="change">len(logging_outputs) == 0</a>:
            return <a id="change">{</a>"sample_size": sample_size<a id="change">}</a>
        with metrics.aggregate() as agg:
            &#47&#47 convert logging_outputs to CPU to avoid unnecessary
            &#47&#47 device-to-host transfers in reduce_metrics
            logging_outputs = utils.apply_to_sample(</code></pre><h3>After Change</h3><pre><code class='java'>
    def _reduce_and_log_stats(self, logging_outputs, sample_size, grad_norm=None):
        if grad_norm is not None:
            metrics.log_speed("ups", 1., priority=100, round=2)
            <a id="change">metrics.log_scalar("gnorm"</a>, grad_norm<a id="change">, priority=400, round=3)</a>
            if self.args.clip_norm &gt; 0:
                <a id="change">metrics.log_scalar(
                    "clip"</a>,
                    torch.where(
                        grad_norm &gt; self.args.clip_norm,
                        grad_norm.new_tensor(100),
                        grad_norm.new_tensor(0),
                    )<a id="change">,
                    priority=500,
                    round=1,
                )</a>

        with metrics.aggregate() as agg:
            if logging_outputs is not None:
                self.task.reduce_metrics(logging_outputs, self.get_criterion())</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/mohammadkhalifa/fairseq-tagging/commit/5028ed1b6bedd526dee27ea731284f43e87303f0#diff-1d9c528283eebce84124f45bd2f04e9c1b50dc4d3f63e867776eb89dc55dd95fL692' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110424070</div><div id='project'> Project Name: mohammadkhalifa/fairseq-tagging</div><div id='commit'> Commit Name: 5028ed1b6bedd526dee27ea731284f43e87303f0</div><div id='time'> Time: 2020-03-11</div><div id='author'> Author: myleott@fb.com</div><div id='file'> File Name: fairseq/trainer.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: _reduce_and_log_stats(4)</div><div id='n_method'> N Method Name: _reduce_and_log_stats(3)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: fairseq/trainer.py</div><div id='n_file'> N File Name: fairseq/trainer.py</div><div id='m_start'> M Start Line: 696</div><div id='m_end'> M End Line: 706</div><div id='n_start'> N Start Line: 692</div><div id='n_end'> N End Line: 713</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                )

    def _reduce_and_log_stats(self, logging_outputs, sample_size):
        if logging_outputs is None or <a id="change">len(logging_outputs) == 0</a>:
            return <a id="change">{</a>"sample_size": sample_size<a id="change">}</a>
        with metrics.aggregate() as agg:
            &#47&#47 convert logging_outputs to CPU to avoid unnecessary
            &#47&#47 device-to-host transfers in reduce_metrics
            logging_outputs = utils.apply_to_sample(</code></pre><h3>After Change</h3><pre><code class='java'>
    def _reduce_and_log_stats(self, logging_outputs, sample_size, grad_norm=None):
        if grad_norm is not None:
            metrics.log_speed("ups", 1., priority=100, round=2)
            <a id="change">metrics.log_scalar("gnorm"</a>, grad_norm<a id="change">, priority=400, round=3)</a>
            if self.args.clip_norm &gt; 0:
                <a id="change">metrics.log_scalar(
                    "clip"</a>,
                    torch.where(
                        grad_norm &gt; self.args.clip_norm,
                        grad_norm.new_tensor(100),
                        grad_norm.new_tensor(0),
                    )<a id="change">,
                    priority=500,
                    round=1,
                )</a>

        with metrics.aggregate() as agg:
            if logging_outputs is not None:
                self.task.reduce_metrics(logging_outputs, self.get_criterion())</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mohammadkhalifa/fairseq-tagging/commit/5028ed1b6bedd526dee27ea731284f43e87303f0#diff-1d9c528283eebce84124f45bd2f04e9c1b50dc4d3f63e867776eb89dc55dd95fL695' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110424071</div><div id='project'> Project Name: mohammadkhalifa/fairseq-tagging</div><div id='commit'> Commit Name: 5028ed1b6bedd526dee27ea731284f43e87303f0</div><div id='time'> Time: 2020-03-11</div><div id='author'> Author: myleott@fb.com</div><div id='file'> File Name: fairseq/trainer.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: _reduce_and_log_stats(4)</div><div id='n_method'> N Method Name: _reduce_and_log_stats(3)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: fairseq/trainer.py</div><div id='n_file'> N File Name: fairseq/trainer.py</div><div id='m_start'> M Start Line: 696</div><div id='m_end'> M End Line: 706</div><div id='n_start'> N Start Line: 692</div><div id='n_end'> N End Line: 713</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            metrics.log_scalar(
                f"{split}_acc", acc_sum / sample_size, sample_size, round=3
            )
            if <a id="change">probs.size(-1) == 2</a>:
                &#47&#47 binary classification task, add auc score
                targets = torch.cat(
                    [log.get("target", 0) for log in logging_outputs], dim=0
                )
                df = pd.DataFrame(
                    <a id="change">{</a>"probs": probs[:, 1].cpu(), "targets": targets.cpu()<a id="change">}</a>
                )
                auc = roc_auc_score(df["targets"], df["probs"])
                metrics.log_scalar(f"{split}_auc", auc, sample_size, round=3)
</code></pre><h3>After Change</h3><pre><code class='java'>
            metrics.log_scalar(
                f"{split}_pre", precision_score(targets, preds), round=3
            )
            <a id="change">metrics.log_scalar(
                f"{split}_rec"</a>, recall_score(targets, preds)<a id="change">, round=3
            )</a>
            <a id="change">metrics.log_scalar(
                f"{split}_f1"</a>, f1_score(targets, preds), sample_size<a id="change">, round=3
            )</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/dptech-corp/uni-mol/commit/2df26a3c3209f52e4d248de5452b68fa0d8dcd9c#diff-cb6fac66af7b1e02215320a2e2fd812e1c354c5affcaf591319069cde9f1d549L267' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110424074</div><div id='project'> Project Name: dptech-corp/uni-mol</div><div id='commit'> Commit Name: 2df26a3c3209f52e4d248de5452b68fa0d8dcd9c</div><div id='time'> Time: 2022-09-08</div><div id='author'> Author: 2015201981@ruc.edu.cn</div><div id='file'> File Name: unimol/losses/cross_entropy.py</div><div id='m_class'> M Class Name: FinetuneCrossEntropyPocketLoss</div><div id='n_method'> N Class Name: FinetuneCrossEntropyPocketLoss</div><div id='m_method'> M Method Name: reduce_metrics(2)</div><div id='n_method'> N Method Name: reduce_metrics(2)</div><div id='m_parent_class'> M Parent Class: FinetuneCrossEntropyLoss</div><div id='n_parent_class'> N Parent Class: FinetuneCrossEntropyLoss</div><div id='m_file'> M File Name: unimol/losses/cross_entropy.py</div><div id='n_file'> N File Name: unimol/losses/cross_entropy.py</div><div id='m_start'> M Start Line: 270</div><div id='m_end'> M End Line: 293</div><div id='n_start'> N Start Line: 270</div><div id='n_end'> N End Line: 297</div><BR>