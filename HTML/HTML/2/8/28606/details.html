<html><h3>Pattern ID :28606
</h3><img src='84475848.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel, durations, pitch, energy = self.phone2mel(phones, speaker_embedding=self.speaker_embedding, return_duration_pitch_energy=True)
            mel = mel.transpose(0, 1)
            wave = <a id="change">self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0</a><a id="change">)</a>
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd
            from Utility.utils import cumsum_durations</code></pre><h3>After Change</h3><pre><code class='java'>
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel, durations, pitch, energy = self.phone2mel(phones, speaker_embedding=self.speaker_embedding, return_duration_pitch_energy=True)
            mel = mel.transpose(0, 1)
            wave = <a id="change">self.mel2wav(</a>mel<a id="change">)</a>
        if view:
            from Utility.utils import cumsum_durations
            fig, ax = plt.subplots(nrows=2, ncols=1)
            ax[0].plot(wave.cpu().numpy())</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 8</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/3e54c9c27cbf77aa5df69bb7ab46dda0eff92736#diff-fa9b964a51baaa8308650d43e48b873abc13a67e1583252e13d4d9c3b40614f8L35' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84475848</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 3e54c9c27cbf77aa5df69bb7ab46dda0eff92736</div><div id='time'> Time: 2021-08-10</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/LJSpeech_FastSpeech2.py</div><div id='m_class'> M Class Name: LJSpeech_FastSpeech2</div><div id='n_method'> N Class Name: LJSpeech_FastSpeech2</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/LJSpeech_FastSpeech2.py</div><div id='n_file'> N File Name: InferenceInterfaces/LJSpeech_FastSpeech2.py</div><div id='m_start'> M Start Line: 35</div><div id='m_end'> M End Line: 36</div><div id='n_start'> N Start Line: 37</div><div id='n_end'> N End Line: 38</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel, durations, pitch, energy = self.phone2mel(phones, speaker_embedding=self.speaker_embedding, return_duration_pitch_energy=True)
            mel = mel.transpose(0, 1)
            wave = <a id="change">self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0</a><a id="change">)</a>
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd
            from Utility.utils import cumsum_durations</code></pre><h3>After Change</h3><pre><code class='java'>
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel, durations, pitch, energy = self.phone2mel(phones, speaker_embedding=self.speaker_embedding, return_duration_pitch_energy=True)
            mel = mel.transpose(0, 1)
            wave = <a id="change">self.mel2wav(</a>mel<a id="change">)</a>
        if view:
            from Utility.utils import cumsum_durations
            fig, ax = plt.subplots(nrows=2, ncols=1)
            ax[0].plot(wave.cpu().numpy())</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/3e54c9c27cbf77aa5df69bb7ab46dda0eff92736#diff-35a7e7c3ad111bf67fe8f37667065dfd135e3ee8dbb86ccf6bfd92b5bcb1de10L30' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84475841</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 3e54c9c27cbf77aa5df69bb7ab46dda0eff92736</div><div id='time'> Time: 2021-08-10</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/Thorsten_FastSpeech2.py</div><div id='m_class'> M Class Name: Thorsten_FastSpeech2</div><div id='n_method'> N Class Name: Thorsten_FastSpeech2</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/Thorsten_FastSpeech2.py</div><div id='n_file'> N File Name: InferenceInterfaces/Thorsten_FastSpeech2.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 35</div><div id='n_start'> N Start Line: 36</div><div id='n_end'> N End Line: 37</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0, 1)
            wave = <a id="change">self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0</a><a id="change">)</a>
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd
            fig, ax = plt.subplots(nrows=2, ncols=1)</code></pre><h3>After Change</h3><pre><code class='java'>
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0, 1)
            wave = <a id="change">self.mel2wav(</a>mel<a id="change">)</a>
        if view:
            fig, ax = plt.subplots(nrows=2, ncols=1)
            ax[0].plot(wave.cpu().numpy())
            lbd.specshow(mel.cpu().numpy(), ax=ax[1], sr=16000, cmap=&quotGnBu&quot, y_axis=&quotmel&quot, x_axis=&quottime&quot, hop_length=256)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/3e54c9c27cbf77aa5df69bb7ab46dda0eff92736#diff-314d55f66734eaf0e2ec05893e8a3f50c54dbdd66e15dc6cc990c5b43f72b5f5L27' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84475842</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 3e54c9c27cbf77aa5df69bb7ab46dda0eff92736</div><div id='time'> Time: 2021-08-10</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/Thorsten_Tacotron2.py</div><div id='m_class'> M Class Name: Thorsten_Tacotron2</div><div id='n_method'> N Class Name: Thorsten_Tacotron2</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/Thorsten_Tacotron2.py</div><div id='n_file'> N File Name: InferenceInterfaces/Thorsten_Tacotron2.py</div><div id='m_start'> M Start Line: 30</div><div id='m_end'> M End Line: 31</div><div id='n_start'> N Start Line: 31</div><div id='n_end'> N End Line: 32</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0, 1)
            wave = <a id="change">self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0</a><a id="change">)</a>
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd
            fig, ax = plt.subplots(nrows=2, ncols=1)</code></pre><h3>After Change</h3><pre><code class='java'>
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0, 1)
            wave = <a id="change">self.mel2wav(</a>mel<a id="change">)</a>
        if view:
            fig, ax = plt.subplots(nrows=2, ncols=1)
            ax[0].plot(wave.cpu().numpy())
            lbd.specshow(mel.cpu().numpy(), ax=ax[1], sr=16000, cmap=&quotGnBu&quot, y_axis=&quotmel&quot, x_axis=&quottime&quot, hop_length=256)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/c309bced25efcaf67b20f1b1897d0ad43edd7ecd#diff-9831c769c510dc412d884a121bb1a93e1cb33185d739dd59c7247f4eda1c3160L29' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84475843</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: c309bced25efcaf67b20f1b1897d0ad43edd7ecd</div><div id='time'> Time: 2021-08-10</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/LJSpeech_Tacotron2.py</div><div id='m_class'> M Class Name: LJSpeech_Tacotron2</div><div id='n_method'> N Class Name: LJSpeech_Tacotron2</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/LJSpeech_Tacotron2.py</div><div id='n_file'> N File Name: InferenceInterfaces/LJSpeech_Tacotron2.py</div><div id='m_start'> M Start Line: 32</div><div id='m_end'> M End Line: 33</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 34</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0, 1)
            wave = <a id="change">self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0</a><a id="change">)</a>
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd
            fig, ax = plt.subplots(nrows=2, ncols=1)</code></pre><h3>After Change</h3><pre><code class='java'>
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0, 1)
            wave = <a id="change">self.mel2wav(</a>mel<a id="change">)</a>
        if view:
            fig, ax = plt.subplots(nrows=2, ncols=1)
            ax[0].plot(wave.cpu().numpy())
            lbd.specshow(mel.cpu().numpy(), ax=ax[1], sr=16000, cmap=&quotGnBu&quot, y_axis=&quotmel&quot, x_axis=&quottime&quot, hop_length=256)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/3e54c9c27cbf77aa5df69bb7ab46dda0eff92736#diff-3858a1f08e235788b7f392ceb18785c5dd6cfe82346d6158699013987814766dL29' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84475844</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 3e54c9c27cbf77aa5df69bb7ab46dda0eff92736</div><div id='time'> Time: 2021-08-10</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/LibriTTS_Tacotron2.py</div><div id='m_class'> M Class Name: LibriTTS_Tacotron2</div><div id='n_method'> N Class Name: LibriTTS_Tacotron2</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/LibriTTS_Tacotron2.py</div><div id='n_file'> N File Name: InferenceInterfaces/LibriTTS_Tacotron2.py</div><div id='m_start'> M Start Line: 32</div><div id='m_end'> M End Line: 33</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 34</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0, 1)
            wave = <a id="change">self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0</a><a id="change">)</a>
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd
            fig, ax = plt.subplots(nrows=2, ncols=1)</code></pre><h3>After Change</h3><pre><code class='java'>
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0, 1)
            wave = <a id="change">self.mel2wav(</a>mel<a id="change">)</a>
        if view:
            fig, ax = plt.subplots(nrows=2, ncols=1)
            ax[0].plot(wave.cpu().numpy())
            lbd.specshow(mel.cpu().numpy(), ax=ax[1], sr=16000, cmap=&quotGnBu&quot, y_axis=&quotmel&quot, x_axis=&quottime&quot, hop_length=256)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/3e54c9c27cbf77aa5df69bb7ab46dda0eff92736#diff-c0a1b78008d8e2a37e9fe86efc0a9b3c2f41dc21931b0fa73e4498a8417319dbL28' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84475845</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 3e54c9c27cbf77aa5df69bb7ab46dda0eff92736</div><div id='time'> Time: 2021-08-10</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/Nancy_Tacotron2.py</div><div id='m_class'> M Class Name: Nancy_Tacotron2</div><div id='n_method'> N Class Name: Nancy_Tacotron2</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/Nancy_Tacotron2.py</div><div id='n_file'> N File Name: InferenceInterfaces/Nancy_Tacotron2.py</div><div id='m_start'> M Start Line: 31</div><div id='m_end'> M End Line: 32</div><div id='n_start'> N Start Line: 32</div><div id='n_end'> N End Line: 33</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel, durations, pitch, energy = self.phone2mel(phones, speaker_embedding=self.speaker_embedding, return_duration_pitch_energy=True)
            mel = mel.transpose(0, 1)
            wave = <a id="change">self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0</a><a id="change">)</a>
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd
            from Utility.utils import cumsum_durations</code></pre><h3>After Change</h3><pre><code class='java'>
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel, durations, pitch, energy = self.phone2mel(phones, speaker_embedding=self.speaker_embedding, return_duration_pitch_energy=True)
            mel = mel.transpose(0, 1)
            wave = <a id="change">self.mel2wav(</a>mel<a id="change">)</a>
        if view:
            from Utility.utils import cumsum_durations
            fig, ax = plt.subplots(nrows=2, ncols=1)
            ax[0].plot(wave.cpu().numpy())</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/3e54c9c27cbf77aa5df69bb7ab46dda0eff92736#diff-1f63ab95c9347b87795c1ff3835921e8bf53468a0fd2686ec56a913abdde3321L31' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84475846</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 3e54c9c27cbf77aa5df69bb7ab46dda0eff92736</div><div id='time'> Time: 2021-08-10</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/Nancy_FastSpeech2.py</div><div id='m_class'> M Class Name: Nancy_FastSpeech2</div><div id='n_method'> N Class Name: Nancy_FastSpeech2</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/Nancy_FastSpeech2.py</div><div id='n_file'> N File Name: InferenceInterfaces/Nancy_FastSpeech2.py</div><div id='m_start'> M Start Line: 35</div><div id='m_end'> M End Line: 36</div><div id='n_start'> N Start Line: 37</div><div id='n_end'> N End Line: 38</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel, durations, pitch, energy = self.phone2mel(phones, speaker_embedding=self.speaker_embedding, return_duration_pitch_energy=True)
            mel = mel.transpose(0, 1)
            wave = <a id="change">self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0</a><a id="change">)</a>
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd
            from Utility.utils import cumsum_durations</code></pre><h3>After Change</h3><pre><code class='java'>
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel, durations, pitch, energy = self.phone2mel(phones, speaker_embedding=self.speaker_embedding, return_duration_pitch_energy=True)
            mel = mel.transpose(0, 1)
            wave = <a id="change">self.mel2wav(</a>mel<a id="change">)</a>
        if view:
            from Utility.utils import cumsum_durations
            fig, ax = plt.subplots(nrows=2, ncols=1)
            ax[0].plot(wave.cpu().numpy())</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/3e54c9c27cbf77aa5df69bb7ab46dda0eff92736#diff-d6349bc4fe66e0815860524d44ffe680c786183cb3b1452eb1a1fe89b583bd53L32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84475847</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 3e54c9c27cbf77aa5df69bb7ab46dda0eff92736</div><div id='time'> Time: 2021-08-10</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/LibriTTS_FastSpeech2.py</div><div id='m_class'> M Class Name: LibriTTS_FastSpeech2</div><div id='n_method'> N Class Name: LibriTTS_FastSpeech2</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/LibriTTS_FastSpeech2.py</div><div id='n_file'> N File Name: InferenceInterfaces/LibriTTS_FastSpeech2.py</div><div id='m_start'> M Start Line: 36</div><div id='m_end'> M End Line: 37</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 39</div><BR>