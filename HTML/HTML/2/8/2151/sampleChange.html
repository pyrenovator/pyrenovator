<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    train, val, model = iris_split_dataset_and_model
    check_obj = TrainTestDifferenceOverfit()
    result = check_obj.run(train, val, model)
    <a id="change">for </a>key, <a id="change">value</a> in <a id="change">result.value.items():
        assert_that(</a>key, any(starts_with(metric_name) for metric_name in DEFAULT_MULTICLASS_METRICS)<a id="change">)</a>
        <a id="change">assert_that(value</a>, close_to(-0.035, 0.01)<a id="change">)</a>


def test_custom_metrics(iris_split_dataset_and_model):
    &#47&#47 Arrange</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 Assert
    train = result.value[&quottrain&quot]
    test<a id="change"> = </a>result.value[&quottest&quot]
    expected_train = {&quotAccuracy&quot: close_to(0.96, 0.01), &quotPrecision - Macro Average&quot: close_to(0.96, 0.01),
                      &quotRecall - Macro Average&quot: close_to(0.96, 0.01)}
    expected_test = {&quotAccuracy&quot: close_to(0.92, 0.01), &quotPrecision - Macro Average&quot: close_to(0.92, 0.01),
                     &quotRecall - Macro Average&quot: close_to(0.92, 0.01)}
    assert_that(train, has_entries(expected_train))
    <a id="change">assert_that(</a>test, <a id="change">has_entries(</a>expected_test<a id="change">))</a>


def test_custom_metrics(iris_split_dataset_and_model):
    &#47&#47 Arrange</code></pre>