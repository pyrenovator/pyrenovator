<html><h3>Pattern ID :1077
</h3><img src='5374354.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            labels = labels.cuda()

            aux, pred = model(images)
            pred<a id="change"> = </a>interp(pred)
            aux = interp(aux)

            loss<a id="change"> = </a>seg_loss(pred, labels) + 0.4 * seg_loss(aux, labels)
            <a id="change">loss.backward()</a>
            optimizer.step()

            print(</code></pre><h3>After Change</h3><pre><code class='java'>
            lr = adjust_learning_rate(
                args, optimizer, i_iter, args.num_epochs * len(trainloader.dataset))

            <a id="change">with torch.cuda.amp.autocast()</a><a id="change">:
                </a>images = images.cuda()
                labels = labels.cuda()

                aux, pred = model(images)
                pred<a id="change"> = </a>interp(pred)
                aux = interp(aux)

                loss<a id="change"> = </a>seg_loss(pred, labels) + 0.4 * seg_loss(aux, labels)

                scaler.scale(loss).backward()
                scaler.step(optimizer)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 6</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/smhassanerfani/atlantis/commit/35a88733c2d4ab90e1ab4a38c2b07faa89eb1d50#diff-ed183d67207df065a11e1289f19d34cc2abbc5448dea952683cfe9728c342b95L111' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5374354</div><div id='project'> Project Name: smhassanerfani/atlantis</div><div id='commit'> Commit Name: 35a88733c2d4ab90e1ab4a38c2b07faa89eb1d50</div><div id='time'> Time: 2021-09-13</div><div id='author'> Author: serfani@email.sc.edu</div><div id='file'> File Name: train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train.py</div><div id='n_file'> N File Name: train.py</div><div id='m_start'> M Start Line: 111</div><div id='m_end'> M End Line: 138</div><div id='n_start'> N Start Line: 111</div><div id='n_end'> N End Line: 146</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    else:
                        raise NotImplementedError

                    gen_acml_loss<a id="change"> = </a>self.G_loss(dis_out_fake)
                    if self.conditional_strategy == "ACGAN":
                        gen_acml_loss += self.ce_loss(cls_out_fake, fake_labels)

                    if self.latent_op:
                        gen_acml_loss += transport_cost*self.latent_norm_reg_weight
                    gen_acml_loss<a id="change"> = </a>gen_acml_loss/self.accumulation_steps

                    <a id="change">gen_acml_loss.backward()</a>

                self.G_optimizer.step()

                &#47&#47 if ema is True: we update parameters of the Gen_copy in adaptive way.</code></pre><h3>After Change</h3><pre><code class='java'>
            for step_index in range(self.g_steps_per_iter):
                self.G_optimizer.zero_grad()
                for acml_step in range(self.accumulation_steps):
                    <a id="change">with torch.cuda.amp.autocast()</a><a id="change"> if self.mixed_precision else dummy_context_mgr() as mp:
                        </a>z, fake_labels = sample_latents(self.prior, self.batch_size, self.z_dim, 1, self.num_classes, None, self.default_device)

                        if self.latent_op:
                            z, transport_cost = latent_optimise(z, fake_labels, self.gen_model, self.dis_model, self.latent_op_step, self.latent_op_rate,
                                                                self.latent_op_alpha, self.latent_op_beta, True, self.default_device)

                        fake_images = self.gen_model(z, fake_labels)
                        if self.diff_aug:
                            fake_images = DiffAugment(fake_images, policy=self.policy)

                        if self.conditional_strategy == "ACGAN":
                            cls_out_fake, dis_out_fake = self.dis_model(fake_images, fake_labels)
                        elif self.conditional_strategy == "cGAN" or self.conditional_strategy == "no":
                            dis_out_fake = self.dis_model(fake_images, fake_labels)
                        else:
                            raise NotImplementedError

                        gen_acml_loss<a id="change"> = </a>self.G_loss(dis_out_fake)
                        if self.conditional_strategy == "ACGAN":
                            gen_acml_loss += self.ce_loss(cls_out_fake, fake_labels)

                        if self.latent_op:
                            gen_acml_loss += transport_cost*self.latent_norm_reg_weight
                        gen_acml_loss<a id="change"> = </a>gen_acml_loss/self.accumulation_steps

                    self.gen_scaler.scale(gen_acml_loss).backward()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/postech-cvlab/pytorch-studiogan/commit/aff9cdd6424bcd8c9bd80ee37c8e22e98a5237f9#diff-9f1d8e92cd6ea2024cda543185e6c91bbc5cd7377d0eb7d5b071abee5e466410L335' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5374355</div><div id='project'> Project Name: postech-cvlab/pytorch-studiogan</div><div id='commit'> Commit Name: aff9cdd6424bcd8c9bd80ee37c8e22e98a5237f9</div><div id='time'> Time: 2020-08-19</div><div id='author'> Author: first287@naver.com</div><div id='file'> File Name: trainer.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: run(3)</div><div id='n_method'> N Method Name: run(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: trainer.py</div><div id='n_file'> N File Name: trainer.py</div><div id='m_start'> M Start Line: 364</div><div id='m_end'> M End Line: 452</div><div id='n_start'> N Start Line: 381</div><div id='n_end'> N End Line: 474</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Initialize the model gradient.
        model.zero_grad()
        &#47&#47 Generate super-resolution images.
        sr<a id="change"> = </a>model(lr)
        &#47&#47 Calculate the difference between the super-resolution image and the high-resolution image at the pixel level.
        pixel_loss<a id="change"> = </a>criterion(sr, hr)
        &#47&#47 Update model weights.
        <a id="change">pixel_loss.backward()</a>
        optimizer.step()
        &#47&#47 Write the loss during training into Tensorboard.
        iters = index + epoch * batches + 1
        writer.add_scalar("Train/Loss", pixel_loss.item(), iters)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Initialize the model gradient.
        model.zero_grad()
        &#47&#47 Mixed precision training.
        <a id="change">with amp.autocast()</a><a id="change">:
            </a>sr<a id="change"> = </a>model(lr)
            loss<a id="change"> = </a>criterion(sr, hr)
        loss.backward()
        optimizer.step()
        &#47&#47 Write the loss during training to Tensorboard.</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/srcnn-pytorch/commit/bb3fc88fe2a676c6b92667d4f11618eadbe949fb#diff-ed183d67207df065a11e1289f19d34cc2abbc5448dea952683cfe9728c342b95L24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5374368</div><div id='project'> Project Name: lornatang/srcnn-pytorch</div><div id='commit'> Commit Name: bb3fc88fe2a676c6b92667d4f11618eadbe949fb</div><div id='time'> Time: 2021-09-15</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(2)</div><div id='n_method'> N Method Name: train(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train.py</div><div id='n_file'> N File Name: train.py</div><div id='m_start'> M Start Line: 43</div><div id='m_end'> M End Line: 47</div><div id='n_start'> N Start Line: 40</div><div id='n_end'> N End Line: 43</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            scheduler = CosineAnnealingLR(optimizer, train_iteration, 1e-3, last_epoch=i-1)
        
        start = time.time()
        output<a id="change"> = </a>model(images)
        forward_time = time.time() - start
        
        loss<a id="change"> = </a>criterion(output, target)
        optimizer.zero_grad()
        
        start = time.time()
        <a id="change">loss.backward()</a>
        backward_time = time.time() - start
        
        &#47&#47 Set to 0 the gradient of pruned neurons
        with torch.no_grad():</code></pre><h3>After Change</h3><pre><code class='java'>
            optimizer = SGD(model.parameters(), lr=0.1, weight_decay=1e-4)
            scheduler = CosineAnnealingLR(optimizer, train_iteration, 1e-3, last_epoch=i-1)
        
        <a id="change">with torch.cuda.amp.autocast()</a><a id="change">:
            </a>start = time.time()
            output<a id="change"> = </a>model(images)
            forward_time = time.time() - start
            
            loss<a id="change"> = </a>criterion(output, target)
            optimizer.zero_grad()
            
            start = time.time()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/eidoslab/simplify/commit/8c1cf93f9a2545c52c01379b934939040a76cc77#diff-41474220006d3f313aca51ff34722bbf4cb675023f4106ffd78a318ae920faccL39' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5374385</div><div id='project'> Project Name: eidoslab/simplify</div><div id='commit'> Commit Name: 8c1cf93f9a2545c52c01379b934939040a76cc77</div><div id='time'> Time: 2021-07-01</div><div id='author'> Author: carlo.alberto.barbano@outlook.com</div><div id='file'> File Name: training/train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: training/train.py</div><div id='n_file'> N File Name: training/train.py</div><div id='m_start'> M Start Line: 55</div><div id='m_end'> M End Line: 112</div><div id='n_start'> N Start Line: 55</div><div id='n_end'> N End Line: 116</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

            features = features.float().to(device)  &#47&#47 (B,T,F)
            targets = targets.long().to(device)
            outputs<a id="change"> = </a>model(features)  &#47&#47 (embed_a,embed_b) in most cases
            embeds = outputs[-1] if isinstance(outputs, tuple) else outputs
            outputs<a id="change"> = </a>model.module.projection(embeds, targets)

            loss = criterion(outputs, targets)
            &#47&#47 loss, acc
            loss_meter.add(loss.item())
            acc_meter.add(outputs.cpu().detach().numpy(),
                          targets.cpu().numpy())

            &#47&#47 updata the model
            optimizer.zero_grad()
            <a id="change">loss.backward()</a>
            optimizer.step()

            &#47&#47 log
            if (i + 1) % log_batch_interval == 0:</code></pre><h3>After Change</h3><pre><code class='java'>
            features = features.float().to(device)  &#47&#47 (B,T,F)
            targets = targets.long().to(device)

            <a id="change">with torch.cuda.amp.autocast(enabled=enable_amp)</a><a id="change">:
                </a>outputs<a id="change"> = </a>model(features)  &#47&#47 (embed_a,embed_b) in most cases
                embeds = outputs[-1] if isinstance(outputs, tuple) else outputs
                outputs<a id="change"> = </a>model.module.projection(embeds, targets)

                loss = criterion(outputs, targets)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/wenet-e2e/wespeaker/commit/80e5c79b304005c55cafe7ebd7e7ca7682c9191d#diff-1e2d9c41df05893e8fcb886f99586a377b4aae608073e511f1efb0065f4adccdL23' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5374389</div><div id='project'> Project Name: wenet-e2e/wespeaker</div><div id='commit'> Commit Name: 80e5c79b304005c55cafe7ebd7e7ca7682c9191d</div><div id='time'> Time: 2022-11-22</div><div id='author'> Author: chenzhengyang117@gmail.com</div><div id='file'> File Name: wespeaker/utils/executor.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: run_epoch(13)</div><div id='n_method'> N Method Name: run_epoch(11)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: wespeaker/utils/executor.py</div><div id='n_file'> N File Name: wespeaker/utils/executor.py</div><div id='m_start'> M Start Line: 57</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 32</div><div id='n_end'> N End Line: 76</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

                    cls_fake_proxies, cls_fake_embed, dis_fake_authen_out = self.dis_model(fake_images, fake_labels)

                    dis_acml_loss<a id="change"> = </a>self.D_loss(dis_real_authen_out, dis_fake_authen_out)
                    if self.conditional_strategy == "ContraGAN":
                        dis_acml_loss += self.contrastive_lambda*self.contrastive_criterion(cls_real_embed, cls_real_proxies, real_cls_mask,
                                                                                            real_labels, t, self.margin)
                    elif self.conditional_strategy == "Proxy_NCA_GAN":
                        dis_acml_loss += self.contrastive_lambda*self.NCA_criterion(cls_real_embed, cls_real_proxies, real_labels)
                    elif self.conditional_strategy == "XT_Xent_GAN":
                        pass
                    else:
                        raise NotImplementedError

                    if self.consistency_reg or self.conditional_strategy == "XT_Xent_GAN":
                        real_images_aug = real_images_aug.to(self.default_device)
                        _, cls_real_aug_embed, dis_real_aug_authen_out = self.dis_model(real_images_aug, real_labels)
                        if self.conditional_strategy == "XT_Xent_GAN":
                            dis_acml_loss += self.contrastive_lambda*self.XT_Xent_criterion(cls_real_embed, cls_real_aug_embed, t)
                        if self.consistency_reg:
                            consistency_loss = self.l2_loss(dis_real_authen_out, dis_real_aug_authen_out)
                            dis_acml_loss += self.consistency_lambda*consistency_loss

                    dis_acml_loss<a id="change"> = </a>dis_acml_loss/self.accumulation_steps
                    <a id="change">dis_acml_loss.backward()</a>

                self.D_optimizer.step()

                if self.weight_clipping_for_dis:</code></pre><h3>After Change</h3><pre><code class='java'>
                        else:
                            real_images, real_labels = next(train_iter)

                    <a id="change">with torch.cuda.amp.autocast()</a><a id="change"> if self.mixed_precision else dummy_context_mgr() as mp:
                        </a>real_images, real_labels = real_images.to(self.default_device), real_labels.to(self.default_device)
                        if self.diff_aug:
                            real_images = DiffAugment(real_images, policy=self.policy)

                        z, fake_labels = sample_latents(self.prior, self.batch_size, self.z_dim, 1, self.num_classes, None, self.default_device)
                        real_cls_mask = make_mask(real_labels, self.num_classes, self.default_device)

                        cls_real_proxies, cls_real_embed, dis_real_authen_out = self.dis_model(real_images, real_labels)

                        fake_images = self.gen_model(z, fake_labels)
                        if self.diff_aug:
                            fake_images = DiffAugment(fake_images, policy=self.policy)

                        cls_fake_proxies, cls_fake_embed, dis_fake_authen_out = self.dis_model(fake_images, fake_labels)

                        dis_acml_loss<a id="change"> = </a>self.D_loss(dis_real_authen_out, dis_fake_authen_out)
                        if self.conditional_strategy == "ContraGAN":
                            dis_acml_loss += self.contrastive_lambda*self.contrastive_criterion(cls_real_embed, cls_real_proxies, real_cls_mask,
                                                                                            real_labels, t, self.margin)
                        elif self.conditional_strategy == "Proxy_NCA_GAN":
                            dis_acml_loss += self.contrastive_lambda*self.NCA_criterion(cls_real_embed, cls_real_proxies, real_labels)
                        elif self.conditional_strategy == "XT_Xent_GAN":
                            pass
                        else:
                            raise NotImplementedError

                        if self.consistency_reg or self.conditional_strategy == "XT_Xent_GAN":
                            real_images_aug = real_images_aug.to(self.default_device)
                            _, cls_real_aug_embed, dis_real_aug_authen_out = self.dis_model(real_images_aug, real_labels)
                            if self.conditional_strategy == "XT_Xent_GAN":
                                dis_acml_loss += self.contrastive_lambda*self.XT_Xent_criterion(cls_real_embed, cls_real_aug_embed, t)
                            if self.consistency_reg:
                                consistency_loss = self.l2_loss(dis_real_authen_out, dis_real_aug_authen_out)
                                dis_acml_loss += self.consistency_lambda*consistency_loss

                        dis_acml_loss<a id="change"> = </a>dis_acml_loss/self.accumulation_steps

                    self.dis_scaler.scale(dis_acml_loss).backward()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/postech-cvlab/pytorch-studiogan/commit/aff9cdd6424bcd8c9bd80ee37c8e22e98a5237f9#diff-9f1d8e92cd6ea2024cda543185e6c91bbc5cd7377d0eb7d5b071abee5e466410L176' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5374365</div><div id='project'> Project Name: postech-cvlab/pytorch-studiogan</div><div id='commit'> Commit Name: aff9cdd6424bcd8c9bd80ee37c8e22e98a5237f9</div><div id='time'> Time: 2020-08-19</div><div id='author'> Author: first287@naver.com</div><div id='file'> File Name: trainer.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: run_ours(3)</div><div id='n_method'> N Method Name: run_ours(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: trainer.py</div><div id='n_file'> N File Name: trainer.py</div><div id='m_start'> M Start Line: 213</div><div id='m_end'> M End Line: 289</div><div id='n_start'> N Start Line: 224</div><div id='n_end'> N End Line: 307</div><BR>