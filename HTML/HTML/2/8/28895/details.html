<html><h3>Pattern ID :28895
</h3><img src='84950672.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    if isinstance(adj, Tensor):
        return dense_to_sparse(adj)
    else:
        idxs<a id="change"> = </a>np.nonzero(adj)
        edge_index<a id="change"> = </a>np.stack(idxs)
        edge_weights = adj[idxs]
        <a id="change">return </a>edge_index, edge_weights


def edge_index_to_adj(edge_index: TensArray,</code></pre><h3>After Change</h3><pre><code class='java'>
        tuple: (:obj:`edge_index`, :obj:`edge_weight`) tuple of same type of
            :obj:`adj` (:class:`~torch.Tensor` or :class:`~numpy.ndarray`).
    
    backend = <a id="change">infer_backend(</a>adj, backend<a id="change">)</a>

    assert backend in [torch, np]
    assert 2 &lt;= adj.ndim &lt;= 3
    assert adj.shape[-1] == adj.shape[-2]

    <a id="change">if backend is torch</a>:
        adj = torch.transpose(adj, -2, -1)
        index = adj.nonzero(as_tuple=True)
    else:
        adj<a id="change"> = </a>np.swapaxes(adj, -2, -1)  &#47&#47 transpose
        index<a id="change"> = </a>adj.nonzero()

    edge_attr = adj[index]
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/torchspatiotemporal/tsl/commit/f28e5a2fddc34eeb90a13c113512c8ab12b6138b#diff-06bf001f44c985548f88f63f6218b0ffef4949bcba885086f99529d813e75099L92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84950672</div><div id='project'> Project Name: torchspatiotemporal/tsl</div><div id='commit'> Commit Name: f28e5a2fddc34eeb90a13c113512c8ab12b6138b</div><div id='time'> Time: 2022-07-20</div><div id='author'> Author: ivan.marisca@hotmail.it</div><div id='file'> File Name: tsl/ops/connectivity.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: adj_to_edge_index(2)</div><div id='n_method'> N Method Name: adj_to_edge_index(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tsl/ops/connectivity.py</div><div id='n_file'> N File Name: tsl/ops/connectivity.py</div><div id='m_start'> M Start Line: 92</div><div id='m_end'> M End Line: 114</div><div id='n_start'> N Start Line: 106</div><div id='n_end'> N End Line: 145</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if isinstance(adj, Tensor):
        return dense_to_sparse(adj)
    else:
        idxs<a id="change"> = </a>np.nonzero(adj)
        edge_index<a id="change"> = </a>np.stack(idxs)
        edge_weights = adj[idxs]
        <a id="change">return </a>edge_index, edge_weights


def edge_index_to_adj(edge_index: TensArray,</code></pre><h3>After Change</h3><pre><code class='java'>
        tuple: (:obj:`edge_index`, :obj:`edge_weight`) tuple of same type of
            :obj:`adj` (:class:`~torch.Tensor` or :class:`~numpy.ndarray`).
    
    backend = <a id="change">infer_backend(</a>adj, backend<a id="change">)</a>

    assert backend in [torch, np]
    assert 2 &lt;= adj.ndim &lt;= 3
    assert adj.shape[-1] == adj.shape[-2]

    <a id="change">if backend is torch</a>:
        adj<a id="change"> = </a>torch.transpose(adj, -2, -1)
        index<a id="change"> = </a>adj.nonzero(as_tuple=True)
    else:
        adj = np.swapaxes(adj, -2, -1)  &#47&#47 transpose
        index = adj.nonzero()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/torchspatiotemporal/tsl/commit/50089afdf23de12eb6d11e9d5e7e64d949d45611#diff-06bf001f44c985548f88f63f6218b0ffef4949bcba885086f99529d813e75099L92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84950704</div><div id='project'> Project Name: torchspatiotemporal/tsl</div><div id='commit'> Commit Name: 50089afdf23de12eb6d11e9d5e7e64d949d45611</div><div id='time'> Time: 2022-08-18</div><div id='author'> Author: ivan.marisca@hotmail.it</div><div id='file'> File Name: tsl/ops/connectivity.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: adj_to_edge_index(2)</div><div id='n_method'> N Method Name: adj_to_edge_index(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tsl/ops/connectivity.py</div><div id='n_file'> N File Name: tsl/ops/connectivity.py</div><div id='m_start'> M Start Line: 92</div><div id='m_end'> M End Line: 114</div><div id='n_start'> N Start Line: 106</div><div id='n_end'> N End Line: 145</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 compute x^k
        exponentials = torch.zeros([x.shape[0], x.shape[1], self.order + 1])
        for o in range(self.order + 1):
            exponentials[:, :, o]<a id="change"> = </a>torch.pow(x, o)

        &#47&#47 multiply by coefficients
        exponentials = torch.multiply(exponentials, self.coeffs)

        &#47&#47 Collapse dimensions
        exponentials<a id="change"> = </a>torch.sum(exponentials, dim=2)

        &#47&#47 sum all values for each dim
        <a id="change">return </a>torch.sum(exponentials, dim=1)


class Exponential(IntegrationTestFunction):</code></pre><h3>After Change</h3><pre><code class='java'>
    def _poly(self, x):
        &#47&#47 Compute all relevant x^k
        &#47&#47 The shape of exponentials is (dim, N, order+1)
        <a id="change">if infer_backend(x) != "tensorflow"</a>:
            exponentials = x.reshape(x.shape + (1,)) ** anp.linspace(
                0, self.order, self.order + 1, like=x
            )
            assert exponentials.dtype == x.dtype
        else:
            &#47&#47 Tensorflow&quots exponentiation gives float64 values if x are float32
            &#47&#47 and the exponent are integer
            ks<a id="change"> = </a>anp.array(range(self.order + 1), dtype=x.dtype, like=x)
            exponentials<a id="change"> = </a>x.reshape(x.shape + (1,)) ** ks
            assert exponentials.dtype == x.dtype
            if exponentials.dtype != self.coeffs.dtype:
                &#47&#47 Tensorflow does not automatically cast float32 to complex128,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/esa/torchquad/commit/a3a1438960cc83afb6844c8279415e131be2ca42#diff-fe1b22e294ae47b16639a2139938eeec68d387dfa25d702da595cb2e75ef1bafL76' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84950773</div><div id='project'> Project Name: esa/torchquad</div><div id='commit'> Commit Name: a3a1438960cc83afb6844c8279415e131be2ca42</div><div id='time'> Time: 2022-03-14</div><div id='author'> Author: ga84muv@mytum.de</div><div id='file'> File Name: torchquad/tests/integration_test_functions.py</div><div id='m_class'> M Class Name: Polynomial</div><div id='n_method'> N Class Name: Polynomial</div><div id='m_method'> M Method Name: _poly(2)</div><div id='n_method'> N Method Name: _poly(2)</div><div id='m_parent_class'> M Parent Class: IntegrationTestFunction</div><div id='n_parent_class'> N Parent Class: IntegrationTestFunction</div><div id='m_file'> M File Name: torchquad/tests/integration_test_functions.py</div><div id='n_file'> N File Name: torchquad/tests/integration_test_functions.py</div><div id='m_start'> M Start Line: 78</div><div id='m_end'> M End Line: 89</div><div id='n_start'> N Start Line: 123</div><div id='n_end'> N End Line: 147</div><BR>