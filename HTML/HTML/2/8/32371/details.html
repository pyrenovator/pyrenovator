<html><h3>Pattern ID :32371
</h3><img src='94509938.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                                   moving_variance_initializer=&quotones&quot)(conv, training=False)
        relu = tf.nn.relu(bn)

        model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=relu)

        np.random.seed(0)
        w_shape = model._layers[0].input.shape
        numpy_data = np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
        baseline_output = model(numpy_data)

        <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>

        output_after_fold = model(numpy_data)

        <a id="change">self.assertFalse(</a>np.allclose(baseline_output, output_after_fold, atol=0)<a id="change">)</a>
        <a id="change">self.assertTrue(</a>np.allclose(baseline_output, output_after_fold, atol=1e-4)<a id="change">)</a>

    def test_bn_fold_with_linear_layer(self):
        
        Custom Model where BN layer is followed by Dense layer</code></pre><h3>After Change</h3><pre><code class='java'>
                                                       moving_variance_initializer=&quotones&quot)(conv, training=False)
            relu = tf.nn.relu(bn)

            model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=relu)

            np.random.seed(0)
            w_shape = model._layers[0].input.shape
            numpy_data = np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
            baseline_output = model(numpy_data)

            <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>

            output_after_fold = model(numpy_data)

            <a id="change">self.assertFalse(</a>np.allclose(baseline_output, output_after_fold, atol=0)<a id="change">)</a>
            <a id="change">self.assertTrue(</a>np.allclose(baseline_output, output_after_fold, atol=1e-4)<a id="change">)</a>

    def test_bn_fold_with_linear_layer(self):
        
        Custom Model where BN layer is followed by Dense layer</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/quic/aimet/commit/287c9529ac2b1bf0984a9edbc65895337bed1f89#diff-2360abe51d6acc4100b585ffbf928a1eaabe859458cf9c2b83f2bc346123311fL855' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 94509938</div><div id='project'> Project Name: quic/aimet</div><div id='commit'> Commit Name: 287c9529ac2b1bf0984a9edbc65895337bed1f89</div><div id='time'> Time: 2021-08-16</div><div id='author'> Author: quic_zabrisha@quicinc.com</div><div id='file'> File Name: TrainingExtensions/tensorflow/test/python/test_batch_norm_fold_keras.py</div><div id='m_class'> M Class Name: TestBatchNormFold</div><div id='n_method'> N Class Name: TestBatchNormFold</div><div id='m_method'> M Method Name: test_batch_norm_fold_with_random_data(1)</div><div id='n_method'> N Method Name: test_batch_norm_fold_with_random_data(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: TrainingExtensions/tensorflow/test/python/test_batch_norm_fold_keras.py</div><div id='n_file'> N File Name: TrainingExtensions/tensorflow/test/python/test_batch_norm_fold_keras.py</div><div id='m_start'> M Start Line: 856</div><div id='m_end'> M End Line: 879</div><div id='n_start'> N Start Line: 855</div><div id='n_end'> N End Line: 881</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                                                       moving_variance_initializer=&quotones&quot)(conv, training=False)
            relu = tf.nn.relu(bn)

            model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=relu)

            np.random.seed(0)
            w_shape = model._layers[0].input.shape
            numpy_data = np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
            baseline_output = model(numpy_data)

            <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>

            output_after_fold = model(numpy_data)

            <a id="change">self.assertFalse(</a>np.allclose(baseline_output, output_after_fold, atol=0)<a id="change">)</a>
            <a id="change">self.assertTrue(</a>np.allclose(baseline_output, output_after_fold, atol=1e-4)<a id="change">)</a>

    def test_bn_fold_with_linear_layer(self):
        
        Custom Model where BN layer is followed by Dense layer</code></pre><h3>After Change</h3><pre><code class='java'>
                                                   moving_variance_initializer=&quotones&quot)(conv, training=False)
        relu = tf.nn.relu(bn)

        model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=relu)

        np.random.seed(0)
        w_shape = model._layers[0].input.shape
        numpy_data = np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
        baseline_output = model(numpy_data)

        <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>

        output_after_fold = model(numpy_data)

        <a id="change">self.assertFalse(</a>np.allclose(baseline_output, output_after_fold, atol=0)<a id="change">)</a>
        <a id="change">self.assertTrue(</a>np.allclose(baseline_output, output_after_fold, atol=1e-4)<a id="change">)</a>

    def test_bn_fold_with_linear_layer(self):
        
        Custom Model where BN layer is followed by Dense layer</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/quic/aimet/commit/28425277900d8639a7088695987da788dbe9d976#diff-834f2d7622f379defad7d1f6d2194617ddaa1f00a614cd69588c9417b768f881L852' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 94509942</div><div id='project'> Project Name: quic/aimet</div><div id='commit'> Commit Name: 28425277900d8639a7088695987da788dbe9d976</div><div id='time'> Time: 2022-12-22</div><div id='author'> Author: quic_haijunz@quicinc.com</div><div id='file'> File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='m_class'> M Class Name: TestBatchNormFold</div><div id='n_method'> N Class Name: TestBatchNormFold</div><div id='m_method'> M Method Name: test_batch_norm_fold_with_random_data(1)</div><div id='n_method'> N Method Name: test_batch_norm_fold_with_random_data(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='n_file'> N File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='m_start'> M Start Line: 856</div><div id='m_end'> M End Line: 882</div><div id='n_start'> N Start Line: 852</div><div id='n_end'> N End Line: 875</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        bn = tf.keras.layers.BatchNormalization(fused=True)(inputs, training=False)
        x = tf.keras.layers.Flatten()(bn)
        dense = tf.keras.layers.Dense(2, activation=tf.nn.relu, name="linear_layer")(x)
        model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=dense)

        &#47&#47 get baseline output
        np.random.seed(0)
        w_shape = model._layers[0].input.shape
        numpy_data = np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
        baseline_output = model(numpy_data)
        weight_before_fold = model._layers[3].kernel.numpy()

        <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>
        after_fold_output = model(numpy_data)
        weight_after_fold = model._layers[3].kernel.numpy()

        &#47&#47 check that weight got updated
        <a id="change">self.assertFalse(</a>np.allclose(weight_before_fold, weight_after_fold, atol=1e-4)<a id="change">)</a>

        &#47&#47 check outputs are close
        <a id="change">self.assertTrue(</a>np.allclose(baseline_output, after_fold_output, atol=1e-4)<a id="change">)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
            bn = tf.keras.layers.BatchNormalization(fused=True)(inputs, training=False)
            x = tf.keras.layers.Flatten()(bn)
            dense = tf.keras.layers.Dense(2, activation=tf.nn.relu, name="linear_layer")(x)
            model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=dense)

            &#47&#47 get baseline output
            np.random.seed(0)
            w_shape = model._layers[0].input.shape
            numpy_data = np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
            baseline_output = model(numpy_data)
            weight_before_fold = model._layers[3].kernel.numpy()

            <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>
            after_fold_output = model(numpy_data)
            weight_after_fold = model._layers[3].kernel.numpy()

            &#47&#47 check that weight got updated
            <a id="change">self.assertFalse(</a>np.allclose(weight_before_fold, weight_after_fold, atol=1e-4)<a id="change">)</a>

            &#47&#47 check outputs are close
            <a id="change">self.assertTrue(</a>np.allclose(baseline_output, after_fold_output, atol=1e-4)<a id="change">)</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/quic/aimet/commit/287c9529ac2b1bf0984a9edbc65895337bed1f89#diff-2360abe51d6acc4100b585ffbf928a1eaabe859458cf9c2b83f2bc346123311fL881' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 94509940</div><div id='project'> Project Name: quic/aimet</div><div id='commit'> Commit Name: 287c9529ac2b1bf0984a9edbc65895337bed1f89</div><div id='time'> Time: 2021-08-16</div><div id='author'> Author: quic_zabrisha@quicinc.com</div><div id='file'> File Name: TrainingExtensions/tensorflow/test/python/test_batch_norm_fold_keras.py</div><div id='m_class'> M Class Name: TestBatchNormFold</div><div id='n_method'> N Class Name: TestBatchNormFold</div><div id='m_method'> M Method Name: test_bn_fold_with_linear_layer(1)</div><div id='n_method'> N Method Name: test_bn_fold_with_linear_layer(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: TrainingExtensions/tensorflow/test/python/test_batch_norm_fold_keras.py</div><div id='n_file'> N File Name: TrainingExtensions/tensorflow/test/python/test_batch_norm_fold_keras.py</div><div id='m_start'> M Start Line: 887</div><div id='m_end'> M End Line: 908</div><div id='n_start'> N Start Line: 886</div><div id='n_end'> N End Line: 908</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            bn = tf.keras.layers.BatchNormalization(fused=True)(inputs, training=False)
            x = tf.keras.layers.Flatten()(bn)
            dense = tf.keras.layers.Dense(2, activation=tf.nn.relu, name="linear_layer")(x)
            model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=dense)

            &#47&#47 get baseline output
            np.random.seed(0)
            w_shape = model._layers[0].input.shape
            numpy_data = np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
            baseline_output = model(numpy_data)
            weight_before_fold = model._layers[3].kernel.numpy()

            <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>
            after_fold_output = model(numpy_data)
            weight_after_fold = model._layers[3].kernel.numpy()

            &#47&#47 check that weight got updated
            <a id="change">self.assertFalse(</a>np.allclose(weight_before_fold, weight_after_fold, atol=1e-4)<a id="change">)</a>

            &#47&#47 check outputs are close
            <a id="change">self.assertTrue(</a>np.allclose(baseline_output, after_fold_output, atol=1e-4)<a id="change">)</a>

    def test_find_conv_bn_pairs_functional_nested(self):
        
        Test case for finding conv-bn pairs when the inner model has 2 layers connected to the input</code></pre><h3>After Change</h3><pre><code class='java'>
        bn = tf.keras.layers.BatchNormalization(fused=True)(inputs, training=False)
        x = tf.keras.layers.Flatten()(bn)
        dense = tf.keras.layers.Dense(2, activation=tf.nn.relu, name="linear_layer")(x)
        model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=dense)

        &#47&#47 get baseline output
        np.random.seed(0)
        w_shape = model._layers[0].input.shape
        numpy_data = np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
        baseline_output = model(numpy_data)
        weight_before_fold = model._layers[3].kernel.numpy()

        <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>
        after_fold_output = model(numpy_data)
        weight_after_fold = model._layers[3].kernel.numpy()

        &#47&#47 check that weight got updated
        <a id="change">self.assertFalse(</a>np.allclose(weight_before_fold, weight_after_fold, atol=1e-4)<a id="change">)</a>

        &#47&#47 check outputs are close
        <a id="change">self.assertTrue(</a>np.allclose(baseline_output, after_fold_output, atol=1e-4)<a id="change">)</a>

    def test_find_conv_bn_pairs_functional_nested(self):
        
        Test case for finding conv-bn pairs when the inner model has 2 layers connected to the input</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/quic/aimet/commit/28425277900d8639a7088695987da788dbe9d976#diff-834f2d7622f379defad7d1f6d2194617ddaa1f00a614cd69588c9417b768f881L882' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 94509945</div><div id='project'> Project Name: quic/aimet</div><div id='commit'> Commit Name: 28425277900d8639a7088695987da788dbe9d976</div><div id='time'> Time: 2022-12-22</div><div id='author'> Author: quic_haijunz@quicinc.com</div><div id='file'> File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='m_class'> M Class Name: TestBatchNormFold</div><div id='n_method'> N Class Name: TestBatchNormFold</div><div id='m_method'> M Method Name: test_bn_fold_with_linear_layer(1)</div><div id='n_method'> N Method Name: test_bn_fold_with_linear_layer(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='n_file'> N File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='m_start'> M Start Line: 887</div><div id='m_end'> M End Line: 911</div><div id='n_start'> N Start Line: 882</div><div id='n_end'> N End Line: 903</div><BR>