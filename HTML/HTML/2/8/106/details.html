<html><h3>Pattern ID :106
</h3><img src='1249571.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.train()
        optimizer = self.optimizer
        loss_fn = self.loss
        metrics<a id="change"> = </a>self.metrics
        optimizer.zero_grad()
        x = to_device(x, device=device)
        z = self.encode(*x)
        &#47&#47 here `out_index` maybe pos_edge_index
        &#47&#47 or (pos_edge_index, neg_edge_index)
        if isinstance(out_index, (list, tuple)):
            assert len(out_index) == 2, &quot`out_index` should be (pos_edge_index, neg_edge_index) or pos_edge_index&quot
            pos_edge_index, neg_edge_index = out_index
        else:
            pos_edge_index, neg_edge_index = out_index, None

        pos_pred = self.decode(z, pos_edge_index)
        pos_y = z.new_ones(pos_edge_index.size(1))

        &#47&#47 Do not include self-loops in negative samples
        &#47&#47 TODO: is it necessary?
        pos_edge_index, _ = remove_self_loops(pos_edge_index)
        pos_edge_index, _ = add_self_loops(pos_edge_index)

        if neg_edge_index is None:
            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))
        neg_pred = self.decode(z, neg_edge_index)

        loss = loss_fn(pos_pred, neg_pred)
        loss.backward()
        optimizer.step()
        if self.scheduler is not None:
            self.scheduler.step()

        neg_y = z.new_zeros(neg_edge_index.size(1))
        y = torch.cat([pos_y, neg_y], dim=0)
        pred = torch.cat([pos_pred, neg_pred], dim=0)

        <a id="change">for metric</a> in metrics<a id="change">:
            metric</a><a id="change">.update_state(y.cpu()</a>, <a id="change">pred.detach().cpu())</a>

        results = [loss.cpu().detach()] + [metric.result() for metric in metrics]
        return dict(zip(self.metrics_names, results))
</code></pre><h3>After Change</h3><pre><code class='java'>
        y = torch.cat([pos_y, neg_y], dim=0)
        pred = torch.cat([pos_pred, neg_pred], dim=0)

        <a id="change">self.update_metrics(</a>pred, y<a id="change">)</a>

        results = [loss.cpu().detach()] + [metric.result() for metric in self.metrics]
        return dict(zip(self.metrics_names, results))
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/edisonleeeee/graphgallery/commit/abb601276c87158085ee67b40b7744311bfc4e41#diff-b8b8686f5bf23605c9ce1c802b6e7b03f219b2b14be555ea474ed01702e24731L22' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1249571</div><div id='project'> Project Name: edisonleeeee/graphgallery</div><div id='commit'> Commit Name: abb601276c87158085ee67b40b7744311bfc4e41</div><div id='time'> Time: 2021-08-07</div><div id='author'> Author: cnljt@outlook.com</div><div id='file'> File Name: graphgallery/nn/models/pyg/autoencoder/autoencoder.py</div><div id='m_class'> M Class Name: AutoEncoder</div><div id='n_method'> N Class Name: AutoEncoder</div><div id='m_method'> M Method Name: train_step_on_batch(5)</div><div id='n_method'> N Method Name: train_step_on_batch(5)</div><div id='m_parent_class'> M Parent Class: TorchKeras</div><div id='n_parent_class'> N Parent Class: TorchKeras</div><div id='m_file'> M File Name: graphgallery/nn/models/pyg/autoencoder/autoencoder.py</div><div id='n_file'> N File Name: graphgallery/nn/models/pyg/autoencoder/autoencoder.py</div><div id='m_start'> M Start Line: 22</div><div id='m_end'> M End Line: 60</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 57</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.train()
        optimizer = self.optimizer
        loss_fn = self.loss
        metrics<a id="change"> = </a>self.metrics
        optimizer.zero_grad()

        if not isinstance(x, (list, tuple)):
            x = [x]
        x = [_x.to(device) if hasattr(x, &quotto&quot) else _x for _x in x]
        y = y.to(device)

        &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
        x, U, V = x
        U.requires_grad = True
        V.requires_grad = True
        out = self(x, U, V)
        if out_index is not None:
            out = out[out_index]
        loss = loss_fn(out, y)

        U_grad, V_grad = torch.autograd.grad(loss, [U, V], retain_graph=True)
        U.requires_grad = False
        V.requires_grad = False

        U_grad = self.eps_U * U_grad / torch.norm(U_grad, 2)
        V_grad = self.eps_V * V_grad / torch.norm(V_grad, 2)

        out_U = self(x, U + U_grad, V)
        out_V = self(x, U, V + V_grad)

        if out_index is not None:
            out_U = out_U[out_index]
            out_V = out_V[out_index]

        loss += self.lamb_U * loss_fn(out_U, y) + self.lamb_V * loss_fn(out_V, y)
        &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47

        loss.backward()
        optimizer.step()
        <a id="change">for metric</a> in metrics<a id="change">:
            </a><a id="change">metric.update_state(y.cpu()</a>, <a id="change">out.detach().cpu())</a>

        results = [loss.cpu().detach()] + [metric.result() for metric in metrics]
        return dict(zip(self.metrics_names, results))
</code></pre><h3>After Change</h3><pre><code class='java'>

        loss.backward()
        optimizer.step()
        <a id="change">self.update_metrics(</a>out, y<a id="change">)</a>

        results = [loss.cpu().detach()] + [metric.result() for metric in self.metrics]
        return dict(zip(self.metrics_names, results))
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/edisonleeeee/graphgallery/commit/eb44cb9e5d0b12f081c365b0135af2b31cd3e19b#diff-adc59d1c48d5e9ffaa3e5f44cec4bfe38b034724d5341c9e367c6760fdbbedabL6' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1249568</div><div id='project'> Project Name: edisonleeeee/graphgallery</div><div id='commit'> Commit Name: eb44cb9e5d0b12f081c365b0135af2b31cd3e19b</div><div id='time'> Time: 2021-08-07</div><div id='author'> Author: cnljt@outlook.com</div><div id='file'> File Name: graphgallery/nn/models/pytorch/sat/base_sat.py</div><div id='m_class'> M Class Name: BaseSAT</div><div id='n_method'> N Class Name: BaseSAT</div><div id='m_method'> M Method Name: train_step_on_batch(5)</div><div id='n_method'> N Method Name: train_step_on_batch(5)</div><div id='m_parent_class'> M Parent Class: TorchKeras</div><div id='n_parent_class'> N Parent Class: TorchKeras</div><div id='m_file'> M File Name: graphgallery/nn/models/pytorch/sat/base_sat.py</div><div id='n_file'> N File Name: graphgallery/nn/models/pytorch/sat/base_sat.py</div><div id='m_start'> M Start Line: 14</div><div id='m_end'> M End Line: 53</div><div id='n_start'> N Start Line: 15</div><div id='n_end'> N End Line: 47</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.train()
        optimizer = self.optimizer
        loss_fn = self.loss
        metrics<a id="change"> = </a>self.metrics
        optimizer.zero_grad()
        x = to_device(x, device=device)
        z = self.encode(*x)
        &#47&#47 here `out_index` maybe pos_edge_index
        &#47&#47 or (pos_edge_index, neg_edge_index)
        if isinstance(out_index, (list, tuple)):
            assert len(out_index) == 2, &quot`out_index` should be (pos_edge_index, neg_edge_index) or pos_edge_index&quot
            pos_edge_index, neg_edge_index = out_index
        else:
            pos_edge_index, neg_edge_index = out_index, None

        pos_pred = self.decode(z, pos_edge_index)
        pos_y = z.new_ones(pos_edge_index.size(1))

        &#47&#47 Do not include self-loops in negative samples
        &#47&#47 TODO: is it necessary?
        pos_edge_index, _ = remove_self_loops(pos_edge_index)
        pos_edge_index, _ = add_self_loops(pos_edge_index)

        if neg_edge_index is None:
            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))
        neg_pred = self.decode(z, neg_edge_index)

        loss = loss_fn(pos_pred, neg_pred)
        loss.backward()
        optimizer.step()
        if self.scheduler is not None:
            self.scheduler.step()

        neg_y = z.new_zeros(neg_edge_index.size(1))
        y = torch.cat([pos_y, neg_y], dim=0)
        pred = torch.cat([pos_pred, neg_pred], dim=0)

        <a id="change">for metric</a> in metrics<a id="change">:
            </a><a id="change">metric.update_state(</a><a id="change">y.cpu()</a>, <a id="change">pred.detach().cpu()</a><a id="change">)</a>

        results = [loss.cpu().detach()] + [metric.result() for metric in metrics]
        return dict(zip(self.metrics_names, results))
</code></pre><h3>After Change</h3><pre><code class='java'>
        y = torch.cat([pos_y, neg_y], dim=0)
        pred = torch.cat([pos_pred, neg_pred], dim=0)

        <a id="change">self.update_metrics(</a>pred, y<a id="change">)</a>

        results = [loss.cpu().detach()] + [metric.result() for metric in self.metrics]
        return dict(zip(self.metrics_names, results))
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/edisonleeeee/graphgallery/commit/abb601276c87158085ee67b40b7744311bfc4e41#diff-b8b8686f5bf23605c9ce1c802b6e7b03f219b2b14be555ea474ed01702e24731L15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1249573</div><div id='project'> Project Name: edisonleeeee/graphgallery</div><div id='commit'> Commit Name: abb601276c87158085ee67b40b7744311bfc4e41</div><div id='time'> Time: 2021-08-07</div><div id='author'> Author: cnljt@outlook.com</div><div id='file'> File Name: graphgallery/nn/models/pyg/autoencoder/autoencoder.py</div><div id='m_class'> M Class Name: AutoEncoder</div><div id='n_method'> N Class Name: AutoEncoder</div><div id='m_method'> M Method Name: train_step_on_batch(5)</div><div id='n_method'> N Method Name: train_step_on_batch(5)</div><div id='m_parent_class'> M Parent Class: TorchKeras</div><div id='n_parent_class'> N Parent Class: TorchKeras</div><div id='m_file'> M File Name: graphgallery/nn/models/pyg/autoencoder/autoencoder.py</div><div id='n_file'> N File Name: graphgallery/nn/models/pyg/autoencoder/autoencoder.py</div><div id='m_start'> M Start Line: 22</div><div id='m_end'> M End Line: 60</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 57</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                           device="cpu"):
        self.eval()
        loss_fn = self.loss
        metrics<a id="change"> = </a>self.metrics
        x, y = to_device(x, y, device=device)
        z = self.encode(*x)
        out = self.decode(z, out_index)
        loss = loss_fn(out, y)
        <a id="change">for metric</a> in metrics<a id="change">:
            </a><a id="change">metric.update_state(y.cpu()</a>, <a id="change">out.detach().cpu())</a>

        results = [loss.cpu().detach()] + [metric.result() for metric in metrics]
        return dict(zip(self.metrics_names, results))
</code></pre><h3>After Change</h3><pre><code class='java'>
        z = self.encode(*x)
        out = self.decode(z, out_index)
        loss = self.compute_loss(out, y)
        <a id="change">self.update_metrics(</a>out, y<a id="change">)</a>

        if loss is not None:
            loss = loss.cpu().item()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/edisonleeeee/graphgallery/commit/eb44cb9e5d0b12f081c365b0135af2b31cd3e19b#diff-5e135cac94d899ee810c613b73c050fb753ba6ce1f985a0020e0421fe6c3fa53L41' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1249572</div><div id='project'> Project Name: edisonleeeee/graphgallery</div><div id='commit'> Commit Name: eb44cb9e5d0b12f081c365b0135af2b31cd3e19b</div><div id='time'> Time: 2021-08-07</div><div id='author'> Author: cnljt@outlook.com</div><div id='file'> File Name: graphgallery/nn/models/pytorch/autoencoder/autoencoder.py</div><div id='m_class'> M Class Name: AutoEncoder</div><div id='n_method'> N Class Name: AutoEncoder</div><div id='m_method'> M Method Name: test_step_on_batch(5)</div><div id='n_method'> N Method Name: test_step_on_batch(5)</div><div id='m_parent_class'> M Parent Class: TorchKeras</div><div id='n_parent_class'> N Parent Class: TorchKeras</div><div id='m_file'> M File Name: graphgallery/nn/models/pytorch/autoencoder/autoencoder.py</div><div id='n_file'> N File Name: graphgallery/nn/models/pytorch/autoencoder/autoencoder.py</div><div id='m_start'> M Start Line: 47</div><div id='m_end'> M End Line: 56</div><div id='n_start'> N Start Line: 29</div><div id='n_end'> N End Line: 36</div><BR>