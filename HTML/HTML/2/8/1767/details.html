<html><h3>Pattern ID :1767
</h3><img src='8210748.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        gym_env_name, dataset_dict = load_dataset_magical()
        venv = make_vec_env(gym_env_name, n_envs=1, parallel=False)
        color_space = ColorSpace.RGB
    elif <a id="change">benchmark[&quotbenchmark_name&quot] == &quotdm_control&quot</a>:
        assert not use_random_rollouts, \
            "use_random_rollouts not yet supported for dm_control"
        gym_env_name<a id="change">, dataset_dict = </a>load_dataset_dm_control()
        venv = make_vec_env(gym_env_name, n_envs=1, parallel=False)
        color_space = ColorSpace.RGB
    elif benchmark[&quotbenchmark_name&quot] == &quotatari&quot:</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 setup environment & dataset
    venv = auto_env.load_vec_env()
    color_space<a id="change"> = </a><a id="change">auto_env.load_color_space()</a>
    if use_random_rollouts:
        dataset_dict = get_random_traj(env=venv,
                                       timesteps=timesteps)
    else:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/e27cbb99e7f7a03a80d5ff8063b3071bf534edda#diff-85e6dfcecb4f7bb11eda0f3c08b89808cf7f28a3eaf145199d43441864816161L86' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8210748</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: e27cbb99e7f7a03a80d5ff8063b3071bf534edda</div><div id='time'> Time: 2020-08-13</div><div id='author'> Author: sam@qxcv.net</div><div id='file'> File Name: src/il_representations/scripts/run_rep_learner.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: run(10)</div><div id='n_method'> N Method Name: run(10)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/il_representations/scripts/run_rep_learner.py</div><div id='n_file'> N File Name: src/il_representations/scripts/run_rep_learner.py</div><div id='m_start'> M Start Line: 92</div><div id='m_end'> M End Line: 115</div><div id='n_start'> N Start Line: 86</div><div id='n_end'> N End Line: 92</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        algo = getattr(algos, algo)

    &#47&#47 setup environment
    <a id="change">if </a><a id="change">benchmark[&quotbenchmark_name&quot] == &quotmagical&quot</a>:
        assert not use_random_rollouts, \
            "use_random_rollouts not yet supported for MAGICAL"
        gym_env_name, dataset_dict = load_dataset_magical()
        venv = make_vec_env(gym_env_name, n_envs=1, parallel=False)
        color_space = ColorSpace.RGB
    elif benchmark[&quotbenchmark_name&quot] == &quotdm_control&quot:
        assert not use_random_rollouts, \
            "use_random_rollouts not yet supported for dm_control"
        gym_env_name, dataset_dict = load_dataset_dm_control()
        venv = make_vec_env(gym_env_name, n_envs=1, parallel=False)
        color_space = ColorSpace.RGB
    elif benchmark[&quotbenchmark_name&quot] == &quotatari&quot:
        if not use_random_rollouts:
            dataset_dict = load_dataset_atari()
        gym_env_name_hwc<a id="change"> = </a>benchmark[&quotatari_env_id&quot]
        venv = VecTransposeImage(VecFrameStack(
            make_atari_env(gym_env_name_hwc), 4))
        color_space = ColorSpace.GRAY</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 setup environment & dataset
    venv = auto_env.load_vec_env()
    color_space<a id="change"> = </a><a id="change">auto_env.load_color_space()</a>
    if use_random_rollouts:
        dataset_dict = get_random_traj(env=venv,
                                       timesteps=timesteps)
    else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/4f43a9030853ed574d23f2e86f5253fc4ccd11de#diff-85e6dfcecb4f7bb11eda0f3c08b89808cf7f28a3eaf145199d43441864816161L81' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8210940</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: 4f43a9030853ed574d23f2e86f5253fc4ccd11de</div><div id='time'> Time: 2020-08-13</div><div id='author'> Author: sam@qxcv.net</div><div id='file'> File Name: src/il_representations/scripts/run_rep_learner.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: run(10)</div><div id='n_method'> N Method Name: run(10)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/il_representations/scripts/run_rep_learner.py</div><div id='n_file'> N File Name: src/il_representations/scripts/run_rep_learner.py</div><div id='m_start'> M Start Line: 92</div><div id='m_end'> M End Line: 115</div><div id='n_start'> N Start Line: 86</div><div id='n_end'> N End Line: 92</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    else:
        if np.max(img) &gt; 1:
            img = normalize_image(img)
        <a id="change">if </a><a id="change">env_cfg[&quotbenchmark_name&quot] == &quotmagical&quot</a> and img.shape[2] == 12:  &#47&#47 For MAGICAL, original img shape is
                                                                             &#47&#47 [96, 96, 12]
            img = np.dsplit(img, 4)
            img = np.concatenate(img, axis=1)  &#47&#47 frames tiled horizontally
        else:
            &#47&#47 The images generated by Captum has a wide margin around the graph. If you wish to crop it you can
            &#47&#47 uncomment the following line and adjust the number to your preference.
            &#47&#47 img = img[50:1150, 100:1100, :]
            plt.axis(&quotoff&quot)
            savefig_kwargs<a id="change"> = </a>{&quotbbox_inches&quot: &quottight&quot, &quotdpi&quot: 150, &quotpad_inches&quot: 0}
    plt.imshow(img)
    if save_dir:
        plt.savefig(f&quot{save_dir}/{save_name}.png&quot, **savefig_kwargs)</code></pre><h3>After Change</h3><pre><code class='java'>
        img = img.detach().numpy()

    &#47&#47 Split framestacked image
    color_space<a id="change"> = </a><a id="change">auto_env.load_color_space()</a>
    n_chans = 3 if color_space == &quotRGB&quot else 1
    split_img = np.dsplit(img, img.shape[2] // n_chans)
    img = np.concatenate(split_img, axis=1)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/2a1417a56faf7fab9fc3aaabb6e6208ca3d09208#diff-04d7c4d87a42834b2102127235c10394e6569c887d9c06f1c9ac178162f836d5L125' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8210833</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: 2a1417a56faf7fab9fc3aaabb6e6208ca3d09208</div><div id='time'> Time: 2021-03-07</div><div id='author'> Author: RPC2@users.noreply.github.com</div><div id='file'> File Name: src/il_representations/scripts/interpret.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: save_img(4)</div><div id='n_method'> N Method Name: save_img(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/il_representations/scripts/interpret.py</div><div id='n_file'> N File Name: src/il_representations/scripts/interpret.py</div><div id='m_start'> M Start Line: 130</div><div id='m_end'> M End Line: 148</div><div id='n_start'> N Start Line: 135</div><div id='n_end'> N End Line: 161</div><BR>