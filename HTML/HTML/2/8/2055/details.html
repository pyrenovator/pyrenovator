<html><h3>Pattern ID :2055
</h3><img src='8946268.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    loop = tqdm(test_loader)
    for batch_idx, frames in enumerate(loop):

        <a id="change">if </a>i &gt;= 10: break

        frames = frames.to(DEVICE)  &#47&#47 [1, T, 3, h, w]
        frames_vis = postprocess_img(frames.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
        input = frames[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 3, h, w]

        pred_rgb = pred_rgb_model.pred_n(input, pred_length=VIDEO_PRED_LENGTH)  &#47&#47 [1, T, 3, h, w]
        pred_rgb_vis = postprocess_img(pred_rgb)  &#47&#47 [T, 3, h, w]

        pred_rgb = torch.cat([input, pred_rgb], dim=1)
        pred_rgb = torch.stack([seg_model(pred_rgb[:, i]) for i in range(pred_rgb.shape[1])], dim=1)
        pred_rgb = pred_rgb.argmax(dim=2).squeeze()  &#47&#47 [T, h, w]
        pred_then_colorized_vis = colorize_semseg(postprocess_mask(pred_rgb), num_classes=SYNPICK_CLASSES) &#47&#47 [T, 3, h, w]

        frames_seg = [seg_model(frames[:, i]).argmax(dim=1) for i in range(frames.shape[1])]
        frames_seg<a id="change"> = </a>torch.stack(frames_seg, dim=1)  &#47&#47 [1, 1, h, w]
        input_seg = frames_seg[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 1, h, w]

        pred_mask = pred_mask_model.pred_n(input_seg, pred_length=VIDEO_PRED_LENGTH)</code></pre><h3>After Change</h3><pre><code class='java'>
    test_data = SynpickVideoDataset(data_dir=data_dir, vid_type=("rgb", 3), num_frames=VIDEO_TOT_LENGTH,
                                    step=4, allow_overlap=VID_DATA_ALLOW_OVERLAP)
    test_loader = DataLoader(test_data, batch_size=1, shuffle=True, num_workers=4)
    iter_loader = <a id="change">iter(</a>test_loader<a id="change">)</a>

    with torch.no_grad():
        for i in tqdm(range(10)):

            frames<a id="change"> = </a><a id="change">next(</a>iter_loader<a id="change">)</a>.to(DEVICE)  &#47&#47 [1, T, 3, h, w]
            frames_vis = postprocess_img(frames.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
            input = frames[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 3, h, w]

            pred_rgb = pred_rgb_model.pred_n(input, pred_length=VIDEO_PRED_LENGTH)
            pred_rgb = torch.cat([input, pred_rgb], dim=1)  &#47&#47 [1, T, 3, h, w]
            pred_rgb_vis = postprocess_img(pred_rgb.squeeze(dim=0))  &#47&#47 [T, 3, h, w]

            pred_rgb = torch.stack([seg_model(pred_rgb[:, i]) for i in range(pred_rgb.shape[1])], dim=1)
            pred_rgb = pred_rgb.argmax(dim=2).squeeze()  &#47&#47 [T, h, w]
            pred_then_colorized_vis = colorize_semseg(postprocess_mask(pred_rgb), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2) &#47&#47 [T, 3, h, w]

            frames_seg = torch.stack([seg_model(frames[:, i]) for i in range(frames.shape[1])], dim=1).argmax(dim=2)  &#47&#47 [1, T, 1, h, w]
            frames_seg_in<a id="change"> = </a>torch.stack([<a id="change">(frames_seg == i)</a> <a id="change">for</a> i in range(SYNPICK_CLASSES)], dim=2).float()  &#47&#47 [1, T, c, h, w] one-hot float
            input_seg = frames_seg_in[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, c, h, w]
            pred_mask = pred_mask_model.pred_n(input_seg, pred_length=VIDEO_PRED_LENGTH).argmax(dim=2)  &#47&#47 [1, n, 1, h, w]
            pred_mask = torch.cat([input_seg.argmax(dim=2), pred_mask], dim=1).squeeze()  &#47&#47 [T, h, w]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ais-bonn/vp-suite/commit/13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3#diff-e07d70acfca9139cbf2c37b7a0074bdfbb966d41dc6c7edcc2cef05e78c00af0L16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8946268</div><div id='project'> Project Name: ais-bonn/vp-suite</div><div id='commit'> Commit Name: 13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3</div><div id='time'> Time: 2021-08-02</div><div id='author'> Author: boltres@ais.uni-bonn.de</div><div id='file'> File Name: scripts/visualize_4_way.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: visualize_4_way(1)</div><div id='n_method'> N Method Name: visualize_4_way(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/visualize_4_way.py</div><div id='n_file'> N File Name: scripts/visualize_4_way.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 73</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 74</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Do this before wrapping.
        eval_dataset = dataloader.dataset

        <a id="change">if </a>is_torch_tpu_available():
            dataloader<a id="change"> = </a>pl.ParallelLoader(dataloader, [args.device]).per_device_loader(args.device)

        if args.past_index &gt;= 0:
            self._past = None</code></pre><h3>After Change</h3><pre><code class='java'>
        self.infer_sess = None

        &#47&#47 Check if there are labels in the dataset
        dummy_inputs<a id="change"> = </a><a id="change">next(iter(</a>dataloader<a id="change">)</a><a id="change">)</a>
        has_labels<a id="change"> = </a>all(<a id="change">dummy_inputs.get(k) is not None</a> <a id="change">for</a> k in self.label_names)

        if self.onnx_model_path and (has_labels == self.exported_with_loss):
            logger.info("[INFO] Inference with given ONNX model")</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/optimum/commit/1c4b5b1caf1f1a58c32898ffb208538d7364b73a#diff-2fce6a27b91f51e97c2c1e0b4c9b86dae5896189543dac9e0a8e4f6cec6b62f9L774' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8946272</div><div id='project'> Project Name: huggingface/optimum</div><div id='commit'> Commit Name: 1c4b5b1caf1f1a58c32898ffb208538d7364b73a</div><div id='time'> Time: 2022-04-29</div><div id='author'> Author: 44135271+JingyaHuang@users.noreply.github.com</div><div id='file'> File Name: optimum/onnxruntime/trainer.py</div><div id='m_class'> M Class Name: ORTTrainer</div><div id='n_method'> N Class Name: ORTTrainer</div><div id='m_method'> M Method Name: evaluation_loop_ort(6)</div><div id='n_method'> N Method Name: evaluation_loop_ort(6)</div><div id='m_parent_class'> M Parent Class: Trainer</div><div id='n_parent_class'> N Parent Class: Trainer</div><div id='m_file'> M File Name: optimum/onnxruntime/trainer.py</div><div id='n_file'> N File Name: optimum/onnxruntime/trainer.py</div><div id='m_start'> M Start Line: 791</div><div id='m_end'> M End Line: 894</div><div id='n_start'> N Start Line: 751</div><div id='n_end'> N End Line: 767</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        model.eval()

        <a id="change">if </a>is_torch_tpu_available():
            dataloader<a id="change"> = </a>pl.ParallelLoader(dataloader, [args.device]).per_device_loader(args.device)

        if args.past_index &gt;= 0:
            self._past = None</code></pre><h3>After Change</h3><pre><code class='java'>
        self.infer_sess = None

        &#47&#47 Check if there are labels in the dataset
        dummy_inputs<a id="change"> = </a><a id="change">next(iter(</a>dataloader<a id="change">)</a><a id="change">)</a>
        has_labels<a id="change"> = </a>all(<a id="change">dummy_inputs.get(k) is not None</a> <a id="change">for</a> k in self.label_names)

        if self.onnx_model_path and (has_labels == self.exported_with_loss):
            logger.info("[INFO] Inference with given ONNX model")</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/optimum/commit/1c4b5b1caf1f1a58c32898ffb208538d7364b73a#diff-2fce6a27b91f51e97c2c1e0b4c9b86dae5896189543dac9e0a8e4f6cec6b62f9L977' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8946275</div><div id='project'> Project Name: huggingface/optimum</div><div id='commit'> Commit Name: 1c4b5b1caf1f1a58c32898ffb208538d7364b73a</div><div id='time'> Time: 2022-04-29</div><div id='author'> Author: 44135271+JingyaHuang@users.noreply.github.com</div><div id='file'> File Name: optimum/onnxruntime/trainer.py</div><div id='m_class'> M Class Name: ORTTrainer</div><div id='n_method'> N Class Name: ORTTrainer</div><div id='m_method'> M Method Name: prediction_loop_ort(6)</div><div id='n_method'> N Method Name: prediction_loop_ort(6)</div><div id='m_parent_class'> M Parent Class: Trainer</div><div id='n_parent_class'> N Parent Class: Trainer</div><div id='m_file'> M File Name: optimum/onnxruntime/trainer.py</div><div id='n_file'> N File Name: optimum/onnxruntime/trainer.py</div><div id='m_start'> M Start Line: 993</div><div id='m_end'> M End Line: 1075</div><div id='n_start'> N Start Line: 951</div><div id='n_end'> N End Line: 970</div><BR>