<html><h3>Pattern ID :13542
</h3><img src='45595126.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    ) -&gt; Tuple[States, TensorBool]:
        Function that takes a batch of states and actions and returns a batch of next
        states and a boolean tensor indicating initial states in the new batch.
        <a id="change">pass</a>

    @abstractmethod
    def reward(self, final_states: States) -&gt; TensorFloat:
        pass</code></pre><h3>After Change</h3><pre><code class='java'>
    def backward_step(self, states: States, actions: TensorLong) -&gt; States:
        Function that takes a batch of states and actions and returns a batch of next
        states and a boolean tensor indicating initial states in the new batch.
        new_states<a id="change"> = </a>deepcopy(states)
        initial_states: TensorBool = new_states.is_initial_state()

        non_initial_states_masks = new_states.backward_masks[~initial_states]
        non_initial_actions<a id="change"> = </a>actions[~initial_states]
        actions_valid<a id="change"> = </a>all(
            torch.gather(non_initial_states_masks, 1, <a id="change">non_initial_actions.unsqueeze(1</a><a id="change">)</a>)
        )
        if not actions_valid:
            raise NonValidActionsError("Actions are not valid")

        not_done_states<a id="change"> = </a>new_states.states[~initial_states]
        self.backward_step_no_worry(not_done_states, non_initial_actions)

        new_states.states[~initial_states]<a id="change"> = </a>not_done_states

        self.update_masks(new_states)
        return new_states</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/saleml/gfn/commit/36c5ca5c3ead6a477cd0be4e7f8d3f04d1d8f9ca#diff-8afccb3dae31059eb5c5cdd762ad55eace9d95ae42f5c20e7e24bf28eff126b7L108' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45595126</div><div id='project'> Project Name: saleml/gfn</div><div id='commit'> Commit Name: 36c5ca5c3ead6a477cd0be4e7f8d3f04d1d8f9ca</div><div id='time'> Time: 2022-08-16</div><div id='author'> Author: salemlahlou9@gmail.com</div><div id='file'> File Name: gfn/envs/env.py</div><div id='m_class'> M Class Name: Env</div><div id='n_method'> N Class Name: Env</div><div id='m_method'> M Method Name: backward_step(3)</div><div id='n_method'> N Method Name: backward_step(3)</div><div id='m_parent_class'> M Parent Class: ABC</div><div id='n_parent_class'> N Parent Class: ABC</div><div id='m_file'> M File Name: gfn/envs/env.py</div><div id='n_file'> N File Name: gfn/envs/env.py</div><div id='m_start'> M Start Line: 135</div><div id='m_end'> M End Line: 135</div><div id='n_start'> N Start Line: 108</div><div id='n_end'> N End Line: 125</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        pass

    def _make_input_reference_position_id_pair(self, input_ids: torch.Tensor):
        <a id="change">pass</a>

    def _make_attention_mask(self, input_ids: torch.Tensor):
        pass
</code></pre><h3>After Change</h3><pre><code class='java'>
        return (token_type_ids, ref_token_type_ids)

    def _make_input_reference_position_id_pair(self, input_ids: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:
        seq_len<a id="change"> = </a>input_ids.size(1)
        position_ids<a id="change"> = </a>torch.arange(
            seq_len, dtype=torch.long, device=self.device)
        ref_position_ids<a id="change"> = </a>torch.zeros(
            seq_len, dtype=torch.long, device=self.device)
        position_ids<a id="change"> = </a>position_ids.unsqueeze(0).expand_as(input_ids)
        ref_position_ids<a id="change"> = </a><a id="change">ref_position_ids.unsqueeze(0</a><a id="change">)</a>.expand_as(input_ids)
        return (position_ids, ref_position_ids)

    def _make_attention_mask(self, input_ids: torch.Tensor) -&gt; torch.Tensor:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/cdpierse/transformers-interpret/commit/0f6342fb0bbcabe9ce3052bd6dcecab4397797a9#diff-83fff3c360fb4f78e2a87649dc7c2bf9c25b174b4f5a220c39da7193cc3c20c3L94' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45595125</div><div id='project'> Project Name: cdpierse/transformers-interpret</div><div id='commit'> Commit Name: 0f6342fb0bbcabe9ce3052bd6dcecab4397797a9</div><div id='time'> Time: 2020-07-20</div><div id='author'> Author: charlespierse@gmail.com</div><div id='file'> File Name: transformers_interpret/explainer.py</div><div id='m_class'> M Class Name: BaseExplainer</div><div id='n_method'> N Class Name: BaseExplainer</div><div id='m_method'> M Method Name: _make_input_reference_position_id_pair(2)</div><div id='n_method'> N Method Name: _make_input_reference_position_id_pair(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: transformers_interpret/explainer.py</div><div id='n_file'> N File Name: transformers_interpret/explainer.py</div><div id='m_start'> M Start Line: 95</div><div id='m_end'> M End Line: 95</div><div id='n_start'> N Start Line: 124</div><div id='n_end'> N End Line: 131</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>


    def dynamic_pooling(self, hidden_states: torch.Tensor, left: torch.Tensor, right: torch.Tensor) -&gt; torch.Tensor:
        <a id="change">pass</a> 


&#47&#47 To do </code></pre><h3>After Change</h3><pre><code class='java'>
        Returns:
            hidden_state: [batch_size, hidden_size*2]
        
        minimum<a id="change"> = </a>-(2**32-1)
        left_mask<a id="change"> = </a>(1 - position_mask) * minimum
        right_mask<a id="change"> = </a>(1-(input_mask-position_mask)) * minimum
        left_hidden_state<a id="change">, _ = </a>torch.max(hidden_states + <a id="change">left_mask.unsqueeze(-1</a><a id="change">)</a>, dim=1)
        right_hidden_state<a id="change">, _ = </a>torch.max(hidden_states + right_mask.unsqueeze(-1), dim=1)
        hidden_state = torch.cat((left_hidden_state, right_hidden_state), dim=-1)
        return hidden_state
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thu-keg/omnievent/commit/bc38773f650d53ae5e052432be4a9c522fefca30#diff-57a91bfe08ff7a8323688c6840572cdcbcb9dbb43a6f9197d309a66299fb5424L38' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45595140</div><div id='project'> Project Name: thu-keg/omnievent</div><div id='commit'> Commit Name: bc38773f650d53ae5e052432be4a9c522fefca30</div><div id='time'> Time: 2022-04-21</div><div id='author'> Author: penghao20170136@163.com</div><div id='file'> File Name: src/OpenEE/aggregation/aggregation.py</div><div id='m_class'> M Class Name: SimpleAggregation</div><div id='n_method'> N Class Name: SimpleAggregation</div><div id='m_method'> M Method Name: dynamic_pooling(4)</div><div id='n_method'> N Method Name: dynamic_pooling(4)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: src/OpenEE/aggregation/aggregation.py</div><div id='n_file'> N File Name: src/OpenEE/aggregation/aggregation.py</div><div id='m_start'> M Start Line: 39</div><div id='m_end'> M End Line: 39</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 55</div><BR>