<html><h3>Pattern ID :568
</h3><img src='2884524.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                        "set the dataloader with .set_loaders(...)"
                    )

            dataset_size = <a id="change">getattr(self, "dali_epoch_size", None) or len(dataloader.dataset)</a>

            dataset_size = self.trainer.limit_train_batches * dataset_size

            num_devices = 1</code></pre><h3>After Change</h3><pre><code class='java'>
        Compute the number of training steps for each epoch.

        if self._num_training_steps is None:
            <a id="change">try:
                </a>dataset = self.extra_args.get("dataset", None)
                if dataset not in ["cifar10", "cifar100", "stl10"]:
                    folder<a id="change"> = </a>os.path.join(self.extra_args["data_dir"], self.extra_args["train_dir"])
                else:
                    folder = None
                no_labels = self.extra_args.get("no_labels", False)
                data_fraction<a id="change"> = </a>self.extra_args.get("data_fraction", -1.0)

                dataset_size = compute_dataset_size(
                    dataset=dataset,
                    folder=folder,
                    train=True,
                    no_labels=no_labels,
                    data_fraction=data_fraction,
                )
            <a id="change">except</a>:
                <a id="change">raise </a><a id="change">RuntimeError(
                    "Please pass &quotdataset&quot or &quotdata_dir &quot"
                    "and &quottrain_dir&quot as parameters to the model."</a><a id="change">
                )</a>

            dataset_size = self.trainer.limit_train_batches * dataset_size

            num_devices = 1</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/vturrisi/contrastive-learning/commit/eb07a9c7c2872efb1ae83767f59a67fa616a7652#diff-bf0f79abb0e767723150e5fe64a4a5935492d2fcf2eb222cfe5f8c901bcd11b0L362' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2884524</div><div id='project'> Project Name: vturrisi/contrastive-learning</div><div id='commit'> Commit Name: eb07a9c7c2872efb1ae83767f59a67fa616a7652</div><div id='time'> Time: 2022-05-02</div><div id='author'> Author: vt.turrisi@gmail.com</div><div id='file'> File Name: solo/methods/base.py</div><div id='m_class'> M Class Name: BaseMethod</div><div id='n_method'> N Class Name: BaseMethod</div><div id='m_method'> M Method Name: num_training_steps(1)</div><div id='n_method'> N Method Name: num_training_steps(1)</div><div id='m_parent_class'> M Parent Class: pl.LightningModule</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: solo/methods/base.py</div><div id='n_file'> N File Name: solo/methods/base.py</div><div id='m_start'> M Start Line: 383</div><div id='m_end'> M End Line: 392</div><div id='n_start'> N Start Line: 362</div><div id='n_end'> N End Line: 384</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        array, sampling_rate = torchaudio.load(path_or_file, format="mp3")
        if self.sampling_rate and self.sampling_rate != sampling_rate:
            if <a id="change">not hasattr(self, "_resampler") or self._resampler.orig_freq != sampling_rate</a>:
                self._resampler = T.Resample(sampling_rate, self.sampling_rate)
            array = self._resampler(array)
            sampling_rate = self.sampling_rate</code></pre><h3>After Change</h3><pre><code class='java'>
                raise ImportError("To support decoding &quotmp3&quot audio files, please install &quotsox&quot.") from err
            array, sampling_rate = self._decode_mp3_torchaudio(path_or_file)
        else:
            <a id="change">try:  &#47&#47 try torchaudio anyway because sometimes it works (depending on the os and os packages installed)
                </a>array<a id="change">, sampling_rate = </a>self._decode_mp3_torchaudio(path_or_file)
            except RuntimeError:
                try:
                    &#47&#47 flake8: noqa
                    import librosa
                except ImportError as err:
                    raise ImportError(
                        "Your version of `torchaudio` (&gt;=0.12.0) doesn&quott support decoding &quotmp3&quot files on your machine. "
                        "To support &quotmp3&quot decoding with `torchaudio&gt;=0.12.0`, please install `ffmpeg&gt;=4` system package "
                        &quotor downgrade `torchaudio` to &lt;0.12: `pip install "torchaudio&lt;0.12"`. &quot
                        "To support decoding &quotmp3&quot audio files without `torchaudio`, please install `librosa`: "
                        "`pip install librosa`. Note that decoding will be extremely slow in that case."
                    ) from err
                &#47&#47 try to decode with librosa for torchaudio&gt;=0.12.0 as a workaround
                warnings.warn("Decoding mp3 with `librosa` instead of `torchaudio`, decoding is slow.")
                try:
                    array<a id="change">, sampling_rate = </a>self._decode_mp3_librosa(path_or_file)
                <a id="change">except </a>RuntimeError as err:
                    <a id="change">raise RuntimeError(
                        "Decoding of &quotmp3&quot failed, probably because of streaming mode "
                        "(`librosa` cannot decode &quotmp3&quot file-like objects, only path-like)."
                    ) from </a>err

        return array, sampling_rate
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/datasets/commit/142404f9ce8fe4e7a72e8c59be70a012b6f707cd#diff-a633089cfc19bde2aaf3ab69fe0b274597ce4b9ba9b8d081382f71ee9f767b0dL282' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2884520</div><div id='project'> Project Name: huggingface/datasets</div><div id='commit'> Commit Name: 142404f9ce8fe4e7a72e8c59be70a012b6f707cd</div><div id='time'> Time: 2022-09-20</div><div id='author'> Author: polina@huggingface.co</div><div id='file'> File Name: src/datasets/features/audio.py</div><div id='m_class'> M Class Name: Audio</div><div id='n_method'> N Class Name: Audio</div><div id='m_method'> M Method Name: _decode_mp3(2)</div><div id='n_method'> N Method Name: _decode_mp3(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/datasets/features/audio.py</div><div id='n_file'> N File Name: src/datasets/features/audio.py</div><div id='m_start'> M Start Line: 290</div><div id='m_end'> M End Line: 308</div><div id='n_start'> N Start Line: 288</div><div id='n_end'> N End Line: 319</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                        "set the dataloader with .set_loaders(...)"
                    )

            dataset_size = <a id="change">getattr(self, "dali_epoch_size", None) or len(dataloader.dataset)</a>

            dataset_size = self.trainer.limit_train_batches * dataset_size

            num_devices = 1</code></pre><h3>After Change</h3><pre><code class='java'>
        Compute the number of training steps for each epoch.

        if self._num_training_steps is None:
            <a id="change">try:
                </a>dataset = self.extra_args.get("dataset", None)
                if dataset not in ["cifar10", "cifar100", "stl10"]:
                    folder = os.path.join(self.extra_args["data_dir"], self.extra_args["train_dir"])
                else:
                    folder = None
                no_labels = self.extra_args.get("no_labels", False)
                data_fraction<a id="change"> = </a>self.extra_args.get("data_fraction", -1.0)

                dataset_size<a id="change"> = </a>compute_dataset_size(
                    dataset=dataset,
                    folder=folder,
                    train=True,
                    no_labels=no_labels,
                    data_fraction=data_fraction,
                )
            <a id="change">except</a>:
                <a id="change">raise </a><a id="change">RuntimeError(
                    "Please pass &quotdataset&quot or &quotdata_dir &quot"
                    "and &quottrain_dir&quot as parameters to the model."</a><a id="change">
                )</a>

            dataset_size = self.trainer.limit_train_batches * dataset_size

            num_devices = 1</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/vturrisi/contrastive-learning/commit/eb07a9c7c2872efb1ae83767f59a67fa616a7652#diff-306471ca72f10d091f7adabfddc03e702f662348314d589d172c5c700eae27abL195' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2884536</div><div id='project'> Project Name: vturrisi/contrastive-learning</div><div id='commit'> Commit Name: eb07a9c7c2872efb1ae83767f59a67fa616a7652</div><div id='time'> Time: 2022-05-02</div><div id='author'> Author: vt.turrisi@gmail.com</div><div id='file'> File Name: solo/methods/linear.py</div><div id='m_class'> M Class Name: LinearModel</div><div id='n_method'> N Class Name: LinearModel</div><div id='m_method'> M Method Name: num_training_steps(1)</div><div id='n_method'> N Method Name: num_training_steps(1)</div><div id='m_parent_class'> M Parent Class: pl.LightningModule</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: solo/methods/linear.py</div><div id='n_file'> N File Name: solo/methods/linear.py</div><div id='m_start'> M Start Line: 199</div><div id='m_end'> M End Line: 208</div><div id='n_start'> N Start Line: 184</div><div id='n_end'> N End Line: 206</div><BR>