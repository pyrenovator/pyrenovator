<html><h3>Pattern ID :11951
</h3><img src='40514026.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        x = x.unsqueeze(-1)
        x = self.project_to_steps(x)  &#47&#47 BxCxTxS
        x = self.dropout(x)
        x = <a id="change">x.unsqueeze(0</a><a id="change">)</a>.expand(targets.size(0), -1, -1, -1, -1)

        copies, bsz, dim, tsz, steps = x.shape
        steps = min(steps, tsz - self.offset)
        predictions = x.new(bsz * copies * (tsz - self.offset + 1) * steps - ((steps + 1) * steps // 2) * copies * bsz)
        labels = torch.zeros_like(predictions)
        weights = torch.full_like(labels, 1 / self.n_negatives) if self.balanced_classes else None

        start = end = 0
        for i in range(steps):
            offset = i + self.offset
            end = start + (tsz - offset) * bsz * copies
            pos_num = (end - start) // copies
            predictions[start:end] = (x[..., :-offset, i]<a id="change"> * </a>targets[..., offset:]).sum(dim=2).flatten()
            labels[start:start + pos_num] = 1.
            if weights is not None:
                weights[start:start + pos_num] = 1.</code></pre><h3>After Change</h3><pre><code class='java'>
            else:
                pos_num = (end - start) // copies
                predictions[start:end] = torch.einsum(
                    "bct,nbct-&gt;nbt", x[..., :<a id="change">-offset</a>, i], <a id="change">targets[..., offset:]</a>
                ).flatten()
                labels[start : start + pos_num] = 1.0
                if weights is not None:
                    weights[start : start + pos_num] = 1.0</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/kssteven418/i-bert/commit/3335de5f441ee1b3824e16dcd98db620e40beaba#diff-9b4dd2bdb515c86c631253c805af3041e9bbf4ce7f68af6a1900ef5b4ffa5c5aL411' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 40514026</div><div id='project'> Project Name: kssteven418/i-bert</div><div id='commit'> Commit Name: 3335de5f441ee1b3824e16dcd98db620e40beaba</div><div id='time'> Time: 2020-02-29</div><div id='author'> Author: alexei.b@gmail.com</div><div id='file'> File Name: fairseq/models/wav2vec.py</div><div id='m_class'> M Class Name: Wav2VecPredictionsModel</div><div id='n_method'> N Class Name: Wav2VecPredictionsModel</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: fairseq/models/wav2vec.py</div><div id='n_file'> N File Name: fairseq/models/wav2vec.py</div><div id='m_start'> M Start Line: 411</div><div id='m_end'> M End Line: 439</div><div id='n_start'> N Start Line: 638</div><div id='n_end'> N End Line: 691</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    from relative distances (with length 2*tokens-1) to absolute distance (length tokens)
    
    query_index = torch.arange(tokens).unsqueeze(0)  &#47&#47 [1, dim]
    key_index = <a id="change">torch.arange(tokens).unsqueeze(1</a><a id="change">)</a>  &#47&#47 [dim, 1]

    relative_index = (key_index<a id="change"> - </a>query_index) + tokens - 1  &#47&#47 dim X dim (zero indexed)
    flatten_index = rearrange(relative_index, &quoti j-&gt;(i j)&quot)  &#47&#47 flatten
    abs_emb = torch.index_select(q_rel, axis, flatten_index)  &#47&#47 [head_planes , (dim*dim)]
    return rearrange(abs_emb, &quotb h t (x y) -&gt; b h t x y&quot, x=tokens)</code></pre><h3>After Change</h3><pre><code class='java'>
    flat_x = rearrange(x, &quotb h l c -&gt; b h (l c)&quot)
    flat_pad = torch.zeros((b, h, l - 1), **dd)
    flat_x_padded = torch.cat((flat_x, flat_pad), dim=2)
    final_x = flat_x_padded.reshape(b, h, l + 1, 2<a id="change"> * </a>l - 1)
    final_x = <a id="change">final_x[:, :, :l, (l - 1):]</a>
    return final_x


def rel_pos_emb_1d(q, rel_emb, shared_heads):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/the-ai-summer/self-attention-cv/commit/400427e8b940a91d0baa90037b7bf2308c8bc9e9#diff-f79da185517a56871e3cc6d2d4115a64d416dea8e8acec3c6ee83a6fae923630L6' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 40514024</div><div id='project'> Project Name: the-ai-summer/self-attention-cv</div><div id='commit'> Commit Name: 400427e8b940a91d0baa90037b7bf2308c8bc9e9</div><div id='time'> Time: 2021-02-09</div><div id='author'> Author: black.adaloglou@gmail.com</div><div id='file'> File Name: self_attention_cv/pos_embeddings/relative_embeddings_1D.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: relative_to_absolute(1)</div><div id='n_method'> N Method Name: relative_to_absolute(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: self_attention_cv/pos_embeddings/relative_embeddings_1D.py</div><div id='n_file'> N File Name: self_attention_cv/pos_embeddings/relative_embeddings_1D.py</div><div id='m_start'> M Start Line: 6</div><div id='m_end'> M End Line: 17</div><div id='n_start'> N Start Line: 11</div><div id='n_end'> N End Line: 27</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        x = x.unsqueeze(-1)
        x = self.project_to_steps(x)  &#47&#47 BxCxTxS
        x = self.dropout(x)
        x = <a id="change">x.unsqueeze(0</a><a id="change">)</a>.expand(targets.size(0), -1, -1, -1, -1)

        copies, bsz, dim, tsz, steps = x.shape
        steps = min(steps, tsz - self.offset)
        predictions = x.new(bsz * copies * (tsz - self.offset + 1) * steps - ((steps + 1) * steps // 2) * copies * bsz)
        labels = torch.zeros_like(predictions)
        weights = torch.full_like(labels, 1 / self.n_negatives) if self.balanced_classes else None

        start = end = 0
        for i in range(steps):
            offset = i + self.offset
            end = start + (tsz - offset) * bsz * copies
            pos_num = (end - start) // copies
            predictions[start:end] = (x[..., :-offset, i]<a id="change"> * </a>targets[..., offset:]).sum(dim=2).flatten()
            labels[start:start + pos_num] = 1.
            if weights is not None:
                weights[start:start + pos_num] = 1.</code></pre><h3>After Change</h3><pre><code class='java'>

        start = end = 0
        for i in range(steps):
            <a id="change">offset</a> = i + self.offset
            end = start + (tsz - offset) * bsz * copies
            if self.infonce:
                predictions[start:end] = torch.einsum(
                    "bct,nbct-&gt;tbn", x[..., :-offset, i], targets[..., offset:]
                ).flatten()
            else:
                pos_num = (end - start) // copies
                predictions[start:end] = torch.einsum(
                    "bct,nbct-&gt;nbt", x[..., :<a id="change">-offset</a>, i], <a id="change">targets[..., offset:]</a>
                ).flatten()
                labels[start : start + pos_num] = 1.0
                if weights is not None:
                    weights[start : start + pos_num] = 1.0</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mohammadkhalifa/fairseq-tagging/commit/3335de5f441ee1b3824e16dcd98db620e40beaba#diff-9b4dd2bdb515c86c631253c805af3041e9bbf4ce7f68af6a1900ef5b4ffa5c5aL408' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 40514007</div><div id='project'> Project Name: mohammadkhalifa/fairseq-tagging</div><div id='commit'> Commit Name: 3335de5f441ee1b3824e16dcd98db620e40beaba</div><div id='time'> Time: 2020-02-29</div><div id='author'> Author: alexei.b@gmail.com</div><div id='file'> File Name: fairseq/models/wav2vec.py</div><div id='m_class'> M Class Name: Wav2VecPredictionsModel</div><div id='n_method'> N Class Name: Wav2VecPredictionsModel</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: fairseq/models/wav2vec.py</div><div id='n_file'> N File Name: fairseq/models/wav2vec.py</div><div id='m_start'> M Start Line: 411</div><div id='m_end'> M End Line: 439</div><div id='n_start'> N Start Line: 638</div><div id='n_end'> N End Line: 691</div><BR>