<html><h3>Pattern ID :22518
</h3><img src='71173310.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 masked by the missing entries
        &#47&#47 note, different batch may contain different number of real entities
        tensor_list = []
        <a id="change">for </a>i, batch in enumerate(out)<a id="change">:
            </a>mean_entity = 0.
            real_number<a id="change"> = </a><a id="change">real_number_tensor[i]</a>
            real_number = real_number if real_number != 0 else 1
            for j, entity in enumerate(batch):
                if j &gt;= real_number_tensor[i]:</code></pre><h3>After Change</h3><pre><code class='java'>
        print(&quotentity_num:&quot, entity_num) if debug else None

        &#47&#47 generate the mask for transformer
        mask = <a id="change">torch.arange(0, self.max_entities).float()</a>
        mask<a id="change"> = </a>mask.repeat(batch_size, 1)
        mask = mask &lt; entity_num.unsqueeze(dim=1)

        print(&quotmask:&quot, mask) if debug else None
        print(&quotmask.shape:&quot, mask.shape) if debug else None

        &#47&#47 mask: [batch_size, max_entities]
        device = next(self.parameters()).device
        mask = mask.to(device)

        &#47&#47 assert the input shape is : batch_seq_size x entities_size x embeding_size
        &#47&#47 note: because the feature size of entity is not equal to 256, so it can not fed into transformer directly.
        &#47&#47 thus, we add a embedding layer to transfer it to right size.
        &#47&#47 x is batch_entities_tensor (dim = 3). Shape: batch_seq_size x entities_size x embeding_size
        x = self.embedd(x)
        print(&quotx.shape:&quot, x.shape) if debug else None

        &#47&#47 mask for transformer need a special format
        mask_seq_len = mask.shape[-1]
        tran_mask = mask.unsqueeze(1)

        &#47&#47 tran_mask: [batch_seq_size x max_entities x max_entities]
        tran_mask = tran_mask.repeat(1, mask_seq_len, 1)

        &#47&#47 out: [batch_seq_size x entities_size x embeding_size]
        out = self.transformer(x, mask=tran_mask)
        print(&quotout.shape:&quot, out.shape) if debug else None

        &#47&#47 entity_embeddings: [batch_seq_size x entities_size x conv1_output_size]
        entity_embeddings = F.relu(self.conv1(F.relu(out).transpose(1, 2))).transpose(1, 2)
        print(&quotentity_embeddings.shape:&quot, entity_embeddings.shape) if debug else None

        &#47&#47 AlphaStar: The mean of the transformer output across across the units (masked by the missing entries) 
        &#47&#47 is fed through a linear layer of size 256 and a ReLU to yield `embedded_entity`
        masked_out<a id="change"> = </a>out<a id="change"> * </a>mask.unsqueeze(2)

        &#47&#47 sum over across the units
        &#47&#47 masked_out: [batch_seq_size x entities_size x embeding_size]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/liuruoze/mini-alphastar/commit/612d42a7bf5ef827e1e919198d839fce106155cd#diff-71869e70f9cb835282d541d2d3529d25b6ed6795c79bc770e860e9318619f6b1L716' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 71173310</div><div id='project'> Project Name: liuruoze/mini-alphastar</div><div id='commit'> Commit Name: 612d42a7bf5ef827e1e919198d839fce106155cd</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: liuruoze@163.com</div><div id='file'> File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_class'> M Class Name: EntityEncoder</div><div id='n_method'> N Class Name: EntityEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='n_file'> N File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_start'> M Start Line: 721</div><div id='m_end'> M End Line: 758</div><div id='n_start'> N Start Line: 716</div><div id='n_end'> N End Line: 778</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        else:
            raise ValueError(&quotThis similarity is not implemented.&quot)
        loss = list()
        <a id="change">for i</a> in range(batch_size)<a id="change">:
            </a>pos_index = labels == labels[i]
            pos_index[i] = 0
            neg_index = labels != labels[i]
            pos_pair_<a id="change"> = </a><a id="change">sim_mat[i][pos_index]</a>
            neg_pair_ = sim_mat[i][neg_index]

            alpha_p = torch.relu(-pos_pair_ + 1 + self.margin)</code></pre><h3>After Change</h3><pre><code class='java'>
            f"feats.size(0): {feats.size(0)} is not equal to labels.size(0): {labels.size(0)}"

        m = labels.size(0)
        mask<a id="change"> = </a><a id="change">labels.expand(m, m).t().eq(labels.expand(m, m)).float()</a>
        pos_mask = mask.triu(diagonal=1)
        neg_mask<a id="change"> = </a>(mask<a id="change"> - </a>1).abs_().triu(diagonal=1)
        if self.similarity == &quotdot&quot:
            sim_mat = torch.matmul(feats, torch.t(feats))
        elif self.similarity == &quotcos&quot:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/qianjinhao/circle-loss/commit/55a6035c552f781d6c761475f88b33b8f684fbe7#diff-ee4498af95089c1dacb3bbdedbf8cffa6eecc60617a8a1d405b07f6f81510abbL13' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 71173311</div><div id='project'> Project Name: qianjinhao/circle-loss</div><div id='commit'> Commit Name: 55a6035c552f781d6c761475f88b33b8f684fbe7</div><div id='time'> Time: 2020-04-02</div><div id='author'> Author: qianjinhao@126.com</div><div id='file'> File Name: circle_loss.py</div><div id='m_class'> M Class Name: CircleLoss</div><div id='n_method'> N Class Name: CircleLoss</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: circle_loss.py</div><div id='n_file'> N File Name: circle_loss.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 40</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 38</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 masked by the missing entries
        &#47&#47 note, different batch may contain different number of real entities
        tensor_list = []
        <a id="change">for </a>i, <a id="change">batch</a> in enumerate(out)<a id="change">:
            </a>mean_entity = 0.
            real_number<a id="change"> = </a><a id="change">real_number_tensor[i]</a>
            real_number = real_number if real_number != 0 else 1
            for j, entity in enumerate(batch):
                if j &gt;= real_number_tensor[i]:</code></pre><h3>After Change</h3><pre><code class='java'>
        print(&quotentity_num:&quot, entity_num) if debug else None

        &#47&#47 generate the mask for transformer
        mask<a id="change"> = </a><a id="change">torch.arange(0, self.max_entities).float()</a>
        mask = mask.repeat(batch_size, 1)
        mask = mask &lt; entity_num.unsqueeze(dim=1)

        print(&quotmask:&quot, mask) if debug else None
        print(&quotmask.shape:&quot, mask.shape) if debug else None

        &#47&#47 mask: [batch_size, max_entities]
        device = next(self.parameters()).device
        mask = mask.to(device)

        &#47&#47 assert the input shape is : batch_seq_size x entities_size x embeding_size
        &#47&#47 note: because the feature size of entity is not equal to 256, so it can not fed into transformer directly.
        &#47&#47 thus, we add a embedding layer to transfer it to right size.
        &#47&#47 x is batch_entities_tensor (dim = 3). Shape: batch_seq_size x entities_size x embeding_size
        x = self.embedd(x)
        print(&quotx.shape:&quot, x.shape) if debug else None

        &#47&#47 mask for transformer need a special format
        mask_seq_len = mask.shape[-1]
        tran_mask = mask.unsqueeze(1)

        &#47&#47 tran_mask: [batch_seq_size x max_entities x max_entities]
        tran_mask = tran_mask.repeat(1, mask_seq_len, 1)

        &#47&#47 out: [batch_seq_size x entities_size x embeding_size]
        out = self.transformer(x, mask=tran_mask)
        print(&quotout.shape:&quot, out.shape) if debug else None

        &#47&#47 entity_embeddings: [batch_seq_size x entities_size x conv1_output_size]
        entity_embeddings = F.relu(self.conv1(F.relu(out).transpose(1, 2))).transpose(1, 2)
        print(&quotentity_embeddings.shape:&quot, entity_embeddings.shape) if debug else None

        &#47&#47 AlphaStar: The mean of the transformer output across across the units (masked by the missing entries) 
        &#47&#47 is fed through a linear layer of size 256 and a ReLU to yield `embedded_entity`
        masked_out = out * mask.unsqueeze(2)

        &#47&#47 sum over across the units
        &#47&#47 masked_out: [batch_seq_size x entities_size x embeding_size]
        &#47&#47 z: [batch_size, embeding_size]
        z = masked_out.sum(dim=1, keepdim=False)

        &#47&#47 here we should dived by the entity_num, not the cls.max_entities
        &#47&#47 z: [batch_size, embeding_size]
        z<a id="change"> = </a>z<a id="change"> / </a>entity_num

        &#47&#47 note, dim=1 means the mean is across all entities in one timestep
        &#47&#47 The mean of the transformer output across across the units  </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/liuruoze/mini-alphastar/commit/612d42a7bf5ef827e1e919198d839fce106155cd#diff-71869e70f9cb835282d541d2d3529d25b6ed6795c79bc770e860e9318619f6b1L717' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 71173308</div><div id='project'> Project Name: liuruoze/mini-alphastar</div><div id='commit'> Commit Name: 612d42a7bf5ef827e1e919198d839fce106155cd</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: liuruoze@163.com</div><div id='file'> File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_class'> M Class Name: EntityEncoder</div><div id='n_method'> N Class Name: EntityEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='n_file'> N File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_start'> M Start Line: 721</div><div id='m_end'> M End Line: 758</div><div id='n_start'> N Start Line: 716</div><div id='n_end'> N End Line: 778</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 invert noise for bright regions (bright regions are considered being on average &gt; 0.33 * 255)
        generated_noise = generated_noise.int()
        bright_regions = img.sum(1) &gt; brightness_threshold * img.shape[1]
        <a id="change">for ch</a> in range(img.shape[1])<a id="change">:
            </a>gnch = generated_noise[:, ch]
            <a id="change">gnch[bright_regions]</a> = gnch[bright_regions] * -1
            generated_noise[:, ch]<a id="change"> = </a>gnch

        anom = (anom.int() + generated_noise).clamp(0, 255).byte()
</code></pre><h3>After Change</h3><pre><code class='java'>
        diff = ((anom.int() + generated_noise).clamp(0, 255) - anom.int())
        diff = diff.reshape(anom.size(0), -1).sum(1).float().div(np.prod(anom.shape)).abs()
        diffi = ((anom.int() - generated_noise).clamp(0, 255) - anom.int())
        diffi<a id="change"> = </a><a id="change">diffi.reshape(anom.size(0), -1).sum(1).float()</a>.div(np.prod(anom.shape)).abs()
        inv = [i for i, (d, di) in enumerate(zip(diff, diffi)) if d &lt; invert_threshold and di &gt; d]
        generated_noise[inv]<a id="change"> = -generated_noise[inv]</a>

        anom = (anom.int() + generated_noise).clamp(0, 255).byte()

        t = 1 if not hasattr(ds, &quotanomalous_label&quot) else ds.anomalous_label  &#47&#47 target transform has already been applied</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/liznerski/fcdd/commit/d110aa8b141dc13f47156da913a6b4f9d64ddc74#diff-fb7d9650a48b1de740043527c5d5e928e02fb69b57694006eafa311d213e906cL133' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 71173304</div><div id='project'> Project Name: liznerski/fcdd</div><div id='commit'> Commit Name: d110aa8b141dc13f47156da913a6b4f9d64ddc74</div><div id='time'> Time: 2020-10-12</div><div id='author'> Author: p_liznersk13@cs.uni-kl.de</div><div id='file'> File Name: python/fcdd/datasets/online_superviser.py</div><div id='m_class'> M Class Name: OnlineSuperviser</div><div id='n_method'> N Class Name: OnlineSuperviser</div><div id='m_method'> M Method Name: __malformed_normal(8)</div><div id='n_method'> N Method Name: __malformed_normal(8)</div><div id='m_parent_class'> M Parent Class: ImgGTTargetTransform</div><div id='n_parent_class'> N Parent Class: ImgGTTargetTransform</div><div id='m_file'> M File Name: python/fcdd/datasets/online_superviser.py</div><div id='n_file'> N File Name: python/fcdd/datasets/online_superviser.py</div><div id='m_start'> M Start Line: 139</div><div id='m_end'> M End Line: 146</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 151</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if center == "median":
        cum_dist = torch.cumsum(distogram, dim=-1)
        central  = torch.searchsorted(cum_dist, 0.5)
        <a id="change">for i</a> in range(shape[-1])<a id="change">:
            </a>central[central==i]<a id="change"> = </a><a id="change">bins[i]</a>
    elif center == "mean":
        central  = (distogram*bins).sum(dim=-1)
    &#47&#47 mask diagonal to 0 dist
    central[np.arange(shape[-2]), np.arange(shape[-3])] = 0.</code></pre><h3>After Change</h3><pre><code class='java'>
    elif center == "mean":
        central  = (distogram * n_bins).sum(dim=-1)
    &#47&#47 create mask for last class - (IGNORE_INDEX)   
    mask<a id="change"> = </a><a id="change">(central &lt;= bins[-2].item()).float()</a>
    &#47&#47 mask diagonal to 0 dist 
    central[np.arange(shape[-2]), np.arange(shape[-3])] = 0.
    &#47&#47 provide weights
    if wide == "var":
        dispersion = (distogram * (n_bins - central.unsqueeze(-1))**2).sum(dim=-1)
    elif wide == "std":
        dispersion = (distogram * (n_bins - central.unsqueeze(-1))**2).sum(dim=-1).sqrt()
    else:
        dispersion = torch.zeros_like(central)
    &#47&#47 rescale to 0-1. lower std / var  --&gt; weight=1
    weights<a id="change"> = </a>mask<a id="change"> / </a>(1+dispersion)

    return central, dispersion, weights
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/alphafold2/commit/c06c4f9c3730bde0428f72a973b0d38632c2646b#diff-09d0cbaf891d623ac245ccf84485a687b554217349ca55557c60b33234b969aeL127' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 71173320</div><div id='project'> Project Name: lucidrains/alphafold2</div><div id='commit'> Commit Name: c06c4f9c3730bde0428f72a973b0d38632c2646b</div><div id='time'> Time: 2021-01-16</div><div id='author'> Author: ericacaide1@gmail.com</div><div id='file'> File Name: utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: center_distogram_torch(5)</div><div id='n_method'> N Method Name: center_distogram_torch(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: utils.py</div><div id='n_file'> N File Name: utils.py</div><div id='m_start'> M Start Line: 136</div><div id='m_end'> M End Line: 157</div><div id='n_start'> N Start Line: 138</div><div id='n_end'> N End Line: 164</div><BR>