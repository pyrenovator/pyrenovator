<html><h3>Pattern ID :5893
</h3><img src='20791421.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            itemgetter("action_scaled", "log_prob")(self.policy_network.sample(next_obs_batch))

        next_state_q1_value = self.target_q1_network(torch.cat([next_obs_batch, next_state_action], dim=1))
        next_state_q2_value<a id="change"> = </a>self.target_q2_network(torch.cat([next_obs_batch, next_state_action], dim=1))
        next_state_min_q = torch.min(next_state_q1_value, next_state_q2_value)
        target_q = (next_state_min_q - self.alpha * next_state_log_pi)
        target_q = reward_batch + self.gamma * (1. - done_batch) * target_q

        &#47&#47compute q loss and backward
        
        q1_loss = F.mse_loss(curr_state_q1_value, target_q.detach())
        q2_loss = F.mse_loss(curr_state_q2_value, <a id="change">target_q.detach()</a>)

        q1_loss_value = q1_loss.detach().cpu().numpy()
        q2_loss_value = <a id="change">q2_loss.detach().cpu().numpy()</a>

        self.q1_optimizer.zero_grad()
        self.q2_optimizer.zero_grad()
        (q1_loss + q2_loss).backward()</code></pre><h3>After Change</h3><pre><code class='java'>
        reward_batch = reward_batch * self.reward_scale
        curr_state_q1_value = self.q1_network(torch.cat([obs_batch, action_batch],dim=1))
        curr_state_q2_value = self.q2_network(torch.cat([obs_batch, action_batch],dim=1))
        <a id="change">with torch.no_grad()</a><a id="change">:
            </a>next_state_action, next_state_log_pi = \
                itemgetter("action_scaled", "log_prob")(self.policy_network.sample(next_obs_batch))

            next_state_q1_value = self.target_q1_network(torch.cat([next_obs_batch, next_state_action], dim=1))
            next_state_q2_value<a id="change"> = </a>self.target_q2_network(torch.cat([next_obs_batch, next_state_action], dim=1))
            next_state_min_q = torch.min(next_state_q1_value, next_state_q2_value)
            target_q = (next_state_min_q - self.alpha * next_state_log_pi)
            target_q = reward_batch + self.gamma * (1. - done_batch) * target_q</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/x35f/unstable_baselines/commit/fd650918d0f96ab53625afed362025e5a53c10a6#diff-8aaf76f4210aca833593cb055f627f6de2656b301420e6ebb8fe67bf581c1f64L78' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 20791421</div><div id='project'> Project Name: x35f/unstable_baselines</div><div id='commit'> Commit Name: fd650918d0f96ab53625afed362025e5a53c10a6</div><div id='time'> Time: 2022-06-13</div><div id='author'> Author: 1621322691@qq.com</div><div id='file'> File Name: unstable_baselines/baselines/sac/agent.py</div><div id='m_class'> M Class Name: SACAgent</div><div id='n_method'> N Class Name: SACAgent</div><div id='m_method'> M Method Name: update(2)</div><div id='n_method'> N Method Name: update(2)</div><div id='m_parent_class'> M Parent Class: BaseAgent,torch.nn.Module</div><div id='n_parent_class'> N Parent Class: BaseAgent,torch.nn.Module</div><div id='m_file'> M File Name: unstable_baselines/baselines/sac/agent.py</div><div id='n_file'> N File Name: unstable_baselines/baselines/sac/agent.py</div><div id='m_start'> M Start Line: 78</div><div id='m_end'> M End Line: 139</div><div id='n_start'> N Start Line: 78</div><div id='n_end'> N End Line: 131</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for batch_idx, (data, target) in enumerate(self.train_data_loader):
            data, target = data.to(self.device), target.to(self.device)

            output_tc<a id="change"> = </a>self.teacher(data)
            &#47&#47 TODO: Find an elegant way to free the feature map and computation graph
            output_tc = torch.tensor(<a id="change">output_tc.detach().cpu().numpy()</a>).cuda()
            
            output_st = self.student(data)
            supervised_loss = self.criterion(output_st, target)/self.accumulation_steps</code></pre><h3>After Change</h3><pre><code class='java'>
        for batch_idx, (data, target) in enumerate(self.train_data_loader):
            data, target = data.to(self.device), target.to(self.device)

            <a id="change">with torch.no_grad()</a><a id="change">:
                </a>output_tc<a id="change"> = </a>self.teacher(data)
                &#47&#47 TODO: Find an elegant way to free the feature map and computation graph
                &#47&#47output_tc = torch.tensor(output_tc.detach().cpu().numpy()).cuda()
            </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lehduong/knowledge-distillation-by-replacing-cheap-conv/commit/7b28b7ea3d6766ff87845d80d5bdc6ef5165cf58#diff-0564ece5aadc13d5923043addc422a8058c6d96026493e84652cedc2f1bdca99L171' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 20791397</div><div id='project'> Project Name: lehduong/knowledge-distillation-by-replacing-cheap-conv</div><div id='commit'> Commit Name: 7b28b7ea3d6766ff87845d80d5bdc6ef5165cf58</div><div id='time'> Time: 2020-01-22</div><div id='author'> Author: oopsxilitol@gmail.com</div><div id='file'> File Name: trainer/trainer.py</div><div id='m_class'> M Class Name: TrainerTeacherAssistant</div><div id='n_method'> N Class Name: TrainerTeacherAssistant</div><div id='m_method'> M Method Name: _train_epoch(2)</div><div id='n_method'> N Method Name: _train_epoch(2)</div><div id='m_parent_class'> M Parent Class: BaseTrainer,BaseKnowledgeDistillationTrainer</div><div id='n_parent_class'> N Parent Class: BaseTrainer,BaseKnowledgeDistillationTrainer</div><div id='m_file'> M File Name: trainer/trainer.py</div><div id='n_file'> N File Name: trainer/trainer.py</div><div id='m_start'> M Start Line: 182</div><div id='m_end'> M End Line: 184</div><div id='n_start'> N Start Line: 182</div><div id='n_end'> N End Line: 187</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            inputs = inputs.to(device)

            &#47&#47 Run inputs through model
            outputs<a id="change"> = </a>model(**inputs)

            &#47&#47 Run pooling logic on outputs
            outputs = self.pooling(outputs, inputs["attention_mask"])

            &#47&#47 Get NumPy array and return
            return <a id="change">outputs.detach().cpu().numpy()</a>

        &#47&#47 Build embeddings using sentence transformers
        return self.model.encode(documents, show_progress_bar=False)
</code></pre><h3>After Change</h3><pre><code class='java'>
                inputs = inputs.to(device)

                &#47&#47 Run inputs through model
                <a id="change">with torch.no_grad()</a><a id="change">:
                    </a>outputs<a id="change"> = </a>model(**inputs)

                &#47&#47 Run pooling logic on outputs
                outputs = self.pooling(outputs, inputs["attention_mask"])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neuml/txtai/commit/6d4417c1258c2b73ee9b0292d0efd7245beb2688#diff-56ce8d6aaf78b4cfa8f7edf0165fe5a6facc4de5eea6236adf8ce1acfaad6307L129' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 20791410</div><div id='project'> Project Name: neuml/txtai</div><div id='commit'> Commit Name: 6d4417c1258c2b73ee9b0292d0efd7245beb2688</div><div id='time'> Time: 2021-08-13</div><div id='author'> Author: 561939+davidmezzetti@users.noreply.github.com</div><div id='file'> File Name: src/python/txtai/vectors/transformers.py</div><div id='m_class'> M Class Name: TransformersVectors</div><div id='n_method'> N Class Name: TransformersVectors</div><div id='m_method'> M Method Name: encode(2)</div><div id='n_method'> N Method Name: encode(2)</div><div id='m_parent_class'> M Parent Class: Vectors</div><div id='n_parent_class'> N Parent Class: Vectors</div><div id='m_file'> M File Name: src/python/txtai/vectors/transformers.py</div><div id='n_file'> N File Name: src/python/txtai/vectors/transformers.py</div><div id='m_start'> M Start Line: 146</div><div id='m_end'> M End Line: 159</div><div id='n_start'> N Start Line: 150</div><div id='n_end'> N End Line: 168</div><BR>