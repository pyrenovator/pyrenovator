<html><h3>Pattern ID :11622
</h3><img src='39309911.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            mask_select = (mask_filled==0.) & (mask_curr&gt;0.) 
            x_curr = torch.where(mask_select, x_ts_unp[:, ti+1, :, :, :], x_curr)
            mask_filled = mask_filled + mask_curr &#47&#47 update the mask
        x_curr<a id="change"> = </a><a id="change">x_curr.permute(0</a>,<a id="change">3</a>,<a id="change">1</a>,<a id="change">2</a><a id="change">)</a> &#47&#47[BxA, C, H, W]
     
        return x_curr, x_cls
</code></pre><h3>After Change</h3><pre><code class='java'>
        for ti in range(self.time_stamp-1):
            &#47&#47 not filled previously but can be filled by ti+1
            mask_curr = reverse_mask[:,ti+1, :, :]
            mask_select = <a id="change">((mask_filled==0.) & (mask_curr&gt;0.)).unsqueeze(-1</a><a id="change">)</a>
            x_curr = torch.where(mask_select, x_ts_unp[:, ti+1, :, :, :], x_curr)
            mask_filled = mask_filled + mask_curr &#47&#47 update the mask
        &#47&#47 x_curr = x_curr.permute(0,3,1,2) &#47&#47[BxA, C, H, W]
     </code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 7</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/coperception/star/commit/731f6b1da07455be85cd59f6a8f6e795d902aa7a#diff-a884c48041b9c06e41c73eb2c54e9b945061acd65915e9fd5c4ff7d8c4c65061L403' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39309911</div><div id='project'> Project Name: coperception/star</div><div id='commit'> Commit Name: 731f6b1da07455be85cd59f6a8f6e795d902aa7a</div><div id='time'> Time: 2022-06-04</div><div id='author'> Author: 954742885@qq.com</div><div id='file'> File Name: coperception/models/transformers/multiagent_mae.py</div><div id='m_class'> M Class Name: AmortizedFusionMMAEViT</div><div id='n_method'> N Class Name: AmortizedFusionMMAEViT</div><div id='m_method'> M Method Name: amortized_random_unmasking(4)</div><div id='n_method'> N Method Name: amortized_random_unmasking(4)</div><div id='m_parent_class'> M Parent Class: MultiAgentMaskedAutoencoderViT</div><div id='n_parent_class'> N Parent Class: MultiAgentMaskedAutoencoderViT</div><div id='m_file'> M File Name: coperception/models/transformers/multiagent_mae.py</div><div id='n_file'> N File Name: coperception/models/transformers/multiagent_mae.py</div><div id='m_start'> M Start Line: 403</div><div id='m_end'> M End Line: 433</div><div id='n_start'> N Start Line: 415</div><div id='n_end'> N End Line: 445</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        t = torch.tensor(inputs, dtype=torch.float32)
        t.unsqueeze_(0)
        t<a id="change"> = </a><a id="change">t.permute(1</a>,<a id="change">0</a>,<a id="change">2</a>,<a id="change">3</a><a id="change">)</a>
        logging.debug(f&quotTensor for prediction: {t.shape}&quot)

        t.to(self._device)
        with torch.no_grad():</code></pre><h3>After Change</h3><pre><code class='java'>
        
        t = self.img_trans(input_img)
        with torch.no_grad():
            pred = self.model(<a id="change">t.unsqueeze(0</a><a id="change">)</a>)
    
        result = self.tokenizer.translate(pred.squeeze(0).argmax(1))
        return result</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/andreybicalho/vrpdr/commit/daf497818875e24e9502e761bea83e6cbed1f909#diff-5f59b3986ec03836911b6150d16d3d7082319a5f1b6c69d3a1698850b3b37750L32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39310071</div><div id='project'> Project Name: andreybicalho/vrpdr</div><div id='commit'> Commit Name: daf497818875e24e9502e761bea83e6cbed1f909</div><div id='time'> Time: 2020-06-17</div><div id='author'> Author: andreybicalho@gmail.com</div><div id='file'> File Name: src/ocr.py</div><div id='m_class'> M Class Name: OCR</div><div id='n_method'> N Class Name: OCR</div><div id='m_method'> M Method Name: predict(2)</div><div id='n_method'> N Method Name: predict(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/ocr.py</div><div id='n_file'> N File Name: src/ocr.py</div><div id='m_start'> M Start Line: 36</div><div id='m_end'> M End Line: 53</div><div id='n_start'> N Start Line: 45</div><div id='n_end'> N End Line: 50</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47with torch.no_grad():
    batch_features = self.__cnn__(images) &#47&#47 (N, features_dim, block_num, block_num)
    
    conv_features = <a id="change">self.__img2embed_conv__(batch_features).permute(0</a>, <a id="change">2</a>, <a id="change">3</a>, <a id="change">1</a><a id="change">)</a> &#47&#47 (N, block_num, block_num, embed_dim * 0.5)
    apool = torch.mean(conv_features, dim = 1) &#47&#47 (N, block_num, embed_dim * 0.5)
    mpool<a id="change">, _ = </a>torch.max(conv_features, dim = 1) &#47&#47 (N, block_num, embed_dim * 0.5)

    imgs_embed = torch.cat([apool, mpool], dim = 2) &#47&#47 (N, block_num, embed_dim)
</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47batch_texts = self.__clip__.encode_text(text_input)

    &#47&#47tags_embed = self.__text2embed__(self.__clip_drop__(batch_texts.float())).unsqueeze(1)
    imgs_embed = <a id="change">self.__img2embed__(self.__clip_drop__(batch_features.float())).unsqueeze(1</a><a id="change">)</a>

    words_embed = self.__content_embed__(input_ids) 
    indices  = torch.arange(self.seq_len + self.tags_num + self.block_num).expand(batch, -1).to(device)
    position_embed = self.__position_embed__(indices)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/siwooyong/codalab-microsoft-coco-image-captioning-challenge/commit/d24b22ec9f0be1acd2f307be20ec85f84f8d8795#diff-7c1ece53a18959b293126dd93f3cf0f768220f50d2c1201e1601681873e6f6e4L54' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39311447</div><div id='project'> Project Name: siwooyong/codalab-microsoft-coco-image-captioning-challenge</div><div id='commit'> Commit Name: d24b22ec9f0be1acd2f307be20ec85f84f8d8795</div><div id='time'> Time: 2021-07-08</div><div id='author'> Author: 68500343+yongsiwoo@users.noreply.github.com</div><div id='file'> File Name: models/base_model.py</div><div id='m_class'> M Class Name: decoder</div><div id='n_method'> N Class Name: decoder</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/base_model.py</div><div id='n_file'> N File Name: models/base_model.py</div><div id='m_start'> M Start Line: 57</div><div id='m_end'> M End Line: 74</div><div id='n_start'> N Start Line: 75</div><div id='n_end'> N End Line: 97</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if target.dim() == 2:
            cluster_means_spatial = cluster_means_spatial.permute(2, 0, 1)
        else:
            cluster_means_spatial = <a id="change">cluster_means_spatial.permute(3</a>, <a id="change">0</a>, <a id="change">1</a>, <a id="change">2</a><a id="change">)</a>

        &#47&#47 compute the distance to cluster means
        dist_to_mean = torch.norm(embeddings - cluster_means_spatial, self.norm, dim=0)

        if ignore_zero_label:
            &#47&#47 zero out distances corresponding to 0-label cluster, so that it does not contribute to the loss
            dist_mask = torch.ones_like(dist_to_mean)
            dist_mask[target == 0] = 0
            dist_to_mean = dist_to_mean * dist_mask
            &#47&#47 decrease number of instances
            n_instances -= 1
            &#47&#47 if there is only 0-label in the target return 0
            if n_instances == 0:
                return 0.0

        &#47&#47 zero out distances less than delta_var (hinge)
        hinge_dist = torch.clamp(dist_to_mean - self.delta_var, min=0) ** 2

        &#47&#47 normalize the variance by instance sizes and number of instances and sum it up
        variance_term<a id="change"> = </a>torch.sum(hinge_dist / instance_sizes_spatial) / n_instances
        return variance_term

    def _compute_unlabeled_push(self, cluster_means, embeddings, target):</code></pre><h3>After Change</h3><pre><code class='java'>
        assert target.dim() in (2, 3)
        ignore_labels = [0] if ignore_zero_label else None
        return cimpl._compute_variance_term_scatter(
            cluster_means, embeddings.unsqueeze(0), <a id="change">target.unsqueeze(0</a><a id="change">)</a>,
            self.norm, self.delta_var, instance_counts, ignore_labels
        )
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/constantinpape/torch-em/commit/6b3c4ed59bff373d2b2f945e3f1aa300659ce9e9#diff-4ae644b7c870f8b2444a41dc20b100f7c4de0377aea62d81ec64ab36f8a94a4fL151' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39309892</div><div id='project'> Project Name: constantinpape/torch-em</div><div id='commit'> Commit Name: 6b3c4ed59bff373d2b2f945e3f1aa300659ce9e9</div><div id='time'> Time: 2021-12-28</div><div id='author'> Author: c.pape@gmx.net</div><div id='file'> File Name: torch_em/loss/spoco_loss.py</div><div id='m_class'> M Class Name: ContrastiveLossBase</div><div id='n_method'> N Class Name: ContrastiveLossBase</div><div id='m_method'> M Method Name: _compute_variance_term(6)</div><div id='n_method'> N Method Name: _compute_variance_term(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: torch_em/loss/spoco_loss.py</div><div id='n_file'> N File Name: torch_em/loss/spoco_loss.py</div><div id='m_start'> M Start Line: 167</div><div id='m_end'> M End Line: 199</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 147</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        x = x.permute(0, 3, 1, 2).view(x.size(0), x.size(3), x.size(1), self.size,
                                       self.size)  &#47&#47 B x T x (H x W) x C -&gt; B x C x T x H x W
        x = self.unpatch_emb(x)
        x<a id="change"> = </a><a id="change">x.permute(</a>0, <a id="change">2</a>, <a id="change">1</a>, <a id="change">3</a>, <a id="change">4</a><a id="change">)</a>  &#47&#47 B x C x T x H x W -&gt; B x T x C x H x W
        return x

</code></pre><h3>After Change</h3><pre><code class='java'>
            image, video = x[:, :, 0], x[:, :, 1:]
            video = self.video_unpatch_emb(video)
            image = self.image_unpatch_emb(image)
            x = torch.cat([<a id="change">image.unsqueeze(2</a><a id="change">)</a>, video], dim=2).permute(0, 2, 1, 3, 4)  &#47&#47 B x C x T x H x W -&gt; B x T x C x H x W
        else:
            image = x[:, :, 0]
            image = self.image_unpatch_emb(image)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/laion-ai/phenaki/commit/04c8fd7948c8e3b4ef008be5b788d4f067d5d9c2#diff-d2675e29d21c30767dbf4b16980547aac6cc99b46ce44781ec89d09ee7193467L81' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39309907</div><div id='project'> Project Name: laion-ai/phenaki</div><div id='commit'> Commit Name: 04c8fd7948c8e3b4ef008be5b788d4f067d5d9c2</div><div id='time'> Time: 2022-10-12</div><div id='author'> Author: d6582533@gmail.com</div><div id='file'> File Name: vivq.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: vivq.py</div><div id='n_file'> N File Name: vivq.py</div><div id='m_start'> M Start Line: 83</div><div id='m_end'> M End Line: 86</div><div id='n_start'> N Start Line: 87</div><div id='n_end'> N End Line: 97</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 reshape back to match original input shape
        &#47&#47z_q, &quotb h w c -&gt; b c h w&quot
        z_q<a id="change"> = </a><a id="change">z_q.permute(0</a>, <a id="change">3</a>, <a id="change">1</a>, <a id="change">2</a><a id="change">)</a>.contiguous()
        return z_q, loss, (perplexity, encodings, encoding_indices)

</code></pre><h3>After Change</h3><pre><code class='java'>
        z_flattened = z.view(-1, self.codebook_dim)

        &#47&#47 distances from z to embeddings e_j
        d = torch.cdist(<a id="change">z_flattened.unsqueeze(0</a><a id="change">)</a>, self.embedding.weight.unsqueeze(0)).squeeze(0)

        encoding_indices = torch.argmin(d, dim=1)
        z_q = self.embedding(encoding_indices).view(z.shape)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tgisaturday/dalle-lightning/commit/99578b1ee75b767bc5b918b86757fb37d2920969#diff-5cc0cb1395e7634e216d321d933d7868cc1ee34fa25763750d65126b9ad1ea15L15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39309873</div><div id='project'> Project Name: tgisaturday/dalle-lightning</div><div id='commit'> Commit Name: 99578b1ee75b767bc5b918b86757fb37d2920969</div><div id='time'> Time: 2021-08-09</div><div id='author'> Author: j@doodlebot.ai</div><div id='file'> File Name: pl_dalle/modules/vqvae/quantize.py</div><div id='m_class'> M Class Name: VectorQuantizer</div><div id='n_method'> N Class Name: VectorQuantizer</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: pl_dalle/modules/vqvae/quantize.py</div><div id='n_file'> N File Name: pl_dalle/modules/vqvae/quantize.py</div><div id='m_start'> M Start Line: 18</div><div id='m_end'> M End Line: 41</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 60</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            samples = mv.sample(sample_shape=(context.num_samples,))

            samples = samples.view(context.num_samples, self.num_repetitions, self._n_dists, self.out_channels, self.cardinality)
            samples<a id="change"> = </a><a id="change">samples.permute(0</a>, <a id="change">2</a>, 4, <a id="change">3</a>, <a id="change">1</a><a id="change">)</a>
            samples = samples.reshape(context.num_samples, self._n_dists * self.cardinality, self.out_channels, self.num_repetitions)

        num_samples, num_features, out_channels, num_repetitions = samples.shape
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 If parent index into out_channels are given

        if context.parent_indices is not None:
            indices = <a id="change">context.parent_indices.unsqueeze(1).unsqueeze(-1</a><a id="change">)</a>.repeat(1, 1, 1, cardinality)
            &#47&#47 Choose only specific samples for each feature/scope
            samples = torch.gather(samples, dim=1, index=indices).squeeze(-1)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/braun-steven/simple-einet/commit/1fb68845af9033ccf3b13e014d9efc0e5a4022a3#diff-101820f13eb50439a477b1a0dbd4b95445a8cb9a75e52b29e813489de61497e8L325' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39309951</div><div id='project'> Project Name: braun-steven/simple-einet</div><div id='commit'> Commit Name: 1fb68845af9033ccf3b13e014d9efc0e5a4022a3</div><div id='time'> Time: 2021-11-24</div><div id='author'> Author: steven.lang.mz@gmail.com</div><div id='file'> File Name: distributions.py</div><div id='m_class'> M Class Name: MultivariateNormal</div><div id='n_method'> N Class Name: MultivariateNormal</div><div id='m_method'> M Method Name: sample(3)</div><div id='n_method'> N Method Name: sample(3)</div><div id='m_parent_class'> M Parent Class: Leaf</div><div id='n_parent_class'> N Parent Class: Leaf</div><div id='m_file'> M File Name: distributions.py</div><div id='n_file'> N File Name: distributions.py</div><div id='m_start'> M Start Line: 334</div><div id='m_end'> M End Line: 349</div><div id='n_start'> N Start Line: 359</div><div id='n_end'> N End Line: 390</div><BR>