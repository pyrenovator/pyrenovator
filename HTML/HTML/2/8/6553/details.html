<html><h3>Pattern ID :6553
</h3><img src='22609979.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            logits = logits + [self.prob_out(zcs)]
            att_ws = att_ws + [att_w]
            prev_out = y  &#47&#47 teacher forcing
            <a id="change">if </a>self.cumulate_att_w and <a id="change">prev_att_w is not None</a>:
                prev_att_w<a id="change"> = prev_att_w</a><a id="change"> + att_w</a>  &#47&#47 Note: error when use +=
            else:
                prev_att_w<a id="change"> = att_w</a>

        logits = torch.cat(logits, dim=1)  &#47&#47 (B, Lmax)
        before_outs = torch.cat(outs, dim=2)  &#47&#47 (B, odim, Lmax)
        att_ws = torch.stack(att_ws, dim=1)  &#47&#47 (B, Lmax, Tmax)</code></pre><h3>After Change</h3><pre><code class='java'>
        prev_att_w_forward = None
        prev_att_w_location = None
        self.forward_att.reset()
        <a id="change">self.location_att.reset()</a>

        &#47&#47 loop for an output sequence
        outs, logits, att_ws = [], [], []
        for y in ys.transpose(0, 1):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/1cff4882bc74573b31714a00e827786595b0b0d4#diff-09890817e338d073ece7c3562e9071826029d455ae39e08ac3f911b70293b37aL378' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 22609979</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 1cff4882bc74573b31714a00e827786595b0b0d4</div><div id='time'> Time: 2021-10-07</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: Layers/TacotronDecoder.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: Layers/TacotronDecoder.py</div><div id='n_file'> N File Name: Layers/TacotronDecoder.py</div><div id='m_start'> M Start Line: 384</div><div id='m_end'> M End Line: 412</div><div id='n_start'> N Start Line: 378</div><div id='n_end'> N End Line: 406</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        prev_out = hs.new_zeros(hs.size(0), self.odim)

        &#47&#47 initialize attention
        <a id="change">prev_att_w</a> = None
        self.att.reset()

        &#47&#47 loop for an output sequence
        outs, logits, att_ws = [], [], []
        for y in ys.transpose(0, 1):
            if self.use_att_extra_inputs:
                att_c, att_w = self.att(hs, hlens, z_list[0], prev_att_w, prev_out)
            else:
                att_c, att_w = self.att(hs, hlens, z_list[0], prev_att_w)
            if self.speaker_embedding_projection_size is not None:
                prenet_out = self.prenet(torch.cat([prev_out, speaker_embedding], dim=-1)) if self.prenet is not None else prev_out
            else:
                prenet_out = self.prenet(prev_out) if self.prenet is not None else prev_out
            xs = torch.cat([att_c, prenet_out], dim=1)
            z_list[0], c_list[0] = self.lstm[0](xs, (z_list[0], c_list[0]))
            for i in range(1, len(self.lstm)):
                z_list[i], c_list[i] = self.lstm[i](z_list[i - 1], (z_list[i], c_list[i]))
            zcs = (torch.cat([z_list[-1], att_c], dim=1) if self.use_concate else z_list[-1])
            outs = outs + [self.feat_out(zcs).view(hs.size(0), self.odim, -1)]
            logits = logits + [self.prob_out(zcs)]
            att_ws = att_ws + [att_w]
            prev_out = y  &#47&#47 teacher forcing
            <a id="change">if </a>self.cumulate_att_w and <a id="change">prev_att_w is not None</a>:
                prev_att_w<a id="change"> = </a>prev_att_w<a id="change"> + </a>att_w  &#47&#47 Note: error when use +=
            else:
                prev_att_w<a id="change"> = </a>att_w

        logits = torch.cat(logits, dim=1)  &#47&#47 (B, Lmax)
        before_outs = torch.cat(outs, dim=2)  &#47&#47 (B, odim, Lmax)</code></pre><h3>After Change</h3><pre><code class='java'>
        prev_att_w_forward = None
        prev_att_w_location = None
        self.forward_att.reset()
        <a id="change">self.location_att.reset()</a>

        &#47&#47 loop for an output sequence
        outs, logits, att_ws = [], [], []
        for y in ys.transpose(0, 1):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/1cff4882bc74573b31714a00e827786595b0b0d4#diff-09890817e338d073ece7c3562e9071826029d455ae39e08ac3f911b70293b37aL350' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 22609981</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 1cff4882bc74573b31714a00e827786595b0b0d4</div><div id='time'> Time: 2021-10-07</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: Layers/TacotronDecoder.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: Layers/TacotronDecoder.py</div><div id='n_file'> N File Name: Layers/TacotronDecoder.py</div><div id='m_start'> M Start Line: 384</div><div id='m_end'> M End Line: 412</div><div id='n_start'> N Start Line: 378</div><div id='n_end'> N End Line: 406</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        prev_out = hs.new_zeros(1, self.odim)

        &#47&#47 initialize attention
        <a id="change">prev_att_w</a> = None
        self.att.reset()

        &#47&#47 setup for attention constraint
        if use_att_constraint:
            last_attended_idx = 0
        else:
            last_attended_idx = None

        &#47&#47 loop for an output sequence
        idx = 0
        outs, att_ws, probs = [], [], []
        while True:
            &#47&#47 updated index
            idx = idx + self.reduction_factor

            &#47&#47 decoder calculation
            if self.use_att_extra_inputs:
                att_c, att_w = self.att(hs,
                                        ilens,
                                        z_list[0],
                                        prev_att_w,
                                        prev_out,
                                        last_attended_idx=last_attended_idx,
                                        backward_window=backward_window,
                                        forward_window=forward_window, )
            else:
                att_c, att_w = self.att(hs,
                                        ilens,
                                        z_list[0],
                                        prev_att_w,
                                        last_attended_idx=last_attended_idx,
                                        backward_window=backward_window,
                                        forward_window=forward_window, )

            att_ws = att_ws + [att_w]
            if self.speaker_embedding_projection_size is not None:
                prenet_out = self.prenet(torch.cat([prev_out, speaker_embedding], dim=-1)) if self.prenet is not None else prev_out
            else:
                prenet_out = self.prenet(prev_out) if self.prenet is not None else prev_out
            xs = torch.cat([att_c, prenet_out], dim=1)
            z_list[0], c_list[0] = self.lstm[0](xs, (z_list[0], c_list[0]))
            for i in range(1, len(self.lstm)):
                z_list[i], c_list[i] = self.lstm[i](z_list[i - 1], (z_list[i], c_list[i]))
            zcs = (torch.cat([z_list[-1], att_c], dim=1) if self.use_concate else z_list[-1])
            outs = outs + [self.feat_out(zcs).view(1, self.odim, -1)]  &#47&#47 [(1, odim, r), ...]
            probs = probs + [torch.sigmoid(self.prob_out(zcs))[0]]  &#47&#47 [(r), ...]
            if self.output_activation_fn is not None:
                prev_out = self.output_activation_fn(outs[-1][:, :, -1])  &#47&#47 (1, odim)
            else:
                prev_out = outs[-1][:, :, -1]  &#47&#47 (1, odim)
            <a id="change">if </a>self.cumulate_att_w and <a id="change">prev_att_w is not None</a>:
                prev_att_w<a id="change"> = </a>prev_att_w<a id="change"> + </a>att_w  &#47&#47 Note: error when use +=
            else:
                prev_att_w<a id="change"> = </a>att_w
            if use_att_constraint:
                last_attended_idx = int(att_w.argmax())
</code></pre><h3>After Change</h3><pre><code class='java'>
        prev_att_w_forward = None
        prev_att_w_location = None
        self.forward_att.reset()
        <a id="change">self.location_att.reset()</a>

        &#47&#47 setup for attention constraint
        if use_att_constraint:
            last_attended_idx = 0</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/1cff4882bc74573b31714a00e827786595b0b0d4#diff-09890817e338d073ece7c3562e9071826029d455ae39e08ac3f911b70293b37aL434' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 22609980</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 1cff4882bc74573b31714a00e827786595b0b0d4</div><div id='time'> Time: 2021-10-07</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: Layers/TacotronDecoder.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: inference(9)</div><div id='n_method'> N Method Name: inference(9)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: Layers/TacotronDecoder.py</div><div id='n_file'> N File Name: Layers/TacotronDecoder.py</div><div id='m_start'> M Start Line: 485</div><div id='m_end'> M End Line: 540</div><div id='n_start'> N Start Line: 482</div><div id='n_end'> N End Line: 533</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 initialize attention
        prev_att_w_forward = None
        <a id="change">prev_att_w_location</a> = None
        self.forward_att.reset()
        self.location_att.reset()

        &#47&#47 setup for attention constraint
        if use_att_constraint:
            last_attended_idx = 0
        else:
            last_attended_idx = None

        &#47&#47 loop for an output sequence
        idx = 0
        outs, att_ws, probs, att_ws_location, att_ws_forward = [], [], [], [], []
        while True:
            &#47&#47 updated index
            idx = idx + self.reduction_factor

            &#47&#47 decoder calculation

            att_c_forward, att_w_forward = self.forward_att(hs, ilens, z_list[0], prev_att_w_forward, prev_out,
                                                            last_attended_idx=last_attended_idx,
                                                            backward_window=backward_window,
                                                            forward_window=forward_window)
            att_c_location, att_w_location = self.location_att(hs, ilens, z_list[0], prev_att_w_location,
                                                               last_attended_idx=last_attended_idx,
                                                               backward_window=backward_window,
                                                               forward_window=forward_window)

            att_c = att_c_location + att_c_forward
            att_w = att_w_location + att_w_forward

            att_ws = att_ws + [att_w]
            att_ws_location = att_ws_location + [att_w_location]
            att_ws_forward = att_ws_forward + [att_w_forward]
            if self.speaker_embedding_projection_size is not None:
                prenet_out = self.prenet(torch.cat([prev_out, speaker_embedding], dim=-1)) if self.prenet is not None else prev_out
            else:
                prenet_out = self.prenet(prev_out) if self.prenet is not None else prev_out
            xs = torch.cat([att_c, prenet_out], dim=1)
            z_list[0], c_list[0] = self.lstm[0](xs, (z_list[0], c_list[0]))
            for i in range(1, len(self.lstm)):
                z_list[i], c_list[i] = self.lstm[i](z_list[i - 1], (z_list[i], c_list[i]))
            zcs = (torch.cat([z_list[-1], att_c], dim=1) if self.use_concate else z_list[-1])
            outs = outs + [self.feat_out(zcs).view(1, self.odim, -1)]  &#47&#47 [(1, odim, r), ...]
            probs = probs + [torch.sigmoid(self.prob_out(zcs))[0]]  &#47&#47 [(r), ...]
            if self.output_activation_fn is not None:
                prev_out = self.output_activation_fn(outs[-1][:, :, -1])  &#47&#47 (1, odim)
            else:
                prev_out = outs[-1][:, :, -1]  &#47&#47 (1, odim)
            <a id="change">if prev_att_w_location is not None</a>:
                prev_att_w_location<a id="change"> = </a>prev_att_w_location<a id="change"> + </a>att_w_location  &#47&#47 Note: error when use +=
            else:
                prev_att_w_location<a id="change"> = </a>att_w_location
            prev_att_w_forward = att_w_forward
            if use_att_constraint:
                last_attended_idx = int(att_w.argmax())</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 initialize attention
        prev_att_w = None
        <a id="change">self.att.reset()</a>

        &#47&#47 setup for attention constraint
        if use_att_constraint:
            last_attended_idx = 0</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/10019cc0757749a84bed3e7c9edf69ef603bf385#diff-09890817e338d073ece7c3562e9071826029d455ae39e08ac3f911b70293b37aL438' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 22609985</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 10019cc0757749a84bed3e7c9edf69ef603bf385</div><div id='time'> Time: 2021-10-14</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: Layers/TacotronDecoder.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: inference(9)</div><div id='n_method'> N Method Name: inference(10)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: Layers/TacotronDecoder.py</div><div id='n_file'> N File Name: Layers/TacotronDecoder.py</div><div id='m_start'> M Start Line: 447</div><div id='m_end'> M End Line: 568</div><div id='n_start'> N Start Line: 479</div><div id='n_end'> N End Line: 534</div><BR>