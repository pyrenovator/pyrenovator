<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        for _ in range(4):
            &#47&#47 original code uses bias=False even though there is no norm layer
            stem_layers.append(nn.Conv2d(in_c, out_c, 3, stride=2, padding=1))
            stem_layers.append(<a id="change">nn.GELU()</a>)
            in_c, out_c = out_c, out_c * 2
        self.stem = nn.Sequential(*stem_layers)
</code></pre><h3>After Change</h3><pre><code class='java'>
        super().__init__()
        self.norm_type = norm_type
        self.out_channels = (embed_dim,)
        self.stem = <a id="change">nn.Sequential(
            </a>nn.Conv2d(3, embed_dim // 8, 3, stride=2, padding=1),
            nn.GELU(),
            nn.Conv2d(embed_dim<a id="change">//8</a>, embed_dim // 4, 3, stride=2, padding=1),
            <a id="change">nn.GELU()</a>,
            nn.Conv2d(embed_dim//4, embed_dim // 2, 3, stride=2, padding=1),
            nn.GELU(),
            nn.Conv2d(embed_dim<a id="change">//2</a>, embed_dim, 3, stride=2, padding=1)<a id="change">,
        )</a>

        kwargs = dict(drop_path=drop_path, layer_scale_init=layer_scale_init)
        self.trunk = nn.Sequential(*[PatchConvBlock(embed_dim, norm_type=norm_type, **kwargs) for _ in range(depth)])
        self.pool = AttentionPooling(embed_dim, mlp_ratio, **kwargs)</code></pre>