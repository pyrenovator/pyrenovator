<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.zero_grad()
        psi = self.defaults[&quotwf&quot](pos)

        inp = <a id="change">[]</a>
        for group in self.param_groups:
            for p in group[&quotparams&quot]:
                if p.requires_grad:
                    inp.append(p)

        for ibatch in range(psi.shape[0]):
            grads = torch.autograd.grad(psi[ibatch], inp, retain_graph=True)
            grads = torch.cat([g.view(-1)/psi[ibatch] for g in grads])
            if ibatch == 0:
                S<a id="change"> = </a>grads * grads.view(-1, 1)
            else:
                S += grads * grads.view(-1, 1)
</code></pre><h3>After Change</h3><pre><code class='java'>
                if p.requires_grad:
                    ninp += p.numel()

        S<a id="change"> = </a>torch.zeros(ninp, ninp)
        sum_grads<a id="change"> = </a>torch.zeros(ninp)

        self.zero_grad()
        psi = self.defaults[&quotwf&quot](pos)

        for ibatch in range(nbatch):

            psi[ibatch].backward(retain_graph=True)
            grads = self._collect_grad() / psi[ibatch]
            S += grads.reshape(-1, 1) @ grads.reshape(1, -1)
            sum_grads<a id="change"> += </a>grads
            self.zero_grad()

        sum_grads /= nbatch
        S<a id="change"> -= </a><a id="change">sum_grads.reshape(</a>-1, <a id="change">1</a><a id="change">)</a> @ sum_grads.reshape(1, -1)
        return S

    def get_gradient(self, pos):</code></pre>