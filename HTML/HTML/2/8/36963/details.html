<html><h3>Pattern ID :36963
</h3><img src='105211524.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                data, target = data.cuda(), target.cuda()
            optimizer.zero_grad()
            &#47&#47 Split data into sub-batches of size batch_size
            <a id="change">for </a>i in range(0, len(data), args.batch_size)<a id="change">:
                </a>data_batch = data[i:i + args.batch_size]
                target_batch<a id="change"> = </a>target[i:i + args.batch_size]
                output<a id="change"> = model(</a>data_batch<a id="change">)</a>
                train_accuracy.update(accuracy(output, target_batch))
                loss = F.cross_entropy(output, target_batch)
                train_loss.update(loss)
                &#47&#47 Average gradients among sub-batches
                loss.div_(math.ceil(float(len(data))<a id="change"> / </a>args.batch_size))
                loss.backward()
            &#47&#47 Gradient is applied across all ranks
            if args.kfac_update_freq &gt; 0:</code></pre><h3>After Change</h3><pre><code class='java'>
            if args.cuda:
                data, target = data.cuda(), target.cuda()
            optimizer.zero_grad()
            output<a id="change"> = </a><a id="change">model(</a>data<a id="change">)</a>

            loss = F.cross_entropy(output, target)
            train_loss.update(loss)
            train_accuracy.update(accuracy(output, target))</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/gpauloski/kfac_pytorch/commit/9afedfd17a78f485b4e75637ad3d59b90627938f#diff-19a5fa9b14aac49ae8de1f5bc85e046f7959f5d60ae3c3575533ff98fc6d2f5fL193' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 105211524</div><div id='project'> Project Name: gpauloski/kfac_pytorch</div><div id='commit'> Commit Name: 9afedfd17a78f485b4e75637ad3d59b90627938f</div><div id='time'> Time: 2020-03-05</div><div id='author'> Author: gpauloski@yahoo.com</div><div id='file'> File Name: examples/pytorch_imagenet_resnet50.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(1)</div><div id='n_method'> N Method Name: train(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/pytorch_imagenet_resnet50.py</div><div id='n_file'> N File Name: examples/pytorch_imagenet_resnet50.py</div><div id='m_start'> M Start Line: 208</div><div id='m_end'> M End Line: 235</div><div id='n_start'> N Start Line: 193</div><div id='n_end'> N End Line: 219</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                data, target = data.cuda(), target.cuda()
            optimizer.zero_grad()
            &#47&#47 Split data into sub-batches of size batch_size
            <a id="change">for i</a> in range(0, len(data), args.batch_size)<a id="change">:
                </a>data_batch = data[i:i + args.batch_size]
                target_batch<a id="change"> = </a>target[i:i + args.batch_size]
                output<a id="change"> = model(</a>data_batch<a id="change">)</a>
                train_accuracy.update(accuracy(output, target_batch))
                loss = F.cross_entropy(output, target_batch)
                train_loss.update(loss)
                &#47&#47 Average gradients among sub-batches
                loss.div_(math.ceil(float(len(data))<a id="change"> / </a>args.batch_size))
                loss.backward()
            &#47&#47 Gradient is applied across all ranks
            if args.kfac_update_freq &gt; 0:</code></pre><h3>After Change</h3><pre><code class='java'>
            if args.cuda:
                data, target = data.cuda(), target.cuda()
            optimizer.zero_grad()
            output<a id="change"> = </a><a id="change">model(</a>data<a id="change">)</a>

            loss = F.cross_entropy(output, target)
            train_loss.update(loss)
            train_accuracy.update(accuracy(output, target))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/gpauloski/kfac-pytorch/commit/9afedfd17a78f485b4e75637ad3d59b90627938f#diff-19a5fa9b14aac49ae8de1f5bc85e046f7959f5d60ae3c3575533ff98fc6d2f5fL204' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 105211532</div><div id='project'> Project Name: gpauloski/kfac-pytorch</div><div id='commit'> Commit Name: 9afedfd17a78f485b4e75637ad3d59b90627938f</div><div id='time'> Time: 2020-03-05</div><div id='author'> Author: gpauloski@yahoo.com</div><div id='file'> File Name: examples/pytorch_imagenet_resnet50.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(1)</div><div id='n_method'> N Method Name: train(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/pytorch_imagenet_resnet50.py</div><div id='n_file'> N File Name: examples/pytorch_imagenet_resnet50.py</div><div id='m_start'> M Start Line: 208</div><div id='m_end'> M End Line: 235</div><div id='n_start'> N Start Line: 193</div><div id='n_end'> N End Line: 219</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        model = self.dummy_model()
        sample = self.dummy_sample_deter

        <a id="change">for t</a> in reversed(range(num_inference_steps))<a id="change">:
            </a>residual<a id="change"> = model(</a>sample, inference_step_times[t]<a id="change">)</a>

            pred_prev_sample = scheduler.step(residual, sample, t, num_inference_steps, eta)

            variance<a id="change"> = </a>0
            if eta &gt; 0:
                noise = self.dummy_sample_deter
                variance = scheduler.get_variance(t, num_inference_steps) ** (0.5)<a id="change"> * </a>eta * noise

            sample = pred_prev_sample + variance
</code></pre><h3>After Change</h3><pre><code class='java'>

        scheduler.set_timesteps(num_inference_steps)
        for t in scheduler.timesteps:
            residual<a id="change"> = </a><a id="change">model(</a>sample, t<a id="change">)</a>

            sample = scheduler.step(residual, t, sample, eta)["prev_sample"]

        result_sum = np.sum(np.abs(sample))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/f448360bd0dfe5e28ee65ab2130532db91d5eafe#diff-7cab305a6a78540131fcce1fafb912ccf6b52aa50b4a0a2b794aea71004d5a95L300' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 105211516</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: f448360bd0dfe5e28ee65ab2130532db91d5eafe</div><div id='time'> Time: 2022-07-15</div><div id='author'> Author: patrick.v.platen@gmail.com</div><div id='file'> File Name: tests/test_scheduler.py</div><div id='m_class'> M Class Name: DDIMSchedulerTest</div><div id='n_method'> N Class Name: DDIMSchedulerTest</div><div id='m_method'> M Method Name: test_full_loop_no_noise(1)</div><div id='n_method'> N Method Name: test_full_loop_no_noise(1)</div><div id='m_parent_class'> M Parent Class: SchedulerCommonTest</div><div id='n_parent_class'> N Parent Class: SchedulerCommonTest</div><div id='m_file'> M File Name: tests/test_scheduler.py</div><div id='n_file'> N File Name: tests/test_scheduler.py</div><div id='m_start'> M Start Line: 303</div><div id='m_end'> M End Line: 325</div><div id='n_start'> N Start Line: 344</div><div id='n_end'> N End Line: 357</div><BR>