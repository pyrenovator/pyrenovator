<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        elif self.config_method.startswith(&quotsingle_double(&quot):

            <a id="change">return </a>torch.cat((detAup.unsqueeze(-1), det_single_up, det_double_up), dim=1)<a id="change">,\
                torch.cat((detAdown.unsqueeze(-1),
                           det_single_down, det_double_down), dim=1)</a>

    def kinetic(self, mo, bkin):
        Computes the values of the kinetic energy
</code></pre><h3>After Change</h3><pre><code class='java'>
        detAdown = torch.det(Adown)

        &#47&#47 store all the dets we need
        det_out_up<a id="change"> = </a><a id="change">detAup.unsqueeze(-1).clone()</a>
        det_out_down<a id="change"> = detAdown.unsqueeze(-1).clone()</a>

        &#47&#47 return the ground state
        if self.config_method == &quotground_state&quot:
            return det_out_up, det_out_down

        &#47&#47 inverse of the
        invAup = torch.inverse(Aup)
        invAdown = torch.inverse(Adown)

        &#47&#47 virtual orbital matrices spin up/down
        Bup = input[:, :self.nup, self.nup:self.index_max_orb_up]
        Bdown = input[:, self.nup:,
                      self.ndown: self.index_max_orb_down]

        &#47&#47 compute the products of Ain and B
        mat_exc_up = (invAup @ Bup)
        mat_exc_down = (invAdown @ Bdown)

        if do_single:

            &#47&#47 determinant of the unique excitation spin up
            det_single_up = mat_exc_up.view(
                nbatch, -1)[:, self.exc_mask.index_unique_single_up]

            &#47&#47 determinant of the unique excitation spin down
            det_single_down = mat_exc_down.view(
                nbatch, -1)[:, self.exc_mask.index_unique_single_down]

            &#47&#47 multiply with ground state determinant
            &#47&#47 and account for permutation for deep excitation
            det_single_up = detAup.unsqueeze(-1) * \
                det_single_up.view(nbatch, -1)

            &#47&#47 multiply with ground state determinant
            &#47&#47 and account for permutation for deep excitation
            det_single_down = detAdown.unsqueeze(-1) * \
                det_single_down.view(nbatch, -1)

            &#47&#47 if the orbital in configs are in increasing order
            &#47&#47 we should deal with that better ...
            &#47&#47 det_up *= self.exc_mask.sign_unique_single_up
            &#47&#47 det_down *= self.exc_mask.sign_unique_single_down

            &#47&#47 accumulate the dets
            det_out_up = torch.cat((det_out_up, det_single_up), dim=1)
            det_out_down = torch.cat(
                (det_out_down, det_single_down), dim=1)

        if do_double:

            &#47&#47 det of unique spin up double exc
            det_double_up = mat_exc_up.view(
                nbatch, -1)[:, self.exc_mask.index_unique_double_up]

            &#47&#47 det_double_up = torch.det(
            &#47&#47     det_double_up.view(nbatch, -1, 2, 2))
            det_double_up = bdet2(
                det_double_up.view(nbatch, -1, 2, 2))

            det_double_up = detAup.unsqueeze(-1) * det_double_up

            &#47&#47 det of unique spin down double exc
            det_double_down = mat_exc_down.view(
                nbatch, -1)[:, self.exc_mask.index_unique_double_down]

            &#47&#47 det_double_down = torch.det(
            &#47&#47     det_double_down.view(nbatch, -1, 2, 2))
            det_double_down = bdet2(
                det_double_down.view(nbatch, -1, 2, 2))

            det_double_down = detAdown.unsqueeze(-1) * det_double_down

            det_out_up = torch.cat((det_out_up, det_double_up), dim=1)
            det_out_down = torch.cat(
                (det_out_down, det_double_down), dim=1)

        <a id="change">return </a>det_out_up<a id="change">, det_out_down</a>

        &#47&#47 if self.config_method.startswith(&quotsingle(&quot):

        &#47&#47     return torch.cat((detAup.unsqueeze(-1), det_single_up), dim=1),\</code></pre>