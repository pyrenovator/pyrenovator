<html><h3>Pattern ID :38508
</h3><img src='110049551.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 append cls token
        cls_token = self.cls_token + self.pos_embed[:, :1, :]
        cls_tokens<a id="change"> = </a><a id="change">cls_token.expand(</a>x_masked.shape[0], <a id="change">-1</a>, <a id="change">-1</a><a id="change">)</a>
        x = <a id="change">torch.cat(</a>(cls_tokens, x_masked)<a id="change">, dim=1)</a>

        &#47&#47 apply Transformer blocks
        for blk in self.blocks:
            x = blk(x)
        x<a id="change"> = </a>self.norm(x)
        &#47&#47 compress for communication
        x = self.compressor(x)

        <a id="change">return </a>x, mask, ids_restore

    def forward_decoder(self, x):
        </code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 x_send = torch.cat((x[:,:1,:], x_masked), dim=1) &#47&#47 put [CLS] token back
        x_send = self.compressor(x_masked)
        
        <a id="change">return </a>x_send, mask, ids_restore

    def forward_decoder(self, x):
        </code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/coperception/star/commit/731f6b1da07455be85cd59f6a8f6e795d902aa7a#diff-a884c48041b9c06e41c73eb2c54e9b945061acd65915e9fd5c4ff7d8c4c65061L564' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110049551</div><div id='project'> Project Name: coperception/star</div><div id='commit'> Commit Name: 731f6b1da07455be85cd59f6a8f6e795d902aa7a</div><div id='time'> Time: 2022-06-04</div><div id='author'> Author: 954742885@qq.com</div><div id='file'> File Name: coperception/models/transformers/multiagent_mae.py</div><div id='m_class'> M Class Name: AmortizedFusionMMAEViT</div><div id='n_method'> N Class Name: AmortizedFusionMMAEViT</div><div id='m_method'> M Method Name: forward_encoder(4)</div><div id='n_method'> N Method Name: forward_encoder(4)</div><div id='m_parent_class'> M Parent Class: MultiAgentMaskedAutoencoderViT</div><div id='n_parent_class'> N Parent Class: MultiAgentMaskedAutoencoderViT</div><div id='m_file'> M File Name: coperception/models/transformers/multiagent_mae.py</div><div id='n_file'> N File Name: coperception/models/transformers/multiagent_mae.py</div><div id='m_start'> M Start Line: 564</div><div id='m_end'> M End Line: 589</div><div id='n_start'> N Start Line: 577</div><div id='n_end'> N End Line: 611</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def _integrate_with_utt_embed(self, hs, utt_embeddings):
        &#47&#47 concat hidden states with spk embeds and then apply projection
        embeddings_expanded<a id="change"> = </a><a id="change">F.normalize(utt_embeddings).unsqueeze(1).expand(-1</a>, hs.size(1), <a id="change">-1</a><a id="change">)</a>
        hs<a id="change"> = </a>self.hs_emb_projection(<a id="change">torch.cat(</a>[hs, embeddings_expanded]<a id="change">, dim=-1)</a>)
        <a id="change">return </a>hs
</code></pre><h3>After Change</h3><pre><code class='java'>
        return xs, masks

    def _integrate_with_utt_embed(self, hs, utt_embeddings):
        <a id="change">return </a>self.hs_emb_projection(x=hs, speaker_embedding=utt_embeddings)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/1b74e15ccae20160a402d1a627694cb85d3c060e#diff-d635fb003b559f77f551259cb56709a57f9a634f85664ca1d8a45aff44d754d7L130' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110049548</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 1b74e15ccae20160a402d1a627694cb85d3c060e</div><div id='time'> Time: 2022-10-27</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: Layers/Conformer.py</div><div id='m_class'> M Class Name: Conformer</div><div id='n_method'> N Class Name: Conformer</div><div id='m_method'> M Method Name: _integrate_with_utt_embed(3)</div><div id='n_method'> N Method Name: _integrate_with_utt_embed(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: Layers/Conformer.py</div><div id='n_file'> N File Name: Layers/Conformer.py</div><div id='m_start'> M Start Line: 132</div><div id='m_end'> M End Line: 134</div><div id='n_start'> N Start Line: 131</div><div id='n_end'> N End Line: 131</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 project embedding into smaller space
        speaker_embeddings_projected = self.embedding_bottleneck(utt_embeddings)
        &#47&#47 concat hidden states with spk embeds and then apply projection
        speaker_embeddings_expanded<a id="change"> = </a><a id="change">F.normalize(speaker_embeddings_projected).unsqueeze(1).expand(-1</a>, hs.size(1), <a id="change">-1</a><a id="change">)</a>
        hs<a id="change"> = </a>self.hs_emb_projection(<a id="change">torch.cat(</a>[hs, speaker_embeddings_expanded]<a id="change">, dim=-1)</a>)
        <a id="change">return </a>hs

    def _integrate_with_utt_embed_decoder(self, hs, utt_embeddings):
        hs = self.hs_emb_projection(x=hs, speaker_embedding=utt_embeddings)</code></pre><h3>After Change</h3><pre><code class='java'>

    def _integrate_with_utt_embed_encoder(self, hs, utt_embeddings):
        expanded_embeddings = self.embedding_expansion(utt_embeddings)
        <a id="change">return </a>hs + expanded_embeddings

    def _integrate_with_utt_embed_decoder(self, hs, utt_embeddings):
        hs = self.hs_emb_projection(x=hs, speaker_embedding=utt_embeddings.detach())</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/3949187cd4e2e25ffc60f80f5ba247b6894f5da1#diff-d635fb003b559f77f551259cb56709a57f9a634f85664ca1d8a45aff44d754d7L137' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110049544</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 3949187cd4e2e25ffc60f80f5ba247b6894f5da1</div><div id='time'> Time: 2022-06-30</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: Layers/Conformer.py</div><div id='m_class'> M Class Name: Conformer</div><div id='n_method'> N Class Name: Conformer</div><div id='m_method'> M Method Name: _integrate_with_utt_embed_encoder(3)</div><div id='n_method'> N Method Name: _integrate_with_utt_embed_encoder(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: Layers/Conformer.py</div><div id='n_file'> N File Name: Layers/Conformer.py</div><div id='m_start'> M Start Line: 139</div><div id='m_end'> M End Line: 143</div><div id='n_start'> N Start Line: 135</div><div id='n_end'> N End Line: 136</div><BR>