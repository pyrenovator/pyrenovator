<html><h3>Pattern ID :35462
</h3><img src='100747616.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def loss_unknown_structure(self, seq, pairs, score_paired, score_unpaired, pred_bp):
        pred_unpaired = torch.ones_like(score_unpaired, dtype=torch.bool)
        print(torch.max(score_paired[1:, 1:]))
        <a id="change">for </a>i, <a id="change">j</a> in <a id="change">enumerate(</a>pred_bp<a id="change">):
            </a>if i &lt; j:
                <a id="change">pred_unpaired[i]</a> = pred_unpaired[j]<a id="change"> = </a>False
        score_unpaired = score_unpaired[1:]
        score_paired = 1 - score_unpaired
        pred_unpaired<a id="change"> = </a>pred_unpaired[1:]

        &#47&#47print(pred_bp)
        &#47&#47print(score_paired)</code></pre><h3>After Change</h3><pre><code class='java'>
        score_paired = 1 - score_unpaired
        &#47&#47print(pred_bp)
        pairs_not_nan = torch.logical_not(torch.isnan(pairs))
        loss  = torch.sum(pairs[pairs_not_nan[:, 0], 0] * score_unpaired[<a id="change">pairs_not_nan[:, 0]</a>])
        loss += torch.sum(pairs[pairs_not_nan[:, 1], 1] * score_paired[pairs_not_nan[:, 1]])

        return loss</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/mxfold/mxfold2/commit/307eec16f1b4f6b77b0950411d034a4289fb83b0#diff-40c7dafe6bf4ae19d9896b17c5ef72d560791abfcb151c955d1f5348a9df295cL126' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 100747616</div><div id='project'> Project Name: mxfold/mxfold2</div><div id='commit'> Commit Name: 307eec16f1b4f6b77b0950411d034a4289fb83b0</div><div id='time'> Time: 2020-01-06</div><div id='author'> Author: satoken@bio.keio.ac.jp</div><div id='file'> File Name: dnnfold/train.py</div><div id='m_class'> M Class Name: PiecewiseLoss</div><div id='n_method'> N Class Name: PiecewiseLoss</div><div id='m_method'> M Method Name: loss_unknown_structure(6)</div><div id='n_method'> N Method Name: loss_unknown_structure(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dnnfold/train.py</div><div id='n_file'> N File Name: dnnfold/train.py</div><div id='m_start'> M Start Line: 126</div><div id='m_end'> M End Line: 140</div><div id='n_start'> N Start Line: 133</div><div id='n_end'> N End Line: 135</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 for one batch, we mask the same polyline features
            if self.with_aux:
                mask_polyline_indices = [random.randint(0, time_step_len-1) for _ in range(x.size()[0])]
                <a id="change">for </a>i, <a id="change">idx</a> in <a id="change">enumerate(</a>mask_polyline_indices<a id="change">):
                    x[i, idx, :]</a><a id="change"> = </a>0.0

            global_graph_out = self.global_graph(x, valid_lens)
            pred = self.traj_pred_mlp(global_graph_out[:, [0]].squeeze(1))

            if self.with_aux:
                aux_in = torch.empty((global_graph_out.size()[0],
                                      self.polyline_vec_shape)
                                     ).to(self.device)
                aux_gt = torch.empty((global_graph_out.size()[0],
                                      self.polyline_vec_shape)
                                     ).to(self.device)
                for i, idx in enumerate(mask_polyline_indices):
                    aux_in[i]<a id="change"> = </a>global_graph_out[i, idx].squeeze(0)
                    aux_gt[i] = x[i, idx].squeeze(0)
                aux_out = self.aux_mlp(aux_in)
</code></pre><h3>After Change</h3><pre><code class='java'>
                return pred, aux_out, aux_gt
            else:
                global_graph_out = self.global_graph(x, valid_lens)
                pred = self.traj_pred_mlp(<a id="change">global_graph_out[:, [0]]</a>.squeeze(1))

                return pred, None, None
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/henry1iu/tnt-trajectory-prediction/commit/d5edc8d904cf69f92ff3c5f3acdfeb64c820ccca#diff-30a78fb4a0ae3bce4bc75278f5050fe453264ac4857acda73396888cdc4f7b0cL201' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 100747653</div><div id='project'> Project Name: henry1iu/tnt-trajectory-prediction</div><div id='commit'> Commit Name: d5edc8d904cf69f92ff3c5f3acdfeb64c820ccca</div><div id='time'> Time: 2021-01-21</div><div id='author'> Author: jb@LIUs-MacBook-Pro.local</div><div id='file'> File Name: core/model/vectornet.py</div><div id='m_class'> M Class Name: OriginalVectorNet</div><div id='n_method'> N Class Name: OriginalVectorNet</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: core/model/vectornet.py</div><div id='n_file'> N File Name: core/model/vectornet.py</div><div id='m_start'> M Start Line: 213</div><div id='m_end'> M End Line: 242</div><div id='n_start'> N Start Line: 205</div><div id='n_end'> N End Line: 237</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 get the contribution of each component
        X_ks = torch.zeros(len(L), spec_shape[1], spec_shape[2]).to(self.device)
        sum_X_k = torch.zeros(spec_shape[1], spec_shape[2]).to(self.device)
        <a id="change">for </a>(i, <a id="change">k</a>) in <a id="change">enumerate(</a>L<a id="change">):
            </a>X_k = nmf_dictionary[:, k].unsqueeze(1) @ psi_out[k, :].unsqueeze(0)
            sum_X_k += X_k
            <a id="change">X_ks[i]</a><a id="change"> = </a>X_k
            &#47&#47 cem : for the denominator we need to sum over all K, not just the selected ones. 

        &#47&#47 need the eps for the denominator
        eps = 1e-10
        X_int<a id="change"> = </a>(X_ks / (sum_X_k.unsqueeze(0)+eps)).sum(0) * X_stft_power_log

        &#47&#47 get back to the standard stft
        X_int = torch.exp(X_int) - 1</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47     sum_X_k += X_k
        &#47&#47     X_ks[i] = X_k
        &#47&#47 cem : for the denominator we need to sum over all K, not just the selected ones. 
        X_withselected = <a id="change">nmf_dictionary[:, L]</a> @ psi_out[L, :]
        Xhat = nmf_dictionary @ psi_out

        &#47&#47 need the eps for the denominator</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/2efd11efe6d6a7c1741a0525e762ceac1837b706#diff-8f3874d114f157f94ccdf7b656a9cc7738dfe21aef4a26c86929a9f19edda806L51' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 100747627</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 2efd11efe6d6a7c1741a0525e762ceac1837b706</div><div id='time'> Time: 2022-11-21</div><div id='author'> Author: csubakan@gmail.com</div><div id='file'> File Name: recipes/ESC50/classification/train_interpreter.py</div><div id='m_class'> M Class Name: InterpreterESC50Brain</div><div id='n_method'> N Class Name: InterpreterESC50Brain</div><div id='m_method'> M Method Name: interpret_batch(2)</div><div id='n_method'> N Method Name: interpret_batch(2)</div><div id='m_parent_class'> M Parent Class: sb.core.Brain</div><div id='n_parent_class'> N Parent Class: sb.core.Brain</div><div id='m_file'> M File Name: recipes/ESC50/classification/train_interpreter.py</div><div id='n_file'> N File Name: recipes/ESC50/classification/train_interpreter.py</div><div id='m_start'> M Start Line: 83</div><div id='m_end'> M End Line: 117</div><div id='n_start'> N Start Line: 84</div><div id='n_end'> N End Line: 120</div><BR>