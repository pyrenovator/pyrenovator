<html><h3>Pattern ID :11301
</h3><img src='38459338.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    min_c = np.min(np_polygon, axis=0)
    max_c = np.max(np_polygon, axis=0)
    h_extend = int(round(0.1 * (max_c[1] - min_c[1])))
    w_extend = <a id="change">int(</a>round(0.1 * (max_c[0]<a id="change"> - min_c[0]</a>))<a id="change">)</a>
    min_row<a id="change"> = </a>np.maximum(0, min_c[1] - h_extend)
    min_col = np.maximum(0, min_c[0] - w_extend)
    max_row<a id="change"> = </a>np.minimum(image_height, max_c[1] + h_extend)
    max_col = np.minimum(image_width, max_c[0] + w_extend)
    <a id="change">return </a>min_row, min_col, max_row, max_col


def get_bboxes_from_polygons(polygons: List[Polygon]) -&gt; List[Tuple]:</code></pre><h3>After Change</h3><pre><code class='java'>
        Tuple: extended bounds
    
    np_polygon = np.array(polygon.exterior.coords)
    <a id="change">return </a>get_extended_bounds_from_np_array_polygon(
        np_polygon, image_bounds, extend_factor=extend_factor
    )
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/dsgoficial/pytorch_segmentation_models_trainer/commit/2b8d58fa4129e5244a7313dcc00b1bea7fd6ed1d#diff-4ac5d551e03e04482456867c4c952953f178582517c0f7f8965a19d6336e07b8L452' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38459338</div><div id='project'> Project Name: dsgoficial/pytorch_segmentation_models_trainer</div><div id='commit'> Commit Name: 2b8d58fa4129e5244a7313dcc00b1bea7fd6ed1d</div><div id='time'> Time: 2021-11-26</div><div id='author'> Author: philipeborba@gmail.com</div><div id='file'> File Name: pytorch_segmentation_models_trainer/utils/polygonrnn_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: get_extended_bounds(3)</div><div id='n_method'> N Method Name: get_extended_bounds(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: pytorch_segmentation_models_trainer/utils/polygonrnn_utils.py</div><div id='n_file'> N File Name: pytorch_segmentation_models_trainer/utils/polygonrnn_utils.py</div><div id='m_start'> M Start Line: 452</div><div id='m_end'> M End Line: 462</div><div id='n_start'> N Start Line: 452</div><div id='n_end'> N End Line: 455</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        height = int(img.size[1] * ratio)
        img = img.resize((width, height), Image.ANTIALIAS)
    elif size is not None:
        img<a id="change"> = </a>img.resize((size, size), Image.ANTIALIAS)
    elif scale is not None:
        img = img.resize((int(img.size[0] / scale), <a id="change">int(img.size[1]</a><a id="change"> / </a>scale<a id="change">)</a>), Image.ANTIALIAS)
    <a id="change">return </a>img if return_pil else np.array(img)


def prepare_img(img_path, new_width, device):</code></pre><h3>After Change</h3><pre><code class='java'>
def load_image(img_path, width=None):
    img = sio.imread(img_path).astype(np.float32)
    if img.shape[2] == 4:  &#47&#47 remove alpha channel
        img<a id="change"> = </a>img[:, :, :3]
    img /= 255.0  &#47&#47 get to [0, 1] range
    if width is not None and width != -1:
        ratio = width / img.shape[0]
        height = int(img.shape[1] * ratio)
        img = resize(img, (width, height), anti_aliasing=True)
    <a id="change">return </a>img


def prepare_img(img_path, new_width, device):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/gordicaleksa/pytorch-neural-style-transfer/commit/6856e5796971c3fb5e77c0a798b35e6e106b5bcb#diff-9653b8c2ce917a6134298b00c8b3f7d4b7c4dc473a752303f37a870392742127L12' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38459330</div><div id='project'> Project Name: gordicaleksa/pytorch-neural-style-transfer</div><div id='commit'> Commit Name: 6856e5796971c3fb5e77c0a798b35e6e106b5bcb</div><div id='time'> Time: 2020-03-30</div><div id='author'> Author: gordicaleksa@gmail.com</div><div id='file'> File Name: utils/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: load_image(2)</div><div id='n_method'> N Method Name: load_image(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: utils/utils.py</div><div id='n_file'> N File Name: utils/utils.py</div><div id='m_start'> M Start Line: 12</div><div id='m_end'> M End Line: 22</div><div id='n_start'> N Start Line: 18</div><div id='n_end'> N End Line: 27</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        :return: (torch.Tensor) Generated output image
        &quot&quot&quot
        &#47&#47 Embed class label
        class_id<a id="change"> = </a>self.embedding(class_id.argmax(dim=-1))
        &#47&#47 Init depth counter
        depth_counter = len(features) - 1
        &#47&#47 Input path
        for index, layer in enumerate(self.input_path):
            if index == 0:
                &#47&#47 Mask feature
                feature = features[depth_counter] * masks[depth_counter]
                output = layer(input, feature)
                depth_counter -= 1
            elif index == 1:
                &#47&#47 Mask feature
                feature = features[depth_counter] * masks[depth_counter]
                output = layer(output, feature)
                depth_counter -= 1
            else:
                output = layer(output)
        &#47&#47 Reshaping
        output = output.view(output.shape[0], <a id="change">int(output.shape[1]</a><a id="change"> // </a>(4 ** 2)<a id="change">)</a>, 4, 4)
        &#47&#47 Main path
        for layer in self.main_path:
            if isinstance(layer, SelfAttention):
                output = layer(output)
            else:
                &#47&#47 Mask feature and concat mask
                feature = features[depth_counter]
                mask = masks[depth_counter]
                feature = torch.cat((feature * mask, mask), dim=1)
                output = layer(output, feature, class_id)
                depth_counter -= 1
        &#47&#47 Final block
        output = self.final_block(output)
        <a id="change">return </a>output


class Discriminator(nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Init depth counter
        depth_counter = len(features) - 1
        &#47&#47 Initial linear layer
        output<a id="change"> = </a>self.linear_layer(input)
        &#47&#47 Forward pass linear blocks
        output = self.linear_block_1(output, features[depth_counter] * masks[depth_counter])
        depth_counter -= 1
        output = self.linear_block_2(output, features[depth_counter] * masks[depth_counter])
        depth_counter -= 1
        &#47&#47 Reshaping
        output = output.view(output.shape[0], -1, 4, 4)
        &#47&#47 Forward pass last linear layer
        output = self.convolution_layer(output)
        &#47&#47 Main path
        for layer in self.main_path:
            if isinstance(layer, SelfAttention):
                output = layer(output)
            else:
                &#47&#47 Mask feature and concat mask
                feature = features[depth_counter]
                mask = masks[depth_counter]
                feature = torch.cat((feature * mask, mask), dim=1)
                output = layer(output, feature, class_id)
                depth_counter -= 1
        &#47&#47 Final block
        output = self.final_block(output)
        <a id="change">return </a>output.tanh()


class Discriminator(nn.Module):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/christophreich1996/semantic_pyramid_for_image_generation/commit/8d56a34edd21d5874a8d45af97eba926a6f171c0#diff-dcfeaa5ac3dffd54264034760914588d92fc7395c81eaa9274715840dc28100bL62' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38459331</div><div id='project'> Project Name: christophreich1996/semantic_pyramid_for_image_generation</div><div id='commit'> Commit Name: 8d56a34edd21d5874a8d45af97eba926a6f171c0</div><div id='time'> Time: 2021-03-29</div><div id='author'> Author: 34400551+ChristophReich1996@users.noreply.github.com</div><div id='file'> File Name: models.py</div><div id='m_class'> M Class Name: Generator</div><div id='n_method'> N Class Name: Generator</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models.py</div><div id='n_file'> N File Name: models.py</div><div id='m_start'> M Start Line: 71</div><div id='m_end'> M End Line: 103</div><div id='n_start'> N Start Line: 74</div><div id='n_end'> N End Line: 97</div><BR>