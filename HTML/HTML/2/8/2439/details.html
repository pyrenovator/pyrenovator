<html><h3>Pattern ID :2439
</h3><img src='10288824.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    )

    final = {}
    <a id="change">for </a>k in outputs.keys()<a id="change">:
        </a><a id="change">final[k]</a><a id="change"> = </a>inputs[k] + outputs[k]
        <a id="change">if </a>k == "input_ids":
            <a id="change">final["labels"]</a> = [tokenizer.pad_token_id] * len(inputs["input_ids"]) + outputs[k]
    return final

</code></pre><h3>After Change</h3><pre><code class='java'>
    input_tokens = tokenizer.tokenize(source)[:max_source_length]

    &#47&#47 2. tokenize output tokens
    output_tokens = <a id="change">tokenizer.tokenize(</a>target<a id="change">)</a>[:max_target_length]

    &#47&#47 3. concat the inputs
    tokens = input_tokens + output_tokens

    labels = [tokenizer.pad_token_id] * len(input_tokens) + tokenizer.convert_tokens_to_ids(output_tokens)

    input_ids<a id="change"> = </a>tokenizer.convert_tokens_to_ids(tokens)

    return {
        "input_ids": paddle.to_tensor(input_ids, dtype="int64"),</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/cd9b90e2339a664617b607015d8735e0d430dce2#diff-9e01507f31a8cef3a50b864311e1088183748ed637f785df03a0d0dad8009454L68' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 10288824</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: cd9b90e2339a664617b607015d8735e0d430dce2</div><div id='time'> Time: 2023-03-29</div><div id='author'> Author: 1435130236@qq.com</div><div id='file'> File Name: examples/language_model/bloom/finetune_generation.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: convert_example(6)</div><div id='n_method'> N Method Name: convert_example(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/language_model/bloom/finetune_generation.py</div><div id='n_file'> N File Name: examples/language_model/bloom/finetune_generation.py</div><div id='m_start'> M Start Line: 68</div><div id='m_end'> M End Line: 106</div><div id='n_start'> N Start Line: 68</div><div id='n_end'> N End Line: 105</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                nwords = len(words)
                ids = torch.IntTensor(nwords + 1)
                nseq = nseq + 1
                <a id="change">for </a><a id="change">i</a> in range(0, len(words))<a id="change">:
                    </a>word = words[i]
                    idx = dict.index(word)
                    <a id="change">if </a>idx == dict.unk_index and word != dict.unk_word:
                        nunk = nunk + 1
                        if word in replaced:
                            replaced[word] = replaced[word] + 1
                        else:
                            replaced[word] = 1
                    <a id="change">ids[i]</a><a id="change"> = </a>idx

                <a id="change">ids[nwords]</a> = dict.eos_index
                consumer(ids)
                ntok = ntok + len(ids)
        return {&quotnseq&quot: nseq, &quotnunk&quot: nunk, &quotntok&quot: ntok, &quotreplaced&quot: len(replaced)}</code></pre><h3>After Change</h3><pre><code class='java'>

        with open(filename, &quotr&quot) as f:
            for line in f:
                ids = <a id="change">Tokenizer.tokenize(</a>line, dict, tokenize<a id="change">, add_if_not_exist=False, consumer=replaced_consumer)</a>
                nseq += 1

                consumer(ids)
                ntok<a id="change"> += </a>len(ids)
        return {&quotnseq&quot: nseq, &quotnunk&quot: sum(replaced.values()), &quotntok&quot: ntok, &quotreplaced&quot: len(replaced)}

    @staticmethod</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/kssteven418/i-bert/commit/cab76554bff7f65c1d423fbe6960012b52adaeb0#diff-3461dadae7b1752387f4f0222a3cd879682d91f526ef1c2a8944457285b329f3L41' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 10288825</div><div id='project'> Project Name: kssteven418/i-bert</div><div id='commit'> Commit Name: cab76554bff7f65c1d423fbe6960012b52adaeb0</div><div id='time'> Time: 2017-10-19</div><div id='author'> Author: louismartin@fb.com</div><div id='file'> File Name: fairseq/tokenizer.py</div><div id='m_class'> M Class Name: Tokenizer</div><div id='n_method'> N Class Name: Tokenizer</div><div id='m_method'> M Method Name: binarize(4)</div><div id='n_method'> N Method Name: binarize(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: fairseq/tokenizer.py</div><div id='n_file'> N File Name: fairseq/tokenizer.py</div><div id='m_start'> M Start Line: 42</div><div id='m_end'> M End Line: 64</div><div id='n_start'> N Start Line: 45</div><div id='n_end'> N End Line: 58</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    )

    final = {}
    <a id="change">for </a><a id="change">k</a> in outputs.keys()<a id="change">:
        </a><a id="change">final[k]</a><a id="change"> = </a>inputs[k] + outputs[k]
        <a id="change">if </a>k == "input_ids":
            <a id="change">final["labels"]</a> = [tokenizer.pad_token_id] * len(inputs["input_ids"]) + outputs[k]
    return final

</code></pre><h3>After Change</h3><pre><code class='java'>
        target += tokenizer.eos_token

    &#47&#47 1. tokenize input-tokens
    input_tokens = <a id="change">tokenizer.tokenize(</a>source<a id="change">)</a>[:max_source_length]

    &#47&#47 2. tokenize output tokens
    output_tokens = tokenizer.tokenize(target)[:max_target_length]

    &#47&#47 3. concat the inputs
    tokens = input_tokens + output_tokens

    labels = [tokenizer.pad_token_id] * len(input_tokens) + tokenizer.convert_tokens_to_ids(output_tokens)

    input_ids<a id="change"> = </a>tokenizer.convert_tokens_to_ids(tokens)

    return {
        "input_ids": paddle.to_tensor(input_ids, dtype="int64"),</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/cd9b90e2339a664617b607015d8735e0d430dce2#diff-9e01507f31a8cef3a50b864311e1088183748ed637f785df03a0d0dad8009454L57' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 10288821</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: cd9b90e2339a664617b607015d8735e0d430dce2</div><div id='time'> Time: 2023-03-29</div><div id='author'> Author: 1435130236@qq.com</div><div id='file'> File Name: examples/language_model/bloom/finetune_generation.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: convert_example(6)</div><div id='n_method'> N Method Name: convert_example(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/language_model/bloom/finetune_generation.py</div><div id='n_file'> N File Name: examples/language_model/bloom/finetune_generation.py</div><div id='m_start'> M Start Line: 68</div><div id='m_end'> M End Line: 106</div><div id='n_start'> N Start Line: 68</div><div id='n_end'> N End Line: 105</div><BR>