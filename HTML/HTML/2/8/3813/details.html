<html><h3>Pattern ID :3813
</h3><img src='14470493.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 now find all the track filepaths
            track_filepaths = glob.glob(os.path.join(mix_dir, f"{mix_id}_RAW", "*.wav"))

            <a id="change">if len(track_filepaths) &gt; self.max_num_tracks</a>:
                <a id="change">continue</a>

            &#47&#47 check length of each track
            tracks = []
            for tidx, track_filepath in enumerate(track_filepaths):
                x, sr = torchaudio.load(track_filepath)
                tracks.append(x)

                nbytes = x.element_size() * x.nelement()
                nbytes_loaded += nbytes

                track_num_frames = x.shape[-1]
                if track_num_frames &lt; mix_num_frames:
                    mix_num_frames<a id="change"> = </a>track_num_frames

            &#47&#47 store this example
            example = {</code></pre><h3>After Change</h3><pre><code class='java'>
        random.shuffle(self.mix_dirs)

        &#47&#47 load files into RAM
        <a id="change">while nbytes_loaded &lt; self.buffer_size_gb * 1e9</a><a id="change">:
            </a>for mix_dir in tqdm(self.mix_dirs):
                mix_id = os.path.basename(mix_dir)
                mix_filepath = glob.glob(os.path.join(mix_dir, "*.wav"))[0]

                if "AimeeNorwich_Child" in mix_filepath:
                    continue

                &#47&#47 save only a random subset of this song so we can load more songs
                silent = True
                counter = 0
                while silent:

                    num_frames = torchaudio.info(mix_filepath).num_frames

                    offset<a id="change"> = </a>np.random.randint(
                        0,
                        num_frames - self.buffer_audio_length - 1,
                    )

                    &#47&#47 now check the length of the mix
                    y, sr = torchaudio.load(
                        mix_filepath,
                        frame_offset=offset,
                        num_frames=self.buffer_audio_length,
                    )

                    energy<a id="change"> = </a>(y**2).mean()
                    print(energy)
                    if energy &gt; 1e-3:
                        silent = False</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/csteinmetz1/automix-toolkit/commit/0fcdce4c33e652710e5c0682499c65bab52b991b#diff-3b5493e29457d0c2fa425a9c7a85b846becf17818150651f5682153839469d49L58' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14470493</div><div id='project'> Project Name: csteinmetz1/automix-toolkit</div><div id='commit'> Commit Name: 0fcdce4c33e652710e5c0682499c65bab52b991b</div><div id='time'> Time: 2022-11-28</div><div id='author'> Author: csteinmetz1@gmail.com</div><div id='file'> File Name: automix/data/medleydb.py</div><div id='m_class'> M Class Name: MedleyDBDataset</div><div id='n_method'> N Class Name: MedleyDBDataset</div><div id='m_method'> M Method Name: reload_buffer(1)</div><div id='n_method'> N Method Name: reload_buffer(1)</div><div id='m_parent_class'> M Parent Class: torch.utils.data.Dataset</div><div id='n_parent_class'> N Parent Class: torch.utils.data.Dataset</div><div id='m_file'> M File Name: automix/data/medleydb.py</div><div id='n_file'> N File Name: automix/data/medleydb.py</div><div id='m_start'> M Start Line: 58</div><div id='m_end'> M End Line: 108</div><div id='n_start'> N Start Line: 62</div><div id='n_end'> N End Line: 148</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        anchor_embedding = run_inference(anchor, encoder)
        pos_embedding = run_inference(pos, encoder)
        neg_embedding = run_inference(neg, encoder)
        <a id="change">if </a>(<a id="change">(anchor_embedding is None)</a> or
            (pos_embedding is None) or
                (neg_embedding is None)):
            &#47&#47 Some utterances might be smaller than a single sliding window.
            <a id="change">continue</a>
        labels.append(1)
        scores.append(cosine_similarity(anchor_embedding, pos_embedding))
        labels.append(0)
        scores.append(cosine_similarity(anchor_embedding, neg_embedding))
        triplets_evaluated<a id="change"> += </a>1
        print("triplets evaluated:", triplets_evaluated, "/", num_eval_triplets)
    return (labels, scores)
</code></pre><h3>After Change</h3><pre><code class='java'>
    spk_to_utts = feature_extraction.get_spk_to_utts(myconfig.TEST_DATA_DIR)
    fetcher = TripletScoreFetcher(spk_to_utts, encoder, num_eval_triplets)
    with multiprocessing.Pool(myconfig.NUM_PROCESSES) as pool:
        <a id="change">while num_eval_triplets &gt; len(labels) // 2</a><a id="change">:
            </a>label_score_pairs = pool.map(fetcher, range(
                num_eval_triplets - len(labels) // 2))
            for triplet_labels, triplet_scores in label_score_pairs:
                labels<a id="change"> += </a>triplet_labels
                scores<a id="change"> += </a>triplet_scores
    print("Evaluated", len(labels) // 2, "triplets in total")
    return (labels, scores)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/wq2012/speakerrecognitionfromscratch/commit/a93d8ddbd387c75b3eb58399b724b95f61e51a24#diff-a125d525a42d9eebcc59ec6396eebb81e99daa0e96afa71d4741fe32d46ab9a2L36' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14470459</div><div id='project'> Project Name: wq2012/speakerrecognitionfromscratch</div><div id='commit'> Commit Name: a93d8ddbd387c75b3eb58399b724b95f61e51a24</div><div id='time'> Time: 2022-05-10</div><div id='author'> Author: quanw@google.com</div><div id='file'> File Name: evaluation.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: compute_scores(2)</div><div id='n_method'> N Method Name: compute_scores(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: evaluation.py</div><div id='n_file'> N File Name: evaluation.py</div><div id='m_start'> M Start Line: 38</div><div id='m_end'> M End Line: 58</div><div id='n_start'> N Start Line: 67</div><div id='n_end'> N End Line: 78</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if len(arg.strip()) == 0:
        return {}
    for kv in arg.split(","):
        <a id="change">if kv == ""</a>:
            <a id="change">continue</a>
        key<a id="change">, value = </a>kv.split("=")
        conf[key] = value
    return conf
</code></pre><h3>After Change</h3><pre><code class='java'>
    pair_delimiter: str = ","

    cpos: int = 0
    <a id="change">while cpos &lt; len(arg)</a><a id="change">:
        </a>key<a id="change"> = </a>_get_key(arg, cpos, kv_delimiter)
        cpos += len(key) + 1
        value = _get_value(arg, cpos, kv_delimiter, pair_delimiter)
        cpos<a id="change"> += </a>len(value) + 1
        conf[key] = value
    return conf
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/torchx/commit/8087ab4b6a1ccc78f2a811226aeacc41793485cb#diff-3768732b61f67df58f24c2d6f8b004982665a8e37ae4fa8fb3a9633b7f8ec840L12' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14470485</div><div id='project'> Project Name: pytorch/torchx</div><div id='commit'> Commit Name: 8087ab4b6a1ccc78f2a811226aeacc41793485cb</div><div id='time'> Time: 2021-09-09</div><div id='author'> Author: aivanou@fb.com</div><div id='file'> File Name: torchx/util/types.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: to_dict(1)</div><div id='n_method'> N Method Name: to_dict(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchx/util/types.py</div><div id='n_file'> N File Name: torchx/util/types.py</div><div id='m_start'> M Start Line: 14</div><div id='m_end'> M End Line: 21</div><div id='n_start'> N Start Line: 25</div><div id='n_end'> N End Line: 39</div><BR>