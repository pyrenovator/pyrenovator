<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
def test_conv2d_transpose(
    x_n_filters_n_pad_n_outshp_n_res, dtype, tensor_fn, device, call
):
    if call in <a id="change">[</a>helpers.tf_call, helpers.tf_graph_call<a id="change"></a>] and "cpu" in device:
        &#47&#47 tf conv2d transpose does not work when CUDA is installed, but array is on CPU
        <a id="change">pytest.skip()</a>
    &#47&#47 smoke test
    if call in [helpers.np_call, helpers.jnp_call]:
        &#47&#47 numpy and jax do not yet support conv2d_transpose
        pytest.skip()</code></pre><h3>After Change</h3><pre><code class='java'>
    if fw == &quottensorflow&quot and "cpu" in device:
        &#47&#47 tf conv2d transpose does not work when CUDA is installed, but array is on CPU
        return
    if fw in <a id="change">[&quotnumpy&quot</a>, <a id="change">&quotjax&quot</a>]:
        &#47&#47 numpy and jax do not yet support conv2d_transpose
        <a id="change">return</a>
    if fw == &quottorch&quot and (&quot16&quot in dtype[0] or &quot16&quot in dtype[1]):
        &#47&#47 not implemented for Half
        return
    x = <a id="change">np.random.uniform(size=array_shape).astype(</a>dtype[0]<a id="change">)</a>
    x = np.expand_dims(x, (-1))
    filters = <a id="change">np.random.uniform(size=(filter_shape,
                                      filter_shape,
                                      1,
                                      1)).astype(</a>dtype[1]<a id="change">)</a>
    <a id="change">helpers.test_array_function(
        </a>dtype,
        as_variable,
        False,
        num_positional_args,
        native_array,
        container,
        instance_method,
        fw,
        <a id="change">"conv2d_transpose"</a><a id="change">,
        x=x,
        filters=filters,
        strides=stride,
        padding=pad,
        output_shape=tuple(output_shape),
        data_format=data_format,
        dilations=dilations
    )</a>


&#47&#47 depthwise_conv2d
@pytest.mark.parametrize(</code></pre>