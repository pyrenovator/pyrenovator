<html><h3>Pattern ID :12165
</h3><img src='41110130.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                for conf in mol["conformations"].values():

                    &#47&#47 Skip failed calculations
                    <a id="change">if </a>"formation_energy" not in conf:
                        continue

                    assert conf["positions"].attrs["units"] == "Å"
                    pos = pt.tensor(conf["positions"], dtype=pt.float32)
                    assert pos.shape == (z.shape[0], 3)

                    assert conf["formation_energy"].attrs["units"] == "eV"
                    y<a id="change"> = </a>pt.tensor(conf["formation_energy"][()], dtype=pt.float64)
                    assert y.shape == ()

                    assert conf["forces"].attrs["units"] == "eV/Å"
                    dy = -pt.tensor(conf["forces"], dtype=pt.float32)
                    assert dy.shape == pos.shape

                    assert conf["partial_charges"].attrs["units"] == "e"
                    pq = pt.tensor(conf["partial_charges"], dtype=pt.float32)
                    assert pq.shape == z.shape

                    assert conf["dipole_moment"].attrs["units"] == "e*Å"
                    dp<a id="change"> = </a>pt.tensor(conf["dipole_moment"], dtype=pt.float32)
                    assert dp.shape == (3,)

                    &#47&#47 Skip samples with large forces</code></pre><h3>After Change</h3><pre><code class='java'>
            if version == "1.0":
                assert "name" in h5.attrs
                mols = h5.items()
                load_confs<a id="change"> = </a>self._load_confs_1_0
            elif <a id="change">version == "2.0"</a>:
                assert len(h5.keys()) == 1
                mols = list(h5.values())[0].items()
                load_confs<a id="change"> = </a>self._load_confs_2_0
            else:
                <a id="change">raise </a><a id="change">RuntimeError(f"Unsuported layout verions: {version}"</a><a id="change">)</a>

            &#47&#47 Iterate over the molecules
            for i_mol, (mol_id, mol) in tqdm(
                enumerate(mols),</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/torchmd/torchmd-net/commit/d23e6500f2cef1fa56d6c99ce5fdb983f1379bca#diff-56de3e28dd2b438171f4af7de59cc66305304d98e21b24faf4d744698d8c1aa3L72' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41110130</div><div id='project'> Project Name: torchmd/torchmd-net</div><div id='commit'> Commit Name: d23e6500f2cef1fa56d6c99ce5fdb983f1379bca</div><div id='time'> Time: 2022-10-28</div><div id='author'> Author: peastman@stanford.edu</div><div id='file'> File Name: torchmdnet/datasets/ace.py</div><div id='m_class'> M Class Name: Ace</div><div id='n_method'> N Class Name: Ace</div><div id='m_method'> M Method Name: sample_iter(2)</div><div id='n_method'> N Method Name: sample_iter(1)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: torchmdnet/datasets/ace.py</div><div id='n_file'> N File Name: torchmdnet/datasets/ace.py</div><div id='m_start'> M Start Line: 72</div><div id='m_end'> M End Line: 123</div><div id='n_start'> N Start Line: 144</div><div id='n_end'> N End Line: 206</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        module_masks = {  &#47&#47 map module masks by name
            module_mask.name: module_mask for module_mask in self._module_masks
        }
        for param_name, <a id="change">mask_tensor</a> in state_dict.items():
            if param_name not in module_masks:
                raise RuntimeError(
                    f"Unexpected parameter name when loading state dict for "
                    f"GMPruningModifier Manager has parameters "
                    f"{list(module_masks.keys())}, given {param_name}"
                )
            mask_disabled<a id="change"> = </a>False
            <a id="change">if </a>not module_masks[param_name].enabled:
                &#47&#47 enable mask object so the loaded mask will apply
                module_masks[param_name].enabled<a id="change"> = </a>True
                mask_disabled<a id="change"> = </a>True
            module_masks[param_name].set_param_mask(mask_tensor)
            if mask_disabled:
                &#47&#47 set mask object back to disabled</code></pre><h3>After Change</h3><pre><code class='java'>
            raise RuntimeError("Cannot load state dict for an uninitialized modifier")

        mask_names = self._module_masks.names
        for <a id="change">key</a> in state_dict:
            if key not in mask_names:
                raise RuntimeError(
                    f"State dict key {key} not found in ConstantPruningModifier params"
                )
        for name in mask_names:
            <a id="change">if name not in state_dict</a>:
                <a id="change">raise </a><a id="change">RuntimeError(
                    f"Mask parameter name {name} not found in state dict"</a><a id="change">
                )</a>

        masks_disabled = False
        if not masks_disabled:
            &#47&#47 enable mask object so that the laoded mask will apply
            masks_disabled<a id="change"> = </a>True
        self._module_masks.set_param_masks([state_dict[name] for name in mask_names])
        if masks_disabled:
            &#47&#47 set mask object back to disabled</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neuralmagic/sparseml/commit/fe5523fe7887a86a5909fd72a531f4577fab358a#diff-0734238a566134bf3546e4f564d93f855dbd07715b57705f0f21c6d2ff651db8L403' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41110395</div><div id='project'> Project Name: neuralmagic/sparseml</div><div id='commit'> Commit Name: fe5523fe7887a86a5909fd72a531f4577fab358a</div><div id='time'> Time: 2021-04-09</div><div id='author'> Author: bfineran@users.noreply.github.com</div><div id='file'> File Name: src/sparseml/pytorch/optim/modifier_pruning.py</div><div id='m_class'> M Class Name: GMPruningModifier</div><div id='n_method'> N Class Name: GMPruningModifier</div><div id='m_method'> M Method Name: load_state_dict(2)</div><div id='n_method'> N Method Name: load_state_dict(2)</div><div id='m_parent_class'> M Parent Class: ScheduledUpdateModifier</div><div id='n_parent_class'> N Parent Class: ScheduledUpdateModifier</div><div id='m_file'> M File Name: src/sparseml/pytorch/optim/modifier_pruning.py</div><div id='n_file'> N File Name: src/sparseml/pytorch/optim/modifier_pruning.py</div><div id='m_start'> M Start Line: 414</div><div id='m_end'> M End Line: 434</div><div id='n_start'> N Start Line: 434</div><div id='n_end'> N End Line: 455</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        module_masks = {  &#47&#47 map module masks by name
            module_mask.name: module_mask for module_mask in self._module_masks
        }
        for param_name, <a id="change">mask_tensor</a> in state_dict.items():
            if param_name not in module_masks:
                raise RuntimeError(
                    f"Unexpected parameter name when loading state dict for "
                    f"ConstantPruningModifier Manager has parameters "
                    f"{list(module_masks.keys())}, given {param_name}"
                )
            mask_disabled<a id="change"> = </a>False
            <a id="change">if </a>not module_masks[param_name].enabled:
                &#47&#47 enable mask object so the loaded mask will apply
                module_masks[param_name].enabled<a id="change"> = </a>True
                mask_disabled<a id="change"> = </a>True
            module_masks[param_name].set_param_mask(mask_tensor)
            if mask_disabled:
                &#47&#47 set mask object back to disabled</code></pre><h3>After Change</h3><pre><code class='java'>
            raise RuntimeError("Cannot load state dict for an uninitialized modifier")

        mask_names = self._module_masks.names
        for <a id="change">key</a> in state_dict:
            if key not in mask_names:
                raise RuntimeError(
                    f"State dict key {key} not found in ConstantPruningModifier params"
                )
        for name in mask_names:
            <a id="change">if name not in state_dict</a>:
                <a id="change">raise </a><a id="change">RuntimeError(
                    f"Mask parameter name {name} not found in state dict"</a><a id="change">
                )</a>

        masks_disabled<a id="change"> = </a>False
        if not masks_disabled:
            &#47&#47 enable mask object so that the laoded mask will apply
            masks_disabled = True</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neuralmagic/sparseml/commit/fe5523fe7887a86a5909fd72a531f4577fab358a#diff-0734238a566134bf3546e4f564d93f855dbd07715b57705f0f21c6d2ff651db8L156' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41108329</div><div id='project'> Project Name: neuralmagic/sparseml</div><div id='commit'> Commit Name: fe5523fe7887a86a5909fd72a531f4577fab358a</div><div id='time'> Time: 2021-04-09</div><div id='author'> Author: bfineran@users.noreply.github.com</div><div id='file'> File Name: src/sparseml/pytorch/optim/modifier_pruning.py</div><div id='m_class'> M Class Name: ConstantPruningModifier</div><div id='n_method'> N Class Name: ConstantPruningModifier</div><div id='m_method'> M Method Name: load_state_dict(2)</div><div id='n_method'> N Method Name: load_state_dict(2)</div><div id='m_parent_class'> M Parent Class: ScheduledModifier</div><div id='n_parent_class'> N Parent Class: ScheduledModifier</div><div id='m_file'> M File Name: src/sparseml/pytorch/optim/modifier_pruning.py</div><div id='n_file'> N File Name: src/sparseml/pytorch/optim/modifier_pruning.py</div><div id='m_start'> M Start Line: 167</div><div id='m_end'> M End Line: 187</div><div id='n_start'> N Start Line: 171</div><div id='n_end'> N End Line: 192</div><BR>