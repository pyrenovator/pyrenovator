<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                expected = [torch_bin_op(t, s) for t, s in zip(tensors, scalars)]

                &#47&#47 we dont support bool and complex types on CUDA for now
                if (dtype in torch.testing.get_all_complex_dtypes() or <a id="change">dtype == torch.bool</a>) and self.device_type == &quotcuda&quot:
                    with self.assertRaisesRegex(RuntimeError, "not implemented for"):
                        foreach_bin_op_(tensors, scalars)

                    with self.assertRaisesRegex(RuntimeError, "not implemented for"):
                        foreach_bin_op(tensors, scalars)
                    return

                res = foreach_bin_op(tensors, scalars)

                if dtype == torch.bool:
                    self.assertEqual(res, [torch_bin_op(<a id="change">t.to(</a>torch.float32<a id="change">)</a>, s) for t, s in zip(tensors, scalars)])

                    with self.assertRaisesRegex(RuntimeError, "result type Float can&quott be cast to the desired output type"):
                        foreach_bin_op_(tensors, scalars)
                    return

                if dtype in torch.testing.integral_types():
                    if self.device_type == &quotcpu&quot:
                        self.assertEqual(res, <a id="change">[e.to(torch.float32) for e in expected]</a>)
                    else:
                        &#47&#47 TODO[type promotion]: Fix once type promotion is enabled.
                        self.assertEqual(res, [e.to(dtype) for e in expected])
                else:
                    self.assertEqual(res, expected)

                if dtype in torch.testing.integral_types() and self.device_type == &quotcpu&quot:
                    with self.assertRaisesRegex(RuntimeError, "result type Float can&quott be cast to the desired output type"):
                        foreach_bin_op_(tensors, scalars)
                    <a id="change">return</a>
                else:
                    <a id="change">foreach_bin_op_(</a>tensors, scalars<a id="change">)</a>
                    self.assertEqual(res, tensors)

    @skipCUDAIfRocm
    @dtypes(*torch.testing.get_all_dtypes())</code></pre><h3>After Change</h3><pre><code class='java'>
                    self.assertEqual(res, expected)

                &#47&#47 test in-place
                if <a id="change">dtype in torch.testing.floating_types()</a> and self.device_type == &quotcpu&quot:
                    <a id="change">foreach_bin_op_(</a>tensors, scalars<a id="change">)</a>
                    <a id="change">return</a>
                else:
                    if <a id="change">foreach_bin_op_ == torch._foreach_div_</a> and \
                       dtype in torch.testing.integral_types() and \
                       self.device_type == &quotcpu&quot:
                        with self.assertRaisesRegex(RuntimeError, "can&quott be cast to the desired output type"):</code></pre>