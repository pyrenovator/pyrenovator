<html><h3>Pattern ID :13167
</h3><img src='44510191.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

class DQRC(BaseLearning):
    def __init__(self, parameters):
        <a id="change">super().__init__(</a>parameters<a id="change">)</a>
        self.beta = parameters[&quotbeta&quot]
        self.num_actions = parameters[&quotnum_actions&quot]
        self.num_features = self.policy_net.h1_size
        self.h = torch.zeros(self.num_actions, self.num_features, requires_grad=False).to(device)</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 regularization parameter
        self.alpha = params[&quotalpha&quot]
        self.epsilon = <a id="change">params[&quotepsilon&quot]</a>
        self.beta = params[&quotbeta&quot]

        &#47&#47 secondary weights optimization parameters
        self.beta_1 = <a id="change">params.get(&quotbeta_1&quot</a>, 0.99<a id="change">)</a>
        self.beta_2<a id="change"> = params</a><a id="change">.get(&quotbeta_2&quot</a>, 0.999<a id="change">)</a>
        self.eps<a id="change"> = params</a><a id="change">.get(&quoteps&quot</a>, 1e-8<a id="change">)</a>

        &#47&#47 learnable parameters for secondary weights
        self.h = torch.zeros(self.actions, features, requires_grad=False).to(device)
        &#47&#47 ADAM optimizer parameters for secondary weights</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/rlai-lab/regularized-gradienttd/commit/8e6702e9e3d8529be2f276e70a242133381a171c#diff-2367bdf6abb655fbfc47df83ab5f4fd87ab0601b3f8251122751387a5c0c5935L7' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 44510191</div><div id='project'> Project Name: rlai-lab/regularized-gradienttd</div><div id='commit'> Commit Name: 8e6702e9e3d8529be2f276e70a242133381a171c</div><div id='time'> Time: 2020-07-05</div><div id='author'> Author: andnpatterson@gmail.com</div><div id='file'> File Name: TDRC/DQRC.py</div><div id='m_class'> M Class Name: DQRC</div><div id='n_method'> N Class Name: DQRC</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: BaseLearning</div><div id='m_file'> M File Name: TDRC/DQRC.py</div><div id='n_file'> N File Name: TDRC/DQRC.py</div><div id='m_start'> M Start Line: 7</div><div id='m_end'> M End Line: 18</div><div id='n_start'> N Start Line: 7</div><div id='n_end'> N End Line: 30</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

class DQRC(BaseLearning):
    def __init__(self, parameters):
        <a id="change">super().__init__(</a>parameters<a id="change">)</a>
        self.beta = parameters[&quotbeta&quot]
        self.num_actions = parameters[&quotnum_actions&quot]
        self.num_features = self.policy_net.h1_size
        self.h = torch.zeros(self.num_actions, self.num_features, requires_grad=False).to(device)</code></pre><h3>After Change</h3><pre><code class='java'>
        self.optimizer = optimizer

        &#47&#47 regularization parameter
        self.alpha = <a id="change">params[&quotalpha&quot]</a>
        self.epsilon = params[&quotepsilon&quot]
        self.beta = params[&quotbeta&quot]

        &#47&#47 secondary weights optimization parameters
        self.beta_1 = <a id="change">params.get(&quotbeta_1&quot</a>, 0.99<a id="change">)</a>
        self.beta_2<a id="change"> = </a><a id="change">params.get(&quotbeta_2&quot</a>, 0.999<a id="change">)</a>
        self.eps<a id="change"> = </a><a id="change">params.get(&quoteps&quot</a>, 1e-8<a id="change">)</a>

        &#47&#47 learnable parameters for secondary weights
        self.h = torch.zeros(self.actions, features, requires_grad=False).to(device)
        &#47&#47 ADAM optimizer parameters for secondary weights</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rlai-lab/regularized-gradienttd/commit/8e6702e9e3d8529be2f276e70a242133381a171c#diff-2367bdf6abb655fbfc47df83ab5f4fd87ab0601b3f8251122751387a5c0c5935L7' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 44510190</div><div id='project'> Project Name: rlai-lab/regularized-gradienttd</div><div id='commit'> Commit Name: 8e6702e9e3d8529be2f276e70a242133381a171c</div><div id='time'> Time: 2020-07-05</div><div id='author'> Author: andnpatterson@gmail.com</div><div id='file'> File Name: TDRC/DQRC.py</div><div id='m_class'> M Class Name: DQRC</div><div id='n_method'> N Class Name: DQRC</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: BaseLearning</div><div id='m_file'> M File Name: TDRC/DQRC.py</div><div id='n_file'> N File Name: TDRC/DQRC.py</div><div id='m_start'> M Start Line: 7</div><div id='m_end'> M End Line: 18</div><div id='n_start'> N Start Line: 7</div><div id='n_end'> N End Line: 30</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 plain_last=False: BN + Act always active even at last layer.
        &#47&#47 act="LeakyReLU": LeakyRelu with 0.2 slope by default.
        &#47&#47 norm_kwargs=bn099_kwargs: BatchNorm with 1-0.99=0.01 momentum and 1e-6 eps by defaut. (pytorch momentum != tensorflow momentum)
        <a id="change">super().__init__(</a>*<a id="change">args, plain_last=False, act=act, act_kwargs=act_kwargs, norm_kwargs=norm_kwargs, **kwargs)</a>


class GlobalPooling(torch.nn.Module):
    Global Pooling to adapt RandLA-Net to a classification task.</code></pre><h3>After Change</h3><pre><code class='java'>

    def __init__(self, *args, **kwargs):
        &#47&#47 BN + Act always active even at last layer.
        <a id="change">kwargs["plain_last"]</a> = False
        &#47&#47 LeakyRelu with 0.2 slope by default.
        kwargs["act"]<a id="change"> = </a><a id="change">kwargs.get(</a>"act", <a id="change">"LeakyReLU"</a><a id="change">)</a>
        kwargs["act_kwargs"]<a id="change"> = </a><a id="change">kwargs.get("act_kwargs"</a>, lrelu02_kwargs<a id="change">)</a>
        &#47&#47 BatchNorm with 1 - 0.99 = 0.01 momentum
        &#47&#47 and 1e-6 eps by defaut (tensorflow momentum != pytorch momentum)
        kwargs["norm_kwargs"] = <a id="change">kwargs.get("norm_kwargs"</a>, bn099_kwargs<a id="change">)</a>
        super().__init__(*args, **kwargs)


class LocalFeatureAggregation(MessagePassing):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ignf/myria3d/commit/4fbe77c32a422b6494cf6f0bde5539d8250df9c5#diff-c1baa46beae2ca0cf1f472374306c71454f154ea9f0ebcf38052f295721d1d0bL112' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 44510189</div><div id='project'> Project Name: ignf/myria3d</div><div id='commit'> Commit Name: 4fbe77c32a422b6494cf6f0bde5539d8250df9c5</div><div id='time'> Time: 2022-11-28</div><div id='author'> Author: 11660435+CharlesGaydon@users.noreply.github.com</div><div id='file'> File Name: myria3d/models/modules/pyg_randla_net.py</div><div id='m_class'> M Class Name: SharedMLP</div><div id='n_method'> N Class Name: SharedMLP</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: MLP</div><div id='n_parent_class'> N Parent Class: MLP</div><div id='m_file'> M File Name: myria3d/models/modules/pyg_randla_net.py</div><div id='n_file'> N File Name: myria3d/models/modules/pyg_randla_net.py</div><div id='m_start'> M Start Line: 112</div><div id='m_end'> M End Line: 116</div><div id='n_start'> N Start Line: 104</div><div id='n_end'> N End Line: 113</div><BR>