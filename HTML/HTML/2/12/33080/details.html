<html><h3>Pattern ID :33080
</h3><img src='95680755.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                                                       self.embedder_type == "positional")
        self.view_embedder, self.view_embed_dim = get_positional_embedder(self.view_multires, 
                                                                         self.embedder_type == "positional")
        <a id="change">log.info(f"Position Embed Dim: {self.pos_embed_dim}"</a><a id="change">)</a>
        log.info(f"View Embed Dim: {self.view_embed_dim}")

    def init_decoder(self):
        Initializes the decoder object. </code></pre><h3>After Change</h3><pre><code class='java'>
    def init_embedder(self, embedder_type, frequencies=None):
        Creates positional embedding functions for the position and view direction.
        
        <a id="change">if embedder_type == &quotnone&quot</a>:
            embedder, embed_dim = None, 0
        elif <a id="change">embedder_type == &quotidentity&quot</a>:
            embedder, embed_dim = torch.nn.Identity(), 0
        elif <a id="change">embedder_type == &quotpositional&quot</a>:
            embedder<a id="change">, embed_dim = </a>get_positional_embedder(frequencies=frequencies)
        else:
            raise NotImplementedError(f&quotUnsupported embedder type for NeuralRadianceField: {embedder_type}&quot)
        return embedder, embed_dim</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/nvidiagameworks/kaolin-wisp/commit/688dfebfd03fbfa81560f103244bc7e776e47245#diff-6efb23a0a6d659486b19aa87b9baed0582e8e7c05b4f427f15be2bf47c2efcd3L34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 95680755</div><div id='project'> Project Name: nvidiagameworks/kaolin-wisp</div><div id='commit'> Commit Name: 688dfebfd03fbfa81560f103244bc7e776e47245</div><div id='time'> Time: 2022-12-20</div><div id='author'> Author: 9556101+orperel@users.noreply.github.com</div><div id='file'> File Name: wisp/models/nefs/nerf.py</div><div id='m_class'> M Class Name: NeuralRadianceField</div><div id='n_method'> N Class Name: NeuralRadianceField</div><div id='m_method'> M Method Name: init_embedder(3)</div><div id='n_method'> N Method Name: init_embedder(1)</div><div id='m_parent_class'> M Parent Class: BaseNeuralField</div><div id='n_parent_class'> N Parent Class: BaseNeuralField</div><div id='m_file'> M File Name: wisp/models/nefs/nerf.py</div><div id='n_file'> N File Name: wisp/models/nefs/nerf.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 42</div><div id='n_start'> N Start Line: 65</div><div id='n_end'> N End Line: 76</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def state_dict_hook(module, state_dict, *args, **kwargs):
        Redirect model as output state_dict for OTE model compatibility
        
        <a id="change">logger.info(&quot----------------- SAMImageClassifier.state_dict_hook() called&quot</a><a id="change">)</a>
        if type(module.backbone).__name__ == &quotOTEMobileNetV3&quot:
            output = OrderedDict()
            for k, v in state_dict.items():
                if k.startswith(&quothead.classifier&quot):</code></pre><h3>After Change</h3><pre><code class='java'>
    def state_dict_hook(module, state_dict, *args, **kwargs):
        Redirect model as output state_dict for OTE model compatibility
        
        <a id="change">backbone_type</a> = type(module.backbone).__name__
        <a id="change">if backbone_type not in [&quotOTEMobileNetV3&quot, &quotOTEEfficientNet&quot, &quotOTEEfficientNetV2&quot]</a>:
            return

        output = OrderedDict()
        <a id="change">if backbone_type == &quotOTEMobileNetV3&quot</a>:
            for k, v in state_dict.items():
                if k.startswith(&quotbackbone&quot):
                    k = k.replace(&quotbackbone.&quot, &quot&quot)
                elif k.startswith(&quothead&quot):
                    k = k.replace(&quothead.&quot, &quot&quot)
                    if &quot3&quot in k:  &#47&#47 MPA uses "classifier.3", while OTE uses "classifier.4". Convert for OTE compatibility.
                        k = k.replace(&quot3&quot, &quot4&quot)
                output[k] = v

        elif backbone_type == &quotOTEEfficientNet&quot:
            for k, v in state_dict.items():
                if k.startswith(&quotbackbone&quot):
                    k = k.replace(&quotbackbone.&quot, &quot&quot)
                elif k.startswith(&quothead&quot):
                    k = k.replace(&quothead&quot, &quotoutput&quot)
                output[k] = v

        elif <a id="change">backbone_type == &quotOTEEfficientNetV2&quot</a>:
            for k, v in state_dict.items():
                if k.startswith(&quotbackbone&quot):
                    k = k.replace(&quotbackbone.&quot, &quot&quot)
                elif k == &quothead.fc.weight&quot:
                    k<a id="change"> = </a>k.replace(&quothead.fc&quot, &quotmodel.classifier&quot)
                    if not module.is_export:
                        v = v.t()
                output[k] = v</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/openvinotoolkit/model_preparation_algorithm/commit/645893988f346dd87d1b1868bf6c58f4b9784cb4#diff-b42ff02ffef42e9ec4f5e721c5585e8fc50ad9c86d48308a1a7e3b1fc20cbeefL55' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 95680759</div><div id='project'> Project Name: openvinotoolkit/model_preparation_algorithm</div><div id='commit'> Commit Name: 645893988f346dd87d1b1868bf6c58f4b9784cb4</div><div id='time'> Time: 2022-04-06</div><div id='author'> Author: songki.choi@intel.com</div><div id='file'> File Name: mpa/modules/models/classifiers/sam_classifier.py</div><div id='m_class'> M Class Name: SAMImageClassifier</div><div id='n_method'> N Class Name: SAMImageClassifier</div><div id='m_method'> M Method Name: state_dict_hook(2)</div><div id='n_method'> N Method Name: state_dict_hook(2)</div><div id='m_parent_class'> M Parent Class: ImageClassifier</div><div id='n_parent_class'> N Parent Class: ImageClassifier</div><div id='m_file'> M File Name: mpa/modules/models/classifiers/sam_classifier.py</div><div id='n_file'> N File Name: mpa/modules/models/classifiers/sam_classifier.py</div><div id='m_start'> M Start Line: 58</div><div id='m_end'> M End Line: 83</div><div id='n_start'> N Start Line: 58</div><div id='n_end'> N End Line: 91</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        self.pos_embedder, self.pos_embed_dim = get_positional_embedder(self.pos_multires, 
                                                                       self.embedder_type == "positional")
        <a id="change">log.info(f"Position Embed Dim: {self.pos_embed_dim}"</a><a id="change">)</a>

    def init_decoder(self):
        Initializes the decoder object.
        </code></pre><h3>After Change</h3><pre><code class='java'>
    def init_embedder(self, embedder_type, frequencies=None, position_input=True):
        Creates positional embedding functions for the position and view direction.
        
        <a id="change">if embedder_type == &quotnone&quot</a>:
            embedder, embed_dim = None, 0
        elif <a id="change">embedder_type == &quotidentity&quot</a>:
            embedder, embed_dim = torch.nn.Identity(), 0
        elif <a id="change">embedder_type == &quotpositional&quot</a>:
            embedder<a id="change">, embed_dim = </a>get_positional_embedder(frequencies=frequencies, position_input=position_input)
        else:
            raise NotImplementedError(f&quotUnsupported embedder type for NeuralSDF: {embedder_type}&quot)
        return embedder, embed_dim</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nvidiagameworks/kaolin-wisp/commit/688dfebfd03fbfa81560f103244bc7e776e47245#diff-3167e0bec8ccf5615ba8eb5a95ba110eaf9653f0e244d09083f37682740e9b65L103' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 95680757</div><div id='project'> Project Name: nvidiagameworks/kaolin-wisp</div><div id='commit'> Commit Name: 688dfebfd03fbfa81560f103244bc7e776e47245</div><div id='time'> Time: 2022-12-20</div><div id='author'> Author: 9556101+orperel@users.noreply.github.com</div><div id='file'> File Name: wisp/models/nefs/neural_sdf.py</div><div id='m_class'> M Class Name: NeuralSDF</div><div id='n_method'> N Class Name: NeuralSDF</div><div id='m_method'> M Method Name: init_embedder(4)</div><div id='n_method'> N Method Name: init_embedder(1)</div><div id='m_parent_class'> M Parent Class: BaseNeuralField</div><div id='n_parent_class'> N Parent Class: BaseNeuralField</div><div id='m_file'> M File Name: wisp/models/nefs/neural_sdf.py</div><div id='n_file'> N File Name: wisp/models/nefs/neural_sdf.py</div><div id='m_start'> M Start Line: 103</div><div id='m_end'> M End Line: 108</div><div id='n_start'> N Start Line: 54</div><div id='n_end'> N End Line: 65</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.view_embedder, self.view_embed_dim = get_positional_embedder(self.view_multires, 
                                                                         self.embedder_type == "positional")
        log.info(f"Position Embed Dim: {self.pos_embed_dim}")
        <a id="change">log.info(f"View Embed Dim: {self.view_embed_dim}"</a><a id="change">)</a>

    def init_decoder(self):
        Initializes the decoder object. 
        </code></pre><h3>After Change</h3><pre><code class='java'>
    def init_embedder(self, embedder_type, frequencies=None):
        Creates positional embedding functions for the position and view direction.
        
        <a id="change">if embedder_type == &quotnone&quot</a>:
            embedder, embed_dim = None, 0
        elif <a id="change">embedder_type == &quotidentity&quot</a>:
            embedder, embed_dim = torch.nn.Identity(), 0
        elif <a id="change">embedder_type == &quotpositional&quot</a>:
            embedder<a id="change">, embed_dim = </a>get_positional_embedder(frequencies=frequencies)
        else:
            raise NotImplementedError(f&quotUnsupported embedder type for NeuralRadianceField: {embedder_type}&quot)
        return embedder, embed_dim</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nvidiagameworks/kaolin-wisp/commit/688dfebfd03fbfa81560f103244bc7e776e47245#diff-6efb23a0a6d659486b19aa87b9baed0582e8e7c05b4f427f15be2bf47c2efcd3L34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 95680761</div><div id='project'> Project Name: nvidiagameworks/kaolin-wisp</div><div id='commit'> Commit Name: 688dfebfd03fbfa81560f103244bc7e776e47245</div><div id='time'> Time: 2022-12-20</div><div id='author'> Author: 9556101+orperel@users.noreply.github.com</div><div id='file'> File Name: wisp/models/nefs/nerf.py</div><div id='m_class'> M Class Name: NeuralRadianceField</div><div id='n_method'> N Class Name: NeuralRadianceField</div><div id='m_method'> M Method Name: init_embedder(3)</div><div id='n_method'> N Method Name: init_embedder(1)</div><div id='m_parent_class'> M Parent Class: BaseNeuralField</div><div id='n_parent_class'> N Parent Class: BaseNeuralField</div><div id='m_file'> M File Name: wisp/models/nefs/nerf.py</div><div id='n_file'> N File Name: wisp/models/nefs/nerf.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 42</div><div id='n_start'> N Start Line: 65</div><div id='n_end'> N End Line: 76</div><BR>