<html><h3>Pattern ID :7477
</h3><img src='24744121.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        if W != self.img_size[1]:
            raise ValueError(f"PatchEmbed module. Input image width ({W}) doesn&quott match model ({self.img_size[1]}).")
        x = self.proj(x)
        if <a id="change">self.flatten</a>:
            x<a id="change"> = x.flatten(2).transpose(1</a>, <a id="change">2</a><a id="change">)</a>  &#47&#47 BCHW -&gt; BNC
        x = self.norm(x)
        return x</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 FIXME look at relaxing size constraints
        assert H == self.img_size[0] and W == self.img_size[1], \
            f"Input image size ({H}*{W}) doesn&quott match model ({self.img_size[0]}*{self.img_size[1]})."
        x = <a id="change">self.proj(x).flatten(2).transpose(1</a>, <a id="change">2</a><a id="change">)</a>  &#47&#47 B Ph*Pw C
        if self.norm is not None:
            x = self.norm(x)
        return x</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/eora-ai/torchok/commit/ab2534f05b48a529d03f8c28af2579245772f4e0#diff-8ea48274a2159a0abc4b0425f2fb246399f29a78d6a46d98cdbda118b48a4195L30' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24744121</div><div id='project'> Project Name: eora-ai/torchok</div><div id='commit'> Commit Name: ab2534f05b48a529d03f8c28af2579245772f4e0</div><div id='time'> Time: 2022-07-11</div><div id='author'> Author: rashit.bayazitov.1995@gmail.com</div><div id='file'> File Name: src/models/modules/blocks/patch_embedding.py</div><div id='m_class'> M Class Name: PatchEmbed</div><div id='n_method'> N Class Name: PatchEmbed</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/models/modules/blocks/patch_embedding.py</div><div id='n_file'> N File Name: src/models/modules/blocks/patch_embedding.py</div><div id='m_start'> M Start Line: 30</div><div id='m_end'> M End Line: 37</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 55</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 prepare input for decoder
        src_flatten = srcs.flatten(2).transpose(1, 2)                                &#47&#47 [Batch, Patches, HiddenDim] 
        pos_embed_flatten = <a id="change">pos_embeds.flatten(2).transpose(1</a>, <a id="change">2</a><a id="change">)</a>                    &#47&#47 [Batch, Patches, HiddenDim] 
        
        bs, _, c = src_flatten.shape
        query_embed, tgt = torch.split(query_embed, c, dim=1)                        &#47&#47 Tgt in contrast to detr not zeros, but learnable</code></pre><h3>After Change</h3><pre><code class='java'>
        assert query_embed is not None

        &#47&#47 prepare input for decoder
        for <a id="change">idx</a> in range(len(srcs)):
            srcs[idx]<a id="change"> = srcs[idx].flatten(2).transpose(1</a>, <a id="change">2</a><a id="change">)</a>
            pos[idx] = pos[idx].flatten(2).transpose(1, 2)
            
        bs, _, c = srcs[0].shape
        query_embed, tgt = torch.split(query_embed, c, dim=1)       &#47&#47 Tgt in contrast to detr not zeros, but learnable</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bwittmann/transoar/commit/b13e8b2db58100e624031db6b1f256e65dd68a87#diff-46296950c0873e06db813f2eb25910c85d79a555ca8fbaddd81bde89454be936L101' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24744120</div><div id='project'> Project Name: bwittmann/transoar</div><div id='commit'> Commit Name: b13e8b2db58100e624031db6b1f256e65dd68a87</div><div id='time'> Time: 2022-05-07</div><div id='author'> Author: bastian.wittmann@tum.de</div><div id='file'> File Name: transoar/models/necks/focused_decoder.py</div><div id='m_class'> M Class Name: FocusedDecoder</div><div id='n_method'> N Class Name: FocusedDecoder</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: transoar/models/necks/focused_decoder.py</div><div id='n_file'> N File Name: transoar/models/necks/focused_decoder.py</div><div id='m_start'> M Start Line: 105</div><div id='m_end'> M End Line: 108</div><div id='n_start'> N Start Line: 105</div><div id='n_end'> N End Line: 109</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        B, C, H, W = x.shape
        assert H == self.img_size[0] and W == self.img_size[1], \
            f"Input image size ({H}*{W}) doesn&quott match model ({self.img_size[0]}*{self.img_size[1]})."
        x = <a id="change">self.proj(x).flatten(2).transpose(1</a>, <a id="change">2</a><a id="change">)</a>
        x = self.norm(x)
        return x
</code></pre><h3>After Change</h3><pre><code class='java'>
        assert H == self.img_size[0] and W == self.img_size[1], \
            f"Input image size ({H}*{W}) doesn&quott match model ({self.img_size[0]}*{self.img_size[1]})."
        x = self.proj(x)
        if <a id="change">self.flatten</a>:
            x<a id="change"> = x.flatten(2).transpose(1</a>, <a id="change">2</a><a id="change">)</a>  &#47&#47 BCHW -&gt; BNC
        x = self.norm(x)
        return x
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/feng-lab/pytorch-image-models/commit/ecc7552c5c5ab1d177705774e8e4efd16939852c#diff-65959474d3816c5eb9737a2e8bfdbdad5fcde39ae3f023ec9756d444af0dfd54L30' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24744123</div><div id='project'> Project Name: feng-lab/pytorch-image-models</div><div id='commit'> Commit Name: ecc7552c5c5ab1d177705774e8e4efd16939852c</div><div id='time'> Time: 2021-05-14</div><div id='author'> Author: rwightman@gmail.com</div><div id='file'> File Name: timm/models/layers/patch_embed.py</div><div id='m_class'> M Class Name: PatchEmbed</div><div id='n_method'> N Class Name: PatchEmbed</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: timm/models/layers/patch_embed.py</div><div id='n_file'> N File Name: timm/models/layers/patch_embed.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 34</div><div id='n_start'> N Start Line: 35</div><div id='n_end'> N End Line: 38</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        assert query_embed is not None

        &#47&#47 prepare input for decoder
        for <a id="change">idx</a> in range(len(srcs)):
            srcs[idx]<a id="change"> = srcs[idx].flatten(2).transpose(1</a>, <a id="change">2</a><a id="change">)</a>
            pos[idx] = pos[idx].flatten(2).transpose(1, 2)
            
        bs, _, c = srcs[0].shape
        query_embed, tgt = torch.split(query_embed, c, dim=1)       &#47&#47 Tgt in contrast to detr not zeros, but learnable</code></pre><h3>After Change</h3><pre><code class='java'>
        assert query_embed is not None

        &#47&#47 prepare input for decoder
        src = <a id="change">src.flatten(2).transpose(1</a>, <a id="change">2</a><a id="change">)</a>
        pos = pos.flatten(2).transpose(1, 2)
            
        bs, _, c = src.shape
        query_embed, tgt = torch.split(query_embed, c, dim=1)       &#47&#47 Tgt in contrast to detr not zeros, but learnable</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bwittmann/transoar/commit/93490790c06b3fe20dfd1eae015b8d79f8fd627a#diff-46296950c0873e06db813f2eb25910c85d79a555ca8fbaddd81bde89454be936L101' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24744126</div><div id='project'> Project Name: bwittmann/transoar</div><div id='commit'> Commit Name: 93490790c06b3fe20dfd1eae015b8d79f8fd627a</div><div id='time'> Time: 2022-05-25</div><div id='author'> Author: bastian.wittmann@tum.de</div><div id='file'> File Name: transoar/models/necks/focused_decoder.py</div><div id='m_class'> M Class Name: FocusedDecoder</div><div id='n_method'> N Class Name: FocusedDecoder</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: transoar/models/necks/focused_decoder.py</div><div id='n_file'> N File Name: transoar/models/necks/focused_decoder.py</div><div id='m_start'> M Start Line: 105</div><div id='m_end'> M End Line: 109</div><div id='n_start'> N Start Line: 55</div><div id='n_end'> N End Line: 58</div><BR>