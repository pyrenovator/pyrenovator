<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                logger.record(&quotbatches_trained&quot, batches_trained)
                logger.dump(step=batches_trained)
                batches_trained += 1
                <a id="change">if </a>(training_batches is not None and batches_trained &gt;= training_batches):
                    logging.info(f"Breaking out of training in epoch {epochs_trained} because max batches "
                                 f"value of {training_batches} has been reached")
                    training_complete<a id="change"> = </a>True
                    break

            assert batches_trained &gt; 0, \
                "went through training loop with no batches---empty dataset?"
            <a id="change">if </a><a id="change">epochs_trained == 0</a>:
                &#47&#47 we infer the size of the dataset from the number of
                &#47&#47 iterations through the loop the first time
                logging.debug(f"Dataset size is {batches_trained}")

            if self.scheduler is not None:
                self.scheduler.step()
            loss_record.append(loss_meter.avg)

            epochs_trained<a id="change"> += </a>1
            <a id="change">if </a><a id="change">(training_epochs is not None and epochs_trained &gt;= training_epochs)</a>:
                training_complete<a id="change"> = </a>True

            should_save_checkpoint = (training_complete or
                                      epochs_trained % self.save_interval == 0)</code></pre><h3>After Change</h3><pre><code class='java'>
                &#47&#47 complicated, but also takes up less memory).
                sub_ds.shuffle(self.shuffle_buffer_size)

        <a id="change">if </a>not self.shuffle_batches:
            <a id="change">assert </a>len(datasets) &lt;= 1, \
                "InterleavedDataset will intrinsically shuffle batches; do " \
                "not use multi-task training if shuffle_batches=False is " \
                f"required (got {len(datasets)} datasets)"</code></pre>