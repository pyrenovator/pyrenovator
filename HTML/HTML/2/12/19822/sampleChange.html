<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    passthrough_kernel = passthrough_faker(args.layer_depth)

    new_checkpoint = copy.deepcopy(checkpoint)
    <a id="change">new_checkpoint[&quotstate_dict&quot]</a>[f&quot{args.layer_name}.output_shift&quot] = torch.Tensor([1.]).to(device)
    new_checkpoint[&quotstate_dict&quot][f&quot{args.layer_name}.weight_bits&quot] = torch.Tensor([8.]).to(device)
    new_checkpoint[&quotstate_dict&quot][f&quot{args.layer_name}.bias_bits&quot] = torch.Tensor([8.]).to(device)
    new_checkpoint[&quotstate_dict&quot][f&quot{args.layer_name}.quantize_activation&quot] = \</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 remove `module.` prefix from the state dictionary keys if model is trained with GPU
    &#47&#47 (see:https://discuss.pytorch.org/t/prefix-parameter-names-in-saved-model-if-trained-by-multi-
    &#47&#47 gpu/494)
    <a id="change">new_state_dict = </a><a id="change">OrderedDict()</a>
    <a id="change">for </a>k, v in new_checkpoint[&quotstate_dict&quot].items()<a id="change">:
        </a>name<a id="change"> = </a><a id="change">k.replace("module."</a>, <a id="change">&quot&quot</a><a id="change">)</a>
        <a id="change">new_state_dict[name] = </a>v

    new_state_dict[f&quot{args.layer_name}.output_shift&quot] = torch.Tensor([1.]).to(device)
    new_state_dict[f&quot{args.layer_name}.weight_bits&quot] = torch.Tensor([8.]).to(device)</code></pre>