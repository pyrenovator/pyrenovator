<html><h3>Pattern ID :14911
</h3><img src='49790321.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            Raises when the &quotmask&quot is not boolean.
        
        if mask is not None:
            <a id="change">if mask.shape != xs.shape</a>:
                <a id="change">raise ValueError("&quotxs&quot and &quotmask&quot must have the same shape."</a><a id="change">)</a>
            <a id="change">if not isinstance(mask, torch.BoolTensor)</a>:
                <a id="change">raise ValueError("&quotmask&quot must be a torch.BoolTensor."</a><a id="change">)</a>
            &#47&#47 we sum the values of xs which are not filtered out by the mask
            numerator = torch.sum(torch.where(~mask, torch.zeros_like(xs), xs), dim=dim, keepdim=keepdim)
            &#47&#47 we count the number of 1 in the mask
            denominator = torch.sum(mask, dim=dim, keepdim=keepdim)</code></pre><h3>After Change</h3><pre><code class='java'>
            Raises when the &quotmask&quot is not boolean.
        
        if mask is not None:
            <a id="change">check_mask(</a>mask, xs<a id="change">)</a>
            &#47&#47 we sum the values of xs which are not filtered out by the mask
            numerator = torch.sum(torch.where(~mask, torch.zeros_like(xs), xs), dim=dim, keepdim=keepdim)
            &#47&#47 we count the number of 1 in the mask
            denominator = torch.sum(mask, dim=dim, keepdim=keepdim)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/bmxitalia/ltntorch/commit/7c5dbd61e5c08467b08908df086ddf1bb345140c#diff-750caba7cb5811e224d2f3f344867f5b1c4695249e360c7ed91af683b1f63435L1256' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 49790321</div><div id='project'> Project Name: bmxitalia/ltntorch</div><div id='commit'> Commit Name: 7c5dbd61e5c08467b08908df086ddf1bb345140c</div><div id='time'> Time: 2023-03-28</div><div id='author'> Author: tommasocarraro96@gmail.com</div><div id='file'> File Name: ltn/fuzzy_ops.py</div><div id='m_class'> M Class Name: AggregMean</div><div id='n_method'> N Class Name: AggregMean</div><div id='m_method'> M Method Name: __call__(5)</div><div id='n_method'> N Method Name: __call__(5)</div><div id='m_parent_class'> M Parent Class: AggregationOperator</div><div id='n_parent_class'> N Parent Class: AggregationOperator</div><div id='m_file'> M File Name: ltn/fuzzy_ops.py</div><div id='n_file'> N File Name: ltn/fuzzy_ops.py</div><div id='m_start'> M Start Line: 1256</div><div id='m_end'> M End Line: 1261</div><div id='n_start'> N Start Line: 1279</div><div id='n_end'> N End Line: 1279</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            Raises when the &quotmask&quot is not boolean.
        
        if mask is not None:
            <a id="change">if mask.shape != xs.shape</a>:
                <a id="change">raise ValueError("&quotxs&quot and &quotmask&quot must have the same shape."</a><a id="change">)</a>
            <a id="change">if not isinstance(mask, torch.BoolTensor)</a>:
                <a id="change">raise ValueError("&quotmask&quot must be a torch.BoolTensor."</a><a id="change">)</a>
            &#47&#47 here, we put 1 where the mask is not satisfied, since 1 is the maximum value for a truth value.
            &#47&#47 this is a way to exclude values from the minimum computation
            xs = torch.where(~mask, 1., xs.double())
        out = torch.amin(xs, dim=dim, keepdim=keepdim)</code></pre><h3>After Change</h3><pre><code class='java'>
            Raises when the &quotmask&quot is not boolean.
        
        if mask is not None:
            <a id="change">check_mask(</a>mask, xs<a id="change">)</a>
            &#47&#47 here, we put 1 where the mask is not satisfied, since 1 is the maximum value for a truth value.
            &#47&#47 this is a way to exclude values from the minimum computation
            xs = torch.where(~mask, 1., xs.double())
        out = torch.amin(xs, dim=dim, keepdim=keepdim)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bmxitalia/ltntorch/commit/7c5dbd61e5c08467b08908df086ddf1bb345140c#diff-750caba7cb5811e224d2f3f344867f5b1c4695249e360c7ed91af683b1f63435L1156' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 49790320</div><div id='project'> Project Name: bmxitalia/ltntorch</div><div id='commit'> Commit Name: 7c5dbd61e5c08467b08908df086ddf1bb345140c</div><div id='time'> Time: 2023-03-28</div><div id='author'> Author: tommasocarraro96@gmail.com</div><div id='file'> File Name: ltn/fuzzy_ops.py</div><div id='m_class'> M Class Name: AggregMin</div><div id='n_method'> N Class Name: AggregMin</div><div id='m_method'> M Method Name: __call__(5)</div><div id='n_method'> N Method Name: __call__(5)</div><div id='m_parent_class'> M Parent Class: AggregationOperator</div><div id='n_parent_class'> N Parent Class: AggregationOperator</div><div id='m_file'> M File Name: ltn/fuzzy_ops.py</div><div id='n_file'> N File Name: ltn/fuzzy_ops.py</div><div id='m_start'> M Start Line: 1187</div><div id='m_end'> M End Line: 1193</div><div id='n_start'> N Start Line: 1213</div><div id='n_end'> N End Line: 1213</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            xs = pi_1(xs)
        xs = torch.pow(1. - xs, p)
        if mask is not None:
            <a id="change">if mask.shape != xs.shape</a>:
                <a id="change">raise ValueError("&quotxs&quot and &quotmask&quot must have the same shape."</a><a id="change">)</a>
            <a id="change">if not isinstance(mask, torch.BoolTensor)</a>:
                <a id="change">raise ValueError("&quotmask&quot must be a torch.BoolTensor."</a><a id="change">)</a>
            &#47&#47 we sum the values of xs which are not filtered out by the mask
            numerator = torch.sum(torch.where(~mask, torch.zeros_like(xs), xs), dim=dim, keepdim=keepdim)
            &#47&#47 we count the number of 1 in the mask
            denominator = torch.sum(mask, dim=dim, keepdim=keepdim)</code></pre><h3>After Change</h3><pre><code class='java'>
            xs = pi_1(xs)
        xs = torch.pow(1. - xs, p)
        if mask is not None:
            <a id="change">check_mask(</a>mask, xs<a id="change">)</a>
            &#47&#47 we sum the values of xs which are not filtered out by the mask
            numerator = torch.sum(torch.where(~mask, torch.zeros_like(xs), xs), dim=dim, keepdim=keepdim)
            &#47&#47 we count the number of 1 in the mask
            denominator = torch.sum(mask, dim=dim, keepdim=keepdim)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bmxitalia/ltntorch/commit/7c5dbd61e5c08467b08908df086ddf1bb345140c#diff-750caba7cb5811e224d2f3f344867f5b1c4695249e360c7ed91af683b1f63435L1447' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 49790319</div><div id='project'> Project Name: bmxitalia/ltntorch</div><div id='commit'> Commit Name: 7c5dbd61e5c08467b08908df086ddf1bb345140c</div><div id='time'> Time: 2023-03-28</div><div id='author'> Author: tommasocarraro96@gmail.com</div><div id='file'> File Name: ltn/fuzzy_ops.py</div><div id='m_class'> M Class Name: AggregPMeanError</div><div id='n_method'> N Class Name: AggregPMeanError</div><div id='m_method'> M Method Name: __call__(7)</div><div id='n_method'> N Method Name: __call__(7)</div><div id='m_parent_class'> M Parent Class: AggregationOperator</div><div id='n_parent_class'> N Parent Class: AggregationOperator</div><div id='m_file'> M File Name: ltn/fuzzy_ops.py</div><div id='n_file'> N File Name: ltn/fuzzy_ops.py</div><div id='m_start'> M Start Line: 1485</div><div id='m_end'> M End Line: 1492</div><div id='n_start'> N Start Line: 1502</div><div id='n_end'> N End Line: 1504</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            xs = pi_0(xs)
        xs = torch.pow(xs, p)
        if mask is not None:
            <a id="change">if mask.shape != xs.shape</a>:
                <a id="change">raise ValueError("&quotxs&quot and &quotmask&quot must have the same shape."</a><a id="change">)</a>
            <a id="change">if not isinstance(mask, torch.BoolTensor)</a>:
                <a id="change">raise ValueError("&quotmask&quot must be a torch.BoolTensor."</a><a id="change">)</a>
            &#47&#47 we sum the values of xs which are not filtered out by the mask
            numerator = torch.sum(torch.where(~mask, torch.zeros_like(xs), xs), dim=dim, keepdim=keepdim)
            &#47&#47 we count the number of 1 in the mask
            denominator = torch.sum(mask, dim=dim, keepdim=keepdim)</code></pre><h3>After Change</h3><pre><code class='java'>
            xs = pi_0(xs)
        xs = torch.pow(xs, p)
        if mask is not None:
            <a id="change">check_mask(</a>mask, xs<a id="change">)</a>
            &#47&#47 we sum the values of xs which are not filtered out by the mask
            numerator = torch.sum(torch.where(~mask, torch.zeros_like(xs), xs), dim=dim, keepdim=keepdim)
            &#47&#47 we count the number of 1 in the mask
            denominator = torch.sum(mask, dim=dim, keepdim=keepdim)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bmxitalia/ltntorch/commit/7c5dbd61e5c08467b08908df086ddf1bb345140c#diff-750caba7cb5811e224d2f3f344867f5b1c4695249e360c7ed91af683b1f63435L1332' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 49790318</div><div id='project'> Project Name: bmxitalia/ltntorch</div><div id='commit'> Commit Name: 7c5dbd61e5c08467b08908df086ddf1bb345140c</div><div id='time'> Time: 2023-03-28</div><div id='author'> Author: tommasocarraro96@gmail.com</div><div id='file'> File Name: ltn/fuzzy_ops.py</div><div id='m_class'> M Class Name: AggregPMean</div><div id='n_method'> N Class Name: AggregPMean</div><div id='m_method'> M Method Name: __call__(7)</div><div id='n_method'> N Method Name: __call__(7)</div><div id='m_parent_class'> M Parent Class: AggregationOperator</div><div id='n_parent_class'> N Parent Class: AggregationOperator</div><div id='m_file'> M File Name: ltn/fuzzy_ops.py</div><div id='n_file'> N File Name: ltn/fuzzy_ops.py</div><div id='m_start'> M Start Line: 1370</div><div id='m_end'> M End Line: 1377</div><div id='n_start'> N Start Line: 1390</div><div id='n_end'> N End Line: 1392</div><BR>