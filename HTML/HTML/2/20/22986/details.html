<html><h3>Pattern ID :22986
</h3><img src='72973343.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        
        Test batch norm fold custom model with randomly initialized kernel, bias and bn params,
        
        <a id="change">if version.parse(tf.version.VERSION) &gt;= version.parse("2.00")</a>:
            inputs = tf.keras.Input(shape=(32, 32, 3,))
            conv = tf.keras.layers.Conv2D(32, (3, 3),
                                             kernel_initializer=tf.random_uniform_initializer(-1, 1),
                                             bias_initializer=&quotrandom_uniform&quot)(inputs)
            bn = tf.keras.layers.BatchNormalization(fused=True,
                                                       beta_initializer=&quotrandom_uniform&quot,
                                                       gamma_initializer=&quotrandom_uniform&quot,
                                                       moving_mean_initializer=&quotrandom_uniform&quot,
                                                       moving_variance_initializer=&quotones&quot)(conv, training=False)
            relu = tf.nn.relu(bn)

            model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=relu)

            np.random.seed(0)
            w_shape<a id="change"> = </a>model._layers[0].input.shape
            numpy_data<a id="change"> = </a>np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
            baseline_output<a id="change"> = </a>model(numpy_data)

            <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>

            output_after_fold<a id="change"> = </a>model(numpy_data)

            self.assertFalse(np.allclose(baseline_output, output_after_fold, atol=0))
            <a id="change">self.assertTrue(</a>np.allclose(baseline_output, output_after_fold, atol=1e-4)<a id="change">)</a>

    def test_bn_fold_with_linear_layer(self):
        
        Custom Model where BN layer is followed by Dense layer</code></pre><h3>After Change</h3><pre><code class='java'>
                                                   moving_variance_initializer=&quotones&quot)(conv, training=False)
        relu = tf.nn.relu(bn)

        model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=relu)

        np.random.seed(0)
        w_shape<a id="change"> = </a>model._layers[0].input.shape
        numpy_data<a id="change"> = </a>np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
        baseline_output<a id="change"> = </a>model(numpy_data)

        <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>

        output_after_fold<a id="change"> = </a>model(numpy_data)

        self.assertFalse(np.allclose(baseline_output, output_after_fold, atol=0))
        <a id="change">self.assertTrue(</a>np.allclose(baseline_output, output_after_fold, atol=1e-4)<a id="change">)</a>

    def test_bn_fold_with_linear_layer(self):
        
        Custom Model where BN layer is followed by Dense layer</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 18</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/quic/aimet/commit/28425277900d8639a7088695987da788dbe9d976#diff-834f2d7622f379defad7d1f6d2194617ddaa1f00a614cd69588c9417b768f881L852' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 72973343</div><div id='project'> Project Name: quic/aimet</div><div id='commit'> Commit Name: 28425277900d8639a7088695987da788dbe9d976</div><div id='time'> Time: 2022-12-22</div><div id='author'> Author: quic_haijunz@quicinc.com</div><div id='file'> File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='m_class'> M Class Name: TestBatchNormFold</div><div id='n_method'> N Class Name: TestBatchNormFold</div><div id='m_method'> M Method Name: test_batch_norm_fold_with_random_data(1)</div><div id='n_method'> N Method Name: test_batch_norm_fold_with_random_data(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='n_file'> N File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='m_start'> M Start Line: 856</div><div id='m_end'> M End Line: 882</div><div id='n_start'> N Start Line: 852</div><div id='n_end'> N End Line: 875</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        Custom Model where BN layer is followed by Dense layer
        :return:
        
        <a id="change">if version.parse(tf.version.VERSION) &gt;= version.parse("2.00")</a>:
            inputs = tf.keras.Input(shape=(1, 1, 4,))
            bn = tf.keras.layers.BatchNormalization(fused=True)(inputs, training=False)
            x = tf.keras.layers.Flatten()(bn)
            dense = tf.keras.layers.Dense(2, activation=tf.nn.relu, name="linear_layer")(x)
            model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=dense)

            &#47&#47 get baseline output
            np.random.seed(0)
            w_shape<a id="change"> = </a>model._layers[0].input.shape
            numpy_data<a id="change"> = </a>np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
            baseline_output<a id="change"> = </a>model(numpy_data)
            weight_before_fold = model._layers[3].kernel.numpy()

            <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>
            after_fold_output<a id="change"> = </a>model(numpy_data)
            weight_after_fold = model._layers[3].kernel.numpy()

            &#47&#47 check that weight got updated
            self.assertFalse(np.allclose(weight_before_fold, weight_after_fold, atol=1e-4))

            &#47&#47 check outputs are close
            <a id="change">self.assertTrue(</a>np.allclose(baseline_output, after_fold_output, atol=1e-4)<a id="change">)</a>

    def test_find_conv_bn_pairs_functional_nested(self):
        
        Test case for finding conv-bn pairs when the inner model has 2 layers connected to the input</code></pre><h3>After Change</h3><pre><code class='java'>
        bn = tf.keras.layers.BatchNormalization(fused=True)(inputs, training=False)
        x = tf.keras.layers.Flatten()(bn)
        dense = tf.keras.layers.Dense(2, activation=tf.nn.relu, name="linear_layer")(x)
        model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=dense)

        &#47&#47 get baseline output
        np.random.seed(0)
        w_shape<a id="change"> = </a>model._layers[0].input.shape
        numpy_data<a id="change"> = </a>np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
        baseline_output<a id="change"> = </a>model(numpy_data)
        weight_before_fold = model._layers[3].kernel.numpy()

        <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>
        after_fold_output<a id="change"> = </a>model(numpy_data)
        weight_after_fold = model._layers[3].kernel.numpy()

        &#47&#47 check that weight got updated
        self.assertFalse(np.allclose(weight_before_fold, weight_after_fold, atol=1e-4))

        &#47&#47 check outputs are close
        <a id="change">self.assertTrue(</a>np.allclose(baseline_output, after_fold_output, atol=1e-4)<a id="change">)</a>

    def test_find_conv_bn_pairs_functional_nested(self):
        
        Test case for finding conv-bn pairs when the inner model has 2 layers connected to the input</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/quic/aimet/commit/28425277900d8639a7088695987da788dbe9d976#diff-834f2d7622f379defad7d1f6d2194617ddaa1f00a614cd69588c9417b768f881L882' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 72973345</div><div id='project'> Project Name: quic/aimet</div><div id='commit'> Commit Name: 28425277900d8639a7088695987da788dbe9d976</div><div id='time'> Time: 2022-12-22</div><div id='author'> Author: quic_haijunz@quicinc.com</div><div id='file'> File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='m_class'> M Class Name: TestBatchNormFold</div><div id='n_method'> N Class Name: TestBatchNormFold</div><div id='m_method'> M Method Name: test_bn_fold_with_linear_layer(1)</div><div id='n_method'> N Method Name: test_bn_fold_with_linear_layer(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='n_file'> N File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='m_start'> M Start Line: 887</div><div id='m_end'> M End Line: 911</div><div id='n_start'> N Start Line: 882</div><div id='n_end'> N End Line: 903</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        Test batch norm fold custom model with randomly initialized kernel, bias and bn params,
        
        <a id="change">if version.parse(tf.version.VERSION) &gt;= version.parse("2.00")</a>:
            inputs = tf.keras.Input(shape=(32, 32, 3,))
            conv = tf.keras.layers.Conv2D(32, (3, 3),
                                             kernel_initializer=tf.random_uniform_initializer(-1, 1),
                                             bias_initializer=&quotrandom_uniform&quot)(inputs)
            bn = tf.keras.layers.BatchNormalization(fused=True,
                                                       beta_initializer=&quotrandom_uniform&quot,
                                                       gamma_initializer=&quotrandom_uniform&quot,
                                                       moving_mean_initializer=&quotrandom_uniform&quot,
                                                       moving_variance_initializer=&quotones&quot)(conv, training=False)
            relu = tf.nn.relu(bn)

            model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=relu)

            np.random.seed(0)
            w_shape<a id="change"> = </a>model._layers[0].input.shape
            numpy_data<a id="change"> = </a>np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
            baseline_output<a id="change"> = </a>model(numpy_data)

            <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>

            output_after_fold<a id="change"> = </a>model(numpy_data)

            self.assertFalse(np.allclose(baseline_output, output_after_fold, atol=0))
            <a id="change">self.assertTrue(</a>np.allclose(baseline_output, output_after_fold, atol=1e-4)<a id="change">)</a>

    def test_bn_fold_with_linear_layer(self):
        
        Custom Model where BN layer is followed by Dense layer</code></pre><h3>After Change</h3><pre><code class='java'>
                                                   moving_variance_initializer=&quotones&quot)(conv, training=False)
        relu = tf.nn.relu(bn)

        model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=relu)

        np.random.seed(0)
        w_shape<a id="change"> = </a>model._layers[0].input.shape
        numpy_data<a id="change"> = </a>np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
        baseline_output<a id="change"> = </a>model(numpy_data)

        <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>

        output_after_fold<a id="change"> = </a>model(numpy_data)

        self.assertFalse(np.allclose(baseline_output, output_after_fold, atol=0))
        <a id="change">self.assertTrue(</a>np.allclose(baseline_output, output_after_fold, atol=1e-4)<a id="change">)</a>

    def test_bn_fold_with_linear_layer(self):
        
        Custom Model where BN layer is followed by Dense layer</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/quic/aimet/commit/28425277900d8639a7088695987da788dbe9d976#diff-834f2d7622f379defad7d1f6d2194617ddaa1f00a614cd69588c9417b768f881L852' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 72973344</div><div id='project'> Project Name: quic/aimet</div><div id='commit'> Commit Name: 28425277900d8639a7088695987da788dbe9d976</div><div id='time'> Time: 2022-12-22</div><div id='author'> Author: quic_haijunz@quicinc.com</div><div id='file'> File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='m_class'> M Class Name: TestBatchNormFold</div><div id='n_method'> N Class Name: TestBatchNormFold</div><div id='m_method'> M Method Name: test_batch_norm_fold_with_random_data(1)</div><div id='n_method'> N Method Name: test_batch_norm_fold_with_random_data(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='n_file'> N File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='m_start'> M Start Line: 856</div><div id='m_end'> M End Line: 882</div><div id='n_start'> N Start Line: 852</div><div id='n_end'> N End Line: 875</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        Test batch norm fold custom model
        
        <a id="change">if version.parse(tf.version.VERSION) &gt;= version.parse("2.00")</a>:
            inputs = tf.keras.Input(shape=(32, 32, 3,))
            conv = tf.keras.layers.Conv2D(32, (3, 3))(inputs)
            bn = tf.keras.layers.BatchNormalization(fused=True)(conv, training=False)
            relu = tf.nn.relu(bn)
            model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=relu)

            np.random.seed(0)
            w_shape<a id="change"> = </a>model._layers[0].input.shape
            numpy_data<a id="change"> = </a>np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)

            baseline_output<a id="change"> = </a>model(numpy_data)

            <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>
            output_after_fold<a id="change"> = </a>model(numpy_data)

            <a id="change">self.assertTrue(</a>np.allclose(baseline_output, output_after_fold, atol=1.e-4)<a id="change">)</a>

    def test_batch_norm_fold_with_random_data(self):
        
        Test batch norm fold custom model with randomly initialized kernel, bias and bn params,</code></pre><h3>After Change</h3><pre><code class='java'>
        conv = tf.keras.layers.Conv2D(32, (3, 3))(inputs)
        bn = tf.keras.layers.BatchNormalization(fused=True)(conv, training=False)
        relu = tf.nn.relu(bn)
        model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=relu)

        np.random.seed(0)
        w_shape<a id="change"> = </a>model._layers[0].input.shape
        numpy_data<a id="change"> = </a>np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)

        baseline_output<a id="change"> = </a>model(numpy_data)

        <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>
        output_after_fold<a id="change"> = </a>model(numpy_data)

        <a id="change">self.assertTrue(</a>np.allclose(baseline_output, output_after_fold, atol=1.e-4)<a id="change">)</a>

    def test_batch_norm_fold_with_random_data(self):
        
        Test batch norm fold custom model with randomly initialized kernel, bias and bn params,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/quic/aimet/commit/28425277900d8639a7088695987da788dbe9d976#diff-834f2d7622f379defad7d1f6d2194617ddaa1f00a614cd69588c9417b768f881L830' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 72973347</div><div id='project'> Project Name: quic/aimet</div><div id='commit'> Commit Name: 28425277900d8639a7088695987da788dbe9d976</div><div id='time'> Time: 2022-12-22</div><div id='author'> Author: quic_haijunz@quicinc.com</div><div id='file'> File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='m_class'> M Class Name: TestBatchNormFold</div><div id='n_method'> N Class Name: TestBatchNormFold</div><div id='m_method'> M Method Name: test_batch_norm_fold(1)</div><div id='n_method'> N Method Name: test_batch_norm_fold(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='n_file'> N File Name: TrainingExtensions/tensorflow/test/python/eager/test_batch_norm_fold_keras.py</div><div id='m_start'> M Start Line: 834</div><div id='m_end'> M End Line: 852</div><div id='n_start'> N Start Line: 831</div><div id='n_end'> N End Line: 846</div><BR>