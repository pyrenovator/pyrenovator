<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        
        Test batch norm fold custom model with randomly initialized kernel, bias and bn params,
        
        <a id="change">if version.parse(tf.version.VERSION) &gt;= version.parse("2.00")</a>:
            inputs = tf.keras.Input(shape=(32, 32, 3,))
            conv = tf.keras.layers.Conv2D(32, (3, 3),
                                             kernel_initializer=tf.random_uniform_initializer(-1, 1),
                                             bias_initializer=&quotrandom_uniform&quot)(inputs)
            bn = tf.keras.layers.BatchNormalization(fused=True,
                                                       beta_initializer=&quotrandom_uniform&quot,
                                                       gamma_initializer=&quotrandom_uniform&quot,
                                                       moving_mean_initializer=&quotrandom_uniform&quot,
                                                       moving_variance_initializer=&quotones&quot)(conv, training=False)
            relu = tf.nn.relu(bn)

            model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=relu)

            np.random.seed(0)
            w_shape<a id="change"> = </a>model._layers[0].input.shape
            numpy_data<a id="change"> = </a>np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
            baseline_output<a id="change"> = </a>model(numpy_data)

            <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>

            output_after_fold<a id="change"> = </a>model(numpy_data)

            self.assertFalse(np.allclose(baseline_output, output_after_fold, atol=0))
            <a id="change">self.assertTrue(</a>np.allclose(baseline_output, output_after_fold, atol=1e-4)<a id="change">)</a>

    def test_bn_fold_with_linear_layer(self):
        
        Custom Model where BN layer is followed by Dense layer</code></pre><h3>After Change</h3><pre><code class='java'>
                                                   moving_variance_initializer=&quotones&quot)(conv, training=False)
        relu = tf.nn.relu(bn)

        model<a id="change"> = </a>tf.keras.Model(inputs=inputs, outputs=relu)

        np.random.seed(0)
        w_shape<a id="change"> = </a>model._layers[0].input.shape
        numpy_data<a id="change"> = </a>np.random.rand(1, w_shape[1], w_shape[2], w_shape[3]).astype(np.float32)
        baseline_output<a id="change"> = </a>model(numpy_data)

        <a id="change">fold_all_batch_norms(</a>model<a id="change">)</a>

        output_after_fold<a id="change"> = </a>model(numpy_data)

        self.assertFalse(np.allclose(baseline_output, output_after_fold, atol=0))
        <a id="change">self.assertTrue(</a>np.allclose(baseline_output, output_after_fold, atol=1e-4)<a id="change">)</a>

    def test_bn_fold_with_linear_layer(self):
        
        Custom Model where BN layer is followed by Dense layer</code></pre>