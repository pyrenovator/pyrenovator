<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    shift = example_clip.shape[2] - 1  &#47&#47 From SE

    &#47&#47 Not very precise because SE block still initializes
    <a id="change">for t</a> in <a id="change">range(1</a>, <a id="change">target.shape[2]</a><a id="change">):
        </a><a id="change">assert </a>torch.allclose(target[:, :, t], outputs[t + shift], atol=5e-2)

    &#47&#47 After temporal_window_size inputs it also produces precise computation
    torch.allclose(target[:, :, 3], outputs[3 + shift], atol=1e-9)</code></pre><h3>After Change</h3><pre><code class='java'>


def test_ResBlock():
    sample = <a id="change">torch.randn(</a>(<a id="change">1</a><a id="change">, 2, 4, 4, 4</a>)<a id="change">)</a>

    &#47&#47 Regular block
    trans = ResBlock(
        dim_in=2,
        dim_out=2,
        temp_kernel_size=3,
        stride=2,
        trans_func=X3DTransform,
        dim_inner=5,
        num_groups=1,
        stride_1x1=False,
        inplace_relu=True,
        eps=1e-5,
        bn_mmt=0.1,
        dilation=1,
        norm_module=torch.nn.BatchNorm3d,
        block_idx=0,
        drop_connect_rate=0.0,
    )

    &#47&#47 Converted block
    cotrans = CoResBlock(
        dim_in=2,
        dim_out=2,
        temp_kernel_size=3,
        stride=2,
        trans_func=CoX3DTransform,
        dim_inner=5,
        num_groups=1,
        stride_1x1=False,
        inplace_relu=True,
        eps=1e-5,
        bn_mmt=0.1,
        dilation=1,
        norm_module=torch.nn.BatchNorm3d,
        block_idx=0,
        drop_connect_rate=0.0,
        temporal_window_size=sample.shape[2],
        temporal_fill="zeros",
        se_scope="clip",
    )
    cotrans.load_state_dict(trans.state_dict(), flatten=True)

    &#47&#47 Training mode has large effect on BatchNorm result - test will fail otherwise
    trans.eval()
    cotrans.eval()

    &#47&#47 Forward through models
    target = trans.forward(sample)

    &#47&#47 forward
    output = cotrans.forward(sample)
    assert torch.allclose(target, output)

    &#47&#47 Broken up
    cotrans.clean_state()
    nothing = cotrans.forward_steps(sample[:, :, :-1], pad_end=False)  &#47&#47 init
    assert isinstance(nothing, TensorPlaceholder)

    lasts<a id="change"> = cotrans.forward_steps(sample[:, :, -1:]</a><a id="change">, pad_end=True)</a>
    assert torch.allclose(lasts, target)


example_clip = torch.normal(mean=torch.zeros(2 * 4 * 4 * 4)).reshape((1, 2, 4, 4, 4))</code></pre>