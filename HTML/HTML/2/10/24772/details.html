<html><h3>Pattern ID :24772
</h3><img src='76626369.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        dnn_blocks=2,
        dnn_neurons=512,
    ):
        blocks<a id="change"> = </a><a id="change">[]</a>
        for block_index in range(cnn_blocks):
            if not using_2d_pooling:
                pooling = Pooling1d(
                    pool_type="max",
                    kernel_size=inter_layer_pooling_size[block_index],
                    pool_axis=2,
                )
            else:
                pooling = Pooling2d(
                    pool_type="max",
                    kernel_size=(
                        inter_layer_pooling_size[block_index],
                        inter_layer_pooling_size[block_index],
                    ),
                    pool_axis=(1, 2),
                )

            blocks.extend(
                [
                    lambda input_shape: Conv2d(
                        input_shape=input_shape,
                        out_channels=cnn_channels[block_index],
                        kernel_size=cnn_kernelsize,
                    ),
                    lambda input_shape: LayerNorm(input_shape),
                    activation(),
                    lambda input_shape: Conv2d(
                        input_shape=input_shape,
                        out_channels=cnn_channels[block_index],
                        kernel_size=cnn_kernelsize,
                    ),
                    lambda input_shape: LayerNorm(input_shape),
                    activation(),
                    &#47&#47 Inter-layer Pooling
                    pooling,
                    Dropout2d(drop_rate=dropout),
                ]
            )

        if time_pooling:
            blocks.append(
                Pooling1d(
                    pool_type="max", kernel_size=time_pooling_size, pool_axis=1,
                )
            )

        if rnn_layers &gt; 0:
            blocks.append(
                lambda input_shape: rnn_class(
                    input_shape=input_shape,
                    hidden_size=rnn_neurons,
                    num_layers=rnn_layers,
                    dropout=dropout,
                    bidirectional=rnn_bidirectional,
                    re_init=rnn_re_init,
                )
            )

        for block_index in range(dnn_blocks):
            <a id="change">blocks.extend(
                </a><a id="change">[
                    </a>lambda input_shape: Linear(
                        input_shape=input_shape,
                        n_neurons=dnn_neurons,
                        bias=True,
                        combine_dims=False,
                    ),
                    lambda input_shape: BatchNorm1d(input_shape),
                    <a id="change">activation()</a>,
                    torch.nn.Dropout(p=dropout)<a id="change"></a>,
                ]<a id="change">
            )</a>

        super().__init__(input_shape, *blocks)
</code></pre><h3>After Change</h3><pre><code class='java'>
                    pool_axis=(1, 2),
                )

            <a id="change">self.append(
                </a>Conv2d<a id="change">,
                out_channels=cnn_channels[block_index],
                kernel_size=cnn_kernelsize,
            )</a>
            self.append(LayerNorm)
            self.append(activation())
            self.append(
                Conv2d,
                out_channels=cnn_channels[block_index],
                kernel_size=cnn_kernelsize,
            )
            self.append(LayerNorm)
            self.append(activation())
            self.append(pooling)
            self.append(Dropout2d(drop_rate=dropout))

        if time_pooling:
            self.append(
                Pooling1d(
                    pool_type="max", kernel_size=time_pooling_size, pool_axis=1,
                )
            )

        if rnn_layers &gt; 0:
            self.append(
                rnn_class,
                hidden_size=rnn_neurons,
                num_layers=rnn_layers,
                dropout=dropout,
                bidirectional=rnn_bidirectional,
                re_init=rnn_re_init,
            )

        for block_index in range(dnn_blocks):
            self.append(Linear, n_neurons=dnn_neurons, bias=True)
            self.append(BatchNorm1d)
            <a id="change">self.append(</a><a id="change">activation())</a>
            <a id="change">self.append(</a>torch.nn.Dropout(p=dropout)<a id="change">)</a>
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/103f6355cf82a6e4b7b52db443400578e70d0ac8#diff-be3f2f248e834db5c50952d25f756f7cd2d846d04cd4770d7f1765501e571672L96' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76626369</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 103f6355cf82a6e4b7b52db443400578e70d0ac8</div><div id='time'> Time: 2020-08-25</div><div id='author'> Author: plantinga.peter@protonmail.com</div><div id='file'> File Name: speechbrain/lobes/models/CRDNN.py</div><div id='m_class'> M Class Name: CRDNN</div><div id='n_method'> N Class Name: CRDNN</div><div id='m_method'> M Method Name: __init__(19)</div><div id='n_method'> N Method Name: __init__(19)</div><div id='m_parent_class'> M Parent Class: Sequential</div><div id='n_parent_class'> N Parent Class: Sequential</div><div id='m_file'> M File Name: speechbrain/lobes/models/CRDNN.py</div><div id='n_file'> N File Name: speechbrain/lobes/models/CRDNN.py</div><div id='m_start'> M Start Line: 96</div><div id='m_end'> M End Line: 170</div><div id='n_start'> N Start Line: 96</div><div id='n_end'> N End Line: 153</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        dnn_neurons=512,
    ):

        blocks<a id="change"> = </a><a id="change">[]</a>

        for block_index in range(cnn_blocks):
            if not using_2d_pooling:
                pooling = sb.nnet.Pooling1d(
                    pool_type="max",
                    kernel_size=inter_layer_pooling_size,
                    pool_axis=2,
                )
            else:
                pooling = sb.nnet.Pooling2d(
                    pool_type="max",
                    kernel_size=(
                        inter_layer_pooling_size,
                        inter_layer_pooling_size,
                    ),
                    pool_axis=(1, 2),
                )

            <a id="change">blocks.extend(
                </a><a id="change">[
                    </a>sb.nnet.Conv2d(
                        out_channels=cnn_channels[block_index],
                        kernel_size=cnn_kernelsize,
                    ),
                    sb.nnet.LayerNorm(),
                    activation(),
                    sb.nnet.Conv2d(
                        out_channels=cnn_channels[block_index],
                        kernel_size=cnn_kernelsize,
                    ),
                    sb.nnet.LayerNorm(),
                    <a id="change">activation()</a>,
                    &#47&#47 Inter-layer Pooling
                    pooling,
                    sb.nnet.Dropout2d(drop_rate=dropout)<a id="change"></a>,
                ]<a id="change">
            )</a>

        if time_pooling:
            blocks.extend(
                [</code></pre><h3>After Change</h3><pre><code class='java'>
                kernel_size=cnn_kernelsize,
            )
            self.append(sb.nnet.LayerNorm)
            <a id="change">self.append(</a><a id="change">activation())</a>
            <a id="change">self.append(</a>pooling<a id="change">)</a>
            <a id="change">self.append(</a>sb.nnet.Dropout2d(drop_rate=dropout)<a id="change">)</a>,

        if time_pooling:
            self.append(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/103f6355cf82a6e4b7b52db443400578e70d0ac8#diff-781631d0e453dd615ed925e5c3478796c46a1540f805103b93fe464578609769L72' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76626353</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 103f6355cf82a6e4b7b52db443400578e70d0ac8</div><div id='time'> Time: 2020-08-25</div><div id='author'> Author: plantinga.peter@protonmail.com</div><div id='file'> File Name: speechbrain/lobes/models/CRDNN_selfatt.py</div><div id='m_class'> M Class Name: CRDNN</div><div id='n_method'> N Class Name: CRDNN</div><div id='m_method'> M Method Name: __init__(25)</div><div id='n_method'> N Method Name: __init__(24)</div><div id='m_parent_class'> M Parent Class: sb.nnet.Sequential</div><div id='n_parent_class'> N Parent Class: sb.nnet.Sequential</div><div id='m_file'> M File Name: speechbrain/lobes/models/CRDNN_selfatt.py</div><div id='n_file'> N File Name: speechbrain/lobes/models/CRDNN_selfatt.py</div><div id='m_start'> M Start Line: 99</div><div id='m_end'> M End Line: 197</div><div id='n_start'> N Start Line: 74</div><div id='n_end'> N End Line: 175</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if residuals is None:
            residuals = [True] * num_blocks

        blocks<a id="change"> = </a><a id="change">[
            </a>DepthwiseSeparableConv1d(conv_channels[0], kernel_size,),
            norm(),
            activation(beta) if isinstance(activation, Swish) else activation()<a id="change"></a>,
        ]

        for i in range(num_blocks):
            channels = int(conv_channels[i] * alpha)
            blocks.append(
                ContextNetBlock(
                    out_channels=channels,
                    kernel_size=kernel_size,
                    num_layers=num_layers,
                    inner_dim=inner_dim,
                    stride=strides[i],
                    beta=beta,
                    dropout=dropout,
                    activation=activation,
                    se_activation=se_activation,
                    norm=norm,
                    residual=residuals[i],
                )
            )

        <a id="change">blocks.extend(
            </a><a id="change">[
                </a>DepthwiseSeparableConv1d(out_channels, kernel_size,),
                norm(),
                activation(beta)
                if isinstance(activation, Swish)
                else <a id="change">activation()</a>,
            ]<a id="change">
        )</a>
        super().__init__(*blocks)


class SEmodule(torch.nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>
        self.append(DepthwiseSeparableConv1d, conv_channels[0], kernel_size)
        self.append(norm)
        if isinstance(activation, Swish):
            <a id="change">self.append(</a>activation(beta)<a id="change">)</a>
        else:
            self.append(activation())

        for i in range(num_blocks):
            channels = int(conv_channels[i] * alpha)
            self.append(
                ContextNetBlock(
                    out_channels=channels,
                    kernel_size=kernel_size,
                    num_layers=num_layers,
                    inner_dim=inner_dim,
                    stride=strides[i],
                    beta=beta,
                    dropout=dropout,
                    activation=activation,
                    se_activation=se_activation,
                    norm=norm,
                    residual=residuals[i],
                )
            )

        self.append(DepthwiseSeparableConv1d, out_channels, kernel_size)
        self.append(norm)
        if isinstance(activation, Swish):
            <a id="change">self.append(</a>activation(beta)<a id="change">)</a>
        else:
            <a id="change">self.append(</a><a id="change">activation())</a>


class SEmodule(torch.nn.Module):
     This class implements the Squeeze-and-excitation module</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/103f6355cf82a6e4b7b52db443400578e70d0ac8#diff-2605bfd61951f73b88c5956447da2864720b295228dc6c740f7d1cb6758cc033L62' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76626368</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 103f6355cf82a6e4b7b52db443400578e70d0ac8</div><div id='time'> Time: 2020-08-25</div><div id='author'> Author: plantinga.peter@protonmail.com</div><div id='file'> File Name: speechbrain/lobes/models/ContextNet.py</div><div id='m_class'> M Class Name: ContextNet</div><div id='n_method'> N Class Name: ContextNet</div><div id='m_method'> M Method Name: __init__(16)</div><div id='n_method'> N Method Name: __init__(15)</div><div id='m_parent_class'> M Parent Class: Sequential</div><div id='n_parent_class'> N Parent Class: Sequential</div><div id='m_file'> M File Name: speechbrain/lobes/models/ContextNet.py</div><div id='n_file'> N File Name: speechbrain/lobes/models/ContextNet.py</div><div id='m_start'> M Start Line: 81</div><div id='m_end'> M End Line: 141</div><div id='n_start'> N Start Line: 64</div><div id='n_end'> N End Line: 124</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        dnn_blocks=2,
        dnn_neurons=512,
    ):
        blocks<a id="change"> = </a><a id="change">[]</a>
        for block_index in range(cnn_blocks):
            if not using_2d_pooling:
                pooling = Pooling1d(
                    pool_type="max",
                    kernel_size=inter_layer_pooling_size[block_index],
                    pool_axis=2,
                )
            else:
                pooling = Pooling2d(
                    pool_type="max",
                    kernel_size=(
                        inter_layer_pooling_size[block_index],
                        inter_layer_pooling_size[block_index],
                    ),
                    pool_axis=(1, 2),
                )

            blocks.extend(
                [
                    lambda input_shape: Conv2d(
                        input_shape=input_shape,
                        out_channels=cnn_channels[block_index],
                        kernel_size=cnn_kernelsize,
                    ),
                    lambda input_shape: LayerNorm(input_shape),
                    activation(),
                    lambda input_shape: Conv2d(
                        input_shape=input_shape,
                        out_channels=cnn_channels[block_index],
                        kernel_size=cnn_kernelsize,
                    ),
                    lambda input_shape: LayerNorm(input_shape),
                    activation(),
                    &#47&#47 Inter-layer Pooling
                    pooling,
                    Dropout2d(drop_rate=dropout),
                ]
            )

        if time_pooling:
            blocks.append(
                Pooling1d(
                    pool_type="max", kernel_size=time_pooling_size, pool_axis=1,
                )
            )

        if rnn_layers &gt; 0:
            blocks.append(
                lambda input_shape: rnn_class(
                    input_shape=input_shape,
                    hidden_size=rnn_neurons,
                    num_layers=rnn_layers,
                    dropout=dropout,
                    bidirectional=rnn_bidirectional,
                    re_init=rnn_re_init,
                )
            )

        for block_index in range(dnn_blocks):
            <a id="change">blocks.extend(
                </a><a id="change">[
                    </a>lambda input_shape: Linear(
                        input_shape=input_shape,
                        n_neurons=dnn_neurons,
                        bias=True,
                        combine_dims=False,
                    ),
                    lambda input_shape: BatchNorm1d(input_shape),
                    <a id="change">activation()</a>,
                    torch.nn.Dropout(p=dropout)<a id="change"></a>,
                ]<a id="change">
            )</a>

        super().__init__(input_shape, *blocks)
</code></pre><h3>After Change</h3><pre><code class='java'>
            )

        if rnn_layers &gt; 0:
            <a id="change">self.append(
                </a>rnn_class<a id="change">,
                hidden_size=rnn_neurons,
                num_layers=rnn_layers,
                dropout=dropout,
                bidirectional=rnn_bidirectional,
                re_init=rnn_re_init,
            )</a>

        for block_index in range(dnn_blocks):
            self.append(Linear, n_neurons=dnn_neurons, bias=True)
            self.append(BatchNorm1d)
            <a id="change">self.append(</a><a id="change">activation())</a>
            <a id="change">self.append(</a>torch.nn.Dropout(p=dropout)<a id="change">)</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/103f6355cf82a6e4b7b52db443400578e70d0ac8#diff-be3f2f248e834db5c50952d25f756f7cd2d846d04cd4770d7f1765501e571672L75' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76626352</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 103f6355cf82a6e4b7b52db443400578e70d0ac8</div><div id='time'> Time: 2020-08-25</div><div id='author'> Author: plantinga.peter@protonmail.com</div><div id='file'> File Name: speechbrain/lobes/models/CRDNN.py</div><div id='m_class'> M Class Name: CRDNN</div><div id='n_method'> N Class Name: CRDNN</div><div id='m_method'> M Method Name: __init__(19)</div><div id='n_method'> N Method Name: __init__(19)</div><div id='m_parent_class'> M Parent Class: Sequential</div><div id='n_parent_class'> N Parent Class: Sequential</div><div id='m_file'> M File Name: speechbrain/lobes/models/CRDNN.py</div><div id='n_file'> N File Name: speechbrain/lobes/models/CRDNN.py</div><div id='m_start'> M Start Line: 96</div><div id='m_end'> M End Line: 170</div><div id='n_start'> N Start Line: 96</div><div id='n_end'> N End Line: 153</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.return_hidden = return_hidden
        self.reshape = False

        dnn_blocks_lst<a id="change"> = </a><a id="change">[]</a>
        for block_index in range(dnn_blocks):
            <a id="change">dnn_blocks_lst.extend(
                </a><a id="change">[
                    </a>lambda input_shape: Linear(
                        input_shape=input_shape,
                        n_neurons=dnn_neurons,
                        bias=True,
                        combine_dims=False,
                    ),
                    lambda input_shape: LayerNorm(input_shape=input_shape),
                    <a id="change">activation()</a>,
                    torch.nn.Dropout(p=dropout)<a id="change"></a>,
                ]<a id="change">
            )</a>

        input_shape = [8, 10, rnn_neurons]
        self.dnn = Sequential(input_shape, *dnn_blocks_lst)
        self.out = Linear(input_size=dnn_neurons, n_neurons=output_neurons)</code></pre><h3>After Change</h3><pre><code class='java'>
        self.return_hidden = return_hidden
        self.reshape = False

        <a id="change">self.dnn</a> = Sequential(input_shape=[8, 10, rnn_neurons])
        for block_index in range(dnn_blocks):
            <a id="change">self.dnn.append(</a>Linear<a id="change">, n_neurons=dnn_neurons, bias=True)</a>
            self.dnn.append(LayerNorm)
            <a id="change">self.dnn.append(</a><a id="change">activation())</a>
            <a id="change">self.dnn.append(</a>torch.nn.Dropout(p=dropout)<a id="change">)</a>

        self.out = Linear(input_size=dnn_neurons, n_neurons=output_neurons)

    def forward(self, x, hx=None):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/103f6355cf82a6e4b7b52db443400578e70d0ac8#diff-0b71168fd1b97ea9a79ae020370807ac9d4050bd29a0c583965f6afb0608964eL59' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76626345</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 103f6355cf82a6e4b7b52db443400578e70d0ac8</div><div id='time'> Time: 2020-08-25</div><div id='author'> Author: plantinga.peter@protonmail.com</div><div id='file'> File Name: speechbrain/lobes/models/RNNLM.py</div><div id='m_class'> M Class Name: RNNLM</div><div id='n_method'> N Class Name: RNNLM</div><div id='m_method'> M Method Name: __init__(12)</div><div id='n_method'> N Method Name: __init__(12)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: speechbrain/lobes/models/RNNLM.py</div><div id='n_file'> N File Name: speechbrain/lobes/models/RNNLM.py</div><div id='m_start'> M Start Line: 89</div><div id='m_end'> M End Line: 106</div><div id='n_start'> N Start Line: 89</div><div id='n_end'> N End Line: 94</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        lin_neurons=512,
        out_neurons=1211,
    ):
        blocks<a id="change"> = </a><a id="change">[]</a>

        blocks.extend([activation(), sb.nnet.BatchNorm1d])

        for block_index in range(lin_blocks):
            <a id="change">blocks.extend(
                </a><a id="change">[
                    </a>lambda input_shape: sb.nnet.Linear(
                        n_neurons=lin_neurons,
                        input_shape=input_shape,
                        bias=True,
                        combine_dims=False,
                    ),
                    <a id="change">activation()</a>,
                    sb.nnet.BatchNorm1d<a id="change"></a>,
                ]<a id="change">
            )</a>

        &#47&#47 Final Softmax classifier
        blocks.extend(
            [</code></pre><h3>After Change</h3><pre><code class='java'>
        self.append(sb.nnet.BatchNorm1d)

        for block_index in range(lin_blocks):
            <a id="change">self.append(</a>sb.nnet.Linear<a id="change">, n_neurons=lin_neurons, bias=True)</a>
            <a id="change">self.append(</a><a id="change">activation())</a>
            <a id="change">self.append(</a>sb.nnet.BatchNorm1d<a id="change">)</a>

        &#47&#47 Final Softmax classifier
        self.append(sb.nnet.Linear, n_neurons=out_neurons, bias=True)
        self.append(sb.nnet.Softmax(apply_log=True))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/103f6355cf82a6e4b7b52db443400578e70d0ac8#diff-33d093973fbe5b45a642ccdc60724a65ae8bf123e3428ae93631b45acc4329ebL111' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76626363</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 103f6355cf82a6e4b7b52db443400578e70d0ac8</div><div id='time'> Time: 2020-08-25</div><div id='author'> Author: plantinga.peter@protonmail.com</div><div id='file'> File Name: speechbrain/lobes/models/Xvector.py</div><div id='m_class'> M Class Name: Classifier</div><div id='n_method'> N Class Name: Classifier</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: sb.nnet.Sequential</div><div id='n_parent_class'> N Parent Class: sb.nnet.Sequential</div><div id='m_file'> M File Name: speechbrain/lobes/models/Xvector.py</div><div id='n_file'> N File Name: speechbrain/lobes/models/Xvector.py</div><div id='m_start'> M Start Line: 119</div><div id='m_end'> M End Line: 147</div><div id='n_start'> N Start Line: 105</div><div id='n_end'> N End Line: 117</div><BR>