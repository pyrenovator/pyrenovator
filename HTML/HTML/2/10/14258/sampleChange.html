<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        model_trainer,
    ):

        <a id="change">try:
            model</a><a id="change">.to(</a>device<a id="change">)</a>
        <a id="change">except </a>Exception as e:
            <a id="change">pass</a>

        if args.scenario == FEDML_CROSS_SILO_SCENARIO_HIERARCHICAL:
            from torch.nn.parallel import DistributedDataParallel as DDP
            from .process_group_manager import ProcessGroupManager

            only_gpu = args.using_gpu
            self.process_group_manager = ProcessGroupManager(
                args.proc_rank_in_silo,
                args.n_proc_in_silo,
                args.pg_master_address,
                args.pg_master_port,
                only_gpu,
            )
            model<a id="change"> = </a><a id="change">DDP(model</a><a id="change">, device_ids=[device] if only_gpu else None)</a>

        if model_trainer is None:
            model_trainer = create_model_trainer(model, args)
        else:</code></pre><h3>After Change</h3><pre><code class='java'>
        model_trainer,
    ):

        <a id="change">ml_engine_adapter.model_to_device(</a>args, <a id="change">model</a>, device<a id="change">)</a>

        if args.scenario == FEDML_CROSS_SILO_SCENARIO_HIERARCHICAL:
            self.process_group_manager<a id="change">, model</a> = ml_engine_adapter.model_ddp(args, model, device)

        if model_trainer is None:
            model_trainer = create_model_trainer(model, args)</code></pre>