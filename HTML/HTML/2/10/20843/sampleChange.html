<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        idx2token = eval_data.idx2token
        
        for b in range(num_batch):
            leak_sample<a id="change">, _, _, _</a> = self.leakgan_forward(fake_sentences, dis, if_sample=True, no_log=False
                                                        , start_letter=self.start_idx, train=False)

            assert leak_sample.shape == (self.batch_size, self.max_length-1)</code></pre><h3>After Change</h3><pre><code class='java'>

        samples = samples[:number_to_gen, :]
        samples = samples.tolist()
        texts = <a id="change">[]</a>
        <a id="change">for </a>sen in samples<a id="change">:
            </a>text<a id="change"> = </a>[]
            for w in sen:
                <a id="change">if w != self.end_idx</a>:
                    text.append(idx2token[w])
                else:
                    <a id="change">break</a>
            <a id="change">texts.append(</a>text<a id="change">)</a>
        &#47&#47 samples = [[idx2token[w] for w in sen] for sen in samples]

        <a id="change">return </a>texts
    
    def adversarial_loss(self, dis):
        with torch.no_grad():</code></pre>