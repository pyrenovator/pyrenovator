<html><h3>Pattern ID :34655
</h3><img src='99562319.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
       local: bool = True):
    if local:
        &#47&#47 Process according to the model used
        input_text<a id="change"> = </a><a id="change">[f"q: {qa[0]} a: {qa[1]}" for qa in prev_qa]</a>
        input_text.append(f"q: {question}")
        input_text.append(f"c: {context}")
        input_text = " ".join(input_text)
        return generate(input_text, model_name=model_name,</code></pre><h3>After Change</h3><pre><code class='java'>
       model_name: str = None, tokenizer_name: str = None,
       local: bool = True):
    if local:
        <a id="change">if isinstance(</a>question, list<a id="change">)</a>:
            &#47&#47 Must have a consistent amount of examples
            assert(len(question) == len(context))
            if len(prev_qa) != 0:
                <a id="change">assert</a>(len(question) == len(prev_qa))
            else:
                prev_qa<a id="change"> = [</a>prev_qa<a id="change"></a>] * len(question)

            &#47&#47 Process according to the model used
            input_text<a id="change"> = </a>[process_item(q, c, p)
                          for q, c, p in zip(question, context, prev_qa)]
        else:
            input_text<a id="change"> = </a>process_item(question, context, prev_qa)

        return generate(input_text, model_name=model_name,
                        tokenizer_name=tokenizer_name, local=local)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/kiri-ai/kiri/commit/7f0b95ef8169196944a99724b719f73413b4f159#diff-efb4ea2eb9bdd78acec50a5426cd4898eb3bec9897114848746eeb91e2ad7a15L10' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 99562319</div><div id='project'> Project Name: kiri-ai/kiri</div><div id='commit'> Commit Name: 7f0b95ef8169196944a99724b719f73413b4f159</div><div id='time'> Time: 2020-12-28</div><div id='author'> Author: ojasaarkristo@gmail.com</div><div id='file'> File Name: kiri/models/qa.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: qa(6)</div><div id='n_method'> N Method Name: qa(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: kiri/models/qa.py</div><div id='n_file'> N File Name: kiri/models/qa.py</div><div id='m_start'> M Start Line: 10</div><div id='m_end'> M End Line: 13</div><div id='n_start'> N Start Line: 18</div><div id='n_end'> N End Line: 32</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                        return_dict=False,
                    )

                    down_block_res_samples<a id="change"> = </a><a id="change">[
                        down_block_res_sample * controlnet_conditioning_scale
                        for down_block_res_sample in down_block_res_samples
                    ]</a>
                    mid_block_res_sample *= controlnet_conditioning_scale

                &#47&#47 predict the noise residual
                noise_pred = self.unet(</code></pre><h3>After Change</h3><pre><code class='java'>
        image = prepare_image(image)

        &#47&#47 condition image(s)
        <a id="change">if isinstance(</a>self.controlnet, ControlNetModel<a id="change">)</a>:
            controlnet_conditioning_image = prepare_controlnet_conditioning_image(
                controlnet_conditioning_image=controlnet_conditioning_image,
                width=width,
                height=height,
                batch_size=batch_size * num_images_per_prompt,
                num_images_per_prompt=num_images_per_prompt,
                device=device,
                dtype=self.controlnet.dtype,
                do_classifier_free_guidance=do_classifier_free_guidance,
            )
        elif isinstance(self.controlnet, MultiControlNetModel):
            controlnet_conditioning_images<a id="change"> = </a><a id="change">[]</a>

            for image_ in controlnet_conditioning_image:
                image_<a id="change"> = </a>prepare_controlnet_conditioning_image(
                    controlnet_conditioning_image=image_,
                    width=width,
                    height=height,
                    batch_size=batch_size * num_images_per_prompt,
                    num_images_per_prompt=num_images_per_prompt,
                    device=device,
                    dtype=self.controlnet.dtype,
                    do_classifier_free_guidance=do_classifier_free_guidance,
                )

                controlnet_conditioning_images.append(image_)

            controlnet_conditioning_image<a id="change"> = </a>controlnet_conditioning_images
        else:
            <a id="change">assert </a>False

        &#47&#47 5. Prepare timesteps
        self.scheduler.set_timesteps(num_inference_steps, device=device)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/1d033a95f62ccf2cdbb31795f69798ff1870241d#diff-27a54da4b44ec996e8b08a60554386b23950f64e56639b90ab8930ccaab67d2aL638' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 99562329</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: 1d033a95f62ccf2cdbb31795f69798ff1870241d</div><div id='time'> Time: 2023-03-30</div><div id='author'> Author: mikegarts@users.noreply.github.com</div><div id='file'> File Name: examples/community/stable_diffusion_controlnet_img2img.py</div><div id='m_class'> M Class Name: StableDiffusionControlNetImg2ImgPipeline</div><div id='n_method'> N Class Name: StableDiffusionControlNetImg2ImgPipeline</div><div id='m_method'> M Method Name: __call__(24)</div><div id='n_method'> N Method Name: __call__(24)</div><div id='m_parent_class'> M Parent Class: DiffusionPipeline</div><div id='n_parent_class'> N Parent Class: DiffusionPipeline</div><div id='m_file'> M File Name: examples/community/stable_diffusion_controlnet_img2img.py</div><div id='n_file'> N File Name: examples/community/stable_diffusion_controlnet_img2img.py</div><div id='m_start'> M Start Line: 662</div><div id='m_end'> M End Line: 872</div><div id='n_start'> N Start Line: 706</div><div id='n_end'> N End Line: 930</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    return_dict=False,
                )

                down_block_res_samples<a id="change"> = </a><a id="change">[
                    down_block_res_sample * controlnet_conditioning_scale
                    for down_block_res_sample in down_block_res_samples
                ]</a>
                mid_block_res_sample *= controlnet_conditioning_scale

                &#47&#47 predict the noise residual
                noise_pred = self.unet(</code></pre><h3>After Change</h3><pre><code class='java'>
        mask_image = prepare_mask_image(mask_image)

        &#47&#47 condition image(s)
        <a id="change">if isinstance(</a>self.controlnet, ControlNetModel<a id="change">)</a>:
            controlnet_conditioning_image = prepare_controlnet_conditioning_image(
                controlnet_conditioning_image=controlnet_conditioning_image,
                width=width,
                height=height,
                batch_size=batch_size * num_images_per_prompt,
                num_images_per_prompt=num_images_per_prompt,
                device=device,
                dtype=self.controlnet.dtype,
                do_classifier_free_guidance=do_classifier_free_guidance,
            )
        elif isinstance(self.controlnet, MultiControlNetModel):
            controlnet_conditioning_images<a id="change"> = []</a>

            for image_ in controlnet_conditioning_image:
                image_<a id="change"> = </a>prepare_controlnet_conditioning_image(
                    controlnet_conditioning_image=image_,
                    width=width,
                    height=height,
                    batch_size=batch_size * num_images_per_prompt,
                    num_images_per_prompt=num_images_per_prompt,
                    device=device,
                    dtype=self.controlnet.dtype,
                    do_classifier_free_guidance=do_classifier_free_guidance,
                )
                controlnet_conditioning_images.append(image_)

            controlnet_conditioning_image<a id="change"> = </a>controlnet_conditioning_images
        else:
            <a id="change">assert </a>False

        masked_image = image * (mask_image &lt; 0.5)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/6290668254f421496c968e39d7de4e07e6bc394d#diff-02430c81697bd4c814e48a05ca1da7358f5bf063727e9e17f33285a049004ba7L776' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 99562321</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: 6290668254f421496c968e39d7de4e07e6bc394d</div><div id='time'> Time: 2023-04-28</div><div id='author'> Author: timegate@kaist.ac.kr</div><div id='file'> File Name: examples/community/stable_diffusion_controlnet_inpaint.py</div><div id='m_class'> M Class Name: StableDiffusionControlNetInpaintPipeline</div><div id='n_method'> N Class Name: StableDiffusionControlNetInpaintPipeline</div><div id='m_method'> M Method Name: __call__(22)</div><div id='n_method'> N Method Name: __call__(22)</div><div id='m_parent_class'> M Parent Class: DiffusionPipeline</div><div id='n_parent_class'> N Parent Class: DiffusionPipeline</div><div id='m_file'> M File Name: examples/community/stable_diffusion_controlnet_inpaint.py</div><div id='n_file'> N File Name: examples/community/stable_diffusion_controlnet_inpaint.py</div><div id='m_start'> M Start Line: 800</div><div id='m_end'> M End Line: 1017</div><div id='n_start'> N Start Line: 844</div><div id='n_end'> N End Line: 1079</div><BR>