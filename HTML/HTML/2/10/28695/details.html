<html><h3>Pattern ID :28695
</h3><img src='84591210.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    states = State(torch.tensor([env.observation_space.sample()]*100))
    actions = Action(torch.tensor([env.action_space.sample()]*99))
    rewards = torch.arange(0, 99, dtype=torch.float)
    <a id="change">replay_buffer.store(states[:-1]</a>, actions, rewards, <a id="change">states[1:]</a><a id="change">)</a>

    &#47&#47 expert buffer
    exp_replay_buffer = ExperienceReplayBuffer(1000, env)
    exp_states = State(torch.tensor([env.observation_space.sample()]*100))</code></pre><h3>After Change</h3><pre><code class='java'>
    states = State(torch.tensor([env.observation_space.sample()]*100))
    actions = Action(torch.tensor([env.action_space.sample()]*99))
    rewards = torch.arange(0, 99, dtype=torch.float)
    samples<a id="change"> = </a><a id="change">Samples(states[:-1]</a>, actions, rewards, <a id="change">states[1:]</a><a id="change">)</a>
    <a id="change">replay_buffer.store(</a>samples<a id="change">)</a>

    &#47&#47 expert buffer
    exp_replay_buffer = ExperienceReplayBuffer(1000, env)
    exp_states = State(torch.tensor([env.observation_space.sample()]*100))</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 12</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/syuntoku14/pytorch-rl-il/commit/f992a34439361f69667ca8d7282db7cbeb65069e#diff-9e597cb9adcbfb94f28af7617cbc10b02b06cdf5c1be1f3021518be0e11e9952L18' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84591210</div><div id='project'> Project Name: syuntoku14/pytorch-rl-il</div><div id='commit'> Commit Name: f992a34439361f69667ca8d7282db7cbeb65069e</div><div id='time'> Time: 2020-05-29</div><div id='author'> Author: syuntoku14@gmail.com</div><div id='file'> File Name: tests/memory/gail_wrapper_test.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: setUp(1)</div><div id='n_method'> N Method Name: setUp(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/memory/gail_wrapper_test.py</div><div id='n_file'> N File Name: tests/memory/gail_wrapper_test.py</div><div id='m_start'> M Start Line: 18</div><div id='m_end'> M End Line: 32</div><div id='n_start'> N Start Line: 19</div><div id='n_end'> N End Line: 35</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    replay_buffer = ExperienceReplayBuffer(1000, env)

    &#47&#47 base buffer
    <a id="change">states</a> = State(torch.tensor([env.observation_space.sample()]*100))
    actions = Action(torch.tensor([env.action_space.sample()]*99))
    rewards = torch.arange(0, 99, dtype=torch.float)
    <a id="change">replay_buffer.store(states[:-1]</a>, actions, rewards, <a id="change">states[1:]</a><a id="change">)</a>

    &#47&#47 expert buffer
    exp_replay_buffer = ExperienceReplayBuffer(1000, env)
    exp_states = State(torch.tensor([env.observation_space.sample()]*100))</code></pre><h3>After Change</h3><pre><code class='java'>
    replay_buffer = ExperienceReplayBuffer(1000, env)

    &#47&#47 base buffer
    <a id="change">states</a> = State(torch.tensor([env.observation_space.sample()]*100))
    actions = Action(torch.tensor([env.action_space.sample()]*99))
    rewards = torch.arange(0, 99, dtype=torch.float)
    samples<a id="change"> = </a><a id="change">Samples(states[:-1]</a>, actions, rewards, <a id="change">states[1:]</a><a id="change">)</a>
    <a id="change">replay_buffer.store(</a>samples<a id="change">)</a>

    &#47&#47 expert buffer
    exp_replay_buffer = ExperienceReplayBuffer(1000, env)
    exp_states = State(torch.tensor([env.observation_space.sample()]*100))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/syuntoku14/pytorch-rl-il/commit/f992a34439361f69667ca8d7282db7cbeb65069e#diff-3ce3474757976c8c84ceb95715fd9efbaca768c858be2cd571548dde341799fbL19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84591199</div><div id='project'> Project Name: syuntoku14/pytorch-rl-il</div><div id='commit'> Commit Name: f992a34439361f69667ca8d7282db7cbeb65069e</div><div id='time'> Time: 2020-05-29</div><div id='author'> Author: syuntoku14@gmail.com</div><div id='file'> File Name: tests/memory/airl_wrapper_test.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: setUp(1)</div><div id='n_method'> N Method Name: setUp(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/memory/airl_wrapper_test.py</div><div id='n_file'> N File Name: tests/memory/airl_wrapper_test.py</div><div id='m_start'> M Start Line: 21</div><div id='m_end'> M End Line: 35</div><div id='n_start'> N Start Line: 22</div><div id='n_end'> N End Line: 38</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 expert buffer
    exp_replay_buffer = ExperienceReplayBuffer(1000, env)
    <a id="change">exp_states</a> = State(torch.tensor([env.observation_space.sample()]*100))
    exp_actions = Action(torch.tensor([env.action_space.sample()]*99))
    exp_rewards = torch.arange(100, 199, dtype=torch.float)
    <a id="change">exp_replay_buffer.store(
        exp_states[:-1]</a>, exp_actions, exp_rewards, <a id="change">exp_states[1:]</a><a id="change">)</a>

    &#47&#47 discriminator
    discriminator_model = fc_discriminator(env)
    discriminator_optimizer = Adam(discriminator_model.parameters())</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 expert buffer
    exp_replay_buffer = ExperienceReplayBuffer(1000, env)
    <a id="change">exp_states</a> = State(torch.tensor([env.observation_space.sample()]*100))
    exp_actions = Action(torch.tensor([env.action_space.sample()]*99))
    exp_rewards = torch.arange(100, 199, dtype=torch.float)
    exp_samples<a id="change"> = </a><a id="change">Samples(
        exp_states[:-1]</a>, exp_actions, exp_rewards, <a id="change">exp_states[1:]</a><a id="change">)</a>
    <a id="change">exp_replay_buffer.store(</a>exp_samples<a id="change">)</a>
    &#47&#47 discriminator
    discriminator_model = fc_discriminator(env)
    discriminator_optimizer = Adam(discriminator_model.parameters())
    discriminator = Discriminator(discriminator_model,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/syuntoku14/pytorch-rl-il/commit/f992a34439361f69667ca8d7282db7cbeb65069e#diff-9e597cb9adcbfb94f28af7617cbc10b02b06cdf5c1be1f3021518be0e11e9952L16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84591212</div><div id='project'> Project Name: syuntoku14/pytorch-rl-il</div><div id='commit'> Commit Name: f992a34439361f69667ca8d7282db7cbeb65069e</div><div id='time'> Time: 2020-05-29</div><div id='author'> Author: syuntoku14@gmail.com</div><div id='file'> File Name: tests/memory/gail_wrapper_test.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: setUp(1)</div><div id='n_method'> N Method Name: setUp(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/memory/gail_wrapper_test.py</div><div id='n_file'> N File Name: tests/memory/gail_wrapper_test.py</div><div id='m_start'> M Start Line: 18</div><div id='m_end'> M End Line: 32</div><div id='n_start'> N Start Line: 19</div><div id='n_end'> N End Line: 35</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    replay_buffer = ExperienceReplayBuffer(1000, env)

    &#47&#47 base buffer
    <a id="change">states</a> = State(torch.tensor([env.observation_space.sample()]*10))
    actions = Action(torch.tensor([env.action_space.sample()]*9))
    rewards = torch.arange(0, 9, dtype=torch.float)
    <a id="change">replay_buffer.store(states[:-1]</a>, actions, rewards, <a id="change">states[1:]</a><a id="change">)</a>

    &#47&#47 expert buffer
    exp_replay_buffer = ExperienceReplayBuffer(1000, env)
    exp_states = State(torch.tensor([env.observation_space.sample()]*10))</code></pre><h3>After Change</h3><pre><code class='java'>
    replay_buffer = ExperienceReplayBuffer(1000, env)

    &#47&#47 base buffer
    <a id="change">states</a> = State(torch.tensor([env.observation_space.sample()]*10))
    actions = Action(torch.tensor([env.action_space.sample()]*9))
    rewards = torch.arange(0, 9, dtype=torch.float)
    samples<a id="change"> = </a><a id="change">Samples(states[:-1]</a>, actions, rewards, <a id="change">states[1:]</a><a id="change">)</a>
    <a id="change">replay_buffer.store(</a>samples<a id="change">)</a>

    &#47&#47 expert buffer
    exp_replay_buffer = ExperienceReplayBuffer(1000, env)
    exp_states = State(torch.tensor([env.observation_space.sample()]*10))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/syuntoku14/pytorch-rl-il/commit/f992a34439361f69667ca8d7282db7cbeb65069e#diff-56036f19574a4b9caf6f7eced4f748f17c79fb8965d211b2282f9d7cbcab5165L14' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84591213</div><div id='project'> Project Name: syuntoku14/pytorch-rl-il</div><div id='commit'> Commit Name: f992a34439361f69667ca8d7282db7cbeb65069e</div><div id='time'> Time: 2020-05-29</div><div id='author'> Author: syuntoku14@gmail.com</div><div id='file'> File Name: tests/memory/sqil_wrapper_test.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: setUp(1)</div><div id='n_method'> N Method Name: setUp(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/memory/sqil_wrapper_test.py</div><div id='n_file'> N File Name: tests/memory/sqil_wrapper_test.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 30</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 33</div><BR>