<html><h3>Pattern ID :41579
</h3><img src='116894967.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        dim_counts = Counter(self.observation_shape)
        spatial_dimension = dim_counts.most_common()[0][0]
        assert dim_counts[spatial_dimension] == 2, "This code assumes a square image, implying at least one dimension size repeated"
        channel_dimension<a id="change"> = </a>dim_counts.most_common()[-1][0]
        assert dim_counts[channel_dimension] == 1, "This code assumes two spatial dimensions and one channels dimension"
        spatial_indicies = np.arange(len(self.observation_shape))[np.array(self.observation_shape) == spatial_dimension]
        channel_index = <a id="change">np.arange(len(self.observation_shape))[np.array(self.observation_shape) == channel_dimension].item()</a>

        new_shape = (channel_dimension, spatial_dimension, spatial_dimension)
        required_permutation = (0, channel_index<a id="change">+</a>1, spatial_indicies[0]+1, spatial_indicies[1]+1) &#47&#47 +1 to account for batch
        self.observation_shape<a id="change"> = </a>new_shape
        self.observation_space = Box(shape=self.observation_shape, low=0, high=255, dtype=np.uint8)
        self.permutation_tuple<a id="change"> = </a>required_permutation

    def _tensorize(self, arr):
        </code></pre><h3>After Change</h3><pre><code class='java'>

    def _make_channels_first(self):
        &#47&#47 Assumes an image in form (C, H, W) or (H, W, C) with H = W != C
        <a id="change">x</a><a id="change">, y, z</a> = self.observation_shape
        if x != y and y == z:
            self.permutation_tuple = None
        else:
            assert x == y and x != z, "Can only handle square images in format (C, H, W) or (H, W, C)"
            self.observation_shape = (<a id="change">z</a><a id="change">, x, y</a>)
            self.observation_space = Box(shape=self.observation_shape, low=0, high=255, dtype=np.uint8)
            self.permutation_tuple = (0, 3, 1, 2)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/d1ad577e009bce6e87e589755c40d71337a0e2cd#diff-11bd63b8ace5530605783f45e027231fff8e98dafa1dbb5675fe0c042e1f07dbL94' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116894967</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: d1ad577e009bce6e87e589755c40d71337a0e2cd</div><div id='time'> Time: 2020-07-27</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: _make_channels_first(1)</div><div id='n_method'> N Method Name: _make_channels_first(1)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: algos/representation_learner.py</div><div id='n_file'> N File Name: algos/representation_learner.py</div><div id='m_start'> M Start Line: 95</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 103</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Assumes a square image

        dim_counts = Counter(self.observation_shape)
        spatial_dimension<a id="change"> = </a>dim_counts.most_common()[0][0]
        assert dim_counts[spatial_dimension] == 2, "This code assumes a square image, implying at least one dimension size repeated"
        channel_dimension<a id="change"> = </a>dim_counts.most_common()[-1][0]
        assert dim_counts[channel_dimension] == 1, "This code assumes two spatial dimensions and one channels dimension"
        spatial_indicies = np.arange(len(self.observation_shape))[np.array(self.observation_shape) == spatial_dimension]
        channel_index = <a id="change">np.arange(len(self.observation_shape))[np.array(self.observation_shape) == channel_dimension].item()</a>

        new_shape = (channel_dimension, spatial_dimension, spatial_dimension)
        required_permutation = (0, channel_index<a id="change">+</a>1, spatial_indicies[0]+1, spatial_indicies[1]+1) &#47&#47 +1 to account for batch
        self.observation_shape = new_shape
        self.observation_space = Box(shape=self.observation_shape, low=0, high=255, dtype=np.uint8)
        self.permutation_tuple<a id="change"> = </a>required_permutation

    def _tensorize(self, arr):
        </code></pre><h3>After Change</h3><pre><code class='java'>

    def _make_channels_first(self):
        &#47&#47 Assumes an image in form (C, H, W) or (H, W, C) with H = W != C
        x<a id="change">, y, z</a> = self.observation_shape
        if x != y and y == z:
            self.permutation_tuple = None
        else:
            assert x == y and x != z, "Can only handle square images in format (C, H, W) or (H, W, C)"
            self.observation_shape = (z<a id="change">, x, y</a>)
            self.observation_space = Box(shape=self.observation_shape, low=0, high=255, dtype=np.uint8)
            self.permutation_tuple = (0, 3, 1, 2)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/f5cbb3623fa01457a4ce34acd05c35f1535ece6c#diff-11bd63b8ace5530605783f45e027231fff8e98dafa1dbb5675fe0c042e1f07dbL92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116894711</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: f5cbb3623fa01457a4ce34acd05c35f1535ece6c</div><div id='time'> Time: 2020-07-27</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: _make_channels_first(1)</div><div id='n_method'> N Method Name: _make_channels_first(1)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: algos/representation_learner.py</div><div id='n_file'> N File Name: algos/representation_learner.py</div><div id='m_start'> M Start Line: 95</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 103</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        dim_counts = Counter(self.observation_shape)
        spatial_dimension = dim_counts.most_common()[0][0]
        assert dim_counts[spatial_dimension] == 2, "This code assumes a square image, implying at least one dimension size repeated"
        channel_dimension<a id="change"> = </a>dim_counts.most_common()[-1][0]
        assert dim_counts[channel_dimension] == 1, "This code assumes two spatial dimensions and one channels dimension"
        spatial_indicies = np.arange(len(self.observation_shape))[np.array(self.observation_shape) == spatial_dimension]
        channel_index = <a id="change">np.arange(len(self.observation_shape))[np.array(self.observation_shape) == channel_dimension].item()</a>

        new_shape = (channel_dimension, spatial_dimension, spatial_dimension)
        required_permutation = (0, channel_index<a id="change">+</a>1, spatial_indicies[0]+1, spatial_indicies[1]+1) &#47&#47 +1 to account for batch
        self.observation_shape<a id="change"> = </a>new_shape
        self.observation_space = Box(shape=self.observation_shape, low=0, high=255, dtype=np.uint8)
        self.permutation_tuple<a id="change"> = </a>required_permutation

    def _tensorize(self, arr):
        </code></pre><h3>After Change</h3><pre><code class='java'>

    def _make_channels_first(self):
        &#47&#47 Assumes an image in form (C, H, W) or (H, W, C) with H = W != C
        x<a id="change">, y, z</a> = self.observation_shape
        if x != y and y == z:
            self.permutation_tuple = None
        else:
            assert x == y and x != z, "Can only handle square images in format (C, H, W) or (H, W, C)"
            self.observation_shape = (z<a id="change">, x, y</a>)
            self.observation_space = Box(shape=self.observation_shape, low=0, high=255, dtype=np.uint8)
            self.permutation_tuple = (0, 3, 1, 2)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/d1ad577e009bce6e87e589755c40d71337a0e2cd#diff-11bd63b8ace5530605783f45e027231fff8e98dafa1dbb5675fe0c042e1f07dbL92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116894966</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: d1ad577e009bce6e87e589755c40d71337a0e2cd</div><div id='time'> Time: 2020-07-27</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: _make_channels_first(1)</div><div id='n_method'> N Method Name: _make_channels_first(1)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: algos/representation_learner.py</div><div id='n_file'> N File Name: algos/representation_learner.py</div><div id='m_start'> M Start Line: 95</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 103</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.pt_model.load_state_dict(torch.load(self.saved_model))

        with torch.no_grad():
            mse_val<a id="change"> = </a>0
            preds = []
            true = []
            for batch_x, batch_y_h, batch_y in data_test_loader:
                batch_x = batch_x.cuda()
                batch_y = batch_y.cuda()
                batch_y_h<a id="change"> = </a>batch_y_h.cuda()
                output = self.pt_model(batch_x, batch_y_h)
                preds.append(output.detach().cpu().numpy())
                true.append(batch_y.detach().cpu().numpy())
                mse_val<a id="change"> += </a><a id="change">self.loss(output, batch_y).item()*</a>batch_x.shape[0]
        preds = np.concatenate(preds)
        true = np.concatenate(true)
</code></pre><h3>After Change</h3><pre><code class='java'>

        with torch.no_grad():
            if self.use_predicted_output:
                true<a id="change">, preds, mse_val</a> = self.eval_epoch_v2(data_test_loader)
            else:
                true<a id="change">, preds, mse_val</a> = self.eval_epoch_v1(data_test_loader)
        preds = np.concatenate(preds)
        true = np.concatenate(true)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/atrcheema/ai4water/commit/8de50cb7db0720c5c4a8fa624572c8f798f1199e#diff-e702bbc842f956175d0f2a6dbc5c9339777ea9e2621652e021e90bce1c230817L144' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116894710</div><div id='project'> Project Name: atrcheema/ai4water</div><div id='commit'> Commit Name: 8de50cb7db0720c5c4a8fa624572c8f798f1199e</div><div id='time'> Time: 2020-08-16</div><div id='author'> Author: ather_abbas786@yahoo.com</div><div id='file'> File Name: models/pytorch_models.py</div><div id='m_class'> M Class Name: HARHNModel</div><div id='n_method'> N Class Name: HARHNModel</div><div id='m_method'> M Method Name: predict(4)</div><div id='n_method'> N Method Name: predict(4)</div><div id='m_parent_class'> M Parent Class: Model</div><div id='n_parent_class'> N Parent Class: Model</div><div id='m_file'> M File Name: models/pytorch_models.py</div><div id='n_file'> N File Name: models/pytorch_models.py</div><div id='m_start'> M Start Line: 154</div><div id='m_end'> M End Line: 171</div><div id='n_start'> N Start Line: 211</div><div id='n_end'> N End Line: 221</div><BR>