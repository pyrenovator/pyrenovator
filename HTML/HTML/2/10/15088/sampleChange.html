<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        else:
            seq_mask = None

        <a id="change">return </a>att_feats<a id="change">, seq, att_masks, seq_mask</a>

    def _forward(self, fc_feats, att_feats, seq, att_masks=None, labels=None):
        att_feats, seq, att_masks, seq_mask = self._prepare_feature_forward(att_feats, att_masks, seq, labels)
        out = self.model(att_feats, seq, att_masks, seq_mask, memory_matrix=self.memory_matrix, labels = labels)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Memory querying and responding for visual features

        &#47&#47dummy_memory_matrix = self.memory_matrix.unsqueeze(0).expand(att_feats.size(0), self.memory_matrix.size(0), self.memory_matrix.size(1))
        max_num_protype = max((<a id="change">labels[:,-1]</a>*3 + labels[:,:-1].sum(-1))) * self.num_prototype
        query_matrix = self.memory_matrix.new_zeros(att_feats.size(0), max_num_protype, self.memory_matrix.shape[-1])
        cmn_masks = self.memory_matrix.new_zeros(query_matrix.shape[0], att_feats.size(1), max_num_protype)
        for i in range(att_feats.size(0)):
            cur_query_matrix = []
            &#47&#47print(labels[i])
            for j in range(len(labels[i])):
                if labels[i, j] == 1:
                    if j != len(labels[i])-1:
                        cur_query_matrix.extend(self.memory_matrix[j*self.num_prototype:(j+1)*self.num_prototype, :])
                    else:
                        cur_query_matrix.extend(self.memory_matrix[j * self.num_prototype:, :])

            cur_query_matrix = torch.stack(cur_query_matrix, 0)
            &#47&#47print(&quot111&quot,query_matrix[i, :cur_query_matrix.shape[0], :].shape, cur_query_matrix.shape)
            <a id="change">query_matrix</a>[i, :cur_query_matrix.shape[0], :] = cur_query_matrix
            cmn_masks[i, :, :cur_query_matrix.shape[0]]<a id="change"> = </a>1

        responses<a id="change"> = </a>self.cmn(att_feats, query_matrix, query_matrix, cmn_masks)
        &#47&#47embeddings = embeddings + responses
        att_feats = att_feats + responses

        &quot&quot&quot

        dummy_memory_matrix = torch.stack([self.memory_matrix[labels[i]==1,:] for i in range(att_feats.size(0))])


        &#47&#47dummy_memory_matrix = torch.stack([torch.cat([self.memory_matrix, self.global_memory], 0) for index in idxs])
        responses = self.cmn(att_feats, dummy_memory_matrix, dummy_memory_matrix)

        att_feats = att_feats + responses
        &quot&quot&quot
        &#47&#47 Memory querying and responding for visual features

        att_masks = att_masks.unsqueeze(-2)
        if seq is not None:
            seq = seq[:, :-1]
            seq_mask = (seq.data &gt; 0)
            seq_mask[:, 0] += True

            seq_mask = seq_mask.unsqueeze(-2)
            seq_mask = seq_mask & subsequent_mask(seq.size(-1)).to(seq_mask)
        else:
            seq_mask = None

        <a id="change">return </a>att_feats<a id="change">, seq, att_masks, seq_mask, query_matrix, cmn_masks[:,0,:]</a>

    def _forward(self, fc_feats, att_feats, seq, att_masks=None, labels=None):
        att_feats, seq, att_masks, seq_mask, query_matrix, cmn_masks = \
            self._prepare_feature_forward(att_feats, att_masks, seq, labels)</code></pre>