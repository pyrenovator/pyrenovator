<html><h3>Pattern ID :40665
</h3><img src='114957626.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        assert dim_counts[spatial_dimension] == 2, "This code assumes a square image, implying at least one dimension size repeated"
        channel_dimension = dim_counts.most_common()[-1][0]
        assert dim_counts[channel_dimension] == 1, "This code assumes two spatial dimensions and one channels dimension"
        spatial_indicies<a id="change"> = </a>np.arange(len(self.observation_shape))[<a id="change">np.array(</a>self.observation_shape<a id="change">)</a> == spatial_dimension]
        channel_index<a id="change"> = </a>np.arange(len(self.observation_shape))[<a id="change">np.array(</a>self.observation_shape<a id="change">)</a> == channel_dimension].item()

        new_shape = (channel_dimension, spatial_dimension, spatial_dimension)
        required_permutation = (0, channel_index+1, spatial_indicies[0]+1, spatial_indicies[1]+1) &#47&#47 +1 to account for batch</code></pre><h3>After Change</h3><pre><code class='java'>
    def _make_channels_first(self):
        &#47&#47 Assumes an image in form (C, H, W) or (H, W, C) with H = W != C
        x, y, z = self.observation_shape
        <a id="change">if x != y</a><a id="change"> and y == z</a>:
            self.permutation_tuple<a id="change"> = </a>None
        else:
            assert x == y and x != z, "Can only handle square images in format (C, H, W) or (H, W, C)"
            self.observation_shape = (z, x, y)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/f5cbb3623fa01457a4ce34acd05c35f1535ece6c#diff-11bd63b8ace5530605783f45e027231fff8e98dafa1dbb5675fe0c042e1f07dbL94' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 114957626</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: f5cbb3623fa01457a4ce34acd05c35f1535ece6c</div><div id='time'> Time: 2020-07-27</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: _make_channels_first(1)</div><div id='n_method'> N Method Name: _make_channels_first(1)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: algos/representation_learner.py</div><div id='n_file'> N File Name: algos/representation_learner.py</div><div id='m_start'> M Start Line: 95</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 103</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        assert dim_counts[spatial_dimension] == 2, "This code assumes a square image, implying at least one dimension size repeated"
        channel_dimension = dim_counts.most_common()[-1][0]
        assert dim_counts[channel_dimension] == 1, "This code assumes two spatial dimensions and one channels dimension"
        spatial_indicies<a id="change"> = </a>np.arange(len(self.observation_shape))[<a id="change">np.array(</a>self.observation_shape<a id="change">)</a> == spatial_dimension]
        channel_index<a id="change"> = </a>np.arange(len(self.observation_shape))[<a id="change">np.array(</a>self.observation_shape<a id="change">)</a> == channel_dimension].item()

        new_shape = (channel_dimension, spatial_dimension, spatial_dimension)
        required_permutation = (0, channel_index+1, spatial_indicies[0]+1, spatial_indicies[1]+1) &#47&#47 +1 to account for batch</code></pre><h3>After Change</h3><pre><code class='java'>
    def _make_channels_first(self):
        &#47&#47 Assumes an image in form (C, H, W) or (H, W, C) with H = W != C
        x, y, z = self.observation_shape
        <a id="change">if </a><a id="change">x != y and y == z</a>:
            self.permutation_tuple<a id="change"> = </a>None
        else:
            assert x == y and x != z, "Can only handle square images in format (C, H, W) or (H, W, C)"
            self.observation_shape = (z, x, y)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/f5cbb3623fa01457a4ce34acd05c35f1535ece6c#diff-11bd63b8ace5530605783f45e027231fff8e98dafa1dbb5675fe0c042e1f07dbL92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 114957593</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: f5cbb3623fa01457a4ce34acd05c35f1535ece6c</div><div id='time'> Time: 2020-07-27</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: _make_channels_first(1)</div><div id='n_method'> N Method Name: _make_channels_first(1)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: algos/representation_learner.py</div><div id='n_file'> N File Name: algos/representation_learner.py</div><div id='m_start'> M Start Line: 95</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 103</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    if n_lags &gt; 0:
        series = df.loc[:, &quoty_scaled&quot].values
        lags<a id="change"> = </a><a id="change">np.array(</a>[series[i: i + n_lags] for i in range(n_samples)]<a id="change">)</a>
        inputs["lags"] = lags
        if np.isnan(lags).any():
            raise ValueError(&quotInput lags contain NaN values in y.&quot)

    if season_config is not None:
        seasonalities = seasonal_features_from_dates(df[&quotds&quot], season_config)
        for name, features in seasonalities.items():
            if n_lags == 0:
                seasonalities[name] = np.expand_dims(features, axis=1)
            else:
                &#47&#47 stride into num_forecast at dim=1 for each sample, just like we did with time
                seasonalities[name] = _stride_time_features_for_forecasts(features)
        inputs["seasonalities"] = seasonalities

    if predict_mode:
        &#47&#47 targets = np.empty((time.shape[0], 1))
        targets = np.empty_like(time)
    else:
        series = df.loc[:, &quoty_scaled&quot].values
        targets = [series[i + n_lags: i + n_lags + n_forecasts] for i in range(n_samples)]
        targets<a id="change"> = </a><a id="change">np.array(</a>targets<a id="change">)</a>

    if verbose:
        print("Tabularized inputs shapes:")
        for key, value in inputs.items():</code></pre><h3>After Change</h3><pre><code class='java'>
        inputs["lags"] = _stride_lagged_features(df_col_name=&quoty_scaled&quot)
        if np.isnan(inputs["lags"]).any(): raise ValueError(&quotInput lags contain NaN values in y.&quot)

    <a id="change">if covar_config is not None</a><a id="change"> and n_lags &gt; 0</a>:
        covariates = OrderedDict({})
        for covar in covar_config:
            if covar in df.columns:
                covariates[covar]<a id="change"> = </a>_stride_lagged_features(df_col_name=covar)
                if np.isnan(covariates[covar]).any(): raise ValueError(&quotInput lags contain NaN values in &quot, covar)
        inputs[&quotcovariates&quot] = covariates
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ourownstory/neural_prophet/commit/ae0ba720f438f8a50ffd5e397e3cde56a91a157b#diff-19e8b8bb76c45be0b19f9651c6c08d9e4641f5f993cdbaa581338cc45aff7516L86' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 114957598</div><div id='project'> Project Name: ourownstory/neural_prophet</div><div id='commit'> Commit Name: ae0ba720f438f8a50ffd5e397e3cde56a91a157b</div><div id='time'> Time: 2020-06-22</div><div id='author'> Author: oskar.triebe@merantix.com</div><div id='file'> File Name: neuralprophet/time_dataset.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: tabularize_univariate_datetime(7)</div><div id='n_method'> N Method Name: tabularize_univariate_datetime(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: neuralprophet/time_dataset.py</div><div id='n_file'> N File Name: neuralprophet/time_dataset.py</div><div id='m_start'> M Start Line: 116</div><div id='m_end'> M End Line: 163</div><div id='n_start'> N Start Line: 93</div><div id='n_end'> N End Line: 177</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        assert dim_counts[spatial_dimension] == 2, "This code assumes a square image, implying at least one dimension size repeated"
        channel_dimension = dim_counts.most_common()[-1][0]
        assert dim_counts[channel_dimension] == 1, "This code assumes two spatial dimensions and one channels dimension"
        spatial_indicies<a id="change"> = </a>np.arange(len(self.observation_shape))[<a id="change">np.array(</a>self.observation_shape<a id="change">)</a> == spatial_dimension]
        channel_index<a id="change"> = </a>np.arange(len(self.observation_shape))[<a id="change">np.array(</a>self.observation_shape<a id="change">)</a> == channel_dimension].item()

        new_shape = (channel_dimension, spatial_dimension, spatial_dimension)
        required_permutation = (0, channel_index+1, spatial_indicies[0]+1, spatial_indicies[1]+1) &#47&#47 +1 to account for batch</code></pre><h3>After Change</h3><pre><code class='java'>
    def _make_channels_first(self):
        &#47&#47 Assumes an image in form (C, H, W) or (H, W, C) with H = W != C
        x, y, z = self.observation_shape
        <a id="change">if </a><a id="change">x != y and y == z</a>:
            self.permutation_tuple<a id="change"> = </a>None
        else:
            assert x == y and x != z, "Can only handle square images in format (C, H, W) or (H, W, C)"
            self.observation_shape = (z, x, y)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/d1ad577e009bce6e87e589755c40d71337a0e2cd#diff-11bd63b8ace5530605783f45e027231fff8e98dafa1dbb5675fe0c042e1f07dbL92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 114957584</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: d1ad577e009bce6e87e589755c40d71337a0e2cd</div><div id='time'> Time: 2020-07-27</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: _make_channels_first(1)</div><div id='n_method'> N Method Name: _make_channels_first(1)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: algos/representation_learner.py</div><div id='n_file'> N File Name: algos/representation_learner.py</div><div id='m_start'> M Start Line: 95</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 103</div><BR>