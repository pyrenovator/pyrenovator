<html><h3>Pattern ID :5320
</h3><img src='19019746.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        D, N = normed_x.shape

        dx = 1.0 / N * inv_var * (N * dxhat - dxhat.sum(dim = 1, keepdim = True) - normed_x * <a id="change">(dxhat * normed_x).sum(dim = 1, keepdim = True)</a>)

        dx = dx.view(*shape)
        return dx, dgamma, dbeta, None</code></pre><h3>After Change</h3><pre><code class='java'>
        BLOCK_SIZE = triton.next_power_of_2(n_cols)
        num_warps = calc_num_warps(BLOCK_SIZE)

        dx<a id="change"> = </a><a id="change">torch.empty_like(</a>dy<a id="change">)</a>

        <a id="change">layernorm_kernel_backward[(n_rows,)](
            </a>dx,
            dxhat,
            normed_x,
            <a id="change">scaled_x</a>,
            inv_var,
            dx.stride(0),
            dxhat.stride(0),
            normed_x.stride(0),
            <a id="change">scaled_x.stride(0</a><a id="change">)</a>,
            <a id="change">inv_var.stride(0</a><a id="change">)</a>,
            n_cols<a id="change">,
            num_warps = num_warps,
            BLOCK_SIZE = BLOCK_SIZE,
        )</a>

        dx = dx.view(*shape)
        return dx, dgamma, dbeta, None
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/triton-transformer/commit/e36192a043d5297a45c7355fac59f94ba9e1688b#diff-efb464e8953d3171bdd3355d448443781f005f551f7281446030316b4157bb28L386' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19019746</div><div id='project'> Project Name: lucidrains/triton-transformer</div><div id='commit'> Commit Name: e36192a043d5297a45c7355fac59f94ba9e1688b</div><div id='time'> Time: 2021-09-22</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: triton_transformer/triton_transformer.py</div><div id='m_class'> M Class Name: _layernorm</div><div id='n_method'> N Class Name: _layernorm</div><div id='m_method'> M Method Name: backward(3)</div><div id='n_method'> N Method Name: backward(3)</div><div id='m_parent_class'> M Parent Class: autograd.Function</div><div id='n_parent_class'> N Parent Class: autograd.Function</div><div id='m_file'> M File Name: triton_transformer/triton_transformer.py</div><div id='n_file'> N File Name: triton_transformer/triton_transformer.py</div><div id='m_start'> M Start Line: 386</div><div id='m_end'> M End Line: 390</div><div id='n_start'> N Start Line: 410</div><div id='n_end'> N End Line: 439</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        D, N = normed_x.shape

        dx = 1.0 / N * inv_var * (N * dxhat - dxhat.sum(dim = 1, keepdim = True) - normed_x * <a id="change">(dxhat * normed_x).sum(dim = 1, keepdim = True)</a>)

        dx = dx.view(*shape)
        return dx, dgamma, dbeta, None</code></pre><h3>After Change</h3><pre><code class='java'>
        BLOCK_SIZE = triton.next_power_of_2(n_cols)
        num_warps = calc_num_warps(BLOCK_SIZE)

        dx<a id="change"> = </a><a id="change">torch.empty_like(</a>dy<a id="change">)</a>

        <a id="change">layernorm_kernel_backward[(n_rows,)](
            </a>dx,
            dxhat,
            normed_x,
            scaled_x,
            inv_var,
            dx.stride(0),
            dxhat.stride(0),
            normed_x.stride(0),
            <a id="change">scaled_x.stride(0</a><a id="change">)</a>,
            <a id="change">inv_var.stride(0</a><a id="change">)</a>,
            n_cols<a id="change">,
            num_warps = num_warps,
            BLOCK_SIZE = BLOCK_SIZE,
        )</a>

        dx = dx.view(*shape)
        return dx, dgamma, dbeta, None
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/triton-transformer/commit/e36192a043d5297a45c7355fac59f94ba9e1688b#diff-efb464e8953d3171bdd3355d448443781f005f551f7281446030316b4157bb28L376' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19019747</div><div id='project'> Project Name: lucidrains/triton-transformer</div><div id='commit'> Commit Name: e36192a043d5297a45c7355fac59f94ba9e1688b</div><div id='time'> Time: 2021-09-22</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: triton_transformer/triton_transformer.py</div><div id='m_class'> M Class Name: _layernorm</div><div id='n_method'> N Class Name: _layernorm</div><div id='m_method'> M Method Name: backward(3)</div><div id='n_method'> N Method Name: backward(3)</div><div id='m_parent_class'> M Parent Class: autograd.Function</div><div id='n_parent_class'> N Parent Class: autograd.Function</div><div id='m_file'> M File Name: triton_transformer/triton_transformer.py</div><div id='n_file'> N File Name: triton_transformer/triton_transformer.py</div><div id='m_start'> M Start Line: 386</div><div id='m_end'> M End Line: 390</div><div id='n_start'> N Start Line: 410</div><div id='n_end'> N End Line: 439</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        dim = grad_probs.shape[-1]
        grad_probs = grad_probs.view(-1, dim)

        dxhat = probs<a id="change"> * </a>grad_probs
        dx = dxhat - (probs * <a id="change">dxhat.sum(dim = -1, keepdim = True)</a>)

        return dx.view(*shape)
</code></pre><h3>After Change</h3><pre><code class='java'>
        shape = grad_probs.shape
        probs, = ctx.saved_tensors

        <a id="change">grad_probs</a> = grad_probs.view(-1, grad_probs.shape[-1])
        n_rows, n_cols = grad_probs.shape

        BLOCK_SIZE = triton.next_power_of_2(n_cols)
        num_warps = calc_num_warps(BLOCK_SIZE)

        dx<a id="change"> = </a><a id="change">torch.empty_like(</a>probs<a id="change">)</a>

        <a id="change">softmax_kernel_backward[(n_rows,)](
            </a>dx,
            probs,
            grad_probs,
            <a id="change">grad_probs.stride(0</a><a id="change">)</a>,
            <a id="change">probs.stride(0</a><a id="change">)</a>,
            dx.stride(0),
            n_cols<a id="change">,
            num_warps = num_warps,
            BLOCK_SIZE = BLOCK_SIZE
        )</a>

        return dx.view(*shape)

triton_softmax = _softmax.apply</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/triton-transformer/commit/b8ee8315f462e97c4b50edfdbf59127b44fc396a#diff-efb464e8953d3171bdd3355d448443781f005f551f7281446030316b4157bb28L188' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19019744</div><div id='project'> Project Name: lucidrains/triton-transformer</div><div id='commit'> Commit Name: b8ee8315f462e97c4b50edfdbf59127b44fc396a</div><div id='time'> Time: 2021-09-22</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: triton_transformer/triton_transformer.py</div><div id='m_class'> M Class Name: _softmax</div><div id='n_method'> N Class Name: _softmax</div><div id='m_method'> M Method Name: backward(3)</div><div id='n_method'> N Method Name: backward(3)</div><div id='m_parent_class'> M Parent Class: autograd.Function</div><div id='n_parent_class'> N Parent Class: autograd.Function</div><div id='m_file'> M File Name: triton_transformer/triton_transformer.py</div><div id='n_file'> N File Name: triton_transformer/triton_transformer.py</div><div id='m_start'> M Start Line: 192</div><div id='m_end'> M End Line: 196</div><div id='n_start'> N Start Line: 217</div><div id='n_end'> N End Line: 235</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        scaled_x, gamma, normed = ctx.saved_tensors

        dbeta = dy.sum(dim = 0)
        dgamma = <a id="change">(dy * normed).sum(dim = 0)</a>
        dxhat = dy * gamma

        n_rows, n_cols = dy.shape
</code></pre><h3>After Change</h3><pre><code class='java'>
        gamma_beta_num_warps = 2

        dbeta = torch.empty_like(gamma)
        dgamma<a id="change"> = </a><a id="change">torch.empty_like(</a>gamma<a id="change">)</a>

        <a id="change">layernorm_gamma_beta_kernel_backward[(triton.cdiv(n_cols, GAMMA_BETA_BLOCK_SIZE),)](
            </a>dbeta,
            dgamma,
            normed,
            dy,
            <a id="change">normed.stride(0</a><a id="change">)</a>,
            <a id="change">dy.stride(0</a><a id="change">)</a>,
            n_rows,
            n_cols<a id="change">,
            num_warps = gamma_beta_num_warps,
            BLOCK_SIZE = GAMMA_BETA_BLOCK_SIZE
        )</a>

        dxhat = dy * gamma
        dx = torch.empty_like(dy)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/triton-transformer/commit/f6f13ca481cab024e606c36b0dee89d0b33e497f#diff-efb464e8953d3171bdd3355d448443781f005f551f7281446030316b4157bb28L576' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19019734</div><div id='project'> Project Name: lucidrains/triton-transformer</div><div id='commit'> Commit Name: f6f13ca481cab024e606c36b0dee89d0b33e497f</div><div id='time'> Time: 2021-09-28</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: triton_transformer/triton_transformer.py</div><div id='m_class'> M Class Name: _layernorm</div><div id='n_method'> N Class Name: _layernorm</div><div id='m_method'> M Method Name: backward(3)</div><div id='n_method'> N Method Name: backward(3)</div><div id='m_parent_class'> M Parent Class: autograd.Function</div><div id='n_parent_class'> N Parent Class: autograd.Function</div><div id='m_file'> M File Name: triton_transformer/triton_transformer.py</div><div id='n_file'> N File Name: triton_transformer/triton_transformer.py</div><div id='m_start'> M Start Line: 581</div><div id='m_end'> M End Line: 594</div><div id='n_start'> N Start Line: 622</div><div id='n_end'> N End Line: 648</div><BR>