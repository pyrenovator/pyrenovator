<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        if small_parameter(param_name, grad):  &#47&#47 Do adam update for small parameters
            grad = adam(inner_ctx, grad, step)
        else:  &#47&#47 Do shampoo-sm3 update for large parameters
            grad = <a id="change">shampoo(inner_ctx</a>, <a id="change">param_name</a>, <a id="change">grad</a>, step<a id="change">)</a> * <a id="change">sm3(inner_ctx</a>, <a id="change">param_name</a>, <a id="change">grad</a><a id="change">)</a>
            grad = ema(inner_ctx, grad, step, 1 - ctx.optimizer.momentum_beta, "momentum", heavyball=True)
            ctx.parameters[param_name] = (1 + ctx.optimizer.weight_decay * parameter_lr) * ctx.parameters[param_name]
        ctx.parameters[param_name] = grad * parameter_lr + ctx.parameters[param_name]
</code></pre><h3>After Change</h3><pre><code class='java'>
    ctx = ctx.add_to_prefix("optimizer")
    lr = -get_current_lr(ctx, step)

    for <a id="change">param_name</a>, grad in grads.items():
        if "optimizer" in param_name:
            continue
        inner_ctx = ctx.add_to_prefix(param_name, count=False)
        parameter_lr = lr * ctx.parameter_variance.get(param_name, 1)
        grad = grad.astype(ctx.model.storage_dtype)
        grad = adaptive_gradient_clipping(ctx, param_name, grad)

        if small_parameter(param_name, grad):  &#47&#47 Do adam update for small parameters
            grad = adam(inner_ctx, grad, step)
        else:  &#47&#47 Do shampoo-sm3 update for large parameters
            grad = graft(<a id="change">sm3(inner_ctx</a>, <a id="change">param_name</a>, <a id="change">grad</a><a id="change">)</a>, <a id="change">shampoo(inner_ctx</a>, <a id="change">param_name</a>, <a id="change">grad</a>, step<a id="change">)</a>)
            grad = ema(inner_ctx, grad, step, 1 - ctx.optimizer.momentum_beta, "momentum", heavyball=True)
            ctx.parameters[param_name] = (1 + ctx.optimizer.weight_decay * parameter_lr) * ctx.parameters[param_name]
        ctx.parameters[param_name] = grad * parameter_lr + ctx.parameters[param_name]</code></pre>