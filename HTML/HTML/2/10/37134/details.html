<html><h3>Pattern ID :37134
</h3><img src='107046117.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            process_id, gpu_util_map[process_id][0], socket.gethostname(), gpu_util_map[process_id][1]))
        assert i == worker_number

        device = <a id="change">torch.device(</a><a id="change">"cuda:"</a><a id="change"> + </a><a id="change">str(gpu_util_map[process_id][1]</a><a id="change">) if torch.cuda.is_available()</a><a id="change"> else </a>"cpu"<a id="change">)</a>
        logging.info(device)
        return device

</code></pre><h3>After Change</h3><pre><code class='java'>
            process_id, gpu_util_map[process_id][0], socket.gethostname(), gpu_util_map[process_id][1]))
        assert i == worker_number

        device = <a id="change">ml_engine_adapter.get_device(</a>args<a id="change">, using_gpu=True, device_id=gpu_util_map[process_id][1])</a>
        logging.info(device)
        return device

</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/fedml-ai/fedml/commit/3d60b170496e1805a4aba26413fd05e8b0df7873#diff-7207d857a0793fea08ebed0d6038c577374126db3466d94313bff6c467d48addL50' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 107046117</div><div id='project'> Project Name: fedml-ai/fedml</div><div id='commit'> Commit Name: 3d60b170496e1805a4aba26413fd05e8b0df7873</div><div id='time'> Time: 2022-08-22</div><div id='author'> Author: alexliang.kh@gmail.com</div><div id='file'> File Name: python/fedml/device/gpu_mapping_mpi.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mapping_processes_to_gpu_device_from_gpu_util_parse(4)</div><div id='n_method'> N Method Name: mapping_processes_to_gpu_device_from_gpu_util_parse(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: python/fedml/device/gpu_mapping_mpi.py</div><div id='n_file'> N File Name: python/fedml/device/gpu_mapping_mpi.py</div><div id='m_start'> M Start Line: 58</div><div id='m_end'> M End Line: 85</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 79</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for host, gpus_util_map_host in gpu_util.items():
            for gpu_j, num_process_on_gpu in enumerate(gpus_util_map_host):
                for _ in range(num_process_on_gpu):
                    <a id="change">gpu_util_map[i]</a> = (host, gpu_j)
                    i += 1
        logging.info("Process %d running on host: %s,gethostname: %s, gpu: %d ..." % (
            process_id, gpu_util_map[process_id][0], socket.gethostname(), gpu_util_map[process_id][1]))
        assert i == worker_number

        device = <a id="change">torch.device(</a><a id="change">"cuda:"</a><a id="change"> + </a><a id="change">str(gpu_util_map[process_id][1]</a><a id="change">) if torch.cuda.is_available()</a><a id="change"> else </a>"cpu"<a id="change">)</a>
        logging.info(device)
        return device

</code></pre><h3>After Change</h3><pre><code class='java'>
            process_id, gpu_util_map[process_id][0], socket.gethostname(), gpu_util_map[process_id][1]))
        assert i == worker_number

        device = <a id="change">ml_engine_adapter.get_device(</a>args<a id="change">, using_gpu=True, device_id=gpu_util_map[process_id][1])</a>
        logging.info(device)
        return device

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/fedml-ai/fedml/commit/afc98fd2861fa1938bd6cc40cd37b00b3298a302#diff-7207d857a0793fea08ebed0d6038c577374126db3466d94313bff6c467d48addL56' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 107046119</div><div id='project'> Project Name: fedml-ai/fedml</div><div id='commit'> Commit Name: afc98fd2861fa1938bd6cc40cd37b00b3298a302</div><div id='time'> Time: 2022-08-18</div><div id='author'> Author: alex.gpt.llm@gmail.com</div><div id='file'> File Name: python/fedml/device/gpu_mapping_mpi.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mapping_processes_to_gpu_device_from_gpu_util_parse(4)</div><div id='n_method'> N Method Name: mapping_processes_to_gpu_device_from_gpu_util_parse(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: python/fedml/device/gpu_mapping_mpi.py</div><div id='n_file'> N File Name: python/fedml/device/gpu_mapping_mpi.py</div><div id='m_start'> M Start Line: 58</div><div id='m_end'> M End Line: 85</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 79</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for host, gpus_util_map_host in gpu_util.items():
            for gpu_j, num_process_on_gpu in enumerate(gpus_util_map_host):
                for _ in range(num_process_on_gpu):
                    <a id="change">gpu_util_map[i]</a> = (host, gpu_j)
                    i += 1
        logging.info("Process %d running on host: %s,gethostname: %s, gpu: %d ..." % (
            process_id, gpu_util_map[process_id][0], socket.gethostname(), gpu_util_map[process_id][1]))
        assert i == worker_number

        device = <a id="change">torch.device(</a><a id="change">"cuda:"</a><a id="change"> + </a><a id="change">str(gpu_util_map[process_id][1]</a><a id="change">) if torch.cuda.is_available()</a><a id="change"> else </a>"cpu"<a id="change">)</a>
        logging.info(device)
        return device

</code></pre><h3>After Change</h3><pre><code class='java'>
            process_id, gpu_util_map[process_id][0], socket.gethostname(), gpu_util_map[process_id][1]))
        assert i == worker_number

        device = <a id="change">ml_engine_adapter.get_device(</a>args<a id="change">, using_gpu=True, device_id=gpu_util_map[process_id][1])</a>
        logging.info(device)
        return device

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/fedml-ai/fedml/commit/ab18c789ec8aa3f8153b41291e1dd23a493c29d8#diff-7207d857a0793fea08ebed0d6038c577374126db3466d94313bff6c467d48addL56' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 107046121</div><div id='project'> Project Name: fedml-ai/fedml</div><div id='commit'> Commit Name: ab18c789ec8aa3f8153b41291e1dd23a493c29d8</div><div id='time'> Time: 2022-08-22</div><div id='author'> Author: alex.gpt.llm@gmail.com</div><div id='file'> File Name: python/fedml/device/gpu_mapping_mpi.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mapping_processes_to_gpu_device_from_gpu_util_parse(4)</div><div id='n_method'> N Method Name: mapping_processes_to_gpu_device_from_gpu_util_parse(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: python/fedml/device/gpu_mapping_mpi.py</div><div id='n_file'> N File Name: python/fedml/device/gpu_mapping_mpi.py</div><div id='m_start'> M Start Line: 58</div><div id='m_end'> M End Line: 85</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 79</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for host, gpus_util_map_host in gpu_util.items():
            for gpu_j, num_process_on_gpu in enumerate(gpus_util_map_host):
                for _ in range(num_process_on_gpu):
                    <a id="change">gpu_util_map[i]</a> = (host, gpu_j)
                    i += 1
        logging.info("Process %d running on host: %s,gethostname: %s, gpu: %d ..." % (
            process_id, gpu_util_map[process_id][0], socket.gethostname(), gpu_util_map[process_id][1]))
        assert i == worker_number

        device = <a id="change">torch.device(</a><a id="change">"cuda:"</a><a id="change"> + </a><a id="change">str(gpu_util_map[process_id][1]</a><a id="change">) if torch.cuda.is_available()</a><a id="change"> else </a>"cpu"<a id="change">)</a>
        logging.info(device)
        return device

</code></pre><h3>After Change</h3><pre><code class='java'>
            process_id, gpu_util_map[process_id][0], socket.gethostname(), gpu_util_map[process_id][1]))
        assert i == worker_number

        device = <a id="change">ml_engine_adapter.get_device(</a>args<a id="change">, using_gpu=True, device_id=gpu_util_map[process_id][1])</a>
        logging.info(device)
        return device

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/fedml-ai/fedml/commit/a9b931c8515a89953dd3576679651c590f11f687#diff-7207d857a0793fea08ebed0d6038c577374126db3466d94313bff6c467d48addL56' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 107046123</div><div id='project'> Project Name: fedml-ai/fedml</div><div id='commit'> Commit Name: a9b931c8515a89953dd3576679651c590f11f687</div><div id='time'> Time: 2022-08-18</div><div id='author'> Author: alexliang.kh@gmail.com</div><div id='file'> File Name: python/fedml/device/gpu_mapping_mpi.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mapping_processes_to_gpu_device_from_gpu_util_parse(4)</div><div id='n_method'> N Method Name: mapping_processes_to_gpu_device_from_gpu_util_parse(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: python/fedml/device/gpu_mapping_mpi.py</div><div id='n_file'> N File Name: python/fedml/device/gpu_mapping_mpi.py</div><div id='m_start'> M Start Line: 58</div><div id='m_end'> M End Line: 85</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 79</div><BR>