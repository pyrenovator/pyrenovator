<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)

        results = {}
        <a id="change">for label</a> in labels<a id="change">:
            </a>hypothesis = f"This example is {label}."
            features<a id="change"> = </a>tokenizer.encode(input_text, hypothesis, return_tensors="pt",
                                        truncation_strategy="only_first")
            logits<a id="change"> = </a>model(features)[0]
            entail_contradiction_logits<a id="change"> = </a>logits[:, [0, 2]]
            probs = entail_contradiction_logits.softmax(dim=1)
            prob_label_is_true<a id="change"> = </a>probs[:, 1]
            results[label] = prob_label_is_true.item()

        return results</code></pre><h3>After Change</h3><pre><code class='java'>
            else:
                tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)

        <a id="change">if </a><a id="change">isinstance(</a>input_text, list<a id="change">)</a>:
            &#47&#47 Must have a consistent amount of examples
            assert(len(input_text) == len(labels))
            &#47&#47 TODO: implement proper batching
            results_list<a id="change"> = </a>[]
            for text, labels in zip(input_text, labels):
                results<a id="change"> = </a>{}
                for label in labels:
                    results[label] = calculate_probability(text, label)
</code></pre>