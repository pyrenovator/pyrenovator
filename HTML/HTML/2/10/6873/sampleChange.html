<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.encoding = AminoAcidWordEmbedding(embedding_dim=self.embedding_dim)

        &#47&#47 Convolutional Layers
        <a id="change">for </a>i, <a id="change">kernel</a> in <a id="change">enumerate(</a>self.kernel_sizes<a id="change">):
            </a>conv_layer<a id="change"> = </a><a id="change">nn.Conv1d(in_channels=self.embedding_dim,
                                   out_channels=self.n_filters,
                                   kernel_size=kernel)</a>
            &#47&#47 Initialize Convolution Layers for SELU activation
            conv_layer.weight.data.normal_(
                0.0, np.sqrt(1. / np.prod(conv_layer.kernel_size)))
            <a id="change">conv_layer.bias.data.fill_(0.01</a><a id="change">)</a>
            <a id="change">self.add_module(f&quotconv{i + 1}&quot</a>, conv_layer<a id="change">)</a>
            &#47&#47 No batch-normalization here

        self.activation1 = nn.SELU()
        self.activation2 = nn.SELU()</code></pre><h3>After Change</h3><pre><code class='java'>
    

    def __init__(self, model_dict, device=&quotcpu&quot):
        <a id="change">super().__init__(</a>model_dict<a id="change">,
                         device=device,
                         embedding=&quotword_embedding&quot,  &#47&#47 Change 1
                         embedding_dim=10,
                         activation=&quotselu&quot,  &#47&#47 Change 2
                         )</a>

    def forward(self, x):
         Forward a batch of sequences through network.
</code></pre>