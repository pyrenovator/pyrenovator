<html><h3>Pattern ID :1343
</h3><img src='6497763.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Since we can evaluate all of z in parallel, estimation will be fast.
        st = self.net(x)
        s, t = st.split(self.dim, dim=1)
        z<a id="change"> = </a>x<a id="change"> * </a>torch.exp(s) + t
        &#47&#47 Reverse order, so if we stack MAFs, correct things happen.
        z = z.flip(dims=(1,)) if self.parity else z
        log_det<a id="change"> = </a>torch.sum(s, dim=1)
        <a id="change">return </a>z<a id="change">, log_det</a>

    def inverse(self, z):
        &#47&#47 we have to decode the x one at a time, sequentially
        x = torch.zeros_like(z)</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, z):
        &#47&#47 we have to decode the x one at a time, sequentially
        x = torch.zeros_like(z)
        log_det<a id="change"> = </a>torch.zeros(<a id="change">z.size(0</a><a id="change">)</a>)
        z = z.flip(dims=(1,)) if self.parity else z
        for i in range(self.dim):
            st = self.net(x.clone())  &#47&#47 clone to avoid in-place op errors if using IAF
            s, t = st.split(self.dim, dim=1)
            x[:, i] = (z[:, i] - t[:, i]) * torch.exp(-s[:, i])
            log_det += -s[:, i]
        <a id="change">return </a>x<a id="change">, log_det</a>


class IAF(MAF):
    Reverses the flow of MAF, giving an Inverse Autoregressive Flow (IAF)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/janosh/torch-mnf/commit/89ce9b3eb1de8e735e68602768c84ad28cbdd251#diff-9cf596a23e82fecb1f0de25f5c6da1317126d0764ce1287b505ed3b9dcc9ed01L33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6497763</div><div id='project'> Project Name: janosh/torch-mnf</div><div id='commit'> Commit Name: 89ce9b3eb1de8e735e68602768c84ad28cbdd251</div><div id='time'> Time: 2020-08-23</div><div id='author'> Author: janosh.riebesell@gmail.com</div><div id='file'> File Name: torch_mnf/flows/maf.py</div><div id='m_class'> M Class Name: MAF</div><div id='n_method'> N Class Name: MAF</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: torch_mnf/flows/maf.py</div><div id='n_file'> N File Name: torch_mnf/flows/maf.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 39</div><div id='n_start'> N Start Line: 43</div><div id='n_end'> N End Line: 51</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        Preconditioning for KFAC SUA.
        mod = group[&quotmod&quot]
        state = self.state[mod]
        gb<a id="change">: Optional[torch.Tensor] = </a>None

        kfe_x = state[&quotkfe_x&quot]
        kfe_gy = state[&quotkfe_gy&quot]
        m2 = state[&quotm2&quot]
        g<a id="change"> = </a>weight_grad
        s = g.shape

        bs = self.state[mod][&quotx&quot].size(0)

        if bias_grad is not None:
            gb = bias_grad.view(-1, 1, 1, 1).expand(-1, -1, s[2], s[3])
            g = torch.cat([g, gb], dim=1)

        g_kfe = self._to_kfe_sua(g, kfe_x, kfe_gy)
        m2.mul_(self.alpha).add_((1. - self.alpha) * bs, g_kfe ** 2)
        g_nat_kfe = g_kfe / (m2 + self.eps)
        g_nat = self._to_kfe_sua(g_nat_kfe, kfe_x.t(), kfe_gy.t())
        if bias_grad is not None:
            gb = g_nat[:, -1, s[2] // 2, s[3] // 2]
            &#47&#47 bias.grad.data = gb
            g_nat = g_nat[:, :-1]
        &#47&#47 weight.grad.data = g_nat

        <a id="change">return </a>g_nat.contiguous()<a id="change">, gb.contiguous()</a>

    def _precond_intra_sua(self, group: dict[str, Union[LayerType, Iterable[torch.Tensor]]], weight_grad: torch.Tensor, bias_grad: Optional[torch.Tensor],
                           ) -&gt; tuple[torch.Tensor, Optional[torch.Tensor]]:
        Preconditioning for KFAC SUA.</code></pre><h3>After Change</h3><pre><code class='java'>
            gb = gb[None, :, None, None].repeat(1, 1, s[2], s[3])    &#47&#47 (out, 1, kh, kw)
            g = torch.cat([g, gb], dim=1)    &#47&#47 (out, in + 1, kh, kw)

        N = <a id="change">state.x.size(0</a><a id="change">)</a>
        g_kfe = self.to_kfe_sua(g, state.kfe_x, state.kfe_gy)  &#47&#47 (out, in + 1, kh, kw)
        m2 = self.alpha<a id="change"> * </a>state.m2 + (1 - self.alpha) * N * (g_kfe.square())  &#47&#47 (out, in + 1, kh, kw)
        g_nat_kfe = g_kfe / (m2 + self.eps)  &#47&#47 (out, in + 1, kh, kw)
        g = self.to_kfe_sua(g_nat_kfe, state.kfe_x.t(), state.kfe_gy.t())  &#47&#47 (out, in + 1, kh, kw)

        if gb is not None:
            gb = g[:, -1, s[2] // 2, s[3] // 2].contiguous()  &#47&#47 (out)
            g = g[:, :-1]  &#47&#47 (out, in, kh, kw)
        g<a id="change"> = </a>g.contiguous()
        <a id="change">return </a>g<a id="change">, gb</a>

    def _precond_intra_sua(self, mod: nn.Conv2d, weight_grad: torch.Tensor,
                           bias_grad: Optional[torch.Tensor]
                           ) -&gt; tuple[torch.Tensor, Optional[torch.Tensor]]:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ain-soph/trojanzoo/commit/6c7dbc51bfacdfb1fbe957a3544f7f6d1ae55bb4#diff-60d04c6f7847bd8fc01137e7634942a75744d0f87d0cab4a7f63e78dd3f54c2bL167' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6497769</div><div id='project'> Project Name: ain-soph/trojanzoo</div><div id='commit'> Commit Name: 6c7dbc51bfacdfb1fbe957a3544f7f6d1ae55bb4</div><div id='time'> Time: 2021-09-24</div><div id='author'> Author: ain-soph@live.com</div><div id='file'> File Name: trojanzoo/utils/fim/ekfac.py</div><div id='m_class'> M Class Name: EKFAC</div><div id='n_method'> N Class Name: EKFAC</div><div id='m_method'> M Method Name: _precond_sua_ra(4)</div><div id='n_method'> N Method Name: _precond_sua_ra(4)</div><div id='m_parent_class'> M Parent Class: BaseKFAC</div><div id='n_parent_class'> N Parent Class: Optimizer</div><div id='m_file'> M File Name: trojanzoo/utils/fim/ekfac.py</div><div id='n_file'> N File Name: trojanzoo/utils/fim/ekfac.py</div><div id='m_start'> M Start Line: 167</div><div id='m_end'> M End Line: 196</div><div id='n_start'> N Start Line: 86</div><div id='n_end'> N End Line: 106</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        &#47&#47 TODO: loop if window_size is greater than 2 (for cycle loss)
        bsz, encoder_dim, n_points = keypoint_desc.size()
        batch_size<a id="change"> = </a>int(bsz<a id="change"> / </a>self.window_size)
        _, _, height, width = desc_dense.size()

        src_desc = keypoint_desc[::self.window_size]  &#47&#47 B x C x N
        src_desc = F.normalize(src_desc, dim=1)

        tgt_desc_dense<a id="change"> = </a>desc_dense[1::self.window_size]  &#47&#47 B x C x H x W
        tgt_desc_unrolled = F.normalize(tgt_desc_dense.view(batch_size, encoder_dim, -1), dim=1)  &#47&#47 B x C x HW

        match_vals = torch.matmul(src_desc.transpose(2, 1), tgt_desc_unrolled)  &#47&#47 B x N x HW
        soft_match_vals = F.softmax(match_vals / self.softmax_temp, dim=2)  &#47&#47 B x N x HW

        v_coord, u_coord = torch.meshgrid([torch.arange(0, height), torch.arange(0, width)])
        v_coord = v_coord.reshape(height * width).float()  &#47&#47 HW
        u_coord = u_coord.reshape(height * width).float()
        coords = torch.stack((u_coord, v_coord), dim=1)  &#47&#47 HW x 2
        tgt_coords_dense = coords.unsqueeze(0).expand(batch_size, height * width, 2).to(self.gpuid)  &#47&#47 B x HW x 2

        pseudo_coords = torch.matmul(tgt_coords_dense.transpose(2, 1),
                                     soft_match_vals.transpose(2, 1)).transpose(2, 1)  &#47&#47 BxNx2

        &#47&#47 GET SCORES for pseudo point locations
        pseudo_norm = normalize_coords(pseudo_coords, height, width).unsqueeze(1)          &#47&#47 B x 1 x N x 2
        tgt_scores_dense = scores_dense[1::self.window_size]
        pseudo_scores = F.grid_sample(tgt_scores_dense, pseudo_norm, mode=&quotbilinear&quot)           &#47&#47 B x 1 x 1 x N
        pseudo_scores = pseudo_scores.reshape(batch_size, 1, n_points)                          &#47&#47 B x 1 x N
        &#47&#47 GET DESCRIPTORS for pseudo point locations
        pseudo_desc = F.grid_sample(tgt_desc_dense, pseudo_norm, mode=&quotbilinear&quot)               &#47&#47 B x C x 1 x N
        pseudo_desc = pseudo_desc.reshape(batch_size, encoder_dim, n_points)                    &#47&#47 B x C x N

        desc_match_score = torch.sum(src_desc * pseudo_desc, dim=1, keepdim=True) / float(encoder_dim)  &#47&#47 Bx1xN
        src_scores = keypoint_scores[::self.window_size]
        if self.score_comp:
            match_weights = 0.5 * (desc_match_score + 1) * src_scores * pseudo_scores
        else:
            match_weights = pseudo_scores

        <a id="change">return </a>pseudo_coords<a id="change">, match_weights</a>

def normalize_coords(coords_2D, width, height):
    Normalizes coords_2D (B x N x 2) to be within [-1, 1] 
    batch_size = coords_2D.size(0)</code></pre><h3>After Change</h3><pre><code class='java'>

        src_desc = keypoint_desc[kp_inds]  &#47&#47 B x C x N
        src_desc = F.normalize(src_desc, dim=1)
        B<a id="change"> = </a><a id="change">src_desc.size(0</a><a id="change">)</a>

        tgt_desc_dense = desc_dense[dense_inds]  &#47&#47 B x C x H x W
        tgt_desc_unrolled = F.normalize(tgt_desc_dense.view(B, encoder_dim, -1), dim=1)  &#47&#47 B x C x HW

        match_vals = torch.matmul(src_desc.transpose(2, 1), tgt_desc_unrolled)  &#47&#47 B x N x HW
        soft_match_vals = F.softmax(match_vals / self.softmax_temp, dim=2)  &#47&#47 B x N x HW

        v_coord, u_coord = torch.meshgrid([torch.arange(0, height), torch.arange(0, width)])
        v_coord = v_coord.reshape(height * width).float()  &#47&#47 HW
        u_coord = u_coord.reshape(height * width).float()
        coords = torch.stack((u_coord, v_coord), dim=1)  &#47&#47 HW x 2
        tgt_coords_dense = coords.unsqueeze(0).expand(B, height * width, 2).to(self.gpuid)  &#47&#47 B x HW x 2

        pseudo_coords = torch.matmul(tgt_coords_dense.transpose(2, 1),
                                     soft_match_vals.transpose(2, 1)).transpose(2, 1)  &#47&#47 BxNx2

        &#47&#47 GET SCORES for pseudo point locations
        pseudo_norm = normalize_coords(pseudo_coords, height, width).unsqueeze(1)          &#47&#47 B x 1 x N x 2
        tgt_scores_dense = scores_dense[dense_inds]
        pseudo_scores = F.grid_sample(tgt_scores_dense, pseudo_norm, mode=&quotbilinear&quot)           &#47&#47 B x 1 x 1 x N
        pseudo_scores = pseudo_scores.reshape(B, 1, n_points)                          &#47&#47 B x 1 x N
        &#47&#47 GET DESCRIPTORS for pseudo point locations
        pseudo_desc = F.grid_sample(tgt_desc_dense, pseudo_norm, mode=&quotbilinear&quot)               &#47&#47 B x C x 1 x N
        pseudo_desc = pseudo_desc.reshape(B, encoder_dim, n_points)                    &#47&#47 B x C x N

        desc_match_score = torch.sum(src_desc * pseudo_desc, dim=1, keepdim=True) / float(encoder_dim)  &#47&#47 Bx1xN
        src_scores = keypoint_scores[kp_inds]
        if self.score_comp:
            match_weights = 0.5 * (desc_match_score + 1) * src_scores * pseudo_scores
        else:
            match_weights = pseudo_scores

        <a id="change">return </a>pseudo_coords<a id="change">, match_weights, kp_inds</a>

def normalize_coords(coords_2D, width, height):
    Normalizes coords_2D (B x N x 2) to be within [-1, 1] 
    batch_size = coords_2D.size(0)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/utiasasrl/hero_radar_odometry/commit/3393ae645f3b4eea057784a2cd3746aefb0c81b1#diff-23e0da2f9fd5de38a06280e99a19331414bae7133b397e03cf546a99b3ddce20L17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6497791</div><div id='project'> Project Name: utiasasrl/hero_radar_odometry</div><div id='commit'> Commit Name: 3393ae645f3b4eea057784a2cd3746aefb0c81b1</div><div id='time'> Time: 2021-01-08</div><div id='author'> Author: keenburn2004@gmail.com</div><div id='file'> File Name: networks/softmax_matcher.py</div><div id='m_class'> M Class Name: SoftmaxMatcher</div><div id='n_method'> N Class Name: SoftmaxMatcher</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: networks/softmax_matcher.py</div><div id='n_file'> N File Name: networks/softmax_matcher.py</div><div id='m_start'> M Start Line: 26</div><div id='m_end'> M End Line: 63</div><div id='n_start'> N Start Line: 27</div><div id='n_end'> N End Line: 66</div><BR>