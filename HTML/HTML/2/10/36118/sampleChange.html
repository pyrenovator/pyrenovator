<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)
    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    net = net.to(device=device)
    <a id="change">if torch.cuda.device_count() &gt; 1</a>:
      <a id="change">print("Let&quots use"</a>, torch.cuda.device_count(), <a id="change">"GPUs!"</a><a id="change">)</a>
      &#47&#47 dim = 0 [30, xxx] -&gt; [10, ...], [10, ...], [10, ...] on 3 GPUs
      net<a id="change"> = </a>DataParallelPassthrough(net, device_ids=[0,1])

    net=net.to(device=device)
</code></pre><h3>After Change</h3><pre><code class='java'>
              rank=0): &#47&#47 config not normally needed due to wandb

    &#47&#47 MODEL LOADING CODE
    <a id="change">print(f"Training on device {device}"</a><a id="change">)</a>
    starting_epoch = 0 &#47&#47 will change if loading from checkpoint
    if config == None:
      config = wandb.config
    &#47&#47 If we&quotre loading from a checkpoint, do so.</code></pre>