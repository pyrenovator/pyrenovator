<html><h3>Pattern ID :18949
</h3><img src='61527464.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                 dropout: Optional[float], add_input_to_output: bool, bias: bool, add_bias_kv: bool,
                 add_zero_attn: bool, kdim: Optional[int], vdim: Optional[int]):
        in_num_dims = [3]
        <a id="change">if </a>isinstance(in_keys, list) and <a id="change">len(in_keys) &gt; 1</a>:
            mask_dim<a id="change"> = </a>len(in_shapes[-1])
            in_num_dims.append(mask_dim + 1)
        out_num_dims = [3]
        if isinstance(out_keys, list) and len(out_keys) &gt; 1:</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 Input dimensionality is inferred from the in_shapes since the block can be used with 1 or 2 dimensional data,
        &#47&#47   without the batch dimension. Additionally the mask dimensions is also inferred if present.
        in_num_dims = <a id="change">[len(in_shape) + 1 for in_shape in in_shapes]</a>

        &#47&#47 Output dimensionality is equal to the input dimensionality, while the dimensionality of the attention weights
        &#47&#47  is only added if the a second out_key is given.
        out_num_dims<a id="change"> = </a>[in_num_dims[0]]
        if isinstance(out_keys, list) and len(out_keys) &gt; 1:
            out_num_dims.append(out_num_dims[0])
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/enlite-ai/maze/commit/6a5f78f95bd250f481740821a633570a5adfb9e4#diff-a48f7422e81464cc43d94f2c1e4795eda4c76fb75934b8e8ece349879c4c262bL40' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 61527464</div><div id='project'> Project Name: enlite-ai/maze</div><div id='commit'> Commit Name: 6a5f78f95bd250f481740821a633570a5adfb9e4</div><div id='time'> Time: 2021-03-18</div><div id='author'> Author: office@enlite.ai</div><div id='file'> File Name: maze/perception/blocks/feed_forward/multi_head_attention.py</div><div id='m_class'> M Class Name: MultiHeadAttentionBlock</div><div id='n_method'> N Class Name: MultiHeadAttentionBlock</div><div id='m_method'> M Method Name: __init__(13)</div><div id='n_method'> N Method Name: __init__(12)</div><div id='m_parent_class'> M Parent Class: ShapeNormalizationBlock</div><div id='n_parent_class'> N Parent Class: ShapeNormalizationBlock</div><div id='m_file'> M File Name: maze/perception/blocks/feed_forward/multi_head_attention.py</div><div id='n_file'> N File Name: maze/perception/blocks/feed_forward/multi_head_attention.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 53</div><div id='n_start'> N Start Line: 57</div><div id='n_end'> N End Line: 104</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                 in_shapes: Union[Sequence[int], List[Sequence[int]]], embed_dim: int, num_heads: int,
                 dropout: Optional[float], add_input_to_output: bool, bias: bool):
        in_num_dims = [3]
        <a id="change">if </a>isinstance(in_keys, list) and <a id="change">len(in_keys) &gt; 1</a>:
            mask_dim<a id="change"> = </a>len(in_shapes[-1])
            in_num_dims.append(mask_dim + 1)
        super().__init__(in_keys=in_keys, out_keys=out_keys, in_shapes=in_shapes, in_num_dims=in_num_dims,
                         out_num_dims=[3])</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 Input dimensionality is inferred from the in_shapes since the block can be used with 1 or 2 dimensional data,
        &#47&#47   without the batch dimension. Additionally the mask dimension is also inferred if present.
        in_num_dims = <a id="change">[len(in_shape) + 1 for in_shape in in_shapes]</a>

        &#47&#47 Output dimensionality is equal to the input dimensionality, while the dimensionality of the attention weights
        &#47&#47  is only added if the a second out_key is given.
        out_num_dims<a id="change"> = </a>[in_num_dims[0]]
        if isinstance(out_keys, list) and len(out_keys) &gt; 1:
            out_num_dims.append(out_num_dims[0])
        super().__init__(in_keys=in_keys, out_keys=out_keys, in_shapes=in_shapes, in_num_dims=in_num_dims,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/enlite-ai/maze/commit/6a5f78f95bd250f481740821a633570a5adfb9e4#diff-8db1c2f87089ded14daa071aff1a3903365f38fd8b81693b62975ad74cf3d1b0L36' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 61527465</div><div id='project'> Project Name: enlite-ai/maze</div><div id='commit'> Commit Name: 6a5f78f95bd250f481740821a633570a5adfb9e4</div><div id='time'> Time: 2021-03-18</div><div id='author'> Author: office@enlite.ai</div><div id='file'> File Name: maze/perception/blocks/general/self_attention_seq.py</div><div id='m_class'> M Class Name: SelfAttentionSeqBlock</div><div id='n_method'> N Class Name: SelfAttentionSeqBlock</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(9)</div><div id='m_parent_class'> M Parent Class: ShapeNormalizationBlock</div><div id='n_parent_class'> N Parent Class: ShapeNormalizationBlock</div><div id='m_file'> M File Name: maze/perception/blocks/general/self_attention_seq.py</div><div id='n_file'> N File Name: maze/perception/blocks/general/self_attention_seq.py</div><div id='m_start'> M Start Line: 37</div><div id='m_end'> M End Line: 54</div><div id='n_start'> N Start Line: 39</div><div id='n_end'> N End Line: 60</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 get whether to keep dimensions
    if &quotkeepdim&quot in ctx.method_kwargs:
        keep_dims = ctx.method_kwargs[&quotkeepdim&quot]
    elif <a id="change">len(ctx.method_args) == 3</a>:
        keep_dims = ctx.method_args[2]
    else:
        keep_dims<a id="change"> = </a>False
        
    layer = ctx.network.add_reduce(input_trt, trt.ReduceOperation.AVG, axes, keep_dims)
    output._trt = layer.get_output(0)</code></pre><h3>After Change</h3><pre><code class='java'>
    if not isinstance(dim, tuple):
        dim = (dim, )

    dim<a id="change"> = </a>tuple(<a id="change">[d if d&gt;=0 else len(input.shape)+d for d in dim]</a>)
        
    &#47&#47 create axes bitmask for reduce layer
    axes = 0</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/grimoire/torch2trt_dynamic/commit/11d2ef919763c792d1389016c4f2f4792fb47a0e#diff-a599dfee389186af32614847c9777ce45941d394838bd1112ca6998c47e2e502L7' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 61527470</div><div id='project'> Project Name: grimoire/torch2trt_dynamic</div><div id='commit'> Commit Name: 11d2ef919763c792d1389016c4f2f4792fb47a0e</div><div id='time'> Time: 2020-07-27</div><div id='author'> Author: streetyao@live.com</div><div id='file'> File Name: torch2trt/converters/mean.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: convert_mean(1)</div><div id='n_method'> N Method Name: convert_mean(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torch2trt/converters/mean.py</div><div id='n_file'> N File Name: torch2trt/converters/mean.py</div><div id='m_start'> M Start Line: 13</div><div id='m_end'> M End Line: 38</div><div id='n_start'> N Start Line: 8</div><div id='n_end'> N End Line: 25</div><BR>