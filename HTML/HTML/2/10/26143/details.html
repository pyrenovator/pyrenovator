<html><h3>Pattern ID :26143
</h3><img src='78795954.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        
        &#47&#47 only support fused BN
        assert bn_op.type == &quotFusedBatchNormV3&quot
        <a id="change">assert </a>len(bn_op.inputs) == 5

        beta_read = bn_op.inputs[constants.BN_OP_PARAM_INDICES[&quotbeta&quot]].op
</code></pre><h3>After Change</h3><pre><code class='java'>
         (is mul_1 op inside BN scope)
        :return: beta read op
        
        <a id="change">if bn_op.type in [&quotMul&quot]</a>:
            &#47&#47 For regular BN
            &#47&#47 mul_1 -&gt; add_1 &lt;-- sub &lt;-- beta_read
            assert len(bn_op.outputs) &gt;= 1, _BN_STRUCTURE_ERROR_MSG
            add_1<a id="change"> = </a>bn_op.outputs[0].consumers()[0]
            <a id="change">assert </a>len(add_1.inputs) &gt;= 2, _BN_STRUCTURE_ERROR_MSG
            sub<a id="change"> = </a>add_1.inputs[1].op
            assert len(sub.inputs) &gt;= 1, _BN_STRUCTURE_ERROR_MSG
            beta_read = sub.inputs[0].op
        elif bn_op.type in [&quotFusedBatchNormV3&quot]:
            <a id="change">assert </a>len(bn_op.inputs) == 5
            beta_read = bn_op.inputs[constants.BN_OP_PARAM_INDICES[&quotbeta&quot]].op
            if beta_read.type == &quotSwitch&quot:      &#47&#47 tf slim bn using training tensor form
                beta_read<a id="change"> = </a>beta_read.inputs[0].op
                <a id="change">assert </a>&quotread&quot in beta_read.name
        else:
            logger.error("Error, unknown BN op")
            <a id="change">assert </a>False

        assert beta_read.type in [&quotReadVariableOp&quot, &quotIdentity&quot]      &#47&#47 Will be identity for tf slim BNs
        return beta_read</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/quic/aimet/commit/04a3d26199c86efdb24da756ab9210e050855d14#diff-4d4c6b2b283172f6b18adb34c493d4a8c54e3dd52877eabf1542f231dd4f0518L112' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78795954</div><div id='project'> Project Name: quic/aimet</div><div id='commit'> Commit Name: 04a3d26199c86efdb24da756ab9210e050855d14</div><div id='time'> Time: 2020-05-21</div><div id='author'> Author: quic_klhsieh@quicinc.com</div><div id='file'> File Name: TrainingExtensions/tensorflow/src/python/aimet_tensorflow/utils/op/fusedbatchnorm.py</div><div id='m_class'> M Class Name: BNUtils</div><div id='n_method'> N Class Name: BNUtils</div><div id='m_method'> M Method Name: get_beta_read_op(1)</div><div id='n_method'> N Method Name: get_beta_read_op(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: TrainingExtensions/tensorflow/src/python/aimet_tensorflow/utils/op/fusedbatchnorm.py</div><div id='n_file'> N File Name: TrainingExtensions/tensorflow/src/python/aimet_tensorflow/utils/op/fusedbatchnorm.py</div><div id='m_start'> M Start Line: 112</div><div id='m_end'> M End Line: 117</div><div id='n_start'> N Start Line: 112</div><div id='n_end'> N End Line: 131</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 Inputs contains the shapes of two matrices.
    input_shapes = [v.shape for v in inputs]
    assert len(input_shapes) == 2, input_shapes
    <a id="change">assert </a>input_shapes[0][-1] == input_shapes[1][-2], input_shapes
    flops = reduce(operator.mul, input_shapes[0]) * input_shapes[-1][-1]
    return flops
</code></pre><h3>After Change</h3><pre><code class='java'>
    assert len(input_shapes) == 2, input_shapes

    &#47&#47 There are three cases: 1) gemm, 2) gemv, 3) dot
    <a id="change">if </a>all(<a id="change">len(shape) == 2</a> for shape in input_shapes):
        &#47&#47 gemm
        <a id="change">assert </a>input_shapes[0][-1] == input_shapes[1][-2], input_shapes
    elif all(len(shape) == 1 for shape in input_shapes):
        &#47&#47 dot
        <a id="change">assert </a>input_shapes[0][0] == input_shapes[1][0], input_shapes

        &#47&#47 expand shape
        input_shapes[0]<a id="change"> = </a>torch.Size([1, input_shapes[0][0]])
        input_shapes[1]<a id="change"> = </a>torch.Size([input_shapes[1][0], 1])
    else:
        &#47&#47 gemv
        if len(input_shapes[0]) == 1:
            <a id="change">assert </a>input_shapes[0][0] == input_shapes[1][-2], input_shapes
            input_shapes.reverse()
        else:
            <a id="change">assert </a>input_shapes[1][0] == input_shapes[0][-1], input_shapes

        &#47&#47 expand the shape of the vector to [batch size, 1]
        input_shapes[-1]<a id="change"> = </a>torch.Size([input_shapes[-1][-1], 1])
    flops = reduce(operator.mul, input_shapes[0]) * input_shapes[-1][-1]
    return flops
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hpcaitech/colossalai/commit/ffcdbf0f6519366f322f2809e19f741492779c6c#diff-981cd0ad911d36e616b5e23857ecb75a4e85f6dff4376f329f7c84340037f4eaL230' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78796000</div><div id='project'> Project Name: hpcaitech/colossalai</div><div id='commit'> Commit Name: ffcdbf0f6519366f322f2809e19f741492779c6c</div><div id='time'> Time: 2023-04-04</div><div id='author'> Author: 72588413+YuliangLiu0306@users.noreply.github.com</div><div id='file'> File Name: colossalai/_analyzer/_subclasses/flop_tensor.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: matmul_flop_jit(2)</div><div id='n_method'> N Method Name: matmul_flop_jit(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: colossalai/_analyzer/_subclasses/flop_tensor.py</div><div id='n_file'> N File Name: colossalai/_analyzer/_subclasses/flop_tensor.py</div><div id='m_start'> M Start Line: 238</div><div id='m_end'> M End Line: 238</div><div id='n_start'> N Start Line: 236</div><div id='n_end'> N End Line: 260</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 Inputs contains the shapes of two matrices.
    input_shapes = [v.shape for v in inputs]
    assert len(input_shapes) == 2, input_shapes
    <a id="change">assert </a>input_shapes[0][-1] == input_shapes[1][-2], input_shapes
    flops = reduce(operator.mul, input_shapes[0]) * input_shapes[-1][-1]
    return flops
</code></pre><h3>After Change</h3><pre><code class='java'>
    assert len(input_shapes) == 2, input_shapes

    &#47&#47 There are three cases: 1) gemm, 2) gemv, 3) dot
    <a id="change">if </a>all(<a id="change">len(shape) == 2</a> for shape in input_shapes):
        &#47&#47 gemm
        <a id="change">assert </a>input_shapes[0][-1] == input_shapes[1][-2], input_shapes
    elif all(len(shape) == 1 for shape in input_shapes):
        &#47&#47 dot
        <a id="change">assert </a>input_shapes[0][0] == input_shapes[1][0], input_shapes

        &#47&#47 expand shape
        input_shapes[0]<a id="change"> = </a>torch.Size([1, input_shapes[0][0]])
        input_shapes[1]<a id="change"> = </a>torch.Size([input_shapes[1][0], 1])
    else:
        &#47&#47 gemv
        if len(input_shapes[0]) == 1:
            <a id="change">assert </a>input_shapes[0][0] == input_shapes[1][-2], input_shapes
            input_shapes.reverse()
        else:
            <a id="change">assert </a>input_shapes[1][0] == input_shapes[0][-1], input_shapes

        &#47&#47 expand the shape of the vector to [batch size, 1]
        input_shapes[-1]<a id="change"> = </a>torch.Size([input_shapes[-1][-1], 1])
    flops = reduce(operator.mul, input_shapes[0]) * input_shapes[-1][-1]
    return flops
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hpcaitech/colossalai/commit/90a9fdd91d12cdfb03d4eaf88ff67a47cbe65f33#diff-639fb184e506dbe4e21ad4a59c6f874d6eae8cc69e047680b2097ecd9f48c97eL15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78795956</div><div id='project'> Project Name: hpcaitech/colossalai</div><div id='commit'> Commit Name: 90a9fdd91d12cdfb03d4eaf88ff67a47cbe65f33</div><div id='time'> Time: 2023-02-07</div><div id='author'> Author: 70263930+Cypher30@users.noreply.github.com</div><div id='file'> File Name: colossalai/fx/profiler/opcount.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: matmul_flop_jit(2)</div><div id='n_method'> N Method Name: matmul_flop_jit(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: colossalai/fx/profiler/opcount.py</div><div id='n_file'> N File Name: colossalai/fx/profiler/opcount.py</div><div id='m_start'> M Start Line: 23</div><div id='m_end'> M End Line: 23</div><div id='n_start'> N Start Line: 21</div><div id='n_end'> N End Line: 45</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 only support fused BN
        assert bn_op.type == &quotFusedBatchNormV3&quot
        <a id="change">assert </a>len(bn_op.inputs) == 5

        gamma_read = bn_op.inputs[constants.BN_OP_PARAM_INDICES[&quotgamma&quot]].op
</code></pre><h3>After Change</h3><pre><code class='java'>
        (is mul_1 op inside BN scope)
        :return: gamma read op
        
        <a id="change">if bn_op.type in [&quotMul&quot]</a>:
            &#47&#47 For regular BN
            &#47&#47 mul_1 &lt;-- mul &lt;-- gamma_read &lt;-- gamma_tensor
            <a id="change">assert </a>len(bn_op.inputs) &gt;= 2, _BN_STRUCTURE_ERROR_MSG
            mul<a id="change"> = </a>bn_op.inputs[1].op
            <a id="change">assert </a>len(mul.inputs) &gt;= 2, _BN_STRUCTURE_ERROR_MSG
            gamma_read<a id="change"> = </a>mul.inputs[1].op
        elif bn_op.type in [&quotFusedBatchNormV3&quot]:
            <a id="change">assert </a>len(bn_op.inputs) == 5
            gamma_read = bn_op.inputs[constants.BN_OP_PARAM_INDICES[&quotgamma&quot]].op
            if gamma_read.type == &quotSwitch&quot:      &#47&#47 tf slim bn using training tensor form
                gamma_read<a id="change"> = </a>gamma_read.inputs[0].op
                assert &quotread&quot in gamma_read.name or gamma_read.type == &quotConst&quot
        else:
            logger.error("Error, unknown BN op")
            <a id="change">assert </a>False
        assert gamma_read.type in [&quotReadVariableOp&quot, &quotIdentity&quot, &quotConst&quot]    &#47&#47 Will be identity for tf slim BNs
        return gamma_read
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/quic/aimet/commit/04a3d26199c86efdb24da756ab9210e050855d14#diff-4d4c6b2b283172f6b18adb34c493d4a8c54e3dd52877eabf1542f231dd4f0518L165' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78795962</div><div id='project'> Project Name: quic/aimet</div><div id='commit'> Commit Name: 04a3d26199c86efdb24da756ab9210e050855d14</div><div id='time'> Time: 2020-05-21</div><div id='author'> Author: quic_klhsieh@quicinc.com</div><div id='file'> File Name: TrainingExtensions/tensorflow/src/python/aimet_tensorflow/utils/op/fusedbatchnorm.py</div><div id='m_class'> M Class Name: BNUtils</div><div id='n_method'> N Class Name: BNUtils</div><div id='m_method'> M Method Name: get_gamma_as_read_op(1)</div><div id='n_method'> N Method Name: get_gamma_as_read_op(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: TrainingExtensions/tensorflow/src/python/aimet_tensorflow/utils/op/fusedbatchnorm.py</div><div id='n_file'> N File Name: TrainingExtensions/tensorflow/src/python/aimet_tensorflow/utils/op/fusedbatchnorm.py</div><div id='m_start'> M Start Line: 174</div><div id='m_end'> M End Line: 177</div><div id='n_start'> N Start Line: 181</div><div id='n_end'> N End Line: 197</div><BR>