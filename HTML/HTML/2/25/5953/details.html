<html><h3>Pattern ID :5953
</h3><img src='20945214.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def testBatchNorm(self):
        device = get_test_device()
        x = torch.randn(16, 3, 224, 224, device=device)
        bn<a id="change"> = </a><a id="change">torch.nn.BatchNorm2d(3</a><a id="change">)</a>.to(device=device)
        for i in range(10):
            z = bn(x)

        device = "lazy"
        x_lazy = x.detach().clone().to(device=device)
        bn<a id="change"> = </a>bn.to(device=device)
        for i in range(10):
            z_lazy = bn(x_lazy)
            torch._lazy.mark_step()</code></pre><h3>After Change</h3><pre><code class='java'>
    def testBatchNorm(self):
        device = get_test_device()
        x = torch.randn(16, 3, 224, 224, device=device)
        <a id="change">weight = </a>torch.randn(3, device=device)
        <a id="change">bias = </a><a id="change">torch.randn(3</a><a id="change">, device=device)</a>

        for i in range(10):
            &#47&#47 BatchNorm2d does extra checks on dimensions which SymInts don&quott support yet
            &#47&#47 so we call `torch.ops.aten.native_batch_norm` to bypass the checks.
            z, _, _ = <a id="change">torch.ops.aten.native_batch_norm(</a>x, <a id="change">weight</a>, <a id="change">bias</a>, <a id="change">None</a>, <a id="change">None</a>, <a id="change">True</a>, <a id="change">0.1</a>, <a id="change">1e-5</a><a id="change">)</a>

        device = "lazy"
        x_lazy = x.detach().clone().to(device=device)
        weight_lazy<a id="change"> = weight</a><a id="change">.detach().clone()</a>.to(device=device)
        bias_lazy<a id="change"> = bias.detach().clone()</a><a id="change">.to(device=device)</a>
        for i in range(10):
            z_lazy, _, _ = <a id="change">torch.ops.aten.native_batch_norm(</a>x_lazy, weight_lazy, bias_lazy, <a id="change">None</a>, <a id="change">None</a>, <a id="change">True</a>, <a id="change">0.1</a>, <a id="change">1e-5</a><a id="change">)</a>
            torch._lazy.mark_step()

        torch.testing.assert_close(z.cpu(), z_lazy.cpu())
        assert metrics.counter_value("IrNodeReused_torch::lazy::TSNativeBatchNormForward") &gt;= 7</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 15</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/8ef6356f267c75276ea23b51163274cd5fffc0ce#diff-e320ff3c48c9f6505f3b0d1819a98262797d390acf79d5a574efbe91b966476bL106' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 20945214</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 8ef6356f267c75276ea23b51163274cd5fffc0ce</div><div id='time'> Time: 2022-06-15</div><div id='author'> Author: korovaikon@gmail.com</div><div id='file'> File Name: test/lazy/test_reuse_ir.py</div><div id='m_class'> M Class Name: TestLazyReuseIr</div><div id='n_method'> N Class Name: TestLazyReuseIr</div><div id='m_method'> M Method Name: testBatchNorm(1)</div><div id='n_method'> N Method Name: testBatchNorm(1)</div><div id='m_parent_class'> M Parent Class: TestCase</div><div id='n_parent_class'> N Parent Class: TestCase</div><div id='m_file'> M File Name: test/lazy/test_reuse_ir.py</div><div id='n_file'> N File Name: test/lazy/test_reuse_ir.py</div><div id='m_start'> M Start Line: 106</div><div id='m_end'> M End Line: 115</div><div id='n_start'> N Start Line: 106</div><div id='n_end'> N End Line: 120</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def testBatchNorm(self):
        device = get_test_device()
        x = torch.randn(16, 3, 224, 224, device=device)
        bn<a id="change"> = </a><a id="change">torch.nn.BatchNorm2d(3</a><a id="change">)</a>.to(device=device)
        for i in range(10):
            z = bn(x)

        device = "lazy"
        x_lazy = x.detach().clone().to(device=device)
        bn<a id="change"> = </a>bn.to(device=device)
        for i in range(10):
            z_lazy = bn(x_lazy)
            torch._lazy.mark_step()</code></pre><h3>After Change</h3><pre><code class='java'>
    def testBatchNorm(self):
        device = get_test_device()
        x = torch.randn(16, 3, 224, 224, device=device)
        <a id="change">weight = </a>torch.randn(3, device=device)
        <a id="change">bias = </a><a id="change">torch.randn(3</a><a id="change">, device=device)</a>

        for i in range(10):
            &#47&#47 BatchNorm2d does extra checks on dimensions which SymInts don&quott support yet
            &#47&#47 so we call `torch.ops.aten.native_batch_norm` to bypass the checks.
            z, _, _ = <a id="change">torch.ops.aten.native_batch_norm(</a>x, weight, bias, None, None, True, <a id="change">0.1</a>, <a id="change">1e-5</a><a id="change">)</a>

        device = "lazy"
        x_lazy = x.detach().clone().to(device=device)
        weight_lazy<a id="change"> = </a><a id="change">weight.detach().clone()</a>.to(device=device)
        bias_lazy<a id="change"> = bias.detach().clone()</a><a id="change">.to(device=device)</a>
        for i in range(10):
            z_lazy, _, _ = <a id="change">torch.ops.aten.native_batch_norm(</a>x_lazy, weight_lazy, bias_lazy, None, None, True, <a id="change">0.1</a>, <a id="change">1e-5</a><a id="change">)</a>
            torch._lazy.mark_step()

        torch.testing.assert_close(z.cpu(), z_lazy.cpu())
        assert metrics.counter_value("IrNodeReused_torch::lazy::TSNativeBatchNormForward") &gt;= 7</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/d332724071704939e1c50704f6bc62bb6c990383#diff-e320ff3c48c9f6505f3b0d1819a98262797d390acf79d5a574efbe91b966476bL104' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 20944958</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: d332724071704939e1c50704f6bc62bb6c990383</div><div id='time'> Time: 2022-06-13</div><div id='author'> Author: korovaikon@gmail.com</div><div id='file'> File Name: test/lazy/test_reuse_ir.py</div><div id='m_class'> M Class Name: TestLazyReuseIr</div><div id='n_method'> N Class Name: TestLazyReuseIr</div><div id='m_method'> M Method Name: testBatchNorm(1)</div><div id='n_method'> N Method Name: testBatchNorm(1)</div><div id='m_parent_class'> M Parent Class: TestCase</div><div id='n_parent_class'> N Parent Class: TestCase</div><div id='m_file'> M File Name: test/lazy/test_reuse_ir.py</div><div id='n_file'> N File Name: test/lazy/test_reuse_ir.py</div><div id='m_start'> M Start Line: 106</div><div id='m_end'> M End Line: 115</div><div id='n_start'> N Start Line: 106</div><div id='n_end'> N End Line: 120</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def testBatchNorm(self):
        device = get_test_device()
        x = torch.randn(16, 3, 224, 224, device=device)
        bn<a id="change"> = </a><a id="change">torch.nn.BatchNorm2d(3</a><a id="change">)</a>.to(device=device)
        for i in range(10):
            z = bn(x)

        device = "lazy"
        x_lazy = x.detach().clone().to(device=device)
        bn<a id="change"> = </a>bn.to(device=device)
        for i in range(10):
            z_lazy = bn(x_lazy)
            torch._lazy.mark_step()</code></pre><h3>After Change</h3><pre><code class='java'>
    def testBatchNorm(self):
        device = get_test_device()
        x = torch.randn(16, 3, 224, 224, device=device)
        <a id="change">weight = </a>torch.randn(3, device=device)
        <a id="change">bias = </a><a id="change">torch.randn(3</a><a id="change">, device=device)</a>

        for i in range(10):
            &#47&#47 BatchNorm2d does extra checks on dimensions which SymInts don&quott support yet
            &#47&#47 so we call `torch.ops.aten.native_batch_norm` to bypass the checks.
            z, _, _ = <a id="change">torch.ops.aten.native_batch_norm(</a>x, weight, bias, None, None, True, <a id="change">0.1</a>, <a id="change">1e-5</a><a id="change">)</a>

        device = "lazy"
        x_lazy = x.detach().clone().to(device=device)
        weight_lazy<a id="change"> = </a><a id="change">weight.detach().clone()</a>.to(device=device)
        bias_lazy<a id="change"> = bias.detach().clone()</a><a id="change">.to(device=device)</a>
        for i in range(10):
            z_lazy, _, _ = <a id="change">torch.ops.aten.native_batch_norm(</a>x_lazy, weight_lazy, bias_lazy, None, None, True, <a id="change">0.1</a>, <a id="change">1e-5</a><a id="change">)</a>
            torch._lazy.mark_step()

        torch.testing.assert_close(z.cpu(), z_lazy.cpu())
        assert metrics.counter_value("IrNodeReused_torch::lazy::TSNativeBatchNormForward") &gt;= 7</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/f7ee061638aa2011191caeff4438fa8aff5bfec3#diff-e320ff3c48c9f6505f3b0d1819a98262797d390acf79d5a574efbe91b966476bL104' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 20945213</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: f7ee061638aa2011191caeff4438fa8aff5bfec3</div><div id='time'> Time: 2022-06-20</div><div id='author'> Author: ezyang@fb.com</div><div id='file'> File Name: test/lazy/test_reuse_ir.py</div><div id='m_class'> M Class Name: TestLazyReuseIr</div><div id='n_method'> N Class Name: TestLazyReuseIr</div><div id='m_method'> M Method Name: testBatchNorm(1)</div><div id='n_method'> N Method Name: testBatchNorm(1)</div><div id='m_parent_class'> M Parent Class: TestCase</div><div id='n_parent_class'> N Parent Class: TestCase</div><div id='m_file'> M File Name: test/lazy/test_reuse_ir.py</div><div id='n_file'> N File Name: test/lazy/test_reuse_ir.py</div><div id='m_start'> M Start Line: 106</div><div id='m_end'> M End Line: 115</div><div id='n_start'> N Start Line: 106</div><div id='n_end'> N End Line: 120</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def testBatchNorm(self):
        device = get_test_device()
        x = torch.randn(16, 3, 224, 224, device=device)
        bn<a id="change"> = </a><a id="change">torch.nn.BatchNorm2d(3</a><a id="change">)</a>.to(device=device)
        for i in range(10):
            z = bn(x)

        device = "lazy"
        x_lazy = x.detach().clone().to(device=device)
        bn<a id="change"> = </a>bn.to(device=device)
        for i in range(10):
            z_lazy = bn(x_lazy)
            torch._lazy.mark_step()</code></pre><h3>After Change</h3><pre><code class='java'>
    def testBatchNorm(self):
        device = get_test_device()
        x = torch.randn(16, 3, 224, 224, device=device)
        <a id="change">weight = </a>torch.randn(3, device=device)
        <a id="change">bias = </a><a id="change">torch.randn(3</a><a id="change">, device=device)</a>

        for i in range(10):
            &#47&#47 BatchNorm2d does extra checks on dimensions which SymInts don&quott support yet
            &#47&#47 so we call `torch.ops.aten.native_batch_norm` to bypass the checks.
            z, _, _ = <a id="change">torch.ops.aten.native_batch_norm(</a>x, weight, bias, None, None, True, <a id="change">0.1</a>, <a id="change">1e-5</a><a id="change">)</a>

        device = "lazy"
        x_lazy = x.detach().clone().to(device=device)
        weight_lazy<a id="change"> = </a><a id="change">weight.detach().clone()</a>.to(device=device)
        bias_lazy<a id="change"> = bias.detach().clone()</a><a id="change">.to(device=device)</a>
        for i in range(10):
            z_lazy, _, _ = <a id="change">torch.ops.aten.native_batch_norm(</a>x_lazy, weight_lazy, bias_lazy, None, None, True, <a id="change">0.1</a>, <a id="change">1e-5</a><a id="change">)</a>
            torch._lazy.mark_step()

        torch.testing.assert_close(z.cpu(), z_lazy.cpu())
        assert metrics.counter_value("IrNodeReused_torch::lazy::TSNativeBatchNormForward") &gt;= 7</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/8ef6356f267c75276ea23b51163274cd5fffc0ce#diff-e320ff3c48c9f6505f3b0d1819a98262797d390acf79d5a574efbe91b966476bL104' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 20945208</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 8ef6356f267c75276ea23b51163274cd5fffc0ce</div><div id='time'> Time: 2022-06-15</div><div id='author'> Author: korovaikon@gmail.com</div><div id='file'> File Name: test/lazy/test_reuse_ir.py</div><div id='m_class'> M Class Name: TestLazyReuseIr</div><div id='n_method'> N Class Name: TestLazyReuseIr</div><div id='m_method'> M Method Name: testBatchNorm(1)</div><div id='n_method'> N Method Name: testBatchNorm(1)</div><div id='m_parent_class'> M Parent Class: TestCase</div><div id='n_parent_class'> N Parent Class: TestCase</div><div id='m_file'> M File Name: test/lazy/test_reuse_ir.py</div><div id='n_file'> N File Name: test/lazy/test_reuse_ir.py</div><div id='m_start'> M Start Line: 106</div><div id='m_end'> M End Line: 115</div><div id='n_start'> N Start Line: 106</div><div id='n_end'> N End Line: 120</div><BR>