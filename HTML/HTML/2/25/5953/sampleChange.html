<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def testBatchNorm(self):
        device = get_test_device()
        x = torch.randn(16, 3, 224, 224, device=device)
        bn<a id="change"> = </a><a id="change">torch.nn.BatchNorm2d(3</a><a id="change">)</a>.to(device=device)
        for i in range(10):
            z = bn(x)

        device = "lazy"
        x_lazy = x.detach().clone().to(device=device)
        bn<a id="change"> = </a>bn.to(device=device)
        for i in range(10):
            z_lazy = bn(x_lazy)
            torch._lazy.mark_step()</code></pre><h3>After Change</h3><pre><code class='java'>
    def testBatchNorm(self):
        device = get_test_device()
        x = torch.randn(16, 3, 224, 224, device=device)
        <a id="change">weight = </a>torch.randn(3, device=device)
        <a id="change">bias = </a><a id="change">torch.randn(3</a><a id="change">, device=device)</a>

        for i in range(10):
            &#47&#47 BatchNorm2d does extra checks on dimensions which SymInts don&quott support yet
            &#47&#47 so we call `torch.ops.aten.native_batch_norm` to bypass the checks.
            z, _, _ = <a id="change">torch.ops.aten.native_batch_norm(</a>x, <a id="change">weight</a>, <a id="change">bias</a>, <a id="change">None</a>, <a id="change">None</a>, <a id="change">True</a>, <a id="change">0.1</a>, <a id="change">1e-5</a><a id="change">)</a>

        device = "lazy"
        x_lazy = x.detach().clone().to(device=device)
        weight_lazy<a id="change"> = weight</a><a id="change">.detach().clone()</a>.to(device=device)
        bias_lazy<a id="change"> = bias.detach().clone()</a><a id="change">.to(device=device)</a>
        for i in range(10):
            z_lazy, _, _ = <a id="change">torch.ops.aten.native_batch_norm(</a>x_lazy, weight_lazy, bias_lazy, <a id="change">None</a>, <a id="change">None</a>, <a id="change">True</a>, <a id="change">0.1</a>, <a id="change">1e-5</a><a id="change">)</a>
            torch._lazy.mark_step()

        torch.testing.assert_close(z.cpu(), z_lazy.cpu())
        assert metrics.counter_value("IrNodeReused_torch::lazy::TSNativeBatchNormForward") &gt;= 7</code></pre>