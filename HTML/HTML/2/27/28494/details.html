<html><h3>Pattern ID :28494
</h3><img src='84379447.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    
    if config.resume:
        <a id="change">if config.resume_d_weight != ""</a>:
            <a id="change">discriminator.load_state_dict(</a><a id="change">torch.load(</a>config.resume_d_weight<a id="change">), strict=config.strict)</a>
        if config.resume_g_weight != "":
            generator.load_state_dict(torch.load(config.resume_g_weight), strict=config.strict)
</code></pre><h3>After Change</h3><pre><code class='java'>

def resume_checkpoint(discriminator: nn.Module, generator: nn.Module) -&gt; None:
    if config.resume:
        <a id="change">if config.resume_d_weight != ""</a>:
            &#47&#47 Get pretrained model state dict
            pretrained_state_dict<a id="change"> = </a><a id="change">torch.load(</a>config.resume_d_weight<a id="change">)</a>
            <a id="change">model_state_dict = discriminator</a><a id="change">.state_dict()</a>
            &#47&#47 Extract the fitted model weights
            new_state_dict<a id="change"> = {k: v for k, v in pretrained_state_dict.items() if k in model_state_dict.items()}</a>
            &#47&#47 Overwrite the pretrained model weights to the current model
            <a id="change">model_state_dict.update(</a>new_state_dict<a id="change">)</a>
            <a id="change">discriminator.load_state_dict(model_state_dict</a><a id="change">, strict=config.strict)</a>
        if config.resume_g_weight != "":
            &#47&#47 Get pretrained model state dict
            pretrained_state_dict = torch.load(config.resume_g_weight)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 19</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lornatang/srgan-pytorch/commit/2c11f14c44490604941be00d7661b19ad8f96597#diff-61221f69809c16ee47dd4cd294d775f91cf98ef417745afe77eab4e2716dfaceL160' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84379447</div><div id='project'> Project Name: lornatang/srgan-pytorch</div><div id='commit'> Commit Name: 2c11f14c44490604941be00d7661b19ad8f96597</div><div id='time'> Time: 2022-02-14</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: train_srgan.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: resume_checkpoint(2)</div><div id='n_method'> N Method Name: resume_checkpoint(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_srgan.py</div><div id='n_file'> N File Name: train_srgan.py</div><div id='m_start'> M Start Line: 206</div><div id='m_end'> M End Line: 211</div><div id='n_start'> N Start Line: 160</div><div id='n_end'> N End Line: 179</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    
    if config.resume:
        <a id="change">if config.resume_weight != ""</a>:
            <a id="change">model.load_state_dict(</a><a id="change">torch.load(</a>config.resume_weight<a id="change">), strict=config.strict)</a>


def train(model, train_dataloader, psnr_criterion, pixel_criterion, optimizer, epoch, scaler, writer) -&gt; None:</code></pre><h3>After Change</h3><pre><code class='java'>

def resume_checkpoint(model) -&gt; None:
    if config.resume:
        <a id="change">if config.resume_weight != ""</a>:
            &#47&#47 Get pretrained model state dict
            pretrained_state_dict<a id="change"> = </a><a id="change">torch.load(</a>config.resume_weight<a id="change">)</a>
            <a id="change">model_state_dict = </a><a id="change">model.state_dict()</a>
            &#47&#47 Extract the fitted model weights
            new_state_dict<a id="change"> = {k: v for k, v in pretrained_state_dict.items() if k in model_state_dict.items()}</a>
            &#47&#47 Overwrite the pretrained model weights to the current model
            <a id="change">model_state_dict.update(</a>new_state_dict<a id="change">)</a>
            <a id="change">model.load_state_dict(</a>model_state_dict<a id="change">, strict=config.strict)</a>


def train(model, train_dataloader, psnr_criterion, pixel_criterion, optimizer, epoch, scaler, writer) -&gt; None:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/srgan-pytorch/commit/2c11f14c44490604941be00d7661b19ad8f96597#diff-e654c2e7420a4ea31af0ee350621a8dabfd9ce87571c367a37e621a3f083d92fL150' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84379446</div><div id='project'> Project Name: lornatang/srgan-pytorch</div><div id='commit'> Commit Name: 2c11f14c44490604941be00d7661b19ad8f96597</div><div id='time'> Time: 2022-02-14</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: train_srresnet.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: resume_checkpoint(1)</div><div id='n_method'> N Method Name: resume_checkpoint(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_srresnet.py</div><div id='n_file'> N File Name: train_srresnet.py</div><div id='m_start'> M Start Line: 158</div><div id='m_end'> M End Line: 161</div><div id='n_start'> N Start Line: 124</div><div id='n_end'> N End Line: 134</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    
    if config.resume:
        <a id="change">if config.resume_d_weight != ""</a>:
            <a id="change">discriminator.load_state_dict(</a><a id="change">torch.load(</a>config.resume_d_weight<a id="change">), strict=config.strict)</a>
        if config.resume_g_weight != "":
            generator.load_state_dict(torch.load(config.resume_g_weight), strict=config.strict)
</code></pre><h3>After Change</h3><pre><code class='java'>

def resume_checkpoint(discriminator: nn.Module, generator: nn.Module) -&gt; None:
    if config.resume:
        <a id="change">if config.resume_d_weight != ""</a>:
            &#47&#47 Get pretrained model state dict
            pretrained_state_dict<a id="change"> = </a><a id="change">torch.load(</a>config.resume_d_weight<a id="change">)</a>
            <a id="change">model_state_dict = </a><a id="change">discriminator.state_dict()</a>
            &#47&#47 Extract the fitted model weights
            new_state_dict<a id="change"> = {k: v for k, v in pretrained_state_dict.items() if k in model_state_dict.items()}</a>
            &#47&#47 Overwrite the pretrained model weights to the current model
            <a id="change">model_state_dict.update(</a>new_state_dict<a id="change">)</a>
            <a id="change">discriminator.load_state_dict(</a>model_state_dict<a id="change">, strict=config.strict)</a>
        if config.resume_g_weight != "":
            &#47&#47 Get pretrained model state dict
            pretrained_state_dict = torch.load(config.resume_g_weight)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/srgan-pytorch/commit/2c11f14c44490604941be00d7661b19ad8f96597#diff-61221f69809c16ee47dd4cd294d775f91cf98ef417745afe77eab4e2716dfaceL197' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84379445</div><div id='project'> Project Name: lornatang/srgan-pytorch</div><div id='commit'> Commit Name: 2c11f14c44490604941be00d7661b19ad8f96597</div><div id='time'> Time: 2022-02-14</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: train_srgan.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: resume_checkpoint(2)</div><div id='n_method'> N Method Name: resume_checkpoint(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_srgan.py</div><div id='n_file'> N File Name: train_srgan.py</div><div id='m_start'> M Start Line: 206</div><div id='m_end'> M End Line: 211</div><div id='n_start'> N Start Line: 160</div><div id='n_end'> N End Line: 179</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if config.resume:
        if config.resume_d_weight != "":
            discriminator.load_state_dict(torch.load(config.resume_d_weight), strict=config.strict)
        <a id="change">if config.resume_g_weight != ""</a>:
            <a id="change">generator.load_state_dict(</a><a id="change">torch.load(</a>config.resume_g_weight<a id="change">), strict=config.strict)</a>


def train(discriminator,</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 Overwrite the pretrained model weights to the current model
            model_state_dict.update(new_state_dict)
            discriminator.load_state_dict(model_state_dict, strict=config.strict)
        <a id="change">if config.resume_g_weight != ""</a>:
            &#47&#47 Get pretrained model state dict
            pretrained_state_dict<a id="change"> = </a><a id="change">torch.load(</a>config.resume_g_weight<a id="change">)</a>
            <a id="change">model_state_dict = </a><a id="change">generator.state_dict()</a>
            &#47&#47 Extract the fitted model weights
            new_state_dict<a id="change"> = {k: v for k, v in pretrained_state_dict.items() if k in model_state_dict.items()}</a>
            &#47&#47 Overwrite the pretrained model weights to the current model
            <a id="change">model_state_dict.update(</a>new_state_dict<a id="change">)</a>
            <a id="change">generator.load_state_dict(</a>model_state_dict<a id="change">, strict=config.strict)</a>


def train(discriminator,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/esrgan-pytorch/commit/0e10b14c2f09a31ab5880f45427f60f1c6a2b0f5#diff-d62cd92dbb6c2541c1742737f637aeab1aa9fcc576e3af108f8ef0c1fd28c8f8L197' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84379444</div><div id='project'> Project Name: lornatang/esrgan-pytorch</div><div id='commit'> Commit Name: 0e10b14c2f09a31ab5880f45427f60f1c6a2b0f5</div><div id='time'> Time: 2022-02-14</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: train_esrgan.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: resume_checkpoint(2)</div><div id='n_method'> N Method Name: resume_checkpoint(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_esrgan.py</div><div id='n_file'> N File Name: train_esrgan.py</div><div id='m_start'> M Start Line: 206</div><div id='m_end'> M End Line: 211</div><div id='n_start'> N Start Line: 161</div><div id='n_end'> N End Line: 180</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    
    if config.resume:
        <a id="change">if config.resume_weight != ""</a>:
            <a id="change">model.load_state_dict(</a><a id="change">torch.load(</a>config.resume_weight<a id="change">), strict=config.strict)</a>


def train(model, train_dataloader, psnr_criterion, pixel_criterion, optimizer, epoch, scaler, writer) -&gt; None:</code></pre><h3>After Change</h3><pre><code class='java'>

def resume_checkpoint(model) -&gt; None:
    if config.resume:
        <a id="change">if config.resume_weight != ""</a>:
            &#47&#47 Get pretrained model state dict
            pretrained_state_dict<a id="change"> = </a><a id="change">torch.load(</a>config.resume_weight<a id="change">)</a>
            <a id="change">model_state_dict = </a><a id="change">model.state_dict()</a>
            &#47&#47 Extract the fitted model weights
            new_state_dict<a id="change"> = {k: v for k, v in pretrained_state_dict.items() if k in model_state_dict.items()}</a>
            &#47&#47 Overwrite the pretrained model weights to the current model
            <a id="change">model_state_dict.update(</a>new_state_dict<a id="change">)</a>
            <a id="change">model.load_state_dict(</a>model_state_dict<a id="change">, strict=config.strict)</a>


def train(model, train_dataloader, psnr_criterion, pixel_criterion, optimizer, epoch, scaler, writer) -&gt; None:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/esrgan-pytorch/commit/0e10b14c2f09a31ab5880f45427f60f1c6a2b0f5#diff-f4329e1175710811d12324bbaab9881a31dff8276b3c7d45269651c3f66f2b77L166' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84379451</div><div id='project'> Project Name: lornatang/esrgan-pytorch</div><div id='commit'> Commit Name: 0e10b14c2f09a31ab5880f45427f60f1c6a2b0f5</div><div id='time'> Time: 2022-02-14</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: train_rrdbnet.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: resume_checkpoint(1)</div><div id='n_method'> N Method Name: resume_checkpoint(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_rrdbnet.py</div><div id='n_file'> N File Name: train_rrdbnet.py</div><div id='m_start'> M Start Line: 174</div><div id='m_end'> M End Line: 177</div><div id='n_start'> N Start Line: 140</div><div id='n_end'> N End Line: 150</div><BR>