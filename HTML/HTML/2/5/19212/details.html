<html><h3>Pattern ID :19212
</h3><img src='62440024.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        split_point = int(len(base_tr_dataset) * (1 - self.val_split))
        np.random.shuffle(idxs)

        tr_subset = Subset(base_tr_dataset, <a id="change">idxs[:split_point]</a>)
        val_subset = Subset(base_tr_dataset, idxs[split_point:])

        return tr_subset, val_subset</code></pre><h3>After Change</h3><pre><code class='java'>
            ) for d in tqdm(self.datasets, desc=&quotLoading LMDB datasets...&quot)
        ])

        val_dataset<a id="change"> = </a>torch.utils.data.ConcatDataset(<a id="change">[
            TensorpackLmdbImageDataset(
                str(self._dataroot / d[&quottr_lmdb&quot]), **d, augmentation_fn=transform_val
            ) for d in tqdm(self.datasets, desc=&quotLoading LMDB datasets...&quot)
        ]</a>)

        &#47&#47 Performs train-validation split
        split_point = int(len(tr_dataset) * (1 - self.val_split))</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/microsoft/archai/commit/d1dd0a59dc86ff271b12e111596b7cbefa2675d3#diff-1a409eb88a4648592a5218e6beb5944cd9ee21f0f0e45436550e25b13cc4a96fL89' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 62440024</div><div id='project'> Project Name: microsoft/archai</div><div id='commit'> Commit Name: d1dd0a59dc86ff271b12e111596b7cbefa2675d3</div><div id='time'> Time: 2022-12-16</div><div id='author'> Author: pierokauffmann@gmail.com</div><div id='file'> File Name: archai/datasets/providers/multi_lmdb_image_provider.py</div><div id='m_class'> M Class Name: MultiTensorpackLmdbImageProvider</div><div id='n_method'> N Class Name: MultiTensorpackLmdbImageProvider</div><div id='m_method'> M Method Name: get_train_val_datasets(3)</div><div id='n_method'> N Method Name: get_train_val_datasets(3)</div><div id='m_parent_class'> M Parent Class: DatasetProvider</div><div id='n_parent_class'> N Parent Class: DatasetProvider</div><div id='m_file'> M File Name: archai/datasets/providers/multi_lmdb_image_provider.py</div><div id='n_file'> N File Name: archai/datasets/providers/multi_lmdb_image_provider.py</div><div id='m_start'> M Start Line: 89</div><div id='m_end'> M End Line: 102</div><div id='n_start'> N Start Line: 89</div><div id='n_end'> N End Line: 113</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    self.config.stacking * self.config.frame_shape[0],
                    self.config.frame_shape[0]
            ):
                frame = <a id="change">x[batch_index, frame_index:frame_index + self.config.frame_shape[0]]</a>
                y[batch_index, frame_index:frame_index + self.config.frame_shape[0]] = standardize_image(frame)

        x_start = y
</code></pre><h3>After Change</h3><pre><code class='java'>
        return self.warm

    def forward(self, x, action, target=None, epsilon=0.0):
        x_start = torch.stack(<a id="change">[standardize_frame(frame) for frame in x]</a>)

        x<a id="change"> = </a>torch.cat((x_start, self.internal_states), dim=1)
        self.update_internal_states_early(x_start)

        x = self.input_embedding(x)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thomas-schillaci/simple/commit/6faa32e29e1bb756ef80dc6999d6233b91e580db#diff-e9a37319197dd60398b4f346df7b56f259d72b30bd8a92a2682701f0701198fbL259' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 62440029</div><div id='project'> Project Name: thomas-schillaci/simple</div><div id='commit'> Commit Name: 6faa32e29e1bb756ef80dc6999d6233b91e580db</div><div id='time'> Time: 2020-11-02</div><div id='author'> Author: thomas.schillaci@gmail.com</div><div id='file'> File Name: src/next_frame_predictor.py</div><div id='m_class'> M Class Name: NextFramePredictor</div><div id='n_method'> N Class Name: NextFramePredictor</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: Container</div><div id='n_parent_class'> N Parent Class: Container</div><div id='m_file'> M File Name: src/next_frame_predictor.py</div><div id='n_file'> N File Name: src/next_frame_predictor.py</div><div id='m_start'> M Start Line: 260</div><div id='m_end'> M End Line: 315</div><div id='n_start'> N Start Line: 317</div><div id='n_end'> N End Line: 363</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                e_tup = next(it_tup, None)
            &#47&#47 All triple notes with the same `n_tup` are added
            if number == 134:
                ic(<a id="change">lst[idx_tup_strt:]</a>)
            assert sum(len(tup) for tup in lst[idx_tup_strt:]) == len(elms_tup)
            &#47&#47 if number == 134:
            &#47&#47     exit(1)</code></pre><h3>After Change</h3><pre><code class='java'>
                    &#47&#47 Expect to be the same
                    if any(isinstance(n, Chord) for n in tup):
                        has_chord = True
                        opns<a id="change"> = </a><a id="change">[tuple(n.notes) if isinstance(n, Chord) else (n,) for n in tup]</a>
                        tups_new.extend(list(itertools.product(*opns)))
                if has_chord:  &#47&#47 Update prior triplet groups
                    lst = lst[:idx_tup_strt] + tups_new
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stefanheng/symbolic-music-generation/commit/7d2ebd5026f91738d46d1fc81d377d45420a5df8#diff-d695f4eee85e0c6394143835ebda0f848963d843fb77ab25aefdda75f0df044cL24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 62440033</div><div id='project'> Project Name: stefanheng/symbolic-music-generation</div><div id='commit'> Commit Name: 7d2ebd5026f91738d46d1fc81d377d45420a5df8</div><div id='time'> Time: 2022-01-31</div><div id='author'> Author: 43276957+SpongeBobBang@users.noreply.github.com</div><div id='file'> File Name: musicnlp/preprocess/music_extractor.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: expand_bar(3)</div><div id='n_method'> N Method Name: expand_bar(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: musicnlp/preprocess/music_extractor.py</div><div id='n_file'> N File Name: musicnlp/preprocess/music_extractor.py</div><div id='m_start'> M Start Line: 44</div><div id='m_end'> M End Line: 116</div><div id='n_start'> N Start Line: 44</div><div id='n_end'> N End Line: 141</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    for i in sampling_points:
        fc_list = []
        for _t in timeseries:
            fc = corrcoef(<a id="change">_t[i:i+window_size]</a>.T)
            if not self_loop: fc -= torch.eye(fc.shape[0])
            fc_list.append(fc)
        dynamic_fc_list.append(torch.stack(fc_list))</code></pre><h3>After Change</h3><pre><code class='java'>
        sampling_init = randrange(minibatch_timeseries.shape[1]-dynamic_length+1)
    sampling_points = list(range(sampling_init, sampling_init+dynamic_length-window_size, window_stride))

    minibatch_fc_list = <a id="change">[get_minibatch_fc(minibatch_timeseries, sampling_point, window_size, self_loop) for sampling_point in sampling_points]</a>
    dynamic_fc<a id="change"> = </a>torch.stack(minibatch_fc_list, dim=1)

    return dynamic_fc, sampling_points
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/egyptdj/stagin/commit/94aeea3f489d31eca5ddc1d4fe97d85777402c60#diff-159e40c9b370133fa00c703e61d2abb6de853222acc165839670d696488fe6a7L6' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 62440020</div><div id='project'> Project Name: egyptdj/stagin</div><div id='commit'> Commit Name: 94aeea3f489d31eca5ddc1d4fe97d85777402c60</div><div id='time'> Time: 2023-04-10</div><div id='author'> Author: egyptdj@yonsei.ac.kr</div><div id='file'> File Name: util/bold.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: process_dynamic_fc(6)</div><div id='n_method'> N Method Name: process_dynamic_fc(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: util/bold.py</div><div id='n_file'> N File Name: util/bold.py</div><div id='m_start'> M Start Line: 21</div><div id='m_end'> M End Line: 31</div><div id='n_start'> N Start Line: 34</div><div id='n_end'> N End Line: 39</div><BR>