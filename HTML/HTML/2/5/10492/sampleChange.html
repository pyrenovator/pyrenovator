<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Loop backward through decoding layers in order to work out the dimensions at each layer - in particular the first
        &#47&#47 linear layer needs to know B*current_size*current_size*channels
        for l_id in range(len(channels)):
            <a id="change">if l_id == len(channels) - 1</a>:
                layers.append(nn.Sequential(
                    nn.Linear(latent_dims, int(current_size * current_size * current_channels)),
                ))
            else:
                layers.append(nn.Sequential(
                    nn.ConvTranspose2d(
                        in_channels=channels[l_id],  &#47&#47 input height
                        out_channels=current_channels,
                        kernel_size=kernel_sizes[l_id],
                        stride=stride[l_id],  &#47&#47 filter movement/step
                        padding=padding[l_id],
                        &#47&#47 if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if
                        &#47&#47 stride=1
                    ),
                    nn.Sigmoid(),  &#47&#47 input shape (1, current_size, current_size)
                ))
                current_size<a id="change"> = </a>current_size / 2
                current_channels = channels[l_id]
        self.layers = nn.ModuleList(layers[::-1])
</code></pre><h3>After Change</h3><pre><code class='java'>
        current_size = feature_size[0]
        &#47&#47 Loop backward through decoding layers in order to work out the dimensions at each layer - in particular the first
        &#47&#47 linear layer needs to know B*current_size*current_size*channels
        for l_id, (channel, kernel, stride, padding) in <a id="change">reversed(</a>list(enumerate(zip(channels, kernel_sizes, strides, paddings)))<a id="change">)</a>:
            conv_layers.append(nn.Sequential(
                nn.ConvTranspose2d(
                    in_channels=channel,  &#47&#47 input height</code></pre>