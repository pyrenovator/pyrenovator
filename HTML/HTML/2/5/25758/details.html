<html><h3>Pattern ID :25758
</h3><img src='78002790.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            )

        &#47&#47 x.shape == (batch_size, target_seq_len, d_model)
        <a id="change">return </a>x
</code></pre><h3>After Change</h3><pre><code class='java'>
        output = pos_enc_tgt

        for i in range(self.num_layers):
            normed_output<a id="change"> = </a>self.layer_norm(output, **kwargs)
            output = output + self.dropout(
                self.attention[i](normed_output, normed_output, normed_output, target_mask, **kwargs),
                **kwargs,
            )
            normed_output = self.layer_norm(output, **kwargs)
            output = output<a id="change"> + </a>self.dropout(
                self.source_attention[i](normed_output, memory, memory, source_mask, **kwargs),
                **kwargs,
            )
            normed_output = self.layer_norm(output, **kwargs)
            output = output + self.dropout(self.position_feed_forward[i](normed_output, **kwargs), **kwargs)

        &#47&#47 (batch_size, seq_len, d_model)
        <a id="change">return </a><a id="change">self.layer_norm(</a>output<a id="change">, **kwargs)</a>
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/mindee/doctr/commit/9530f81d15395006b4844299236bdadba11c1dde#diff-e1106a3628d5365c5fe2e4fec7304ea8e40c58a5439f23d8f20513e722955178L160' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78002790</div><div id='project'> Project Name: mindee/doctr</div><div id='commit'> Commit Name: 9530f81d15395006b4844299236bdadba11c1dde</div><div id='time'> Time: 2022-07-01</div><div id='author'> Author: felixdittrich92@gmail.com</div><div id='file'> File Name: doctr/models/recognition/transformer/tensorflow.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: call(5)</div><div id='n_method'> N Method Name: call(5)</div><div id='m_parent_class'> M Parent Class: NestedObject,layers.Layer</div><div id='n_parent_class'> N Parent Class: tf.keras.layers.Layer</div><div id='m_file'> M File Name: doctr/models/recognition/transformer/tensorflow.py</div><div id='n_file'> N File Name: doctr/models/recognition/transformer/tensorflow.py</div><div id='m_start'> M Start Line: 251</div><div id='m_end'> M End Line: 265</div><div id='n_start'> N Start Line: 160</div><div id='n_end'> N End Line: 179</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            )

        &#47&#47 shape (batch_size, target_seq_len, d_model)
        <a id="change">return </a>x
</code></pre><h3>After Change</h3><pre><code class='java'>
            output = output + self.dropout(
                self.attention[i](normed_output, normed_output, normed_output, target_mask)
            )
            normed_output<a id="change"> = </a>self.layer_norm(output)
            output = output<a id="change"> + </a>self.dropout(
                self.source_attention[i](normed_output, memory, memory, source_mask)
            )
            normed_output = <a id="change">self.layer_norm(</a>output<a id="change">)</a>
            output = output + self.dropout(self.position_feed_forward[i](normed_output))

        <a id="change">return </a>self.layer_norm(output)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mindee/doctr/commit/fddceba7bee5098b4219b7ba6a0bdf4f4a98adfe#diff-5eb4b6b7a215017ac91351a0c5e665af04fa644ddf1ecd5037545ba096ec1337L69' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78002919</div><div id='project'> Project Name: mindee/doctr</div><div id='commit'> Commit Name: fddceba7bee5098b4219b7ba6a0bdf4f4a98adfe</div><div id='time'> Time: 2022-06-09</div><div id='author'> Author: felixdittrich92@gmail.com</div><div id='file'> File Name: doctr/models/recognition/transformer/pytorch.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: doctr/models/recognition/transformer/pytorch.py</div><div id='n_file'> N File Name: doctr/models/recognition/transformer/pytorch.py</div><div id='m_start'> M Start Line: 74</div><div id='m_end'> M End Line: 91</div><div id='n_start'> N Start Line: 147</div><div id='n_end'> N End Line: 167</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        &#47&#47 compute output
        att = (att_score @ v).view(batch_size, seg_len, -1)
        <a id="change">return </a>self.layer_norm(self.mlp(att) + x)
              
    def circulant_shift(self, x, shift):
        </code></pre><h3>After Change</h3><pre><code class='java'>
        
        &#47&#47 compute output
        att = (att_score @ v).view(batch_size, seg_len, -1)
        out<a id="change"> = </a>self.dropout(self.mlp(att))
        <a id="change">return </a><a id="change">self.layer_norm(</a>out<a id="change"> + </a>x<a id="change">)</a>
              
    def circulant_shift(self, x, shift):
        
        Shifts top row of `x` by `shift`, second row by `shift-1`, etc. This is</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/augustwester/transformer-xl/commit/cc7f32da8e71438812e757fbe2a131b14a5cfc2f#diff-eb7ae2070281ad9c6011e2b97c48b86fea6c48408aa6b0e9d20c8c520d3c7cf2L24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78002921</div><div id='project'> Project Name: augustwester/transformer-xl</div><div id='commit'> Commit Name: cc7f32da8e71438812e757fbe2a131b14a5cfc2f</div><div id='time'> Time: 2022-11-28</div><div id='author'> Author: august.wester@gmail.com</div><div id='file'> File Name: attention.py</div><div id='m_class'> M Class Name: MultiHeadAttention</div><div id='n_method'> N Class Name: MultiHeadAttention</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: attention.py</div><div id='n_file'> N File Name: attention.py</div><div id='m_start'> M Start Line: 28</div><div id='m_end'> M End Line: 51</div><div id='n_start'> N Start Line: 29</div><div id='n_end'> N End Line: 54</div><BR>