<html><h3>Pattern ID :22342
</h3><img src='70479539.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        out = torch.cat([state, action], 1)
        for i, layer in enumerate(self.networks):
            out = layer(out)
        <a id="change">return </a>state + out
    
    def predict(self, state, action):
        pass</code></pre><h3>After Change</h3><pre><code class='java'>

        mean = out[:, :self.output_dim]

        logvar = self.max_logvar<a id="change"> - </a><a id="change">F.softplus(</a>self.max_logvar - out[:, self.output_dim:]<a id="change">)</a>
        logvar<a id="change"> = </a>self.min_logvar<a id="change"> + </a>F.softplus(logvar - self.min_logvar)
        return mean, torch.exp(logvar)
    
    def predict(self, state, action):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/x35f/unstable_baselines/commit/a5871d3488b73457316980bf84fb817d1081de6d#diff-a9dbd33eecd80da366708c7eef0b5c971c7bbf89b5027a23e3382062f7632208L47' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70479539</div><div id='project'> Project Name: x35f/unstable_baselines</div><div id='commit'> Commit Name: a5871d3488b73457316980bf84fb817d1081de6d</div><div id='time'> Time: 2021-11-20</div><div id='author'> Author: 1621322691@qq.com</div><div id='file'> File Name: common/models.py</div><div id='m_class'> M Class Name: BaseModel</div><div id='n_method'> N Class Name: BaseModel</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: common/models.py</div><div id='n_file'> N File Name: common/models.py</div><div id='m_start'> M Start Line: 47</div><div id='m_end'> M End Line: 48</div><div id='n_start'> N Start Line: 57</div><div id='n_end'> N End Line: 63</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        results_pairwise = rearrange(results_pairwise, &quotb h n d -&gt; b n (h d)&quot, h = h)

        results = torch.cat((results_scalar, results_pairwise), dim = -1)
        <a id="change">return </a>single_repr
</code></pre><h3>After Change</h3><pre><code class='java'>
        point_qk_diff = rearrange(q_point, &quotb i d c -&gt; b i () d c&quot) - rearrange(k_point, &quotb j d c -&gt; b () j d c&quot)
        point_dist = (point_qk_diff ** 2).sum(dim = -2)

        point_weights = <a id="change">F.softplus(</a>self.point_weights<a id="change">)</a>
        point_weights = repeat(point_weights, &quoth -&gt; (b h) () () ()&quot, b = b)

        attn_logits_points = -0.5 * (point_dist<a id="change"> * </a>point_weights).sum(dim = -1)

        &#47&#47 combine attn logits

        attn_logits = attn_logits_scalar<a id="change"> + attn_logits_pairwise + </a>attn_logits_points

        &#47&#47 mask

        if exists(mask):
            mask = rearrange(mask, &quotb i -&gt; b i ()&quot) * rearrange(mask, &quotb j -&gt; b () j&quot)
            mask_value = max_neg_value(attn_logits)
            attn_logits = attn_logits.masked_fill(~mask, mask_value)

        &#47&#47 attention

        attn = attn_logits.softmax(dim = - 1)

        &#47&#47 aggregate values

        results_scalar = einsum(&quotb i j, b j d -&gt; b i d&quot, attn, v_scalar)

        attn_with_heads = rearrange(attn, &quot(b h) i j -&gt; b h i j&quot, h = h)
        results_pairwise = einsum(&quotb h i j, b i j d -&gt; b h i d&quot, attn_with_heads, pairwise_repr)

        &#47&#47 aggregate point values

        results_points = einsum(&quotb i j, b j d c -&gt; b i d c&quot, attn, v_point)

        &#47&#47 merge back heads

        results_scalar = rearrange(results_scalar, &quot(b h) n d -&gt; b n (h d)&quot, h = h)
        results_pairwise = rearrange(results_pairwise, &quotb h n d -&gt; b n (h d)&quot, h = h)
        results_points<a id="change"> = </a>rearrange(results_points, &quot(b h) n d c -&gt; b n (h d c)&quot, h = h)

        results = torch.cat((results_scalar, results_pairwise, results_points), dim = -1)
        return self.to_out(results)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/invariant-point-attention/commit/50b83b2cd424d6d78992e69936604801c9ad9f39#diff-0da2273b318a8de68ee540d826cb25884d25cde25c8c908cdf65788b98c2aac3L75' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70479569</div><div id='project'> Project Name: lucidrains/invariant-point-attention</div><div id='commit'> Commit Name: 50b83b2cd424d6d78992e69936604801c9ad9f39</div><div id='time'> Time: 2021-07-16</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: invariant_point_attention/invariant_point_attention.py</div><div id='m_class'> M Class Name: InvariantPointAttention</div><div id='n_method'> N Class Name: InvariantPointAttention</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: invariant_point_attention/invariant_point_attention.py</div><div id='n_file'> N File Name: invariant_point_attention/invariant_point_attention.py</div><div id='m_start'> M Start Line: 99</div><div id='m_end'> M End Line: 128</div><div id='n_start'> N Start Line: 87</div><div id='n_end'> N End Line: 148</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def forward(self, state):
        a = F.relu(self.l1(state))
        a = F.relu(self.l2(a))
        <a id="change">return </a>self.max_action * torch.tanh(self.l3(a))


class Critic(nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>
        action = a_distribution.rsample()

        logp_pi = a_distribution.log_prob(action).sum(axis=-1)
        logp_pi<a id="change"> -= </a>(2<a id="change"> * </a>(np<a id="change">.log(2) - action - </a><a id="change">F.softplus(</a>-2 * action<a id="change">)</a>)).sum(axis=1)
        logp_pi = torch.unsqueeze(logp_pi, dim=1)

        action = self.max_action * torch.tanh(action)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ryanxhr/dwbc/commit/7bf8e90c7bbf238b9a80c6c033844d37a17e898e#diff-75aa8d0a222c16ec3e4bb78749eef436b3d51c25ea931fe019fed10965e94549L20' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70479579</div><div id='project'> Project Name: ryanxhr/dwbc</div><div id='commit'> Commit Name: 7bf8e90c7bbf238b9a80c6c033844d37a17e898e</div><div id='time'> Time: 2022-06-24</div><div id='author'> Author: xuhaoran8@jd.com</div><div id='file'> File Name: algos/DWBC.py</div><div id='m_class'> M Class Name: Actor</div><div id='n_method'> N Class Name: Actor</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: algos/DWBC.py</div><div id='n_file'> N File Name: algos/DWBC.py</div><div id='m_start'> M Start Line: 22</div><div id='m_end'> M End Line: 23</div><div id='n_start'> N Start Line: 36</div><div id='n_end'> N End Line: 52</div><BR>