<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        loss = torch.sum(weight * (recons_loss + kld_weight * kld_loss), dim = 0)

        return <a id="change">{</a>&quotloss&quot: loss, &quotReconstruction Loss&quot:recons_loss.mean(0), &quotKLD&quot:-kld_loss<a id="change">}</a>

    def sample(self, batch_size:int, current_device: int) -&gt; Tensor:
        z = torch.randn(batch_size,
                        self.latent_dim)</code></pre><h3>After Change</h3><pre><code class='java'>
        kld_weight = kwargs[&quotM_N&quot] &#47&#47 Account for the minibatch samples from the dataset

        log_p_x_z = ((recons - input) ** 2).flatten(2).mean(-1) &#47&#47 Reconstruction Loss
        kld_loss = -0.5<a id="change"> * </a>torch.sum(1 + log_var - mu ** 2 - <a id="change">log_var.exp()</a>, dim=2)
        &#47&#47 Get importance weights
        log_weight = (log_p_x_z<a id="change"> + </a>kld_weight<a id="change"> * </a>kld_loss) &#47&#47.detach().data

        &#47&#47 Rescale the weights (along the sample dim) to lie in [0, 1] and sum to 1
        weight = F.softmax(log_weight, dim = -1)</code></pre>