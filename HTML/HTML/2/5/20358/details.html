<html><h3>Pattern ID :20358
</h3><img src='66029839.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                    loss_Dr1 = r1_penalty * (self.r1_gamma / 2)
                    loss_numpy[&quotloss_Dr1&quot] = loss_Dr1.cpu().detach().numpy().mean()

                loss4 = <a id="change">(loss_Dreal + loss_Dr1).mean()</a> * float(gain)
                &#47&#47 if do_Dmain:
                &#47&#47     loss4 += loss3
            with torch.autograd.profiler.record_function(name + &quot_backward&quot):</code></pre><h3>After Change</h3><pre><code class='java'>
                &#47&#47     loss4 += loss3
            with torch.autograd.profiler.record_function(name + &quot_backward&quot):
                &#47&#47 loss4.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。
                <a id="change">(real_logits * 0 + loss_Dreal + loss_Dr1).mean().mul(gain).backward()</a>
                if self.align_grad:
                    mapping = self.mapping.module if self.is_distributed else self.mapping
                    synthesis = self.synthesis.module if self.is_distributed else self.synthesis
                    discriminator = self.discriminator.module if self.is_distributed else self.discriminator</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/miemie2013/miemiegan/commit/308da226a2d1e0dc4f2c0543c80e1904d79a3bf1#diff-c3be3e49b4968a2ee433a8b0d38c7aa9f68d5116602220ff22567e41b765b44bL184' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66029839</div><div id='project'> Project Name: miemie2013/miemiegan</div><div id='commit'> Commit Name: 308da226a2d1e0dc4f2c0543c80e1904d79a3bf1</div><div id='time'> Time: 2022-04-09</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_class'> M Class Name: StyleGANv2ADAModel</div><div id='n_method'> N Class Name: StyleGANv2ADAModel</div><div id='m_method'> M Method Name: accumulate_gradients(9)</div><div id='n_method'> N Method Name: accumulate_gradients(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='n_file'> N File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_start'> M Start Line: 184</div><div id='m_end'> M End Line: 353</div><div id='n_start'> N Start Line: 208</div><div id='n_end'> N End Line: 356</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                loss_Dr1 = r1_penalty * (self.r1_gamma / 2)
                loss_numpy[&quotloss_Dr1&quot] = loss_Dr1.cpu().detach().numpy().mean()

            loss4 = <a id="change">(loss_Dreal + loss_Dr1).mean()</a> * float(gain)
            if do_Dmain:
                loss4 += loss3
            loss4.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 if do_Dmain:
            &#47&#47     loss4 += loss3
            &#47&#47 loss4.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。
            <a id="change">(real_logits * 0 + loss_Dreal + loss_Dr1).mean().mul(gain).backward()</a>
        return loss_numpy

    def train_iter(self, optimizers=None):
        phase_real_img = self.input[0]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/miemie2013/miemiegan/commit/cf43a0a8db722386b89e71d5d33b472774867ea1#diff-c3be3e49b4968a2ee433a8b0d38c7aa9f68d5116602220ff22567e41b765b44bL145' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66029835</div><div id='project'> Project Name: miemie2013/miemiegan</div><div id='commit'> Commit Name: cf43a0a8db722386b89e71d5d33b472774867ea1</div><div id='time'> Time: 2022-02-24</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_class'> M Class Name: StyleGANv2ADAModel</div><div id='n_method'> N Class Name: StyleGANv2ADAModel</div><div id='m_method'> M Method Name: accumulate_gradients(8)</div><div id='n_method'> N Method Name: accumulate_gradients(8)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='n_file'> N File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_start'> M Start Line: 148</div><div id='m_end'> M End Line: 236</div><div id='n_start'> N Start Line: 176</div><div id='n_end'> N End Line: 268</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 if do_Dmain:
            &#47&#47     loss4 += loss3
            &#47&#47 loss4.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。
            <a id="change">(real_logits * 0 + loss_Dreal + loss_Dr1).mean()</a>.mul(gain).backward()
        return loss_numpy

    def train_iter(self, optimizers=None):</code></pre><h3>After Change</h3><pre><code class='java'>
                loss_Dr1 = r1_penalty * (self.r1_gamma / 2)
                loss_numpy[&quotloss_Dr1&quot] = loss_Dr1.cpu().detach().numpy().mean()

            loss4 = (loss_Dreal<a id="change"> + </a>loss_Dr1).mean()<a id="change"> * </a>float(gain)
            &#47&#47 if do_Dmain:
            &#47&#47     loss4 += loss3
            <a id="change">loss4.backward()</a>  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。
        return loss_numpy

    def train_iter(self, optimizers=None):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/miemie2013/miemiegan/commit/fbc8738996ce75111be885ba7ac313d85969a2b8#diff-c3be3e49b4968a2ee433a8b0d38c7aa9f68d5116602220ff22567e41b765b44bL134' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66029863</div><div id='project'> Project Name: miemie2013/miemiegan</div><div id='commit'> Commit Name: fbc8738996ce75111be885ba7ac313d85969a2b8</div><div id='time'> Time: 2022-02-25</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_class'> M Class Name: StyleGANv2ADAModel</div><div id='n_method'> N Class Name: StyleGANv2ADAModel</div><div id='m_method'> M Method Name: accumulate_gradients(8)</div><div id='n_method'> N Method Name: accumulate_gradients(8)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='n_file'> N File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_start'> M Start Line: 138</div><div id='m_end'> M End Line: 260</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 262</div><BR>