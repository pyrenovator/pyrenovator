<html><h3>Pattern ID :2204
</h3><img src='9333322.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                        &#47&#47 FIXME: un-optimized clones
                        &#47&#47 NOTE: this happends on the main stream FIXME?
                        event = torch.cuda.Event(blocking=True)
                        <a id="change">with </a>torch<a id="change">.no_grad():
                            </a>t<a id="change"> = </a><a id="change">x.clone()</a>
                            event.record()

                        reuse_q = self.buffer_reuse_queues[receive_rank][self.rank]
                        &#47&#47 sync clone event</code></pre><h3>After Change</h3><pre><code class='java'>
                          is_activations):
        try:
            stream = self.grad_recv_stream if not is_activations else self.acti_recv_stream
            <a id="change">with </a>torch<a id="change">.cuda.stream(stream):
                </a>request_objects = []
                if not is_activations:
                    ranks_dict_items<a id="change"> = </a>reversed(ranks_dict_items)
                for (tensor_name, receive_ranks) in ranks_dict_items:
                    if not is_activations:
                        receive_ranks = reversed(receive_ranks)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/saareliad/ftpipe/commit/2cc10d5a34ef54c6fe4eb864a72f9063c1396579#diff-e8a3a19b1943afe92b627d303a564e72a2ad183b89af477fbd5c65031cec3416L162' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9333322</div><div id='project'> Project Name: saareliad/ftpipe</div><div id='commit'> Commit Name: 2cc10d5a34ef54c6fe4eb864a72f9063c1396579</div><div id='time'> Time: 2020-08-25</div><div id='author'> Author: saareliad@campus.technion.ac.il</div><div id='file'> File Name: pipeline/communication/multiprocessing.py</div><div id='m_class'> M Class Name: MultiprocessingCommunicationHandler</div><div id='n_method'> N Class Name: MultiprocessingCommunicationHandler</div><div id='m_method'> M Method Name: _recv_tensors_p2p(4)</div><div id='n_method'> N Method Name: _recv_tensors_p2p(5)</div><div id='m_parent_class'> M Parent Class: SimpleCommBase</div><div id='n_parent_class'> N Parent Class: SimpleCommBase</div><div id='m_file'> M File Name: pipeline/communication/multiprocessing.py</div><div id='n_file'> N File Name: pipeline/communication/multiprocessing.py</div><div id='m_start'> M Start Line: 171</div><div id='m_end'> M End Line: 235</div><div id='n_start'> N Start Line: 162</div><div id='n_end'> N End Line: 217</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                np.testing.assert_allclose(a, c)

    def test_scalar_fuse_unary(self):
        <a id="change">with </a>jt<a id="change">.profile_scope() as rep:
            </a>a = jt.array([1])
            b = -a
            a = a.clone()
            b<a id="change"> = </a><a id="change">b.clone()</a>
            jt.sync([a, b])
            assert a.data == 1
            assert b.data == -1
        assert len(rep) == 2</code></pre><h3>After Change</h3><pre><code class='java'>
    def test_scalar_fuse_unary(self):
        c = jt.ones(10)
        jt.sync_all()
        <a id="change">with </a>jt<a id="change">.profile_scope() as rep:
            </a>b<a id="change"> = </a>c-1
            assert b.data[1] == 0
        assert len(rep) == 2
        </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jittor/jittor/commit/88bb84255f00e272fd80126b9c29ef5cfbd09591#diff-bbbe77d996f1db9353924b23d9ce1c328f39cb30ef56208153740e5939767e4aL196' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9333319</div><div id='project'> Project Name: jittor/jittor</div><div id='commit'> Commit Name: 88bb84255f00e272fd80126b9c29ef5cfbd09591</div><div id='time'> Time: 2022-05-05</div><div id='author'> Author: randonlang@gmail.com</div><div id='file'> File Name: python/jittor/test/test_array.py</div><div id='m_class'> M Class Name: TestArray</div><div id='n_method'> N Class Name: TestArray</div><div id='m_method'> M Method Name: test_scalar_fuse_unary(1)</div><div id='n_method'> N Method Name: test_scalar_fuse_unary(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: python/jittor/test/test_array.py</div><div id='n_file'> N File Name: python/jittor/test/test_array.py</div><div id='m_start'> M Start Line: 197</div><div id='m_end'> M End Line: 205</div><div id='n_start'> N Start Line: 197</div><div id='n_end'> N End Line: 202</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        position_ids = position_ids.to(args.device)
        segment_ids = segment_ids.to(args.device)

        <a id="change">with </a>torch<a id="change">.no_grad():
            </a>if args.mlm:
                outputs<a id="change"> = </a>model(inputs, masked_lm_labels=labels, position_ids=position_ids, token_type_ids=segment_ids)
            else:
                if args.model_type == &quotbart&quot:
                    decoder_input_ids = labels[:, :-1].contiguous()
                    decoder_input_ids[decoder_input_ids == args.mlm_ignore_index] = tokenizer.pad_token_id
                    lm_labels<a id="change"> = </a><a id="change">labels[:, 1:].clone()</a>
                    outputs = model(inputs, labels=labels, lm_labels=lm_labels, decoder_input_ids=decoder_input_ids, position_ids=position_ids, token_type_ids=segment_ids)
                else:
                    outputs = model(inputs, labels=labels, position_ids=position_ids, token_type_ids=segment_ids)
            lm_loss = outputs[0]</code></pre><h3>After Change</h3><pre><code class='java'>
        position_ids = position_ids.to(args.device)
        segment_ids = segment_ids.to(args.device)

        <a id="change">with </a>torch<a id="change">.no_grad():
            </a>if args.model_type in [&quotbart&quot, &quotmbart&quot, &quotmarian&quot]:
                &#47&#47 decoder_input_ids = labels[:, :-1].contiguous()
                decoder_input_ids = shift_tokens_right(labels, args.mlm_ignore_index)
                decoder_input_ids[decoder_input_ids == args.mlm_ignore_index] = tokenizer.pad_token_id</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/b84a6548a69fd9f62652eed1c74fd4b1fdb8b65b#diff-90e760d3065758cd3fed35d36be801cfed8d2418d888df295dbecdc933432ad7L293' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9333316</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: b84a6548a69fd9f62652eed1c74fd4b1fdb8b65b</div><div id='time'> Time: 2020-11-15</div><div id='author'> Author: mehrad@stanford.edu</div><div id='file'> File Name: genienlp/paraphrase/run_lm_finetuning.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate(5)</div><div id='n_method'> N Method Name: evaluate(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: genienlp/paraphrase/run_lm_finetuning.py</div><div id='n_file'> N File Name: genienlp/paraphrase/run_lm_finetuning.py</div><div id='m_start'> M Start Line: 318</div><div id='m_end'> M End Line: 344</div><div id='n_start'> N Start Line: 330</div><div id='n_end'> N End Line: 369</div><BR>