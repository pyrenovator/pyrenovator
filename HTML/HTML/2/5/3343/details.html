<html><h3>Pattern ID :3343
</h3><img src='13061095.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    if trainer.is_main_process():
        click.secho(f"Measuring performance on {tracker_context}", fg="green", blink=True)

    <a id="change">with torch.no_grad()</a><a id="change">:
        </a>total_loss = 0.0
        total_samples = 0.0

        for image_embeddings, text_data in dataloader:
            image_embeddings = image_embeddings.to(trainer.device)
            text_data = text_data.to(trainer.device)

            batches = image_embeddings.shape[0]

            input_args = dict(image_embed=image_embeddings)

            if text_conditioned:
                input_args = dict(**input_args, text=text_data)
            else:
                input_args = dict(**input_args, text_embed=text_data)

            if use_ema:
                loss = trainer.ema_diffusion_prior(**input_args)
            else:
                loss = trainer(**input_args)

            total_loss<a id="change"> += </a>loss * batches
            total_samples += batches

        avg_loss = total_loss / total_samples</code></pre><h3>After Change</h3><pre><code class='java'>
    
    trainer.eval()

    use_ema = "ema"<a id="change"> if </a>use_ema<a id="change"> else </a>"online"
    tracker_folder = f"metrics/{use_ema}-{split}"

    &#47&#47 detemine if valid timesteps are passed</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/f9423d308b6f36e51152c2c45045ff4ebb308287#diff-283456789c9565d0a8ad235fc41b44188f310b3043c3bcdeb6678f1958a57b51L69' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 13061095</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: f9423d308b6f36e51152c2c45045ff4ebb308287</div><div id='time'> Time: 2022-07-20</div><div id='author'> Author: 51308183+nousr@users.noreply.github.com</div><div id='file'> File Name: train_diffusion_prior.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: eval_model(10)</div><div id='n_method'> N Method Name: eval_model(7)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_diffusion_prior.py</div><div id='n_file'> N File Name: train_diffusion_prior.py</div><div id='m_start'> M Start Line: 69</div><div id='m_end'> M End Line: 111</div><div id='n_start'> N Start Line: 367</div><div id='n_end'> N End Line: 428</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        else:
            &#47&#47 Run softmax again to get vocabulary logits
            &#47&#47 Not most efficient but less error-prone
            <a id="change">with torch.no_grad()</a><a id="change">:
                </a>sm_out<a id="change"> = </a>self.crit(pred_hid)
            prediction_scores = sm_out.view(bsz, tgt_len, -1)
        &#47&#47 ========================== End of modified ==========================
</code></pre><h3>After Change</h3><pre><code class='java'>
        _tgt_len = tgt_len
        if in_eval:
            _tgt_len -= 1
        prediction_scores = softmax_output.view(bsz, _tgt_len, -1)<a id="change"> if </a>(labels is None or in_eval)<a id="change"> else </a>()
        from stefutil import mic
        mic(prediction_scores)
        &#47&#47 ========================== Begin of modified ==========================</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stefanheng/symbolic-music-generation/commit/918a7d621f604e3e164f1f9e3a86bbb2df9ddfc3#diff-7d29a856c5e9e30825be17ece8e6d7ff393f00e120f33efa6f690086e89d13b0L107' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 13061101</div><div id='project'> Project Name: stefanheng/symbolic-music-generation</div><div id='commit'> Commit Name: 918a7d621f604e3e164f1f9e3a86bbb2df9ddfc3</div><div id='time'> Time: 2022-10-19</div><div id='author'> Author: stefan.hg@outlook.com</div><div id='file'> File Name: musicnlp/models/transformer_xl.py</div><div id='m_class'> M Class Name: MyTransfoXLLMHeadModel</div><div id='n_method'> N Class Name: MyTransfoXLLMHeadModel</div><div id='m_method'> M Method Name: forward(10)</div><div id='n_method'> N Method Name: forward(10)</div><div id='m_parent_class'> M Parent Class: TransfoXLLMHeadModel</div><div id='n_parent_class'> N Parent Class: TransfoXLLMHeadModel</div><div id='m_file'> M File Name: musicnlp/models/transformer_xl.py</div><div id='n_file'> N File Name: musicnlp/models/transformer_xl.py</div><div id='m_start'> M Start Line: 110</div><div id='m_end'> M End Line: 170</div><div id='n_start'> N Start Line: 150</div><div id='n_end'> N End Line: 211</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        else:
            &#47&#47 Run softmax again to get vocabulary logits
            &#47&#47 Not most efficient but less error-prone
            <a id="change">with torch.no_grad()</a><a id="change">:
                </a>sm_out<a id="change"> = </a>self.crit(pred_hid)
            prediction_scores = sm_out.view(bsz, tgt_len, -1)
        &#47&#47 ========================== End of modified ==========================
</code></pre><h3>After Change</h3><pre><code class='java'>
                labels[0, 1] = self.config.eos_token_id

        softmax_output = self.crit(pred_hid, labels)
        prediction_scores = softmax_output.view(bsz, tgt_len, -1)<a id="change"> if </a>labels is None<a id="change"> else </a>()

        if labels is not None:
            losses = softmax_output.view(bsz, tgt_len - 1)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stefanheng/symbolic-music-generation/commit/ca81780596a271b062d5e86e99be1c3c18534a07#diff-7d29a856c5e9e30825be17ece8e6d7ff393f00e120f33efa6f690086e89d13b0L80' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 13061099</div><div id='project'> Project Name: stefanheng/symbolic-music-generation</div><div id='commit'> Commit Name: ca81780596a271b062d5e86e99be1c3c18534a07</div><div id='time'> Time: 2022-05-26</div><div id='author'> Author: stefan.hg@outlook.com</div><div id='file'> File Name: musicnlp/models/transformer_xl.py</div><div id='m_class'> M Class Name: MyTransfoXLLMHeadModel</div><div id='n_method'> N Class Name: MyTransfoXLLMHeadModel</div><div id='m_method'> M Method Name: forward(10)</div><div id='n_method'> N Method Name: forward(10)</div><div id='m_parent_class'> M Parent Class: TransfoXLLMHeadModel</div><div id='n_parent_class'> N Parent Class: MusicTransformerMixin,TransfoXLLMHeadModel</div><div id='m_file'> M File Name: musicnlp/models/transformer_xl.py</div><div id='n_file'> N File Name: musicnlp/models/transformer_xl.py</div><div id='m_start'> M Start Line: 117</div><div id='m_end'> M End Line: 140</div><div id='n_start'> N Start Line: 190</div><div id='n_end'> N End Line: 190</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        with eval_model.module.backbone.register_forward_hook(feature_vector_hook):
            with eval_model.module.backbone.register_forward_hook(saliency_map_hook):
                for data in data_loader:
                    <a id="change">with torch.no_grad()</a><a id="change">:
                        </a>result<a id="change"> = </a>eval_model(return_loss=False, rescale=True, **data)
                    eval_predictions.extend(result)

        for key in [</code></pre><h3>After Change</h3><pre><code class='java'>
        metric = None
        if eval:
            metric = dataset.evaluate(eval_predictions, **cfg.evaluation)
            metric = metric[&quotmAP&quot]<a id="change"> if </a>isinstance(cfg.evaluation.metric, list)<a id="change"> else </a>metric[cfg.evaluation.metric]

        &#47&#47 Check and unwrap ImageTilingDataset object from TaskAdaptEvalDataset
        while hasattr(dataset, &quotdataset&quot) and not isinstance(dataset, ImageTilingDataset):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/openvinotoolkit/model_preparation_algorithm/commit/2f4fb6b91080d4b06f9134758206b3c48d4dfc54#diff-16a9a4573fb1c6b284bc5036e7b737679f1018138a97fa6a4d54c519d1a84642L73' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 13061098</div><div id='project'> Project Name: openvinotoolkit/model_preparation_algorithm</div><div id='commit'> Commit Name: 2f4fb6b91080d4b06f9134758206b3c48d4dfc54</div><div id='time'> Time: 2022-10-17</div><div id='author'> Author: eugene.liu@intel.com</div><div id='file'> File Name: mpa/det/inferrer.py</div><div id='m_class'> M Class Name: DetectionInferrer</div><div id='n_method'> N Class Name: DetectionInferrer</div><div id='m_method'> M Method Name: infer(5)</div><div id='n_method'> N Method Name: infer(5)</div><div id='m_parent_class'> M Parent Class: DetectionStage</div><div id='n_parent_class'> N Parent Class: DetectionStage</div><div id='m_file'> M File Name: mpa/det/inferrer.py</div><div id='n_file'> N File Name: mpa/det/inferrer.py</div><div id='m_start'> M Start Line: 97</div><div id='m_end'> M End Line: 196</div><div id='n_start'> N Start Line: 84</div><div id='n_end'> N End Line: 210</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                        &#47&#47 FIXME: un-optimized clones
                        &#47&#47 NOTE: this happends on the main stream FIXME?
                        event = torch.cuda.Event(blocking=True)
                        <a id="change">with torch.no_grad()</a><a id="change">:
                            </a>t<a id="change"> = </a>x.clone()
                            event.record()

                        reuse_q = self.buffer_reuse_queues[receive_rank][self.rank]</code></pre><h3>After Change</h3><pre><code class='java'>
    def _recv_tensors_p2p(self, batch_idx, ranks_dict_items,
                          is_activations):
        try:
            stream = self.grad_recv_stream<a id="change"> if </a>not is_activations<a id="change"> else </a>self.acti_recv_stream
            with torch.cuda.stream(stream):
                request_objects = []
                if not is_activations:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/saareliad/ftpipe/commit/2cc10d5a34ef54c6fe4eb864a72f9063c1396579#diff-e8a3a19b1943afe92b627d303a564e72a2ad183b89af477fbd5c65031cec3416L171' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 13061097</div><div id='project'> Project Name: saareliad/ftpipe</div><div id='commit'> Commit Name: 2cc10d5a34ef54c6fe4eb864a72f9063c1396579</div><div id='time'> Time: 2020-08-25</div><div id='author'> Author: saareliad@campus.technion.ac.il</div><div id='file'> File Name: pipeline/communication/multiprocessing.py</div><div id='m_class'> M Class Name: MultiprocessingCommunicationHandler</div><div id='n_method'> N Class Name: MultiprocessingCommunicationHandler</div><div id='m_method'> M Method Name: _recv_tensors_p2p(4)</div><div id='n_method'> N Method Name: _recv_tensors_p2p(5)</div><div id='m_parent_class'> M Parent Class: SimpleCommBase</div><div id='n_parent_class'> N Parent Class: SimpleCommBase</div><div id='m_file'> M File Name: pipeline/communication/multiprocessing.py</div><div id='n_file'> N File Name: pipeline/communication/multiprocessing.py</div><div id='m_start'> M Start Line: 171</div><div id='m_end'> M End Line: 235</div><div id='n_start'> N Start Line: 162</div><div id='n_end'> N End Line: 217</div><BR>