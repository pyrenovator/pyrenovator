<html><h3>Pattern ID :34174
</h3><img src='97597153.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def forward(self, text, view=False):
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = <a id="change">self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0</a>, <a id="change">1</a><a id="change">)</a>
            wave = self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0)
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, text, view=False):
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel, durations, pitch, energy = <a id="change">self.phone2mel(</a>phones<a id="change">, speaker_embedding=self.speaker_embedding, return_duration_pitch_energy=True)</a>
            mel = mel.transpose(0, 1)
            wave = self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0)
        if view:
            import matplotlib.pyplot as plt</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/4bbfcda47cf77f65ad0e557f8a06a174197d1bfc#diff-98c0a7845dd35e306bac5af5963f246159ffc54c9cc93cdac53373929d69df73L33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 97597153</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 4bbfcda47cf77f65ad0e557f8a06a174197d1bfc</div><div id='time'> Time: 2021-07-24</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/LJSpeech_FastSpeechInference.py</div><div id='m_class'> M Class Name: LJSpeech_FastSpeechInference</div><div id='n_method'> N Class Name: LJSpeech_FastSpeechInference</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/LJSpeech_FastSpeechInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/LJSpeech_FastSpeechInference.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 57</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def forward(self, text, view=False):
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = <a id="change">self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0</a>, <a id="change">1</a><a id="change">)</a>
            wave = self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0)
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, text, view=False):
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel, durations, pitch, energy = <a id="change">self.phone2mel(</a>phones<a id="change">, speaker_embedding=self.speaker_embedding, return_duration_pitch_energy=True)</a>
            mel = mel.transpose(0, 1)
            wave = self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0)
        if view:
            import matplotlib.pyplot as plt</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/4bbfcda47cf77f65ad0e557f8a06a174197d1bfc#diff-4b2f26f3d3287b567ffaec37b852ede237af7e76f93c389c33396f41ee6a1cf0L30' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 97597152</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 4bbfcda47cf77f65ad0e557f8a06a174197d1bfc</div><div id='time'> Time: 2021-07-24</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/Thorsten_FastSpeechInference.py</div><div id='m_class'> M Class Name: Thorsten_FastSpeechInference</div><div id='n_method'> N Class Name: Thorsten_FastSpeechInference</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/Thorsten_FastSpeechInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/Thorsten_FastSpeechInference.py</div><div id='m_start'> M Start Line: 32</div><div id='m_end'> M End Line: 41</div><div id='n_start'> N Start Line: 32</div><div id='n_end'> N End Line: 56</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def forward(self, text, view=False):
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = <a id="change">self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0</a>, <a id="change">1</a><a id="change">)</a>
            wave = self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0)
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, text, view=False):
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel, durations, pitch, energy = <a id="change">self.phone2mel(</a>phones<a id="change">, speaker_embedding=self.speaker_embedding, return_duration_pitch_energy=True)</a>
            mel = mel.transpose(0, 1)
            wave = self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0)
        if view:
            import matplotlib.pyplot as plt</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/4bbfcda47cf77f65ad0e557f8a06a174197d1bfc#diff-7d3b87a93b0bc1f791ef878d1df587515e570f34cd1a868873e0fd6e7f941af5L31' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 97597147</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 4bbfcda47cf77f65ad0e557f8a06a174197d1bfc</div><div id='time'> Time: 2021-07-24</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/Nancy_FastSpeechInference.py</div><div id='m_class'> M Class Name: Nancy_FastSpeechInference</div><div id='n_method'> N Class Name: Nancy_FastSpeechInference</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/Nancy_FastSpeechInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/Nancy_FastSpeechInference.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 57</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def forward(self, text, view=False):
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = <a id="change">self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0</a>, <a id="change">1</a><a id="change">)</a>
            wave = self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0)
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, text, view=False):
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel, durations, pitch, energy = <a id="change">self.phone2mel(</a>phones<a id="change">, speaker_embedding=self.speaker_embedding, return_duration_pitch_energy=True)</a>
            mel = mel.transpose(0, 1)
            wave = self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0)
        if view:
            import matplotlib.pyplot as plt</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/4bbfcda47cf77f65ad0e557f8a06a174197d1bfc#diff-74abc2e7bebe273ec5fa359ca3a9ef79f13947e109a095575f6b818f4e7f438cL32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 97597148</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 4bbfcda47cf77f65ad0e557f8a06a174197d1bfc</div><div id='time'> Time: 2021-07-24</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/LibriTTS_FastSpeechInference.py</div><div id='m_class'> M Class Name: LibriTTS_FastSpeechInference</div><div id='n_method'> N Class Name: LibriTTS_FastSpeechInference</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/LibriTTS_FastSpeechInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/LibriTTS_FastSpeechInference.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 34</div><div id='n_end'> N End Line: 58</div><BR>