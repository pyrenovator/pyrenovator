<html><h3>Pattern ID :19541
</h3><img src='63656393.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                 final_process=None,
                 device="cuda:0"):
        super(TCDNNet, self).__init__()
        <a id="change">if </a>len(att_layers) != <a id="change">len(</a>tc_layers<a id="change">)</a> + 1:
            raise RuntimeError("There must be one more attention layer than that of temporal convolution layers.")
        num_filters = int(m.ceil(m.log(seq_length, 2)))

        self.layers = nn.ModuleDict()
        channels = in_channels

        for i in range(len(tc_layers)):
            self.layers.add_module("attention_{}".format(i),
                                   AttentionBlock(channels, att_layers[i][0], att_layers[i][1], device))
            channels += att_layers[i][1]
            self.layers.add_module("tconv_{}".format(i),
                                   TCBlock(channels, seq_length, tc_layers[i], device))
            channels += num_filters * tc_layers[i]

        self.layers.add_module("attention_{}".format(len(att_layers)<a id="change">-1</a>),
                               AttentionBlock(channels, att_layers[-1][0], att_layers[-1][1], device))
        channels += att_layers[-1][1]
</code></pre><h3>After Change</h3><pre><code class='java'>
        channels += additional_length
        fc_layers = list(fc_layers) + [out_channels]

        self.layers.add_module("fc_amalgamate", <a id="change">nn.Linear(</a>seq_length, 1<a id="change">)</a>.to(device))
        for i in range(len(fc_layers)):
            self.layers.add_module("fc_{}".format(i), nn.Linear(channels, fc_layers[i]).to(device))
            channels = fc_layers[i]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/iffix/machin/commit/5b8d4a14723b753d9ee9d6dece151e40b3531c98#diff-b99a43ebb8bdea7f7a9ff2be74dc2b460878eec11cb5e5374efa147eedc92cf6L109' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63656393</div><div id='project'> Project Name: iffix/machin</div><div id='commit'> Commit Name: 5b8d4a14723b753d9ee9d6dece151e40b3531c98</div><div id='time'> Time: 2020-04-25</div><div id='author'> Author: hanhanmumuqq@163.com</div><div id='file'> File Name: models/base/tcdnnet.py</div><div id='m_class'> M Class Name: TCDNNet</div><div id='n_method'> N Class Name: TCDNNet</div><div id='m_method'> M Method Name: __init__(11)</div><div id='n_method'> N Method Name: __init__(11)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/base/tcdnnet.py</div><div id='n_file'> N File Name: models/base/tcdnnet.py</div><div id='m_start'> M Start Line: 109</div><div id='m_end'> M End Line: 139</div><div id='n_start'> N Start Line: 195</div><div id='n_end'> N End Line: 218</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        layers = []
        current_size = feature_size[0]
        current_channels = 1
        for l_id in range(<a id="change">len(</a>channels<a id="change">)</a>):
            <a id="change">if </a>l_id == len(channels) - 1:
                layers.append(nn.Sequential(
                    nn.Linear(int(current_size * current_size * current_channels), latent_dims),
                ))
            else:
                layers.append(nn.Sequential(  &#47&#47 input shape (1, current_size, current_size)
                    nn.Conv2d(
                        in_channels=current_channels,  &#47&#47 input height
                        out_channels=channels[l_id],  &#47&#47 n_filters
                        kernel_size=kernel_sizes[l_id],  &#47&#47 filter size
                        stride=stride[l_id],  &#47&#47 filter movement/step
                        padding=padding[l_id],
                        &#47&#47 if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if
                        &#47&#47 stride=1
                    ),  &#47&#47 output shape (out_channels, current_size, current_size)
                    nn.ReLU(),  &#47&#47 activation
                    nn.MaxPool2d(kernel_size=2),  &#47&#47 choose max value in 2x2 area, output shape (16, 14, 14)
                ))
                current_size = current_size<a id="change"> / 2</a>
                current_channels = channels[l_id]
        self.layers = nn.ModuleList(layers)

    def forward(self, x):</code></pre><h3>After Change</h3><pre><code class='java'>
                nn.Linear(int(current_size * current_size * current_channels), latent_dims),
            )
            self.fc_var = nn.Sequential(
                <a id="change">nn.Linear(</a>int(current_size * current_size * current_channels), latent_dims<a id="change">)</a>,
            )
        else:
            self.fc = nn.Sequential(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jameschapman19/cca_zoo/commit/a67b4d1253acfaa0d8f3b544104e7f329d975239#diff-3377d0e8ff2e3d41948279d51bf1d82b80f1f48aa340ab1418fd5248633b935eL116' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63656387</div><div id='project'> Project Name: jameschapman19/cca_zoo</div><div id='commit'> Commit Name: a67b4d1253acfaa0d8f3b544104e7f329d975239</div><div id='time'> Time: 2021-02-17</div><div id='author'> Author: james.chapman.19@ucl.ac.uk</div><div id='file'> File Name: cca_zoo/deep_models.py</div><div id='m_class'> M Class Name: CNNEncoder</div><div id='n_method'> N Class Name: CNNEncoder</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(8)</div><div id='m_parent_class'> M Parent Class: BaseEncoder</div><div id='n_parent_class'> N Parent Class: BaseEncoder</div><div id='m_file'> M File Name: cca_zoo/deep_models.py</div><div id='n_file'> N File Name: cca_zoo/deep_models.py</div><div id='m_start'> M Start Line: 116</div><div id='m_end'> M End Line: 154</div><div id='n_start'> N Start Line: 114</div><div id='n_end'> N End Line: 158</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    mlp = []
    for i in range(len(dims)-1):
        mlp.append(nn.Linear(dims[i], dims[i+1]))
        <a id="change">if </a>i&lt;<a id="change">len(</a>dims<a id="change">)</a>-2:
            mlp.append(nn.ReLU())
            if add_batchnorm:
                mlp.append(nn.BatchNorm1d(dims[i<a id="change">+1</a>]))
    return nn.Sequential(*mlp)

</code></pre><h3>After Change</h3><pre><code class='java'>
        ])
    else:
        return nn.Sequential(*[
            nn.Sequential(<a id="change">nn.Linear(</a>channels[i - 1], channels[i]<a id="change">)</a>, nn.ReLU())
            for i in range(1, len(channels))
        ])    
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mako443/text2pos-cvpr2022/commit/88c1c8af6aea88e3a9e528f30f519f4a6d1fbaef#diff-2dccda26e4003aa3a3dd764be0a7d33383f11dab88267e726c71f3be31479bc3L9' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63656388</div><div id='project'> Project Name: mako443/text2pos-cvpr2022</div><div id='commit'> Commit Name: 88c1c8af6aea88e3a9e528f30f519f4a6d1fbaef</div><div id='time'> Time: 2021-04-16</div><div id='author'> Author: manuel.kolmet@gmail.com</div><div id='file'> File Name: models/modules.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: get_mlp(2)</div><div id='n_method'> N Method Name: get_mlp(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: models/modules.py</div><div id='n_file'> N File Name: models/modules.py</div><div id='m_start'> M Start Line: 10</div><div id='m_end'> M End Line: 19</div><div id='n_start'> N Start Line: 21</div><div id='n_end'> N End Line: 30</div><BR>