<html><h3>Pattern ID :7824
</h3><img src='27922990.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        x_denoised = (
            self.c_skip(sigmas_padded) * x_noisy + self.c_out(sigmas_padded) * x_pred
        )
        x_denoised = x_denoised.clamp(-1.0, 1)<a id="change"> if </a>clamp<a id="change"> else </a>x_denoised

        return x_denoised
</code></pre><h3>After Change</h3><pre><code class='java'>
            return x_denoised.clamp(-1.0, 1.0)
        else:
            &#47&#47 Find dynamic threshold quantile for each batch
            x_flat = <a id="change">rearrange(</a>x_denoised, <a id="change">"b ... -&gt; b (...)"</a><a id="change">)</a>
            scale<a id="change"> = </a>torch.quantile(x_flat.abs(), self.dynamic_threshold, dim=-1)
            &#47&#47 Clamp to a min of 1.0
            scale.clamp_(min=1.0)
            &#47&#47 Clamp all values and scale
            scale<a id="change"> = </a>pad_dims(scale, ndim=x_denoised.ndim - scale.ndim)
            x_denoised = x_denoised.clamp(-scale, scale) / scale
            return x_denoised
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/archinetai/audio-diffusion-pytorch/commit/a5f1069e72d90085d0c07c57e803252966b0413d#diff-2678fbb2636c135caed9b7af07b32741ab81e9722df27eabaabefbc78db80f94L214' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 27922990</div><div id='project'> Project Name: archinetai/audio-diffusion-pytorch</div><div id='commit'> Commit Name: a5f1069e72d90085d0c07c57e803252966b0413d</div><div id='time'> Time: 2022-08-11</div><div id='author'> Author: flavio.schneider.97@gmail.com</div><div id='file'> File Name: audio_diffusion_pytorch/diffusion.py</div><div id='m_class'> M Class Name: Diffusion</div><div id='n_method'> N Class Name: Diffusion</div><div id='m_method'> M Method Name: denoise_fn(4)</div><div id='n_method'> N Method Name: denoise_fn(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: audio_diffusion_pytorch/diffusion.py</div><div id='n_file'> N File Name: audio_diffusion_pytorch/diffusion.py</div><div id='m_start'> M Start Line: 214</div><div id='m_end'> M End Line: 235</div><div id='n_start'> N Start Line: 223</div><div id='n_end'> N End Line: 241</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        dim_context = default(dim_context, dim)

        self.norm = LayerNorm(dim)
        self.context_norm = LayerNorm(dim_context)<a id="change"> if </a>norm_context<a id="change"> else </a>nn.Identity()

        self.attn_dropout = nn.Dropout(dropout)
</code></pre><h3>After Change</h3><pre><code class='java'>

        pos = torch.arange(window_size)
        grid = torch.stack(torch.meshgrid(pos, pos, indexing = &quotij&quot))
        grid = <a id="change">rearrange(</a>grid, <a id="change">&quotc i j -&gt; (i j) c&quot</a><a id="change">)</a>
        rel_pos<a id="change"> = </a>rearrange(grid, &quoti ... -&gt; i 1 ...&quot) - rearrange(grid, &quotj ... -&gt; 1 j ...&quot)
        rel_pos<a id="change"> += </a>window_size - 1
        rel_pos_indices = (rel_pos * torch.tensor([2 * window_size - 1, 1])).sum(dim = -1)

        self.register_buffer(&quotrel_pos_indices&quot, rel_pos_indices, persistent = False)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/robotic-transformer-pytorch/commit/1455daa18da596213bc36adc8c96dc1842624e46#diff-714add18c97f340060ba4a44bb66acab778a9d3cc68325e0c6d3c5d98e52ff8fL10' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 27923043</div><div id='project'> Project Name: lucidrains/robotic-transformer-pytorch</div><div id='commit'> Commit Name: 1455daa18da596213bc36adc8c96dc1842624e46</div><div id='time'> Time: 2022-12-14</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: robotic_transformer_pytorch/robotic_transformer_pytorch.py</div><div id='m_class'> M Class Name: Attention</div><div id='n_method'> N Class Name: Attention</div><div id='m_method'> M Method Name: __init__(5)</div><div id='n_method'> N Method Name: __init__(8)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: robotic_transformer_pytorch/robotic_transformer_pytorch.py</div><div id='n_file'> N File Name: robotic_transformer_pytorch/robotic_transformer_pytorch.py</div><div id='m_start'> M Start Line: 13</div><div id='m_end'> M End Line: 38</div><div id='n_start'> N Start Line: 134</div><div id='n_end'> N End Line: 167</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        cond_prob_drop = 0.
    ):
        batch_size, device = image_embed.shape[0], image_embed.device
        t = self.time_mlp(time)<a id="change"> if </a>exists(self.time_mlp)<a id="change"> else </a>None

        cond_prob_mask = prob_mask_like(batch_size, cond_prob_drop, device = device)
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 mask out image embedding depending on condition dropout
        &#47&#47 for classifier free guidance

        image_embed<a id="change"> = </a>torch.where(
            rearrange(cond_prob_mask, &quotb -&gt; b 1&quot),
            image_embed,
            <a id="change">rearrange(</a>self.null_image_embed, <a id="change">&quotd -&gt; 1 d&quot</a><a id="change">)</a>
        )

        cond<a id="change"> = </a>torch.cat((t, image_embed), dim = -1)

        hiddens = []
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/25d980ebbf1e22ce8396cdec400e22e83f754176#diff-038ecede954c29266888cb88e37cc06f61ba2433f8b5142c7b2b2cefde5ed0edL402' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 27922995</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: 25d980ebbf1e22ce8396cdec400e22e83f754176</div><div id='time'> Time: 2022-04-12</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: dalle2_pytorch/dalle2_pytorch.py</div><div id='m_class'> M Class Name: Unet</div><div id='n_method'> N Class Name: Unet</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dalle2_pytorch/dalle2_pytorch.py</div><div id='n_file'> N File Name: dalle2_pytorch/dalle2_pytorch.py</div><div id='m_start'> M Start Line: 411</div><div id='m_end'> M End Line: 414</div><div id='n_start'> N Start Line: 412</div><div id='n_end'> N End Line: 425</div><BR>