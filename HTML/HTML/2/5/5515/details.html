<html><h3>Pattern ID :5515
</h3><img src='19383510.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 could randomize -- even better would be to randomize in dataloader
        &#47&#47 might be expensive though
        note_ons = [(n.start, n.pitch, n.velocity, program) for n in inst.notes]
        note_offs = <a id="change">[(n.end, n.pitch, 0, program) for n in inst.notes]</a>
        <a id="change">inst_events.extend(</a>note_ons+note_offs<a id="change">)</a>
    if len(inst_events) &lt; 64:
        return
    time, pitch, vel, prog = zip(*sorted(inst_events))
    delta = torch.FloatTensor([0, *time]).diff(1)</code></pre><h3>After Change</h3><pre><code class='java'>
            
        &#47&#47 shorten all notes so they end 2*$margin before next (within pitch)
        for seq in nbp.values():
            <a id="change">for </a>i,n in <a id="change">enumerate(</a>seq[:-1]<a id="change">):
                </a>max_end = seq[i+1].start-2*time_margin
                if n.end &gt; max_end:
                    n.end = max_end
                &#47&#47 and flatten again</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/intelligent-instruments-lab/iil-python-tools/commit/78c2ab9e98adc304bebc8cff2541364d27d91dab#diff-8af53289ffb9f0e2a971a5b93eff5e24e5fe8ee26ecbc05887330392031aa724L19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19383510</div><div id='project'> Project Name: intelligent-instruments-lab/iil-python-tools</div><div id='commit'> Commit Name: 78c2ab9e98adc304bebc8cff2541364d27d91dab</div><div id='time'> Time: 2022-04-15</div><div id='author'> Author: victor.shepardson@gmail.com</div><div id='file'> File Name: notepredictor/scripts/lakh_prep_multitrack.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: process(1)</div><div id='n_method'> N Method Name: process(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: notepredictor/scripts/lakh_prep_multitrack.py</div><div id='n_file'> N File Name: notepredictor/scripts/lakh_prep_multitrack.py</div><div id='m_start'> M Start Line: 19</div><div id='m_end'> M End Line: 38</div><div id='n_start'> N Start Line: 22</div><div id='n_end'> N End Line: 50</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                section.entities.extend(entities)
                if self.entity_splitter:
                    split_ents = pydash.flatten(
                        <a id="change">[self.entity_splitter(x, section.get_text()) for x in entities]</a>
                    )
                    <a id="change">section.entities.extend(</a>split_ents<a id="change">)</a>
        except Exception:
            affected_doc_ids = [doc.idx for doc in docs]
            for doc in docs:
                message = (</code></pre><h3>After Change</h3><pre><code class='java'>
                all_words = ner_processed_section.to_tokenized_words(self.config.id2label)
                transformed_words = self.bio_preprocessor(all_words)
                for transformed_word in transformed_words:
                    <a id="change">for </a>i, label in <a id="change">enumerate(</a>transformed_word.word_labels_strings<a id="change">):
                        </a>if self.debug:
                            logger.info(
                                f"processing label: {label} for token {section.get_text()[transformed_word.word_offsets[i][0]:transformed_word.word_offsets[i][1]]}"
                            )</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/astrazeneca/kazu/commit/c06d9dfad81aea104f51e1918c1c3ce620d64cbf#diff-4f70f364a824447b60bf464f7b67ae2d963527c6e03e36a792bdf2ad67949174L185' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19383509</div><div id='project'> Project Name: astrazeneca/kazu</div><div id='commit'> Commit Name: c06d9dfad81aea104f51e1918c1c3ce620d64cbf</div><div id='time'> Time: 2022-11-30</div><div id='author'> Author: richard.jackson4@astrazeneca.com</div><div id='file'> File Name: kazu/steps/ner/hf_token_classification.py</div><div id='m_class'> M Class Name: TransformersModelForTokenClassificationNerStep</div><div id='n_method'> N Class Name: TransformersModelForTokenClassificationNerStep</div><div id='m_method'> M Method Name: _run(2)</div><div id='n_method'> N Method Name: _run(2)</div><div id='m_parent_class'> M Parent Class: BaseStep</div><div id='n_parent_class'> N Parent Class: BaseStep</div><div id='m_file'> M File Name: kazu/steps/ner/hf_token_classification.py</div><div id='n_file'> N File Name: kazu/steps/ner/hf_token_classification.py</div><div id='m_start'> M Start Line: 192</div><div id='m_end'> M End Line: 205</div><div id='n_start'> N Start Line: 163</div><div id='n_end'> N End Line: 190</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            batch_data = batch_data.to(config.device)
            batch_token_starts = batch_token_starts.to(config.device)
            batch_tags = batch_tags.to(config.device)
            <a id="change">sent_data.extend(</a>[<a id="change">[tokenizer.convert_ids_to_tokens(idx.item()) for idx in indices
                               if (idx.item() &gt; 0 and idx.item() != 101)]</a> for indices in batch_data]<a id="change">)</a>
            batch_masks = batch_data.gt(0)  &#47&#47 get padding mask
            &#47&#47 compute model output and loss
            loss = model((batch_data, batch_token_starts),
                         token_type_ids=None, attention_mask=batch_masks, labels=batch_tags)[0]</code></pre><h3>After Change</h3><pre><code class='java'>
            batch_tags = batch_tags.to(&quotcpu&quot).numpy()
            for i, indices in enumerate(np.argmax(batch_output, axis=2)):
                pred_tag = []
                <a id="change">for </a>j, idx in <a id="change">enumerate(</a>indices<a id="change">):
                    </a>if label_masks[i][j]:
                        pred_tag.append(id2label.get(idx))
                pred_tags.append(pred_tag)
            true_tags.extend([[id2label.get(idx) for idx in indices if idx &gt; -1] for indices in batch_tags])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hemingkx/wordseg/commit/148a03a62ebd0fc3dcbd4828b32aabd8ee76dc97#diff-13a1fbaf4d3a9ece7f1a03bc5edee62a33ad0fb1d42ea49968482079914bc388L77' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19383507</div><div id='project'> Project Name: hemingkx/wordseg</div><div id='commit'> Commit Name: 148a03a62ebd0fc3dcbd4828b32aabd8ee76dc97</div><div id='time'> Time: 2021-05-05</div><div id='author'> Author: hemingkx@gmail.com</div><div id='file'> File Name: BERT-Softmax/train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate(3)</div><div id='n_method'> N Method Name: evaluate(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: BERT-Softmax/train.py</div><div id='n_file'> N File Name: BERT-Softmax/train.py</div><div id='m_start'> M Start Line: 81</div><div id='m_end'> M End Line: 117</div><div id='n_start'> N Start Line: 80</div><div id='n_end'> N End Line: 125</div><BR>