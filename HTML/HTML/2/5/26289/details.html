<html><h3>Pattern ID :26289
</h3><img src='79042006.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.selected_features = config[&quotselected_features&quot]
        self.dataset = dataset
        self.device = config[&quotdevice&quot]
        self.item_feat<a id="change"> = </a><a id="change">dataset.get_item_feature().to(</a>self.device<a id="change">)</a>

        &#47&#47 need change the &quotload_col&quot config
        print(self.item_feat.interaction.keys()) &#47&#47 [&quotitem_id&quot &quotclass&quot]
        self.hidden_size = config[&quothidden_size&quot]</code></pre><h3>After Change</h3><pre><code class='java'>
        elif self.loss_type == &quotCE&quot:
            self.loss_fct = nn.CrossEntropyLoss()
        else:
            <a id="change">raise </a><a id="change">NotImplementedError("Make sure &quotloss_type&quot in [&quotBPR&quot, &quotCE&quot]!"</a><a id="change">)</a>

        self.initializer_range = config[&quotinitializer_range&quot]
        self.apply(self.init_weights)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/rucaibox/recbole/commit/50813513da4c5d1c81678862ec4a5f3b64ddf571#diff-fdb02c00f9b271adab6e04d4cd6ef252ca7a9d5187c419a7a907ecf2406f3a91L43' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 79042006</div><div id='project'> Project Name: rucaibox/recbole</div><div id='commit'> Commit Name: 50813513da4c5d1c81678862ec4a5f3b64ddf571</div><div id='time'> Time: 2020-10-14</div><div id='author'> Author: hui.wang@ruc.edu.cn</div><div id='file'> File Name: recbox/model/sequential_recommender/sasrecf.py</div><div id='m_class'> M Class Name: SASRecF</div><div id='n_method'> N Class Name: SASRecF</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: SequentialRecommender</div><div id='n_parent_class'> N Parent Class: SequentialRecommender</div><div id='m_file'> M File Name: recbox/model/sequential_recommender/sasrecf.py</div><div id='n_file'> N File Name: recbox/model/sequential_recommender/sasrecf.py</div><div id='m_start'> M Start Line: 43</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 70</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                &#47&#47 XXX: Breaking the self.model convention but I see no way around it for now.
                if ShardedDDPOption.AUTO_WRAP in self.args.sharded_ddp:
                    model = auto_wrap(model)
                self.model = model<a id="change"> = </a><a id="change">FullyShardedDDP(
                    model,
                    mixed_precision=mixed_precision,
                    reshard_after_forward=zero_3,
                    cpu_offload=cpu_offload,
                ).to(</a>self.args.device<a id="change">)</a>

        elif is_sagemaker_dp_enabled():
            model = DDP(model, device_ids=[dist.get_local_rank()], broadcast_buffers=False)
        elif self.args.local_rank != -1:</code></pre><h3>After Change</h3><pre><code class='java'>

    def _wrap_model(self, model, training=True):
        if is_sagemaker_mp_enabled():
            <a id="change">raise </a><a id="change">NotImplementedError(
                "Sagemaker&quots distrubuted data parallel features are not supported by `ORTTrainer` yet. Stay tuned!"</a><a id="change">
            )</a>

        &#47&#47 already initialized its own DDP and AMP
        if self.deepspeed:
            return self.deepspeed</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/optimum/commit/1c4b5b1caf1f1a58c32898ffb208538d7364b73a#diff-2fce6a27b91f51e97c2c1e0b4c9b86dae5896189543dac9e0a8e4f6cec6b62f9L1265' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 79042003</div><div id='project'> Project Name: huggingface/optimum</div><div id='commit'> Commit Name: 1c4b5b1caf1f1a58c32898ffb208538d7364b73a</div><div id='time'> Time: 2022-04-29</div><div id='author'> Author: 44135271+JingyaHuang@users.noreply.github.com</div><div id='file'> File Name: optimum/onnxruntime/trainer.py</div><div id='m_class'> M Class Name: ORTTrainer</div><div id='n_method'> N Class Name: ORTTrainer</div><div id='m_method'> M Method Name: _wrap_model(3)</div><div id='n_method'> N Method Name: _wrap_model(3)</div><div id='m_parent_class'> M Parent Class: Trainer</div><div id='n_parent_class'> N Parent Class: Trainer</div><div id='m_file'> M File Name: optimum/onnxruntime/trainer.py</div><div id='n_file'> N File Name: optimum/onnxruntime/trainer.py</div><div id='m_start'> M Start Line: 1268</div><div id='m_end'> M End Line: 1315</div><div id='n_start'> N Start Line: 1233</div><div id='n_end'> N End Line: 1267</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 If sigma provided use the same for all batch items (used for sampling)
        if exists(sigma):
            sigmas = <a id="change">torch.full(size=(batch,), fill_value=sigma).to(</a>device<a id="change">)</a>

        assert exists(sigmas)

        &#47&#47 Predict network output and add skip connection
        c_skip<a id="change">, c_out, c_in, c_noise = </a>self.get_scale_weights(sigmas)
        x_pred = self.net(c_in * x_noisy, c_noise, **kwargs)
        x_denoised = c_skip * x_noisy + c_out * x_pred
</code></pre><h3>After Change</h3><pre><code class='java'>
        sigma: Optional[float] = None,
        **kwargs,
    ) -&gt; Tensor:
        <a id="change">raise </a><a id="change">NotImplementedError("Diffusion class missing denoise_fn"</a><a id="change">)</a>

    def forward(self, x: Tensor, noise: Tensor = None, **kwargs) -&gt; Tensor:
        raise NotImplementedError("Diffusion class missing forward function")
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/archinetai/audio-diffusion-pytorch/commit/68da808cd7e5acb5c571cf14ccefecb3ddceec5b#diff-2678fbb2636c135caed9b7af07b32741ab81e9722df27eabaabefbc78db80f94L269' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 79042000</div><div id='project'> Project Name: archinetai/audio-diffusion-pytorch</div><div id='commit'> Commit Name: 68da808cd7e5acb5c571cf14ccefecb3ddceec5b</div><div id='time'> Time: 2022-10-08</div><div id='author'> Author: flavio.schneider.97@gmail.com</div><div id='file'> File Name: audio_diffusion_pytorch/diffusion.py</div><div id='m_class'> M Class Name: Diffusion</div><div id='n_method'> N Class Name: Diffusion</div><div id='m_method'> M Method Name: denoise_fn(4)</div><div id='n_method'> N Method Name: denoise_fn(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: audio_diffusion_pytorch/diffusion.py</div><div id='n_file'> N File Name: audio_diffusion_pytorch/diffusion.py</div><div id='m_start'> M Start Line: 276</div><div id='m_end'> M End Line: 305</div><div id='n_start'> N Start Line: 106</div><div id='n_end'> N End Line: 106</div><BR>