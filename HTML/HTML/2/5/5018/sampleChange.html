<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
class net_pars:
    def __init__(self,nets):
        &#47&#47 select a network setting
        if <a id="change">(nets == &quotoptim&quot) or (nets == &quotoptim_adsig&quot)</a> :
            &#47&#47 the optimized network settings
            self.dropout = 0.1 &#47&#470.0/0.1 chose how much dropout one likes. 0=no dropout; internet says roughly 20% (0.20) is good, although it also states that smaller networks might desire smaller amount of dropout
            self.batch_norm = True &#47&#47 False/True turns on batch normalistion</code></pre><h3>After Change</h3><pre><code class='java'>
            self.fitS0 = False &#47&#47 indicates whether to fit S0 (True) or fix it to 1 (for normalised signals); I prefer fitting S0 as it takes along the potential error is S0.
            self.depth = 4 &#47&#47 number of layers
            self.width = 500 &#47&#47 new option that determines network width. Putting to 0 makes it as wide as the number of b-values
        boundsrange<a id="change"> = </a>0.3 * np.array(self.cons_max)-<a id="change">np.array(</a>self.cons_min<a id="change">)</a> &#47&#47 ensure that we are on the most lineair bit of the sigmoid function
        self.cons_min = np.array(self.cons_min) - boundsrange
        self.cons_max<a id="change"> = </a>np.array(self.cons_max) + boundsrange


</code></pre>