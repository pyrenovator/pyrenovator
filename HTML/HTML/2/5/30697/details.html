<html><h3>Pattern ID :30697
</h3><img src='90523491.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    
    n_gram = None
    for i in range(0, n):
        <a id="change">if i == (n - 1)</a>:
            last_sample = None
        else:
            last_sample = <a id="change">-(n - i - 1)</a>
        sample = permute(input[..., i:last_sample, :], shifts=n - i - 1)
        if n_gram is None:
            n_gram = sample
        else:</code></pre><h3>After Change</h3><pre><code class='java'>
    
    n_gram = permute(input[..., :-(n-1), :], shifts=n-1)
    for i in range(1, n-1):
        <a id="change">n_gram.mul_(</a>permute(input[..., i:-(n-1 - i), :], shifts=n-1 - i)<a id="change">)</a>
    n_gram.mul_(input[...,n-1:,:])
    return multiset(n_gram)

</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/hyperdimensional-computing/torchhd/commit/ff34552916de3293f970a4a393ebd9efe8e5fa0f#diff-2eec1c18711dc8b77e517b45771208f50de1693b062b658d75343e8e081d67cdL488' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 90523491</div><div id='project'> Project Name: hyperdimensional-computing/torchhd</div><div id='commit'> Commit Name: ff34552916de3293f970a4a393ebd9efe8e5fa0f</div><div id='time'> Time: 2022-05-16</div><div id='author'> Author: linxinyuan@gmail.com</div><div id='file'> File Name: torchhd/functional.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: ngrams(2)</div><div id='n_method'> N Method Name: ngrams(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchhd/functional.py</div><div id='n_file'> N File Name: torchhd/functional.py</div><div id='m_start'> M Start Line: 488</div><div id='m_end'> M End Line: 499</div><div id='n_start'> N Start Line: 488</div><div id='n_end'> N End Line: 491</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.running_var.fill_(1)
    
    def forward(self, x):
        <a id="change">if x.dim() != 4</a>:
            raise ValueError(&quotexpected 4D input (got {}D input)&quot
                             .format(x.dim()))
        if self.version == &quotS0&quot:
            if self.non_linear:
                num = x * torch.sigmoid(self.v * x)
                return num / group_std(x, eps = self.eps) * self.gamma + self.beta
            else:
                return x * self.gamma + self.beta
        if self.version == &quotB0&quot:
            if self.training:
                var = torch.var(x, dim = (0, 2, 3), unbiased = False, keepdim = True).reshape(1, x.size(1), 1, 1)
                with torch.no_grad():
                   self.running_var.copy_(self<a id="change">.momentum * self.running_var + </a>(1 - self.momentum) * var)
            else:
                var = self.running_var
</code></pre><h3>After Change</h3><pre><code class='java'>
        if self.version == &quotB0&quot:
            if self.training:
                var = torch.var(x, dim = (0, 2, 3), unbiased = False, keepdim = True)
                <a id="change">self.running_var.mul_(</a>self.momentum<a id="change">)</a>
                self.running_var.add_((1 - self.momentum) * var)
            else:
                var = self.running_var</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digantamisra98/evonorm/commit/2b8670c5ace4245b2ce8c234d59a26f6fba1b29a#diff-3e603d8ee6e954d92d8ca2340dc887ad739428240f8c52b56be403bbc30e64e6L37' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 90523510</div><div id='project'> Project Name: digantamisra98/evonorm</div><div id='commit'> Commit Name: 2b8670c5ace4245b2ce8c234d59a26f6fba1b29a</div><div id='time'> Time: 2020-04-25</div><div id='author'> Author: mishradiganta91@gmail.com</div><div id='file'> File Name: evonorm2d.py</div><div id='m_class'> M Class Name: EvoNorm2D</div><div id='n_method'> N Class Name: EvoNorm2D</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: evonorm2d.py</div><div id='n_file'> N File Name: evonorm2d.py</div><div id='m_start'> M Start Line: 38</div><div id='m_end'> M End Line: 52</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 61</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    runs with success, but needs further validation and possibly optimization for lower runtime impact.

    
    <a id="change">if drop_prob == 0.</a> or not training:
        return x
    _, _, height, width = x.shape
    total_size = width<a id="change"> * </a>height
    clipped_block_size = min(block_size, min(width, height))
    &#47&#47 seed_drop_rate, the gamma parameter
    seed_drop_rate = gamma_scale * drop_prob * total_size / clipped_block_size ** 2 / (
            (width - block_size + 1) *
            (height - block_size + 1))

    &#47&#47 Forces the block to be inside the feature map.
    w_i, h_i = torch.meshgrid(torch.arange(width).to(x.device), torch.arange(height).to(x.device))
    valid_block = ((w_i &gt;= clipped_block_size // 2) & (w_i &lt; width - (clipped_block_size - 1) // 2)) & \
                  ((h_i &gt;= clipped_block_size // 2) & (h_i &lt; height - (clipped_block_size - 1) // 2))
    valid_block = torch.reshape(valid_block, (1, 1, height, width)).float()

    uniform_noise = torch.rand_like(x, dtype=torch.float32)
    block_mask = ((2 - seed_drop_rate - valid_block + uniform_noise) &gt;= 1).float()
    block_mask = -F.max_pool2d(
        -block_mask,
        kernel_size=clipped_block_size,  &#47&#47 block_size, ???
        stride=1,
        padding=clipped_block_size // 2)

    if drop_with_noise:
        normal_noise = torch.randn_like(x)
        x = x * block_mask + normal_noise * (1 - block_mask)
    else:
        normalize_scale = block_mask.numel() / (torch.sum(block_mask)<a id="change"> + </a>1e-7)
        x = x * block_mask * normalize_scale
    return x
</code></pre><h3>After Change</h3><pre><code class='java'>
    else:
        normalize_scale = (block_mask.numel() / block_mask.to(dtype=torch.float32).sum().add(1e-7)).to(x.dtype)
        if inplace:
            <a id="change">x.mul_(</a>block_mask * normalize_scale<a id="change">)</a>
        else:
            x = x * block_mask * normalize_scale
    return x
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/feng-lab/pytorch-image-models/commit/1904ed8fecdb3f37818378421350315d2abf1224#diff-9431741d608429ed80ae9a820816fda52965a3227c7819c89a44ac86ecac9db5L24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 90523500</div><div id='project'> Project Name: feng-lab/pytorch-image-models</div><div id='commit'> Commit Name: 1904ed8fecdb3f37818378421350315d2abf1224</div><div id='time'> Time: 2020-05-13</div><div id='author'> Author: rwightman@gmail.com</div><div id='file'> File Name: timm/models/layers/drop.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: drop_block_2d(7)</div><div id='n_method'> N Method Name: drop_block_2d(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: timm/models/layers/drop.py</div><div id='n_file'> N File Name: timm/models/layers/drop.py</div><div id='m_start'> M Start Line: 25</div><div id='m_end'> M End Line: 62</div><div id='n_start'> N Start Line: 26</div><div id='n_end'> N End Line: 69</div><BR>