<html><h3>Pattern ID :33174
</h3><img src='95881078.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Cal PSNR
        total_psnr += 10. * torch.log10(1. / torch.mean((sr_tensor_y - hr_tensor_y) ** 2))

        sr_image_y = <a id="change">sr_tensor_y.mul_(255.0).cpu()</a>.squeeze_(0).squeeze_(0).numpy()
        sr_image = np.array([sr_image_y, bic_ycbcr[..., 1], bic_ycbcr[..., 2]]).transpose([1, 2, 0])
        sr_image = np.clip(imgproc.convert_ycbcr_to_rgb(sr_image), 0.0, 255.0).astype(np.uint8)
        sr_image = Image.fromarray(sr_image)</code></pre><h3>After Change</h3><pre><code class='java'>
        hr_image = Image.open(hr_image_path).convert("RGB")
        hr_image_width = hr_image.width // config.upscale_factor * config.upscale_factor
        hr_image_height = hr_image.height // config.upscale_factor * config.upscale_factor
        hr_image<a id="change"> = </a>hr_image.resize([hr_image_width, hr_image_height], Image.BICUBIC)

        lr_image = hr_image.resize([hr_image.width // config.upscale_factor, hr_image.height // config.upscale_factor], Image.BICUBIC)
        bic_image = lr_image.resize([hr_image.width, hr_image.height], Image.BICUBIC)

        &#47&#47 Extract Y channel lr image data.
        lr_image = np.array(lr_image).astype(np.float32)
        lr_ycbcr = imgproc.convert_rgb_to_ycbcr(lr_image)
        lr_y_image = lr_ycbcr[..., 0]
        lr_y_image /= 255.
        lr_y_tensor = torch.from_numpy(lr_y_image).to(config.device).unsqueeze(0).unsqueeze(0)
        lr_y_tensor<a id="change"> = </a><a id="change">lr_y_tensor.half()</a>

        &#47&#47 Extract Y channel bicubic image data.
        bic_image = np.array(bic_image).astype(np.float32)
        bic_ycbcr = imgproc.convert_rgb_to_ycbcr(bic_image)

        &#47&#47 Extract Y channel hr image data.
        hr_image = np.array(hr_image).astype(np.float32)
        hr_ycbcr = imgproc.convert_rgb_to_ycbcr(hr_image)
        hr_y_image = hr_ycbcr[..., 0]
        hr_y_image /= 255.
        hr_y_tensor = torch.from_numpy(hr_y_image).to(config.device).unsqueeze(0).unsqueeze(0)
        hr_y_tensor<a id="change"> = </a>hr_y_tensor.half()

        &#47&#47 Only reconstruct the Y channel image data.
        with torch.no_grad():</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lornatang/fsrcnn-pytorch/commit/5a0ecdd432cc264e98e446689348e5565a84ac1f#diff-58b7fc05c0526d9a9b3c0b50dda416fcbf0a654e696da4b6df82cbb5a6b2dcfcL53' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 95881078</div><div id='project'> Project Name: lornatang/fsrcnn-pytorch</div><div id='commit'> Commit Name: 5a0ecdd432cc264e98e446689348e5565a84ac1f</div><div id='time'> Time: 2021-11-19</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: validate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: validate.py</div><div id='n_file'> N File Name: validate.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 95</div><div id='n_start'> N Start Line: 63</div><div id='n_end'> N End Line: 98</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            gain = 1.0
            scale = 1.0
            if "ln_" in n or ".ln" in n or "time_" in n or "_mask" in n:
                m[n] = <a id="change">p.cpu()</a>
                continue
            elif n == "emb.weight":
                scale = -25 * self.args.lr_init
            else:</code></pre><h3>After Change</h3><pre><code class='java'>
                else:
                    nn.init.orthogonal_(m[n], gain=gain * scale)

            m[n]<a id="change"> = </a>m[n].cpu()
            if os.environ["RWKV_FLOAT_MODE"] == "fp16":
                m[n]<a id="change"> = </a><a id="change">m[n].half()</a>
            elif os.environ["RWKV_FLOAT_MODE"] == "bf16":
                m[n]<a id="change"> = </a>m[n].bfloat16()

            &#47&#47 if n == "emb.weight":
            &#47&#47     print(m[n])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/blinkdl/rwkv-lm/commit/cdb098c0e057e75082e2785972219f320fb4e282#diff-6eba7ffecaf7b1f3c9b254a3089d1dc3373b8e48e81e829d8432bac461ca416aL324' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 95881059</div><div id='project'> Project Name: blinkdl/rwkv-lm</div><div id='commit'> Commit Name: cdb098c0e057e75082e2785972219f320fb4e282</div><div id='time'> Time: 2022-09-05</div><div id='author'> Author: a@a.com</div><div id='file'> File Name: RWKV-v4neo/src/model.py</div><div id='m_class'> M Class Name: RWKV</div><div id='n_method'> N Class Name: RWKV</div><div id='m_method'> M Method Name: generate_init_weight(1)</div><div id='n_method'> N Method Name: generate_init_weight(1)</div><div id='m_parent_class'> M Parent Class: pl.LightningModule</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: RWKV-v4neo/src/model.py</div><div id='n_file'> N File Name: RWKV-v4neo/src/model.py</div><div id='m_start'> M Start Line: 336</div><div id='m_end'> M End Line: 376</div><div id='n_start'> N Start Line: 335</div><div id='n_end'> N End Line: 382</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Cal PSNR
        total_psnr += 10. * torch.log10(1. / torch.mean((sr_tensor_y - lr_tensor_y) ** 2))

        sr_image_y = <a id="change">sr_tensor_y.mul_(255.0).cpu()</a>.squeeze_(0).squeeze_(0).numpy()
        sr_image = np.array([sr_image_y, lr_ycbcr[..., 1], lr_ycbcr[..., 2]]).transpose([1, 2, 0])
        sr_image = np.clip(imgproc.convert_ycbcr_to_rgb(sr_image), 0.0, 255.0).astype(np.uint8)
        sr_image = Image.fromarray(sr_image)</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 Extract Y channel hr image data.
        hr_image = np.array(hr_image).astype(np.float32)
        hr_ycbcr<a id="change"> = </a>imgproc.convert_rgb_to_ycbcr(hr_image)
        hr_y_image = hr_ycbcr[..., 0]
        hr_y_image<a id="change"> /= </a>255.
        hr_y_tensor = torch.from_numpy(hr_y_image).to(config.device).unsqueeze(0).unsqueeze(0)
        hr_y_tensor<a id="change"> = </a><a id="change">hr_y_tensor.half()</a>

        &#47&#47 Only reconstruct the Y channel image data.
        with torch.no_grad():
            sr_y_tensor = model(lr_y_tensor)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/vdsr-pytorch/commit/4a9bc788a52873e287460db8207a3c5dd5543870#diff-58b7fc05c0526d9a9b3c0b50dda416fcbf0a654e696da4b6df82cbb5a6b2dcfcL27' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 95881056</div><div id='project'> Project Name: lornatang/vdsr-pytorch</div><div id='commit'> Commit Name: 4a9bc788a52873e287460db8207a3c5dd5543870</div><div id='time'> Time: 2021-11-19</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: validate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: validate.py</div><div id='n_file'> N File Name: validate.py</div><div id='m_start'> M Start Line: 66</div><div id='m_end'> M End Line: 84</div><div id='n_start'> N Start Line: 66</div><div id='n_end'> N End Line: 95</div><BR>