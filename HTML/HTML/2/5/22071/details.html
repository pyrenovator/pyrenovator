<html><h3>Pattern ID :22071
</h3><img src='70016509.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        source_text = batch_data[&quotsource_text&quot]
        for text in source_text:
            text = &quot &quot.join(text)
            encoding_dict<a id="change"> = </a><a id="change">self.tokenizer(</a>text<a id="change">, return_tensors=&quotpt&quot)</a>
            input_ids = encoding_dict[&quotinput_ids&quot].to(self.device)

            output_ids = self.model.generate(input_ids, max_length=self.max_target_length, early_stopping=True)
</code></pre><h3>After Change</h3><pre><code class='java'>
            input_ids, attention_mask=attn_masks, num_beams=5, max_length=self.max_target_length, early_stopping=True
        )
        generated_text = self.tokenizer.batch_decode(sample_outputs, skip_special_tokens=True)
        generate_corpus<a id="change"> = </a><a id="change">[text.lower().split() for text in generated_text]</a>
        return generate_corpus

    def tokenize_text(self, text):
        input_ids = []</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/47a1a3dc1eee71dd585124dbf1786e2508d34561#diff-256d1cc3e26719e1a4665d427f3287df187da7886f0bdca794d1e8832f37233cL38' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70016509</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 47a1a3dc1eee71dd585124dbf1786e2508d34561</div><div id='time'> Time: 2021-04-15</div><div id='author'> Author: 1020139164@qq.com</div><div id='file'> File Name: textbox/model/Seq2Seq/prophetnet.py</div><div id='m_class'> M Class Name: ProphetNet</div><div id='n_method'> N Class Name: ProphetNet</div><div id='m_method'> M Method Name: generate(3)</div><div id='n_method'> N Method Name: generate(3)</div><div id='m_parent_class'> M Parent Class: Seq2SeqGenerator</div><div id='n_parent_class'> N Parent Class: Seq2SeqGenerator</div><div id='m_file'> M File Name: textbox/model/Seq2Seq/prophetnet.py</div><div id='n_file'> N File Name: textbox/model/Seq2Seq/prophetnet.py</div><div id='m_start'> M Start Line: 38</div><div id='m_end'> M End Line: 50</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 45</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        source_text = batch_data["source_text"]
        for text in source_text:
            sentence = &quot &quot.join(text)
            encoding_dict<a id="change"> = </a><a id="change">self.tokenizer(</a>sentence<a id="change">, return_tensors="pt")</a>
            input_ids = encoding_dict[&quotinput_ids&quot].to(self.device)
            sample_outputs = self.decoder.generate(
                input_ids, num_beams=5, max_length=self.max_target_length, early_stopping=True
            )</code></pre><h3>After Change</h3><pre><code class='java'>
            input_ids, attention_mask=attn_masks, num_beams=5, max_length=self.max_target_length, early_stopping=True
        )
        generated_text = self.tokenizer.batch_decode(sample_outputs, skip_special_tokens=True)
        generate_corpus<a id="change"> = </a><a id="change">[text.lower().split() for text in generated_text]</a>
        return generate_corpus

    def tokenize_text(self, text):
        texts = [&quot &quot.join(t) for t in text]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/47a1a3dc1eee71dd585124dbf1786e2508d34561#diff-cb6154a8f614953fc099f2d791b0b41c862387b24dc8dc538bfe98ebbaa4a3b7L42' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70016517</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 47a1a3dc1eee71dd585124dbf1786e2508d34561</div><div id='time'> Time: 2021-04-15</div><div id='author'> Author: 1020139164@qq.com</div><div id='file'> File Name: textbox/model/Seq2Seq/bart.py</div><div id='m_class'> M Class Name: BART</div><div id='n_method'> N Class Name: BART</div><div id='m_method'> M Method Name: generate(3)</div><div id='n_method'> N Method Name: generate(3)</div><div id='m_parent_class'> M Parent Class: Seq2SeqGenerator</div><div id='n_parent_class'> N Parent Class: Seq2SeqGenerator</div><div id='m_file'> M File Name: textbox/model/Seq2Seq/bart.py</div><div id='n_file'> N File Name: textbox/model/Seq2Seq/bart.py</div><div id='m_start'> M Start Line: 43</div><div id='m_end'> M End Line: 54</div><div id='n_start'> N Start Line: 41</div><div id='n_end'> N End Line: 48</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        preds = []
        for cur_queries, cur_docs in batches:
            features = <a id="change">self.tokenizer(
                </a>cur_queries,
                [doc.content for doc in cur_docs]<a id="change">,
                max_seq_len=self.max_seq_len,
                pad_to_max_seq_len=True,
                truncation_strategy="longest_first",
            )</a>

            tensors<a id="change"> = </a>{k: paddle.to_tensor(v) for (k, v) in features.items()}

            with paddle.no_grad():
                if self.use_en:</code></pre><h3>After Change</h3><pre><code class='java'>
                else:
                    datasets.append([query, doc.content])
            outputs = self.transformer_model(datasets)
            similarity_scores<a id="change"> = </a><a id="change">[item["similarity"] for item in outputs]</a>
            preds.extend(similarity_scores)

            for doc, rank_score in zip(cur_docs, similarity_scores):
                doc.rank_score = rank_score</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/35be940d8e29d002d830da63c5923f63b0ec4d5d#diff-e4ecbdd7379c6bb54f6934b38056f91532487822cf4efec218b9a1369b9e3aceL129' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70016512</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 35be940d8e29d002d830da63c5923f63b0ec4d5d</div><div id='time'> Time: 2023-03-06</div><div id='author'> Author: w5688414@gmail.com</div><div id='file'> File Name: pipelines/pipelines/nodes/ranker/ernie_ranker.py</div><div id='m_class'> M Class Name: ErnieRanker</div><div id='n_method'> N Class Name: ErnieRanker</div><div id='m_method'> M Method Name: predict_batch(5)</div><div id='n_method'> N Method Name: predict_batch(5)</div><div id='m_parent_class'> M Parent Class: BaseRanker</div><div id='n_parent_class'> N Parent Class: BaseRanker</div><div id='m_file'> M File Name: pipelines/pipelines/nodes/ranker/ernie_ranker.py</div><div id='n_file'> N File Name: pipelines/pipelines/nodes/ranker/ernie_ranker.py</div><div id='m_start'> M Start Line: 159</div><div id='m_end'> M End Line: 177</div><div id='n_start'> N Start Line: 150</div><div id='n_end'> N End Line: 159</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if top_k is None:
            top_k = self.top_k

        features = <a id="change">self.tokenizer(
            </a>[query for doc in documents],
            [doc.content for doc in documents]<a id="change">,
            max_seq_len=self.max_seq_len,
            pad_to_max_seq_len=True,
            truncation_strategy="longest_first",
        )</a>

        tensors<a id="change"> = </a>{k: paddle.to_tensor(v) for (k, v) in features.items()}

        with paddle.no_grad():
            if self.use_en:</code></pre><h3>After Change</h3><pre><code class='java'>
            else:
                datasets.append([query, doc.content])
        outputs = self.transformer_model(datasets)
        similarity_scores<a id="change"> = </a><a id="change">[item["similarity"] for item in outputs]</a>

        for doc, rank_score in zip(documents, similarity_scores):
            doc.rank_score = rank_score
            doc.score = rank_score</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/35be940d8e29d002d830da63c5923f63b0ec4d5d#diff-e4ecbdd7379c6bb54f6934b38056f91532487822cf4efec218b9a1369b9e3aceL84' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70016515</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 35be940d8e29d002d830da63c5923f63b0ec4d5d</div><div id='time'> Time: 2023-03-06</div><div id='author'> Author: w5688414@gmail.com</div><div id='file'> File Name: pipelines/pipelines/nodes/ranker/ernie_ranker.py</div><div id='m_class'> M Class Name: ErnieRanker</div><div id='n_method'> N Class Name: ErnieRanker</div><div id='m_method'> M Method Name: predict(4)</div><div id='n_method'> N Method Name: predict(4)</div><div id='m_parent_class'> M Parent Class: BaseRanker</div><div id='n_parent_class'> N Parent Class: BaseRanker</div><div id='m_file'> M File Name: pipelines/pipelines/nodes/ranker/ernie_ranker.py</div><div id='n_file'> N File Name: pipelines/pipelines/nodes/ranker/ernie_ranker.py</div><div id='m_start'> M Start Line: 98</div><div id='m_end'> M End Line: 115</div><div id='n_start'> N Start Line: 97</div><div id='n_end'> N End Line: 104</div><BR>