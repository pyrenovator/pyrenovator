<html><h3>Pattern ID :37981
</h3><img src='108712315.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        results = []
        batch = np.asarray(batch)
        with torch.no_grad():
            image_batch<a id="change"> = </a><a id="change">batch.astype(</a>&quotfloat32&quot<a id="change">)</a>
            image_batch = torch.from_numpy(image_batch).to(self.device)
            facesBatch, probabilitiesBatch = self.face_detector(image_batch, return_prob=True)
            for faces, probabilities in zip(facesBatch, probabilitiesBatch):
                batched = []</code></pre><h3>After Change</h3><pre><code class='java'>
        with torch.no_grad():
            image = torch.from_numpy(data.astype(&quotfloat32&quot)).to(self.device)
            &#47&#47 Create a batch of size 1
            image<a id="change"> = </a><a id="change">image.unsqueeze(0</a><a id="change">)</a>

            &#47&#47 Detect faces
            batch_boxes, batch_probs, _ = self.face_detector.detect(image, landmarks=True)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/jina-ai/jina-hub/commit/22993c7537903c526271697f746cc4d08c38fcce#diff-a8cbf9663e3989902bbaa6fd0ad40a351b4ea4eed4093287f3540a6a618db738L78' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 108712315</div><div id='project'> Project Name: jina-ai/jina-hub</div><div id='commit'> Commit Name: 22993c7537903c526271697f746cc4d08c38fcce</div><div id='time'> Time: 2021-05-20</div><div id='author'> Author: 67507873+shakurshams@users.noreply.github.com</div><div id='file'> File Name: segmenters/image/FaceNetSegmenter/__init__.py</div><div id='m_class'> M Class Name: FaceNetSegmenter</div><div id='n_method'> N Class Name: FaceNetSegmenter</div><div id='m_method'> M Method Name: segment(2)</div><div id='n_method'> N Method Name: segment(2)</div><div id='m_parent_class'> M Parent Class: BaseSegmenter,TorchDevice</div><div id='n_parent_class'> N Parent Class: BaseSegmenter,TorchDevice</div><div id='m_file'> M File Name: segmenters/image/FaceNetSegmenter/__init__.py</div><div id='n_file'> N File Name: segmenters/image/FaceNetSegmenter/__init__.py</div><div id='m_start'> M Start Line: 78</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 80</div><div id='n_end'> N End Line: 110</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47     raise ValueError("{} {} SR doesn&quott match target {} SR".format(
        &#47&#47         sampling_rate, self.sampling_rate))
        &#47&#47 audio = torch.load(filename)
        audio = torch.FloatTensor(<a id="change">np.load(filename).astype(</a>np.float32<a id="change">)</a>) 
        audio<a id="change"> = </a>audio.unsqueeze(0)
        &#47&#47 audio_norm = audio / self.max_wav_value
        &#47&#47 audio_norm = audio_norm.unsqueeze(0)
        &#47&#47 spec_filename = filename.replace(".wav", ".spec.pt")</code></pre><h3>After Change</h3><pre><code class='java'>
            raise ValueError("{} {} SR doesn&quott match target {} SR".format(
                sampling_rate, self.sampling_rate))
        audio_norm = audio / self.max_wav_value
        audio_norm<a id="change"> = </a><a id="change">audio_norm.unsqueeze(0</a><a id="change">)</a>
        spec = spectrogram(audio_norm, self.filter_length, self.hop_length, self.win_length,
            center=False)
        spec = torch.squeeze(spec, 0)
        return spec, audio_norm</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/babysor/realtime-voice-clone-chinese/commit/3ce874ab460658326d08c4a2dc73e4ca051d2324#diff-9adafb1c97fa7f80af133c9cfb5720260576216f4c19dbcf26e587399480c031L80' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 108712306</div><div id='project'> Project Name: babysor/realtime-voice-clone-chinese</div><div id='commit'> Commit Name: 3ce874ab460658326d08c4a2dc73e4ca051d2324</div><div id='time'> Time: 2023-02-10</div><div id='author'> Author: babysor00@gmail.com</div><div id='file'> File Name: models/synthesizer/vits_dataset.py</div><div id='m_class'> M Class Name: VitsDataset</div><div id='n_method'> N Class Name: VitsDataset</div><div id='m_method'> M Method Name: get_audio(2)</div><div id='n_method'> N Method Name: get_audio(2)</div><div id='m_parent_class'> M Parent Class: torch.utils.data.Dataset</div><div id='n_parent_class'> N Parent Class: torch.utils.data.Dataset</div><div id='m_file'> M File Name: models/synthesizer/vits_dataset.py</div><div id='n_file'> N File Name: models/synthesizer/vits_dataset.py</div><div id='m_start'> M Start Line: 87</div><div id='m_end'> M End Line: 103</div><div id='n_start'> N Start Line: 87</div><div id='n_end'> N End Line: 96</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if src_bbox.shape[0] == 0:
        return np.zeros((0, 4), dtype=loc.dtype)

    src_bbox<a id="change"> = </a><a id="change">src_bbox.astype(</a>src_bbox.dtype<a id="change">, copy=False)</a>
    src_width = src_bbox[:, 2] - src_bbox[:, 0]
    src_height = src_bbox[:, 3] - src_bbox[:, 1]
    src_ctr_x = src_bbox[:, 0] + 0.5 * src_width</code></pre><h3>After Change</h3><pre><code class='java'>
    if src_bbox.size()[0] == 0:
        return torch.zeros((0, 4), dtype=loc.dtype)

    src_width = <a id="change">torch.unsqueeze(</a>src_bbox[:, 2] - src_bbox[:, 0], <a id="change">-1</a><a id="change">)</a>
    src_height = torch.unsqueeze(src_bbox[:, 3] - src_bbox[:, 1], -1)
    src_ctr_x = torch.unsqueeze(src_bbox[:, 0], -1) + 0.5 * src_width
    src_ctr_y = torch.unsqueeze(src_bbox[:, 1], -1) + 0.5 * src_height

    dx = loc[:, 0::4]
    dy = loc[:, 1::4]
    dw = loc[:, 2::4]
    dh = loc[:, 3::4]

    ctr_x<a id="change"> = </a>dx * src_width + src_ctr_x
    ctr_y = dy * src_height + src_ctr_y
    w = torch.exp(dw) * src_width
    h = torch.exp(dh) * src_height</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bubbliiiing/faster-rcnn-pytorch/commit/d456f02a402fd8cf8db1d991aa612439b3c0ffb2#diff-9653b8c2ce917a6134298b00c8b3f7d4b7c4dc473a752303f37a870392742127L29' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 108712305</div><div id='project'> Project Name: bubbliiiing/faster-rcnn-pytorch</div><div id='commit'> Commit Name: d456f02a402fd8cf8db1d991aa612439b3c0ffb2</div><div id='time'> Time: 2021-01-30</div><div id='author'> Author: 47347516+bubbliiiing@users.noreply.github.com</div><div id='file'> File Name: utils/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: loc2bbox(2)</div><div id='n_method'> N Method Name: loc2bbox(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: utils/utils.py</div><div id='n_file'> N File Name: utils/utils.py</div><div id='m_start'> M Start Line: 30</div><div id='m_end'> M End Line: 49</div><div id='n_start'> N Start Line: 43</div><div id='n_end'> N End Line: 60</div><BR>