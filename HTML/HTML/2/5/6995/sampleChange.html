<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        pass

    def on_trace_stop(self, signal, context):
        <a id="change">pass</a>

    def on_trace_read(self, signal, context):
        if self._framework:
            signal.frameworks.append(self._framework)</code></pre><h3>After Change</h3><pre><code class='java'>
            for device in range(torch.cuda.device_count()):
                if &quotpytorch_mem_stats&quot in context and device in context[&quotpytorch_mem_stats&quot]: 
                    start_mem_stats = context[&quotpytorch_mem_stats&quot][device]
                    stop_mem_stats<a id="change"> = </a>_read_mem_stats(device)

                    mem_diff = _compute_diff(start_mem_stats, stop_mem_stats)
                    mem_alloc = signal.alloc_summary.add()
                    mem_alloc.allocator_type = signals_pb2.MemoryAllocation.AllocatorType.PYTORCH_CUDA_ALLOCATOR
                    mem_alloc.device_idx = device
                    mem_alloc.allocated_size = mem_diff.get(&quotallocated_size&quot, 0)
                    mem_alloc.reserved_size = mem_diff.get(&quotreserved_size&quot, 0)
                    mem_alloc.freed_size = mem_diff.get(&quotfreed_size&quot, 0)
                    mem_alloc.num_allocations = mem_diff.get(&quotnum_allocations&quot, 0)
                    mem_alloc.num_alloc_retries = mem_diff.get(&quotnum_alloc_retries&quot, 0)
                    mem_alloc.num_ooms<a id="change"> = </a><a id="change">mem_diff.get(&quotnum_ooms&quot</a>, 0<a id="change">)</a>

    def on_trace_read(self, signal, context, options):
        if self._framework:
            signal.frameworks.append(self._framework)</code></pre>