<html><h3>Pattern ID :18610
</h3><img src='60757727.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.acti2 = torch.nn.LeakyReLU()
        self.drop2 = torch.nn.Dropout(0.2)
        self.pool2 = torch.nn.MaxPool2d(2)
        self.conv3 = torch.nn.Conv2d(1, 1, (<a id="change">50</a><a id="change">, 50</a>))
        self.acti3 = torch.nn.LeakyReLU()
        self.drop3 = torch.nn.Dropout(0.2)
        self.encoder = torch.nn.Sequential(self.conv1, self.acti1, self.drop1, self.pool1,</code></pre><h3>After Change</h3><pre><code class='java'>
        self.acti3 = torch.nn.LeakyReLU()
        self.drop3 = torch.nn.Dropout2d(0.2)
        self.encoder_fine = torch.nn.Sequential(self.conv1, self.acti1, self.drop1, self.pool1)
        self.encoder_medium<a id="change"> = </a><a id="change">torch.nn.Sequential(</a>self.conv2, self.acti2, self.drop2, self.pool2<a id="change">)</a>
        self.encoder_coarse = torch.nn.Sequential(self.conv3, self.acti3, self.drop3)

        self.channel_reducer_1 = torch.nn.Conv2d(in_channels=10, out_channels=1, kernel_size=1)
        self.channel_reducer_2 = torch.nn.Conv2d(in_channels=10, out_channels=1, kernel_size=1)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/e00821e875c1dc3913edb61b7869c7bdc2a36dfa#diff-bc0bb039a4107c1aef8f739f51702815e3b1e3660906f43073f64344333f9a7fL13' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60757727</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: e00821e875c1dc3913edb61b7869c7bdc2a36dfa</div><div id='time'> Time: 2021-02-12</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: SpeakerEmbedding/SiameseSpeakerEmbedding.py</div><div id='m_class'> M Class Name: SiameseSpeakerEmbedding</div><div id='n_method'> N Class Name: SiameseSpeakerEmbedding</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: SpeakerEmbedding/SiameseSpeakerEmbedding.py</div><div id='n_file'> N File Name: SpeakerEmbedding/SiameseSpeakerEmbedding.py</div><div id='m_start'> M Start Line: 13</div><div id='m_end'> M End Line: 26</div><div id='n_start'> N Start Line: 13</div><div id='n_end'> N End Line: 30</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            SqueezeExcitation(embed_dim, embed_dim // 4),
            nn.Conv2d(embed_dim, embed_dim, 1)
        )
        self.layer_scale = nn.Parameter(torch.ones((embed_dim<a id="change">,1,1</a>)) * layer_scale_init)
        self.drop_path = StochasticDepth(drop_path, &quotrow&quot) if drop_path &gt; 0 else nn.Identity()

    def forward(self, x: torch.Tensor):</code></pre><h3>After Change</h3><pre><code class='java'>
        if norm_type == &quotln&quot:
            &#47&#47 LayerNorm version. Primary format is (N, H, W, C)
            &#47&#47 follow this approach https://github.com/pytorch/vision/blob/main/torchvision/models/convnext.py
            self.layers<a id="change"> = </a><a id="change">nn.Sequential(
                </a>nn.LayerNorm(embed_dim),
                nn.Linear(embed_dim, embed_dim),
                nn.GELU(),
                Permute(0, 3, 1, 2),        &#47&#47 (N, H, W, C) -&gt; (N, C, H, W)
                nn.Conv2d(embed_dim, embed_dim, 3, padding=1, groups=embed_dim),    &#47&#47 dw-conv
                nn.GELU(),
                SqueezeExcitation(embed_dim, embed_dim // 4),
                Permute(0, 2, 3, 1),        &#47&#47 (N, C, H, W) -&gt; (N, H, W, C)
                nn.Linear(embed_dim, embed_dim)<a id="change">
            )</a>
            self.layer_scale = nn.Parameter(torch.ones(embed_dim) * layer_scale_init)

        else:
            &#47&#47 BatchNorm version. Primary format is (N, C, H, W)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/gau-nernst/vision-toolbox/commit/9c33936b15da329b7d51d981196aca20d5e00077#diff-06aa870b4857860e20e31864ed75afe923611be3298c7662abf5065cbc7d651aL77' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60757726</div><div id='project'> Project Name: gau-nernst/vision-toolbox</div><div id='commit'> Commit Name: 9c33936b15da329b7d51d981196aca20d5e00077</div><div id='time'> Time: 2022-03-04</div><div id='author'> Author: gau.nernst@yahoo.com.sg</div><div id='file'> File Name: vision_toolbox/backbones/patchconvnet.py</div><div id='m_class'> M Class Name: PatchConvBlock</div><div id='n_method'> N Class Name: PatchConvBlock</div><div id='m_method'> M Method Name: __init__(5)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: vision_toolbox/backbones/patchconvnet.py</div><div id='n_file'> N File Name: vision_toolbox/backbones/patchconvnet.py</div><div id='m_start'> M Start Line: 77</div><div id='m_end'> M End Line: 89</div><div id='n_start'> N Start Line: 77</div><div id='n_end'> N End Line: 109</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            nn.Conv2d(64, 256, (3, 3), (1, 1), (1, 1)),
            nn.PixelShuffle(2),
            nn.PReLU(),
            nn.Conv2d(64, 256, (3, 3), (<a id="change">1</a><a id="change">, 1</a>), (1, 1)),
            nn.PixelShuffle(2),
            nn.PReLU(),
        )</code></pre><h3>After Change</h3><pre><code class='java'>
        upsampling = []
        for _ in range(2):
            upsampling.append(UpsampleBlock(64))
        self.upsampling<a id="change"> = </a><a id="change">nn.Sequential(</a>*<a id="change">upsampling)</a>

        &#47&#47 Output layer.
        self.conv_block3 = nn.Conv2d(64, 3, (9, 9), (1, 1), (4, 4))
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/srgan-pytorch/commit/2c11f14c44490604941be00d7661b19ad8f96597#diff-fada037ad086638e65c7ae77e3d223963e9afaa26326aab0ea718f4013176e43L106' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60757724</div><div id='project'> Project Name: lornatang/srgan-pytorch</div><div id='commit'> Commit Name: 2c11f14c44490604941be00d7661b19ad8f96597</div><div id='time'> Time: 2022-02-14</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: model.py</div><div id='m_class'> M Class Name: Generator</div><div id='n_method'> N Class Name: Generator</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model.py</div><div id='n_file'> N File Name: model.py</div><div id='m_start'> M Start Line: 127</div><div id='m_end'> M End Line: 134</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 146</div><BR>