<html><h3>Pattern ID :40639
</h3><img src='114915481.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    model = choose_models(cfg[&quotMODEL&quot][&quotNAME&quot])(cfg[&quotMODEL&quot][&quotSUB_NAME&quot], pretrained=cfg[&quotEVAL&quot][&quotMODEL_PATH&quot], num_classes=cfg[&quotDATASET&quot][&quotNUM_CLASSES&quot], image_size=cfg[&quotEVAL&quot][&quotIMAGE_SIZE&quot][0])   
    model = model.to(device)

    val_transform = <a id="change">T.Compose(
        T.Resize(</a>tuple(map(lambda x: int(x / 0.9), cfg[&quotEVAL&quot][&quotIMAGE_SIZE&quot]))<a id="change">)</a>,
        T.CenterCrop(cfg[&quotEVAL&quot][&quotIMAGE_SIZE&quot]),
        T.ToTensor(),
        <a id="change">T.Normalize(</a>[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]<a id="change">)
    )</a>

    val_dataset = ImageNet(cfg[&quotDATASET&quot][&quotROOT&quot], split=&quotval&quot, transform=val_transform)
    val_dataloader = DataLoader(val_dataset, batch_size=cfg[&quotEVAL&quot][&quotBATCH_SIZE&quot], num_workers=cfg[&quotEVAL&quot][&quotWORKERS&quot], pin_memory=True)
</code></pre><h3>After Change</h3><pre><code class='java'>
def main(cfg):
    device = torch.device(cfg[&quotDEVICE&quot])

    model = get_model(cfg[&quotMODEL&quot][&quotNAME&quot], cfg[&quotMODEL&quot][&quotVARIANT&quot], cfg[&quotMODEL_PATH&quot], <a id="change">cfg[&quotDATASET&quot]</a>[&quotNUM_CLASSES&quot], cfg[&quotEVAL&quot][&quotIMAGE_SIZE&quot][0])
    model = model.to(device)

    _, val_transform = get_transforms(cfg)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/sithu31296/image-classification/commit/73c841ee1e7c55eae40dcccc6437b08fea7469bf#diff-625699df75ed3d3edb9f8e8f5a4ebcb7a16ab5a2874978deb150f0d8301ee9a4L44' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 114915481</div><div id='project'> Project Name: sithu31296/image-classification</div><div id='commit'> Commit Name: 73c841ee1e7c55eae40dcccc6437b08fea7469bf</div><div id='time'> Time: 2021-07-07</div><div id='author'> Author: sithu31296@gmail.com</div><div id='file'> File Name: tools/val.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tools/val.py</div><div id='n_file'> N File Name: tools/val.py</div><div id='m_start'> M Start Line: 44</div><div id='m_end'> M End Line: 57</div><div id='n_start'> N Start Line: 46</div><div id='n_end'> N End Line: 50</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    model = choose_models(cfg[&quotMODEL&quot][&quotNAME&quot])(cfg[&quotMODEL&quot][&quotSUB_NAME&quot], pretrained=cfg[&quotEVAL&quot][&quotMODEL_PATH&quot], num_classes=cfg[&quotDATASET&quot][&quotNUM_CLASSES&quot], image_size=cfg[&quotEVAL&quot][&quotIMAGE_SIZE&quot][0])   
    model = model.to(device)

    val_transform = <a id="change">T.Compose(
        T.Resize(</a>tuple(map(lambda x: int(x / 0.9), cfg[&quotEVAL&quot][&quotIMAGE_SIZE&quot]))<a id="change">)</a>,
        T.CenterCrop(cfg[&quotEVAL&quot][&quotIMAGE_SIZE&quot]),
        T.ToTensor(),
        <a id="change">T.Normalize(</a>[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]<a id="change">)
    )</a>

    val_dataset = ImageNet(cfg[&quotDATASET&quot][&quotROOT&quot], split=&quotval&quot, transform=val_transform)
    val_dataloader = DataLoader(val_dataset, batch_size=cfg[&quotEVAL&quot][&quotBATCH_SIZE&quot], num_workers=cfg[&quotEVAL&quot][&quotWORKERS&quot], pin_memory=True)
</code></pre><h3>After Change</h3><pre><code class='java'>
def main(cfg):
    device = torch.device(cfg[&quotDEVICE&quot])

    model = get_model(cfg[&quotMODEL&quot][&quotNAME&quot], cfg[&quotMODEL&quot][&quotVARIANT&quot], cfg[&quotMODEL_PATH&quot], cfg[&quotDATASET&quot][&quotNUM_CLASSES&quot], <a id="change">cfg[&quotEVAL&quot][&quotIMAGE_SIZE&quot][0]</a>)
    model = model.to(device)

    _, val_transform = get_transforms(cfg)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sithu31296/sota-backbones/commit/73c841ee1e7c55eae40dcccc6437b08fea7469bf#diff-625699df75ed3d3edb9f8e8f5a4ebcb7a16ab5a2874978deb150f0d8301ee9a4L43' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 114915480</div><div id='project'> Project Name: sithu31296/sota-backbones</div><div id='commit'> Commit Name: 73c841ee1e7c55eae40dcccc6437b08fea7469bf</div><div id='time'> Time: 2021-07-07</div><div id='author'> Author: sithu31296@gmail.com</div><div id='file'> File Name: tools/val.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tools/val.py</div><div id='n_file'> N File Name: tools/val.py</div><div id='m_start'> M Start Line: 44</div><div id='m_end'> M End Line: 57</div><div id='n_start'> N Start Line: 46</div><div id='n_end'> N End Line: 50</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.ignore_label = 255
        img_size = (img_size, img_size) if isinstance(img_size, int) else img_size

        self.image_transforms = <a id="change">T.Compose(</a>[
            <a id="change">T.Resize(</a>img_size<a id="change">, interpolation=T.InterpolationMode.BILINEAR)</a>,
            <a id="change">T.Normalize(</a>(0.3257, 0.3690, 0.3223), (0.2112, 0.2148, 0.2115)<a id="change">)</a>
        ]<a id="change">)</a>
        self.label_transforms = T.Resize(img_size, interpolation=T.InterpolationMode.NEAREST)

        if split != &quottest&quot:
            img_path = Path(root) / &quotleftImg8bit&quot / split</code></pre><h3>After Change</h3><pre><code class='java'>

        self.label_map = np.arange(256)
        for id, trainid in self.ID2TRAINID.items():
            <a id="change">self.label_map[id]</a> = trainid

        img_path = Path(root) / &quotleftImg8bit&quot / split
        self.files = list(img_path.rglob(&quot*.png&quot))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sithu31296/semantic-segmentation/commit/66612f96041d5c478f558477efc0b23d246747d4#diff-7e45cbddcfadc0465dbb1e1b34636cb77dde59dedf51e4b776f9389f2e0228d1L19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 114915488</div><div id='project'> Project Name: sithu31296/semantic-segmentation</div><div id='commit'> Commit Name: 66612f96041d5c478f558477efc0b23d246747d4</div><div id='time'> Time: 2021-08-02</div><div id='author'> Author: sithu31296@gmail.com</div><div id='file'> File Name: datasets/cityscapes.py</div><div id='m_class'> M Class Name: CityScapes</div><div id='n_method'> N Class Name: CityScapes</div><div id='m_method'> M Method Name: __init__(4)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: datasets/cityscapes.py</div><div id='n_file'> N File Name: datasets/cityscapes.py</div><div id='m_start'> M Start Line: 19</div><div id='m_end'> M End Line: 44</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 40</div><BR>