<html><h3>Pattern ID :36882
</h3><img src='105007842.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        
        seq_length = seg.size(1)
        device = seg.device
        emb<a id="change"> = </a><a id="change">self.pe[: seq_length]</a>.transpose(0, 1)

        return emb.to(device)
</code></pre><h3>After Change</h3><pre><code class='java'>
            device = src.device
            no_pad_num = (src != 0).sum(dim=-1)
        
        emb<a id="change"> =  </a><a id="change">torch.zeros(</a>batch_size, seq_length, self.emb_size<a id="change">)</a>
        for i in range(batch_size):
            emb[i, :no_pad_num[i], :] = self.emb[2: no_pad_num[i]+2]

        return emb.to(device)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tencent/tencentpretrain/commit/2bc6d47065d7a5e6907d449cf5114248000274fe#diff-41324f66c261d89709c738adf53f3dddb45e587991d1f8c895e23d2dedb742dbL45' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 105007842</div><div id='project'> Project Name: tencent/tencentpretrain</div><div id='commit'> Commit Name: 2bc6d47065d7a5e6907d449cf5114248000274fe</div><div id='time'> Time: 2022-12-16</div><div id='author'> Author: 40569026+JINGZIjingzi@users.noreply.github.com</div><div id='file'> File Name: tencentpretrain/embeddings/sinusoidalpos_embedding.py</div><div id='m_class'> M Class Name: SinusoidalposEmbedding</div><div id='n_method'> N Class Name: SinusoidalposEmbedding</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: tencentpretrain/embeddings/sinusoidalpos_embedding.py</div><div id='n_file'> N File Name: tencentpretrain/embeddings/sinusoidalpos_embedding.py</div><div id='m_start'> M Start Line: 45</div><div id='m_end'> M End Line: 47</div><div id='n_start'> N Start Line: 55</div><div id='n_end'> N End Line: 68</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            noisy_wavs, (batch_size * num_blocks, 16384, 1)
        )
        zeros = torch.zeros(batch_size, num_blocks * 16384, 1)
        <a id="change">zeros[:, :wav_size, :]</a> = clean_wavs
        clean_wavs = zeros.clone()
        clean_wavs<a id="change"> = </a>torch.reshape(
            clean_wavs, (batch_size * num_blocks, 16384, 1)
        )
</code></pre><h3>After Change</h3><pre><code class='java'>
        self.original_len = clean_wavs.shape[1]

        &#47&#47 Add padding to make sure all the signal will be processed.
        padding_elements = <a id="change">torch.zeros(
            </a>clean_wavs.shape[0], hparams["chunk_size"]<a id="change">, device=clean_wavs.device
        )</a>
        clean_wavs<a id="change"> = </a>torch.cat([clean_wavs, padding_elements], dim=1)
        noisy_wavs = torch.cat([noisy_wavs, padding_elements], dim=1)

        &#47&#47 Split sentences in smaller chunks</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/c91d417913af7aef5b1cf8937fb9d14754b5daa4#diff-8cc1ce71cb41490c54a415d6789e8e424d9f26fb5d749a2efd99e1e742506bafL213' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 105007872</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: c91d417913af7aef5b1cf8937fb9d14754b5daa4</div><div id='time'> Time: 2021-07-13</div><div id='author'> Author: mirco.ravanelli@gmail.com</div><div id='file'> File Name: recipes/Voicebank/enhance/SEGAN/train.py</div><div id='m_class'> M Class Name: SEBrain</div><div id='n_method'> N Class Name: SEBrain</div><div id='m_method'> M Method Name: evaluate_batch(3)</div><div id='n_method'> N Method Name: evaluate_batch(3)</div><div id='m_parent_class'> M Parent Class: sb.Brain</div><div id='n_parent_class'> N Parent Class: sb.Brain</div><div id='m_file'> M File Name: recipes/Voicebank/enhance/SEGAN/train.py</div><div id='n_file'> N File Name: recipes/Voicebank/enhance/SEGAN/train.py</div><div id='m_start'> M Start Line: 235</div><div id='m_end'> M End Line: 253</div><div id='n_start'> N Start Line: 235</div><div id='n_end'> N End Line: 255</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    mask = paddle.where(mask_cond, paddle.full(mask_cond.shape, 0), mask)

    if past_key_values_length &gt; 0:
        <a id="change">mask[:, :past_key_values_length]</a> = False

    expanded_mask<a id="change"> = </a>mask.unsqueeze(0).expand([batch_size, target_length, target_length + past_key_values_length])
    return expanded_mask

</code></pre><h3>After Change</h3><pre><code class='java'>
    mask = masked_fill(mask, mask_cond &lt; (mask_cond + 1).reshape([mask.shape[-1], 1]), 0)

    if past_key_values_length &gt; 0:
        mask<a id="change"> = </a>paddle.concat([<a id="change">paddle.zeros(</a>target_length, past_key_values_length<a id="change">)</a>, mask], axis=-1)

    return mask[None, None, :, :].expand([batch_size, 1, target_length, target_length + past_key_values_length])
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/5f01f073ed6e140743170652b201c16356350dc7#diff-99e104eff4c095428aa1cd5d186107ae22737297e8ec3b5c12cd138e69a79cb5L90' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 105007863</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 5f01f073ed6e140743170652b201c16356350dc7</div><div id='time'> Time: 2023-04-13</div><div id='author'> Author: 40840292+linjieccc@users.noreply.github.com</div><div id='file'> File Name: paddlenlp/transformers/llama/modeling.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _make_causal_mask(3)</div><div id='n_method'> N Method Name: _make_causal_mask(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: paddlenlp/transformers/llama/modeling.py</div><div id='n_file'> N File Name: paddlenlp/transformers/llama/modeling.py</div><div id='m_start'> M Start Line: 96</div><div id='m_end'> M End Line: 106</div><div id='n_start'> N Start Line: 101</div><div id='n_end'> N End Line: 109</div><BR>