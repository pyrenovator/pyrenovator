<html><h3>Pattern ID :39137
</h3><img src='111335554.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    result_array = sitk.GetArrayFromImage(result)
    reference_array = sitk.GetArrayFromImage(reference)
    voxelspacing = result.GetSpacing()
    <a id="change">if result.GetSpacing() != reference.GetSpacing()</a>:
        <a id="change">raise </a>ValueError("The reference and result images should have same resolutions")
    if result.GetSize() != reference.GetSize():
        raise ValueError("The reference and result images should have same shape")
        </code></pre><h3>After Change</h3><pre><code class='java'>
    
    result_array = reverse_one_hot(inp, params["model"]["class_list"])
    &#47&#47 we squeeze because target is a 5D tensor (for 3D models)
    reference_array = <a id="change">target.squeeze(1</a><a id="change">)</a>.cpu().detach().numpy()

    hd1 = __surface_distances(result_array, reference_array, params["subject_spacing"])
    hd2 = __surface_distances(reference_array, result_array, params["subject_spacing"])</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/cbica/gandlf/commit/d781f5415a19cdd0124c64364e64cf0a85461a63#diff-e8e9d1aecc57d03523e91ca58b5b79b0c557a8abb59e324ba3a85e65db05a6d3L225' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111335554</div><div id='project'> Project Name: cbica/gandlf</div><div id='commit'> Commit Name: d781f5415a19cdd0124c64364e64cf0a85461a63</div><div id='time'> Time: 2021-06-25</div><div id='author'> Author: sarthak.pati@hotmail.com</div><div id='file'> File Name: GANDLF/metrics.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: hd95(3)</div><div id='n_method'> N Method Name: hd95(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: GANDLF/metrics.py</div><div id='n_file'> N File Name: GANDLF/metrics.py</div><div id='m_start'> M Start Line: 225</div><div id='m_end'> M End Line: 235</div><div id='n_start'> N Start Line: 225</div><div id='n_end'> N End Line: 232</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        return img

    def __call__(self, img: torch.Tensor) -&gt; torch.Tensor:
        <a id="change">if img.shape[1] != 3</a>:
            <a id="change">raise </a>ValueError("HED jitter can only be applied to images with 3 channels (RGB).")

        return self.adjust_hed(img)
</code></pre><h3>After Change</h3><pre><code class='java'>
        else:
            img = self.adjust_hed(img)
            if len(original_shape) == 3:
                return <a id="change">img.squeeze(0</a><a id="change">)</a>
            return img


class StainNormalization(object):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/hi-ml/commit/5ce9e00fd52f9a4f80c11aa35d3b7152c1ce9fca#diff-01b65da2b180814d6d0b581e4a11ccaaca9d0a386437562e7dcba91e24110c7dL74' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111335552</div><div id='project'> Project Name: microsoft/hi-ml</div><div id='commit'> Commit Name: 5ce9e00fd52f9a4f80c11aa35d3b7152c1ce9fca</div><div id='time'> Time: 2023-02-22</div><div id='author'> Author: 61745616+harshita-s@users.noreply.github.com</div><div id='file'> File Name: hi-ml/src/health_ml/utils/data_augmentations.py</div><div id='m_class'> M Class Name: HEDJitter</div><div id='n_method'> N Class Name: HEDJitter</div><div id='m_method'> M Method Name: __call__(2)</div><div id='n_method'> N Method Name: __call__(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: hi-ml/src/health_ml/utils/data_augmentations.py</div><div id='n_file'> N File Name: hi-ml/src/health_ml/utils/data_augmentations.py</div><div id='m_start'> M Start Line: 75</div><div id='m_end'> M End Line: 78</div><div id='n_start'> N Start Line: 75</div><div id='n_end'> N End Line: 90</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                min_slot_id = slot_id
                min_offset = offset

        <a id="change">if min_slot_id is None</a>:
            <a id="change">raise </a>RuntimeError("Can not evict a chunk")

        with Timer() as timer:
            cuda_tensor = torch.narrow(self.cuda_partial_weight.view(-1), 0, min_offset * self.embedding_dim,</code></pre><h3>After Change</h3><pre><code class='java'>
        mask = torch.logical_or(torch.isin(self.cached_chunk_table[:, 0], self.evict_backlist),
                                self.cached_chunk_table[:, 0] == -1)
        buf = self.cached_chunk_table[mask, 0].clone()
        idx = <a id="change">torch.nonzero(mask).squeeze(1</a><a id="change">)</a>
        self.cached_chunk_table[:, 0].index_fill_(0, idx, self.chunk_num)
        min_row, min_slot_id = torch.min(self.cached_chunk_table[:, 0], dim=0)

        min_chunk_id, min_offset = self.cached_chunk_table[min_slot_id]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hpcaitech/cachedembedding/commit/5b9995175361069d8eaa507674a59791f722761a#diff-aab5f7e7e049810d29a74e3eab12af668892a81357998cc464ab0f8cd2272767L213' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111335559</div><div id='project'> Project Name: hpcaitech/cachedembedding</div><div id='commit'> Commit Name: 5b9995175361069d8eaa507674a59791f722761a</div><div id='time'> Time: 2022-07-26</div><div id='author'> Author: 34452939+zxgx@users.noreply.github.com</div><div id='file'> File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='m_class'> M Class Name: ChunkParamMgr</div><div id='n_method'> N Class Name: ChunkParamMgr</div><div id='m_method'> M Method Name: _evict(1)</div><div id='n_method'> N Method Name: _evict(1)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='n_file'> N File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='m_start'> M Start Line: 217</div><div id='m_end'> M End Line: 235</div><div id='n_start'> N Start Line: 204</div><div id='n_end'> N End Line: 225</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                                  frame_length=self._frame_length,
                                  frame_shift=self._frame_shift,
                                  sample_frequency=audio_segment.sample_rate).numpy()
        elif <a id="change">self._feature_method == &quotfbank&quot</a>:
            &#47&#47 计算梅尔频谱
            feature = fbank(waveform=waveform,
                            num_mel_bins=self._n_mels,
                            frame_length=self._frame_length,
                            frame_shift=self._frame_shift,
                            sample_frequency=audio_segment.sample_rate).numpy()
        else:
            <a id="change">raise </a>Exception(f&quot预处理方法 {self._feature_method} 不存在！&quot)
        &#47&#47 归一化
        mean = np.mean(feature, 1, keepdims=True)
        std = np.std(feature, 1, keepdims=True)</code></pre><h3>After Change</h3><pre><code class='java'>
            audio_segment.normalize(target_db=self._target_dB)
        &#47&#47 获取音频特征
        waveform = torch.from_numpy(np.expand_dims(audio_segment.samples, 0)).float()
        feature = <a id="change">self.feat_fun(waveform).squeeze(0</a><a id="change">)</a>.transpose(1, 0).numpy()
        &#47&#47 归一化
        mean = np.mean(feature, 1, keepdims=True)
        std = np.std(feature, 1, keepdims=True)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yeyupiaoling/audioclassification-pytorch/commit/f9a39f29e647cb3c02b8bb832a8d66c8655e4b1e#diff-16d41d5a471aa7cc4fe1b2a36c807558d42d547e1de4cd47ce61937322983e62L33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111335556</div><div id='project'> Project Name: yeyupiaoling/audioclassification-pytorch</div><div id='commit'> Commit Name: f9a39f29e647cb3c02b8bb832a8d66c8655e4b1e</div><div id='time'> Time: 2022-12-06</div><div id='author'> Author: yeyupiaoling@foxmail.com</div><div id='file'> File Name: macls/data_utils/featurizer/audio_featurizer.py</div><div id='m_class'> M Class Name: AudioFeaturizer</div><div id='n_method'> N Class Name: AudioFeaturizer</div><div id='m_method'> M Method Name: featurize(2)</div><div id='n_method'> N Method Name: featurize(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: macls/data_utils/featurizer/audio_featurizer.py</div><div id='n_file'> N File Name: macls/data_utils/featurizer/audio_featurizer.py</div><div id='m_start'> M Start Line: 48</div><div id='m_end'> M End Line: 66</div><div id='n_start'> N Start Line: 57</div><div id='n_end'> N End Line: 58</div><BR>