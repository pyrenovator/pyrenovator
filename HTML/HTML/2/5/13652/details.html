<html><h3>Pattern ID :13652
</h3><img src='45769594.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    output = ctx.method_return

    &#47&#47 transpose weight
    weight_transpose = <a id="change">weight.t()</a>
    ctx.method_args = [weight]
    ctx.method_kwargs = {}
    ctx.method_return = weight_transpose
    convert_t(ctx)

    &#47&#47 matmul
    matmul_output = input.matmul(weight_transpose)
    ctx.method_args = [input, weight]
    ctx.method_kwargs = {}
    ctx.method_return = matmul_output
    convert_matmul(ctx)

    &#47&#47 add bias
    if bias is not None:
        add_bias_output = matmul_output<a id="change"> + </a>bias
        ctx.method_args = [matmul_output, bias]
        ctx.method_return<a id="change"> = </a>add_bias_output
        convert_add(ctx)
        output._trt = add_bias_output._trt
    else:</code></pre><h3>After Change</h3><pre><code class='java'>
    output = ctx.method_return

    in_channels = weight.shape[1]
    out_channels = <a id="change">weight.shape[0]</a>
    module = torch.nn.Linear(in_channels, out_channels, bias is not None)
    module.weight = torch.nn.Parameter(weight)
    if bias is not None:
        module.bias = torch.nn.Parameter(bias)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/grimoire/torch2trt_dynamic/commit/6b7a712d3a248cfcf94e95f9769e2bd8a27c611f#diff-0412cab89ea295aaa56df7ba86c2e8969457aa24da03dc665af508614ea34e3bL11' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45769594</div><div id='project'> Project Name: grimoire/torch2trt_dynamic</div><div id='commit'> Commit Name: 6b7a712d3a248cfcf94e95f9769e2bd8a27c611f</div><div id='time'> Time: 2021-02-23</div><div id='author'> Author: streetyao@live.com</div><div id='file'> File Name: torch2trt_dynamic/converters/linear.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: convert_linear(1)</div><div id='n_method'> N Method Name: convert_linear(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torch2trt_dynamic/converters/linear.py</div><div id='n_file'> N File Name: torch2trt_dynamic/converters/linear.py</div><div id='m_start'> M Start Line: 14</div><div id='m_end'> M End Line: 44</div><div id='n_start'> N Start Line: 11</div><div id='n_end'> N End Line: 25</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    bond_buckets[native_bond_idxs[1], native_bond_idxs[0]] = cutoffs.shape[0]
    &#47&#47 find the indexes - symmetric and we dont want the diag
    close_bond_idxs = ( bond_buckets &lt; len(cutoffs) ).triu(diagonal=1)
    close_bond_idxs<a id="change"> = </a>( close_bond_idxs<a id="change"> + </a><a id="change">close_bond_idxs.t()</a> ).nonzero().t()
    &#47&#47 merge all bonds
    whole_bond_idxs = torch.cat([native_bond_idxs, close_bond_idxs], dim=-1)
</code></pre><h3>After Change</h3><pre><code class='java'>
    bond_buckets   += len(cutoffs) * torch.eye(bond_buckets.shape[0]).long()
    close_bond_idxs = ( bond_buckets &lt; len(cutoffs) ).nonzero().t()
    &#47&#47 merge all bonds
    if <a id="change">close_bond_idxs.shape[0]</a> &gt; 0:
        whole_bond_idxs = torch.cat([native_bond_idxs, close_bond_idxs], dim=-1)
    else:
        whole_bond_idxs = native_bond_idxs</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/geometric-vector-perceptron/commit/22f9b33ad0772e693055c0076bdd5607b66fbe2d#diff-3c4d3e9b2d9cca8bf55129be87f3334c429ad0ab75a5329f0d84e34cb61d4021L321' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45769595</div><div id='project'> Project Name: lucidrains/geometric-vector-perceptron</div><div id='commit'> Commit Name: 22f9b33ad0772e693055c0076bdd5607b66fbe2d</div><div id='time'> Time: 2021-02-28</div><div id='author'> Author: ericalcaide1@gmail.com</div><div id='file'> File Name: examples/data_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: encode_whole_bonds(5)</div><div id='n_method'> N Method Name: encode_whole_bonds(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/data_utils.py</div><div id='n_file'> N File Name: examples/data_utils.py</div><div id='m_start'> M Start Line: 345</div><div id='m_end'> M End Line: 379</div><div id='n_start'> N Start Line: 339</div><div id='n_end'> N End Line: 378</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        logits = self.model.classify(x)

        L = <a id="change">L.view_as(logits.t()).t()</a>

        &#47&#47 Calculate entropy H(q(y|x)) and sum over all labels
        H = -torch.sum(torch.mul(logits, torch.log(logits + 1e-8)), dim=-1)
        L = torch.sum(torch.mul(logits, L), dim=-1)

        &#47&#47 Equivalent to -U(x)
        U<a id="change"> = </a>L<a id="change"> + </a>H

        return torch.mean(U)
</code></pre><h3>After Change</h3><pre><code class='java'>
        self.sampler = sampler

    def forward(self, x, y=None, likelihood_func=losses.reconstruction_loss):
        batch_size = <a id="change">x.shape[0]</a>
        is_labelled = False if y is None else True

        &#47&#47 Prepare for sampling
        xs, ys = (x, y)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bioshape-lab/pirounet/commit/905ff42f59d43741a1e02f8c8f163e144aa2c47e#diff-ae9866f759e06062f2427faf6c2026a7384b4324f8933bbfae0e5f2d6ad2637aL196' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45769567</div><div id='project'> Project Name: bioshape-lab/pirounet</div><div id='commit'> Commit Name: 905ff42f59d43741a1e02f8c8f163e144aa2c47e</div><div id='time'> Time: 2022-05-26</div><div id='author'> Author: nmiolane@harold.ece.ucsb.edu</div><div id='file'> File Name: move/models/dgm_lstm_vae.py</div><div id='m_class'> M Class Name: SVI</div><div id='n_method'> N Class Name: SVI</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: move/models/dgm_lstm_vae.py</div><div id='n_file'> N File Name: move/models/dgm_lstm_vae.py</div><div id='m_start'> M Start Line: 223</div><div id='m_end'> M End Line: 237</div><div id='n_start'> N Start Line: 196</div><div id='n_end'> N End Line: 255</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        H1bar = H1 - H1.mean(dim=1).unsqueeze(dim=1)
        H2bar = H2 - H2.mean(dim=1).unsqueeze(dim=1)

        SigmaHat12 = (1.0 / (m - 1))<a id="change"> * </a>torch.matmul(H1bar, <a id="change">H2bar.t()</a>)
        SigmaHat11 = (1 - self.r) * (1.0 / (m - 1)) * torch.matmul(H1bar,
                                                                   H1bar.t()) + self.r * torch.eye(o1,
                                                                                                   dtype=torch.double,
                                                                                                   device=H1.device).float()
        SigmaHat22 = (1 - self.r) * (1.0 / (m - 1)) * torch.matmul(H2bar,
                                                                   H2bar.t()) + self.r * torch.eye(o2,
                                                                                                   dtype=torch.double,
                                                                                                   device=H2.device).float()

        &#47&#47 performs the inverse square root of the covariance matrices by the cholesky decomposition. This is more stable than using SVD
        SigmaHat11RootInv = torch.linalg.inv(torch.linalg.cholesky(_minimal_regularisation(SigmaHat11, self.eps)))
        SigmaHat22RootInv = torch.linalg.inv(torch.linalg.cholesky(_minimal_regularisation(SigmaHat22, self.eps)))

        Tval = torch.matmul(torch.matmul(SigmaHat11RootInv,
                                         SigmaHat12), SigmaHat22RootInv)

        trace_TT<a id="change"> = </a>torch.matmul(Tval.t(), Tval)
        eigvals = torch.real(torch.linalg.eigvals(trace_TT))
        eigvals = eigvals[torch.gt(eigvals, self.eps)]
        corr = torch.sum(torch.sqrt(eigvals))</code></pre><h3>After Change</h3><pre><code class='java'>
        o1 = H1.shape[1]
        o2 = H2.shape[1]

        n = <a id="change">H1.shape[0]</a>

        H1bar, H2bar = _demean(H1, H2)

        SigmaHat12 = (1.0 / (n - 1)) * torch.matmul(H1bar.T, H2bar)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jameschapman19/cca_zoo/commit/109657aa0c08d40d8571bc16e653094cb6206408#diff-abb7a5d5582a748bb8e9b037ee50860d69b8505da48d9f6c9c4a34060dd0bac9L142' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45769532</div><div id='project'> Project Name: jameschapman19/cca_zoo</div><div id='commit'> Commit Name: 109657aa0c08d40d8571bc16e653094cb6206408</div><div id='time'> Time: 2021-07-14</div><div id='author'> Author: james.chapman.19@ucl.ac.uk</div><div id='file'> File Name: cca_zoo/deepmodels/objectives.py</div><div id='m_class'> M Class Name: CCA</div><div id='n_method'> N Class Name: CCA</div><div id='m_method'> M Method Name: loss(3)</div><div id='n_method'> N Method Name: loss(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: cca_zoo/deepmodels/objectives.py</div><div id='n_file'> N File Name: cca_zoo/deepmodels/objectives.py</div><div id='m_start'> M Start Line: 143</div><div id='m_end'> M End Line: 171</div><div id='n_start'> N Start Line: 145</div><div id='n_end'> N End Line: 166</div><BR>