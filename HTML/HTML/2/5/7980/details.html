<html><h3>Pattern ID :7980
</h3><img src='28411209.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self._c = np.zeros((2, 1, 64)).astype(&quotfloat32&quot)

    def __call__(self, x, sr: int):
        <a id="change">if </a>x.dim() == 1:
            x<a id="change"> = </a><a id="change">x.unsqueeze(0</a><a id="change">)</a>
        if x.dim() &gt; 2:
            raise ValueError(f"Too many dimensions for input audio chunk {x.dim()}")

        if sr != 16000 and (sr % 16000 == 0):</code></pre><h3>After Change</h3><pre><code class='java'>
            self.reset_states(batch_size)

        if sr in [8000, 16000]:
            ort_inputs = {&quotinput&quot: x.numpy(), &quoth&quot: self._h, &quotc&quot: self._c, &quotsr&quot: <a id="change">np.array(</a>sr<a id="change">)</a>}
            ort_outs = self.session.run(None, ort_inputs)
            out, self._h, self._c = ort_outs
        else:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/snakers4/silero-vad/commit/081e6b9886f2173f722baf3cc5001583722b1eb8#diff-cd640fcd0eb5b66051202fb6c0f1ee7c63568ccb08af512ffec5612c331ef03eL30' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 28411209</div><div id='project'> Project Name: snakers4/silero-vad</div><div id='commit'> Commit Name: 081e6b9886f2173f722baf3cc5001583722b1eb8</div><div id='time'> Time: 2022-10-26</div><div id='author'> Author: dvoronin322@gmail.com</div><div id='file'> File Name: utils_vad.py</div><div id='m_class'> M Class Name: OnnxWrapper</div><div id='n_method'> N Class Name: OnnxWrapper</div><div id='m_method'> M Method Name: __call__(3)</div><div id='n_method'> N Method Name: __call__(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: utils_vad.py</div><div id='n_file'> N File Name: utils_vad.py</div><div id='m_start'> M Start Line: 30</div><div id='m_end'> M End Line: 53</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 73</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        img = np.array(Image.open(os.path.join(config.ROOT_DIR, self.fname, img_name)).convert("RGB"))

        <a id="change">if </a>self.rect_training:
            bboxes = [ann[1:] for ann in annotations if (ann[2] &gt; 0 and ann[3] &gt; 0)]
            bboxes = torch.tensor(bboxes)
            classes = torch.tensor([ann[0] for ann in annotations])
            labels<a id="change"> = </a>torch.cat([<a id="change">classes.unsqueeze(1</a><a id="change">)</a>, bboxes], dim=-1)
            sh, sw = img.shape[0:2]
            img, ratio, pad = letterbox(img, (tg_height, tg_width), auto=False, scaleup=False)
            if labels.size:  &#47&#47 normalized xywh to pixel xyxy format</code></pre><h3>After Change</h3><pre><code class='java'>
                                           bboxes=np.roll(labels, axis=1, shift=4)
                                           )
            img = augmentations["image"]
            labels = np.roll(<a id="change">np.array(</a>augmentations["bboxes"]<a id="change">)</a>, axis=1, shift=1)

        if len(labels) &gt; 0:
            &#47&#47 bboxes = torch.tensor(bboxes).roll(dims=1, shifts=1)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/alessandromondin/yolov5m/commit/6b474e8468a32129b9cc3499a6c96ef9cad8fbc3#diff-3c75bbc5e19f6e327e6c16638ad2413dc0d3200a9db147adecb096c4f05994faL84' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 28411211</div><div id='project'> Project Name: alessandromondin/yolov5m</div><div id='commit'> Commit Name: 6b474e8468a32129b9cc3499a6c96ef9cad8fbc3</div><div id='time'> Time: 2022-11-25</div><div id='author'> Author: alessandromondin00@gmail.com</div><div id='file'> File Name: dataset_ultra.py</div><div id='m_class'> M Class Name: MS_COCO_2017</div><div id='n_method'> N Class Name: MS_COCO_2017</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: dataset_ultra.py</div><div id='n_file'> N File Name: dataset_ultra.py</div><div id='m_start'> M Start Line: 94</div><div id='m_end'> M End Line: 118</div><div id='n_start'> N Start Line: 99</div><div id='n_end'> N End Line: 128</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        img = torch.from_numpy(img).to(self.device)
        img = img.float()  &#47&#47 uint8 to fp16/32
        img /= 255.0  &#47&#47 0 - 255 to 0.0 - 1.0
        <a id="change">if </a>img.ndimension() == 3:
            img<a id="change"> = </a><a id="change">img.unsqueeze(0</a><a id="change">)</a>
        return img
    
    def _postprocess(self, img, origimg, pred, conf_thres, iou_thres, height, width):
        </code></pre><h3>After Change</h3><pre><code class='java'>
            imgsz = check_img_size(max(img.shape[:2]), s=self.detector.stride.max())  &#47&#47 check img_size
            img = letterbox(img, new_shape=imgsz)[0]
            pp_imgs.append(img)
        pp_imgs = <a id="change">np.array(</a>pp_imgs<a id="change">)</a>
        pp_imgs = pp_imgs.transpose(0, 3, 1, 2)
        pp_imgs = torch.from_numpy(pp_imgs).to(self.device)
        pp_imgs = pp_imgs.float()  &#47&#47 uint8 to fp16/32
        pp_imgs /= 255.0  &#47&#47 0 - 255 to 0.0 - 1.0</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/elyha7/yoloface/commit/794e25df420f25fd7937e0af41fefd7bf184fad6#diff-f1b9b6b0dc58eb8986b1bfad93f0267affbcc78f5f1f1a553babeec2b36a8780L63' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 28411215</div><div id='project'> Project Name: elyha7/yoloface</div><div id='commit'> Commit Name: 794e25df420f25fd7937e0af41fefd7bf184fad6</div><div id='time'> Time: 2022-01-10</div><div id='author'> Author: artemrebrikov@gmail.com</div><div id='file'> File Name: face_detector.py</div><div id='m_class'> M Class Name: YoloDetector</div><div id='n_method'> N Class Name: YoloDetector</div><div id='m_method'> M Method Name: _preprocess(2)</div><div id='n_method'> N Method Name: _preprocess(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: face_detector.py</div><div id='n_file'> N File Name: face_detector.py</div><div id='m_start'> M Start Line: 67</div><div id='m_end'> M End Line: 83</div><div id='n_start'> N Start Line: 66</div><div id='n_end'> N End Line: 82</div><BR>