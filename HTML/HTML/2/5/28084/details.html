<html><h3>Pattern ID :28084
</h3><img src='83023763.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            df_val.append(df.reset_index(drop=True))
        else:
            df_train.append(df[df["ds"] &lt; threshold_time_stamp].reset_index(drop=True))
            <a id="change">df_val.append(</a>df[df["ds"] &gt;= threshold_time_stamp].reset_index(drop=True)<a id="change">)</a>
    return df_train, df_val


def split_df(df, n_lags, n_forecasts, valid_p=0.2, inputs_overbleed=True, local_modeling=False):</code></pre><h3>After Change</h3><pre><code class='java'>
    for key in df_dict:
        if df_dict[key]["ds"].max() &lt; threshold_time_stamp:
            df_train[key] = df_dict[key].copy(deep=True).reset_index(drop=True)
        elif <a id="change"></a>df_dict[key]["ds"].min() &gt; threshold_time_stamp:
            df_val[key] = df_dict[key].copy(deep=True).reset_index(drop=True)
        else:
            df = df_dict[key].copy(deep=True)
            n_train = len(df[df["ds"] &lt; threshold_time_stamp])
            split_idx_train = n_train + n_lags + n_forecasts - 1
            split_idx_val = split_idx_train - n_lags if inputs_overbleed else split_idx_train
            df_train[key]<a id="change"> = </a><a id="change">df.copy(deep=True).iloc[:split_idx_train]</a>.reset_index(drop=True)
            df_val[key] = df.copy(deep=True).iloc[split_idx_val:].reset_index(drop=True)
    return df_train, df_val
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ourownstory/neural_prophet/commit/6619741f934957dff2a7fa4ff66620772d41471f#diff-cb8ae2d50e5d5d245ed6fcc8cadf2baf7294fa9ac5c63e819fbfe34f0e4c2552L500' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83023763</div><div id='project'> Project Name: ourownstory/neural_prophet</div><div id='commit'> Commit Name: 6619741f934957dff2a7fa4ff66620772d41471f</div><div id='time'> Time: 2022-02-14</div><div id='author'> Author: ourownstory@users.noreply.github.com</div><div id='file'> File Name: neuralprophet/df_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: split_considering_timestamp(5)</div><div id='n_method'> N Method Name: split_considering_timestamp(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: neuralprophet/df_utils.py</div><div id='n_file'> N File Name: neuralprophet/df_utils.py</div><div id='m_start'> M Start Line: 500</div><div id='m_end'> M End Line: 510</div><div id='n_start'> N Start Line: 526</div><div id='n_end'> N End Line: 552</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    level = pyramid_levels_min
    total_anchors /= num_anchors
    while total_anchors &gt; 0:
        <a id="change">pyramid_levels.append(</a>level<a id="change">)</a>
        stride_hh, stride_ww = feature_sizes[0][0] / feature_sizes[level][0], feature_sizes[0][1] / feature_sizes[level][1]
        cur_num_anchors = tf.math.ceil(input_shape[0] / stride_hh) * tf.math.ceil(input_shape[1] / stride_ww)
        total_anchors -= int(cur_num_anchors)
        level += 1</code></pre><h3>After Change</h3><pre><code class='java'>


def get_pyramid_levels_by_anchors(input_shape, total_anchors, num_anchors="auto", pyramid_levels_min=3):
    feature_sizes = <a id="change">get_feature_sizes(input_shape, [pyramid_levels_min, pyramid_levels_min + 10])[pyramid_levels_min:]</a>
    feature_sizes = tf.convert_to_tensor(feature_sizes, dtype="int32")
    num_anchors_at_each_level_cumsum = tf.cumsum(tf.reduce_prod(feature_sizes, axis=-1))
    <a id="change">if </a>num_anchors == "auto":
        &#47&#47 Pick from [1, 3, 9], 1 for yolox, 3 for yolor, 9 for efficientdet
        picks = tf.convert_to_tensor([1, 3, 9], dtype=tf.int32)
        max_anchors<a id="change"> = </a>num_anchors_at_each_level_cumsum[-1] * picks
        num_anchors = picks[tf.argmax(total_anchors &lt; max_anchors)]

    total_anchors = total_anchors // num_anchors</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/df3cf1ce0ac4b02a9c73496b1a583b9a892c7b0a#diff-0b4f97076caf9c1a827dc3bdff3c0c4eb77d00da49f17542a248e3a2920b42d4L100' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83023761</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: df3cf1ce0ac4b02a9c73496b1a583b9a892c7b0a</div><div id='time'> Time: 2022-03-25</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/coco/anchors_func.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: get_pyramid_levels_by_anchors(4)</div><div id='n_method'> N Method Name: get_pyramid_levels_by_anchors(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/coco/anchors_func.py</div><div id='n_file'> N File Name: keras_cv_attention_models/coco/anchors_func.py</div><div id='m_start'> M Start Line: 101</div><div id='m_end'> M End Line: 112</div><div id='n_start'> N Start Line: 103</div><div id='n_end'> N End Line: 114</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            num_errors += 1
            continue

        <a id="change">all_ids.append(</a>sentence_id<a id="change">)</a>
        all_embeddings.append(embedding)

        if index % 1000 == 0:
            print(f&quotEmbedded {index} with {num_errors} errors&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
        start_ix = batch_ix * batch_size
        end_ix = min((batch_ix + 1) * batch_size, n_sentences)

        <a id="change">if </a>start_ix == end_ix:
            continue

        sentences_text = sentences.iloc[start_ix: end_ix][&quottext&quot].to_list()
        sentences_id<a id="change"> = </a><a id="change">sentences.iloc[start_ix: end_ix]</a>[&quotsentence_id&quot].to_list()

        try:
            preprocessed_sentences = model.preprocess_many(sentences_text)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bluebrain/search/commit/6eb30c8b3e77791ee4e407dd19d7a5e08fe5e132#diff-6a370a606e89902d9cea7c7edf876b91c643d1c115291d5912b04e3bd88cf446L263' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83023758</div><div id='project'> Project Name: bluebrain/search</div><div id='commit'> Commit Name: 6eb30c8b3e77791ee4e407dd19d7a5e08fe5e132</div><div id='time'> Time: 2020-09-04</div><div id='author'> Author: jankrepl@yahoo.com</div><div id='file'> File Name: src/bbsearch/embedding_models.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: compute_database_embeddings(4)</div><div id='n_method'> N Method Name: compute_database_embeddings(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/bbsearch/embedding_models.py</div><div id='n_file'> N File Name: src/bbsearch/embedding_models.py</div><div id='m_start'> M Start Line: 287</div><div id='m_end'> M End Line: 309</div><div id='n_start'> N Start Line: 433</div><div id='n_end'> N End Line: 494</div><BR>