<html><h3>Pattern ID :28379
</h3><img src='83715353.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            train_losses_this_epoch.append(float(grad_accum[-1]))
            if len(grad_accum) % gradient_accumulation == 0:
                train_loss = 0.0
                <a id="change">for </a>accum_loss in grad_accum<a id="change">:
                    </a>train_loss<a id="change"> += </a>accum_loss
                train_loss /= len(grad_accum)
                grad_accum = list()
                optimizer.zero_grad()</code></pre><h3>After Change</h3><pre><code class='java'>
        optimizer.zero_grad()
        train_losses_this_epoch = list()
        for train_datapoint in train_loader:
            train_loss<a id="change"> = </a>net(train_datapoint[0].to(device),
                             train_datapoint[1].to(device),
                             train_datapoint[2].to(device),
                             train_datapoint[3].to(device))
            train_losses_this_epoch.append(float(train_loss))
            (train_loss / gradient_accumulation).backward()
            <a id="change">del train_loss</a>
            grad_accum += 1
            if grad_accum % gradient_accumulation == 0:
                grad_accum = 0
                step_counter += 1</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/b3a6d9d487ef8387f96cc83cf6d4a4e51077d88c#diff-3733df8b039701cd2c523886f2a148aaa4acda8b5a48effada89068247bad70eL93' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83715353</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: b3a6d9d487ef8387f96cc83cf6d4a4e51077d88c</div><div id='time'> Time: 2021-02-24</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: PipelineTransformerTTS_CSS10.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train_loop(9)</div><div id='n_method'> N Method Name: train_loop(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: PipelineTransformerTTS_CSS10.py</div><div id='n_file'> N File Name: PipelineTransformerTTS_CSS10.py</div><div id='m_start'> M Start Line: 93</div><div id='m_end'> M End Line: 108</div><div id='n_start'> N Start Line: 93</div><div id='n_end'> N End Line: 106</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    matching_matrix[pppppp] = mmm
    print()
    &#47&#47 对每个gt，取cost最小的k个候选正样本去学习。
    <a id="change">for gt_idx</a> in range(num_gt)<a id="change">:
        </a>_<a id="change">, pos_idx = </a>torch.topk(cost[gt_idx], k=dynamic_ks[gt_idx], largest=False)
        matching_matrix[gt_idx][pos_idx] = 1
    del topk_ious, dynamic_ks, pos_idx
</code></pre><h3>After Change</h3><pre><code class='java'>
    _, pos_idx = torch.topk(cost, k=max_k, largest=False)
    M = cost.shape[1]
    offset = torch.arange(start=0, end=M*num_gt, step=M, dtype=torch.int64, device=cost.device).unsqueeze(-1)
    pos_idx_1d<a id="change"> = </a>(pos_idx + offset).flatten()
    matching_matrix = matching_matrix.flatten()
    matching_matrix[pos_idx_1d] = fill_value.flatten()
    matching_matrix = matching_matrix.reshape(cost.shape)
    <a id="change">del topk_ious, dynamic_ks, max_k, masks, fill_value, pos_idx, offset, pos_idx_1d</a>

    &#47&#47 [M, ]  M个候选正样本匹配的gt数
    anchor_matching_gt = matching_matrix.sum(0)
    &#47&#47 deal with the case that one anchor matches multiple ground-truths</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/miemie2013/miemiedetection/commit/43dd136f727776fe4f3474de2de9675c0617c409#diff-4b0ddb3c787ff21a73dd6799a6ee13237ca68ff513f445cf155bbfb6a438c6f0L42' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83715352</div><div id='project'> Project Name: miemie2013/miemiedetection</div><div id='commit'> Commit Name: 43dd136f727776fe4f3474de2de9675c0617c409</div><div id='time'> Time: 2023-05-08</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: test_code/test2_YOLOX_simota_matching.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: simota_matching2(3)</div><div id='n_method'> N Method Name: simota_matching2(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: test_code/test2_YOLOX_simota_matching.py</div><div id='n_file'> N File Name: test_code/test2_YOLOX_simota_matching.py</div><div id='m_start'> M Start Line: 52</div><div id='m_end'> M End Line: 89</div><div id='n_start'> N Start Line: 52</div><div id='n_end'> N End Line: 69</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def _trocr(self, image):
        generated_text = ""
        img = image.copy()
        <a id="change">for box</a> in text_boxes(image)<a id="change">:
            </a>x,y,w,h = box
            rect = cv2.rectangle(im2, (x, y), (x + w, y + h), (0, 255, 0), 2)
            cropped<a id="change"> = </a>im2[y:y + h, x:x + w]
            pixel_values = self.processor(images=cropped, return_tensors="pt").pixel_values
            generated_ids = self.model.generate(pixel_values)
            del pixel_values</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47generated_text = ""
        img = np.asarray(image.copy())
        &#47&#47crops = np.array([])
        crops<a id="change"> = </a>[]
        print("&gt; Cropping page into lines")
        for box in tqdm(text_boxes(image)):
            x,y,w,h = box
            rect = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)
            crops.append(Image.fromarray(img[y:y + h, x:x + w]).convert("RGB"))
        print("&gt; Done Cropping")
        print("&gt; Running TrOCR")
        pixel_values = self.processor(images=crops, return_tensors="pt").pixel_values
        print("| &gt; loaded pixels")
        <a id="change">del crops</a>
        del img
        generated_ids = self.model.generate(pixel_values)
        print("| &gt; generated tokens")
        del pixel_values</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/cypherousskies/reading-for-listeners/commit/f9df6b3112187a0c2ae890489418e9c98598d3eb#diff-dde6c90e8413176f059fd93b4ebc0abc7f2fa7cbe7e3a735d30cb92e9b50da51L78' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83715354</div><div id='project'> Project Name: cypherousskies/reading-for-listeners</div><div id='commit'> Commit Name: f9df6b3112187a0c2ae890489418e9c98598d3eb</div><div id='time'> Time: 2022-03-09</div><div id='author'> Author: 5472563+CypherousSkies@users.noreply.github.com</div><div id='file'> File Name: reading4listeners/util/ocr.py</div><div id='m_class'> M Class Name: TrOCR</div><div id='n_method'> N Class Name: TrOCR</div><div id='m_method'> M Method Name: _trocr(2)</div><div id='n_method'> N Method Name: _trocr(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: reading4listeners/util/ocr.py</div><div id='n_file'> N File Name: reading4listeners/util/ocr.py</div><div id='m_start'> M Start Line: 79</div><div id='m_end'> M End Line: 90</div><div id='n_start'> N Start Line: 82</div><div id='n_end'> N End Line: 102</div><BR>