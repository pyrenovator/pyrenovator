<html><h3>Pattern ID :23891
</h3><img src='74413934.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 Memory querying and responding for visual features

        dummy_memory_matrix = self.memory_matrix.unsqueeze(0).expand(att_feats.size(0), <a id="change">self.memory_matrix.size(0</a><a id="change">)</a>, self.memory_matrix.size(1))
        responses = self.cmn(att_feats, dummy_memory_matrix, dummy_memory_matrix)

        max_num_protype = max((labels[:,-1]*3 + labels[:,:-1].sum(-1))) * self.num_prototype</code></pre><h3>After Change</h3><pre><code class='java'>
        cmn_masks = self.memory_matrix.new_zeros(query_matrix.shape[0], att_feats.size(1), max_num_protype)

        for i in range(att_feats.size(0)):
            cur_query_matrix<a id="change"> = []</a>
            &#47&#47print(labels[i])
            for j in range(len(labels[i])):
                if labels[i, j] == 1:
                    if j != len(labels[i])-1:
                        cur_query_matrix.extend(self.memory_matrix[j*self.num_prototype:(j+1)*self.num_prototype, :])
                    else:
                        <a id="change">cur_query_matrix.extend(</a>self.memory_matrix[j * self.num_prototype:, :]<a id="change">)</a>

            cur_query_matrix = torch.stack(cur_query_matrix, 0)
            &#47&#47print(&quot111&quot,query_matrix[i, :cur_query_matrix.shape[0], :].shape, cur_query_matrix.shape)
            query_matrix[i, :cur_query_matrix.shape[0], :] = cur_query_matrix</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/markin-wang/xpronet/commit/947c6bd650f8ff11d6c2f9a12f79d265c1f384ce#diff-b630bb1eacf9d665efc0c82b70d348b40f19422267ac86cbe6329800b8b3d4d3L400' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74413934</div><div id='project'> Project Name: markin-wang/xpronet</div><div id='commit'> Commit Name: 947c6bd650f8ff11d6c2f9a12f79d265c1f384ce</div><div id='time'> Time: 2021-11-23</div><div id='author'> Author: cserwj@gmail.com</div><div id='file'> File Name: modules/base_cmn.py</div><div id='m_class'> M Class Name: BaseCMN</div><div id='n_method'> N Class Name: BaseCMN</div><div id='m_method'> M Method Name: _prepare_feature_forward(5)</div><div id='n_method'> N Method Name: _prepare_feature_forward(5)</div><div id='m_parent_class'> M Parent Class: AttModel</div><div id='n_parent_class'> N Parent Class: AttModel</div><div id='m_file'> M File Name: modules/base_cmn.py</div><div id='n_file'> N File Name: modules/base_cmn.py</div><div id='m_start'> M Start Line: 400</div><div id='m_end'> M End Line: 401</div><div id='n_start'> N Start Line: 404</div><div id='n_end'> N End Line: 422</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            loss = criterion(output, target)

            &#47&#47 record loss
            losses.update(loss.item(), <a id="change">x_in.size(0</a><a id="change">)</a>)

            &#47&#47 forward through postprocessor (scaling, etc.) and do evaluation
            if post_processor is not None:</code></pre><h3>After Change</h3><pre><code class='java'>

    inputs = []
    outputs = []
    tars<a id="change"> = []</a>

    Eval mode.
    with torch.no_grad():
        end = time.time()
        for i, (x_in, target, em_tar) in enumerate(val_loader):

            x_in = x_in.to(hy_par.device)
            if type(target) is torch.Tensor:
                target = target.to(hy_par.device)
            elif type(target) in (tuple, list):
                target = (target[0].to(hy_par.device), target[1].to(hy_par.device))
            else:
                raise TypeError("Not supported type to push to cuda.")

            &#47&#47 compute output
            output = model(x_in)
            loss = criterion(output, target)

            &#47&#47 record loss
            losses.update(loss.item())

            &#47&#47 measure elapsed time
            batch_time.update(time.time() - end)
            end = time.time()

            inputs.append(x_in.cpu())
            outputs.append(output.detach().cpu())
            <a id="change">tars.extend(</a>em_tar<a id="change">)</a>

    print("Test: Time: {batch_time.avg:.3f} \t""Loss: {loss.avg:.4f}".format(batch_time=batch_time, loss=losses))

    Forward output through post-processor for eval.</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/turagalab/decode/commit/889789c97eb30b2a757b6ab589c7472589f22f2a#diff-9d0572aba2fe317f29a36ea3db7de768a7c5d025accf738e260660614d587dccL171' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74413933</div><div id='project'> Project Name: turagalab/decode</div><div id='commit'> Commit Name: 889789c97eb30b2a757b6ab589c7472589f22f2a</div><div id='time'> Time: 2019-05-14</div><div id='author'> Author: gitdev@LRM.photo</div><div id='file'> File Name: deepsmlm/neuralfitter/train_test.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test(8)</div><div id='n_method'> N Method Name: test(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: deepsmlm/neuralfitter/train_test.py</div><div id='n_file'> N File Name: deepsmlm/neuralfitter/train_test.py</div><div id='m_start'> M Start Line: 178</div><div id='m_end'> M End Line: 227</div><div id='n_start'> N Start Line: 176</div><div id='n_end'> N End Line: 217</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        embeddings = self.tgt_embed(tgt)

        &#47&#47 Memory querying and responding for textual features
        dummy_memory_matrix = memory_matrix.unsqueeze(0).expand(embeddings.size(0), memory_matrix.size(0), <a id="change">memory_matrix.size(1</a><a id="change">)</a>)
        &#47&#47dummy_memory_matrix = torch.stack([self.memory_matrix[labels[i] == 1, :] for i in range(embeddings.size(0))])
        responses = self.cmn(embeddings, dummy_memory_matrix, dummy_memory_matrix)
        embeddings = embeddings + responses</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47responses = self.cmn(embeddings, dummy_memory_matrix, dummy_memory_matrix)
        responses = []
        for i in range(embeddings.size(0)):
            query_matrix<a id="change"> = []</a>
            for j in range(len(labels[i])):
                if labels[i, j] == 1:
                    if j != len(labels[i])-1:
                        query_matrix.extend(memory_matrix[j*self.num_prototype:(j+1)*self.num_prototype, :])
                    else:
                        <a id="change">query_matrix.extend(</a>memory_matrix[j * self.num_prototype:, :]<a id="change">)</a>

            query_matrix = torch.stack(query_matrix, 0)
            query_matrix = query_matrix.unsqueeze(0)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/markin-wang/xpronet/commit/8a47fdb250bd2c0c90632d5faf0fa10481af5ee7#diff-b630bb1eacf9d665efc0c82b70d348b40f19422267ac86cbe6329800b8b3d4d3L73' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74413932</div><div id='project'> Project Name: markin-wang/xpronet</div><div id='commit'> Commit Name: 8a47fdb250bd2c0c90632d5faf0fa10481af5ee7</div><div id='time'> Time: 2021-11-21</div><div id='author'> Author: cserwj@gmail.com</div><div id='file'> File Name: modules/base_cmn.py</div><div id='m_class'> M Class Name: Transformer</div><div id='n_method'> N Class Name: Transformer</div><div id='m_method'> M Method Name: decode(8)</div><div id='n_method'> N Method Name: decode(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: modules/base_cmn.py</div><div id='n_file'> N File Name: modules/base_cmn.py</div><div id='m_start'> M Start Line: 74</div><div id='m_end'> M End Line: 79</div><div id='n_start'> N Start Line: 75</div><div id='n_end'> N End Line: 97</div><BR>