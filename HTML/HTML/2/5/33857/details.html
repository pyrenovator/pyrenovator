<html><h3>Pattern ID :33857
</h3><img src='97090537.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        current_q.append(val); probs.append(taus)
    current_q = torch.stack(current_q, dim=0)
    curr_qval = [current_q[i].gather(1, acts.view(-1, 1)) for i in range(pred_sprt)]
    curr_qval<a id="change"> = </a><a id="change">torch.stack(curr_qval, dim=1).squeeze(2</a><a id="change">)</a>
    probs = torch.stack(probs, dim=1).unsqueeze(1)
    
    &#47&#47Quantile Regresion Loss
    target_q = target_q.view(batch_size, -1, 1).expand(-1, target_sprt, pred_sprt).detach()</code></pre><h3>After Change</h3><pre><code class='java'>
    next_q = torch.stack(next_q, dim=2)
    max_act = next_q.mean(dim=2).argmax(dim=1)
    next_qval = [next_q[idx][max_a] for idx, max_a in enumerate(max_act)] 
    next_qval<a id="change"> = </a><a id="change">torch.stack(</a>next_qval<a id="change">, dim=0)</a>
    target_q = rewards.view(-1, 1) + discount_factor * next_qval
    
    current_q, probs = [], []
    for _ in range(pred_sprt):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 7</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/rl-max/deep-reinforcement-learning-pytorch/commit/73861608078d0aaa893895fc1bcf77e21a3ac545#diff-aafdd1355396b0b9cfce8d3137c104171c757bb77905f5016e809fe8d214d2ddL60' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 97090537</div><div id='project'> Project Name: rl-max/deep-reinforcement-learning-pytorch</div><div id='commit'> Commit Name: 73861608078d0aaa893895fc1bcf77e21a3ac545</div><div id='time'> Time: 2021-06-15</div><div id='author'> Author: poiroth946@gmail.com</div><div id='file'> File Name: iqn.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(4)</div><div id='n_method'> N Method Name: train(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: iqn.py</div><div id='n_file'> N File Name: iqn.py</div><div id='m_start'> M Start Line: 60</div><div id='m_end'> M End Line: 73</div><div id='n_start'> N Start Line: 61</div><div id='n_end'> N End Line: 73</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            &#47&#47mask = torch.round(masks)

            center_img_salient = rgb_center_img_tensor*mask     &#47&#47 3 channels x 1 frame x H x W
            center_img_salient = <a id="change">center_img_salient.squeeze(1</a><a id="change">)</a>

            &#47&#47 Put image values into range [0, 1] and then normalize using 
            &#47&#47 mean and std for ImageNet
            &#47&#47 https://pytorch.org/docs/stable/torchvision/models.html

            center_img_salient = tensor_min_max_normalize(center_img_salient)
            normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
            center_img_salient = normalize(center_img_salient)

            &#47&#47print (&quotInput size&quot, input.size())      
            &#47&#47print (&quotsalient&quot, center_img_salient.size())    
            &#47&#47print(vid_path)

            &#47&#47 Visualize mask region
            &#47&#47center_img = vid_tensor_to_numpy(center_img_salient.unsqueeze(1))[0]
            &#47&#47center_img = cv2.cvtColor(center_img, cv2.COLOR_RGB2BGR)
            &#47&#47center_img = cv_f32_to_u8(center_img)
            &#47&#47cv2.imshow(&quotinput&quot, center_img)
            &#47&#47cv2.waitKey()

            &#47&#47&#47&#47 Visual mask
            &#47&#47&#47&#47mask = vid_tensor_to_numpy(input[3].unsqueeze(0))[0]
            &#47&#47&#47&#47print(mask)
            &#47&#47&#47&#47mask = cv2.merge([mask, mask, mask])

            center_img_salient<a id="change"> = </a>center_img_salient.unsqueeze(0)
            if cuda:
                center_img_salient = center_img_salient.to(device)
</code></pre><h3>After Change</h3><pre><code class='java'>
                                    std=[0.229, 0.224, 0.225])
                center_img_salient = normalize(center_img_salient)
                center_img_salient_batch.append(center_img_salient)
            center_img_salient<a id="change"> = </a><a id="change">torch.stack(</a>center_img_salient_batch<a id="change">, dim=0)</a>  &#47&#47 N x 3 channels x 1 frame x H x W

            &#47&#47print (&quotInput size&quot, inputs.size())      
            &#47&#47print (&quotsalient&quot, center_img_salient.size())    </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rvl-lab-utoronto/video_similarity_search/commit/18ec38547447c76ceed935f971282fce78095ca3#diff-98f1ab4b8aa34886d0f0a9d861b630e102aafdb9b6fed0569e138b1facf9d4efL49' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 97090555</div><div id='project'> Project Name: rvl-lab-utoronto/video_similarity_search</div><div id='commit'> Commit Name: 18ec38547447c76ceed935f971282fce78095ca3</div><div id='time'> Time: 2020-08-28</div><div id='author'> Author: salar77h@gmail.com</div><div id='file'> File Name: clustering/cluster_masks.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: get_embeddings_mask_regions(4)</div><div id='n_method'> N Method Name: get_embeddings_mask_regions(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: clustering/cluster_masks.py</div><div id='n_file'> N File Name: clustering/cluster_masks.py</div><div id='m_start'> M Start Line: 60</div><div id='m_end'> M End Line: 125</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 111</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if self.sl_f != 0 and self.sl is not None:
            sl = torch.zeros((), device=clean.device)
            for mss in multi_stage_specs:
                mss<a id="change"> = </a>as_complex(<a id="change">mss.squeeze(1</a><a id="change">)</a>).unsqueeze(1)
                sl += self.sl(input=mss, target=clean[..., : mss.shape[-1]])
            else:
                sl = self.sl(input=enhanced, target=clean)</code></pre><h3>After Change</h3><pre><code class='java'>
        multi_stage_td = None
        if multi_stage_specs:
            &#47&#47 Stack spectrograms in a channel dimension
            multi_stage<a id="change"> = </a>as_complex(<a id="change">torch.stack(</a>multi_stage_specs<a id="change">, dim=1)</a>)
        lsnr_gt = self.lsnr(clean, noise=noisy - clean)
        if self.istft is not None:
            if self.store_losses or self.mrsl is not None:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rikorose/deepfilternet/commit/2aacf4d049fc9e7b073c15d705c60f87f3d554f7#diff-bb896194128eb37561935a04f142d629f33c23c5617c6717dd129c556d97e5c3L436' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 97090540</div><div id='project'> Project Name: rikorose/deepfilternet</div><div id='commit'> Commit Name: 2aacf4d049fc9e7b073c15d705c60f87f3d554f7</div><div id='time'> Time: 2022-04-12</div><div id='author'> Author: h.schroeter@pm.me</div><div id='file'> File Name: DeepFilterNet/df/loss.py</div><div id='m_class'> M Class Name: Loss</div><div id='n_method'> N Class Name: Loss</div><div id='m_method'> M Method Name: forward(10)</div><div id='n_method'> N Method Name: forward(10)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: DeepFilterNet/df/loss.py</div><div id='n_file'> N File Name: DeepFilterNet/df/loss.py</div><div id='m_start'> M Start Line: 468</div><div id='m_end'> M End Line: 474</div><div id='n_start'> N Start Line: 456</div><div id='n_end'> N End Line: 485</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    cum_sum = ref3.cumsum(dim=-1)
    lens = masks.sum(dim=-1)
    assert lens.ndim == 1
    cum_sum<a id="change"> = </a><a id="change">cum_sum.index_select(-1, lens.int()).squeeze(-1</a><a id="change">)</a>
    spk_emb = cum_sum / lens[:, None]
    return spk_emb

</code></pre><h3>After Change</h3><pre><code class='java'>
    cum_sum = ref3.cumsum(dim=-1)
    lens = (~masks).sum(dim=-1)
    assert lens.ndim == 1
    tmp<a id="change"> = </a><a id="change">torch.stack(</a>[cum_sum[i, :, lens[i] - 1] for i in range(len(cum_sum))]<a id="change">)</a>
    spk_emb = tmp / lens[:, None]
    return spk_emb

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ga642381/robustvc/commit/81b5e04f16ab1c96b73ded4ad3751626d1212770#diff-08cfb8f971b5d341127ff7def77a0e3c285d3d467a1972edd16081a8c1d1b541L55' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 97090543</div><div id='project'> Project Name: ga642381/robustvc</div><div id='commit'> Commit Name: 81b5e04f16ab1c96b73ded4ad3751626d1212770</div><div id='time'> Time: 2021-09-16</div><div id='author'> Author: ga642381@gmail.com</div><div id='file'> File Name: S2VC/S2VC-robust/train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: extract_ref_feats(3)</div><div id='n_method'> N Method Name: extract_ref_feats(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: S2VC/S2VC-robust/train.py</div><div id='n_file'> N File Name: S2VC/S2VC-robust/train.py</div><div id='m_start'> M Start Line: 59</div><div id='m_end'> M End Line: 63</div><div id='n_start'> N Start Line: 68</div><div id='n_end'> N End Line: 72</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            else:
                gru_output, h_n = self.rnn(x.unsqueeze(1), h_n)
            &#47&#47 output dim: BSx1 and Squeeze sequence length after completing GRU step
            x<a id="change"> = </a>self.fc_resnet(<a id="change">gru_output.squeeze(1</a><a id="change">)</a>)
            &#47&#47 normalize by frame-rate: 25.0 for VIPL
            &#47&#47 x = x*25.0
            batched_output_per_clip.append(x.squeeze(0))</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47     &#47&#47 hr = hr * 25.0
            hr_per_clip.append(hr.flatten())

        output_seq<a id="change"> = </a><a id="change">torch.stack(</a>hr_per_clip<a id="change">, dim=0)</a>.permute(1,0)
        &#47&#47 return output_seq, gru_output.squeeze(0), fc_out
        return output_seq, output_seq.squeeze(0)[:6]
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/anweshcr7/rhythmnet/commit/0f9fc9b96933c04f723fbfa5b80cdf1a398828c3#diff-3fc5bf831ef8bd1cc5d50189ec691215fb3d3ae0cbb974e736200edc7f8c65cdL32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 97090531</div><div id='project'> Project Name: anweshcr7/rhythmnet</div><div id='commit'> Commit Name: 0f9fc9b96933c04f723fbfa5b80cdf1a398828c3</div><div id='time'> Time: 2021-03-14</div><div id='author'> Author: anwesh.marwade@beyondsports.nl</div><div id='file'> File Name: src/models/rhythmNet.py</div><div id='m_class'> M Class Name: RhythmNet</div><div id='n_method'> N Class Name: RhythmNet</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/models/rhythmNet.py</div><div id='n_file'> N File Name: src/models/rhythmNet.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 56</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 64</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                backward_probs = self.backward_actions_sampler.get_probs(
                    non_sink_new_states
                )
                trajectories_log_pbs[~sink_states_mask]<a id="change"> += </a>(
                    <a id="change">backward_probs.gather(-1, actions[~sink_states_mask].unsqueeze(-1))
                    .squeeze(-1</a><a id="change">)</a>
                    .log()
                )
            step += 1
</code></pre><h3>After Change</h3><pre><code class='java'>
        trajectories_states = torch.stack(trajectories_states, dim=0)
        trajectories_states = self.env.States(states_tensor=trajectories_states)
        trajectories_actions = torch.stack(trajectories_actions, dim=0)
        trajectories_logprobs<a id="change"> = </a><a id="change">torch.stack(</a>trajectories_logprobs<a id="change">, dim=0)</a>

        trajectories = Trajectories(
            env=self.env,
            states=trajectories_states,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/saleml/gfn/commit/095aeaefbabb8e69ada4d72b7f158d5f687f387b#diff-65f1a1871bf9322279626a0aa4389807a06b9711fc2901a9f8e4fbced4327d40L44' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 97090534</div><div id='project'> Project Name: saleml/gfn</div><div id='commit'> Commit Name: 095aeaefbabb8e69ada4d72b7f158d5f687f387b</div><div id='time'> Time: 2022-10-25</div><div id='author'> Author: salemlahlou9@gmail.com</div><div id='file'> File Name: src/gfn/samplers/trajectories_sampler.py</div><div id='m_class'> M Class Name: TrajectoriesSampler</div><div id='n_method'> N Class Name: TrajectoriesSampler</div><div id='m_method'> M Method Name: sample_trajectories(3)</div><div id='n_method'> N Method Name: sample_trajectories(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/gfn/samplers/trajectories_sampler.py</div><div id='n_file'> N File Name: src/gfn/samplers/trajectories_sampler.py</div><div id='m_start'> M Start Line: 58</div><div id='m_end'> M End Line: 119</div><div id='n_start'> N Start Line: 47</div><div id='n_end'> N End Line: 106</div><BR>