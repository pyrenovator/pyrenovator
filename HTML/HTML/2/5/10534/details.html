<html><h3>Pattern ID :10534
</h3><img src='36682697.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                batch = tuple(t.to(self.device) for t in batch)
                input_ids, input_mask, segment_ids, label_ids = batch
                train_target = Class2Simi(label_ids, mode=&quotcls&quot).detach()
                loss_fct<a id="change"> = </a><a id="change">nn.CrossEntropyLoss()</a>
                loss = self.model(input_ids, segment_ids, input_mask, train_target, loss_fct = loss_fct, mode = &quottrain&quot)
                
                self.optimizer.zero_grad()
                loss.backward()</code></pre><h3>After Change</h3><pre><code class='java'>
                
        self.model = best_model

        <a id="change">if args.save_model</a>:
            pretrained_model_dir<a id="change"> = </a>os.path.join(args.method_output_dir, &quotpretrain&quot)
            if not os.path.exists(pretrained_model_dir):
                os.makedirs(pretrained_model_dir)
            save_model(self.model, pretrained_model_dir)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/thuiar/textoir/commit/4f0068bc25a3a26da045579505b16f4458389c60#diff-f247534295e46ad22b9247198c94dfeff934046fe3fa4dde83add533bb77c39aL51' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 36682697</div><div id='project'> Project Name: thuiar/textoir</div><div id='commit'> Commit Name: 4f0068bc25a3a26da045579505b16f4458389c60</div><div id='time'> Time: 2021-08-02</div><div id='author'> Author: zhang-hl20@mails.tsinghua.edu.cn</div><div id='file'> File Name: open_intent_discovery/methods/semi_supervised/KCL_BERT/pretrain.py</div><div id='m_class'> M Class Name: PretrainKCLManager</div><div id='n_method'> N Class Name: PretrainKCLManager</div><div id='m_method'> M Method Name: train(3)</div><div id='n_method'> N Method Name: train(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: open_intent_discovery/methods/semi_supervised/KCL_BERT/pretrain.py</div><div id='n_file'> N File Name: open_intent_discovery/methods/semi_supervised/KCL_BERT/pretrain.py</div><div id='m_start'> M Start Line: 51</div><div id='m_end'> M End Line: 81</div><div id='n_start'> N Start Line: 56</div><div id='n_end'> N End Line: 113</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.global_avgpooling = torch.nn.AdaptiveAvgPool1d(1)
        &#47&#47 损失函数, loss
        self.loss_type = self.graph_config.loss_type if self.graph_config.loss_type else "BCE"
        self.loss_ce<a id="change"> = </a><a id="change">torch.nn.CrossEntropyLoss(ignore_index=0)</a>
        self.loss_mlsm = torch.nn.MultiLabelSoftMarginLoss()  &#47&#47 like BCEWithLogitsLoss
        self.loss_bcelog = torch.nn.BCEWithLogitsLoss()
        self.loss_bce = torch.nn.BCELoss()
        self.loss_mse = torch.nn.MSELoss()</code></pre><h3>After Change</h3><pre><code class='java'>
        self.pretrained_config = pretrained_config.from_pretrained(graph_config.pretrained_model_name_or_path, output_hidden_states=graph_config.output_hidden_states)
        self.pretrained_config.update({"gradient_checkpointing": True})
        super(TCGraph, self).__init__(self.pretrained_config)
        <a id="change">if self.graph_config.is_train</a>:
            self.pretrain_model = pretrained_model.from_pretrained(graph_config.pretrained_model_name_or_path, config=self.pretrained_config)
            self.pretrain_model.resize_token_embeddings(len(tokenizer))
        else:
            self.pretrain_model<a id="change"> = </a>pretrained_model(self.pretrained_config)  &#47&#47 推理时候只需要加载超参数, 不需要预训练模型的权重
            self.pretrain_model.resize_token_embeddings(len(tokenizer))
        &#47&#47 &#47&#47 tokenizer.model_max_length = self.model.config.max_position_embeddings
        &#47&#47 如果用隐藏层输出</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yongzhuo/pytorch-nlu/commit/d3946801ec80f6f92ff2bd08b9cb342f904934c2#diff-ffe92dac8f6d0ce49425ecd1f744dc91c3d97ec5292888cc015279cae9de336cL17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 36682696</div><div id='project'> Project Name: yongzhuo/pytorch-nlu</div><div id='commit'> Commit Name: d3946801ec80f6f92ff2bd08b9cb342f904934c2</div><div id='time'> Time: 2023-02-02</div><div id='author'> Author: 2714618994@qq.com</div><div id='file'> File Name: pytorch_nlu/pytorch_textclassification/tcGraph.py</div><div id='m_class'> M Class Name: TCGraph</div><div id='n_method'> N Class Name: TCGraph</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(2)</div><div id='m_parent_class'> M Parent Class: BertPreTrainedModel</div><div id='n_parent_class'> N Parent Class: BertPreTrainedModel</div><div id='m_file'> M File Name: pytorch_nlu/pytorch_textclassification/tcGraph.py</div><div id='n_file'> N File Name: pytorch_nlu/pytorch_textclassification/tcGraph.py</div><div id='m_start'> M Start Line: 27</div><div id='m_end'> M End Line: 56</div><div id='n_start'> N Start Line: 16</div><div id='n_end'> N End Line: 42</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        base_model = GPTModel(**config)
        model = GPTLMHeadModel(base_model)

        loss_fct<a id="change"> = </a><a id="change">paddle.nn.loss.CrossEntropyLoss()</a>

        logits = model(input_ids)
        loss = loss_fct(logits, input_ids)
        self.parent.assertEqual(loss.shape, [1])</code></pre><h3>After Change</h3><pre><code class='java'>
        base_model = GPTModel(**config)
        model = GPTLMHeadModel(base_model)

        <a id="change">if self.parent.use_labels</a>:
            loss<a id="change">, logits = </a>model(input_ids, labels=input_ids, return_dict=self.parent.return_dict)
            self.parent.assertEqual(loss.shape, [1])
            self.parent.assertEqual(logits.shape, [self.batch_size, self.seq_length, self.vocab_size])
            loss.backward()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/db3bde142ca2da76bfc701cd4ecc17140c248060#diff-587ce97ea371bcb9aa115ae9d48a2c9ffbf7d3bda55f68549cda07362b5e5a68L288' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 36682695</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: db3bde142ca2da76bfc701cd4ecc17140c248060</div><div id='time'> Time: 2022-12-06</div><div id='author'> Author: 40912707+Yam0214@users.noreply.github.com</div><div id='file'> File Name: tests/transformers/gpt/test_modeling.py</div><div id='m_class'> M Class Name: GPTModelTester</div><div id='n_method'> N Class Name: GPTModelTester</div><div id='m_method'> M Method Name: create_and_check_forward_and_backwards(4)</div><div id='n_method'> N Method Name: create_and_check_forward_and_backwards(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/transformers/gpt/test_modeling.py</div><div id='n_file'> N File Name: tests/transformers/gpt/test_modeling.py</div><div id='m_start'> M Start Line: 292</div><div id='m_end'> M End Line: 298</div><div id='n_start'> N Start Line: 318</div><div id='n_end'> N End Line: 324</div><BR>