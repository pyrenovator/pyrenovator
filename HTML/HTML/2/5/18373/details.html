<html><h3>Pattern ID :18373
</h3><img src='60152209.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        text_len = torch.LongTensor([self.feature_list[index][1]]).to(self.device)
        speech = torch.transpose(torch.Tensor(self.feature_list[index][2]), 0, 1).to(self.device)
        speech_len = torch.LongTensor([self.feature_list[index][3]]).to(self.device)
        <a id="change">if </a>self.spemb:
            spemb = torch.Tensor(self.feature_list[index][4]).to(self.device)
            return text, text_len, speech, speech_len, spemb
        return text, text_len, speech, speech_len</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 return a pair of cleaned audio and spectrogram
        file_path = self.list_of_paths[index]
        wave, sr = sf.read(file_path)
        <a id="change">if self.ap is None</a>:
            self.ap<a id="change"> = </a><a id="change">AudioPreprocessor(input_sr=sr, output_sr=16000, melspec_buckets=80)</a>
        normalized_wave = self.ap.audio_to_wave_tensor(wave, normalize=True, mulaw=False).to(self.device)
        melspec = self.ap.audio_to_mel_spec_tensor(normalized_wave, normalize=False).to(self.device)
        return normalized_wave, melspec
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/b43437ffd52b1d82638a75e3648c752f2492652c#diff-6d37714a960ee957f0bd8c25ac6b1f0f61e2e6e8f14e269209172239a689a904L19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60152209</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: b43437ffd52b1d82638a75e3648c752f2492652c</div><div id='time'> Time: 2021-02-19</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: MelGAN/MelGANDataset.py</div><div id='m_class'> M Class Name: MelGANDataset</div><div id='n_method'> N Class Name: MelGANDataset</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: MelGAN/MelGANDataset.py</div><div id='n_file'> N File Name: MelGAN/MelGANDataset.py</div><div id='m_start'> M Start Line: 19</div><div id='m_end'> M End Line: 26</div><div id='n_start'> N Start Line: 23</div><div id='n_end'> N End Line: 29</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    if not (min_len &lt;= dur_in_seconds &lt;= max_len):
                        print(f"Excluding {_norm_unsilenced_path} because of its duration of {round(dur_in_seconds, 2)} seconds.")
                        continue
                    <a id="change">if </a>sr != ap.sr:
                        print(f"Inconsistent sampling rate in the Data! Excluding {_norm_unsilenced_path}")
                        continue
                except RuntimeError:</code></pre><h3>After Change</h3><pre><code class='java'>
                    unsilence.render_media(_norm_unsilenced_path, silent_speed=12, silent_volume=0, audio_only=True)
                try:
                    wave, sr = sf.read(_norm_unsilenced_path)
                    <a id="change">if ap_post is None</a>:
                        ap_post<a id="change"> = </a><a id="change">AudioPreprocessor(input_sr=sr, output_sr=16000, melspec_buckets=80, hop_length=256, n_fft=1024, cut_silence=cut_silences)</a>
                    if sr != ap_post.sr:
                        print(f"Inconsistent sample rate! {_norm_unsilenced_path}")
                        continue
                    norm_wave = ap_post.resample(torch.Tensor(wave))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/75b62a182afd59073742c3952753398ba2935e03#diff-a49dac0d7d67877dcf8511175f18c0155a9aba98acf2e0ee7bfd3a2ed69fb144L124' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60152208</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 75b62a182afd59073742c3952753398ba2935e03</div><div id='time'> Time: 2021-10-04</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/TacotronDataset.py</div><div id='m_class'> M Class Name: TacotronDataset</div><div id='n_method'> N Class Name: TacotronDataset</div><div id='m_method'> M Method Name: cache_builder_process(9)</div><div id='n_method'> N Method Name: cache_builder_process(9)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/TacotronDataset.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/TacotronDataset.py</div><div id='m_start'> M Start Line: 129</div><div id='m_end'> M End Line: 168</div><div id='n_start'> N Start Line: 129</div><div id='n_end'> N End Line: 171</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        text_len = torch.LongTensor([self.feature_list[index][1]]).to(self.device)
        speech = torch.transpose(torch.Tensor(self.feature_list[index][2]), 0, 1).to(self.device)
        speech_len = torch.LongTensor([self.feature_list[index][3]]).to(self.device)
        <a id="change">if </a>self.spemb:
            spemb = torch.Tensor(self.feature_list[index][4]).to(self.device)
            return text, text_len, speech, speech_len, spemb
        return text, text_len, speech, speech_len</code></pre><h3>After Change</h3><pre><code class='java'>
        transcript = self.path_to_transcript_dict[self.key_list[index]]
        path = self.key_list[index]
        wave, sr = sf.read(os.path.join("Corpora/CSS10/", path))
        <a id="change">if self.ap is None</a>:
            self.ap<a id="change"> = </a><a id="change">AudioPreprocessor(input_sr=sr, output_sr=16000, melspec_buckets=80, hop_length=256, n_fft=1024)</a>
        text = self.tf.string_to_tensor(transcript).long()
        text_len = torch.LongTensor(text.shape(0))
        speech = torch.transpose(self.ap.audio_to_mel_spec_tensor(wave), 0, 1)
        speech_len = torch.LongTensor(speech.shape(1))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/1e192df888be8f1dc1c20971132b31fe73153b7d#diff-0965ad6e3a8f04afe3a358a7558e203eaa1f244ad6e8e6fbfe73f8a2052b8cb1L12' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60152207</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 1e192df888be8f1dc1c20971132b31fe73153b7d</div><div id='time'> Time: 2021-02-22</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_class'> M Class Name: TransformerTTSDataset</div><div id='n_method'> N Class Name: TransformerTTSDataset</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='n_file'> N File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_start'> M Start Line: 14</div><div id='m_end'> M End Line: 21</div><div id='n_start'> N Start Line: 32</div><div id='n_end'> N End Line: 44</div><BR>