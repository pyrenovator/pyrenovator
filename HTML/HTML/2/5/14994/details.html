<html><h3>Pattern ID :14994
</h3><img src='50444131.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        mem = default(mem, lambda: torch.empty(num_memory_layers, b, 0, d, **to(x)))
        lmem = default(lmem, lambda: torch.empty(num_memory_layers, b, 0, d, **to(x)))

        total_len = <a id="change">mem.shape[2]</a> + lmem.shape[2] + self.seq_len
        pos_emb = self.pos_emb[:, (self.seq_len - t):total_len]

        next_mem = []</code></pre><h3>After Change</h3><pre><code class='java'>
        init_mem = lambda: torch.empty(num_memory_layers, b, 0, d, **to(x))

        mem = default(mem, init_mem)
        lmem<a id="change"> = </a><a id="change">default(</a>lmem, init_mem<a id="change">)</a>

        mem_len, lmem_len = map(lambda t: t.shape[2], (mem, lmem))
        total_len = mem_len + lmem_len + self.seq_len

        pos_emb = self.pos_emb[:, (self.seq_len - t):total_len]
        mem_iter, lmem_iter = map(iterate_tensor, (mem, lmem))

        hiddens = []

        for ind, (attn, ff) in enumerate(zip(self.attn_layers, self.ff_layers)):
            layer_num = ind + 1
            use_memory = layer_num in self.memory_layers
            memories = map(next, (mem_iter, lmem_iter)) if use_memory else None

            if use_memory:
                hiddens.append(x)

            x = attn(x, memories = memories, calc_memory = use_memory, input_mask = mask, pos_emb = pos_emb)
            x = ff(x)

        hiddens = torch.stack(hiddens)
        out = self.to_logits(x)

        &#47&#47 calculate next memory state

        next_memory = self.memory_network(lmem, mem, hiddens)
        <a id="change">return </a>out, next_memory
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/memory-transformer-xl/commit/cbabe1ae6fa311092a9d0a88116c079a5ad8d790#diff-a0bf60cdef5ad628f9a83f0454c9c66a535268529835e839bb54088805dba051L255' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 50444131</div><div id='project'> Project Name: lucidrains/memory-transformer-xl</div><div id='commit'> Commit Name: cbabe1ae6fa311092a9d0a88116c079a5ad8d790</div><div id='time'> Time: 2020-07-22</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: memory_transformer_xl/memory_transformer_xl.py</div><div id='m_class'> M Class Name: MemoryTransformerXL</div><div id='n_method'> N Class Name: MemoryTransformerXL</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: memory_transformer_xl/memory_transformer_xl.py</div><div id='n_file'> N File Name: memory_transformer_xl/memory_transformer_xl.py</div><div id='m_start'> M Start Line: 255</div><div id='m_end'> M End Line: 296</div><div id='n_start'> N Start Line: 306</div><div id='n_end'> N End Line: 345</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        return loss

    def forward(self, image, text = None):
        b, device, img_size, = <a id="change">image.shape[0]</a>, image.device, self.image_size
        check_shape(image, &quotb c h w&quot, h = img_size, w = img_size, c = self.channels)

        times = torch.randint(0, self.num_timesteps, (b,), device = device, dtype = torch.long)</code></pre><h3>After Change</h3><pre><code class='java'>

    def forward(self, image, text = None, unet_number = None):
        assert not (len(self.unets) &gt; 1 and not exists(unet_number)), f&quotyou must specify which unet you want trained, from a range of 1 to {len(self.unets)}, if you are training cascading DDPM (multiple unets)&quot
        unet_number = <a id="change">default(</a>unet_number, 1<a id="change">)</a>
        assert 1 &lt;= unet_number &lt;= len(self.unets)

        index = unet_number - 1
        unet<a id="change"> = </a>self.unets[index]
        target_image_size = self.image_sizes[index]

        b, c, h, w, device, = *image.shape, image.device

        check_shape(image, &quotb c h w&quot, c = self.channels)
        assert h &gt;= target_image_size and w &gt;= target_image_size

        times = torch.randint(0, self.num_timesteps, (b,), device = device, dtype = torch.long)

        image_embed = self.get_image_embed(image)
        text_encodings = self.get_text_encodings(text) if exists(text) else None

        lowres_cond_img = image if index &gt; 0 else None
        ddpm_image = resize_image_to(image, target_image_size)
        <a id="change">return </a>self.p_losses(unet, ddpm_image, times, image_embed = image_embed, text_encodings = text_encodings, lowres_cond_img = lowres_cond_img)

&#47&#47 main class
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/0332eaa6ff7b5804a42495cbcedad0b31928e51f#diff-038ecede954c29266888cb88e37cc06f61ba2433f8b5142c7b2b2cefde5ed0edL1146' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 50444135</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: 0332eaa6ff7b5804a42495cbcedad0b31928e51f</div><div id='time'> Time: 2022-04-18</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: dalle2_pytorch/dalle2_pytorch.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dalle2_pytorch/dalle2_pytorch.py</div><div id='n_file'> N File Name: dalle2_pytorch/dalle2_pytorch.py</div><div id='m_start'> M Start Line: 1147</div><div id='m_end'> M End Line: 1156</div><div id='n_start'> N Start Line: 1186</div><div id='n_end'> N End Line: 1207</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        old_mem, new_mem = split_at_index(1, -self.mem_len, torch.cat((mem, x), dim=1))

        if <a id="change">old_mem.shape[1]</a> != 0 and self.lmem_len &gt; 0:
            pass

        return logits, Memory(new_mem, new_lmem)</code></pre><h3>After Change</h3><pre><code class='java'>

        init_mem = lambda: torch.empty(b, 0, e, **to(x))
        mem = default(mem, init_mem)
        lmem<a id="change"> = </a><a id="change">default(</a>lmem, init_mem<a id="change">)</a>

        mem_len = mem.shape[1]
        lmem_len = lmem.shape[1]

        q = self.to_q(x)

        kv_input = torch.cat((lmem, mem, x), dim=1)
        kv_len = kv_input.shape[1]
        k, v = self.to_kv(kv_input).chunk(2, dim=-1)

        merge_heads = lambda x: reshape_dim(x, -1, (-1, dim_h)).transpose(1, 2)
        q, k, v = map(merge_heads, (q, k, v))

        k, v = map(lambda x: x.expand(-1, h, -1, -1), (k, v))

        dots = torch.einsum(&quotbhid,bhjd-&gt;bhij&quot, q, k) * self.scale
        mask_value = max_neg_value(dots)

        if pos_emb is not None:
            pos_emb = pos_emb[:, -kv_len:].type(q.dtype)
            pos_dots = torch.einsum(&quotbhid,hjd-&gt;bhij&quot, q, pos_emb) * self.scale
            pos_dots = shift(pos_dots)
            dots = dots + pos_dots

        if input_mask is not None:
            mask = input_mask[:, None, :, None] * input_mask[:, None, None, :]
            mask = F.pad(mask, (mem_len + lmem_len, 0), value = True)
            dots.masked_fill_(~mask, mask_value)

        total_mem_len = mem_len + lmem_len
        mask = torch.ones(t, t + total_mem_len, **to(x)).triu_(diagonal = 1 + total_mem_len).bool()
        dots.masked_fill_(mask[None, None, ...], mask_value)

        attn = dots.softmax(dim=-1)
        attn = self.attn_dropout(attn)

        out = torch.einsum(&quotbhij,bhjd-&gt;bhid&quot, attn, v)
        out = out.transpose(1, 2).reshape(b, t, -1)
        out = self.to_out(out)

        <a id="change">return </a>self.dropout(out)

&#47&#47 memory attention network
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/memory-transformer-xl/commit/cbabe1ae6fa311092a9d0a88116c079a5ad8d790#diff-a0bf60cdef5ad628f9a83f0454c9c66a535268529835e839bb54088805dba051L154' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 50444139</div><div id='project'> Project Name: lucidrains/memory-transformer-xl</div><div id='commit'> Commit Name: cbabe1ae6fa311092a9d0a88116c079a5ad8d790</div><div id='time'> Time: 2020-07-22</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: memory_transformer_xl/memory_transformer_xl.py</div><div id='m_class'> M Class Name: SelfAttention</div><div id='n_method'> N Class Name: SelfAttention</div><div id='m_method'> M Method Name: forward(6)</div><div id='n_method'> N Method Name: forward(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: memory_transformer_xl/memory_transformer_xl.py</div><div id='n_file'> N File Name: memory_transformer_xl/memory_transformer_xl.py</div><div id='m_start'> M Start Line: 157</div><div id='m_end'> M End Line: 217</div><div id='n_start'> N Start Line: 160</div><div id='n_end'> N End Line: 206</div><BR>