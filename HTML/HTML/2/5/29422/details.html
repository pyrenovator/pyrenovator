<html><h3>Pattern ID :29422
</h3><img src='87133093.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        print(f"Processing `{os.path.abspath(lr_image_path)}`...")
        lr_image = Image.open(lr_image_path).convert("RGB")
        hr_image = <a id="change">Image.open(hr_image_path).convert("RGB"</a><a id="change">)</a>

        &#47&#47 Extract RGB channel image data
        lr_tensor = imgproc.image2tensor(lr_image, range_norm=False, half=True).to(config.device).unsqueeze_(0)
        hr_tensor = imgproc.image2tensor(hr_image, range_norm=False, half=True).to(config.device).unsqueeze_(0)

        &#47&#47 Only reconstruct the Y channel image data.
        with torch.no_grad():
            sr_tensor = model(lr_tensor).clamp_(0, 1)

        &#47&#47 Cal PSNR
        sr_y_tensor = imgproc.convert_rgb_to_y(sr_tensor)
        hr_y_tensor<a id="change"> = </a>imgproc.convert_rgb_to_y(hr_tensor)
        total_psnr += 10. * torch.log10(1. / torch.mean((sr_y_tensor - hr_y_tensor) ** 2))

        sr_image = imgproc.tensor2image(sr_tensor, range_norm=False, half=True)</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 Load the super-resolution model weights
    checkpoint = torch.load(config.model_path, map_location=lambda storage, loc: storage)
    model.load_state_dict(<a id="change">checkpoint["state_dict"]</a>)
    print(f"Load ESRGAN model weights `{os.path.abspath(config.model_path)}` successfully.")

    &#47&#47 Create a folder of super-resolution experiment results</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lornatang/esrgan-pytorch/commit/087e0c9bc621989889918b52b7c0dba9485c5fd6#diff-58b7fc05c0526d9a9b3c0b50dda416fcbf0a654e696da4b6df82cbb5a6b2dcfcL28' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87133093</div><div id='project'> Project Name: lornatang/esrgan-pytorch</div><div id='commit'> Commit Name: 087e0c9bc621989889918b52b7c0dba9485c5fd6</div><div id='time'> Time: 2022-03-06</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: validate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: validate.py</div><div id='n_file'> N File Name: validate.py</div><div id='m_start'> M Start Line: 28</div><div id='m_end'> M End Line: 82</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 91</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Compute heatmaps as preprocessing step
        label_heatmaps = []
        for idx, y in enumerate(tqdm(self.labels)):
            x = <a id="change">Image.open(os.path.join(root_directory, self.image_names[idx])).convert(
                "RGB"</a><a id="change"> &#47&#47didn&quott do this for DLC
            )</a>  &#47&#47 Rick&quots images have 1 color channel; change to 3.
            if transform:
                x, y = transform(images = np.expand_dims(x, axis = 0), keypoints = np.expand_dims(y, axis = 0)) &#47&#47check transform and normalization
            x = x.squeeze(0)
            y = y.squeeze(0)
            x<a id="change"> = </a>self.torch_transform(x)
            y_heatmap = draw_keypoints(y, x.shape[-2], x.shape[-1], self.output_shape, sigma = 5)
            label_heatmaps.append(y_heatmap)
        self.label_heatmaps = torch.from_numpy(np.asarray(label_heatmaps)).float()</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Compute heatmaps as preprocessing step
        &#47&#47check that max of heatmaps look good
        self.compute_heatmaps()
        self.num_targets = <a id="change">self.labels[0].shape[0]</a>
        print(self.num_targets)

    def compute_heatmaps(self):
        label_heatmaps = []</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/danbider/lightning-pose/commit/545a2f0293f923aca78924357ba161baf71f2982#diff-0779795c0a8a233449cfa9c0bd55d45453213457b10fa40da3e5a32966494943L58' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87133095</div><div id='project'> Project Name: danbider/lightning-pose</div><div id='commit'> Commit Name: 545a2f0293f923aca78924357ba161baf71f2982</div><div id='time'> Time: 2021-07-15</div><div id='author'> Author: ubuntu@ip-172-31-72-121.ec2.internal</div><div id='file'> File Name: pose_est_nets/datasets/datasets.py</div><div id='m_class'> M Class Name: DLCHeatmapDataset</div><div id='n_method'> N Class Name: DLCHeatmapDataset</div><div id='m_method'> M Method Name: __init__(5)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: torch.utils.data.Dataset</div><div id='n_parent_class'> N Parent Class: torch.utils.data.Dataset</div><div id='m_file'> M File Name: pose_est_nets/datasets/datasets.py</div><div id='n_file'> N File Name: pose_est_nets/datasets/datasets.py</div><div id='m_start'> M Start Line: 80</div><div id='m_end'> M End Line: 137</div><div id='n_start'> N Start Line: 80</div><div id='n_end'> N End Line: 114</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        print(f"Processing `{os.path.abspath(lr_image_path)}`...")
        lr_image = Image.open(lr_image_path).convert("RGB")
        hr_image = <a id="change">Image.open(hr_image_path).convert("RGB"</a><a id="change">)</a>

        &#47&#47 Extract RGB channel image data
        lr_tensor = imgproc.image2tensor(lr_image, range_norm=False, half=True).to(config.device).unsqueeze_(0)
        hr_tensor = imgproc.image2tensor(hr_image, range_norm=False, half=True).to(config.device).unsqueeze_(0)

        &#47&#47 Only reconstruct the Y channel image data.
        with torch.no_grad():
            sr_tensor = model(lr_tensor).clamp_(0, 1)

        &#47&#47 Cal PSNR
        sr_y_tensor = imgproc.convert_rgb_to_y(sr_tensor)
        hr_y_tensor<a id="change"> = </a>imgproc.convert_rgb_to_y(hr_tensor)
        total_psnr += 10. * torch.log10(1. / torch.mean((sr_y_tensor - hr_y_tensor) ** 2))

        sr_image = imgproc.tensor2image(sr_tensor, range_norm=False, half=True)</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 Load the super-resolution model weights
    checkpoint = torch.load(config.model_path, map_location=lambda storage, loc: storage)
    model.load_state_dict(<a id="change">checkpoint["state_dict"]</a>)
    print(f"Load SRGAN model weights `{os.path.abspath(config.model_path)}` successfully.")

    &#47&#47 Create a folder of super-resolution experiment results</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/srgan-pytorch/commit/231bd74d21d7f532fd746f4a1cb8fb3bc008c933#diff-58b7fc05c0526d9a9b3c0b50dda416fcbf0a654e696da4b6df82cbb5a6b2dcfcL26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87133100</div><div id='project'> Project Name: lornatang/srgan-pytorch</div><div id='commit'> Commit Name: 231bd74d21d7f532fd746f4a1cb8fb3bc008c933</div><div id='time'> Time: 2022-03-03</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: validate.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: validate.py</div><div id='n_file'> N File Name: validate.py</div><div id='m_start'> M Start Line: 28</div><div id='m_end'> M End Line: 82</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 91</div><BR>