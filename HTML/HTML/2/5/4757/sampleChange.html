<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
def get_encoder_decoder_tokenizer():
     Function to get a default pre-trained version of T5 in ONNX ready for use 
    path_t5_encoder = _models_path.joinpath(&quott5-encoder.onnx&quot)
    path_t5_decoder<a id="change"> = </a>_models_path.joinpath(&quott5-decoder-with-lm-head.onnx&quot)

    _models_path.mkdir(exist_ok=True)

    &#47&#47 Checks if encoder is already expanded
    if not path_t5_encoder.exists():
        path_t5_encoder_tarball = _models_path.joinpath(&quott5-encoder.tar.gz&quot)
        _download_generation_model(path_t5_encoder_tarball)

    &#47&#47 Checks if decoder is already expanded
    if not path_t5_decoder.exists():
        path_t5_decoder_tarball = _models_path.joinpath(&quott5-decoder-with-lm-head.tar.gz&quot)
        _download_generation_model(path_t5_decoder_tarball)

    &#47&#47 Loading the models
    decoder_sess = InferenceSession(<a id="change">str(</a>path_t5_decoder<a id="change">)</a>)
    encoder_sess = InferenceSession(str(path_t5_encoder))
    &#47&#47 The tokenizer should be the one you trained in the case of fine-tuning
    tokenizer = T5Tokenizer.from_pretrained(&quott5-base&quot)</code></pre><h3>After Change</h3><pre><code class='java'>

def get_encoder_decoder_tokenizer():
     Function to get a default pre-trained version of T5 in ONNX ready for use 
    <a id="change">try:
        </a>decoder_sess<a id="change">, encoder_sess = </a>_handle_creation_of_sessions()
    <a id="change">except</a>:
        filelist = glob.glob(os.path.join(_models_path, "*"))
        for f in filelist:
            os.remove(f)</code></pre>