<html><h3>Pattern ID :17096
</h3><img src='57237359.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 setup model
    loss_record, most_recent_encoder_path = model.learn(dataset_dict, pretrain_epochs, pretrain_batches)
    <a id="change">if </a>ppo_finetune and <a id="change">not</a> isinstance(model, algos.RecurrentCPC):
        encoder_checkpoint = model.encoder_checkpoints_path
        all_checkpoints = glob(os.path.join(encoder_checkpoint, &quot*&quot))
        latest_checkpoint = max(all_checkpoints, key=os.path.getctime)
        encoder_feature_extractor_kwargs = {&quotfeatures_dim&quot: algo_params["representation_dim"],
                                            &quotencoder_path&quot: os.path.abspath(latest_checkpoint)}

        &#47&#47 TODO figure out how to not have to set `ortho_init` to False for the whole policy
        policy_kwargs = {&quotfeatures_extractor_class&quot: EncoderFeatureExtractor,
                         &quotfeatures_extractor_kwargs&quot: encoder_feature_extractor_kwargs,
                         &quotortho_init&quot: False}
        ppo_model = PPO(policy=ActorCriticPolicy, env=venv,
                        verbose=1, policy_kwargs=policy_kwargs)
        ppo_model = initialize_non_features_extractor(ppo_model)
        <a id="change">ppo_model.learn(total_timesteps=ppo_timesteps)</a>

    venv.close()
    return {
        &quotencoder_path&quot: most_recent_encoder_path,</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 setup model
    loss_record, most_recent_encoder_path = model.learn(
        webdataset, pretrain_epochs, pretrain_batches)
    <a id="change">if </a>ppo_finetune and <a id="change">not</a> isinstance(model, algos.RecurrentCPC):
        raise NotImplementedError("PPO fine-tuning is not currently supported")

        &#47&#47 encoder_checkpoint = model.encoder_checkpoints_path</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/1086682dee2c96d5c039e3190b1fec8ce4c683bd#diff-85e6dfcecb4f7bb11eda0f3c08b89808cf7f28a3eaf145199d43441864816161L123' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 57237359</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: 1086682dee2c96d5c039e3190b1fec8ce4c683bd</div><div id='time'> Time: 2020-11-16</div><div id='author'> Author: sam@qxcv.net</div><div id='file'> File Name: src/il_representations/scripts/run_rep_learner.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: run(11)</div><div id='n_method'> N Method Name: run(11)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/il_representations/scripts/run_rep_learner.py</div><div id='n_file'> N File Name: src/il_representations/scripts/run_rep_learner.py</div><div id='m_start'> M Start Line: 126</div><div id='m_end'> M End Line: 161</div><div id='n_start'> N Start Line: 123</div><div id='n_end'> N End Line: 165</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
			n_steps += 1
			score += reward
			agent.remember(observation, action, prob, val, reward, terminal)
			<a id="change">if </a>n_steps<a id="change"> % </a>N == 0:
				<a id="change">agent.learn()</a>
				learn_iters += 1
			observation = observation_
		score_history.append(score)
		avg_score = np.mean(score_history[-100:])</code></pre><h3>After Change</h3><pre><code class='java'>
				next_observations=[observation],
			)
			finish_trajectories(agent, ppo, finished_trajectories)
			<a id="change">if </a>n_steps<a id="change"> % </a>N == 0:
				&#47&#47 agent.learn()
				BaseModel.hard_update(ppo.last_policy, agent.policy)
				finish_trajectories(agent, ppo, agent_history_maps.terminate_all())</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neurotorch/neurotorch/commit/1b8dc23f0e38fa1f7ef9f3d4d08edd671137b16f#diff-09dfd647bc1273bf6835dc23e0871491b8ce164d28080b9bd4ac74c449399eeeL346' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 57237360</div><div id='project'> Project Name: neurotorch/neurotorch</div><div id='commit'> Commit Name: 1b8dc23f0e38fa1f7ef9f3d4d08edd671137b16f</div><div id='time'> Time: 2022-12-14</div><div id='author'> Author: 50332514+JeremieGince@users.noreply.github.com</div><div id='file'> File Name: tutorials/reinforcement_learning/ppo_from_youtube.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tutorials/reinforcement_learning/ppo_from_youtube.py</div><div id='n_file'> N File Name: tutorials/reinforcement_learning/ppo_from_youtube.py</div><div id='m_start'> M Start Line: 354</div><div id='m_end'> M End Line: 386</div><div id='n_start'> N Start Line: 358</div><div id='n_end'> N End Line: 412</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 setup model
    loss_record, most_recent_encoder_path = model.learn(dataset_dict, pretrain_epochs, pretrain_batches)
    <a id="change">if </a>ppo_finetune and <a id="change">not</a> isinstance(model, algos.RecurrentCPC):
        encoder_checkpoint = model.encoder_checkpoints_path
        all_checkpoints = glob(os.path.join(encoder_checkpoint, &quot*&quot))
        latest_checkpoint = max(all_checkpoints, key=os.path.getctime)
        encoder_feature_extractor_kwargs = {&quotfeatures_dim&quot: algo_params["representation_dim"],
                                            &quotencoder_path&quot: os.path.abspath(latest_checkpoint)}

        &#47&#47 TODO figure out how to not have to set `ortho_init` to False for the whole policy
        policy_kwargs = {&quotfeatures_extractor_class&quot: EncoderFeatureExtractor,
                         &quotfeatures_extractor_kwargs&quot: encoder_feature_extractor_kwargs,
                         &quotortho_init&quot: False}
        ppo_model = PPO(policy=ActorCriticPolicy, env=venv,
                        verbose=1, policy_kwargs=policy_kwargs)
        ppo_model = initialize_non_features_extractor(ppo_model)
        <a id="change">ppo_model.learn(total_timesteps=ppo_timesteps)</a>

    venv.close()
    return {
        &quotencoder_path&quot: most_recent_encoder_path,</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 setup model
    loss_record, most_recent_encoder_path = model.learn(
        webdataset, pretrain_epochs, pretrain_batches)
    <a id="change">if </a>ppo_finetune and <a id="change">not</a> isinstance(model, algos.RecurrentCPC):
        raise NotImplementedError("PPO fine-tuning is not currently supported")

        &#47&#47 encoder_checkpoint = model.encoder_checkpoints_path</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/47ccff934463fdfcd9a8887bff27286744d1fe17#diff-85e6dfcecb4f7bb11eda0f3c08b89808cf7f28a3eaf145199d43441864816161L114' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 57237362</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: 47ccff934463fdfcd9a8887bff27286744d1fe17</div><div id='time'> Time: 2020-11-16</div><div id='author'> Author: sam@qxcv.net</div><div id='file'> File Name: src/il_representations/scripts/run_rep_learner.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: run(11)</div><div id='n_method'> N Method Name: run(11)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/il_representations/scripts/run_rep_learner.py</div><div id='n_file'> N File Name: src/il_representations/scripts/run_rep_learner.py</div><div id='m_start'> M Start Line: 126</div><div id='m_end'> M End Line: 161</div><div id='n_start'> N Start Line: 123</div><div id='n_end'> N End Line: 165</div><BR>