<html><h3>Pattern ID :41152
</h3><img src='116046043.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 zero stage 1 mode
        if not self.partition_gradients:
            required_version = pkg_version.parse("0.3.17")
            ckpt_version = <a id="change">state_dict_list[0]</a>.get("ds_version", False)
            error_str = f"ZeRO stage 1 changed in {required_version} and is not backwards compatible " \
                "with older stage 1 checkpoints. If you&quotd like to load an old ZeRO-1 checkpoint " \
                "please use an older version of DeepSpeed (&lt;= 0.5.8) and set &quotlegacy_stage1&quot: true in your zero config json."</code></pre><h3>After Change</h3><pre><code class='java'>

        if load_from_fp32_weights:
            &#47&#47 option 2 from above
            <a id="change">if </a>self.elastic_checkpoint and not ckpt_is_rigid:
                self._restore_from_elastic_fp32_weights(state_dict_list)
            else:
                &#47&#47 For non-elastic checkpoint, simply copying from saved weights of current rank is sufficient.
                for current, saved in zip(self.single_partition_of_fp32_groups, current_rank_sd[SINGLE_PARTITION_OF_FP32_GROUPS]):
                    src_tensor<a id="change"> = </a>_get_padded_tensor(saved, <a id="change">current.numel()</a>)
                    current.data.copy_(src_tensor.data)
        else:
            &#47&#47 option 1 from above</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/3293cf72a0abd5cf77a831996bd054bc908476a6#diff-99dcf26ea2876ff5bbf05b5165c4133eaa0d0f36b170685643c2f7e2eb566addL2131' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116046043</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: 3293cf72a0abd5cf77a831996bd054bc908476a6</div><div id='time'> Time: 2022-01-14</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/runtime/zero/stage_1_and_2.py</div><div id='m_class'> M Class Name: DeepSpeedZeroOptimizer</div><div id='n_method'> N Class Name: DeepSpeedZeroOptimizer</div><div id='m_method'> M Method Name: load_state_dict(4)</div><div id='n_method'> N Method Name: load_state_dict(4)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: deepspeed/runtime/zero/stage_1_and_2.py</div><div id='n_file'> N File Name: deepspeed/runtime/zero/stage_1_and_2.py</div><div id='m_start'> M Start Line: 2131</div><div id='m_end'> M End Line: 2165</div><div id='n_start'> N Start Line: 2147</div><div id='n_end'> N End Line: 2204</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
		
		for param_idx, param in enumerate(self.model.parameters()):
			&#47&#47 for each neuron at a time step t
			for neuron_idx in range(<a id="change">self.true_time_series.shape[1]</a>):
				if param.requires_grad:
					try:
						self.eligibility_trace_t[param_idx][:, neuron_idx] = torch.autograd.grad(z[neuron_idx], param, retain_graph=True)[0][:, neuron_idx]</code></pre><h3>After Change</h3><pre><code class='java'>
		Equation (13)
		
		for param_idx, param in enumerate(self.model.parameters()):
			<a id="change">if </a>param.ndim &gt;= 1:
				N_out = param.shape[-1]
			else:
				N_out<a id="change"> = </a><a id="change">param.numel()</a>
			&#47&#47 for each neuron at a time step t
			for neuron_idx in range(N_out):
				if param.requires_grad:
					if param.ndim &gt;= 1:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neurotorch/neurotorch/commit/285261877f25e27c96db8cf79ca1beac1933906d#diff-1a3b36b500eea965a9b6e7a858eed41919d2405c9e22da6d65e08b496089e2f2L133' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116046044</div><div id='project'> Project Name: neurotorch/neurotorch</div><div id='commit'> Commit Name: 285261877f25e27c96db8cf79ca1beac1933906d</div><div id='time'> Time: 2022-12-30</div><div id='author'> Author: 93488840+AnthoDrouin@users.noreply.github.com</div><div id='file'> File Name: src/neurotorch/learning_algorithms/debug_e_prop_v2.py</div><div id='m_class'> M Class Name: SimplifiedEprop</div><div id='n_method'> N Class Name: SimplifiedEprop</div><div id='m_method'> M Method Name: compute_dz_dw_local(2)</div><div id='n_method'> N Method Name: compute_dz_dw_local(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/neurotorch/learning_algorithms/debug_e_prop_v2.py</div><div id='n_file'> N File Name: src/neurotorch/learning_algorithms/debug_e_prop_v2.py</div><div id='m_start'> M Start Line: 139</div><div id='m_end'> M End Line: 146</div><div id='n_start'> N Start Line: 148</div><div id='n_end'> N End Line: 164</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>


def sigmoid_soft_cross_entropy(x, t, normalize=True, reduce=&quotmean&quot):
    return <a id="change">SigmoidSoftCrossEntropy(normalize, reduce).apply((x, t))[0]</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
    log1p_exp = torch.log1p(torch.exp(x))
    loss = t * (log1p_exp - x) + (1 - t) * log1p_exp

    <a id="change">if </a>_reduce == &quotsum&quot:
        if normalize:
            count<a id="change"> = </a><a id="change">t.numel()</a>
        else:
            count = len(t)
        count = max(count, 1.)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yuta-hi/pytorch_bayesian_unet/commit/55d3121d70f1ce110a10cacc47efeffb9534dced#diff-f275bc63d6196e39c663aa3d711bac7a0d3fd0343b519b5eb76ce050f064bfd0L21' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116046038</div><div id='project'> Project Name: yuta-hi/pytorch_bayesian_unet</div><div id='commit'> Commit Name: 55d3121d70f1ce110a10cacc47efeffb9534dced</div><div id='time'> Time: 2020-03-30</div><div id='author'> Author: hiasa.yuta.ht7@is.naist.jp</div><div id='file'> File Name: pytorch_bcnn/functions/loss/sigmoid_soft_cross_entropy.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: sigmoid_soft_cross_entropy(4)</div><div id='n_method'> N Method Name: sigmoid_soft_cross_entropy(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: pytorch_bcnn/functions/loss/sigmoid_soft_cross_entropy.py</div><div id='n_file'> N File Name: pytorch_bcnn/functions/loss/sigmoid_soft_cross_entropy.py</div><div id='m_start'> M Start Line: 22</div><div id='m_end'> M End Line: 22</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 33</div><BR>