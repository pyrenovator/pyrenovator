<html><h3>Pattern ID :4625
</h3><img src='16661604.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                    inference_cuda_module.residual_add_bias_fp32

    def forward(self, input, residual, residual_norm, bias):
        return <a id="change">DeepSpeedMLPFunction.apply(</a>input,
                                          residual,
                                          residual_norm,
                                          bias,
                                          self.inter_w,
                                          self.inter_b,
                                          self.attn_nw,
                                          self.attn_nb,
                                          self.config,
                                          self.mp_group,
                                          self.output_b,
                                          self.output_w,
                                          self.q_scales,
                                          self.q_groups,
                                          self.merge_count,
                                          self.mlp_gemm_func,
                                          self.fused_gemm_gelu,
                                          self.vector_matmul_func,
                                          self.bias_residual_func,
                                          self.residual_add_func<a id="change">)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
            add_bias=bias is not None,
            residual_add=residual_add)

        <a id="change">if </a><a id="change">self.mp_group is not None and dist.get_world_size(group=self.mp_group) &gt; 1</a>:
            dist.all_reduce(residual, group=self.mp_group)

        return residual</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/c702b64c94243674c3143a4cf29d59777a88307d#diff-9e4ae80750d7192e689307f7e660fd912cebc385a8af9dd8aecb8db714ab98d1L67' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 16661604</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: c702b64c94243674c3143a4cf29d59777a88307d</div><div id='time'> Time: 2023-01-09</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/ops/transformer/inference/ds_mlp.py</div><div id='m_class'> M Class Name: DeepSpeedMLP</div><div id='n_method'> N Class Name: DeepSpeedMLP</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: deepspeed/ops/transformer/inference/ds_mlp.py</div><div id='n_file'> N File Name: deepspeed/ops/transformer/inference/ds_mlp.py</div><div id='m_start'> M Start Line: 159</div><div id='m_end'> M End Line: 178</div><div id='n_start'> N Start Line: 67</div><div id='n_end'> N End Line: 94</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        proj_in_dim = in_dim + hidden_dim
        self.feat_out = nn.Linear(proj_in_dim, out_dim * reduction_factor, bias=False)

        <a id="change">self.apply(</a>decoder_init<a id="change">)</a>

    def _zero_state(self, hs):
        init_hs = hs.new_zeros(hs.size(0), self.lstm[0].hidden_size)
        return init_hs</code></pre><h3>After Change</h3><pre><code class='java'>
        proj_in_dim = in_dim + hidden_dim
        self.feat_out = nn.Linear(proj_in_dim, out_dim * reduction_factor, bias=False)

        <a id="change">if reduction_factor &gt; 1</a><a id="change"> and downsample_by_conv</a>:
            self.conv_downsample = nn.Conv1d(
                in_dim,
                in_dim,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/r9y9/nnsvs/commit/6b106af7dad6253702fe0f13fcf445f892d9b3b9#diff-cdad0f8e1444a75bf6546ba65fcc13c89bd689ff806a2ed6bbd60d304c957ab6L99' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 16661605</div><div id='project'> Project Name: r9y9/nnsvs</div><div id='commit'> Commit Name: 6b106af7dad6253702fe0f13fcf445f892d9b3b9</div><div id='time'> Time: 2022-10-15</div><div id='author'> Author: zryuichi@gmail.com</div><div id='file'> File Name: nnsvs/tacotron/decoder.py</div><div id='m_class'> M Class Name: NonAttentiveDecoder</div><div id='n_method'> N Class Name: NonAttentiveDecoder</div><div id='m_method'> M Method Name: __init__(14)</div><div id='n_method'> N Method Name: __init__(10)</div><div id='m_parent_class'> M Parent Class: BaseModel</div><div id='n_parent_class'> N Parent Class: BaseModel</div><div id='m_file'> M File Name: nnsvs/tacotron/decoder.py</div><div id='n_file'> N File Name: nnsvs/tacotron/decoder.py</div><div id='m_start'> M Start Line: 115</div><div id='m_end'> M End Line: 128</div><div id='n_start'> N Start Line: 118</div><div id='n_end'> N End Line: 165</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            else:
                return m

        <a id="change">self.apply(</a>add_sn<a id="change">)</a>

    def forward(self, image_batch):
        image_batch = image_batch.to(module_device(self))
        features = self.encoder(image_batch)</code></pre><h3>After Change</h3><pre><code class='java'>
        )

        for module in self.modules():
            <a id="change">if </a><a id="change">(
                isinstance(module, (nn.Conv2d, nn.ConvTranspose2d))
                and len(module._forward_pre_hooks) == 0
            )</a>:
                torch.nn.utils.spectral_norm(module)

    def forward(self, image_batch):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/aiwizo/template-nvae/commit/28cd1b1de1501c4c33856588294e278378568efe#diff-6d4440ee825f80b81421868173023972e6913d7a6ed7f3deaa37e09702b45ddeL11' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 16661602</div><div id='project'> Project Name: aiwizo/template-nvae</div><div id='commit'> Commit Name: 28cd1b1de1501c4c33856588294e278378568efe</div><div id='time'> Time: 2020-09-03</div><div id='author'> Author: samedii@gmail.com</div><div id='file'> File Name: vae/architecture/model.py</div><div id='m_class'> M Class Name: Model</div><div id='n_method'> N Class Name: Model</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: vae/architecture/model.py</div><div id='n_file'> N File Name: vae/architecture/model.py</div><div id='m_start'> M Start Line: 13</div><div id='m_end'> M End Line: 33</div><div id='n_start'> N Start Line: 13</div><div id='n_end'> N End Line: 33</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                norm_w=None,
                norm_b=None,
                alibi=None):
        output = <a id="change">DeepSpeedSelfAttentionFunction.apply(
            </a>input,
            input_mask,
            head_mask,
            layer_past,
            get_present,
            encoder_hidden_states,
            encoder_attention_mask,
            output_attentions,
            norm_w,
            norm_b,
            self.config,
            self.attn_qkvw,
            self.attn_qkvb,
            self.num_attention_heads_per_partition,
            self.norm_factor,
            self.hidden_size_per_partition,
            self.attn_ow,
            self.attn_ob,
            self.mp_group,
            self.q_scales,
            self.q_groups,
            self.merge_count,
            self.qkv_merging,
            self.score_context_func,
            alibi<a id="change">)</a>

        return output
</code></pre><h3>After Change</h3><pre><code class='java'>

        inp_norm = qkv_out[-1]

        <a id="change">if </a><a id="change">self.config.mlp_after_attn and self.mp_group is not None and dist.get_world_size(
                group=self.mp_group) &gt; 1</a>:
            dist.all_reduce(output, group=self.mp_group)

        return (output, key_layer, value_layer, context_layer, inp_norm)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/bb68c526ad2c267dfb235db9c0d0fb1413d19a34#diff-88a3148746124b4093264a91ae8cac5be0bb592bfb2868d5df944836e55d93dbL446' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 16661603</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: bb68c526ad2c267dfb235db9c0d0fb1413d19a34</div><div id='time'> Time: 2022-12-22</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/ops/transformer/inference/ds_attention.py</div><div id='m_class'> M Class Name: DeepSpeedSelfAttention</div><div id='n_method'> N Class Name: DeepSpeedSelfAttention</div><div id='m_method'> M Method Name: forward(12)</div><div id='n_method'> N Method Name: forward(12)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: deepspeed/ops/transformer/inference/ds_attention.py</div><div id='n_file'> N File Name: deepspeed/ops/transformer/inference/ds_attention.py</div><div id='m_start'> M Start Line: 458</div><div id='m_end'> M End Line: 485</div><div id='n_start'> N Start Line: 120</div><div id='n_end'> N End Line: 151</div><BR>