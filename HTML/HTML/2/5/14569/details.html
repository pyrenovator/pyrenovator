<html><h3>Pattern ID :14569
</h3><img src='47937823.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47what&quots happening here?
        print(&quotREWARD SHAPE: &quot, inputs[&quotreward&quot].shape)
        <a id="change">print(&quotX shape: &quot</a>, x.shape<a id="change">)</a>
        clipped_reward = torch.clamp(inputs["reward"], -1, 1).view(T * B, 1)
        core_input = torch.cat([x, clipped_reward, one_hot_last_action], dim=-1)
        &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47transformer
        &#47&#47 if self.use_lstm:</code></pre><h3>After Change</h3><pre><code class='java'>
        baseline = self.baseline(core_output)

        &#47&#47 print(&quotPOLICY SHAPE: &quot,policy_logits.shape)
        policy_logits<a id="change"> = </a><a id="change">policy_logits.reshape(</a>T<a id="change">*</a>B, self.num_actions<a id="change">)</a>
        &#47&#47 print(&quotTMP : {} Original : {}&quot.format(policy_logits_tmp[:3, :], policy_logits[:3, :3, :]))
        if self.training:
            &#47&#47 Sample from multinomial distribution for explorationx
            action = torch.multinomial(F.softmax(policy_logits, dim=1), num_samples=1)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/jerrodparker20/adaptive-transformers-in-rl/commit/6f99ef29b7f170d3f6d169d073705131bfd8ea8f#diff-e7806c09783bb947489c86c3d53067e349956e43f586009564c23515b667feb3L739' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 47937823</div><div id='project'> Project Name: jerrodparker20/adaptive-transformers-in-rl</div><div id='commit'> Commit Name: 6f99ef29b7f170d3f6d169d073705131bfd8ea8f</div><div id='time'> Time: 2020-03-13</div><div id='author'> Author: shakti.shrivastava13@gmail.com</div><div id='file'> File Name: Model/monobeast.py</div><div id='m_class'> M Class Name: AtariNet</div><div id='n_method'> N Class Name: AtariNet</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: Model/monobeast.py</div><div id='n_file'> N File Name: Model/monobeast.py</div><div id='m_start'> M Start Line: 739</div><div id='m_end'> M End Line: 794</div><div id='n_start'> N Start Line: 801</div><div id='n_end'> N End Line: 820</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for image_batch in images:
            output = self.backbone(image_batch)
            outputs.append(output)
        <a id="change">print(</a>torch.cat(outputs), <a id="change">"OUTPUT SHAPE 2D context"</a><a id="change">)</a>
        return torch.cat(outputs)

    def forward(self, images):
        Forward pass from images to representations.</code></pre><h3>After Change</h3><pre><code class='java'>
                outputs.append(output.reshape(output.shape[0], output.shape[1], -1))
            outputs = torch.cat(outputs, dim=2)
            representations_concat = self.representation_fc(outputs)
            representations<a id="change"> = </a><a id="change">output.reshape(</a>representations_concat.shape[0], representations_concat.shape[1], representations_concat.shape[2]<a id="change">//</a>8,
                                             representations_concat.shape[2]//8<a id="change">)</a>
        else:
            images_by_frame_group = torch.permute(images, (1, 0, 2, 3, 4))
            image_batch = images_by_frame_group[0]
            representations = self.backbone(image_batch)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/danbider/lightning-pose/commit/0d32330b5411d0c60b904da26ca649bc34361e4c#diff-99cc1aafbbd2d9185478090d049cb28431c41fdb606d1787b4e8c11baa8aa7ebL137' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 47937827</div><div id='project'> Project Name: danbider/lightning-pose</div><div id='commit'> Commit Name: 0d32330b5411d0c60b904da26ca649bc34361e4c</div><div id='time'> Time: 2022-04-15</div><div id='author'> Author: colehurwitz@gmail.com</div><div id='file'> File Name: lightning_pose/models/base.py</div><div id='m_class'> M Class Name: BaseFeatureExtractor</div><div id='n_method'> N Class Name: BaseFeatureExtractor</div><div id='m_method'> M Method Name: get_representations(3)</div><div id='n_method'> N Method Name: get_representations(2)</div><div id='m_parent_class'> M Parent Class: LightningModule</div><div id='n_parent_class'> N Parent Class: LightningModule</div><div id='m_file'> M File Name: lightning_pose/models/base.py</div><div id='n_file'> N File Name: lightning_pose/models/base.py</div><div id='m_start'> M Start Line: 157</div><div id='m_end'> M End Line: 162</div><div id='n_start'> N Start Line: 141</div><div id='n_end'> N End Line: 173</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for image_batch in images:
            output = self.backbone(image_batch)
            outputs.append(output)
        <a id="change">print(</a>torch.cat(outputs), <a id="change">"OUTPUT SHAPE 2D context"</a><a id="change">)</a>
        return torch.cat(outputs)

    def forward(self, images):
        Forward pass from images to representations.</code></pre><h3>After Change</h3><pre><code class='java'>
                outputs.append(output.reshape(output.shape[0], output.shape[1], -1))
            outputs = torch.cat(outputs, dim=2)
            representations_concat = self.representation_fc(outputs)
            representations<a id="change"> = </a><a id="change">output.reshape(</a>representations_concat.shape[0], representations_concat.shape[1], representations_concat.shape[2]<a id="change">//</a>8,
                                             representations_concat.shape[2]//8<a id="change">)</a>
        else:
            images_by_frame_group = torch.permute(images, (1, 0, 2, 3, 4))
            image_batch = images_by_frame_group[0]
            representations = self.backbone(image_batch)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/danbider/lightning-pose/commit/b683cb69d8df9187f8708c2788450fd68519e9cf#diff-99cc1aafbbd2d9185478090d049cb28431c41fdb606d1787b4e8c11baa8aa7ebL137' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 47937826</div><div id='project'> Project Name: danbider/lightning-pose</div><div id='commit'> Commit Name: b683cb69d8df9187f8708c2788450fd68519e9cf</div><div id='time'> Time: 2022-04-15</div><div id='author'> Author: colehurwitz@gmail.com</div><div id='file'> File Name: lightning_pose/models/base.py</div><div id='m_class'> M Class Name: BaseFeatureExtractor</div><div id='n_method'> N Class Name: BaseFeatureExtractor</div><div id='m_method'> M Method Name: get_representations(3)</div><div id='n_method'> N Method Name: get_representations(2)</div><div id='m_parent_class'> M Parent Class: LightningModule</div><div id='n_parent_class'> N Parent Class: LightningModule</div><div id='m_file'> M File Name: lightning_pose/models/base.py</div><div id='n_file'> N File Name: lightning_pose/models/base.py</div><div id='m_start'> M Start Line: 157</div><div id='m_end'> M End Line: 162</div><div id='n_start'> N Start Line: 141</div><div id='n_end'> N End Line: 173</div><BR>