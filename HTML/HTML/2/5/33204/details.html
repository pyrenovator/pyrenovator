<html><h3>Pattern ID :33204
</h3><img src='95893959.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
class autocast(object):
    def __init__(self, enabled=True, dtype=torch.bfloat16):
        supported_dtype = [torch.bfloat16]
        <a id="change">if </a>dtype not in supported_dtype :
            warnings.warn("In CPU autocast, but the target dtype is not supported. Disable the autocast.")
            <a id="change">warnings.warn("CPU Autocast only support dtype of torch.bfloat16 currently."</a><a id="change">)</a>
            enabled = False
            dtype<a id="change"> = </a>torch.bfloat16
        self._enabled = enabled
        self._dtype = dtype
</code></pre><h3>After Change</h3><pre><code class='java'>
    ``torch.cpu.amp.autocast(args...)`` is equivalent to ``torch.autocast("cpu", args...)``
    
    def __init__(self, enabled=True, fast_dtype=torch.float16):
        <a id="change">super()</a>.__init__("cpu", enabled=enabled, fast_dtype=fast_dtype)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/324673a537fc818527b8375700a9b95a83a00c92#diff-9ad6f7b5b257d7863976b16d40c261cec5fd7f569d6f92133c6813fe54795fecL7' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 95893959</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 324673a537fc818527b8375700a9b95a83a00c92</div><div id='time'> Time: 2021-08-10</div><div id='author'> Author: puririshi98@berkeley.edu</div><div id='file'> File Name: torch/cpu/amp/autocast_mode.py</div><div id='m_class'> M Class Name: autocast</div><div id='n_method'> N Class Name: autocast</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: torch.autocast_mode.autocast</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: torch/cpu/amp/autocast_mode.py</div><div id='n_file'> N File Name: torch/cpu/amp/autocast_mode.py</div><div id='m_start'> M Start Line: 7</div><div id='m_end'> M End Line: 14</div><div id='n_start'> N Start Line: 9</div><div id='n_end'> N End Line: 9</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        enabled(bool, optional, default=True):  Whether autocasting should be enabled in the region.
    
    def __init__(self, enabled=True):
        <a id="change">if </a>enabled and amp_definitely_not_available():
            <a id="change">warnings.warn("torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling."</a><a id="change">)</a>
            self._enabled<a id="change"> = </a>False
        else:
            self._enabled = enabled
</code></pre><h3>After Change</h3><pre><code class='java'>
    ``torch.cuda.amp.autocast(args...)`` is equivalent to ``torch.autocast("cuda", args...)``
    
    def __init__(self, enabled=True, fast_dtype=torch.float16):
        <a id="change">super()</a>.__init__("cuda", enabled=enabled, fast_dtype=fast_dtype)


&#47&#47 Casts Tensors and containers of Tensors.  Special-cases passthroughs for strings and np.ndarrays, which</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/324673a537fc818527b8375700a9b95a83a00c92#diff-dac4bd53ced015c8810b3b02fc5c2ec6c2b0658c5090b4fbbd09c96bd45087d1L118' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 95893965</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 324673a537fc818527b8375700a9b95a83a00c92</div><div id='time'> Time: 2021-08-10</div><div id='author'> Author: puririshi98@berkeley.edu</div><div id='file'> File Name: torch/cuda/amp/autocast_mode.py</div><div id='m_class'> M Class Name: autocast</div><div id='n_method'> N Class Name: autocast</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(2)</div><div id='m_parent_class'> M Parent Class: torch.autocast_mode.autocast</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: torch/cuda/amp/autocast_mode.py</div><div id='n_file'> N File Name: torch/cuda/amp/autocast_mode.py</div><div id='m_start'> M Start Line: 119</div><div id='m_end'> M End Line: 125</div><div id='n_start'> N Start Line: 16</div><div id='n_end'> N End Line: 17</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if clean_up_tokenization_spaces is not None:
            postprocess_params["clean_up_tokenization_spaces"] = clean_up_tokenization_spaces

        <a id="change">if </a>stop_sequence is not None:
            stop_sequence_ids = self.tokenizer.encode(stop_sequence, add_special_tokens=False)
            if len(stop_sequence_ids) &gt; 1:
                <a id="change">warnings.warn(
                    "Stopping on a multiple token sequence is not yet supported on transformers. The first token of"
                    " the stop sequence will be used as the stop sequence string in the interim."</a><a id="change">
                )</a>
            generate_kwargs["eos_token_id"]<a id="change"> = </a>stop_sequence_ids[0]

        return preprocess_params, forward_params, postprocess_params
</code></pre><h3>After Change</h3><pre><code class='java'>
        max_input_length=None,
        **generate_kwargs,
    ):
        preprocess_params, forward_params, postprocess_params = <a id="change">super()</a>._sanitize_parameters(
            return_tensors,
            return_text,
            return_type,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/optimum-graphcore/commit/664159a88f3b26ebb5a6f76bd8343285f1693c67#diff-c76091b5b84d47b9864fd44f4e7bf64e0336bb870a6d3b88d2b9ce1e54f09861L8' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 95893961</div><div id='project'> Project Name: huggingface/optimum-graphcore</div><div id='commit'> Commit Name: 664159a88f3b26ebb5a6f76bd8343285f1693c67</div><div id='time'> Time: 2023-03-22</div><div id='author'> Author: 19981378+HMellor@users.noreply.github.com</div><div id='file'> File Name: optimum/graphcore/pipelines/text2text_generation.py</div><div id='m_class'> M Class Name: IPUText2TextGenerationPipeline</div><div id='n_method'> N Class Name: IPUText2TextGenerationPipeline</div><div id='m_method'> M Method Name: _sanitize_parameters(8)</div><div id='n_method'> N Method Name: _sanitize_parameters(8)</div><div id='m_parent_class'> M Parent Class: Text2TextGenerationPipeline</div><div id='n_parent_class'> N Parent Class: Text2TextGenerationPipeline</div><div id='m_file'> M File Name: optimum/graphcore/pipelines/text2text_generation.py</div><div id='n_file'> N File Name: optimum/graphcore/pipelines/text2text_generation.py</div><div id='m_start'> M Start Line: 19</div><div id='m_end'> M End Line: 46</div><div id='n_start'> N Start Line: 19</div><div id='n_end'> N End Line: 27</div><BR>