<html><h3>Pattern ID :17644
</h3><img src='58267640.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        for op in operators:
            for f in op.operators:
                <a id="change">if </a>&quotlinalg_&quot in f:
                    ret<a id="change"> = </a><a id="change">getattr(torch.linalg, f[7:])(</a>a, *<a id="change">op.input)</a>
                    ret1<a id="change"> = </a>getattr(torch.linalg, f[7:])(a, *op.input, out=tuple(ret))
                    for i, name in enumerate(op.names):
                        self.assertIs(getattr(ret, name), ret[i])
                else:</code></pre><h3>After Change</h3><pre><code class='java'>
                    check_namedtuple(ret1, op.names)
                &#47&#47
                &#47&#47 2. check the out= variant, if it exists
                if <a id="change">func and op.hasout</a>:
                    ret2 = func(a, *op.input, out=tuple(ret1))
                    check_namedtuple(ret2, op.names)
                &#47&#47</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/5c5abd591d0b452ab8d4d37115fbc37cc8c984c7#diff-2b70b559a337a78b31562d0e1e916b750229615fc23cd2bb56480889dfdcdb06L51' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58267640</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 5c5abd591d0b452ab8d4d37115fbc37cc8c984c7</div><div id='time'> Time: 2021-01-08</div><div id='author'> Author: anto.cuni@gmail.com</div><div id='file'> File Name: test/test_namedtuple_return_api.py</div><div id='m_class'> M Class Name: TestNamedTupleAPI</div><div id='n_method'> N Class Name: TestNamedTupleAPI</div><div id='m_method'> M Method Name: test_namedtuple_return(1)</div><div id='n_method'> N Method Name: test_namedtuple_return(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: test/test_namedtuple_return_api.py</div><div id='n_file'> N File Name: test/test_namedtuple_return_api.py</div><div id='m_start'> M Start Line: 51</div><div id='m_end'> M End Line: 89</div><div id='n_start'> N Start Line: 52</div><div id='n_end'> N End Line: 102</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
  x = tf.keras.layers.AveragePooling2D(pool_size=8)(x)
  x = tf.keras.layers.Flatten()(x)

  <a id="change">if </a>gp_layer_hparams:
    &#47&#47 add random projection layer to reduce dimension
    gp_output_layer<a id="change"> = </a>functools.partial(
        ed.layers.RandomFeatureGaussianProcess,
        num_inducing=gp_layer_hparams[&quotgp_hidden_dim&quot],
        gp_kernel_scale=gp_layer_hparams[&quotgp_scale&quot],
        gp_output_bias=gp_layer_hparams[&quotgp_bias&quot],
        normalize_input=gp_layer_hparams[&quotgp_input_normalization&quot],
        gp_cov_momentum=gp_layer_hparams[&quotgp_cov_discount_factor&quot],
        gp_cov_ridge_penalty=gp_layer_hparams[&quotgp_cov_ridge_penalty&quot])
    if gp_layer_hparams[&quotgp_input_dim&quot] &gt; 0:
      x = tf.keras.layers.Dense(
          gp_layer_hparams[&quotgp_input_dim&quot],
          kernel_initializer=&quotrandom_normal&quot,
          use_bias=False,
          trainable=False)(x)
    logits<a id="change">, covmat = </a><a id="change">gp_output_layer(num_classes)(</a>x<a id="change">)</a>
  else:
    logits = tf.keras.layers.Dense(
        num_classes,
        kernel_initializer=&quothe_normal&quot,</code></pre><h3>After Change</h3><pre><code class='java'>

  output_layer = models_util.make_output_layer(
      gp_layer_hparams=gp_layer_hparams)
  if <a id="change">gp_layer_hparams and gp_layer_hparams[&quotgp_input_dim&quot] &gt; 0</a>:
    &#47&#47 Uses random projection to reduce the input dimension of the GP layer.
    x = tf.keras.layers.Dense(
        gp_layer_hparams[&quotgp_input_dim&quot],</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/google/uncertainty-baselines/commit/88f78028fdfa6ed7a59eb79b549b14f328da5ba4#diff-a288afdbc2983be32214a41a2ba1d719bc6f0c4c0b44a73d667ef0a46cb50a4aL126' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58267633</div><div id='project'> Project Name: google/uncertainty-baselines</div><div id='commit'> Commit Name: 88f78028fdfa6ed7a59eb79b549b14f328da5ba4</div><div id='time'> Time: 2020-09-23</div><div id='author'> Author: jjren@google.com</div><div id='file'> File Name: experimental/single_model_uncertainty/models/wide_resnet.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: wide_resnet(10)</div><div id='n_method'> N Method Name: wide_resnet(10)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: experimental/single_model_uncertainty/models/wide_resnet.py</div><div id='n_file'> N File Name: experimental/single_model_uncertainty/models/wide_resnet.py</div><div id='m_start'> M Start Line: 216</div><div id='m_end'> M End Line: 243</div><div id='n_start'> N Start Line: 215</div><div id='n_end'> N End Line: 228</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
  inputs = tf.keras.Input(
      shape=[len_seqs], batch_size=batch_size, dtype=tf.int32)

  <a id="change">if </a>one_hot:
    x<a id="change"> = </a>tf.one_hot(inputs, depth=VOCAB_SIZE)
    embed_size = VOCAB_SIZE
  else:
    x<a id="change"> = </a><a id="change">tf.keras.layers.Embedding(
        VOCAB_SIZE, embed_size, name=&quotembedding&quot)(
            </a>inputs<a id="change">)</a>
  &#47&#47 filter-wise dropout before conv, x.shape=[batch_size, len_seqs, embed_size]
  if before_conv_dropout:
    x = models_util.apply_dropout(
        x, dropout_rate, use_mc_dropout, filter_wise_dropout=True)</code></pre><h3>After Change</h3><pre><code class='java'>
          x)
  x = models_util.apply_dropout(
      x, dropout_rate, use_mc_dropout, name=&quotdropout2&quot)
  if <a id="change">gp_layer_hparams and gp_layer_hparams[&quotgp_input_dim&quot] &gt; 0</a>:
    &#47&#47 Uses random projection to reduce the input dimension of the GP layer.
    x = tf.keras.layers.Dense(
        gp_layer_hparams[&quotgp_input_dim&quot],</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/google/uncertainty-baselines/commit/3602f67f107c01a884cdf85306690a9a066b8bbc#diff-d3741817e06a9bc22874d81edfa82dcb40dda3d7f5355de1369afc2dfdf7fa9cL72' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58267639</div><div id='project'> Project Name: google/uncertainty-baselines</div><div id='commit'> Commit Name: 3602f67f107c01a884cdf85306690a9a066b8bbc</div><div id='time'> Time: 2020-08-26</div><div id='author'> Author: jjren@google.com</div><div id='file'> File Name: experimental/single_model_uncertainty/models/genomics_cnn.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: create_model(14)</div><div id='n_method'> N Method Name: create_model(14)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: experimental/single_model_uncertainty/models/genomics_cnn.py</div><div id='n_file'> N File Name: experimental/single_model_uncertainty/models/genomics_cnn.py</div><div id='m_start'> M Start Line: 113</div><div id='m_end'> M End Line: 170</div><div id='n_start'> N Start Line: 125</div><div id='n_end'> N End Line: 188</div><BR>