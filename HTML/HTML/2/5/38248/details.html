<html><h3>Pattern ID :38248
</h3><img src='109494254.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                optimizer(None, lr=1e-2, rho=1.1)

    def test_nadam(self):
        <a id="change">self._test_basic_cases(
            </a>lambda weight, bias: optim.NAdam([weight, bias], lr=1e-3)<a id="change">
        )</a>
        self._test_basic_cases(
            lambda weight, bias: optim.NAdam(
                self._build_params_dict(weight, bias, lr=1e-2),
                lr=1e-3)</code></pre><h3>After Change</h3><pre><code class='java'>
                optimizer(None, lr=1e-2, rho=1.1)

    def test_nadam(self):
        <a id="change">for </a><a id="change">optimizer</a> in <a id="change">[</a>optim.NAdam, optim_mt.NAdam<a id="change"></a>]<a id="change">:
            </a><a id="change">self._test_basic_cases(
                </a>lambda weight, bias: optimizer([weight, bias], lr=1e-3)<a id="change">
            )</a>
            self._test_basic_cases(
                lambda weight, bias: optimizer(
                    self._build_params_dict(weight, bias, lr=1e-2),
                    lr=1e-3)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/f0e972a481b51ddf9d21d3ba8e8ef0ec2e15cd8a#diff-f2b37d0b5812153acf9ff1e337d375c5cad0076c4ddc30535ec2d55c8ac9b770L484' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 109494254</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: f0e972a481b51ddf9d21d3ba8e8ef0ec2e15cd8a</div><div id='time'> Time: 2021-06-27</div><div id='author'> Author: iramazanli@fb.com</div><div id='file'> File Name: test/test_optim.py</div><div id='m_class'> M Class Name: TestOptim</div><div id='n_method'> N Class Name: TestOptim</div><div id='m_method'> M Method Name: test_nadam(1)</div><div id='n_method'> N Method Name: test_nadam(1)</div><div id='m_parent_class'> M Parent Class: TestCase</div><div id='n_parent_class'> N Parent Class: TestCase</div><div id='m_file'> M File Name: test/test_optim.py</div><div id='n_file'> N File Name: test/test_optim.py</div><div id='m_start'> M Start Line: 484</div><div id='m_end'> M End Line: 504</div><div id='n_start'> N Start Line: 488</div><div id='n_end'> N End Line: 509</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                lr=1e-1),
            [lambda opt: ReduceLROnPlateau(opt)]
        )
        <a id="change">self._test_basic_cases(
            </a>lambda weight, bias: optim.Adagrad(
                self._build_params_dict(weight, bias, lr=1e-2),
                lr=1e-1),
            [lambda opt: ReduceLROnPlateau(opt),
             lambda opt: ExponentialLR(opt, gamma=0.99)]<a id="change">
        )</a>
        with self.assertRaisesRegex(ValueError, "Invalid lr_decay value: -0.5"):
            optim.Adagrad(None, lr=1e-2, lr_decay=-0.5)

    def test_adagrad_sparse(self):</code></pre><h3>After Change</h3><pre><code class='java'>
                optimizer(None, lr=1e-2, momentum_decay=-0.2)

    def test_adagrad(self):
        <a id="change">for </a><a id="change">optimizer</a> in <a id="change">[</a>optim.Adagrad, optim_mt.Adagrad<a id="change"></a>]<a id="change">:
            </a>self._test_basic_cases(
                lambda weight, bias: optimizer([weight, bias], lr=1e-1)
            )
            self._test_basic_cases(
                lambda weight, bias: optimizer(
                    [weight, bias], lr=1e-1, initial_accumulator_value=0.1
                )
            )
            self._test_basic_cases(
                lambda weight, bias: optimizer(
                    self._build_params_dict(weight, bias, lr=1e-2),
                    lr=1e-1)
            )
            self._test_basic_cases(
                lambda weight, bias: optimizer(
                    self._build_params_dict(weight, bias, lr=1e-2),
                    lr=1e-1),
                [lambda opt: ReduceLROnPlateau(opt)]
            )
            <a id="change">self._test_basic_cases(
                </a>lambda weight, bias: optimizer(
                    self._build_params_dict(weight, bias, lr=1e-2),
                    lr=1e-1),
                [lambda opt: ReduceLROnPlateau(opt),
                 lambda opt: ExponentialLR(opt, gamma=0.99)]<a id="change">
            )</a>
            with self.assertRaisesRegex(ValueError, "Invalid lr_decay value: -0.5"):
                optimizer(None, lr=1e-2, lr_decay=-0.5)

    def test_adagrad_sparse(self):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/4a544df00dee565e6ccb73e971ff734346b16474#diff-f2b37d0b5812153acf9ff1e337d375c5cad0076c4ddc30535ec2d55c8ac9b770L509' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 109494262</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 4a544df00dee565e6ccb73e971ff734346b16474</div><div id='time'> Time: 2021-07-07</div><div id='author'> Author: ramvenkat98@devvm1486.atn0.facebook.com</div><div id='file'> File Name: test/test_optim.py</div><div id='m_class'> M Class Name: TestOptim</div><div id='n_method'> N Class Name: TestOptim</div><div id='m_method'> M Method Name: test_adagrad(1)</div><div id='n_method'> N Method Name: test_adagrad(1)</div><div id='m_parent_class'> M Parent Class: TestCase</div><div id='n_parent_class'> N Parent Class: TestCase</div><div id='m_file'> M File Name: test/test_optim.py</div><div id='n_file'> N File Name: test/test_optim.py</div><div id='m_start'> M Start Line: 510</div><div id='m_end'> M End Line: 538</div><div id='n_start'> N Start Line: 512</div><div id='n_end'> N End Line: 542</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self._test_basic_cases(
            lambda weight, bias: optim.RAdam([weight, bias], lr=1e-3, weight_decay=0.1)
        )
        <a id="change">self._test_basic_cases(
            </a>lambda weight, bias: optim.RAdam([weight, bias], lr=1e-3),
            [lambda opt: ExponentialLR(opt, gamma=0.9),
                lambda opt: ReduceLROnPlateau(opt)]<a id="change">
        )</a>
        with self.assertRaisesRegex(ValueError, "Invalid beta parameter at index 0: 1.0"):
            optim.RAdam(None, lr=1e-2, betas=(1.0, 0.0))

        with self.assertRaisesRegex(ValueError, "Invalid weight_decay value: -1"):</code></pre><h3>After Change</h3><pre><code class='java'>
                optimizer(None, lr=1e-2, betas=(0.0, 1.0))

    def test_radam(self):
        <a id="change">for </a><a id="change">optimizer</a> in <a id="change">[</a>optim.RAdam, optim_mt.RAdam<a id="change"></a>]<a id="change">:
            </a>self._test_basic_cases(
                lambda weight, bias: optimizer([weight, bias], lr=1e-3)
            )
            self._test_basic_cases(
                lambda weight, bias: optimizer(
                    self._build_params_dict(weight, bias, lr=1e-2),
                    lr=1e-3)
            )
            self._test_basic_cases(
                lambda weight, bias: optimizer([weight, bias], lr=1e-3, weight_decay=0.1)
            )
            <a id="change">self._test_basic_cases(
                </a>lambda weight, bias: optimizer([weight, bias], lr=1e-3),
                [lambda opt: ExponentialLR(opt, gamma=0.9),
                    lambda opt: ReduceLROnPlateau(opt)]<a id="change">
            )</a>
            with self.assertRaisesRegex(ValueError, "Invalid beta parameter at index 0: 1.0"):
                optimizer(None, lr=1e-2, betas=(1.0, 0.0))

            with self.assertRaisesRegex(ValueError, "Invalid weight_decay value: -1"):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/5563f4bda03548f1ade0af20c888b725785dbb59#diff-f2b37d0b5812153acf9ff1e337d375c5cad0076c4ddc30535ec2d55c8ac9b770L557' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 109494255</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 5563f4bda03548f1ade0af20c888b725785dbb59</div><div id='time'> Time: 2021-06-27</div><div id='author'> Author: iramazanli@fb.com</div><div id='file'> File Name: test/test_optim.py</div><div id='m_class'> M Class Name: TestOptim</div><div id='n_method'> N Class Name: TestOptim</div><div id='m_method'> M Method Name: test_radam(1)</div><div id='n_method'> N Method Name: test_radam(1)</div><div id='m_parent_class'> M Parent Class: TestCase</div><div id='n_parent_class'> N Parent Class: TestCase</div><div id='m_file'> M File Name: test/test_optim.py</div><div id='n_file'> N File Name: test/test_optim.py</div><div id='m_start'> M Start Line: 558</div><div id='m_end'> M End Line: 580</div><div id='n_start'> N Start Line: 560</div><div id='n_end'> N End Line: 583</div><BR>