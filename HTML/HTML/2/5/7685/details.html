<html><h3>Pattern ID :7685
</h3><img src='25545366.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        image, gt_mask = test_dataset[n]
        image_vis = image.astype(&quotuint8&quot)
        gt_mask<a id="change"> = </a><a id="change">gt_mask.squeeze()</a>

        if seg_model is not None:
            x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)
            pr_mask = best_model.predict(x_tensor)</code></pre><h3>After Change</h3><pre><code class='java'>

        if seg_model is not None:
            seg_model.eval()
            <a id="change">with torch.no_grad()</a><a id="change">:
                </a>x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)
                print(x_tensor.shape)
                pr_mask = seg_model.predict(x_tensor)
                pr_mask = pr_mask.argmax(dim=1).squeeze().cpu().numpy().astype(&quotuint8&quot)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ais-bonn/vp-suite/commit/36b68bc67b166214b4c2975c8394f80bea8a212a#diff-b601549f53dd2792fb726f06778dc09d2a665ab9ec045898f6e564a87f7a8c23L16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25545366</div><div id='project'> Project Name: ais-bonn/vp-suite</div><div id='commit'> Commit Name: 36b68bc67b166214b4c2975c8394f80bea8a212a</div><div id='time'> Time: 2021-07-15</div><div id='author'> Author: boltres@ais.uni-bonn.de</div><div id='file'> File Name: visualize.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: visualize(2)</div><div id='n_method'> N Method Name: visualize(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: visualize.py</div><div id='n_file'> N File Name: visualize.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 41</div><div id='n_start'> N Start Line: 16</div><div id='n_end'> N End Line: 33</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        pred_mask_vis = colorize_semseg(pred_mask, num_classes=SYNPICK_CLASSES)  &#47&#47 [T, 3, h, w]

        frames_colorized = colorize_semseg(postprocess_mask(frames_seg.squeeze()), num_classes=SYNPICK_CLASSES).unsqueeze(dim=0) &#47&#47 [1, T, 3, h, w]
        frames_colorized_vis<a id="change"> = </a>postprocess_img(<a id="change">frames_colorized.squeeze(dim=0)</a>)  &#47&#47 [T, 3, h, w]
        input_colorized = frames_colorized[:VIDEO_IN_LENGTH]

        colorized_then_pred = pred_colorized_mask_model.pred_n(input_colorized, pred_length=VIDEO_PRED_LENGTH)</code></pre><h3>After Change</h3><pre><code class='java'>
    test_loader = DataLoader(test_data, batch_size=1, shuffle=True, num_workers=4)
    iter_loader = iter(test_loader)

    <a id="change">with torch.no_grad()</a><a id="change">:
        </a>for i in tqdm(range(10)):

            frames = next(iter_loader).to(DEVICE)  &#47&#47 [1, T, 3, h, w]
            frames_vis = postprocess_img(frames.squeeze(dim=0))  &#47&#47 [T, 3, h, w]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ais-bonn/vp-suite/commit/13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3#diff-e07d70acfca9139cbf2c37b7a0074bdfbb966d41dc6c7edcc2cef05e78c00af0L13' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25545360</div><div id='project'> Project Name: ais-bonn/vp-suite</div><div id='commit'> Commit Name: 13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3</div><div id='time'> Time: 2021-08-02</div><div id='author'> Author: boltres@ais.uni-bonn.de</div><div id='file'> File Name: scripts/visualize_4_way.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: visualize_4_way(1)</div><div id='n_method'> N Method Name: visualize_4_way(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/visualize_4_way.py</div><div id='n_file'> N File Name: scripts/visualize_4_way.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 73</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 74</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        else:
            self.process()
        output_img = self.post_process()
        output_img<a id="change"> = </a><a id="change">output_img.data.squeeze()</a>.float().cpu().clamp_(0, 1).numpy()
        output_img = np.transpose(output_img[[2, 1, 0], :, :], (1, 2, 0))
        if img_mode == &quotL&quot:
            output_img = cv2.cvtColor(output_img, cv2.COLOR_BGR2GRAY)</code></pre><h3>After Change</h3><pre><code class='java'>
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        &#47&#47 ------------------- process image (without the alpha channel) ------------------- &#47&#47
        <a id="change">with torch.no_grad()</a><a id="change">:
            </a>self.pre_process(img)
            if self.tile_size &gt; 0:
                self.tile_process()
            else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sczhou/codeformer/commit/581abcb93b238be31d0cfea8978c3d204114bc1b#diff-892ca18bc1ec8a6270d8961318654133b86bea4bf806217ace8f8a7e49dd35d7L174' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25545356</div><div id='project'> Project Name: sczhou/codeformer</div><div id='commit'> Commit Name: 581abcb93b238be31d0cfea8978c3d204114bc1b</div><div id='time'> Time: 2022-09-04</div><div id='author'> Author: shangchenzhou@gmail.com</div><div id='file'> File Name: basicsr/utils/realesrgan_utils.py</div><div id='m_class'> M Class Name: RealESRGANer</div><div id='n_method'> N Class Name: RealESRGANer</div><div id='m_method'> M Method Name: enhance(4)</div><div id='n_method'> N Method Name: enhance(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: basicsr/utils/realesrgan_utils.py</div><div id='n_file'> N File Name: basicsr/utils/realesrgan_utils.py</div><div id='m_start'> M Start Line: 199</div><div id='m_end'> M End Line: 211</div><div id='n_start'> N Start Line: 199</div><div id='n_end'> N End Line: 211</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            A batch of audio signals to transform to features.
        
        out = self.model.feature_extractor(wav)
        out<a id="change"> = </a><a id="change">self.model.feature_aggregator(out).squeeze(</a>0<a id="change">)</a>
        out = out.transpose(2, 1)

        return out
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 If we freeze, we simply remove all grads and features from the graph.
        if self.freeze:
            <a id="change">with torch.no_grad()</a><a id="change">:
                </a>return self.extract_features(wav).detach()

        return self.extract_features(wav)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/e532179dbe4f945aa99cb7f2270ec55d6004f3fa#diff-f154e5df4be06d0debd3139de826910c14071a9c496b593aa9b96f0ef37db90cL159' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25545369</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: e532179dbe4f945aa99cb7f2270ec55d6004f3fa</div><div id='time'> Time: 2021-04-07</div><div id='author'> Author: parcollet.titouan@gmail.com</div><div id='file'> File Name: speechbrain/lobes/models/fairseq_wav2vec.py</div><div id='m_class'> M Class Name: FairseqWav2Vec1</div><div id='n_method'> N Class Name: FairseqWav2Vec1</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: speechbrain/lobes/models/fairseq_wav2vec.py</div><div id='n_file'> N File Name: speechbrain/lobes/models/fairseq_wav2vec.py</div><div id='m_start'> M Start Line: 167</div><div id='m_end'> M End Line: 171</div><div id='n_start'> N Start Line: 174</div><div id='n_end'> N End Line: 178</div><BR>