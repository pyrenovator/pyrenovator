<html><h3>Pattern ID :1230
</h3><img src='6285390.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
		
		self.env = kwargs.get("env", self.env)
		as_batch = kwargs.get("as_batch", True)
		as_sequence<a id="change"> = </a><a id="change">kwargs.get(</a>"as_sequence", False<a id="change">)</a>
		assert not (as_batch and as_sequence), "Cannot return actions as both batch and sequence."
		re_as_dict = kwargs.get("re_as_dict", isinstance(obs[0], dict))
		re_format = kwargs.get("re_format", "index")
		as_numpy = kwargs.get("as_numpy", True)</code></pre><h3>After Change</h3><pre><code class='java'>
			re_actions = re_actions[list(re_actions.keys())[0]]
		elif re_as_dict and not isinstance(re_actions, dict):
			keys = self.discrete_actions + self.continuous_actions
			re_actions<a id="change"> = </a><a id="change">{k: re_actions for k in keys}</a>
		return re_actions
	
	def format_batch_discrete_actions(
			self,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/neurotorch/neurotorch/commit/0470756f489a772da07cd64cfad8a300f24f6bfa#diff-b41e36b140b3c4fae96164ed34e5dae20114d3bb3684633592b9e2a13e44cab9L141' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6285390</div><div id='project'> Project Name: neurotorch/neurotorch</div><div id='commit'> Commit Name: 0470756f489a772da07cd64cfad8a300f24f6bfa</div><div id='time'> Time: 2022-12-03</div><div id='author'> Author: 50332514+JeremieGince@users.noreply.github.com</div><div id='file'> File Name: src/neurotorch/rl/agent.py</div><div id='m_class'> M Class Name: Agent</div><div id='n_method'> N Class Name: Agent</div><div id='m_method'> M Method Name: get_actions(2)</div><div id='n_method'> N Method Name: get_actions(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/neurotorch/rl/agent.py</div><div id='n_file'> N File Name: src/neurotorch/rl/agent.py</div><div id='m_start'> M Start Line: 141</div><div id='m_end'> M End Line: 156</div><div id='n_start'> N Start Line: 142</div><div id='n_end'> N End Line: 158</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        path = paths.get(col)
        num_rows = pq.ParquetFile(path).metadata.num_rows if path else 0
        if buckets and col in buckets and freq_limit[col] &gt; 1:
            num_rows<a id="change"> += </a><a id="change">buckets.get(</a>col, 0<a id="change">)</a>
        if buckets and col in buckets and not freq_limit[col]:
            num_rows = buckets.get(col, 0)
        embeddings[col] = _emb_sz_rule(num_rows)
    return embeddings</code></pre><h3>After Change</h3><pre><code class='java'>
    if isinstance(buckets, int):
        buckets = {name: buckets for name in cat_names}
    if isinstance(max_size, int):
        max_size<a id="change"> = </a><a id="change">{name: max_size for name in cat_names}</a>
    for col in _get_embedding_order(cat_names):
        path = paths.get(col)
        num_rows = pq.ParquetFile(path).metadata.num_rows if path else 0
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nvidia/nvtabular/commit/8d0e95e71eceabbe0d2e31a05f9f584f38fd0e48#diff-1ca374b0454b2a9fd152a1a4d3ba35e323000565d3fed5567253473d505aa8efL442' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6285395</div><div id='project'> Project Name: nvidia/nvtabular</div><div id='commit'> Commit Name: 8d0e95e71eceabbe0d2e31a05f9f584f38fd0e48</div><div id='time'> Time: 2021-02-11</div><div id='author'> Author: ronayak@hotmail.com</div><div id='file'> File Name: nvtabular/ops/categorify.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _get_embeddings_dask(5)</div><div id='n_method'> N Method Name: _get_embeddings_dask(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: nvtabular/ops/categorify.py</div><div id='n_file'> N File Name: nvtabular/ops/categorify.py</div><div id='m_start'> M Start Line: 445</div><div id='m_end'> M End Line: 454</div><div id='n_start'> N Start Line: 464</div><div id='n_end'> N End Line: 484</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        distillation_loss = ((1.0 - self._hardness) * loss) + (
            self._hardness * teacher_loss
        )
        global_step<a id="change"> = </a><a id="change">kwargs.get(</a>"global_step"<a id="change">)</a>
        global_step = epoch * steps_per_epoch if global_step is None else global_step
        _log_losses(self.loggers, global_step, loss, teacher_loss, distillation_loss)
        return distillation_loss
</code></pre><h3>After Change</h3><pre><code class='java'>
        teacher_inputs = (
            student_inputs
            if not self._teacher_input_keys
            else <a id="change">{key: student_inputs[key] for key in self._teacher_input_keys}</a>
        )
        &#47&#47 copy to keep from updating student&quots inputs
        teacher_inputs<a id="change"> = </a>deepcopy(teacher_inputs)

        if self._teacher == "self":
            _LOGGER.info("Copying current models state for self distillation")</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neuralmagic/sparseml/commit/00add9fd9b677d966f02dd7c32060e50140dc14f#diff-37a1d70c58e00289a182955989f1d34a7b14be0cae1ced43409e44cb36926904L218' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6285392</div><div id='project'> Project Name: neuralmagic/sparseml</div><div id='commit'> Commit Name: 00add9fd9b677d966f02dd7c32060e50140dc14f</div><div id='time'> Time: 2022-02-01</div><div id='author'> Author: mark@neuralmagic.com</div><div id='file'> File Name: src/sparseml/pytorch/optim/modifier_distillation.py</div><div id='m_class'> M Class Name: DistillationModifier</div><div id='n_method'> N Class Name: DistillationModifier</div><div id='m_method'> M Method Name: loss_update(8)</div><div id='n_method'> N Method Name: loss_update(8)</div><div id='m_parent_class'> M Parent Class: ScheduledUpdateModifier</div><div id='n_parent_class'> N Parent Class: ScheduledModifier</div><div id='m_file'> M File Name: src/sparseml/pytorch/optim/modifier_distillation.py</div><div id='n_file'> N File Name: src/sparseml/pytorch/optim/modifier_distillation.py</div><div id='m_start'> M Start Line: 244</div><div id='m_end'> M End Line: 290</div><div id='n_start'> N Start Line: 260</div><div id='n_end'> N End Line: 327</div><BR>