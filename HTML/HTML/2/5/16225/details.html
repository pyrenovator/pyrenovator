<html><h3>Pattern ID :16225
</h3><img src='54195130.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 5-level loop, forgive me...
        for xi, xs in enumerate(X):
            for yi, ys in <a id="change">enumerate(</a>Y<a id="change">)</a>:
                for zi, zs in enumerate(Z):
                    lx, ly, lz = len(xs), len(ys), len(zs)
                    &#47&#47 construct points
                    xx, yy, zz = custom_meshgrid(xs, ys, zs)
                    world_xyzs = torch.cat([xx.reshape(-1, 1), yy.reshape(-1, 1), zz.reshape(-1, 1)], dim=-1).unsqueeze(0).to(count.device) &#47&#47 [1, N, 3]

                    &#47&#47 cascading
                    for cas in range(self.cascade):
                        bound = min(2 ** cas, self.bound)
                        half_grid_size = bound / resolution
                        &#47&#47 scale to current cascade&quots resolution
                        cas_world_xyzs = world_xyzs * (bound - half_grid_size)

                        &#47&#47 split batch to avoid OOM
                        head = 0
                        while head &lt; B:
                            tail = min(head + S, B)

                            &#47&#47 world2cam transform (poses is c2w, so we need to transpose it. Another transpose is needed for batched matmul, so the final form is without transpose.)
                            cam_xyzs = cas_world_xyzs - poses[head:tail, :3, 3].unsqueeze(1)
                            cam_xyzs = cam_xyzs @ poses[head:tail, :3, :3] &#47&#47 [S, N, 3]
                            
                            &#47&#47 query if point is covered by any camera
                            mask_z = cam_xyzs[:, :, 2] &gt; 0 &#47&#47 [S, N]
                            mask_x = torch.abs(cam_xyzs[:, :, 0]) &lt; cx / fx * cam_xyzs[:, :, 2] + half_grid_size * 2
                            mask_y = torch.abs(cam_xyzs[:, :, 1]) &lt; cy / fy * cam_xyzs[:, :, 2] + half_grid_size * 2
                            mask = (mask_z & mask_x & mask_y).sum(0).reshape(lx, ly, lz) &#47&#47 [N] --&gt; [lx, ly, lz]

                            &#47&#47 update count 
                            count[cas, xi * S: xi<a id="change"> * </a>S + lx, yi * S: yi * S + ly, zi * S: zi * S + lz] += mask
                            head += S
    
        &#47&#47 mark untrained grid as -1</code></pre><h3>After Change</h3><pre><code class='java'>
                    &#47&#47 construct points
                    xx, yy, zz = custom_meshgrid(xs, ys, zs)
                    coords = torch.cat([xx.reshape(-1, 1), yy.reshape(-1, 1), zz.reshape(-1, 1)], dim=-1) &#47&#47 [N, 3], in [0, 128)
                    indices<a id="change"> = </a><a id="change">raymarching.morton3D(coords).long()</a> &#47&#47 [N]
                    world_xyzs = (2 * coords.float() / (self.grid_size - 1) - 1).unsqueeze(0) &#47&#47 [1, N, 3] in [-1, 1]

                    &#47&#47 cascading
                    for cas in range(self.cascade):
                        bound = min(2 ** cas, self.bound)
                        half_grid_size = bound / self.grid_size
                        &#47&#47 scale to current cascade&quots resolution
                        cas_world_xyzs = world_xyzs * (bound - half_grid_size)

                        &#47&#47 split batch to avoid OOM
                        head = 0
                        while head &lt; B:
                            tail = min(head + S, B)

                            &#47&#47 world2cam transform (poses is c2w, so we need to transpose it. Another transpose is needed for batched matmul, so the final form is without transpose.)
                            cam_xyzs = cas_world_xyzs - poses[head:tail, :3, 3].unsqueeze(1)
                            cam_xyzs = cam_xyzs @ poses[head:tail, :3, :3] &#47&#47 [S, N, 3]
                            
                            &#47&#47 query if point is covered by any camera
                            mask_z = cam_xyzs[:, :, 2] &gt; 0 &#47&#47 [S, N]
                            mask_x = torch.abs(cam_xyzs[:, :, 0]) &lt; cx / fx * cam_xyzs[:, :, 2] + half_grid_size * 2
                            mask_y = torch.abs(cam_xyzs[:, :, 1]) &lt; cy / fy * cam_xyzs[:, :, 2] + half_grid_size * 2
                            mask = (mask_z & mask_x & mask_y).sum(0).reshape(-1) &#47&#47 [N]

                            &#47&#47 update count 
                            count[cas<a id="change">, indices</a>] += mask
                            head += S
    
        &#47&#47 mark untrained grid as -1</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ashawkey/torch-ngp/commit/f02ec4824ef16a650c5a4acac510ec6c224a4337#diff-96330057ed34864879e5c07ca3b71aa0415cc9281c388c0ec9d3d6892d48343aL397' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 54195130</div><div id='project'> Project Name: ashawkey/torch-ngp</div><div id='commit'> Commit Name: f02ec4824ef16a650c5a4acac510ec6c224a4337</div><div id='time'> Time: 2022-06-02</div><div id='author'> Author: ashawkey1999@gmail.com</div><div id='file'> File Name: nerf/renderer.py</div><div id='m_class'> M Class Name: NeRFRenderer</div><div id='n_method'> N Class Name: NeRFRenderer</div><div id='m_method'> M Method Name: mark_untrained_grid(4)</div><div id='n_method'> N Method Name: mark_untrained_grid(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: nerf/renderer.py</div><div id='n_file'> N File Name: nerf/renderer.py</div><div id='m_start'> M Start Line: 397</div><div id='m_end'> M End Line: 438</div><div id='n_start'> N Start Line: 397</div><div id='n_end'> N End Line: 439</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        Y = torch.linspace(-1, 1, resolution).split(S)
        Z = torch.linspace(-1, 1, resolution).split(S)
        for xi, xs in enumerate(X):
            for yi, ys in <a id="change">enumerate(</a>Y<a id="change">)</a>:
                for zi, zs in enumerate(Z):
                    lx, ly, lz = len(xs), len(ys), len(zs)
                    &#47&#47 construct points
                    xx, yy, zz = custom_meshgrid(xs, ys, zs)
                    xyzs = torch.cat([xx.reshape(-1, 1), yy.reshape(-1, 1), zz.reshape(-1, 1)], dim=-1) &#47&#47 [N, 3], in [-1, 1]

                    &#47&#47 cascading
                    for cas in range(self.cascade):
                        bound = min(2 ** cas, self.bound)
                        half_grid_size = bound / resolution
                        &#47&#47 scale to current cascade&quots resolution
                        cas_xyzs = xyzs * (bound - half_grid_size)
                        &#47&#47 add noise in [-hgs, hgs]
                        cas_xyzs += (torch.rand_like(cas_xyzs) * 2 - 1) * half_grid_size
                        &#47&#47 query density
                        sigmas = self.density(cas_xyzs.to(tmp_grid.device))[&quotsigma&quot].reshape(lx, ly, lz).detach()
                        &#47&#47 from `scalbnf(MIN_CONE_STEPSIZE(), 0)`, check `splat_grid_samples_nerf_max_nearest_neighbor`
                        &#47&#47 scale == 2 * sqrt(3) / 1024
                        sigmas *= self.density_scale * 0.003383
                        &#47&#47 assign 
                        tmp_grid[cas, xi * S: xi * S + lx, yi * S: yi * S + ly, zi * S: zi<a id="change"> * S + </a>lz] = sigmas
        
        
        &#47&#47 ema update</code></pre><h3>After Change</h3><pre><code class='java'>
                    &#47&#47 construct points
                    xx, yy, zz = custom_meshgrid(xs, ys, zs)
                    coords = torch.cat([xx.reshape(-1, 1), yy.reshape(-1, 1), zz.reshape(-1, 1)], dim=-1) &#47&#47 [N, 3], in [0, 128)
                    indices<a id="change"> = </a><a id="change">raymarching.morton3D(coords).long()</a> &#47&#47 [N]
                    xyzs = 2 * coords.float() / (self.grid_size - 1) - 1 &#47&#47 [N, 3] in [-1, 1]

                    &#47&#47 cascading
                    for cas in range(self.cascade):
                        bound = min(2 ** cas, self.bound)
                        half_grid_size = bound / self.grid_size
                        &#47&#47 scale to current cascade&quots resolution
                        cas_xyzs = xyzs * (bound - half_grid_size)
                        &#47&#47 add noise in [-hgs, hgs]
                        cas_xyzs += (torch.rand_like(cas_xyzs) * 2 - 1) * half_grid_size
                        &#47&#47 query density
                        sigmas = self.density(cas_xyzs)[&quotsigma&quot].reshape(-1).detach()
                        &#47&#47 from `scalbnf(MIN_CONE_STEPSIZE(), 0)`, check `splat_grid_samples_nerf_max_nearest_neighbor`
                        &#47&#47 scale == 2 * sqrt(3) / 1024
                        sigmas *= self.density_scale * 0.003383
                        &#47&#47 assign 
                        tmp_grid[cas<a id="change">, indices</a>] = sigmas
        
        
        &#47&#47 ema update</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ashawkey/torch-ngp/commit/f02ec4824ef16a650c5a4acac510ec6c224a4337#diff-96330057ed34864879e5c07ca3b71aa0415cc9281c388c0ec9d3d6892d48343aL447' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 54195122</div><div id='project'> Project Name: ashawkey/torch-ngp</div><div id='commit'> Commit Name: f02ec4824ef16a650c5a4acac510ec6c224a4337</div><div id='time'> Time: 2022-06-02</div><div id='author'> Author: ashawkey1999@gmail.com</div><div id='file'> File Name: nerf/renderer.py</div><div id='m_class'> M Class Name: NeRFRenderer</div><div id='n_method'> N Class Name: NeRFRenderer</div><div id='m_method'> M Method Name: update_extra_state(3)</div><div id='n_method'> N Method Name: update_extra_state(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: nerf/renderer.py</div><div id='n_file'> N File Name: nerf/renderer.py</div><div id='m_start'> M Start Line: 454</div><div id='m_end'> M End Line: 488</div><div id='n_start'> N Start Line: 461</div><div id='n_end'> N End Line: 490</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    mrr, hits = [], []

    for i, (s, p, o) in <a id="change">enumerate(</a>test_spo<a id="change">)</a>:
        row = scores[i]  &#47&#47 corresponding predictions
        idx = o if direction == "o" else s
        true_score = row[idx]

        &#47&#47 remove current label from scores
        row = row.clone()
        row[idx] = float("-Inf")

        &#47&#47 follow LibKGE protocol for ranking and ties
        rank = int(torch.sum(row &gt; true_score, dtype=torch.long))
        num_ties = int(torch.sum(row == true_score, dtype=torch.long))
        rank = rank + num_ties // 2 + 1

        &#47&#47 compute MRR and Hits@k
        mrr.append(1<a id="change"> / </a>rank)
        hits.append(int(rank &lt;= k))

    return mrr, hits</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 get the scores of the true target subjects/objects
    idx = 0 if direction == "s" else 2
    targets<a id="change"> = </a><a id="change">test_spo[:, idx].long()</a>
    arange = torch.arange(len(targets), dtype=torch.long, device="cpu")
    true_scores = scores[arange<a id="change">, targets</a>].view(-1, 1)

    &#47&#47 remove the true subjects/objects from the scores so they don&quott factor in rankings
    scores = scores.clone()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tsafavi/codex/commit/3dddca246e4fb616cef251bafb32dac648e8eedb#diff-7473d3c6ae8fdca415f05877da582b17af17f591a0a1312717bb10fd4da4b992L119' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 54195154</div><div id='project'> Project Name: tsafavi/codex</div><div id='commit'> Commit Name: 3dddca246e4fb616cef251bafb32dac648e8eedb</div><div id='time'> Time: 2020-07-08</div><div id='author'> Author: tsafavi@umich.edu</div><div id='file'> File Name: scripts/baseline.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate_rankings(5)</div><div id='n_method'> N Method Name: evaluate_rankings(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/baseline.py</div><div id='n_file'> N File Name: scripts/baseline.py</div><div id='m_start'> M Start Line: 129</div><div id='m_end'> M End Line: 151</div><div id='n_start'> N Start Line: 129</div><div id='n_end'> N End Line: 148</div><BR>