<html><h3>Pattern ID :8027
</h3><img src='28461234.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
def mhsa_with_multi_head_relative_position_embedding(
    inputs, num_heads=4, key_dim=0, global_query=None, out_shape=None, out_weight=True, qkv_bias=False, out_bias=False, attn_dropout=0, name=None
):
    channel_axis = -1<a id="change"> if </a>image_data_format() == "channels_last"<a id="change"> else </a>1
    input_channel = inputs.shape[channel_axis]
    height, width = inputs.shape[1:-1] if image_data_format() == "channels_last" else inputs.shape[2:]
</code></pre><h3>After Change</h3><pre><code class='java'>
        inputs = layers.Permute([2, 3, 1])(inputs)
    elif image_data_format() == "channels_first" and data_format == "channels_last":
        inputs = layers.Permute([3, 1, 2])(inputs)
    conv_channel_axis = -1<a id="change"> if </a><a id="change">image_data_format() == "channels_last" else </a>1

    if global_query is not None:
        &#47&#47 kv = layers.Dense(qk_out * 2, use_bias=qkv_bias, name=name and name + "kv")(inputs)  &#47&#47 For GCViT weights</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/2ba27b0132168f3590dd4b3bead9edc15a70ba7d#diff-93ecfaca577d52a2659237cd2194089f24ed46627c659ab6c323a696749405deL25' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 28461234</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: 2ba27b0132168f3590dd4b3bead9edc15a70ba7d</div><div id='time'> Time: 2023-02-11</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/coatnet/coatnet.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mhsa_with_multi_head_relative_position_embedding(11)</div><div id='n_method'> N Method Name: mhsa_with_multi_head_relative_position_embedding(10)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/coatnet/coatnet.py</div><div id='n_file'> N File Name: keras_cv_attention_models/coatnet/coatnet.py</div><div id='m_start'> M Start Line: 25</div><div id='m_end'> M End Line: 57</div><div id='n_start'> N Start Line: 32</div><div id='n_end'> N End Line: 74</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        bias_init = tf.constant_initializer(-tf.math.log((1 - 0.01) / 0.01).numpy())
        class_features = det_header_pre(fpn_features, num_channels, head_depth, use_sep_conv, activation=activation, name="classifier_")
        class_out = det_header_post(class_features, num_classes, num_anchors, bias_init, use_sep_conv, classifier_activation, name="classifier_")
        outputs = tf.concat([bboxes_out, class_out, object_out], axis=-1)<a id="change"> if </a>use_object_scores<a id="change"> else </a>tf.concat([bboxes_out, class_out], axis=-1)
    else:
        outputs = tf.concat([bboxes_out, object_out], axis=-1) if use_object_scores else bboxes_out
    outputs = keras.layers.Activation("linear", dtype="float32", name="outputs_fp32")(outputs)</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 Regard input_shape as force using original shape if first element is None or -1,
    &#47&#47 else assume channel dimention is the one with min value in input_shape, and put it first or last regarding image_data_format
    input_shape = backend.align_input_shape_by_image_data_format(input_shape)
    channel_axis = -1<a id="change"> if </a><a id="change">image_data_format() == "channels_last" else </a>1
    backbone.trainable = False if freeze_backbone else True
    use_object_scores, num_anchors, anchor_scale = anchors_func.get_anchors_mode_parameters(anchors_mode, use_object_scores, num_anchors, anchor_scale)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/4d4ea978b42024953a1eba7469530dec223545e0#diff-3f9f0e5959ff53138eb9239ccd1a0739b9d3c72b2e971e9417426d682d495fd7L136' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 28461235</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: 4d4ea978b42024953a1eba7469530dec223545e0</div><div id='time'> Time: 2023-02-14</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/efficientdet/efficientdet.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: EfficientDet(22)</div><div id='n_method'> N Method Name: EfficientDet(22)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/efficientdet/efficientdet.py</div><div id='n_file'> N File Name: keras_cv_attention_models/efficientdet/efficientdet.py</div><div id='m_start'> M Start Line: 168</div><div id='m_end'> M End Line: 200</div><div id='n_start'> N Start Line: 180</div><div id='n_end'> N End Line: 225</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            block_name = stack_name + "block{}_".format(block_id + 1)
            block_drop_rate = drop_connect_rate * global_block_id / total_blocks
            mlp_ratio = cur_mlp_ratios[block_id] if isinstance(cur_mlp_ratios, (list, tuple)) else cur_mlp_ratios
            is_attn_block = True<a id="change"> if </a>block_id &gt; num_block - cur_num_attn_blocks - 1<a id="change"> else </a>False
            nn = meta_block(nn, is_attn_block, mlp_ratio=mlp_ratio, layer_scale=layer_scale, drop_rate=block_drop_rate, activation=activation, name=block_name)
            global_block_id += 1
</code></pre><h3>After Change</h3><pre><code class='java'>
            block_drop_rate = drop_connect_rate * global_block_id / total_blocks
            mlp_ratio = cur_mlp_ratios[block_id] if isinstance(cur_mlp_ratios, (list, tuple)) else cur_mlp_ratios
            if block_id &gt;= attn_block_start_id:
                nn = layers.Permute([2, 3, 1])(nn)<a id="change"> if </a>block_id == attn_block_start_id and <a id="change">image_data_format() == "channels_first" else </a>nn
                nn = attn_block(nn, mlp_ratio=mlp_ratio, layer_scale=layer_scale, drop_rate=block_drop_rate, activation=activation, name=block_name)
                nn = layers.Permute([3, 1, 2])(nn) if block_id == num_block - 1 and image_data_format() == "channels_first" else nn
            else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/e05e233f369a1d58f912872b1581a80d15cacc3f#diff-e4e5a4f85b1ff1331833f78429788f4c2aeb32f0af6bd15093785e3e483e2c29L49' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 28461232</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: e05e233f369a1d58f912872b1581a80d15cacc3f</div><div id='time'> Time: 2023-02-07</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/efficientformer/efficientformer.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: EfficientFormer(17)</div><div id='n_method'> N Method Name: EfficientFormer(17)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/efficientformer/efficientformer.py</div><div id='n_file'> N File Name: keras_cv_attention_models/efficientformer/efficientformer.py</div><div id='m_start'> M Start Line: 68</div><div id='m_end'> M End Line: 110</div><div id='n_start'> N Start Line: 71</div><div id='n_end'> N End Line: 120</div><BR>