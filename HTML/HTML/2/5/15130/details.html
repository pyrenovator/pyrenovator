<html><h3>Pattern ID :15130
</h3><img src='51324879.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                track.chunk_start = start
                track.chunk_duration = duration
                target = track.targets[self.target].audio.transpose(1, 0)
                target<a id="change"> = </a><a id="change">torch.Tensor(</a>target<a id="change">)</a>.float()

                if self._is_active(target, threshold=self.threshold):
                    data = {</code></pre><h3>After Change</h3><pre><code class='java'>

        for songID, track in enumerate(self.mus.tracks):
            if set(self.sources) == set(__sources__):
                mixture = <a id="change">track.audio.transpose(1</a>, <a id="change">0</a><a id="change">)</a>
            else:
                sources = []
                for _source in self.sources:
                    sources.append(track.targets[_source].audio.transpose(1, 0)[np.newaxis])</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tky823/dnn-based_source_separation/commit/b7a22e8f24f8206fc28ef8b7f01f01fcce0a498c#diff-8f1539f8f92a2935319a03c1ee38b31a527ccde3261a84eef37557a3687d73b3L83' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 51324879</div><div id='project'> Project Name: tky823/dnn-based_source_separation</div><div id='commit'> Commit Name: b7a22e8f24f8206fc28ef8b7f01f01fcce0a498c</div><div id='time'> Time: 2021-08-10</div><div id='author'> Author: 40362510+tky823@users.noreply.github.com</div><div id='file'> File Name: egs/musdb18/conv-tasnet/src/adhoc_dataset.py</div><div id='m_class'> M Class Name: WaveTrainDataset</div><div id='n_method'> N Class Name: WaveTrainDataset</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(8)</div><div id='m_parent_class'> M Parent Class: WaveDataset</div><div id='n_parent_class'> N Parent Class: WaveDataset</div><div id='m_file'> M File Name: egs/musdb18/conv-tasnet/src/adhoc_dataset.py</div><div id='n_file'> N File Name: egs/musdb18/conv-tasnet/src/adhoc_dataset.py</div><div id='m_start'> M Start Line: 91</div><div id='m_end'> M End Line: 117</div><div id='n_start'> N Start Line: 83</div><div id='n_end'> N End Line: 98</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                                               encoded_texts=encoded_texts.detach(),
                                               tgt_nonpadding=target_non_padding_mask)
        else:
            glow_loss<a id="change"> = </a><a id="change">torch.Tensor(</a>[0.0]<a id="change">)</a>

        if not is_inference:
            return before_outs, after_outs, predicted_durations, pitch_predictions, energy_predictions, kl_loss, glow_loss
</code></pre><h3>After Change</h3><pre><code class='java'>
        else:
            target_non_padding_mask = None
        before_outs = self.decoder(encoded_texts, nonpadding=target_non_padding_mask).transpose(1, 2)
        before_outs = <a id="change">self.out_proj(before_outs).transpose(1</a>, <a id="change">2</a><a id="change">)</a>

        after_outs = None

        &#47&#47 forward flow post-net</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/25d5dd64db2eb9b9512b343ad11ef047c1fe09cc#diff-12643f5b2c8b9a82605c22c3f362317aa32afc7f0c07d080244ac4cefb2f5794L276' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 51324886</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 25d5dd64db2eb9b9512b343ad11ef047c1fe09cc</div><div id='time'> Time: 2022-12-27</div><div id='author'> Author: lux.florian@gmail.com</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/PortaSpeech/PortaSpeech.py</div><div id='m_class'> M Class Name: PortaSpeech</div><div id='n_method'> N Class Name: PortaSpeech</div><div id='m_method'> M Method Name: _forward(12)</div><div id='n_method'> N Method Name: _forward(14)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module,ABC</div><div id='n_parent_class'> N Parent Class: torch.nn.Module,ABC</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/PortaSpeech/PortaSpeech.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/PortaSpeech/PortaSpeech.py</div><div id='m_start'> M Start Line: 285</div><div id='m_end'> M End Line: 373</div><div id='n_start'> N Start Line: 327</div><div id='n_end'> N End Line: 351</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        Xs = stft(wavs.data.cpu().numpy(), n_fft=1024, hop_length=512)
        Xs = np.log(1 + np.abs(Xs))
        Xs<a id="change"> = </a><a id="change">torch.Tensor(</a>Xs<a id="change">)</a>.float().to(self.device)

        &#47&#47 Concatenate labels (due to data augmentation)
        if stage == sb.Stage.TRAIN and False:</code></pre><h3>After Change</h3><pre><code class='java'>

        X_stft = self.modules.compute_stft(wavs)
        X_stft_power = sb.processing.features.spectral_magnitude(X_stft, power=self.hparams.spec_mag_power)
        X_stft_logpower = <a id="change">torch.log(X_stft_power + 1).transpose(1</a>, <a id="change">2</a><a id="change">)</a>

        &#47&#47 Concatenate labels (due to data augmentation)
        if stage == sb.Stage.TRAIN and False:
            classid = torch.cat([classid] * self.n_augment, dim=0)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/5141f8cfe46029b6dd2c051199291f4c21cae8e0#diff-8f3874d114f157f94ccdf7b656a9cc7738dfe21aef4a26c86929a9f19edda806L137' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 51324882</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 5141f8cfe46029b6dd2c051199291f4c21cae8e0</div><div id='time'> Time: 2022-11-20</div><div id='author'> Author: me@francescopaissan.it</div><div id='file'> File Name: recipes/ESC50/classification/train_interpreter.py</div><div id='m_class'> M Class Name: InterpreterESC50Brain</div><div id='n_method'> N Class Name: InterpreterESC50Brain</div><div id='m_method'> M Method Name: compute_objectives(4)</div><div id='n_method'> N Method Name: compute_objectives(4)</div><div id='m_parent_class'> M Parent Class: sb.core.Brain</div><div id='n_parent_class'> N Parent Class: sb.core.Brain</div><div id='m_file'> M File Name: recipes/ESC50/classification/train_interpreter.py</div><div id='n_file'> N File Name: recipes/ESC50/classification/train_interpreter.py</div><div id='m_start'> M Start Line: 147</div><div id='m_end'> M End Line: 173</div><div id='n_start'> N Start Line: 150</div><div id='n_end'> N End Line: 171</div><BR>