<html><h3>Pattern ID :31271
</h3><img src='91673572.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        h : tensor
            The output features
        
        semantic_embeddings<a id="change"> = </a><a id="change">[]</a>
        h = self.hidden(h)
        if self._cached_graph is None or self._cached_graph is not g:
            self._cached_graph = g
            self._cached_coalesced_graph.clear()
            for meta_path in self.meta_paths:
                self._cached_coalesced_graph[meta_path] = dgl.metapath_reachable_graph(
                        g, meta_path)

        <a id="change">for </a>i, meta_path in enumerate(self.meta_paths)<a id="change">:

            </a>new_g = self._cached_coalesced_graph[meta_path]
            <a id="change">semantic_embeddings.append(</a>self.propagation_layers[i](new_g, h).flatten(1)<a id="change">)</a>
        semantic_embeddings = torch.stack(semantic_embeddings, dim=1)

        return self.semantic_fusion(semantic_embeddings)
</code></pre><h3>After Change</h3><pre><code class='java'>
                self._cached_coalesced_graph[meta_path] = dgl.metapath_reachable_graph(
                        g, meta_path)

        h = <a id="change">self.model(</a>self._cached_coalesced_graph, h<a id="change">)</a>
        return h


</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/bupt-gamma/openhgnn/commit/bd15d668053389800a158b521ef97860b18e3719#diff-dcb3ada8373d1a7302711fab0b7c9bdcd8be5e440bde471c0babc84098fd2d37L135' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 91673572</div><div id='project'> Project Name: bupt-gamma/openhgnn</div><div id='commit'> Commit Name: bd15d668053389800a158b521ef97860b18e3719</div><div id='time'> Time: 2021-09-07</div><div id='author'> Author: 34649403+Theheavens@users.noreply.github.com</div><div id='file'> File Name: openhgnn/models/HPN.py</div><div id='m_class'> M Class Name: HPNLayer</div><div id='n_method'> N Class Name: HPNLayer</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: openhgnn/models/HPN.py</div><div id='n_file'> N File Name: openhgnn/models/HPN.py</div><div id='m_start'> M Start Line: 151</div><div id='m_end'> M End Line: 166</div><div id='n_start'> N Start Line: 135</div><div id='n_end'> N End Line: 144</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        h : tensor
            The output features
        
        semantic_embeddings<a id="change"> = </a><a id="change">[]</a>

        if self._cached_graph is None or self._cached_graph is not g:
            self._cached_graph = g
            self._cached_coalesced_graph.clear()
            for meta_path in self.meta_paths:
                self._cached_coalesced_graph[meta_path] = dgl.metapath_reachable_graph(
                        g, meta_path)

        <a id="change">for </a>i, meta_path in enumerate(self.meta_paths)<a id="change">:
            </a>new_g = self._cached_coalesced_graph[meta_path]
            <a id="change">semantic_embeddings.append(</a>self.gat_layers[i](new_g, h).flatten(1)<a id="change">)</a>
        semantic_embeddings = torch.stack(semantic_embeddings, dim=1)                  &#47&#47 (N, M, D * K)

        return self.semantic_attention(semantic_embeddings)                            &#47&#47 (N, D * K)
</code></pre><h3>After Change</h3><pre><code class='java'>
            for meta_path in self.meta_paths:
                self._cached_coalesced_graph[meta_path] = dgl.metapath_reachable_graph(
                        g, meta_path)
        h = <a id="change">self.model(</a>self._cached_coalesced_graph, h<a id="change">)</a>
        return h
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bupt-gamma/openhgnn/commit/bd15d668053389800a158b521ef97860b18e3719#diff-2f354b81b662a7a8ee08913aaa88328a62ba33f16f029b2460e0cb581daf04e1L100' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 91673573</div><div id='project'> Project Name: bupt-gamma/openhgnn</div><div id='commit'> Commit Name: bd15d668053389800a158b521ef97860b18e3719</div><div id='time'> Time: 2021-09-07</div><div id='author'> Author: 34649403+Theheavens@users.noreply.github.com</div><div id='file'> File Name: openhgnn/models/HAN.py</div><div id='m_class'> M Class Name: HANLayer</div><div id='n_method'> N Class Name: HANLayer</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: openhgnn/models/HAN.py</div><div id='n_file'> N File Name: openhgnn/models/HAN.py</div><div id='m_start'> M Start Line: 114</div><div id='m_end'> M End Line: 128</div><div id='n_start'> N Start Line: 117</div><div id='n_end'> N End Line: 120</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 tokenize the text. -&gt; then return prediction
  
    &#47&#47 Text as sequence of sentencepiece ID"s.
    context<a id="change"> =</a><a id="change">[]</a>
    question = []
    <a id="change">for </a>i in inputs<a id="change">:
        </a>question.append(i[&quotquestion&quot])
        <a id="change">context.append(</a>i[&quotcontext&quot]<a id="change">)</a>

    prediction_output = []
    for i in range(len(inputs)):
        model = FlaxBertForQuestionAnswering.from_pretrained("mrm8488/bert-multi-cased-finedtuned-xquad-tydiqa-goldp")</code></pre><h3>After Change</h3><pre><code class='java'>
    prediction_output = []
    for inp in inputs:
      tokenized = self.tokenizer(inp[&quotquestion&quot], inp[&quotcontext&quot], return_tensors="jax", padding=True)
      output = <a id="change">self.model(**tokenized)</a>
      answer_start_index = output.start_logits.argmax()
      answer_end_index = output.end_logits.argmax()
      predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]
      prediction_output.append({</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pair-code/lit/commit/91a22d65b7165cea1ad68dfffce0769ec9a2c966#diff-e66e2ed65042046b3905d9bc4b44fa2c3bb19cb8c07da5a9540002725714fab0L129' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 91673570</div><div id='project'> Project Name: pair-code/lit</div><div id='commit'> Commit Name: 91a22d65b7165cea1ad68dfffce0769ec9a2c966</div><div id='time'> Time: 2022-06-16</div><div id='author'> Author: 31214277+aryan1107@users.noreply.github.com</div><div id='file'> File Name: lit_nlp/examples/models/tydi.py</div><div id='m_class'> M Class Name: TydiModel</div><div id='n_method'> N Class Name: TydiModel</div><div id='m_method'> M Method Name: predict_minibatch(2)</div><div id='n_method'> N Method Name: predict_minibatch(2)</div><div id='m_parent_class'> M Parent Class: lit_model.Model</div><div id='n_parent_class'> N Parent Class: lit_model.Model</div><div id='m_file'> M File Name: lit_nlp/examples/models/tydi.py</div><div id='n_file'> N File Name: lit_nlp/examples/models/tydi.py</div><div id='m_start'> M Start Line: 134</div><div id='m_end'> M End Line: 156</div><div id='n_start'> N Start Line: 130</div><div id='n_end'> N End Line: 138</div><BR>