<html><h3>Pattern ID :1108
</h3><img src='5591869.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        data_time_m.update(time.time() - end)
        if not args.prefetcher:
            input, target = input.cuda(), target.cuda()
            <a id="change">if </a>args.mixup &gt; 0.:
                lam = 1.
                if not args.mixup_off_epoch or epoch &lt; args.mixup_off_epoch:
                    lam = np.random.beta(args.mixup, args.mixup)
                input<a id="change"> = </a>input.mul(lam).add_(1 - lam, <a id="change">input.flip(0</a><a id="change">)</a>)
                target = mixup_target(target, args.num_classes, lam, args.smoothing)

        output = model(input)</code></pre><h3>After Change</h3><pre><code class='java'>
        if not args.prefetcher:
            input, target = input.cuda(), target.cuda()
            if args.mixup &gt; 0.:
                input<a id="change">, target</a> = mixup_batch(
                    input, target,
                    alpha=args.mixup, num_classes=args.num_classes, smoothing=args.smoothing,
                    disable=args.mixup_off_epoch and epoch &gt;= args.mixup_off_epoch)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/feng-lab/pytorch-image-models/commit/232ab7fb12ba082e6d4039c7a7c7f2701caa0a71#diff-ed183d67207df065a11e1289f19d34cc2abbc5448dea952683cfe9728c342b95L454' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5591869</div><div id='project'> Project Name: feng-lab/pytorch-image-models</div><div id='commit'> Commit Name: 232ab7fb12ba082e6d4039c7a7c7f2701caa0a71</div><div id='time'> Time: 2019-12-20</div><div id='author'> Author: rwightman@gmail.com</div><div id='file'> File Name: train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train_epoch(11)</div><div id='n_method'> N Method Name: train_epoch(11)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train.py</div><div id='n_file'> N File Name: train.py</div><div id='m_start'> M Start Line: 454</div><div id='m_end'> M End Line: 461</div><div id='n_start'> N Start Line: 470</div><div id='n_end'> N End Line: 476</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                if len(frames) &gt; 0: img = frames[-1]
                else: img = np.zeros((112, 112, 3), dtype=np.uint8)
            if crop_augment: pass &#47&#47 TODO: implement random crop
            <a id="change">if </a>mirror_augment: img<a id="change"> = </a><a id="change">cv2.flip(</a>img, <a id="change">1</a><a id="change">)</a>
            &#47&#47 TODO: add temporal augmentation (repeat, deletion)
            frames.append(img)
    else:
        cap = cv2.VideoCapture(path)</code></pre><h3>After Change</h3><pre><code class='java'>
            if len(frames) &gt; 0: img = frames[-1]
            else: img = np.zeros((112, 112, 3), dtype=np.uint8)
        if crop_augment:
            img = cv2.resize(img, (128<a id="change">, 128</a>))
            if is_training:
                crop_x = random.randint(0, 16)
                crop_y = random.randint(0, 16)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sailordiary/m3f.pytorch/commit/639f60090b44d3fdb3b40ae0df467ffed523da9e#diff-2730a8c5bd5549f02454fcdfd4a30faef0d608acd1627662eacd9e71c765c6feL46' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5591868</div><div id='project'> Project Name: sailordiary/m3f.pytorch</div><div id='commit'> Commit Name: 639f60090b44d3fdb3b40ae0df467ffed523da9e</div><div id='time'> Time: 2020-02-01</div><div id='author'> Author: me@sailorzhang.com</div><div id='file'> File Name: models/dataset.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: load_video(7)</div><div id='n_method'> N Method Name: load_video(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: models/dataset.py</div><div id='n_file'> N File Name: models/dataset.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 75</div><div id='n_start'> N Start Line: 47</div><div id='n_end'> N End Line: 70</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Processing time steps
        h = self.ligru_cell(w)

        <a id="change">if </a>self.bidirectional:
            h_f, h_b = h.chunk(2, dim=1)
            h_b = <a id="change">h_b.flip(0</a><a id="change">)</a>
            h<a id="change"> = </a>torch.cat([h_f, h_b], dim=2)

        return h
</code></pre><h3>After Change</h3><pre><code class='java'>
            x = ligru_lay(x)

        x = x.transpose(0,1)
        return x<a id="change">, 0</a>


class liGRU_layer(torch.jit.ScriptModule):
    def __init__(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/c4bf280dd72034847589ca5466253e879386e735#diff-a7c3190f943cb09b3b7e0b688790f61f6e5e838546dec54468346ae1c2be7e08L1323' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 5591871</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: c4bf280dd72034847589ca5466253e879386e735</div><div id='time'> Time: 2020-05-01</div><div id='author'> Author: mirco.ravabelli@gmail.com</div><div id='file'> File Name: speechbrain/nnet/architectures.py</div><div id='m_class'> M Class Name: liGRU</div><div id='n_method'> N Class Name: liGRU</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: torch.jit.ScriptModule</div><div id='n_parent_class'> N Parent Class: torch.jit.ScriptModule</div><div id='m_file'> M File Name: speechbrain/nnet/architectures.py</div><div id='n_file'> N File Name: speechbrain/nnet/architectures.py</div><div id='m_start'> M Start Line: 1326</div><div id='m_end'> M End Line: 1346</div><div id='n_start'> N Start Line: 1286</div><div id='n_end'> N End Line: 1291</div><BR>