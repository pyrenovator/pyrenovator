<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        pin_memory=pin_memory, drop_last=True,
    )

    queryloader<a id="change"> = </a><a id="change">DataLoader(
        </a>VideoDataset(dataset.query, seq_len=args.seq_len, sample=&quotevenly&quot, transform=transform_test)<a id="change">,
        batch_size=args.test_batch, shuffle=False, num_workers=args.workers,
        pin_memory=pin_memory, drop_last=False,
    )</a>

    galleryloader = DataLoader(
        VideoDataset(dataset.gallery, seq_len=args.seq_len, sample=&quotevenly&quot, transform=transform_test),
        batch_size=args.test_batch, shuffle=False, num_workers=args.workers,
        pin_memory=pin_memory, drop_last=False,
    )

    print("Initializing model: {}".format(args.arch))
    model = models.init_model(name=args.arch, num_classes=dataset.num_train_pids, loss={&quotxent&quot})
    print("Model size: {:.3f} M".format(count_num_param(model)))

    criterion = CrossEntropyLoss(num_classes=dataset.num_train_pids, use_gpu=use_gpu, label_smooth=args.label_smooth)
    optimizer = init_optim(args.optim, model.parameters(), args.lr, args.weight_decay)
    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=args.stepsize, gamma=args.gamma)

    if args.fixbase_epoch &gt; 0:
        if hasattr(model, &quotclassifier&quot) and isinstance(model.classifier, nn.Module):
            optimizer_tmp = init_optim(args.optim, model.classifier.parameters(), args.fixbase_lr, args.weight_decay)
        else:
            print("Warn: model has no attribute &quotclassifier&quot and fixbase_epoch is reset to 0")
            args.fixbase_epoch = 0

    if args.load_weights and check_isfile(args.load_weights):
        &#47&#47 load pretrained weights but ignore layers that don&quott match in size
        checkpoint = torch.load(args.load_weights)
        pretrain_dict = checkpoint[&quotstate_dict&quot]
        model_dict = model.state_dict()
        pretrain_dict = {k: v for k, v in pretrain_dict.items() if k in model_dict and model_dict[k].size() == v.size()}
        model_dict.update(pretrain_dict)
        model.load_state_dict(model_dict)
        print("Loaded pretrained weights from &quot{}&quot".format(args.load_weights))

    if args.resume and check_isfile(args.resume):
        checkpoint = torch.load(args.resume)
        model.load_state_dict(checkpoint[&quotstate_dict&quot])
        args.start_epoch = checkpoint[&quotepoch&quot] + 1
        best_rank1 = checkpoint[&quotrank1&quot]
        print("Loaded checkpoint from &quot{}&quot".format(args.resume))
        print("- start_epoch: {}\n- rank1: {}".format(args.start_epoch, best_rank1))

    if use_gpu:
        model = nn.DataParallel(model).cuda()

    if args.evaluate:
        print("Evaluate only")
        distmat = test(model, queryloader, galleryloader, args.pool, use_gpu, return_distmat=True)
        if args.visualize_ranks:
            visualize_ranked_results(
                distmat, dataset,
                save_dir=osp.join(args.save_dir, &quotranked_results&quot),
                topk=20,
            )
        return

    start_time = time.time()
    train_time = 0
    best_epoch = args.start_epoch
    print("==&gt; Start training")

    if args.fixbase_epoch &gt; 0:
        print("Train classifier for {} epochs while keeping base network frozen".format(args.fixbase_epoch))

        for epoch in range(args.fixbase_epoch):
            start_train_time = time.time()
            train(epoch, model, criterion, optimizer_tmp, trainloader, use_gpu, freeze_bn=True)
            train_time += round(time.time() - start_train_time)

        del optimizer_tmp
        print("Now open all layers for training")

    for epoch in range(args.start_epoch, args.max_epoch):
        start_train_time = time.time()
        train(epoch, model, criterion, optimizer, trainloader, use_gpu)
        train_time += round(time.time() - start_train_time)
        
        scheduler.step()
        
        if (epoch + 1) &gt; args.start_eval and args.eval_step &gt; 0 and (epoch + 1) % args.eval_step == 0 or (epoch + 1) == args.max_epoch:
            print("==&gt; Test")
            rank1 = test(model, queryloader, galleryloader, args.pool, use_gpu)
            is_best = rank1 &gt; best_rank1
            
            if is_best:
                best_rank1 = rank1
                best_epoch<a id="change"> = </a>epoch + 1

            if use_gpu:
                state_dict = model.module.state_dict()</code></pre><h3>After Change</h3><pre><code class='java'>
        print("Evaluate only")

        for name in args.target:
            print(<a id="change">"Evaluating {} ...".format(</a>name<a id="change">)</a>)
            queryloader = testloader_dict[name][&quotquery&quot]
            galleryloader = testloader_dict[name][&quotgallery&quot]
            distmat = test(model, queryloader, galleryloader, args.pool, use_gpu, return_distmat=True)</code></pre>