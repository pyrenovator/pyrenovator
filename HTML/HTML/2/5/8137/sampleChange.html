<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        else:
            &#47&#47 Here, we&quotll use torch.distributed.
            &#47&#47 Initializes the distributed backend which will take care of sychronizing nodes/GPUs
            <a id="change">torch.distributed.init_process_group(backend="nccl")</a>
            device = torch.device("cuda", self.local_rank)
            n_gpu = 1

        if device.type == "cuda":</code></pre><h3>After Change</h3><pre><code class='java'>
        else:
            &#47&#47 Here, we&quotll use torch.distributed.
            &#47&#47 Initializes the distributed backend which will take care of sychronizing nodes/GPUs
            <a id="change">if not torch.distributed.is_initialized()</a>:
                <a id="change">torch.distributed.init_process_group(backend="nccl", timeout=self.ddp_timeout_delta)</a>
            device = torch.device("cuda", self.local_rank)
            self._n_gpu = 1

        if device.type == "cuda":</code></pre>