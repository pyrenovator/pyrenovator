<html><h3>Pattern ID :7416
</h3><img src='24601319.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            return user_embedding
        if self.mode == "item":
            return item_embedding
        <a id="change">if self.sim_func == "cosine"</a>:
            y = torch.cosine_similarity(user_embedding, item_embedding, dim=1)
        elif self.sim_func == "dot":
            y = torch.mul(user_embedding, item_embedding).sum(dim=1)
        else:
            <a id="change">raise </a>ValueError("similarity function only support %s, but got %s" % (["cosine", "dot"], self.sim_func))

        sample_weight = self.embedding(x, self.sample_weight_feature, squeeze_dim=True).squeeze(1)
</code></pre><h3>After Change</h3><pre><code class='java'>
            batch_size = user_embedding.shape[0]
            index0 = self.index0[:batch_size * (self.n_neg + 1)]
            index1 = self.index1[:batch_size * (self.n_neg + 1)]
            index0[<a id="change">np.where(index0 &gt;= batch_size</a><a id="change">)</a>] -= batch_size
            index1[np.where(index1 &gt;= batch_size)] -= batch_size

            scores = scores[index0, index1]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/datawhalechina/torch-rechub/commit/d0461152ddffad7a6bf7c7532b7b540094623e95#diff-16cab9e6b17798cf716613c6493b3a5a50aea041bdf0c65f5c89b59a4d0c686aL55' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24601319</div><div id='project'> Project Name: datawhalechina/torch-rechub</div><div id='commit'> Commit Name: d0461152ddffad7a6bf7c7532b7b540094623e95</div><div id='time'> Time: 2022-06-07</div><div id='author'> Author: icewwl@163.com</div><div id='file'> File Name: torch_rechub/models/matching/youtube_sbc.py</div><div id='m_class'> M Class Name: YoutubeSBC</div><div id='n_method'> N Class Name: YoutubeSBC</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: torch_rechub/models/matching/youtube_sbc.py</div><div id='n_file'> N File Name: torch_rechub/models/matching/youtube_sbc.py</div><div id='m_start'> M Start Line: 55</div><div id='m_end'> M End Line: 80</div><div id='n_start'> N Start Line: 60</div><div id='n_end'> N End Line: 87</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    if reduction == "mean":
        func = torch.mean
    elif <a id="change">reduction == "sum"</a>:
        func = torch.sum
    else:
        <a id="change">raise </a>ValueError("reduction should in (&quotmean&quot, &quotsum&quot)")
    if with_logits:
        y_pred = torch.sigmoid(y_pred)
    y_pred = torch.clamp(y_pred, 1e-6, 1 - 1e-6)</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 target == -1. It&quots neither a positive sample nor a negative sample.
    return torch.sum(
        <a id="change">torch.where(target == -1</a>, torch.tensor(0., device=target.device),
                    alpha * (1 - pred) ** gamma * target * torch.clamp_max(-torch.log(pred), 100) +
                    (1 - alpha) * pred ** gamma * (1 - target) * torch.clamp_max(-torch.log(1 - pred), 100)<a id="change">)</a>)


class FocalLoss(nn.Module):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jintao-huang/efficientdet_pytorch/commit/b140444fc9d402a1206ec4a8d6e0514b82003371#diff-4c422858fce93337b79d5c0e8f87c16b917c07d87986359aef07294446b24b38L9' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24601308</div><div id='project'> Project Name: jintao-huang/efficientdet_pytorch</div><div id='commit'> Commit Name: b140444fc9d402a1206ec4a8d6e0514b82003371</div><div id='time'> Time: 2021-03-31</div><div id='author'> Author: hjt_study@qq.com</div><div id='file'> File Name: models/loss.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: weighted_binary_focal_loss(4)</div><div id='n_method'> N Method Name: weighted_binary_focal_loss(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: models/loss.py</div><div id='n_file'> N File Name: models/loss.py</div><div id='m_start'> M Start Line: 9</div><div id='m_end'> M End Line: 32</div><div id='n_start'> N Start Line: 21</div><div id='n_end'> N End Line: 24</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            if min_value &gt; prune_epoch_to_now[i] &gt;= 0:
                idx = i
                min_value = prune_epoch_to_now[i]
        <a id="change">if idx &lt; 0</a>:
            <a id="change">raise </a>Exception(&quotEarly stop as there is not any layer to be pruned...&quot)
        return idx
</code></pre><h3>After Change</h3><pre><code class='java'>
        unpruned_layers = list(filter(lambda x: x[&quotepoch&quot] &gt;= epoch, self.pruning_plan))
        unpruned_layers_epoch = np.array(list(map(lambda x: x[&quotepoch&quot], unpruned_layers)))
        prune_epoch_to_now = unpruned_layers_epoch-epoch
        soonest_layer_idxes = <a id="change">np.where(prune_epoch_to_now == prune_epoch_to_now.min()</a><a id="change">)</a>[0]
        soonest_layer_names = list()
        for i in soonest_layer_idxes:
            soonest_layer_names.append(unpruned_layers[i][&quotname&quot])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lehduong/knowledge-distillation-by-replacing-cheap-conv/commit/7308659bcb1aa76bf8ee9ab2f42e88efb85d667c#diff-e8e0e0e2ed2cba04fff88771f359d8bd33954ec7141108cef021efb865c84554L203' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24601324</div><div id='project'> Project Name: lehduong/knowledge-distillation-by-replacing-cheap-conv</div><div id='commit'> Commit Name: 7308659bcb1aa76bf8ee9ab2f42e88efb85d667c</div><div id='time'> Time: 2020-02-15</div><div id='author'> Author: oopsxilitol@gmail.com</div><div id='file'> File Name: trainer/atakdp.py</div><div id='m_class'> M Class Name: ATAKDPTrainer</div><div id='n_method'> N Class Name: ATAKDPTrainer</div><div id='m_method'> M Method Name: get_index_of_pruned_layer(2)</div><div id='n_method'> N Method Name: get_index_of_pruned_layer(2)</div><div id='m_parent_class'> M Parent Class: TAKDPTrainer</div><div id='n_parent_class'> N Parent Class: TAKDPTrainer</div><div id='m_file'> M File Name: trainer/atakdp.py</div><div id='n_file'> N File Name: trainer/atakdp.py</div><div id='m_start'> M Start Line: 204</div><div id='m_end'> M End Line: 213</div><div id='n_start'> N Start Line: 216</div><div id='n_end'> N End Line: 229</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        tensor([0., 2., 0.])

    
    <a id="change">if input.dtype in {torch.bool, torch.complex64, torch.complex128}</a>:
        <a id="change">raise </a>NotImplementedError(
            "Boolean, and Complex hypervectors are not supported yet."
        )
</code></pre><h3>After Change</h3><pre><code class='java'>

    if dtype == torch.bool:
        if tie is not None:
            return <a id="change">torch.where(input == other</a>, input, tie<a id="change">)</a>
        else:
            return torch.logical_and(input, other)

    return torch.add(input, other)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hyperdimensional-computing/torchhd/commit/6d2a0fa535d893efdd92dc8ef8b1d0acdd47c55b#diff-2eec1c18711dc8b77e517b45771208f50de1693b062b658d75343e8e081d67cdL416' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24601322</div><div id='project'> Project Name: hyperdimensional-computing/torchhd</div><div id='commit'> Commit Name: 6d2a0fa535d893efdd92dc8ef8b1d0acdd47c55b</div><div id='time'> Time: 2022-06-01</div><div id='author'> Author: mikeheddes@gmail.com</div><div id='file'> File Name: torchhd/functional.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: bundle(2)</div><div id='n_method'> N Method Name: bundle(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchhd/functional.py</div><div id='n_file'> N File Name: torchhd/functional.py</div><div id='m_start'> M Start Line: 447</div><div id='m_end'> M End Line: 452</div><div id='n_start'> N Start Line: 457</div><div id='n_end'> N End Line: 471</div><BR>