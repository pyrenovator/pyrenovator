<html><h3>Pattern ID :1800
</h3><img src='8282238.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        **kwargs: Any,
    ) -&gt; Tuple[tf.Tensor, tf.Tensor]:

        batch_size = <a id="change">tf.shape(</a>q<a id="change">)</a>[0]

        q = self.wq(q, **kwargs)  &#47&#47 (batch_size, seq_len, d_model)
        k = self.wk(k, **kwargs)  &#47&#47 (batch_size, seq_len, d_model)
        v = self.wv(v, **kwargs)  &#47&#47 (batch_size, seq_len, d_model)

        q<a id="change"> = </a>self.split_heads(q, batch_size)  &#47&#47 (batch_size, num_heads, seq_len_q, depth)
        k = self.split_heads(k, batch_size)  &#47&#47 (batch_size, num_heads, seq_len_k, depth)
        v = self.split_heads(v, batch_size)  &#47&#47 (batch_size, num_heads, seq_len_v, depth)

        &#47&#47 scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)
        &#47&#47 attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)
        scaled_attention<a id="change"> = </a>scaled_dot_product_attention(q, k, v, mask)

        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  &#47&#47 (batch, seq_len_q, num_heads, depth)

        concat_attention = tf.reshape(scaled_attention,
                                      (batch_size, -1, self.d_model))  &#47&#47 (batch_size, seq_len_q, d_model)

        output<a id="change"> = </a>self.dense(concat_attention, **kwargs)  &#47&#47 (batch_size, seq_len_q, d_model)

        return output
</code></pre><h3>After Change</h3><pre><code class='java'>
        batch_size = query.shape[0]

        &#47&#47 linear projections of Q, K, V
        query<a id="change">, key, value</a> = [tf.transpose(
            tf.reshape(linear(x, **kwargs), shape=[batch_size, -1, self.num_heads, self.d_k]), perm=[0, 2, 1, 3]
        ) for linear, x in zip(self.linear_layers, (query, key, value))]
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/mindee/doctr/commit/9530f81d15395006b4844299236bdadba11c1dde#diff-e1106a3628d5365c5fe2e4fec7304ea8e40c58a5439f23d8f20513e722955178L107' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8282238</div><div id='project'> Project Name: mindee/doctr</div><div id='commit'> Commit Name: 9530f81d15395006b4844299236bdadba11c1dde</div><div id='time'> Time: 2022-07-01</div><div id='author'> Author: felixdittrich92@gmail.com</div><div id='file'> File Name: doctr/models/recognition/transformer/tensorflow.py</div><div id='m_class'> M Class Name: MultiHeadAttention</div><div id='n_method'> N Class Name: MultiHeadAttention</div><div id='m_method'> M Method Name: call(5)</div><div id='n_method'> N Method Name: call(5)</div><div id='m_parent_class'> M Parent Class: NestedObject,layers.Layer</div><div id='n_parent_class'> N Parent Class: tf.keras.layers.Layer</div><div id='m_file'> M File Name: doctr/models/recognition/transformer/tensorflow.py</div><div id='n_file'> N File Name: doctr/models/recognition/transformer/tensorflow.py</div><div id='m_start'> M Start Line: 135</div><div id='m_end'> M End Line: 156</div><div id='n_start'> N Start Line: 107</div><div id='n_end'> N End Line: 121</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    matmul_qk = tf.matmul(q, k, transpose_b=True)  &#47&#47 (..., seq_len_q, seq_len_k)
    &#47&#47 scale matmul_qk
    dk<a id="change"> = </a>tf.cast(<a id="change">tf.shape(</a>k<a id="change">)</a>[-1], q.dtype)
    scaled_attention_logits<a id="change"> = </a>matmul_qk / tf.math.sqrt(dk)
    &#47&#47 add the mask to the scaled tensor.
    if mask is not None:
        scaled_attention_logits += (tf.cast(mask, dtype=q.dtype) * -1e9)
    &#47&#47 softmax is normalized on the last axis (seq_len_k) so that the scores
    &#47&#47 add up to 1.
    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  &#47&#47 (..., seq_len_q, seq_len_k)
    output<a id="change"> = </a>tf.matmul(attention_weights, v)  &#47&#47 (..., seq_len_q, depth_v)
    return output

</code></pre><h3>After Change</h3><pre><code class='java'>
    if mask is not None:
        scores = tf.where(mask == 0, -1e9, scores)
    p_attn = tf.nn.softmax(scores, axis=-1)
    return tf.matmul(p_attn, value)<a id="change">, p_attn</a>


class PositionwiseFeedForward(layers.Layer, NestedObject):
     Position-wise Feed-Forward Network </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mindee/doctr/commit/9530f81d15395006b4844299236bdadba11c1dde#diff-e1106a3628d5365c5fe2e4fec7304ea8e40c58a5439f23d8f20513e722955178L70' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8282061</div><div id='project'> Project Name: mindee/doctr</div><div id='commit'> Commit Name: 9530f81d15395006b4844299236bdadba11c1dde</div><div id='time'> Time: 2022-07-01</div><div id='author'> Author: felixdittrich92@gmail.com</div><div id='file'> File Name: doctr/models/recognition/transformer/tensorflow.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: scaled_dot_product_attention(4)</div><div id='n_method'> N Method Name: scaled_dot_product_attention(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: doctr/models/recognition/transformer/tensorflow.py</div><div id='n_file'> N File Name: doctr/models/recognition/transformer/tensorflow.py</div><div id='m_start'> M Start Line: 88</div><div id='m_end'> M End Line: 99</div><div id='n_start'> N Start Line: 63</div><div id='n_end'> N End Line: 67</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def __call__(self, datapoint):
        image = datapoint["image"]
        if self.keep_shape:
            cropped_shape<a id="change"> = </a>tf.reduce_min(<a id="change">tf.keras.backend.shape(</a>image<a id="change">)</a>[:2])
            image<a id="change"> = </a>tf.image.random_crop(image, (cropped_shape, cropped_shape, 3))

        if self.random_crop &gt; 0 and self.random_crop &lt; 1:
            cropped_shape<a id="change"> = </a>tf.cast(tf.cast(tf.keras.backend.shape(image)[:2], tf.float32) * self.random_crop, tf.int32)
            input_image = tf.image.random_crop(image, (*cropped_shape, 3))
        else:
            input_image = tf.image.central_crop(image, self.central_crop)</code></pre><h3>After Change</h3><pre><code class='java'>
        if self.random_crop_min &gt; 0 and self.random_crop_min &lt; 1:
            &#47&#47 cropped_shape = tf.cast(tf.cast(tf.keras.backend.shape(image)[:2], tf.float32) * self.random_crop_min, tf.int32)
            &#47&#47 input_image = random_crop_with_min_fraction(image, self.random_crop_min)
            hh<a id="change">, ww</a> = random_crop_fraction(image.shape, scale=(self.random_crop_min, 1.0))
            input_image = tf.image.random_crop(image, (hh, ww, 3))
        else:
            input_image = tf.image.central_crop(image, self.central_crop)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/dcf056c5f39fd07fd07a7bb53bd0b6ccd68f8ba0#diff-4c3c6690984340f126a2283fe3773e52f7537c7f532cdba8ddda7e5af5973517L31' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8282164</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: dcf056c5f39fd07fd07a7bb53bd0b6ccd68f8ba0</div><div id='time'> Time: 2021-10-15</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/imagenet/data.py</div><div id='m_class'> M Class Name: RandomProcessImage</div><div id='n_method'> N Class Name: RandomProcessImage</div><div id='m_method'> M Method Name: __call__(2)</div><div id='n_method'> N Method Name: __call__(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/imagenet/data.py</div><div id='n_file'> N File Name: keras_cv_attention_models/imagenet/data.py</div><div id='m_start'> M Start Line: 32</div><div id='m_end'> M End Line: 39</div><div id='n_start'> N Start Line: 57</div><div id='n_end'> N End Line: 66</div><BR>