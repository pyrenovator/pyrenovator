<html><h3>Pattern ID :29413
</h3><img src='87123505.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        ds.map(lambda example: example[&quotsubgroup_label&quot]).batch(
            batch_size).as_numpy_iterator())
    subgroup_labels = np.concatenate(subgroup_labels).tolist()
    df_a = <a id="change">pd.DataFrame(</a>{&quotexample_id&quot: ids, &quotsubgroup_label&quot: subgroup_labels}<a id="change">)</a>
    bias_table = bias_table[bias_table[&quotexample_id&quot].isin(ids)]
    predictions_merge<a id="change"> = </a>pd.merge(bias_table, df_a, on=[&quotexample_id&quot])
    prob_one = (predictions_merge[&quotsubgroup_label&quot]
                == 1).sum() / len(predictions_merge)
    num_samples.append(len(predictions_merge))</code></pre><h3>After Change</h3><pre><code class='java'>
  subgroup_ids = []
  num_samples = []
  prob_representation = []
  <a id="change">for </a>idx in range(num_rounds)<a id="change">:
    </a>ds = dataloader.train_ds
    bias_table = pd.read_csv(
        os.path.join(
            os.path.join(output_dir, f&quotround_{idx}&quot), &quotbias_table.csv&quot))
    predictions_merge = merge_subgroup_labels(ds, bias_table, batch_size)
    for subgroup_id in range(num_subgroups):
      prob_i = (predictions_merge[&quotsubgroup_label&quot]
                == subgroup_id).sum() / len(predictions_merge)
      round_idx.append(idx)
      subgroup_ids.append(subgroup_id)
      num_samples.append(len(predictions_merge))
      <a id="change">prob_representation.append(</a>prob_i<a id="change">)</a>
  return pd.DataFrame({
      &quotnum_samples&quot: num_samples,
      &quotprob_representation&quot: prob_representation,
      &quotround_idx&quot: round_idx,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/google/uncertainty-baselines/commit/f5b53459d654b40668528e806a24776b53864278#diff-898a1ff69c9d70117cfb7c75da053a4e8649b705ffef48bf652f1c38fc3a5858L34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87123505</div><div id='project'> Project Name: google/uncertainty-baselines</div><div id='commit'> Commit Name: f5b53459d654b40668528e806a24776b53864278</div><div id='time'> Time: 2022-11-03</div><div id='author'> Author: no-reply@google.com</div><div id='file'> File Name: experimental/shoshin/evaluate_model_lib.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate_active_sampling(5)</div><div id='n_method'> N Method Name: evaluate_active_sampling(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: experimental/shoshin/evaluate_model_lib.py</div><div id='n_file'> N File Name: experimental/shoshin/evaluate_model_lib.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 59</div><div id='n_start'> N Start Line: 68</div><div id='n_end'> N End Line: 92</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        ds.map(lambda example: example[&quotsubgroup_label&quot]).batch(
            batch_size).as_numpy_iterator())
    subgroup_labels = np.concatenate(subgroup_labels).tolist()
    df_a = <a id="change">pd.DataFrame(</a>{&quotexample_id&quot: ids, &quotsubgroup_label&quot: subgroup_labels}<a id="change">)</a>
    bias_table = bias_table[bias_table[&quotexample_id&quot].isin(ids)]
    predictions_merge<a id="change"> = </a>pd.merge(bias_table, df_a, on=[&quotexample_id&quot])
    prob_one = (predictions_merge[&quotsubgroup_label&quot]
                == 1).sum() / len(predictions_merge)
    num_samples.append(len(predictions_merge))</code></pre><h3>After Change</h3><pre><code class='java'>
  subgroup_ids = []
  num_samples = []
  prob_representation = []
  <a id="change">for idx</a> in range(num_rounds)<a id="change">:
    </a>ds = dataloader.train_ds
    bias_table = pd.read_csv(
        os.path.join(
            os.path.join(output_dir, f&quotround_{idx}&quot), &quotbias_table.csv&quot))
    predictions_merge = merge_subgroup_labels(ds, bias_table, batch_size)
    for subgroup_id in range(num_subgroups):
      prob_i = (predictions_merge[&quotsubgroup_label&quot]
                == subgroup_id).sum() / len(predictions_merge)
      round_idx.append(idx)
      <a id="change">subgroup_ids.append(</a>subgroup_id<a id="change">)</a>
      num_samples.append(len(predictions_merge))
      prob_representation.append(prob_i)
  return pd.DataFrame({
      &quotnum_samples&quot: num_samples,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/google/uncertainty-baselines/commit/f5b53459d654b40668528e806a24776b53864278#diff-898a1ff69c9d70117cfb7c75da053a4e8649b705ffef48bf652f1c38fc3a5858L26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87123506</div><div id='project'> Project Name: google/uncertainty-baselines</div><div id='commit'> Commit Name: f5b53459d654b40668528e806a24776b53864278</div><div id='time'> Time: 2022-11-03</div><div id='author'> Author: no-reply@google.com</div><div id='file'> File Name: experimental/shoshin/evaluate_model_lib.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate_active_sampling(5)</div><div id='n_method'> N Method Name: evaluate_active_sampling(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: experimental/shoshin/evaluate_model_lib.py</div><div id='n_file'> N File Name: experimental/shoshin/evaluate_model_lib.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 59</div><div id='n_start'> N Start Line: 68</div><div id='n_end'> N End Line: 92</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 create the regressor features
    if regressor_config is not None:
        regressors = <a id="change">pd.DataFrame()</a>
        for reg in df.columns:
            if reg in regressor_config:
                regressors[reg] = df[reg]

        &#47&#47 Make sure column order is consistent
        regressors = regressors[sorted(regressors.columns.tolist())]
        regressors<a id="change"> = </a>regressors.values

        if n_lags == 0:
            regressors = np.expand_dims(regressors, axis=1)</code></pre><h3>After Change</h3><pre><code class='java'>

            if multiplicative_regressors is not None:
                multiplicative_regressor_feature_windows = []
                <a id="change">for i</a> in range(0, multiplicative_regressors.shape[1])<a id="change">:
                    &#47&#47 stride into num_forecast at dim=1 for each sample, just like we did with time
                    multiplicative_regressor_feature_windows.append(
                        </a>_stride_time_features_for_forecasts(multiplicative_regressors[:, i])<a id="change">)</a>
                multiplicative_regressors = np.dstack(multiplicative_regressor_feature_windows)
                regressors["multiplicative"] = multiplicative_regressors

        inputs["regressors"] = regressors</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ourownstory/neural_prophet/commit/71ff07c9baa8002f2611b7f6d3f8f94825e59b1b#diff-19e8b8bb76c45be0b19f9651c6c08d9e4641f5f993cdbaa581338cc45aff7516L99' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87123513</div><div id='project'> Project Name: ourownstory/neural_prophet</div><div id='commit'> Commit Name: 71ff07c9baa8002f2611b7f6d3f8f94825e59b1b</div><div id='time'> Time: 2020-09-14</div><div id='author'> Author: hansika.hewamalage@monash.edu</div><div id='file'> File Name: neuralprophet/time_dataset.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: tabularize_univariate_datetime(10)</div><div id='n_method'> N Method Name: tabularize_univariate_datetime(10)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: neuralprophet/time_dataset.py</div><div id='n_file'> N File Name: neuralprophet/time_dataset.py</div><div id='m_start'> M Start Line: 195</div><div id='m_end'> M End Line: 213</div><div id='n_start'> N Start Line: 201</div><div id='n_end'> N End Line: 267</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        except AttributeError:
            raise AttributeError(
                "Holidays in {} are not currently supported!".format(country))
    country_specific_holidays_df = <a id="change">pd.DataFrame(</a>list(country_specific_holidays.items())<a id="change">, columns=[&quotds&quot, &quotholiday&quot])</a>
    country_specific_holidays_df.reset_index(inplace=True, drop=True)
    country_specific_holidays_df[&quotds&quot]<a id="change"> = </a>pd.to_datetime(country_specific_holidays_df[&quotds&quot])
    return country_specific_holidays_df

def make_holidays_features(df, holidays_config, country_name, train_holiday_names=None):</code></pre><h3>After Change</h3><pre><code class='java'>
            raise AttributeError(
                "Holidays in {} are not currently supported!".format(country))
    country_specific_holidays_dict = defaultdict(list)
    <a id="change">for </a>date, <a id="change">holiday</a> in country_specific_holidays.items()<a id="change">:
        country_specific_holidays_dict[holiday].append(</a>pd.to_datetime(date)<a id="change">)</a>
    return country_specific_holidays_dict

def make_events_features(df, events_config=None, country_holidays_config=None):
    </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ourownstory/neural_prophet/commit/0a81a83367453cfe473d25b0cb43bbc57acd74d8#diff-19e8b8bb76c45be0b19f9651c6c08d9e4641f5f993cdbaa581338cc45aff7516L245' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87123514</div><div id='project'> Project Name: ourownstory/neural_prophet</div><div id='commit'> Commit Name: 0a81a83367453cfe473d25b0cb43bbc57acd74d8</div><div id='time'> Time: 2020-07-19</div><div id='author'> Author: hansika.hewamalage@monash.edu</div><div id='file'> File Name: neuralprophet/time_dataset.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: make_country_specific_holidays_df(2)</div><div id='n_method'> N Method Name: make_country_specific_holidays_df(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: neuralprophet/time_dataset.py</div><div id='n_file'> N File Name: neuralprophet/time_dataset.py</div><div id='m_start'> M Start Line: 265</div><div id='m_end'> M End Line: 268</div><div id='n_start'> N Start Line: 263</div><div id='n_end'> N End Line: 266</div><BR>