<html><h3>Pattern ID :351
</h3><img src='2169153.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Confidence Loss(cosine distance to classes center)
        &#47&#47 pos [num, num_priors]
        &#47&#47 conf_data [num, num_priors, feature_dim]
        conf_data<a id="change"> = </a>conf_data / <a id="change">torch.norm(</a>conf_data<a id="change">, dim=2, keepdim=True)</a>  &#47&#47 [num, num_priors, feature_dim]
        batch_conf = conf_data.view(-1, self.num_classes).mm(self.imprinted_matrix.t()) * self.scale  &#47&#47 [n_way, num_classes]

        &#47&#47 Compute max conf across batch for hard negative mining (logit-combined)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 pos [num, num_priors]
        &#47&#47 conf_data [num, num_priors, feature_dim]
        features = [conf_data.view(-1, self.num_classes)]
        <a id="change">for i</a> in range(3)<a id="change">:
            </a>new_features<a id="change"> = </a>(self.denselayer1, self.denselayer2, self.denselayer3)[i](*features)
            features.append(new_features)
        batch_conf = new_features * self.scale  &#47&#47 [n_way, num_classes]
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ze-yang/context-transformer/commit/fdad2f0570a1a57d0925ef2ff8b6a15611f910b5#diff-a2028be8bfd0e5e51d2fcfa0d360dd245f11ea1008b0e31fc76492ecac77f420L71' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2169153</div><div id='project'> Project Name: ze-yang/context-transformer</div><div id='commit'> Commit Name: fdad2f0570a1a57d0925ef2ff8b6a15611f910b5</div><div id='time'> Time: 2019-03-08</div><div id='author'> Author: 981435961@qq.com</div><div id='file'> File Name: layers/modules/multibox_loss_combined_imprinted.py</div><div id='m_class'> M Class Name: MultiBoxLoss_combined</div><div id='n_method'> N Class Name: MultiBoxLoss_combined</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: layers/modules/multibox_loss_combined_imprinted.py</div><div id='n_file'> N File Name: layers/modules/multibox_loss_combined_imprinted.py</div><div id='m_start'> M Start Line: 71</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 108</div><div id='n_end'> N End Line: 112</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 mask keypoints with cls and detection range
        &#47&#47 mask = torch.norm(point_coords[:, :2], dim=1) &lt; 57.6
        mask<a id="change"> = </a>torch.logical_and(point_cls==4, <a id="change">torch.norm(</a>point_coords[:, :2]<a id="change">, dim=1)</a> &lt; 57.6)

        xyz = point_coords[mask]
        xyz_batch_cnt = xyz.new_zeros(batch_size).int()</code></pre><h3>After Change</h3><pre><code class='java'>

        xyz = torch.cat(point_coords, dim=0)
        xyz_batch_cnt = xyz.new_zeros(batch_size).int()
        <a id="change">for bs_idx</a> in range(batch_size)<a id="change">:
            </a>xyz_batch_cnt[bs_idx]<a id="change"> = </a>len(point_coords[bs_idx])
        new_xyz = global_roi_grid_points.view(-1, 3)
        new_xyz_batch_cnt = xyz.new_zeros(batch_size).int()
        for bs_idx in range(batch_size):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/derrickxunu/opencood/commit/c7ecf237666697c93ad84b5d271c16e133ac8ccb#diff-f4cb87069fc62f998ddf748b24aaedf6327228c72d684d28aec39a9dbb96eca3L163' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2169152</div><div id='project'> Project Name: derrickxunu/opencood</div><div id='commit'> Commit Name: c7ecf237666697c93ad84b5d271c16e133ac8ccb</div><div id='time'> Time: 2022-04-01</div><div id='author'> Author: yunshuang.yuan@ikg.uni-hannover.de</div><div id='file'> File Name: opencood/models/sub_modules/roi_head.py</div><div id='m_class'> M Class Name: RoIHead</div><div id='n_method'> N Class Name: RoIHead</div><div id='m_method'> M Method Name: roi_grid_pool(2)</div><div id='n_method'> N Method Name: roi_grid_pool(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: opencood/models/sub_modules/roi_head.py</div><div id='n_file'> N File Name: opencood/models/sub_modules/roi_head.py</div><div id='m_start'> M Start Line: 164</div><div id='m_end'> M End Line: 184</div><div id='n_start'> N Start Line: 188</div><div id='n_end'> N End Line: 208</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    total_norm += param_norm**norm_type
            else:
                try:
                    param_norm<a id="change"> = </a>float(<a id="change">torch.norm(</a>p, norm_type<a id="change">, dtype=torch.float32)</a>)
                except TypeError as err:
                    param_norm = float(torch.norm(p.float(), norm_type))
                &#47&#47param_norm = p.data.float().norm(norm_type)</code></pre><h3>After Change</h3><pre><code class='java'>
    else:
        total_norm = 0.
        tensor_mp_rank = bwc_tensor_model_parallel_rank(mpu=mpu)
        <a id="change">for p</a> in parameters<a id="change">:
            &#47&#47 Pipeline parallelism may replicate parameters. Avoid multi-counting.
            </a>if hasattr(p, &quotds_pipe_replicated&quot) and p.ds_pipe_replicated:
                continue

            &#47&#47 Filter to avoid over-counting replicated tensors from tensor
            &#47&#47 model parallelism
            if (tensor_mp_rank &gt; 0) and not is_model_parallel_parameter(p):
                continue

            param_norm<a id="change"> = </a>p.data.float().norm(norm_type)
            total_norm += param_norm**norm_type

        &#47&#47 Sum across all model parallel GPUs.</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/e2fdd254edff5780d00c04111572c913ee698719#diff-6a2c29272a4f62bf59569ba619eb9a79a758a4786879cc55991b5ea739b37a49L385' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2169155</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: e2fdd254edff5780d00c04111572c913ee698719</div><div id='time'> Time: 2021-09-29</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/runtime/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: get_weight_norm(3)</div><div id='n_method'> N Method Name: get_weight_norm(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: deepspeed/runtime/utils.py</div><div id='n_file'> N File Name: deepspeed/runtime/utils.py</div><div id='m_start'> M Start Line: 403</div><div id='m_end'> M End Line: 437</div><div id='n_start'> N Start Line: 500</div><div id='n_end'> N End Line: 529</div><BR>