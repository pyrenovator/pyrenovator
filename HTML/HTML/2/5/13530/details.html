<html><h3>Pattern ID :13530
</h3><img src='45591719.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    @dtypes(*torch.testing.get_all_dtypes())
    def test_int_scalarlist(self, device, dtype):
        for N in N_values:
            for foreach_bin_op, foreach_bin_op_, torch_bin_op in <a id="change">zip(</a>self.foreach_bin_ops,
                                                                     self.foreach_bin_ops_,
                                                                     self.torch_bin_ops<a id="change">)</a>:
                tensors = self._get_test_data(device, dtype, N)
                scalars = [1 for _ in range(N)]
                expected = [torch_bin_op(t, s) for t, s in zip(tensors, scalars)]

                &#47&#47 we dont support bool and complex types on CUDA for now
                if (dtype in torch.testing.get_all_complex_dtypes() or dtype == torch.bool) and self.device_type == &quotcuda&quot:
                    with self.assertRaisesRegex(RuntimeError, "not implemented for"):
                        foreach_bin_op_(tensors, scalars)

                    with self.assertRaisesRegex(RuntimeError, "not implemented for"):
                        foreach_bin_op(tensors, scalars)
                    return

                res = foreach_bin_op(tensors, scalars)

                if dtype == torch.bool:
                    self.assertEqual(res, [torch_bin_op(t.to(torch.float32), s) for t, s in zip(tensors, scalars)])

                    with self.assertRaisesRegex(RuntimeError, "result type Float can&quott be cast to the desired output type"):
                        foreach_bin_op_(tensors, scalars)
                    return

                if dtype in torch.testing.integral_types():
                    if self.device_type == &quotcpu&quot:
                        self.assertEqual(res, [e.to(torch.float32) for e in expected])
                    else:
                        &#47&#47 TODO[type promotion]: Fix once type promotion is enabled.
                        self.assertEqual(res, [e.to(dtype) for e in expected])
                else:
                    self.assertEqual(res, expected)

                if dtype in torch.testing.integral_types() and self.device_type == &quotcpu&quot:
                    with self.assertRaisesRegex(RuntimeError, "result type Float can&quott be cast to the desired output type"):
                        foreach_bin_op_(tensors, scalars)
                    <a id="change">return</a>
                else:
                    foreach_bin_op_(tensors, scalars)
                    self.assertEqual(res, tensors)
</code></pre><h3>After Change</h3><pre><code class='java'>
                    self.assertEqual(res, expected)

                &#47&#47 test in-place
                <a id="change">if dtype in torch.testing.floating_types()</a> and self.device_type == &quotcpu&quot:
                    foreach_bin_op_(tensors, scalars)
                    return
                else:
                    if foreach_bin_op_ == torch._foreach_div_ and \
                       dtype in torch.testing.integral_types() and \
                       self.device_type == &quotcpu&quot:
                        with self.assertRaisesRegex(RuntimeError, "can&quott be cast to the desired output type"):
                            foreach_bin_op_(tensors, scalars)
                    else:
                        <a id="change">foreach_bin_op_(</a>tensors, scalars<a id="change">)</a>
                        self.assertEqual(res, tensors)

    @skipCUDAIfRocm
    @dtypes(*torch.testing.get_all_dtypes())</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/110a17a4d96d21cecf449073c9b66e1c888d2573#diff-d11ea193df3e88b33bbb36334bb325f36630ad7c2486057068c58f633a79d1c1L388' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45591719</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 110a17a4d96d21cecf449073c9b66e1c888d2573</div><div id='time'> Time: 2021-03-04</div><div id='author'> Author: iuriiz@fb.com</div><div id='file'> File Name: test/test_foreach.py</div><div id='m_class'> M Class Name: TestForeach</div><div id='n_method'> N Class Name: TestForeach</div><div id='m_method'> M Method Name: test_int_scalarlist(3)</div><div id='n_method'> N Method Name: test_int_scalarlist(3)</div><div id='m_parent_class'> M Parent Class: TestCase</div><div id='n_parent_class'> N Parent Class: TestCase</div><div id='m_file'> M File Name: test/test_foreach.py</div><div id='n_file'> N File Name: test/test_foreach.py</div><div id='m_start'> M Start Line: 404</div><div id='m_end'> M End Line: 446</div><div id='n_start'> N Start Line: 388</div><div id='n_end'> N End Line: 435</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    @dtypes(*torch.testing.get_all_dtypes())
    def test_complex_scalarlist(self, device, dtype):
        for N in N_values:
            for foreach_bin_op, foreach_bin_op_, torch_bin_op in <a id="change">zip(</a>self.foreach_bin_ops,
                                                                     self.foreach_bin_ops_,
                                                                     self.torch_bin_ops<a id="change">)</a>:
                tensors = self._get_test_data(device, dtype, N)
                scalars = [3 + 5j for _ in range(N)]
                expected = [torch_bin_op(t, s) for t, s in zip(tensors, scalars)]

                if dtype == torch.bool:
                    if foreach_bin_op == torch._foreach_sub:
                        with self.assertRaisesRegex(RuntimeError, "Subtraction, the `-` operator, with two bool"):
                            foreach_bin_op_(tensors, scalar)

                        with self.assertRaisesRegex(RuntimeError, "Subtraction, the `-` operator, with two bool"):
                            foreach_bin_op(tensors, scalar)
                    <a id="change">return</a>

                with self.assertRaisesRegex(TypeError, "argument &quotscalars&quot must be tuple of floats"):
                    res = foreach_bin_op(tensors, scalars)
</code></pre><h3>After Change</h3><pre><code class='java'>
                    res = foreach_bin_op(tensors, scalars)
                    self.assertEqual(res, expected)

                <a id="change">if dtype not in [torch.complex64, torch.complex128]</a>:
                    with self.assertRaisesRegex(RuntimeError, "can&quott be cast to the desired output type"):
                        foreach_bin_op_(tensors, scalars)
                else:
                    <a id="change">foreach_bin_op_(</a>tensors, scalars<a id="change">)</a>
                    self.assertEqual(res, tensors)

    @skipCUDAIfRocm
    @dtypes(*torch.testing.get_all_dtypes())</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/cce84b5ca5fb02bda814138bd361eea6cafc16d5#diff-d11ea193df3e88b33bbb36334bb325f36630ad7c2486057068c58f633a79d1c1L584' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45591717</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: cce84b5ca5fb02bda814138bd361eea6cafc16d5</div><div id='time'> Time: 2021-02-02</div><div id='author'> Author: iuriiz@devfair004.maas</div><div id='file'> File Name: test/test_foreach.py</div><div id='m_class'> M Class Name: TestForeach</div><div id='n_method'> N Class Name: TestForeach</div><div id='m_method'> M Method Name: test_complex_scalarlist(3)</div><div id='n_method'> N Method Name: test_complex_scalarlist(3)</div><div id='m_parent_class'> M Parent Class: TestCase</div><div id='n_parent_class'> N Parent Class: TestCase</div><div id='m_file'> M File Name: test/test_foreach.py</div><div id='n_file'> N File Name: test/test_foreach.py</div><div id='m_start'> M Start Line: 586</div><div id='m_end'> M End Line: 608</div><div id='n_start'> N Start Line: 580</div><div id='n_end'> N End Line: 613</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    @dtypes(*torch.testing.get_all_dtypes())
    def test_complex_scalarlist(self, device, dtype):
        for N in N_values:
            for foreach_bin_op, foreach_bin_op_, torch_bin_op in <a id="change">zip(</a>self.foreach_bin_ops,
                                                                     self.foreach_bin_ops_,
                                                                     self.torch_bin_ops<a id="change">)</a>:
                tensors = self._get_test_data(device, dtype, N)
                scalars = [3 + 5j for _ in range(N)]
                expected = [torch_bin_op(t, s) for t, s in zip(tensors, scalars)]

                if dtype == torch.bool:
                    if foreach_bin_op == torch._foreach_sub:
                        with self.assertRaisesRegex(RuntimeError, "Subtraction, the `-` operator, with two bool"):
                            foreach_bin_op_(tensors, scalar)

                        with self.assertRaisesRegex(RuntimeError, "Subtraction, the `-` operator, with two bool"):
                            foreach_bin_op(tensors, scalar)
                    <a id="change">return</a>

                with self.assertRaisesRegex(TypeError, "argument &quotscalars&quot must be tuple of floats"):
                    res = foreach_bin_op(tensors, scalars)
</code></pre><h3>After Change</h3><pre><code class='java'>
                    res = foreach_bin_op(tensors, scalars)
                    self.assertEqual(res, expected)

                <a id="change">if dtype not in [torch.complex64, torch.complex128]</a>:
                    with self.assertRaisesRegex(RuntimeError, "can&quott be cast to the desired output type"):
                        foreach_bin_op_(tensors, scalars)
                else:
                    <a id="change">foreach_bin_op_(</a>tensors, scalars<a id="change">)</a>
                    self.assertEqual(res, tensors)

    @skipCUDAIfRocm
    @dtypes(*torch.testing.get_all_dtypes())</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/110a17a4d96d21cecf449073c9b66e1c888d2573#diff-d11ea193df3e88b33bbb36334bb325f36630ad7c2486057068c58f633a79d1c1L591' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45591724</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 110a17a4d96d21cecf449073c9b66e1c888d2573</div><div id='time'> Time: 2021-03-04</div><div id='author'> Author: iuriiz@fb.com</div><div id='file'> File Name: test/test_foreach.py</div><div id='m_class'> M Class Name: TestForeach</div><div id='n_method'> N Class Name: TestForeach</div><div id='m_method'> M Method Name: test_complex_scalarlist(3)</div><div id='n_method'> N Method Name: test_complex_scalarlist(3)</div><div id='m_parent_class'> M Parent Class: TestCase</div><div id='n_parent_class'> N Parent Class: TestCase</div><div id='m_file'> M File Name: test/test_foreach.py</div><div id='n_file'> N File Name: test/test_foreach.py</div><div id='m_start'> M Start Line: 593</div><div id='m_end'> M End Line: 615</div><div id='n_start'> N Start Line: 587</div><div id='n_end'> N End Line: 620</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    @dtypes(*torch.testing.get_all_dtypes())
    def test_int_scalarlist(self, device, dtype):
        for N in N_values:
            for foreach_bin_op, foreach_bin_op_, torch_bin_op in <a id="change">zip(</a>self.foreach_bin_ops,
                                                                     self.foreach_bin_ops_,
                                                                     self.torch_bin_ops<a id="change">)</a>:
                tensors = self._get_test_data(device, dtype, N)
                scalars = [1 for _ in range(N)]
                expected = [torch_bin_op(t, s) for t, s in zip(tensors, scalars)]

                &#47&#47 we dont support bool and complex types on CUDA for now
                if (dtype in torch.testing.get_all_complex_dtypes() or dtype == torch.bool) and self.device_type == &quotcuda&quot:
                    with self.assertRaisesRegex(RuntimeError, "not implemented for"):
                        foreach_bin_op_(tensors, scalars)

                    with self.assertRaisesRegex(RuntimeError, "not implemented for"):
                        foreach_bin_op(tensors, scalars)
                    return

                res = foreach_bin_op(tensors, scalars)

                if dtype == torch.bool:
                    self.assertEqual(res, [torch_bin_op(t.to(torch.float32), s) for t, s in zip(tensors, scalars)])

                    with self.assertRaisesRegex(RuntimeError, "result type Float can&quott be cast to the desired output type"):
                        foreach_bin_op_(tensors, scalars)
                    return

                if dtype in torch.testing.integral_types():
                    if self.device_type == &quotcpu&quot:
                        self.assertEqual(res, [e.to(torch.float32) for e in expected])
                    else:
                        &#47&#47 TODO[type promotion]: Fix once type promotion is enabled.
                        self.assertEqual(res, [e.to(dtype) for e in expected])
                else:
                    self.assertEqual(res, expected)

                if dtype in torch.testing.integral_types() and self.device_type == &quotcpu&quot:
                    with self.assertRaisesRegex(RuntimeError, "result type Float can&quott be cast to the desired output type"):
                        foreach_bin_op_(tensors, scalars)
                    <a id="change">return</a>
                else:
                    foreach_bin_op_(tensors, scalars)
                    self.assertEqual(res, tensors)
</code></pre><h3>After Change</h3><pre><code class='java'>
                    self.assertEqual(res, expected)

                &#47&#47 test in-place
                <a id="change">if </a>dtype in torch.testing.floating_types() and <a id="change">self.device_type == &quotcpu&quot</a>:
                    foreach_bin_op_(tensors, scalars)
                    return
                else:
                    if foreach_bin_op_ == torch._foreach_div_ and \
                       dtype in torch.testing.integral_types() and \
                       self.device_type == &quotcpu&quot:
                        with self.assertRaisesRegex(RuntimeError, "can&quott be cast to the desired output type"):
                            foreach_bin_op_(tensors, scalars)
                    else:
                        <a id="change">foreach_bin_op_(</a>tensors, scalars<a id="change">)</a>
                        self.assertEqual(res, tensors)

    @skipCUDAIfRocm
    @dtypes(*torch.testing.get_all_dtypes())</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/cce84b5ca5fb02bda814138bd361eea6cafc16d5#diff-d11ea193df3e88b33bbb36334bb325f36630ad7c2486057068c58f633a79d1c1L395' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 45591721</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: cce84b5ca5fb02bda814138bd361eea6cafc16d5</div><div id='time'> Time: 2021-02-02</div><div id='author'> Author: iuriiz@devfair004.maas</div><div id='file'> File Name: test/test_foreach.py</div><div id='m_class'> M Class Name: TestForeach</div><div id='n_method'> N Class Name: TestForeach</div><div id='m_method'> M Method Name: test_int_scalarlist(3)</div><div id='n_method'> N Method Name: test_int_scalarlist(3)</div><div id='m_parent_class'> M Parent Class: TestCase</div><div id='n_parent_class'> N Parent Class: TestCase</div><div id='m_file'> M File Name: test/test_foreach.py</div><div id='n_file'> N File Name: test/test_foreach.py</div><div id='m_start'> M Start Line: 397</div><div id='m_end'> M End Line: 439</div><div id='n_start'> N Start Line: 381</div><div id='n_end'> N End Line: 428</div><BR>