<html><h3>Pattern ID :34393
</h3><img src='98652179.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        self.padding_token_idx = self.tokenizer.pad_token_id
        self.loss = nn.CrossEntropyLoss(ignore_index=self.padding_token_idx, reduction=&quotnone&quot)
        <a id="change">if </a>config[&quottask_type&quot] == "summarization":
            self.t5_task_text = "summarize: "
        elif config[&quottask_type&quot] == "translation":
            self.t5_task_text = "translate German to English: "
        else:
            <a id="change">raise </a><a id="change">NotImplementedError("Only summarization and translation are supported."</a><a id="change">)</a>

    def generate(self, batch_data, eval_data):
        source_text = batch_data[&quotsource_text&quot]
        input_ids, attn_masks = self.tokenize_text(source_text)</code></pre><h3>After Change</h3><pre><code class='java'>
        self.tokenizer = T5Tokenizer.from_pretrained(self.pretrained_model_path)
        self.configuration = T5Config.from_pretrained(self.pretrained_model_path)
        self.model = T5ForConditionalGeneration.from_pretrained(self.pretrained_model_path, config=self.configuration)
        self.task_prefix = config[&quottask_prefix&quot]<a id="change"> if </a>config[&quottask_prefix&quot]<a id="change"> else </a>&quot&quot

    def generate(self, batch_data, eval_data):
        source_text = batch_data[&quotsource_text&quot]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/62b0e37edc873093b5a92c978ed23d0e304f7de2#diff-eb2c898e89b79cddd937005956fa13163d763721255b69110887d4c3c6936205L26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 98652179</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 62b0e37edc873093b5a92c978ed23d0e304f7de2</div><div id='time'> Time: 2022-01-18</div><div id='author'> Author: wxDai2001@gmail.com</div><div id='file'> File Name: textbox/model/Seq2Seq/t5.py</div><div id='m_class'> M Class Name: T5</div><div id='n_method'> N Class Name: T5</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: Seq2SeqGenerator</div><div id='n_parent_class'> N Parent Class: Seq2SeqGenerator</div><div id='m_file'> M File Name: textbox/model/Seq2Seq/t5.py</div><div id='n_file'> N File Name: textbox/model/Seq2Seq/t5.py</div><div id='m_start'> M Start Line: 26</div><div id='m_end'> M End Line: 40</div><div id='n_start'> N Start Line: 35</div><div id='n_end'> N End Line: 35</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if dtype is None:
        dtype = torch.get_default_dtype()

    <a id="change">if </a>dtype in {torch.complex64, torch.complex128}:
        <a id="change">raise </a><a id="change">NotImplementedError("Complex hypervectors are not supported yet."</a><a id="change">)</a>

    if dtype == torch.uint8:
        raise ValueError("Unsigned integer hypervectors are not supported.")
</code></pre><h3>After Change</h3><pre><code class='java'>
        raise ValueError("Unsigned integer hypervectors are not supported.")

    if dtype in {torch.complex64, torch.complex128}:
        dtype = torch.float<a id="change"> if </a>dtype == torch.complex64<a id="change"> else </a>torch.double

        angle = torch.empty(
            num_embeddings, embedding_dim, dtype=dtype, device=device</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hyperdimensional-computing/torchhd/commit/1f7e9dbf92a4a1be0d4285b6ccd7231afa85c2a3#diff-2eec1c18711dc8b77e517b45771208f50de1693b062b658d75343e8e081d67cdL91' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 98652178</div><div id='project'> Project Name: hyperdimensional-computing/torchhd</div><div id='commit'> Commit Name: 1f7e9dbf92a4a1be0d4285b6ccd7231afa85c2a3</div><div id='time'> Time: 2022-06-07</div><div id='author'> Author: mikeheddes@gmail.com</div><div id='file'> File Name: torchhd/functional.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: random_hv(0)</div><div id='n_method'> N Method Name: random_hv(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchhd/functional.py</div><div id='n_file'> N File Name: torchhd/functional.py</div><div id='m_start'> M Start Line: 132</div><div id='m_end'> M End Line: 135</div><div id='n_start'> N Start Line: 178</div><div id='n_end'> N End Line: 193</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        if config[&quottask_type&quot] == "summarization":
            self.task_text = "TL;DR:"
        elif <a id="change"></a>config[&quottask_type&quot] == "translation":
            self.task_text = "story:"
        elif config[&quottask_type&quot] == "multi_dialog":
            self.task_text = "question:"
        else:
            <a id="change">raise </a><a id="change">NotImplementedError("Only summarization and translation are supported."</a><a id="change">)</a>

        self.loss = nn.CrossEntropyLoss(ignore_index=self.padding_token_idx, reduction=&quotnone&quot)

    def generate(self, batch_data, eval_data):</code></pre><h3>After Change</h3><pre><code class='java'>
        self.configuration = GPT2Config.from_pretrained(self.pretrained_model_path, pad_token_id=self.tokenizer.pad_token_id)
        self.model = GPT2LMHeadModel.from_pretrained(self.pretrained_model_path, config=self.configuration)
        self.model.resize_token_embeddings(len(self.tokenizer))
        self.task_prefix = config[&quottask_prefix&quot]<a id="change"> if </a>config[&quottask_prefix&quot]<a id="change"> else </a>&quot&quot

    def generate(self, batch_data, eval_data):
        source_text = batch_data[&quotsource_text&quot]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/81da6bb852a3637c8053ccf5f9b236dc4283fd86#diff-7bfe3fdc6bdc45164cae119523b0a961ecca9fd88248a0f4eef88731095a4fe8L27' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 98652181</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 81da6bb852a3637c8053ccf5f9b236dc4283fd86</div><div id='time'> Time: 2022-01-20</div><div id='author'> Author: wxDai2001@gmail.com</div><div id='file'> File Name: textbox/model/Seq2Seq/gpt2seq.py</div><div id='m_class'> M Class Name: GPT2Seq</div><div id='n_method'> N Class Name: GPT2Seq</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: Seq2SeqGenerator</div><div id='n_parent_class'> N Parent Class: Seq2SeqGenerator</div><div id='m_file'> M File Name: textbox/model/Seq2Seq/gpt2seq.py</div><div id='n_file'> N File Name: textbox/model/Seq2Seq/gpt2seq.py</div><div id='m_start'> M Start Line: 37</div><div id='m_end'> M End Line: 46</div><div id='n_start'> N Start Line: 31</div><div id='n_end'> N End Line: 31</div><BR>