<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        KW = self.w_k(K)
        KW = torch.einsum("nk,bnc-&gt;bkc", E, KW)
        QW = self.w_q(Q)
        QW<a id="change"> = </a><a id="change">torch.einsum("bnc,bkc-&gt;bnk"</a>, QW, KW<a id="change">)</a>
        P_bar = QW/torch.sqrt(torch.tensor(self.dim, dtype=torch.float32))
        P_bar = P_bar.softmax(dim=-1)
        P_bar = self.dropout(P_bar)
</code></pre><h3>After Change</h3><pre><code class='java'>
        KW = torch.matmul(E, KW)
        KW = torch.transpose(KW, 1, 2)
        QW = self.w_q(Q)
        QW<a id="change"> = </a><a id="change">torch.matmul(</a>QW, KW<a id="change">)</a>

        &#47&#47 TODO: Possibly change the dtype?
        P_bar = QW/torch.sqrt(torch.tensor(self.dim, dtype=torch.float32))
        P_bar = P_bar.softmax(dim=-1)</code></pre>