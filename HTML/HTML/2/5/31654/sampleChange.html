<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            if args.no_prefetcher:
                target = target.cuda()
                input = input.cuda()
                <a id="change">if args.fp16</a>:
                    input<a id="change"> = </a>input.half()

            &#47&#47 compute output
            output = model(input)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 warmup, reduce variability of first batch time, especially for comparing torchscript vs non
        input = torch.randn((args.batch_size,) + data_config[&quotinput_size&quot]).cuda()
        if args.channels_last:
            input<a id="change"> = </a><a id="change">input.contiguous(memory_format=torch.channels_last)</a>
        model(input)
        end = time.time()
        for batch_idx, (input, target) in enumerate(loader):
            if args.no_prefetcher:</code></pre>