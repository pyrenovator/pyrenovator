<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        is_list = isinstance(input_text, list)

        encoded_input = <a id="change">tokenizer.encode(</a>input_text<a id="change">, return_tensors=&quotpt&quot)</a>
        encoded_input = encoded_input.to(device)

        output = model.generate(input_ids=encoded_input, num_return_sequences=1)

        if is_list:
            return [tokenizer.decode(tokens, skip_special_tokens=True) for tokens in output]
        else:
            <a id="change">return tokenizer</a><a id="change">.decode(</a>output[0]<a id="change">, skip_special_tokens=True)</a>
    else:
        raise ValueError(&quotNon-local inference is not currently implemented&quot)

</code></pre><h3>After Change</h3><pre><code class='java'>
                model_name = DEFAULT_MODEL
            else:
                &#47&#47 Get from predefined list or try to find remotely
                model_name = <a id="change">MODELS.get(model_name) or model_name</a>
                model = AutoModelForPreTraining.from_pretrained(model_name)
            model.to(device)
        
        &#47&#47 Initialise tokenizer, allow switching if new one is provided.</code></pre>