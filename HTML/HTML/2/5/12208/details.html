<html><h3>Pattern ID :12208
</h3><img src='41342247.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        segment_ids = segment_ids.to(args.device)

        with torch.no_grad():
            <a id="change">if </a>args.mlm:
                outputs = model(inputs, masked_lm_labels=labels, position_ids=position_ids, token_type_ids=segment_ids)
            else:
                if args.model_type == &quotbart&quot:
                    decoder_input_ids = labels[:, :-1].contiguous()
                    decoder_input_ids[decoder_input_ids == args.mlm_ignore_index] = tokenizer.pad_token_id
                    lm_labels<a id="change"> = </a><a id="change">labels[:, 1:].clone()</a>
                    outputs = model(inputs, labels=labels, lm_labels=lm_labels, decoder_input_ids=decoder_input_ids, position_ids=position_ids, token_type_ids=segment_ids)
                else:
                    outputs = model(inputs, labels=labels, position_ids=position_ids, token_type_ids=segment_ids)
            lm_loss = outputs[0]</code></pre><h3>After Change</h3><pre><code class='java'>
            inputs, labels = mask_tokens(inputs, labels, tokenizer, args.mlm_probability, args.mlm_ignore_index)
        inputs = inputs.to(args.device)
        labels = labels.to(args.device)
        attention_mask<a id="change"> = </a><a id="change">attention_mask.to(</a>args.device<a id="change">)</a>
        position_ids = position_ids.to(args.device)
        segment_ids = segment_ids.to(args.device)

        with torch.no_grad():</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/b84a6548a69fd9f62652eed1c74fd4b1fdb8b65b#diff-90e760d3065758cd3fed35d36be801cfed8d2418d888df295dbecdc933432ad7L318' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41342247</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: b84a6548a69fd9f62652eed1c74fd4b1fdb8b65b</div><div id='time'> Time: 2020-11-15</div><div id='author'> Author: mehrad@stanford.edu</div><div id='file'> File Name: genienlp/paraphrase/run_lm_finetuning.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate(5)</div><div id='n_method'> N Method Name: evaluate(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: genienlp/paraphrase/run_lm_finetuning.py</div><div id='n_file'> N File Name: genienlp/paraphrase/run_lm_finetuning.py</div><div id='m_start'> M Start Line: 318</div><div id='m_end'> M End Line: 344</div><div id='n_start'> N Start Line: 330</div><div id='n_end'> N End Line: 369</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 group.setdefault(&quotparams_old&quot, group[&quotparams&quot])

            for p in group[&quotparams&quot]:
                <a id="change">if </a>p.grad is None:
                    continue

                p_t = p
                param_state = self.state[p]
                if &quotparam_old&quot not in param_state:
                    param_state[&quotparam_old&quot]<a id="change"> = </a><a id="change">torch.clone(</a>p<a id="change">)</a>.detach()
                else:
                    p_t = param_state[&quotparam_old&quot]
</code></pre><h3>After Change</h3><pre><code class='java'>
    def step(self, global_params, device):
        for group in self.param_groups:
            for p, g in zip(group[&quotparams&quot], global_params):
                g<a id="change"> = </a><a id="change">g.to(</a>device<a id="change">)</a>
                d_p = p.grad.data + group[&quotmu&quot] * (p.data - g.data)
                p.data.add_(d_p, alpha=-group[&quotlr&quot])
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tsingz0/pfl-non-iid/commit/330ce2d6169fd4a54cec28895418bd38c206b6a4#diff-a99c19163c19c03eede69bdda22f1a2d923b8eb7d0f4b0463d797d66d5fc8e87L89' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41342252</div><div id='project'> Project Name: tsingz0/pfl-non-iid</div><div id='commit'> Commit Name: 330ce2d6169fd4a54cec28895418bd38c206b6a4</div><div id='time'> Time: 2021-03-24</div><div id='author'> Author: 2719584131@qq.com</div><div id='file'> File Name: system/flcore/optimizers/fedoptimizer.py</div><div id='m_class'> M Class Name: PerturbedGradientDescent</div><div id='n_method'> N Class Name: PerturbedGradientDescent</div><div id='m_method'> M Method Name: step(3)</div><div id='n_method'> N Method Name: step(1)</div><div id='m_parent_class'> M Parent Class: Optimizer</div><div id='n_parent_class'> N Parent Class: Optimizer</div><div id='m_file'> M File Name: system/flcore/optimizers/fedoptimizer.py</div><div id='n_file'> N File Name: system/flcore/optimizers/fedoptimizer.py</div><div id='m_start'> M Start Line: 89</div><div id='m_end'> M End Line: 108</div><div id='n_start'> N Start Line: 116</div><div id='n_end'> N End Line: 121</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        compressed_st[&quotstate_dict&quot][f&quot{name}&quot][&quotu&quot] = (u[:, :i]@torch.diag(s)[:i, :i]).clone()
        compressed_st[&quotstate_dict&quot][f&quot{name}&quot][&quotv&quot] = vt[:i].clone()

    <a id="change">if </a>embed is not None:
        compressed_st[&quotstate_dict&quot][&quotembed&quot]<a id="change"> = </a><a id="change">embed.clone()</a>

    name = delta_ckpt.replace(&quotdelta&quot, &quotcompressed_delta&quot)
    torch.save(compressed_st, f&quot{name}&quot)
</code></pre><h3>After Change</h3><pre><code class='java'>
        from diffusers import StableDiffusionPipeline
        compressed_key = &quotunet&quot
        compressed_st = {compressed_key: {}}
        pretrained_st<a id="change"> = </a><a id="change">StableDiffusionPipeline.from_pretrained(ckpt, torch_dtype=torch.float16).to(</a>"cuda"<a id="change">)</a>
        pretrained_st = pretrained_st.unet.state_dict()
        if &quotmodifier_token&quot in st:
            compressed_st[&quotmodifier_token&quot] = st[&quotmodifier_token&quot]
        st = st[&quotunet&quot]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/adobe-research/custom-diffusion/commit/5cd1e9c869b793d88573533a6a2adccd10aadcd0#diff-0f4293c247a4f4e8eab25c82da6ce7037c91175297d9dae021e3b167f28c1121L9' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 41342251</div><div id='project'> Project Name: adobe-research/custom-diffusion</div><div id='commit'> Commit Name: 5cd1e9c869b793d88573533a6a2adccd10aadcd0</div><div id='time'> Time: 2023-01-05</div><div id='author'> Author: nupurkumari@Nupurs-MacBook-Pro.local</div><div id='file'> File Name: src/compress.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: compress(5)</div><div id='n_method'> N Method Name: compress(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/compress.py</div><div id='n_file'> N File Name: src/compress.py</div><div id='m_start'> M Start Line: 10</div><div id='m_end'> M End Line: 48</div><div id='n_start'> N Start Line: 8</div><div id='n_end'> N End Line: 48</div><BR>