<html><h3>Pattern ID :6914
</h3><img src='23267875.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            coarse_samples, coarse_lengths = validSampler(
                valid_pixels, valid_coords, train_cam_tf, sample_ray_num, coarse_sample_pnum, 200, 200, train_focal, near_t, far_t
            )
            coarse_cams = <a id="change">coarse_samples[:, -1, :-3]</a>.contiguous()
            gt_rgb = coarse_samples[:, -1, -3:].contiguous()
            coarse_samples = coarse_samples[:, :-1, :].contiguous()
            coarse_rgbo = coarse_net.forward(coarse_samples)</code></pre><h3>After Change</h3><pre><code class='java'>
            print("Evaluation in epoch: %4d / %4d\t, test counter: %d test loss: %.4f\taverage time: %.4lf\tavg render time:%lf\tremaining eval time:%s"%(
                    ep, epochs, test_cnt, test_loss.item() / 2, eval_timer.get_mean_time(), render_timer.get_mean_time(), eval_timer.remaining_time(epochs - ep - 1)
            ))
            images_to_save<a id="change"> = [</a>coarse_result, train_result<a id="change"></a>]
            <a id="change">images_to_save.extend(</a>test_results<a id="change">)</a>
            save_image(images_to_save, "./output/result_%03d.png"%(test_cnt), nrow = 3)
            &#47&#47 ======== Saving checkpoints ========
            torch.save({
                &quotmodel&quot: coarse_net.state_dict()},</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/enigmatisms/nerf/commit/5bf2199afe3d4eff27be923b0e6d62a3118af597#diff-ed183d67207df065a11e1289f19d34cc2abbc5448dea952683cfe9728c342b95L66' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23267875</div><div id='project'> Project Name: enigmatisms/nerf</div><div id='commit'> Commit Name: 5bf2199afe3d4eff27be923b0e6d62a3118af597</div><div id='time'> Time: 2022-04-13</div><div id='author'> Author: 984041003@qq.com</div><div id='file'> File Name: train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train.py</div><div id='n_file'> N File Name: train.py</div><div id='m_start'> M Start Line: 66</div><div id='m_end'> M End Line: 188</div><div id='n_start'> N Start Line: 73</div><div id='n_end'> N End Line: 196</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

                    &#47&#47 1x1 conv for the entropy parameters prediction network, so
                    &#47&#47 we only keep the elements in the "center"
                    ctx_p = <a id="change">ctx_params[i:i + 1, :, padding:padding + 1, padding:padding + 1]</a>
                    p = params[i:i + 1, :, h:h + 1, w:w + 1]
                    gaussian_params = self.entropy_parameters(torch.cat((p, ctx_p), dim=1))
                    scales_hat, means_hat = gaussian_params.chunk(2, 1)
</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 Warning, this is slow...
            &#47&#47 TODO: profile the calls to the bindings...
            symbols_list = []
            indexes_list<a id="change"> = []</a>
            for h in range(y_height):
                for w in range(y_width):
                    y_crop = y_hat[i:i + 1, :, h:h + kernel_size,
                                   w:w + kernel_size]
                    ctx_p = F.conv2d(y_crop,
                                     self.context_prediction.weight,
                                     bias=self.context_prediction.bias)

                    &#47&#47 1x1 conv for the entropy parameters prediction network, so
                    &#47&#47 we only keep the elements in the "center"
                    p = params[i:i + 1, :, h:h + 1, w:w + 1]
                    gaussian_params = self.entropy_parameters(
                        torch.cat((p, ctx_p), dim=1))
                    scales_hat, means_hat = gaussian_params.chunk(2, 1)

                    indexes = self.gaussian_conditional.build_indexes(scales_hat)
                    y_q = torch.round(y_crop - means_hat)
                    y_hat[i, :, h + padding, w + padding] = (y_q + means_hat)[i, :, padding,padding]

                    symbols_list.extend(y_q[i, :, padding, padding].int().tolist())
                    <a id="change">indexes_list.extend(</a>indexes[i, :].squeeze().int().tolist()<a id="change">)</a>

            encoder.encode_with_indexes(symbols_list, indexes_list, cdf,
                                        cdf_lengths, offsets)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/interdigitalinc/compressai/commit/b590b3bac89b6b39b8cbdca2a770ddb9fe0b2ccf#diff-1afd903e71d04b39f80bdd2ae05ccb72b7ff55edcb0145fccfcc08f92f6cc97dL489' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23267874</div><div id='project'> Project Name: interdigitalinc/compressai</div><div id='commit'> Commit Name: b590b3bac89b6b39b8cbdca2a770ddb9fe0b2ccf</div><div id='time'> Time: 2020-07-08</div><div id='author'> Author: Jean.Begaint@interdigital.com</div><div id='file'> File Name: compressai/models/priors.py</div><div id='m_class'> M Class Name: JointAutoregressiveHierarchicalPriors</div><div id='n_method'> N Class Name: JointAutoregressiveHierarchicalPriors</div><div id='m_method'> M Method Name: compress(2)</div><div id='n_method'> N Method Name: compress(2)</div><div id='m_parent_class'> M Parent Class: CompressionModel</div><div id='n_parent_class'> N Parent Class: CompressionModel</div><div id='m_file'> M File Name: compressai/models/priors.py</div><div id='n_file'> N File Name: compressai/models/priors.py</div><div id='m_start'> M Start Line: 500</div><div id='m_end'> M End Line: 539</div><div id='n_start'> N Start Line: 509</div><div id='n_end'> N End Line: 544</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            Log first 3 and a random subset to tensorboard
            if LOG_FIGURES and i == 0:
                ix = [0, 1, 2, 3, 4, 5]
                plot_io_frame_model(x_in, <a id="change">output[:, 0]</a>, target, em_tar, ix,
                                    fig_str=&quottestset/fig_&quot,
                                    comet_log=experiment,
                                    board_log=logger,</code></pre><h3>After Change</h3><pre><code class='java'>

    inputs = []
    outputs = []
    tars<a id="change"> = []</a>

    Eval mode.
    with torch.no_grad():
        end = time.time()
        for i, (x_in, target, em_tar) in enumerate(val_loader):

            x_in = x_in.to(hy_par.device)
            if type(target) is torch.Tensor:
                target = target.to(hy_par.device)
            elif type(target) in (tuple, list):
                target = (target[0].to(hy_par.device), target[1].to(hy_par.device))
            else:
                raise TypeError("Not supported type to push to cuda.")

            &#47&#47 compute output
            output = model(x_in)
            loss = criterion(output, target)

            &#47&#47 record loss
            losses.update(loss.item())

            &#47&#47 measure elapsed time
            batch_time.update(time.time() - end)
            end = time.time()

            inputs.append(x_in.cpu())
            outputs.append(output.detach().cpu())
            <a id="change">tars.extend(</a>em_tar<a id="change">)</a>

    print("Test: Time: {batch_time.avg:.3f} \t""Loss: {loss.avg:.4f}".format(batch_time=batch_time, loss=losses))

    Forward output through post-processor for eval.</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/turagalab/decode/commit/889789c97eb30b2a757b6ab589c7472589f22f2a#diff-9d0572aba2fe317f29a36ea3db7de768a7c5d025accf738e260660614d587dccL171' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23267879</div><div id='project'> Project Name: turagalab/decode</div><div id='commit'> Commit Name: 889789c97eb30b2a757b6ab589c7472589f22f2a</div><div id='time'> Time: 2019-05-14</div><div id='author'> Author: gitdev@LRM.photo</div><div id='file'> File Name: deepsmlm/neuralfitter/train_test.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test(8)</div><div id='n_method'> N Method Name: test(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: deepsmlm/neuralfitter/train_test.py</div><div id='n_file'> N File Name: deepsmlm/neuralfitter/train_test.py</div><div id='m_start'> M Start Line: 178</div><div id='m_end'> M End Line: 227</div><div id='n_start'> N Start Line: 176</div><div id='n_end'> N End Line: 217</div><BR>