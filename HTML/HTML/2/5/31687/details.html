<html><h3>Pattern ID :31687
</h3><img src='92394689.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

            noise                   = torch.randn((batch_size, 100))
            if cuda:
                noise<a id="change">               = </a><a id="change">noise.cuda(</a>local_rank<a id="change">)</a>
            G_result                = G_model_train(noise)
            D_result                = D_model_train(G_result)
            D_fake_loss             = BCE_loss(D_result, y_fake)</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47----------------------&#47&#47
            scaler.scale(D_real_loss).backward()

            <a id="change">with </a><a id="change">autocast():
                </a>G_result<a id="change">                = </a>G_model_train(noise_1)
                D_result                = D_model_train(G_result)
                D_fake_loss             = BCE_loss(D_result, y_fake)
            &#47&#47----------------------&#47&#47</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/bubbliiiing/dcgan-pytorch/commit/cdd6a27591afafb4f346acbea338b6e49c4333a8#diff-1159d7fa34eff8cbe9fa807908c5121873390f54788a592aa0a1605ee5d1e0a4L21' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 92394689</div><div id='project'> Project Name: bubbliiiing/dcgan-pytorch</div><div id='commit'> Commit Name: cdd6a27591afafb4f346acbea338b6e49c4333a8</div><div id='time'> Time: 2022-07-07</div><div id='author'> Author: 3323290568@qq.com</div><div id='file'> File Name: utils/utils_fit.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: fit_one_epoch(19)</div><div id='n_method'> N Method Name: fit_one_epoch(19)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: utils/utils_fit.py</div><div id='n_file'> N File Name: utils/utils_fit.py</div><div id='m_start'> M Start Line: 21</div><div id='m_end'> M End Line: 119</div><div id='n_start'> N Start Line: 25</div><div id='n_end'> N End Line: 114</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if partition_gradients:
            if self.overlap_comm:
                self.local_overflow = self._has_inf_or_nan(self.gpu_sum)
                self.gpu_sum<a id="change"> = </a><a id="change">torch.zeros(1, dtype=torch.float).cuda()</a>

            overflow = self.local_overflow if self.offload_optimizer else self.has_overflow_partitioned_grads_serial(
            )
            &#47&#47overflow = self.has_overflow_partitioned_grads_serial()</code></pre><h3>After Change</h3><pre><code class='java'>
    @instrument_w_nvtx
    def has_overflow(self, partition_gradients=True):
        if partition_gradients:
            <a id="change">with </a><a id="change">torch.cuda.stream(self.__reduce_and_partition_stream):
                </a>self.local_overflow<a id="change"> = </a>bool(self.__inf_or_nan_tracker.item())
                self.__inf_or_nan_tracker.zero_()

            overflow = self.local_overflow</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/4912e0ad7efcaf97389ae944259aa0e9f331038a#diff-1ad5daa1b31aa5573616024068d646f0c38e88d4d3a71d3d0e4bc352ea232178L2859' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 92394688</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: 4912e0ad7efcaf97389ae944259aa0e9f331038a</div><div id='time'> Time: 2022-01-20</div><div id='author'> Author: 31414860+jfc4050@users.noreply.github.com</div><div id='file'> File Name: deepspeed/runtime/zero/stage3.py</div><div id='m_class'> M Class Name: DeepSpeedZeroOptimizer_Stage3</div><div id='n_method'> N Class Name: DeepSpeedZeroOptimizer_Stage3</div><div id='m_method'> M Method Name: has_overflow(2)</div><div id='n_method'> N Method Name: has_overflow(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: deepspeed/runtime/zero/stage3.py</div><div id='n_file'> N File Name: deepspeed/runtime/zero/stage3.py</div><div id='m_start'> M Start Line: 2861</div><div id='m_end'> M End Line: 2866</div><div id='n_start'> N Start Line: 2728</div><div id='n_end'> N End Line: 2732</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            queries_per_block = min(L, 1024//k) 
            threads = k * queries_per_block
            blocks = ((L*k)//threads) + C + 1
            query_map<a id="change"> = </a><a id="change">torch.ones((N, H, blocks), dtype=torch.int32).cuda()</a> * L 
            blocks_map = torch.ones((N, H, blocks), dtype=torch.int32).cuda() * -1 
            _, sorted_group_indices = torch.sort(groups, descending=True, dim=-1)
</code></pre><h3>After Change</h3><pre><code class='java'>

        else:
            &#47&#47 Allocate bookkeeping parameters to facilitate the kernel
            <a id="change">with </a><a id="change">torch.no_grad():
                </a>Q_pb = 16
                block_counts = (counts + Q_pb - 1) // Q_pb
                block_counts = block_counts.int()
                block_counts_cumsum = block_counts.view(-1).cumsum(-1).view(N, H, C).int()
                indx_maps = torch.ones(
                    (block_counts.sum(), 4),
                    device=Q.device,
                    dtype=torch.int32
                )
                counts_cumsum<a id="change"> = </a>counts.cumsum(-1).int()
                total_blocks = block_counts.sum().item()

            &#47&#47 Actually perform the dot product</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/idiap/fast-transformers/commit/ac1fd6316f59b56faa3b4e9236810d4e97ed5b15#diff-e91bf79b7e2f1026ed509f7acfa914077ef9851d0eb373421f7aa40468c45da4L162' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 92394691</div><div id='project'> Project Name: idiap/fast-transformers</div><div id='commit'> Commit Name: ac1fd6316f59b56faa3b4e9236810d4e97ed5b15</div><div id='time'> Time: 2020-11-25</div><div id='author'> Author: avyas@idiap.ch</div><div id='file'> File Name: fast_transformers/sparse_product/__init__.py</div><div id='m_class'> M Class Name: ClusteredSparseDotProduct</div><div id='n_method'> N Class Name: ClusteredSparseDotProduct</div><div id='m_method'> M Method Name: forward(7)</div><div id='n_method'> N Method Name: forward(7)</div><div id='m_parent_class'> M Parent Class: torch.autograd.Function</div><div id='n_parent_class'> N Parent Class: torch.autograd.Function</div><div id='m_file'> M File Name: fast_transformers/sparse_product/__init__.py</div><div id='n_file'> N File Name: fast_transformers/sparse_product/__init__.py</div><div id='m_start'> M Start Line: 185</div><div id='m_end'> M End Line: 201</div><div id='n_start'> N Start Line: 164</div><div id='n_end'> N End Line: 208</div><BR>