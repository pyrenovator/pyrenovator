<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            for epoch in range(self.epochs):
                loss = 0.0
                pred_list = []
                acc_list = <a id="change">[]</a>
                tmp = float(self.t0 * np.power(self.t1 / self.t0, epoch / self.epochs))
                self.elayers.train()
                optimizer.zero_grad()
                tic = time.perf_counter()
                for gid in tqdm.tqdm(dataset_indices):
                    data = dataset[gid]
                    data.to(self.device)
                    prob, _ = self.explain(data.x, data.edge_index, embed=emb_dict[gid], tmp=tmp, training=True)
                    loss_tmp = self.__loss__(prob, ori_pred_dict[gid])
                    loss_tmp.backward()
                    loss += loss_tmp.item()
                    pred_label = prob.argmax(-1).item()
                    pred_list.append(pred_label)
                    acc_list.append(pred_label == data.y)

                optimizer.step()
                duration += time.perf_counter() - tic
                accs<a id="change"> = </a><a id="change">torch.stack(</a>acc_list<a id="change">, dim=0)</a>
                acc = np.array(accs).mean()
                print(f&quotEpoch: {epoch} | Loss: {loss} | Acc : {acc}&quot)
        else:
            with torch.no_grad():</code></pre><h3>After Change</h3><pre><code class='java'>

                optimizer.step()
                duration += time.perf_counter() - tic
                <a id="change">print(f&quotEpoch: {epoch} | Loss: {loss/len(x_dict)}&quot</a><a id="change">)</a>
            print(f"training time is {duration:.5}s")

    def forward(self,
                x: Tensor,</code></pre>