<html><h3>Pattern ID :6692
</h3><img src='23008735.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            for epoch in range(self.epochs):
                loss = 0.0
                pred_list = []
                acc_list = <a id="change">[]</a>
                tmp = float(self.t0 * np.power(self.t1 / self.t0, epoch / self.epochs))
                self.elayers.train()
                optimizer.zero_grad()
                tic = time.perf_counter()
                for gid in tqdm.tqdm(dataset_indices):
                    data = dataset[gid]
                    data.to(self.device)
                    prob, _ = self.explain(data.x, data.edge_index, embed=emb_dict[gid], tmp=tmp, training=True)
                    loss_tmp = self.__loss__(prob, ori_pred_dict[gid])
                    loss_tmp.backward()
                    loss += loss_tmp.item()
                    pred_label = prob.argmax(-1).item()
                    pred_list.append(pred_label)
                    acc_list.append(pred_label == data.y)

                optimizer.step()
                duration += time.perf_counter() - tic
                accs<a id="change"> = </a><a id="change">torch.stack(</a>acc_list<a id="change">, dim=0)</a>
                acc = np.array(accs).mean()
                print(f&quotEpoch: {epoch} | Loss: {loss} | Acc : {acc}&quot)
        else:
            with torch.no_grad():</code></pre><h3>After Change</h3><pre><code class='java'>

                optimizer.step()
                duration += time.perf_counter() - tic
                <a id="change">print(f&quotEpoch: {epoch} | Loss: {loss/len(x_dict)}&quot</a><a id="change">)</a>
            print(f"training time is {duration:.5}s")

    def forward(self,
                x: Tensor,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/divelab/dig/commit/7bc976472260abbe590320af2f499da668c5e0cb#diff-568d7f47b1c5fd2fa00b587179854781743fd9ce06a1713f6ce1d3ee14c5743fL390' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23008735</div><div id='project'> Project Name: divelab/dig</div><div id='commit'> Commit Name: 7bc976472260abbe590320af2f499da668c5e0cb</div><div id='time'> Time: 2021-04-28</div><div id='author'> Author: 1161283769@qq.com</div><div id='file'> File Name: dig/xgraph/method/pgexplainer.py</div><div id='m_class'> M Class Name: PGExplainer</div><div id='n_method'> N Class Name: PGExplainer</div><div id='m_method'> M Method Name: train_explanation_network(2)</div><div id='n_method'> N Method Name: train_explanation_network(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dig/xgraph/method/pgexplainer.py</div><div id='n_file'> N File Name: dig/xgraph/method/pgexplainer.py</div><div id='m_start'> M Start Line: 390</div><div id='m_end'> M End Line: 455</div><div id='n_start'> N Start Line: 581</div><div id='n_end'> N End Line: 622</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
		reservoir.forward = self.eprop._decorate_hidden_forward(reservoir.forward, reservoir.name)
		output_layer.forward = self.eprop._decorate_forward(output_layer.forward, output_layer.name)
		for _ in progress_bar:
			x_pred = <a id="change">[]</a>
			x_pred.append(self.true_time_series[:, 0, :].clone())
			forward_tensor = self.true_time_series[:, 0, :].clone().to(reservoir.device)
			hh = None
			for t in range(1, self.true_time_series.shape[-2]):
				forward_tensor, hh = unpack_out_hh(reservoir(forward_tensor, hh, t=t-1))
				forward_tensor, _ = unpack_out_hh(output_layer(forward_tensor, None, t=t-1))
				x_pred.append(forward_tensor)
				&#47&#47 eligibility_traces = dy_dw_local(y=forward_tensor, params=self.params)
				&#47&#47 self.eprop.eligibility_traces = eligibility_traces
				&#47&#47 batch_loss = self.eprop.apply_criterion(forward_tensor, self.true_time_series[:, t].to(forward_tensor.device))
				&#47&#47 learning_signals = self.compute_learning_signals(loss_at_t)
				&#47&#47 errors = self.eprop.compute_errors(forward_tensor, self.true_time_series[:, t])
				&#47&#47 learning_signals = self.eprop.compute_learning_signals(errors)
				&#47&#47 self.eprop.update_grads(errors, batch_loss)
				forward_tensor.detach_()
				hh = recursive_detach(hh)
				&#47&#47 if t % self.update_each == 0:
				&#47&#47 	self.eprop._make_optim_step()
			self.eprop._make_optim_step()
			x_pred<a id="change"> = </a><a id="change">torch.stack(</a>[t.cpu() for t in x_pred]<a id="change">, dim=1)</a>
			pvar = PVarianceLoss()(x_pred, self.true_time_series.to(x_pred.device))
			mse = torch.nn.MSELoss()(x_pred, self.true_time_series.to(x_pred.device))
			progress_bar.set_postfix({"pvar": to_numpy(pvar).item(), "MSE": to_numpy(mse).item()})
			pvars.append(to_numpy(pvar).item())</code></pre><h3>After Change</h3><pre><code class='java'>
			val_x_pred = self.model.get_prediction_trace(inputs)
			pvar = PVarianceLoss()(val_x_pred, self.raw_time_series.to(val_x_pred.device))
			val_pvars.append(to_numpy(pvar).item())
		<a id="change">print(f"Validation PVariance: {np.mean(val_pvars):.3f}"</a><a id="change">)</a>
		return x_pred, self.raw_time_series

	def compute_learning_signals(self, error: torch.Tensor):
		learning_signals = []</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neurotorch/neurotorch/commit/da8d4065502c761ccf6e28e47dd189e3b5488140#diff-bfbe6bfd7f09fee9a898ae4ce6ce338f6bfc05e7db28469ba6540dfae09a766dL109' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23008732</div><div id='project'> Project Name: neurotorch/neurotorch</div><div id='commit'> Commit Name: da8d4065502c761ccf6e28e47dd189e3b5488140</div><div id='time'> Time: 2023-01-31</div><div id='author'> Author: 50332514+JeremieGince@users.noreply.github.com</div><div id='file'> File Name: src/neurotorch/learning_algorithms/debug_e_prop_v5.py</div><div id='m_class'> M Class Name: SimplifiedEpropFinal</div><div id='n_method'> N Class Name: SimplifiedEpropFinal</div><div id='m_method'> M Method Name: train(4)</div><div id='n_method'> N Method Name: train(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/neurotorch/learning_algorithms/debug_e_prop_v5.py</div><div id='n_file'> N File Name: src/neurotorch/learning_algorithms/debug_e_prop_v5.py</div><div id='m_start'> M Start Line: 120</div><div id='m_end'> M End Line: 153</div><div id='n_start'> N Start Line: 115</div><div id='n_end'> N End Line: 144</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                client_val_dataset  = dataset_test.create_tf_dataset_for_client(client_id)
                train_data = []
                train_labels = []
                val_data = <a id="change">[]</a>
                val_labels = []
                for train_sample in client_train_dataset:
                    train_data.append(torch.Tensor(train_sample[&quotpixels&quot].numpy()))
                    train_labels.append(train_sample[&quotlabel&quot].numpy())
                train_data = torch.stack(train_data,0)
                train_labels = torch.Tensor(train_labels)
                for val_sample in client_val_dataset:
                    val_data.append(torch.Tensor(val_sample[&quotpixels&quot].numpy()))
                    val_labels.append(val_sample[&quotlabel&quot].numpy())
                val_data<a id="change"> = </a><a id="change">torch.stack(</a>val_data,0<a id="change">)</a>
                val_labels = torch.Tensor(val_labels)

                Client_EMNIST_Dataset_train = (train_data,train_labels)
                Client_EMNIST_Dataset_val  = (val_data,val_labels)</code></pre><h3>After Change</h3><pre><code class='java'>
            os.makedirs(os.path.join(self.root, &quottest&quot), exist_ok=True)

        dataset_train, dataset_test = load_emnist(self.root, only_digits=self.only_digits)
        <a id="change">print(&quotStart generating datasets...&quot</a><a id="change">)</a>
        if self.split in [&quottrain&quot,&quotval&quot]:
            rand_client_ids = np.random.permutation(len(dataset_train.client_ids))
            for i in tqdm(rand_client_ids):
                train_path = os.path.join(self.root,&quottrain&quot, &quotEMNIST_client_{}.pt&quot.format(i))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mloptpsu/fedtorch/commit/7577f1e2efbce9c4cc0bbd149ec88313f35f1cf6#diff-7d35ef7f49dee959b108b05ee0fb472257e4989397559d007607feb3d77afa01L81' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23008727</div><div id='project'> Project Name: mloptpsu/fedtorch</div><div id='commit'> Commit Name: 7577f1e2efbce9c4cc0bbd149ec88313f35f1cf6</div><div id='time'> Time: 2021-01-23</div><div id='author'> Author: mohamadmahdi.kamani@gmail.com</div><div id='file'> File Name: fedtorch/components/datasets/loader/federated_datasets.py</div><div id='m_class'> M Class Name: EMNIST</div><div id='n_method'> N Class Name: EMNIST</div><div id='m_method'> M Method Name: download(1)</div><div id='n_method'> N Method Name: download(1)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: fedtorch/components/datasets/loader/federated_datasets.py</div><div id='n_file'> N File Name: fedtorch/components/datasets/loader/federated_datasets.py</div><div id='m_start'> M Start Line: 92</div><div id='m_end'> M End Line: 143</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 137</div><BR>