<html><h3>Pattern ID :41993
</h3><img src='117727760.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        with record_function("(zhg) get cpu chunk indices"):
            &#47&#47 &#47&#47input_id / moving chunk size
            &#47&#47 move chunk_id_set to CUDA
            cpu_chunk_id_list = <a id="change">[]</a>
            <a id="change">for </a>chunk_id in chunk_id_set<a id="change">:
                </a>if not self._chunk_in_cuda(chunk_id):
                    <a id="change">cpu_chunk_id_list.append(</a>chunk_id<a id="change">)</a>

        self.num_hits_history.append(len(chunk_id_set) - len(cpu_chunk_id_list))
        self.num_miss_history.append(len(cpu_chunk_id_list))
        self.num_write_back_history.append(0)</code></pre><h3>After Change</h3><pre><code class='java'>
        with record_function("(zhg) cache update"):
            self._prepare_chunks_on_cuda(cpu_chunk_id_list)

        self.evict_backlist<a id="change"> = </a><a id="change">torch.tensor(</a>[]<a id="change">, device=chunk_id_set.device, dtype=chunk_id_set.dtype)</a>
        &#47&#47 new ids chunk_offset + offset_in_chunk
        with record_function("(zhg) embed idx -&gt; cache chunk id"):
            mapped_ids = self._id_to_cached_cuda_id(ids).view(ids.shape)
        return mapped_ids</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/hpcaitech/cachedembedding/commit/5b9995175361069d8eaa507674a59791f722761a#diff-aab5f7e7e049810d29a74e3eab12af668892a81357998cc464ab0f8cd2272767L155' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117727760</div><div id='project'> Project Name: hpcaitech/cachedembedding</div><div id='commit'> Commit Name: 5b9995175361069d8eaa507674a59791f722761a</div><div id='time'> Time: 2022-07-26</div><div id='author'> Author: 34452939+zxgx@users.noreply.github.com</div><div id='file'> File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='m_class'> M Class Name: ChunkParamMgr</div><div id='n_method'> N Class Name: ChunkParamMgr</div><div id='m_method'> M Method Name: prepare_ids(2)</div><div id='n_method'> N Method Name: prepare_ids(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='n_file'> N File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='m_start'> M Start Line: 167</div><div id='m_end'> M End Line: 195</div><div id='n_start'> N Start Line: 155</div><div id='n_end'> N End Line: 178</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def compute_gradient(self, state_lst, action_lst, reward_lst, next_state_lst, done_lst):
        final_state = torch.tensor(next_state_lst[-1], dtype=torch.float)
        R = 0.0 if done_lst[-1] else self.v(final_state).item()
        td_target_lst = <a id="change">[]</a>
        <a id="change">for </a>reward in reward_lst[::-1]<a id="change">:
            </a>R = self.args[&quotgamma&quot] * R + reward
            <a id="change">td_target_lst.append(</a>[R]<a id="change">)</a>
        td_target_lst.reverse()

        state_batch, action_batch, td_target = torch.tensor(state_lst, dtype=torch.float), torch.tensor(action_lst), \
            torch.tensor(td_target_lst)</code></pre><h3>After Change</h3><pre><code class='java'>
        action = torch.tensor(action_lst)
        reward = torch.tensor(reward_lst, dtype = torch.float).unsqueeze(-1)
        next_state = torch.tensor(next_state_lst, dtype = torch.float)
        done<a id="change"> = </a><a id="change">torch.tensor(</a>done_lst<a id="change">, dtype = torch.float)</a>.unsqueeze(-1)
        
        td = reward + (1 - done) * self.args[&quotgamma&quot] * self.v(next_state)
        if self.args[&quotadvantage&quot] == True :</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/seolhokim/distributedrl-pytorch-ray/commit/24173b188cfefde68f9b724d2c24ac5c6cbd722a#diff-dc1e556a58e7b1560cb88492da108ef995e9159cd1c55f2334dafddf9c1642fdL34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117727757</div><div id='project'> Project Name: seolhokim/distributedrl-pytorch-ray</div><div id='commit'> Commit Name: 24173b188cfefde68f9b724d2c24ac5c6cbd722a</div><div id='time'> Time: 2021-06-05</div><div id='author'> Author: kilmya1@naver.com</div><div id='file'> File Name: agents/algorithms/actor_critic.py</div><div id='m_class'> M Class Name: ActorCritic</div><div id='n_method'> N Class Name: ActorCritic</div><div id='m_method'> M Method Name: compute_gradient(6)</div><div id='n_method'> N Method Name: compute_gradient(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: agents/algorithms/actor_critic.py</div><div id='n_file'> N File Name: agents/algorithms/actor_critic.py</div><div id='m_start'> M Start Line: 35</div><div id='m_end'> M End Line: 47</div><div id='n_start'> N Start Line: 31</div><div id='n_end'> N End Line: 39</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        wav_lens = [mel_len * self.hop_len for mel_len in mel_lens]
        max_mel_len = max(mel_lens)

        mel_embs = <a id="change">[]</a>

        <a id="change">for </a>mel in mels<a id="change">:
            </a>mel = mel.unsqueeze(0)
            mel_emb, _ = self.mel_rnn(mel)
            mel_emb = mel_emb.squeeze(0)
            <a id="change">mel_embs.append(</a>mel_emb<a id="change">)</a>

        mel_embs = pad_sequence(
            mel_embs, batch_first=True, padding_value=float(self.quant_dim // 2)
        )</code></pre><h3>After Change</h3><pre><code class='java'>

        pad_mels = pad_sequence(mels, batch_first=True)
        pack_mels = pack_padded_sequence(
            pad_mels, <a id="change">torch.tensor(</a>mel_lens<a id="change">)</a>, batch_first=True, enforce_sorted=False
        )
        pack_mel_embs<a id="change">, _ = </a>self.mel_rnn(pack_mels)
        mel_embs, _ = pad_packed_sequence(pack_mel_embs, batch_first=True)

        &#47&#47 mel_embs: (batch, emb_dim, max_mel_len)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yistlin/universal-vocoder/commit/decd133f652564aab54717a4e8df0316421e35c0#diff-0b303f21197833211aecf17dfcb415a3d2172623cfededbfc805892f128cd01eL63' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117727758</div><div id='project'> Project Name: yistlin/universal-vocoder</div><div id='commit'> Commit Name: decd133f652564aab54717a4e8df0316421e35c0</div><div id='time'> Time: 2020-10-07</div><div id='author'> Author: yishen992@gmail.com</div><div id='file'> File Name: models/universal_vocoder.py</div><div id='m_class'> M Class Name: UniversalVocoder</div><div id='n_method'> N Class Name: UniversalVocoder</div><div id='m_method'> M Method Name: generate(2)</div><div id='n_method'> N Method Name: generate(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/universal_vocoder.py</div><div id='n_file'> N File Name: models/universal_vocoder.py</div><div id='m_start'> M Start Line: 78</div><div id='m_end'> M End Line: 108</div><div id='n_start'> N Start Line: 77</div><div id='n_end'> N End Line: 106</div><BR>