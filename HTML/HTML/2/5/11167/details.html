<html><h3>Pattern ID :11167
</h3><img src='38222663.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            batch, targets, lengths
        )  &#47&#47&#47&#47 sorts the batch wrt the length of sequences

        pred<a id="change"> = </a>model(
            torch.autograd.Variable(batch).to(device), lengths.cpu().numpy()
        )  &#47&#47&#47&#47 perform forward pass
        pred = torch.squeeze(pred)
        loss = criterion(
            pred.to(device), torch.autograd.Variable(targets.float()).to(device)
        )  &#47&#47&#47&#47 compute loss
        pred_val<a id="change"> = </a>pred &gt;= 0.5  &#47&#47&#47&#47 get predictions
        y_true += list(targets.int())
        y_pred<a id="change"> += </a><a id="change">list(</a>pred_val.data.int().detach().cpu().numpy()<a id="change">)</a>
        total_loss += loss

    acc = accuracy_score(y_true, y_pred)  &#47&#47&#47&#47 computing accuracy using sklearn&quots function
</code></pre><h3>After Change</h3><pre><code class='java'>
        _,
    ) in data_loader["val_loader"]:
        &#47&#47&#47&#47 perform forward pass
        pred = <a id="change">model(
            </a>sent1.to(device),
            sent2.to(device),
            sents1_len.to(device),
            sents2_len.to(device)<a id="change">,
        )</a>
        &#47&#47&#47&#47 compute loss
        loss = criterion(
            pred.to(device), torch.autograd.Variable(targets.float()).to(device)
        )</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/shahrukhx01/siamese-nn-semantic-text-similarity/commit/f3d054dd14ef532c408b1306c3341115777ac22f#diff-be822a1f9a4a693be118629ef529ccaecde36733327973c865b9d50a0c7bb839L78' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38222663</div><div id='project'> Project Name: shahrukhx01/siamese-nn-semantic-text-similarity</div><div id='commit'> Commit Name: f3d054dd14ef532c408b1306c3341115777ac22f</div><div id='time'> Time: 2021-12-30</div><div id='author'> Author: sk28671@gmail.com</div><div id='file'> File Name: siamese_sts/trainer/train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate_dev_set(5)</div><div id='n_method'> N Method Name: evaluate_dev_set(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: siamese_sts/trainer/train.py</div><div id='n_file'> N File Name: siamese_sts/trainer/train.py</div><div id='m_start'> M Start Line: 78</div><div id='m_end'> M End Line: 95</div><div id='n_start'> N Start Line: 91</div><div id='n_end'> N End Line: 116</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

            model.zero_grad()

            pred<a id="change"> = </a>model(
                torch.autograd.Variable(batch).to(device), lengths.cpu().numpy()
            )  &#47&#47&#47&#47 perform forward pass
            pred<a id="change"> = </a>torch.squeeze(pred)
            loss = criterion(
                pred.to(device), torch.autograd.Variable(targets.float()).to(device)
            )  &#47&#47&#47&#47 compute loss

            loss.backward()  &#47&#47&#47&#47 perform backward pass
            optimizer.step()  &#47&#47&#47&#47 update weights

            pred_val = pred &gt;= 0.5  &#47&#47&#47&#47 get predictions
            y_true += list(targets.int().numpy())  &#47&#47&#47&#47 accumulate targets from batch
            y_pred<a id="change"> += </a><a id="change">list(
                </a>pred_val.data.int().detach().cpu().numpy()<a id="change">
            )</a>  &#47&#47&#47&#47 accumulate preds from batch
            total_loss += loss  &#47&#47&#47&#47 accumulate train loss

        acc = accuracy_score(</code></pre><h3>After Change</h3><pre><code class='java'>

            model.zero_grad()
            &#47&#47&#47&#47 perform forward pass
            pred = <a id="change">model(
                </a>sent1.to(device),
                sent2.to(device),
                sents1_len.to(device),
                sents2_len.to(device)<a id="change">,
            )</a>

            &#47&#47&#47&#47 compute loss
            loss = criterion(
                pred.to(device), torch.autograd.Variable(targets.float()).to(device)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/shahrukhx01/siamese-nn-semantic-text-similarity/commit/f3d054dd14ef532c408b1306c3341115777ac22f#diff-be822a1f9a4a693be118629ef529ccaecde36733327973c865b9d50a0c7bb839L15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38222599</div><div id='project'> Project Name: shahrukhx01/siamese-nn-semantic-text-similarity</div><div id='commit'> Commit Name: f3d054dd14ef532c408b1306c3341115777ac22f</div><div id='time'> Time: 2021-12-30</div><div id='author'> Author: sk28671@gmail.com</div><div id='file'> File Name: siamese_sts/trainer/train.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train_model(6)</div><div id='n_method'> N Method Name: train_model(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: siamese_sts/trainer/train.py</div><div id='n_file'> N File Name: siamese_sts/trainer/train.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 47</div><div id='n_start'> N Start Line: 16</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 This block of code does a bit of juggling to handle any case where there are multiple outputs in train mode
    &#47&#47 So we trace once and look at the graph, and get the indices of the nodes that lead into the original fx output
    &#47&#47 node. Then we use those indices to select from train_nodes returned by torchvision get_graph_node_names
    tracer<a id="change"> = </a>NodePathTracer(leaf_modules=list(_leaf_modules), autowrap_functions=list(_autowrap_functions))
    graph<a id="change"> = </a>tracer.trace(model)
    graph_nodes = <a id="change">list(</a>reversed(graph.nodes)<a id="change">)</a>
    output_node_names = [n.name for n in graph_nodes[0]._input_nodes.keys()]
    graph_node_names<a id="change"> = </a>[n.name for n in graph_nodes]
    output_node_indices = [-graph_node_names.index(node_name) for node_name in output_node_names]
    train_nodes, eval_nodes = get_graph_node_names(
        model, tracer_kwargs={&quotleaf_modules&quot: list(_leaf_modules), &quotautowrap_functions&quot: list(_autowrap_functions)})</code></pre><h3>After Change</h3><pre><code class='java'>
    model.train()

    model = _create_fx_model(model, train=True)
    outputs = tuple(<a id="change">model(</a>torch.randn((batch_size, *input_size))<a id="change">)</a>.values())
    if isinstance(outputs, tuple):
        outputs = torch.cat(outputs)
    outputs.mean().backward()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/feng-lab/pytorch-image-models/commit/9b3519545d6bf901047dccd24832793c95919cd4#diff-0adb667cd397bd56edce10eec11e1b10821740a10d72bd148b09645fc9108968L360' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38222595</div><div id='project'> Project Name: feng-lab/pytorch-image-models</div><div id='commit'> Commit Name: 9b3519545d6bf901047dccd24832793c95919cd4</div><div id='time'> Time: 2021-11-19</div><div id='author'> Author: rwightman@gmail.com</div><div id='file'> File Name: tests/test_models.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_model_backward_fx(2)</div><div id='n_method'> N Method Name: test_model_backward_fx(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/test_models.py</div><div id='n_file'> N File Name: tests/test_models.py</div><div id='m_start'> M Start Line: 365</div><div id='m_end'> M End Line: 396</div><div id='n_start'> N Start Line: 378</div><div id='n_end'> N End Line: 386</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 This block of code does a bit of juggling to handle any case where there are multiple outputs in train mode
    &#47&#47 So we trace once and look at the graph, and get the indices of the nodes that lead into the original fx output
    &#47&#47 node. Then we use those indices to select from train_nodes returned by torchvision get_graph_node_names
    tracer<a id="change"> = </a>NodePathTracer(leaf_modules=list(_leaf_modules), autowrap_functions=list(_autowrap_functions))
    graph<a id="change"> = </a>tracer.trace(model)
    graph_nodes = <a id="change">list(</a>reversed(graph.nodes)<a id="change">)</a>
    output_node_names = [n.name for n in graph_nodes[0]._input_nodes.keys()]
    graph_node_names = [n.name for n in graph_nodes]
    output_node_indices = [-graph_node_names.index(node_name) for node_name in output_node_names]
    train_nodes, eval_nodes = get_graph_node_names(
        model, tracer_kwargs={&quotleaf_modules&quot: list(_leaf_modules), &quotautowrap_functions&quot: list(_autowrap_functions)})
    eval_return_nodes<a id="change"> = </a>[eval_nodes[ix] for ix in output_node_indices]

    fx_model = create_feature_extractor(
        model, train_return_nodes=[train_nodes[-1]], eval_return_nodes=eval_return_nodes,</code></pre><h3>After Change</h3><pre><code class='java'>
        outputs = torch.cat(outputs)

    model = _create_fx_model(model)
    fx_outputs = tuple(<a id="change">model(</a>inputs<a id="change">)</a>.values())
    if isinstance(fx_outputs, tuple):
        fx_outputs = torch.cat(fx_outputs)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/feng-lab/pytorch-image-models/commit/9b3519545d6bf901047dccd24832793c95919cd4#diff-0adb667cd397bd56edce10eec11e1b10821740a10d72bd148b09645fc9108968L312' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 38222605</div><div id='project'> Project Name: feng-lab/pytorch-image-models</div><div id='commit'> Commit Name: 9b3519545d6bf901047dccd24832793c95919cd4</div><div id='time'> Time: 2021-11-19</div><div id='author'> Author: rwightman@gmail.com</div><div id='file'> File Name: tests/test_models.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_model_forward_fx(2)</div><div id='n_method'> N Method Name: test_model_forward_fx(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/test_models.py</div><div id='n_file'> N File Name: tests/test_models.py</div><div id='m_start'> M Start Line: 320</div><div id='m_end'> M End Line: 348</div><div id='n_start'> N Start Line: 348</div><div id='n_end'> N End Line: 360</div><BR>