<html><h3>Pattern ID :23312
</h3><img src='73471520.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        source_text = batch_data[&quotsource_text&quot]
        generate_corpus = []
        for src in source_text:
            input_ids = <a id="change">self.tokenize_text(src, self.task_text, self.source_max_length).unsqueeze(0</a><a id="change">)</a>

            sample_outputs = self.model.generate(
                input_ids,
                num_beams=4,
                max_length=input_ids.size(1) + self.target_max_length,
                early_stopping=True,
            )
            generated_text = self.tokenizer.decode(sample_outputs[0][input_ids.size(1) + 1:], skip_special_tokens=True)
            generated_text<a id="change"> = </a>generated_text.split()
            generate_corpus.append(generated_text)
        return generate_corpus
</code></pre><h3>After Change</h3><pre><code class='java'>
        task_prefix_len = len(task_prefix_tokens)
        for src in source_text:
            input_tokens = self.tokenizer.tokenize(src)[:self.source_max_length - task_prefix_len] + task_prefix_tokens
            input_ids = <a id="change">torch.tensor(</a>self.tokenizer.convert_tokens_to_ids(input_tokens)<a id="change">, dtype=torch.long)</a>.unsqueeze(0)
            sample_outputs = self.model.generate(
                input_ids,
                num_beams=4,
                max_length=len(input_tokens) + self.target_max_length,
                early_stopping=True,
            )
            generated_text = self.tokenizer.decode(sample_outputs[0][len(input_tokens) + 1:], skip_special_tokens=True,
                                                   clean_up_tokenization_spaces=False)
            generated_text<a id="change"> = </a>generated_text.lower().split()
            generate_corpus.append(generated_text)

        return generate_corpus</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/81da6bb852a3637c8053ccf5f9b236dc4283fd86#diff-7bfe3fdc6bdc45164cae119523b0a961ecca9fd88248a0f4eef88731095a4fe8L37' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73471520</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 81da6bb852a3637c8053ccf5f9b236dc4283fd86</div><div id='time'> Time: 2022-01-20</div><div id='author'> Author: wxDai2001@gmail.com</div><div id='file'> File Name: textbox/model/Seq2Seq/gpt2seq.py</div><div id='m_class'> M Class Name: GPT2Seq</div><div id='n_method'> N Class Name: GPT2Seq</div><div id='m_method'> M Method Name: generate(3)</div><div id='n_method'> N Method Name: generate(3)</div><div id='m_parent_class'> M Parent Class: Seq2SeqGenerator</div><div id='n_parent_class'> N Parent Class: Seq2SeqGenerator</div><div id='m_file'> M File Name: textbox/model/Seq2Seq/gpt2seq.py</div><div id='n_file'> N File Name: textbox/model/Seq2Seq/gpt2seq.py</div><div id='m_start'> M Start Line: 51</div><div id='m_end'> M End Line: 61</div><div id='n_start'> N Start Line: 37</div><div id='n_end'> N End Line: 50</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        mel_embs = []

        for mel in mels:
            mel<a id="change"> = </a><a id="change">mel.unsqueeze(0</a><a id="change">)</a>
            mel_emb, _ = self.mel_rnn(mel)
            mel_emb = mel_emb.squeeze(0)
            mel_embs.append(mel_emb)
</code></pre><h3>After Change</h3><pre><code class='java'>

        pad_mels = pad_sequence(mels, batch_first=True)
        pack_mels = pack_padded_sequence(
            pad_mels, <a id="change">torch.tensor(</a>mel_lens<a id="change">)</a>, batch_first=True, enforce_sorted=False
        )
        pack_mel_embs<a id="change">, _ = </a>self.mel_rnn(pack_mels)
        mel_embs, _ = pad_packed_sequence(pack_mel_embs, batch_first=True)

        &#47&#47 mel_embs: (batch, emb_dim, max_mel_len)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yistlin/universal-vocoder/commit/decd133f652564aab54717a4e8df0316421e35c0#diff-0b303f21197833211aecf17dfcb415a3d2172623cfededbfc805892f128cd01eL63' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73471511</div><div id='project'> Project Name: yistlin/universal-vocoder</div><div id='commit'> Commit Name: decd133f652564aab54717a4e8df0316421e35c0</div><div id='time'> Time: 2020-10-07</div><div id='author'> Author: yishen992@gmail.com</div><div id='file'> File Name: models/universal_vocoder.py</div><div id='m_class'> M Class Name: UniversalVocoder</div><div id='n_method'> N Class Name: UniversalVocoder</div><div id='m_method'> M Method Name: generate(2)</div><div id='n_method'> N Method Name: generate(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/universal_vocoder.py</div><div id='n_file'> N File Name: models/universal_vocoder.py</div><div id='m_start'> M Start Line: 78</div><div id='m_end'> M End Line: 108</div><div id='n_start'> N Start Line: 77</div><div id='n_end'> N End Line: 106</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        network_prediction = self.q_network.forward(batch_inputs).view(self.batch_size, self.agents, self.number_actions)
        &#47&#47 Bellman equation
        batch_labels_tensor = batch_labels + (discount_factor * max_target_net)
        td_errors<a id="change"> = </a>(network_prediction - <a id="change">batch_labels_tensor.unsqueeze(-1</a><a id="change">)</a>).detach()

        index = torch.tensor(transitions[1], dtype=torch.long).unsqueeze(-1)
        y_pred = (torch.gather(network_prediction, -1, index)).squeeze()</code></pre><h3>After Change</h3><pre><code class='java'>
        Transitions are tuple of shape obses_t, actions, rewards, obses_tp1, dones
        &quot&quot&quot
        curr_state = torch.tensor(transitions[0])
        next_state = <a id="change">torch.tensor(</a>transitions[3]<a id="change">)</a>

        &#47&#47 Labels are the rewards
        rewards = torch.clamp(torch.tensor(transitions[2], dtype=torch.float32), -1, 1)
        y = self.target_network.forward(next_state).detach().squeeze() &#47&#47 TODO: should it be next state or current state that we forward?
        y = y.view(self.batch_size, self.agents, self.number_actions)
        &#47&#47 Get the maximum prediction for the next state from the target network
        max_target_net = y.max(-1)[0]
        network_prediction = self.q_network.forward(curr_state).view(self.batch_size, self.agents, self.number_actions)
        &#47&#47 Bellman equation
        batch_labels_tensor<a id="change"> = </a>rewards + (discount_factor * max_target_net.detach())

        &#47&#47td_errors = (network_prediction - batch_labels_tensor.unsqueeze(-1)).detach() &#47&#47 TODO td error needed for exp replay
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/gml16/rl-medical/commit/8a44d0b4c41689fa1ec3c16b470f02e656be2e3c#diff-a451f3c4508cbd7cadd24d18d354c50ab0d5384af7fdbf40dc9a165c9dc5afcdL206' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73471514</div><div id='project'> Project Name: gml16/rl-medical</div><div id='commit'> Commit Name: 8a44d0b4c41689fa1ec3c16b470f02e656be2e3c</div><div id='time'> Time: 2020-03-05</div><div id='author'> Author: g.m.leroy@outlook.com</div><div id='file'> File Name: examples/LandmarkDetection/DQN/DQNModelTorch.py</div><div id='m_class'> M Class Name: DQN</div><div id='n_method'> N Class Name: DQN</div><div id='m_method'> M Method Name: _calculate_loss(3)</div><div id='n_method'> N Method Name: _calculate_loss(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/LandmarkDetection/DQN/DQNModelTorch.py</div><div id='n_file'> N File Name: examples/LandmarkDetection/DQN/DQNModelTorch.py</div><div id='m_start'> M Start Line: 208</div><div id='m_end'> M End Line: 220</div><div id='n_start'> N Start Line: 211</div><div id='n_end'> N End Line: 221</div><BR>