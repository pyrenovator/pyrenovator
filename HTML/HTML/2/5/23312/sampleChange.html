<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        source_text = batch_data[&quotsource_text&quot]
        generate_corpus = []
        for src in source_text:
            input_ids = <a id="change">self.tokenize_text(src, self.task_text, self.source_max_length).unsqueeze(0</a><a id="change">)</a>

            sample_outputs = self.model.generate(
                input_ids,
                num_beams=4,
                max_length=input_ids.size(1) + self.target_max_length,
                early_stopping=True,
            )
            generated_text = self.tokenizer.decode(sample_outputs[0][input_ids.size(1) + 1:], skip_special_tokens=True)
            generated_text<a id="change"> = </a>generated_text.split()
            generate_corpus.append(generated_text)
        return generate_corpus
</code></pre><h3>After Change</h3><pre><code class='java'>
        task_prefix_len = len(task_prefix_tokens)
        for src in source_text:
            input_tokens = self.tokenizer.tokenize(src)[:self.source_max_length - task_prefix_len] + task_prefix_tokens
            input_ids = <a id="change">torch.tensor(</a>self.tokenizer.convert_tokens_to_ids(input_tokens)<a id="change">, dtype=torch.long)</a>.unsqueeze(0)
            sample_outputs = self.model.generate(
                input_ids,
                num_beams=4,
                max_length=len(input_tokens) + self.target_max_length,
                early_stopping=True,
            )
            generated_text = self.tokenizer.decode(sample_outputs[0][len(input_tokens) + 1:], skip_special_tokens=True,
                                                   clean_up_tokenization_spaces=False)
            generated_text<a id="change"> = </a>generated_text.lower().split()
            generate_corpus.append(generated_text)

        return generate_corpus</code></pre>