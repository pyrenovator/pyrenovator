<html><h3>Pattern ID :5668
</h3><img src='19884221.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                pl_penalty = (pl_lengths - pl_mean).square()
                loss_Gpl = pl_penalty * self.pl_weight

                loss_Gpl = (gen_img[:, 0, 0, 0] * 0 + loss_Gpl).mean()<a id="change"> * </a>float(gain)
                loss_numpy[&quotloss_Gpl&quot]<a id="change"> = loss_Gpl.cpu().detach().numpy()</a>
            with torch.autograd.profiler.record_function(&quotGpl_backward&quot):
                loss_Gpl.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。
                if self.align_grad:
                    mapping = self.mapping.module if self.is_distributed else self.mapping</code></pre><h3>After Change</h3><pre><code class='java'>
                &#47&#47     loss4 += loss3
            with torch.autograd.profiler.record_function(name + &quot_backward&quot):
                &#47&#47 loss4.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。
                <a id="change">(real_logits * 0 + loss_Dreal + loss_Dr1).mean().mul(gain).backward()</a>
                if self.align_grad:
                    mapping = self.mapping.module if self.is_distributed else self.mapping
                    synthesis = self.synthesis.module if self.is_distributed else self.synthesis
                    discriminator = self.discriminator.module if self.is_distributed else self.discriminator</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/miemie2013/miemiegan/commit/308da226a2d1e0dc4f2c0543c80e1904d79a3bf1#diff-c3be3e49b4968a2ee433a8b0d38c7aa9f68d5116602220ff22567e41b765b44bL184' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19884221</div><div id='project'> Project Name: miemie2013/miemiegan</div><div id='commit'> Commit Name: 308da226a2d1e0dc4f2c0543c80e1904d79a3bf1</div><div id='time'> Time: 2022-04-09</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_class'> M Class Name: StyleGANv2ADAModel</div><div id='n_method'> N Class Name: StyleGANv2ADAModel</div><div id='m_method'> M Method Name: accumulate_gradients(9)</div><div id='n_method'> N Method Name: accumulate_gradients(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='n_file'> N File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_start'> M Start Line: 184</div><div id='m_end'> M End Line: 353</div><div id='n_start'> N Start Line: 208</div><div id='n_end'> N End Line: 356</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            pl_penalty = (pl_lengths - pl_mean).square()
            loss_Gpl = pl_penalty * self.pl_weight

            loss_Gpl = (gen_img[:, 0, 0, 0] * 0 + loss_Gpl).mean()<a id="change"> * </a>float(gain)
            loss_numpy[&quotloss_Gpl&quot]<a id="change"> = loss_Gpl.cpu().detach().numpy()</a>
            loss_Gpl.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。

        &#47&#47 Dmain: Minimize logits for generated images.
        loss3 = 0.0</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 loss_G = loss_Gmain
            &#47&#47 loss_G = loss_G * float(gain)
            &#47&#47 loss_G.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。
            <a id="change">loss_Gmain.mean().mul(gain).backward()</a>

        &#47&#47 Gpl: Apply path length regularization.
        if do_Gpl:
            &#47&#47 print(&quot----------------- do_Gpl -----------------&quot)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/miemie2013/miemiegan/commit/cf43a0a8db722386b89e71d5d33b472774867ea1#diff-c3be3e49b4968a2ee433a8b0d38c7aa9f68d5116602220ff22567e41b765b44bL145' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19884220</div><div id='project'> Project Name: miemie2013/miemiegan</div><div id='commit'> Commit Name: cf43a0a8db722386b89e71d5d33b472774867ea1</div><div id='time'> Time: 2022-02-24</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_class'> M Class Name: StyleGANv2ADAModel</div><div id='n_method'> N Class Name: StyleGANv2ADAModel</div><div id='m_method'> M Method Name: accumulate_gradients(8)</div><div id='n_method'> N Method Name: accumulate_gradients(8)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='n_file'> N File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_start'> M Start Line: 148</div><div id='m_end'> M End Line: 236</div><div id='n_start'> N Start Line: 176</div><div id='n_end'> N End Line: 268</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        policy_loss_value = policy_loss.detach().cpu().numpy()

        &#47&#47entropy loss
        entropy_loss = <a id="change">-torch.mean(dist_entropy)</a>
        entropy_loss_value<a id="change"> =  entropy_loss.detach().cpu().numpy()</a>
        tot_loss = v_loss + entropy_loss + policy_loss

        self.policy_optimizer.zero_grad()
        self.v_optimizer.zero_grad()</code></pre><h3>After Change</h3><pre><code class='java'>
            raise NotImplementedError
        policy_loss_value = policy_loss.detach().cpu().numpy()
        self.policy_optimizer.zero_grad()
        <a id="change">policy_loss.backward()</a>
        self.policy_optimizer.step()

        &#47&#47compute value loss
        v_loss = F.mse_loss(curr_state_v, future_return_batch)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/x35f/unstable_baselines/commit/6c5f28faf8eed273f859610adbd71a0361d36112#diff-52f03432c99c716ff4dd3aab99ae6fafde4ebca9abe1cdbec481a8fee78251bcL74' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19884217</div><div id='project'> Project Name: x35f/unstable_baselines</div><div id='commit'> Commit Name: 6c5f28faf8eed273f859610adbd71a0361d36112</div><div id='time'> Time: 2021-03-31</div><div id='author'> Author: 1621322691@qq.com</div><div id='file'> File Name: ppo/model.py</div><div id='m_class'> M Class Name: PPOAgent</div><div id='n_method'> N Class Name: PPOAgent</div><div id='m_method'> M Method Name: update(2)</div><div id='n_method'> N Method Name: update(2)</div><div id='m_parent_class'> M Parent Class: BaseAgent,torch.nn.Module</div><div id='n_parent_class'> N Parent Class: BaseAgent,torch.nn.Module</div><div id='m_file'> M File Name: ppo/model.py</div><div id='n_file'> N File Name: ppo/model.py</div><div id='m_start'> M Start Line: 93</div><div id='m_end'> M End Line: 116</div><div id='n_start'> N Start Line: 96</div><div id='n_end'> N End Line: 125</div><BR>