<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        segment_ids = segment_ids.to(args.device)

        with torch.no_grad():
            if <a id="change">args.mlm</a>:
                outputs<a id="change"> = </a><a id="change">model(</a>inputs<a id="change">, masked_lm_labels=labels, position_ids=position_ids, token_type_ids=segment_ids)</a>
            else:
                if args.model_type == &quotbart&quot:
                    decoder_input_ids = labels[:, :-1].contiguous()
                    decoder_input_ids[decoder_input_ids == args.mlm_ignore_index] = tokenizer.pad_token_id</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 debugging
            if args.debug:
                print()
                print(<a id="change">[tokenizer.decode(t, skip_special_tokens=True) for t in lm_logits.max(-1)[1]]</a>)
                
            assert lm_logits.shape[-1] == model.config.vocab_size
            </code></pre>