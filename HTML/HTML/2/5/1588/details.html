<html><h3>Pattern ID :1588
</h3><img src='7292527.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 The reason for using non-empty tensors as the first elements is to avoid the
    &#47&#47 floating point exception thrown in sync() for aggregating empty tensors
    def _init_states(self) -&gt; None:
        <a id="change">if </a>len(getattr(self, PREDICTIONS)) &gt; 0:
            return

        <a id="change">getattr(self, PREDICTIONS).append(
            </a>torch.zeros((self._n_tasks<a id="change">, 1</a>), dtype=torch.double, device=self.device)<a id="change">
        )</a>
        getattr(self, LABELS).append(
            torch.zeros((self._n_tasks, 1), dtype=torch.double, device=self.device)
        )
        getattr(self, WEIGHTS).append(</code></pre><h3>After Change</h3><pre><code class='java'>

    def _init_states(self) -&gt; None:
        state = getattr(self, self._fused_name)
        state<a id="change"> = </a>torch.zeros(
            (len(self.state_names), self._n_tasks, 1),
            dtype=torch.double,
            device=self.device,
        )
        <a id="change">setattr(</a>self, self._fused_name, state<a id="change">)</a>

        for name, _ in self._fused_map.items():
            setattr(
                self,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/facebookresearch/torchrec/commit/df576fab294f27a11da2cc337c951b35210db8b4#diff-8820e947aafc85a1827c5fcad6e32775262d64bf5ac9bd7a1b5f335e830f8edbL77' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7292527</div><div id='project'> Project Name: facebookresearch/torchrec</div><div id='commit'> Commit Name: df576fab294f27a11da2cc337c951b35210db8b4</div><div id='time'> Time: 2023-01-13</div><div id='author'> Author: renganxu@meta.com</div><div id='file'> File Name: torchrec/metrics/auc.py</div><div id='m_class'> M Class Name: AUCMetricComputation</div><div id='n_method'> N Class Name: AUCMetricComputation</div><div id='m_method'> M Method Name: _init_states(1)</div><div id='n_method'> N Method Name: _init_states(1)</div><div id='m_parent_class'> M Parent Class: RecMetricComputation</div><div id='n_parent_class'> N Parent Class: RecMetricComputation</div><div id='m_file'> M File Name: torchrec/metrics/auc.py</div><div id='n_file'> N File Name: torchrec/metrics/auc.py</div><div id='m_start'> M Start Line: 91</div><div id='m_end'> M End Line: 102</div><div id='n_start'> N Start Line: 77</div><div id='n_end'> N End Line: 92</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                setattr(leaf_module, split_path[-1], sharded_module)
            else:
                self._dmp_wrapped_module = sharded_module
            <a id="change">if </a>isinstance(sharded_module, FusedOptimizerModule):
                <a id="change">fused_optims.append(</a>(path<a id="change">, sharded_module.fused_optimizer</a>)<a id="change">)</a>
        else:
            for name, child in module.named_children():
                self._shard_modules_impl(
                    child,</code></pre><h3>After Change</h3><pre><code class='java'>
            return module

        for name, child in module.named_children():
            child<a id="change"> = </a>self._shard_modules_impl(
                child,
                path + "." + name if path else name,
            )
            <a id="change">setattr(</a>module, name, child<a id="change">)</a>

        return module

    def _init_parameters(self, module: nn.Module) -&gt; None:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/torchrec/commit/f13d0c06f6492b058beeb9fe7e2b9e2bbaa5f0f2#diff-088378575010e7b9e27ea06507ba52fcc8604bcf9cb107f4939a9a49b0d52c89L338' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7292523</div><div id='project'> Project Name: pytorch/torchrec</div><div id='commit'> Commit Name: f13d0c06f6492b058beeb9fe7e2b9e2bbaa5f0f2</div><div id='time'> Time: 2022-11-07</div><div id='author'> Author: dstaay@meta.com</div><div id='file'> File Name: torchrec/distributed/model_parallel.py</div><div id='m_class'> M Class Name: DistributedModelParallel</div><div id='n_method'> N Class Name: DistributedModelParallel</div><div id='m_method'> M Method Name: _shard_modules_impl(3)</div><div id='n_method'> N Method Name: _shard_modules_impl(4)</div><div id='m_parent_class'> M Parent Class: FusedOptimizerModule,nn.Module</div><div id='n_parent_class'> N Parent Class: FusedOptimizerModule,nn.Module</div><div id='m_file'> M File Name: torchrec/distributed/model_parallel.py</div><div id='n_file'> N File Name: torchrec/distributed/model_parallel.py</div><div id='m_start'> M Start Line: 342</div><div id='m_end'> M End Line: 371</div><div id='n_start'> N Start Line: 352</div><div id='n_end'> N End Line: 374</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 The reason for using non-empty tensors as the first elements is to avoid the
    &#47&#47 floating point exception thrown in sync() for aggregating empty tensors
    def _init_states(self) -&gt; None:
        <a id="change">if </a>len(getattr(self, PREDICTIONS)) &gt; 0:
            return

        <a id="change">getattr(self, PREDICTIONS).append(
            </a>torch.zeros((self._n_tasks<a id="change">, 1</a>), dtype=torch.double, device=self.device)<a id="change">
        )</a>
        getattr(self, LABELS).append(
            torch.zeros((self._n_tasks, 1), dtype=torch.double, device=self.device)
        )
        getattr(self, WEIGHTS).append(</code></pre><h3>After Change</h3><pre><code class='java'>
        )

    def _init_states(self) -&gt; None:
        state<a id="change"> = </a>getattr(self, self._fused_name)
        state = torch.zeros(
            (len(self.state_names), self._n_tasks, 1),
            dtype=torch.double,
            device=self.device,
        )
        <a id="change">setattr(</a>self, self._fused_name, state<a id="change">)</a>

        for name, _ in self._fused_map.items():
            setattr(
                self,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/facebookresearch/torchrec/commit/50c861a4debb6d0d8bd55ddb27452e89f2d19d51#diff-8820e947aafc85a1827c5fcad6e32775262d64bf5ac9bd7a1b5f335e830f8edbL90' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7292533</div><div id='project'> Project Name: facebookresearch/torchrec</div><div id='commit'> Commit Name: 50c861a4debb6d0d8bd55ddb27452e89f2d19d51</div><div id='time'> Time: 2022-12-03</div><div id='author'> Author: renganxu@meta.com</div><div id='file'> File Name: torchrec/metrics/auc.py</div><div id='m_class'> M Class Name: AUCMetricComputation</div><div id='n_method'> N Class Name: AUCMetricComputation</div><div id='m_method'> M Method Name: _init_states(1)</div><div id='n_method'> N Method Name: _init_states(1)</div><div id='m_parent_class'> M Parent Class: RecMetricComputation</div><div id='n_parent_class'> N Parent Class: RecMetricComputation</div><div id='m_file'> M File Name: torchrec/metrics/auc.py</div><div id='n_file'> N File Name: torchrec/metrics/auc.py</div><div id='m_start'> M Start Line: 91</div><div id='m_end'> M End Line: 102</div><div id='n_start'> N Start Line: 77</div><div id='n_end'> N End Line: 92</div><BR>