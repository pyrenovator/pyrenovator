<html><h3>Pattern ID :16890
</h3><img src='56774358.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        loss = metrics[&quotloss&quot]

        if self.config.use_amp:
            <a id="change">scaler.scale(loss).backward()</a>
            <a id="change">scaler.step(</a>optimizer<a id="change">)</a>
            scaler.update()
        else:
            loss.backward()
            optimizer.step()</code></pre><h3>After Change</h3><pre><code class='java'>

        if self.config.use_amp:
            with amp.scale_loss(loss, optimizer) as scaled_loss:
                <a id="change">scaled_loss.backward()</a>
        else:
            loss.backward()

        optimizer.step()</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/affjljoo3581/gpt2/commit/f7af3a138cb7c96f9518fa8c418a03a601fa5a50#diff-63240343052ed75642934489cd0abe51f29fb49ea17c9609eac4cbf8d3d6dc64L154' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 56774358</div><div id='project'> Project Name: affjljoo3581/gpt2</div><div id='commit'> Commit Name: f7af3a138cb7c96f9518fa8c418a03a601fa5a50</div><div id='time'> Time: 2020-09-08</div><div id='author'> Author: affjljoo3581@gmail.com</div><div id='file'> File Name: src/gpt2/training/training.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: _train_step(6)</div><div id='n_method'> N Method Name: _train_step(7)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: src/gpt2/training/training.py</div><div id='n_file'> N File Name: src/gpt2/training/training.py</div><div id='m_start'> M Start Line: 154</div><div id='m_end'> M End Line: 171</div><div id='n_start'> N Start Line: 166</div><div id='n_end'> N End Line: 175</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    :param epochs_per_save: how many epochs to train in between checkpoints
    
    net = net.to(device)
    <a id="change">scaler</a> = GradScaler()
    train_loader = DataLoader(batch_size=batch_size,
                              dataset=train_dataset,
                              drop_last=True,
                              num_workers=8,
                              pin_memory=False,
                              shuffle=True,
                              prefetch_factor=8,
                              collate_fn=collate_and_pad,
                              persistent_workers=True)
    if use_speaker_embedding:
        reference_speaker_embedding_for_att_plot = torch.Tensor(train_dataset[0][4]).to(device)
    else:
        reference_speaker_embedding_for_att_plot = None
    step_counter = 0
    epoch = 0
    net.train()
    if fine_tune:
        lr = lr * 0.01
    optimizer = torch.optim.Adam(net.parameters(), lr=lr, eps=1.0e-06, weight_decay=0.0)
    if path_to_checkpoint is not None:
        &#47&#47 careful when restarting, plotting data will be overwritten!
        check_dict = torch.load(os.path.join(path_to_checkpoint), map_location=device)
        net.load_state_dict(check_dict["model"])
        if not fine_tune:
            optimizer.load_state_dict(check_dict["optimizer"])
            scaler.load_state_dict(check_dict["scaler"])
            step_counter = check_dict["step_counter"]
    start_time = time.time()
    while True:
        epoch += 1
        optimizer.zero_grad()
        train_losses_this_epoch = list()
        for batch in tqdm(train_loader):
            with autocast():
                if not use_speaker_embedding:
                    train_loss = net(text=batch[0].to(device),
                                     text_lengths=batch[1].to(device),
                                     speech=batch[2].to(device),
                                     speech_lengths=batch[3].to(device),
                                     speaker_embeddings=None,
                                     step=step_counter)
                else:
                    train_loss = net(text=batch[0].to(device),
                                     text_lengths=batch[1].to(device),
                                     speech=batch[2].to(device),
                                     speech_lengths=batch[3].to(device),
                                     speaker_embeddings=batch[4].to(device),
                                     step=step_counter)
                train_losses_this_epoch.append(float(train_loss))
            optimizer.zero_grad()
            <a id="change">scaler.scale(train_loss).backward()</a>
            if step_counter - 1 == net.switch_on_prenet_step:
                if net.dec.prenet is not None and not net.start_with_prenet:
                    optimizer.add_param_group({&quotparams&quot: net.dec.prenet.parameters()})
            step_counter += 1
            torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)
            <a id="change">scaler.step(</a>optimizer<a id="change">)</a>
            scaler.update()
        with torch.no_grad():
            net.eval()
            if epoch % epochs_per_save == 0:</code></pre><h3>After Change</h3><pre><code class='java'>
                                 step=step_counter)
            train_losses_this_epoch.append(float(train_loss))
            optimizer.zero_grad()
            <a id="change">train_loss.backward()</a>
            if step_counter - 1 == net.switch_on_prenet_step:
                if net.dec.prenet is not None and not net.start_with_prenet:
                    optimizer.add_param_group({&quotparams&quot: net.dec.prenet.parameters()})
            step_counter += 1</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/0b357abbd5e5bbd61ae876f372615d4485ce7a81#diff-50506526d43ed453ff387fee15511f145ae91f8e336dbcc118883a5d89a1232cL79' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 56774359</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 0b357abbd5e5bbd61ae876f372615d4485ce7a81</div><div id='time'> Time: 2021-08-27</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/tacotron2_train_loop.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train_loop(12)</div><div id='n_method'> N Method Name: train_loop(12)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/tacotron2_train_loop.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/tacotron2_train_loop.py</div><div id='m_start'> M Start Line: 108</div><div id='m_end'> M End Line: 190</div><div id='n_start'> N Start Line: 124</div><div id='n_end'> N End Line: 183</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    :param epochs_per_save: how many epochs to train in between checkpoints
    
    net = net.to(device)
    <a id="change">scaler</a> = GradScaler()
    if use_speaker_embedding:
        reference_speaker_embedding_for_plot = torch.Tensor(train_dataset[0][7]).to(device)
    else:
        reference_speaker_embedding_for_plot = None
    torch.multiprocessing.set_sharing_strategy(&quotfile_system&quot)
    train_loader = DataLoader(batch_size=batch_size,
                              dataset=train_dataset,
                              drop_last=True,
                              num_workers=8,
                              pin_memory=False,
                              shuffle=True,
                              prefetch_factor=8,
                              collate_fn=collate_and_pad,
                              persistent_workers=True)
    step_counter = 0
    net.train()
    if fine_tune:
        lr = lr * 0.01
    optimizer = torch.optim.Adam(net.parameters(), lr=lr)
    scheduler = WarmupScheduler(optimizer, warmup_steps=warmup_steps)
    epoch = 0
    if path_to_checkpoint is not None:
        check_dict = torch.load(path_to_checkpoint, map_location=device)
        net.load_state_dict(check_dict["model"])
        if not fine_tune:
            optimizer.load_state_dict(check_dict["optimizer"])
            scaler.load_state_dict(check_dict["scaler"])
            scheduler.load_state_dict(check_dict["scheduler"])
            step_counter = check_dict["step_counter"]
    start_time = time.time()
    while True:
        epoch += 1
        optimizer.zero_grad()
        train_losses_this_epoch = list()
        for batch in tqdm(train_loader):
            with autocast():
                if not use_speaker_embedding:
                    train_loss = net(batch[0].to(device), batch[1].to(device), batch[2].to(device),
                                     batch[3].to(device), batch[4].to(device), batch[5].to(device),
                                     batch[6].to(device))
                else:
                    train_loss = net(batch[0].to(device), batch[1].to(device), batch[2].to(device),
                                     batch[3].to(device), batch[4].to(device), batch[5].to(device),
                                     batch[6].to(device), batch[7].to(device))
                train_losses_this_epoch.append(float(train_loss))
            optimizer.zero_grad()
            <a id="change">scaler.scale(train_loss).backward()</a>
            step_counter += 1
            torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)
            <a id="change">scaler.step(</a>optimizer<a id="change">)</a>
            scaler.update()
            scheduler.step()
        with torch.no_grad():
            net.eval()</code></pre><h3>After Change</h3><pre><code class='java'>
                                 batch[6].to(device), batch[7].to(device))
            train_losses_this_epoch.append(float(train_loss))
            optimizer.zero_grad()
            <a id="change">train_loss.backward()</a>
            step_counter += 1
            torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)
            optimizer.step()
            scheduler.step()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/9acf5082bd9123fa8cbc8be370ceec36501acf58#diff-b8085078dc768b2f7e93d9bc99d3eeaabf3b6734a8f951665829ac81840bed0bL98' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 56774360</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 9acf5082bd9123fa8cbc8be370ceec36501acf58</div><div id='time'> Time: 2021-08-27</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/fastspeech2_train_loop.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train_loop(13)</div><div id='n_method'> N Method Name: train_loop(13)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/fastspeech2_train_loop.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/fastspeech2_train_loop.py</div><div id='m_start'> M Start Line: 128</div><div id='m_end'> M End Line: 201</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 193</div><BR>