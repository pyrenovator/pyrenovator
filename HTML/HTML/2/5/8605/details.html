<html><h3>Pattern ID :8605
</h3><img src='29960153.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        super().__init__()
        hdim = hidden_dim

        self.encoder<a id="change"> = nn</a><a id="change">.Sequential(
            </a>nn.Conv2d(3, hdim, 4, stride = 2, padding = 1),
            nn.ReLU(),
            nn.Conv2d(hdim, hdim, 4, stride = 2, padding = 1),
            nn.ReLU(),
            nn.Conv2d(hdim, hdim, 4, stride = 2, padding = 1),
            nn.ReLU(),
            nn.Conv2d(hdim, num_tokens, 1)<a id="change">
        )</a>

        self.decoder = <a id="change">nn.Sequential(
            </a>nn.ConvTranspose2d(dim, hdim, 4, stride = 2, padding = 1),
            nn.ReLU(),
            nn.ConvTranspose2d(hdim, hdim, 4, stride = 2, padding = 1),
            nn.ReLU(),
            nn.ConvTranspose2d(hdim, hdim, 4, stride = 2, padding = 1),
            nn.ReLU(),
            nn.Conv2d(hdim, 3, 1)<a id="change">
        )</a>

        self.num_tokens = num_tokens
        self.codebook = nn.Embedding(num_tokens, dim)
</code></pre><h3>After Change</h3><pre><code class='java'>
        super().__init__()
        hdim = hidden_dim
        
        <a id="change">assert </a>num_layers &gt;= 1
        
        encoder_layers = []
        decoder_layers = []</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/dalle-pytorch/commit/95a980129346b66ce7cbb3f984b698ca21e0965c#diff-7fee3463af42e34e03d754e24fa9b24e3cde98aae198d2cb45f200d6da301016L80' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 29960153</div><div id='project'> Project Name: lucidrains/dalle-pytorch</div><div id='commit'> Commit Name: 95a980129346b66ce7cbb3f984b698ca21e0965c</div><div id='time'> Time: 2021-01-06</div><div id='author'> Author: nauman.mustafa.x@gmail.com</div><div id='file'> File Name: dalle_pytorch/dalle_pytorch.py</div><div id='m_class'> M Class Name: DiscreteVAE</div><div id='n_method'> N Class Name: DiscreteVAE</div><div id='m_method'> M Method Name: __init__(5)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dalle_pytorch/dalle_pytorch.py</div><div id='n_file'> N File Name: dalle_pytorch/dalle_pytorch.py</div><div id='m_start'> M Start Line: 82</div><div id='m_end'> M End Line: 102</div><div id='n_start'> N Start Line: 80</div><div id='n_end'> N End Line: 107</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        self.alibi = AlibiPositionalBias(heads = heads)

        self.to_q<a id="change"> = </a><a id="change">nn.Sequential(
            </a>nn.Conv1d(dim, inner_dim, 1, bias = False),
            nn.Conv1d(inner_dim, inner_dim, 3, bias = False, groups = inner_dim)<a id="change">
        )</a>

        self.to_k = nn.Sequential(
            nn.Conv1d(dim, inner_dim, 1, bias = False),
            nn.Conv1d(inner_dim, inner_dim, 3, bias = False, groups = inner_dim)
        )

        self.to_v = <a id="change">nn.Sequential(
            </a>nn.Conv1d(dim, inner_dim, 1, bias = False),
            nn.Conv1d(inner_dim, inner_dim, 3, bias = False, groups = inner_dim)<a id="change">
        )</a>

        self.to_out = nn.Linear(inner_dim, dim, bias = False)

    def forward(self, x):</code></pre><h3>After Change</h3><pre><code class='java'>
        ds_conv_kernel_sizes = (0, 3, 5, 7) &#47&#47 heads were grouped into 4 groups and given a depthwise conv after the queries / keys / values projection
    ):
        super().__init__()
        <a id="change">assert </a>heads &gt;= 4 and (heads % 4) == 0, &quotheads must be greater than 4 and divisible by 4&quot

        self.scale = dim_head ** -0.5
        self.heads = heads</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/tranception-pytorch/commit/b2eaf893294394093839a66effb621645d54cd6c#diff-18b0a7fd74d6ed16b8ebef089a2a63eb9b5ff5662fc464204330a63b2b4466c1L80' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 29960155</div><div id='project'> Project Name: lucidrains/tranception-pytorch</div><div id='commit'> Commit Name: b2eaf893294394093839a66effb621645d54cd6c</div><div id='time'> Time: 2022-06-12</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: tranception_pytorch/tranception_pytorch.py</div><div id='m_class'> M Class Name: CausalAttention</div><div id='n_method'> N Class Name: CausalAttention</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: tranception_pytorch/tranception_pytorch.py</div><div id='n_file'> N File Name: tranception_pytorch/tranception_pytorch.py</div><div id='m_start'> M Start Line: 90</div><div id='m_end'> M End Line: 109</div><div id='n_start'> N Start Line: 99</div><div id='n_end'> N End Line: 127</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        super(AddonNN, self).__init__()

        &#47&#47 keep everything but the last layer 
        self.featurizer<a id="change"> = </a><a id="change">nn.Sequential(</a>*<a id="change">list(model.classifier.children())[:-1])</a>
        
        &#47&#47 freeze the featurizer
        for param in self.featurizer.parameters():
            param.requires_grad_ = False

        &#47&#47 create small network that will take features as input
        &#47&#47 TODO: got to figure out what is input size
        self.addon_nn = <a id="change">nn.Sequential(
            </a>nn.Linear(feat_size, 4096), 
            nn.ReLU(), 
            nn.Linear(4096, 4096), 
            nn.ReLU(), 
            nn.Linear(4096, num_classes)<a id="change">)</a> 

    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
        &#47&#47 pass through the original network up to the penultimate layer</code></pre><h3>After Change</h3><pre><code class='java'>
    def __init__(self, model:Network, num_classes:int=10, stack_num=1)-&gt;None:
        super(AddonNN, self).__init__()

        <a id="change">assert </a>stack_num in set((1,2,3))

        self.FEAT_SIZE = {1: 32768, 2: 16384, 3: 32768}
        </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/archai/commit/16a8b37ef55c82318b3c89402322a1a36f063113#diff-78d7ef277c143adf9ed48114cd24da6d03296baf18dcd78c4a97084c8797caa9L12' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 29960154</div><div id='project'> Project Name: microsoft/archai</div><div id='commit'> Commit Name: 16a8b37ef55c82318b3c89402322a1a36f063113</div><div id='time'> Time: 2022-12-16</div><div id='author'> Author: dedey@microsoft.com</div><div id='file'> File Name: archai/algos/proxynas/addon_nn.py</div><div id='m_class'> M Class Name: AddonNN</div><div id='n_method'> N Class Name: AddonNN</div><div id='m_method'> M Method Name: __init__(4)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: archai/algos/proxynas/addon_nn.py</div><div id='n_file'> N File Name: archai/algos/proxynas/addon_nn.py</div><div id='m_start'> M Start Line: 12</div><div id='m_end'> M End Line: 29</div><div id='n_start'> N Start Line: 8</div><div id='n_end'> N End Line: 23</div><BR>