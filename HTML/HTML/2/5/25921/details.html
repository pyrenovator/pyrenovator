<html><h3>Pattern ID :25921
</h3><img src='78319487.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        if exists(mask):
            mask = rearrange(mask, &quotb n -&gt; b () n ()&quot)
            <a id="change">k.masked_fill_(</a>~mask, <a id="change">-torch.finfo(k.dtype).max</a><a id="change">)</a>

        q = q.softmax(dim = -1)
        k = k.softmax(dim = -2)
</code></pre><h3>After Change</h3><pre><code class='java'>

        if exists(mask):
            mask = rearrange(mask, &quotb n -&gt; b () n ()&quot)
            k<a id="change"> = </a><a id="change">k.masked_fill(</a>~mask, <a id="change">-torch.finfo(k.dtype).max</a><a id="change">)</a>

        q = q.softmax(dim = -1)
        k = k.softmax(dim = -2)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/protein-bert-pytorch/commit/9440e114b898abcfc4bfc28f78465d7fc062ff22#diff-6e35313d9af4f12619a10ddacdffb91019586962c8eddcde1ba5702de45fcc56L48' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78319487</div><div id='project'> Project Name: lucidrains/protein-bert-pytorch</div><div id='commit'> Commit Name: 9440e114b898abcfc4bfc28f78465d7fc062ff22</div><div id='time'> Time: 2021-06-10</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: protein_bert_pytorch/protein_bert_pytorch.py</div><div id='m_class'> M Class Name: GlobalLinearSelfAttention</div><div id='n_method'> N Class Name: GlobalLinearSelfAttention</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: protein_bert_pytorch/protein_bert_pytorch.py</div><div id='n_file'> N File Name: protein_bert_pytorch/protein_bert_pytorch.py</div><div id='m_start'> M Start Line: 48</div><div id='m_end'> M End Line: 56</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 57</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        if exists(mask):
            conv_input_mask = rearrange(mask, &quotb n -&gt; b () n&quot)
            <a id="change">conv_input.masked_fill_(~conv_input_mask</a>, 0.<a id="change">)</a>

        narrow_out = self.narrow_conv(conv_input)
        narrow_out = rearrange(narrow_out, &quotb d n -&gt; b n d&quot)
        wide_out = self.wide_conv(conv_input)</code></pre><h3>After Change</h3><pre><code class='java'>

        if exists(mask):
            conv_input_mask = rearrange(mask, &quotb n -&gt; b () n&quot)
            conv_input<a id="change"> = </a><a id="change">conv_input.masked_fill(~conv_input_mask</a>, 0.<a id="change">)</a>

        narrow_out = self.narrow_conv(conv_input)
        narrow_out = rearrange(narrow_out, &quotb d n -&gt; b n d&quot)
        wide_out = self.wide_conv(conv_input)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/protein-bert-pytorch/commit/9440e114b898abcfc4bfc28f78465d7fc062ff22#diff-6e35313d9af4f12619a10ddacdffb91019586962c8eddcde1ba5702de45fcc56L201' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78319491</div><div id='project'> Project Name: lucidrains/protein-bert-pytorch</div><div id='commit'> Commit Name: 9440e114b898abcfc4bfc28f78465d7fc062ff22</div><div id='time'> Time: 2021-06-10</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: protein_bert_pytorch/protein_bert_pytorch.py</div><div id='m_class'> M Class Name: Layer</div><div id='n_method'> N Class Name: Layer</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: protein_bert_pytorch/protein_bert_pytorch.py</div><div id='n_file'> N File Name: protein_bert_pytorch/protein_bert_pytorch.py</div><div id='m_start'> M Start Line: 215</div><div id='m_end'> M End Line: 215</div><div id='n_start'> N Start Line: 216</div><div id='n_end'> N End Line: 216</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        This is called by Multi-head attention object to find the values.
        
        scores = torch.matmul(q, k.transpose(-2, -1)) / d_k ** 0.5  &#47&#47 bs, head, q_len, k_len
        <a id="change">scores.masked_fill_(</a>mask == 0, <a id="change">-np.inf</a><a id="change">)</a>
        scores = (scores - scores.max()).softmax(dim=-1)
        output = torch.matmul(scores, v)  &#47&#47 bs, head, q_len, d_k
        return output
</code></pre><h3>After Change</h3><pre><code class='java'>
        
        scores = torch.matmul(q, k.transpose(-2, -1)) / d_k ** 0.5  &#47&#47 bs, head, q_len, k_len
        if mask is not None:
            scores = <a id="change">scores.masked_fill(</a>mask == 0, <a id="change">-np.inf</a><a id="change">)</a>
        scores = (scores - scores.max()).softmax(dim=-1)
        scores<a id="change"> = </a>scores.masked_fill(torch.isnan(scores), 0)
        output = torch.matmul(scores, v)  &#47&#47 bs, head, q_len, d_k
        return output
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuwangcy/rechorus/commit/3499e224537d509ed981d53c7978c5c5452b5014#diff-04e02abc91d51a5592f17aba7804d786a92852545ded25fcb0b16bcc01df9611L48' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78319495</div><div id='project'> Project Name: thuwangcy/rechorus</div><div id='commit'> Commit Name: 3499e224537d509ed981d53c7978c5c5452b5014</div><div id='time'> Time: 2020-11-16</div><div id='author'> Author: THUwangcy@gmail.com</div><div id='file'> File Name: src/utils/layers.py</div><div id='m_class'> M Class Name: MultiHeadAttention</div><div id='n_method'> N Class Name: MultiHeadAttention</div><div id='m_method'> M Method Name: scaled_dot_product_attention(5)</div><div id='n_method'> N Method Name: scaled_dot_product_attention(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/utils/layers.py</div><div id='n_file'> N File Name: src/utils/layers.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 53</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 56</div><BR>