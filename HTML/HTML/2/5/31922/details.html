<html><h3>Pattern ID :31922
</h3><img src='93367793.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        base_optimizer_group_states = []
        for i in range(len(self.optimizer.param_groups)):
            partition_states = {}
            all_partition_group_states = <a id="change">[
                sd[&quotbase_optimizer_state&quot][i] for sd in all_state_dict
            ]</a>

            if self.is_moe_group(self.optimizer.param_groups[i]):
                ranks = self.get_ep_ranks()
                all_partition_group_states<a id="change"> = </a>[
                    all_partition_group_states[i] for i in ranks
                ]
</code></pre><h3>After Change</h3><pre><code class='java'>
            for key, saved in base_optimizer_group_states[i].items():
                if torch.is_tensor(self.optimizer.state[p][key]):
                    dst_tensor = self.optimizer.state[p][key]
                    src_tensor = _get_padded_tensor(saved, <a id="change">dst_tensor.numel()</a>)
                    self.optimizer.state[p][key].data.copy_(src_tensor.data)
                else:
                    self.optimizer.state[p][key] = saved</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/3293cf72a0abd5cf77a831996bd054bc908476a6#diff-99dcf26ea2876ff5bbf05b5165c4133eaa0d0f36b170685643c2f7e2eb566addL2066' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 93367793</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: 3293cf72a0abd5cf77a831996bd054bc908476a6</div><div id='time'> Time: 2022-01-14</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/runtime/zero/stage_1_and_2.py</div><div id='m_class'> M Class Name: DeepSpeedZeroOptimizer</div><div id='n_method'> N Class Name: DeepSpeedZeroOptimizer</div><div id='m_method'> M Method Name: _restore_base_optimizer_state(2)</div><div id='n_method'> N Method Name: _restore_base_optimizer_state(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: deepspeed/runtime/zero/stage_1_and_2.py</div><div id='n_file'> N File Name: deepspeed/runtime/zero/stage_1_and_2.py</div><div id='m_start'> M Start Line: 2070</div><div id='m_end'> M End Line: 2097</div><div id='n_start'> N Start Line: 2066</div><div id='n_end'> N End Line: 2074</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 3) Using the extracted value to directly update the base optimizer.
    def _restore_base_optimizer_state(self, all_state_dict):
        base_optimizer_group_states = []
        for <a id="change">i</a> in range(len(self.optimizer.param_groups)):
            partition_states = {}
            all_partition_group_states = [
                sd[&quotbase_optimizer_state&quot][i] for sd in all_state_dict
            ]

            if self.is_moe_group(self.optimizer.param_groups[i]):
                ranks = self.get_ep_ranks()
                all_partition_group_states = [
                    all_partition_group_states[i] for i in ranks
                ]

            for key in all_partition_group_states[0].keys():
                all_partition_states<a id="change"> = </a><a id="change">[
                    all_states[key] for all_states in all_partition_group_states
                ]</a>
                partition_states[key] = self._partition_base_optimizer_state(
                    key,
                    all_partition_states,
                    i)</code></pre><h3>After Change</h3><pre><code class='java'>
            for key, saved in base_optimizer_group_states[i].items():
                if torch.is_tensor(self.optimizer.state[p][key]):
                    dst_tensor = self.optimizer.state[p][key]
                    src_tensor = _get_padded_tensor(saved, <a id="change">dst_tensor.numel()</a>)
                    self.optimizer.state[p][key].data.copy_(src_tensor.data)
                else:
                    self.optimizer.state[p][key] = saved</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/3293cf72a0abd5cf77a831996bd054bc908476a6#diff-99dcf26ea2876ff5bbf05b5165c4133eaa0d0f36b170685643c2f7e2eb566addL2069' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 93367796</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: 3293cf72a0abd5cf77a831996bd054bc908476a6</div><div id='time'> Time: 2022-01-14</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/runtime/zero/stage_1_and_2.py</div><div id='m_class'> M Class Name: DeepSpeedZeroOptimizer</div><div id='n_method'> N Class Name: DeepSpeedZeroOptimizer</div><div id='m_method'> M Method Name: _restore_base_optimizer_state(2)</div><div id='n_method'> N Method Name: _restore_base_optimizer_state(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: deepspeed/runtime/zero/stage_1_and_2.py</div><div id='n_file'> N File Name: deepspeed/runtime/zero/stage_1_and_2.py</div><div id='m_start'> M Start Line: 2070</div><div id='m_end'> M End Line: 2097</div><div id='n_start'> N Start Line: 2066</div><div id='n_end'> N End Line: 2074</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                if p.requires_grad:
                    inp.append(p)

        for <a id="change">ibatch</a> in range(psi.shape[0]):
            grads = torch.autograd.grad(psi[ibatch], inp, retain_graph=True)
            grads = torch.cat(<a id="change">[g.view(-1)/psi[ibatch] for g in grads]</a>)
            if ibatch == 0:
                S<a id="change"> = </a>grads * grads.view(-1, 1)
            else:
                S += grads * grads.view(-1, 1)
</code></pre><h3>After Change</h3><pre><code class='java'>
        for group in self.param_groups:
            for p in group[&quotparams&quot]:
                if p.requires_grad:
                    ninp += <a id="change">p.numel()</a>

        S = torch.zeros(ninp, ninp)
        sum_grads = torch.zeros(ninp)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nlesc-jcer/qmctorch/commit/9f40f526749f6a91afacd7fa260c5e0c7e934715#diff-cefdd5d413077f5a707bb83bf6ebbac113eb5193728a62f34d612924494720f3L39' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 93367801</div><div id='project'> Project Name: nlesc-jcer/qmctorch</div><div id='commit'> Commit Name: 9f40f526749f6a91afacd7fa260c5e0c7e934715</div><div id='time'> Time: 2020-02-07</div><div id='author'> Author: nicolas.gm.renaud@gmail.com</div><div id='file'> File Name: deepqmc/optim/sr.py</div><div id='m_class'> M Class Name: StochasticReconfiguration</div><div id='n_method'> N Class Name: StochasticReconfiguration</div><div id='m_method'> M Method Name: get_overlap_matrix(2)</div><div id='n_method'> N Method Name: get_overlap_matrix(2)</div><div id='m_parent_class'> M Parent Class: Optimizer</div><div id='n_parent_class'> N Parent Class: Optimizer</div><div id='m_file'> M File Name: deepqmc/optim/sr.py</div><div id='n_file'> N File Name: deepqmc/optim/sr.py</div><div id='m_start'> M Start Line: 42</div><div id='m_end'> M End Line: 58</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 57</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        if self.cpu_offload_params:
            self.param_groups_fp16_flat_cpu_memory = []
            for j, <a id="change">param_group</a> in enumerate(self.optimizer.param_groups):
                total_params<a id="change"> = </a>sum(<a id="change">[p.ds_tensor.numel() for p in param_group[&quotparams&quot]]</a>)
                self.param_groups_fp16_flat_cpu_memory.append(
                    torch.empty(total_params,
                                dtype=torch.half,</code></pre><h3>After Change</h3><pre><code class='java'>
                else:
                    print_rank_0(f"Params in nvme and cpu {self.params_in_nvme_and_cpu}")
                    &#47&#47Flat buffer may not be available for parameters that reside in NVME
                    if not self.params_in_nvme_and_cpu or flat_offset + total_elements &lt;= <a id="change">self.param_groups_fp16_flat_cpu_memory[
                            j].numel()</a>:
                        fp16_partitioned_group_flat = self.param_groups_fp16_flat_cpu_memory[
                            j].narrow(0,
                                      flat_offset,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/0d4a54a04d658db40a120bc10c6f1f1a4478f6f1#diff-1ad5daa1b31aa5573616024068d646f0c38e88d4d3a71d3d0e4bc352ea232178L879' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 93367803</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: 0d4a54a04d658db40a120bc10c6f1f1a4478f6f1</div><div id='time'> Time: 2021-04-18</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/runtime/zero/stage3.py</div><div id='m_class'> M Class Name: FP16_DeepSpeedZeroOptimizer_Stage3</div><div id='n_method'> N Class Name: FP16_DeepSpeedZeroOptimizer_Stage3</div><div id='m_method'> M Method Name: _create_fp16_partitions_with_defragmentation(1)</div><div id='n_method'> N Method Name: _create_fp16_partitions_with_defragmentation(1)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: deepspeed/runtime/zero/stage3.py</div><div id='n_file'> N File Name: deepspeed/runtime/zero/stage3.py</div><div id='m_start'> M Start Line: 884</div><div id='m_end'> M End Line: 944</div><div id='n_start'> N Start Line: 1079</div><div id='n_end'> N End Line: 1177</div><BR>