<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        calibrate_logits = pmi_calibrate(model, max_seq_length=config.dataloader.max_seq_length)
        model.register_calibrate_logits(calibrate_logits)
    elif config.calibrate_type == "contextualized_calibrate":
        <a id="change">if </a>config.contextualized_calibrate.use_split == "train":
            context_dataset = train_dataset
        elif config.contextualized_calibrate.use_split == "valid":
            context_dataset = valid_dataset
        elif <a id="change">config.contextualized_calibrate.use_split is None and config.contextualized_calibrate.num_example is not None</a>:
            sampler = FewShotSampler(num_examples_total=config.contextualized_calibrate.num_example,
                                also_sample_dev=False)
            context_dataset = sampler(train_dataset)</code></pre><h3>After Change</h3><pre><code class='java'>
        logits = prompt_model.forward_without_verbalize(batch)
        all_logits.append(logits.detach())
    all_logits = torch.cat(all_logits, dim=0)
    return <a id="change">all_logits.mean(dim=0)</a>


&#47&#47 def calibrate(model: PromptForClassification, calibrate_method: str=None, config: CfgNode =None , train_dataset: Optional[List]=None, valid_dataset: Optional[List]=None):
&#47&#47     rCalibrate the PromptForClassification model. Select and run the calibrate using the global config node.</code></pre>