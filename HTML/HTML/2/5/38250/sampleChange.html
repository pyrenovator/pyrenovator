<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        kfe_x = state[&quotkfe_x&quot]
        kfe_gy = state[&quotkfe_gy&quot]
        m2 = state[&quotm2&quot]
        g<a id="change"> = </a>weight_grad
        s = g.shape

        bs = self.state[mod][&quotx&quot].size(0)

        if bias_grad is not None:
            gb = bias_grad.view(-1, 1, 1, 1).expand(-1, -1, s[2], s[3])
            g = torch.cat([g, gb], dim=1)

        g_kfe = self._to_kfe_sua(g, kfe_x, kfe_gy)
        m2.mul_(self.alpha).add_((1. - self.alpha) * bs, g_kfe ** 2)
        g_nat_kfe = g_kfe / (m2 + self.eps)
        g_nat = self._to_kfe_sua(g_nat_kfe, kfe_x.t(), kfe_gy.t())
        if bias_grad is not None:
            gb = g_nat[:, -1, s[2] // 2, s[3] // 2]
            &#47&#47 bias.grad.data = gb
            g_nat = g_nat[:, :-1]
        &#47&#47 weight.grad.data = g_nat

        <a id="change">return </a>g_nat.contiguous()<a id="change">, gb.contiguous()</a>

    def _precond_intra_sua(self, group: dict[str, Union[LayerType, Iterable[torch.Tensor]]], weight_grad: torch.Tensor, bias_grad: Optional[torch.Tensor],
                           ) -&gt; tuple[torch.Tensor, Optional[torch.Tensor]]:
        Preconditioning for KFAC SUA.</code></pre><h3>After Change</h3><pre><code class='java'>
        if gb is not None:
            gb = g[:, -1, s[2] // 2, s[3] // 2].contiguous()  &#47&#47 (out)
            g = g[:, :-1]  &#47&#47 (out, in, kh, kw)
        g<a id="change"> = </a><a id="change">g.contiguous()</a>
        return g, gb

    def _precond_intra_sua(self, mod: nn.Conv2d, weight_grad: torch.Tensor,
                           bias_grad: Optional[torch.Tensor]</code></pre>