<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 Forward through models
    target = trans(example_clip)

    outputs = <a id="change">[]</a>
    &#47&#47 Manual zero pad (due to padding=1 in trans.b Conv3d)
    zeros = <a id="change">torch.zeros_like(example_clip[:, :, 0]</a><a id="change">)</a>
    <a id="change">outputs.append(cotrans</a><a id="change">.forward(</a>zeros<a id="change">))</a>
    <a id="change">for </a><a id="change">i</a> in <a id="change">range(example_clip.shape[2]</a><a id="change">):
        </a><a id="change">outputs.append(cotrans</a><a id="change">.forward(example_clip</a>[:, :, <a id="change">i</a>]<a id="change">))</a>
    <a id="change">outputs.append(cotrans.forward(</a>zeros<a id="change">)</a><a id="change">)</a>
    <a id="change">outputs.append(cotrans</a><a id="change">.forward(</a>zeros<a id="change">))</a>
    <a id="change">outputs.append(cotrans.forward(</a>zeros<a id="change">)</a><a id="change">)</a>

    &#47&#47 For debugging:
    &#47&#47 close = []
    &#47&#47 for t in range(target.shape[2]):</code></pre><h3>After Change</h3><pre><code class='java'>


def test_ResBlock():
    sample = <a id="change">torch.randn(</a>(<a id="change">1</a><a id="change">, 2, 4, 4, 4</a>)<a id="change">)</a>

    &#47&#47 Regular block
    trans = ResBlock(
        dim_in=2,
        dim_out=2,
        temp_kernel_size=3,
        stride=2,
        trans_func=X3DTransform,
        dim_inner=5,
        num_groups=1,
        stride_1x1=False,
        inplace_relu=True,
        eps=1e-5,
        bn_mmt=0.1,
        dilation=1,
        norm_module=torch.nn.BatchNorm3d,
        block_idx=0,
        drop_connect_rate=0.0,
    )

    &#47&#47 Converted block
    <a id="change">cotrans</a> = CoResBlock(
        dim_in=2,
        dim_out=2,
        temp_kernel_size=3,
        stride=2,
        trans_func=CoX3DTransform,
        dim_inner=5,
        num_groups=1,
        stride_1x1=False,
        inplace_relu=True,
        eps=1e-5,
        bn_mmt=0.1,
        dilation=1,
        norm_module=torch.nn.BatchNorm3d,
        block_idx=0,
        drop_connect_rate=0.0,
        temporal_window_size=sample.shape[2],
        temporal_fill="zeros",
        se_scope="clip",
    )
    cotrans.load_state_dict(trans.state_dict(), flatten=True)

    &#47&#47 Training mode has large effect on BatchNorm result - test will fail otherwise
    trans.eval()
    cotrans.eval()

    &#47&#47 Forward through models
    target = trans.forward(sample)

    &#47&#47 forward
    output = <a id="change">cotrans.forward(</a>sample<a id="change">)</a>
    assert torch.allclose(target, output)

    &#47&#47 Broken up
    <a id="change">cotrans.clean_state()</a>
    nothing = cotrans.forward_steps(sample[:, :, :-1], pad_end=False)  &#47&#47 init
    assert isinstance(nothing, TensorPlaceholder)

    lasts = <a id="change">cotrans.forward_steps(</a><a id="change">sample[:, :, -1:], pad_end=True)</a>
    assert torch.allclose(lasts, target)


example_clip = torch.normal(mean=torch.zeros(2 * 4 * 4 * 4)).reshape((1, 2, 4, 4, 4))</code></pre>