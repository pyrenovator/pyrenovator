<html><h3>Pattern ID :19397
</h3><img src='63345158.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        output.sum().backward(go, False, True)
        grad = torch.ones(5, 5)

        <a id="change">self.assertTrue(torch</a><a id="change">.allclose(</a>x.grad, y + grad<a id="change">))</a>
        self.assertTrue(torch.allclose(y.grad, x + grad * 2))

        &#47&#47 Test with optional arg.
        x.grad.zero_()
        y.grad.zero_()
        z = torch.randn((5, 5), requires_grad=True)
        output = ops.custom.op_with_autograd(x, 2, y, z)
        self.assertTrue(output.allclose(x + 2 * y + x * y + z))

        go = torch.ones((), requires_grad=True)
        output.sum().backward(go, False, True)
        self.assertTrue(torch.allclose(x.grad, y + grad))
        <a id="change">self.assertTrue(torch.allclose(</a>y.grad, x + grad * 2<a id="change">)</a><a id="change">)</a>
        self.assertTrue(torch.allclose(z.grad, grad))

    def test_calling_custom_op_with_autograd_in_nograd_mode(self):
        with torch.no_grad():</code></pre><h3>After Change</h3><pre><code class='java'>
        output.sum().backward(go, False, True)
        grad = torch.ones(5, 5)

        <a id="change">self.assertEqual(</a>x.grad, y + grad<a id="change">)</a>
        self.assertEqual(y.grad, x + grad * 2)

        &#47&#47 Test with optional arg.
        x.grad.zero_()
        y.grad.zero_()
        z = torch.randn((5, 5), requires_grad=True)
        output = ops.custom.op_with_autograd(x, 2, y, z)
        self.assertTrue(output.allclose(x + 2 * y + x * y + z))

        go = torch.ones((), requires_grad=True)
        output.sum().backward(go, False, True)
        self.assertEqual(x.grad, y + grad)
        <a id="change">self.assertEqual(</a>y.grad, x + grad * 2<a id="change">)</a>
        self.assertEqual(z.grad, grad)

    def test_calling_custom_op_with_autograd_in_nograd_mode(self):
        with torch.no_grad():</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/57d4c6cf424892888866ed98551f769cb5656623#diff-21dc5a91dbd040d3bc107916d5770020e041e59f0596ceff20776ee6af539472L45' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63345158</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 57d4c6cf424892888866ed98551f769cb5656623</div><div id='time'> Time: 2021-08-25</div><div id='author'> Author: github.pmeier@posteo.de</div><div id='file'> File Name: test/custom_operator/test_custom_ops.py</div><div id='m_class'> M Class Name: TestCustomOperators</div><div id='n_method'> N Class Name: TestCustomOperators</div><div id='m_method'> M Method Name: test_calling_custom_op_with_autograd(1)</div><div id='n_method'> N Method Name: test_calling_custom_op_with_autograd(1)</div><div id='m_parent_class'> M Parent Class: TestCase</div><div id='n_parent_class'> N Parent Class: TestCase</div><div id='m_file'> M File Name: test/custom_operator/test_custom_ops.py</div><div id='n_file'> N File Name: test/custom_operator/test_custom_ops.py</div><div id='m_start'> M Start Line: 45</div><div id='m_end'> M End Line: 61</div><div id='n_start'> N Start Line: 45</div><div id='n_end'> N End Line: 61</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        output.sum().backward(go, False, True)
        grad = torch.ones(5, 5)

        <a id="change">self.assertTrue(</a><a id="change">torch.allclose(</a>x.grad, y + grad<a id="change">))</a>
        <a id="change">self.assertTrue(torch.allclose(</a>y.grad, x + grad * 2<a id="change">)</a><a id="change">)</a>

        &#47&#47 Test with optional arg.
        x.grad.zero_()
        y.grad.zero_()</code></pre><h3>After Change</h3><pre><code class='java'>
        output.sum().backward(go, False, True)
        grad = torch.ones(5, 5)

        <a id="change">self.assertEqual(</a>x.grad, y + grad<a id="change">)</a>
        <a id="change">self.assertEqual(</a>y.grad, x + grad * 2<a id="change">)</a>

        &#47&#47 Test with optional arg.
        x.grad.zero_()
        y.grad.zero_()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/57d4c6cf424892888866ed98551f769cb5656623#diff-21dc5a91dbd040d3bc107916d5770020e041e59f0596ceff20776ee6af539472L37' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63345159</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 57d4c6cf424892888866ed98551f769cb5656623</div><div id='time'> Time: 2021-08-25</div><div id='author'> Author: github.pmeier@posteo.de</div><div id='file'> File Name: test/custom_operator/test_custom_ops.py</div><div id='m_class'> M Class Name: TestCustomOperators</div><div id='n_method'> N Class Name: TestCustomOperators</div><div id='m_method'> M Method Name: test_calling_custom_op_with_autograd(1)</div><div id='n_method'> N Method Name: test_calling_custom_op_with_autograd(1)</div><div id='m_parent_class'> M Parent Class: TestCase</div><div id='n_parent_class'> N Parent Class: TestCase</div><div id='m_file'> M File Name: test/custom_operator/test_custom_ops.py</div><div id='n_file'> N File Name: test/custom_operator/test_custom_ops.py</div><div id='m_start'> M Start Line: 45</div><div id='m_end'> M End Line: 61</div><div id='n_start'> N Start Line: 45</div><div id='n_end'> N End Line: 61</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
			&quot0&quot: [None for _ in range(time_steps)]
		}
		hh_pred = SequentialModel._format_hidden_outputs_traces(hh_states)
		<a id="change">self.assertTrue(</a><a id="change">np.allclose(</a>hh_states_transposed[&quot0&quot], hh_pred[&quot0&quot]<a id="change">))</a>

		hh_states = {
			&quot0&quot: [None for _ in range(time_steps)]
		}
		hh_states_transposed = {
			&quot0&quot: [None for _ in range(time_steps)]
		}
		hh_pred = SequentialModel._format_hidden_outputs_traces(hh_states)
		<a id="change">self.assertTrue(np.allclose(</a>hh_states_transposed[&quot0&quot], hh_pred[&quot0&quot]<a id="change">)</a><a id="change">)</a>

</code></pre><h3>After Change</h3><pre><code class='java'>
			&quot0&quot: [None for _ in range(time_steps)]
		}
		hh_pred = SequentialModel._format_hidden_outputs_traces(hh_states)
		<a id="change">self.assertEqual(</a>hh_states_transposed[&quot0&quot],  hh_pred[&quot0&quot]<a id="change">)</a>

		hh_states = {
			&quot0&quot: [None for _ in range(time_steps)]
		}
		hh_states_transposed = {
			&quot0&quot: [None for _ in range(time_steps)]
		}
		hh_pred = SequentialModel._format_hidden_outputs_traces(hh_states)
		<a id="change">self.assertEqual(</a>hh_states_transposed[&quot0&quot], hh_pred[&quot0&quot]<a id="change">)</a>

	def test_init_transforms(self):
		&#47&#47 Test that the model is initialized with the default transforms with one layer
		model = SequentialModel(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neurotorch/neurotorch/commit/e47ce91adddebb5f659e8ea19c014c805cf33297#diff-0a8f5935c3f624b10184944f5daa76005cdcf0edb5dfb835f13f032022848114L292' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63345151</div><div id='project'> Project Name: neurotorch/neurotorch</div><div id='commit'> Commit Name: e47ce91adddebb5f659e8ea19c014c805cf33297</div><div id='time'> Time: 2022-07-13</div><div id='author'> Author: 50332514+JeremieGince@users.noreply.github.com</div><div id='file'> File Name: tests/test_sequential.py</div><div id='m_class'> M Class Name: TestSequential</div><div id='n_method'> N Class Name: TestSequential</div><div id='m_method'> M Method Name: test_format_hidden_outputs_traces(1)</div><div id='n_method'> N Method Name: test_format_hidden_outputs_traces(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: tests/test_sequential.py</div><div id='n_file'> N File Name: tests/test_sequential.py</div><div id='m_start'> M Start Line: 316</div><div id='m_end'> M End Line: 338</div><div id='n_start'> N Start Line: 372</div><div id='n_end'> N End Line: 394</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 test that it works
        input = torch.rand(1, 3, 224, 224)
        ref = resnet(input)
        <a id="change">self.assertTrue(torch.allclose(</a>r2(input), ref<a id="change">)</a><a id="change">)</a>

        &#47&#47 functions exist also to get at the private modules in each package
        torchvision = i.import_module("torchvision")

        f2 = BytesIO()
        &#47&#47 if we are doing transfer learning we might want to re-save
        &#47&#47 things that were loaded from a package.
        &#47&#47 We need to tell the exporter about any modules that
        &#47&#47 came from imported packages so that it can resolve
        &#47&#47 class names like torchvision.models.resnet.ResNet
        &#47&#47 to their source code.
        with PackageExporter(f2, importer=(i, sys_importer)) as e:
            &#47&#47 e.importers is a list of module importing functions
            &#47&#47 that by default contains importlib.import_module.
            &#47&#47 it is searched in order until the first success and
            &#47&#47 that module is taken to be what torchvision.models.resnet
            &#47&#47 should be in this code package. In the case of name collisions,
            &#47&#47 such as trying to save a ResNet from two different packages,
            &#47&#47 we take the first thing found in the path, so only ResNet objects from
            &#47&#47 one importer will work. This avoids a bunch of name mangling in
            &#47&#47 the source code. If you need to actually mix ResNet objects,
            &#47&#47 we suggest reconstructing the model objects using code from a single package
            &#47&#47 using functions like save_state_dict and load_state_dict to transfer state
            &#47&#47 to the correct code objects.
            e.intern("**")
            e.save_pickle("model", "model.pkl", r2)

        f2.seek(0)

        i2 = PackageImporter(f2)
        r3 = i2.load_pickle("model", "model.pkl")
        <a id="change">self.assertTrue(</a><a id="change">torch.allclose(</a>r3(input), ref<a id="change">))</a>

    @skipIfNoTorchVision
    def test_model_save(self):
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 test that it works
        input = torch.rand(1, 3, 224, 224)
        ref = resnet(input)
        <a id="change">self.assertEqual(</a>r2(input), ref<a id="change">)</a>

        &#47&#47 functions exist also to get at the private modules in each package
        torchvision = i.import_module("torchvision")

        f2 = BytesIO()
        &#47&#47 if we are doing transfer learning we might want to re-save
        &#47&#47 things that were loaded from a package.
        &#47&#47 We need to tell the exporter about any modules that
        &#47&#47 came from imported packages so that it can resolve
        &#47&#47 class names like torchvision.models.resnet.ResNet
        &#47&#47 to their source code.
        with PackageExporter(f2, importer=(i, sys_importer)) as e:
            &#47&#47 e.importers is a list of module importing functions
            &#47&#47 that by default contains importlib.import_module.
            &#47&#47 it is searched in order until the first success and
            &#47&#47 that module is taken to be what torchvision.models.resnet
            &#47&#47 should be in this code package. In the case of name collisions,
            &#47&#47 such as trying to save a ResNet from two different packages,
            &#47&#47 we take the first thing found in the path, so only ResNet objects from
            &#47&#47 one importer will work. This avoids a bunch of name mangling in
            &#47&#47 the source code. If you need to actually mix ResNet objects,
            &#47&#47 we suggest reconstructing the model objects using code from a single package
            &#47&#47 using functions like save_state_dict and load_state_dict to transfer state
            &#47&#47 to the correct code objects.
            e.intern("**")
            e.save_pickle("model", "model.pkl", r2)

        f2.seek(0)

        i2 = PackageImporter(f2)
        r3 = i2.load_pickle("model", "model.pkl")
        <a id="change">self.assertEqual(</a>r3(input), ref<a id="change">)</a>

    @skipIfNoTorchVision
    def test_model_save(self):
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/57d4c6cf424892888866ed98551f769cb5656623#diff-bb1928956a254940fbd73866942ecee697ca02d8809184cfa4071f2abe372a1aL32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63345162</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 57d4c6cf424892888866ed98551f769cb5656623</div><div id='time'> Time: 2021-08-25</div><div id='author'> Author: github.pmeier@posteo.de</div><div id='file'> File Name: test/package/test_model.py</div><div id='m_class'> M Class Name: ModelTest</div><div id='n_method'> N Class Name: ModelTest</div><div id='m_method'> M Method Name: test_resnet(1)</div><div id='n_method'> N Method Name: test_resnet(1)</div><div id='m_parent_class'> M Parent Class: PackageTestCase</div><div id='n_parent_class'> N Parent Class: PackageTestCase</div><div id='m_file'> M File Name: test/package/test_model.py</div><div id='n_file'> N File Name: test/package/test_model.py</div><div id='m_start'> M Start Line: 51</div><div id='m_end'> M End Line: 84</div><div id='n_start'> N Start Line: 51</div><div id='n_end'> N End Line: 84</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            if reduce_range:
                ref_scales = [s * 255 / 127 for s in ref_scales]
                ref_zero_points = [math.floor(z / 2) for z in ref_zero_points]
            <a id="change">self.assertTrue(torch.allclose(</a>qparams[0], torch.tensor(ref_scales, dtype=qparams[0].dtype)<a id="change">, atol=0.0001)</a><a id="change">)</a>
            if qscheme == torch.per_channel_affine_float_qparams:
                <a id="change">self.assertTrue(</a><a id="change">torch.allclose(</a>qparams[1], torch.tensor(ref_zero_points, dtype=qparams[1].dtype)<a id="change">, atol=1))</a>
            else:
                self.assertTrue(torch.allclose(qparams[1], torch.tensor(ref_zero_points, dtype=qparams[1].dtype)))

</code></pre><h3>After Change</h3><pre><code class='java'>
            if reduce_range:
                ref_scales = [s * 255 / 127 for s in ref_scales]
                ref_zero_points = [math.floor(z / 2) for z in ref_zero_points]
            <a id="change">self.assertEqual(</a>qparams[0], torch.tensor(ref_scales, dtype=qparams[0].dtype)<a id="change">, rtol=1e-5, atol=0.0001)</a>
            if qscheme == torch.per_channel_affine_float_qparams:
                <a id="change">self.assertEqual(</a>qparams[1], torch.tensor(ref_zero_points, dtype=qparams[1].dtype)<a id="change">, rtol=1e-5, atol=1)</a>
            else:
                self.assertEqual(qparams[1], torch.tensor(ref_zero_points, dtype=qparams[1].dtype))

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/57d4c6cf424892888866ed98551f769cb5656623#diff-6affba81f1d18fe02817e3db1d971bc58198c8cb59a7c39d7e5a276d47e1d24fL125' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63345163</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 57d4c6cf424892888866ed98551f769cb5656623</div><div id='time'> Time: 2021-08-25</div><div id='author'> Author: github.pmeier@posteo.de</div><div id='file'> File Name: test/quantization/core/test_workflow_module.py</div><div id='m_class'> M Class Name: TestObserver</div><div id='n_method'> N Class Name: TestObserver</div><div id='m_method'> M Method Name: test_per_channel_observers(5)</div><div id='n_method'> N Method Name: test_per_channel_observers(5)</div><div id='m_parent_class'> M Parent Class: QuantizationTestCase</div><div id='n_parent_class'> N Parent Class: QuantizationTestCase</div><div id='m_file'> M File Name: test/quantization/core/test_workflow_module.py</div><div id='n_file'> N File Name: test/quantization/core/test_workflow_module.py</div><div id='m_start'> M Start Line: 208</div><div id='m_end'> M End Line: 212</div><div id='n_start'> N Start Line: 208</div><div id='n_end'> N End Line: 212</div><BR>