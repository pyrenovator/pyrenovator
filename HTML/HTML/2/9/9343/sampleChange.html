<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        onnx.checker.check_model(onnx_model)
    except RuntimeError as e:
        opset_version=11
        <a id="change">if </a>"aten::upsample_bilinear2d" in e.args[0]:
            operator_export_type<a id="change"> = </a>torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK
            torch.onnx.export(model, dummy_input, onnx_file, verbose=True,
                              input_names=[ "input" ] , output_names=["output"],
                              opset_version = opset_version,
                              operator_export_type=operator_export_type)
            onnx_model<a id="change"> = </a>onnx.load(onnx_file)
            onnx.checker.check_model(onnx_model)
        else:
            <a id="change">raise </a>Exception(e)
    except Exception as e:
        raise Exception(e)
    if simplify:</code></pre><h3>After Change</h3><pre><code class='java'>
    
    convert torch model to tflite model using onnx
    
    <a id="change">if </a>type(input_shape[0]) == tuple:
        if check_model_is_cuda(model):
            dummy_input<a id="change"> = </a>tuple([torch.randn(ishape, device="cuda") for ishape in input_shape])
        else:
            dummy_input = tuple([torch.randn(ishape, device="cpu") for ishape in input_shape])
    elif type(input_shape) == tuple:
        if check_model_is_cuda(model):
            dummy_input = torch.randn(input_shape, device="cuda")
        else:
            dummy_input = torch.randn(input_shape, device="cpu")
    else:
        <a id="change">raise </a><a id="change">Exception("input_shape must be tuple"</a><a id="change">)</a>

    try:
        torch.onnx.export(model, dummy_input, onnx_file,
                          input_names=[ "input" ] , output_names=["output"])</code></pre>