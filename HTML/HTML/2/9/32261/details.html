<html><h3>Pattern ID :32261
</h3><img src='94381728.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>


def augment_hsv(img, hgain=0.015, sgain=0.7, vgain=0.4):
    r = np<a id="change">.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1</a>  &#47&#47 random gains
    hue, sat, val = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))
    dtype = img.dtype  &#47&#47 uint8

    x<a id="change"> = </a><a id="change">np.arange(</a>0, 256<a id="change">, dtype=np.int16)</a>
    lut_hue = ((x * r[0]) % 180).astype(dtype)
    lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)
    lut_val = np.clip(x * r[2], 0, 255).astype(dtype)

    img_hsv<a id="change"> = </a>cv2.merge(
        (cv2.LUT(hue, lut_hue)<a id="change">, cv2.LUT(sat, lut_sat), cv2.LUT(val, lut_val)</a>)
    ).astype(dtype)
    cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR, dst=img)  &#47&#47 no return needed
</code></pre><h3>After Change</h3><pre><code class='java'>

    hsv_augs = hsv_augs.astype(dtype)
    img_hsv[..., 0] = (img_hsv[..., 0] + hsv_augs[0]) % 180
    img_hsv[<a id="change">...</a><a id="change">, 1</a>] = np.clip(img_hsv[<a id="change">...</a><a id="change">, 1</a>] + hsv_augs[1], 0, 255)
    img_hsv[..., 2] = np.clip(img_hsv[..., 2] + hsv_augs[2], 0, 255)

    cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR, dst=img)  &#47&#47 no return needed</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/megvii-basedetection/yolox/commit/a5f629a6d28fcc3742ce9483698b3376ce457533#diff-8979574eb63a17c4616c1e9aa7ff1407320c861206351db916f74f3000ca41cdL22' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 94381728</div><div id='project'> Project Name: megvii-basedetection/yolox</div><div id='commit'> Commit Name: a5f629a6d28fcc3742ce9483698b3376ce457533</div><div id='time'> Time: 2021-10-13</div><div id='author'> Author: 35716746+LGD-Ti-fighting@users.noreply.github.com</div><div id='file'> File Name: yolox/data/data_augment.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: augment_hsv(4)</div><div id='n_method'> N Method Name: augment_hsv(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: yolox/data/data_augment.py</div><div id='n_file'> N File Name: yolox/data/data_augment.py</div><div id='m_start'> M Start Line: 22</div><div id='m_end'> M End Line: 33</div><div id='n_start'> N Start Line: 22</div><div id='n_end'> N End Line: 30</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        channel_dimension = dim_counts.most_common()[-1][0]
        assert dim_counts[channel_dimension] == 1, "This code assumes two spatial dimensions and one channels dimension"
        spatial_indicies = np.arange(len(self.observation_shape))[np.array(self.observation_shape) == spatial_dimension]
        channel_index<a id="change"> = </a><a id="change">np.arange(</a>len(self.observation_shape)<a id="change">)</a>[np.array(self.observation_shape) == channel_dimension].item()

        new_shape = (channel_dimension, spatial_dimension, spatial_dimension)
        required_permutation = (0<a id="change">, channel_index+1, spatial_indicies[0]+1, spatial_indicies[1]+1</a>) &#47&#47 +1 to account for batch
        self.observation_shape = new_shape
        self.observation_space = Box(shape=self.observation_shape, low=0, high=255, dtype=np.uint8)
        self.permutation_tuple<a id="change"> = </a>required_permutation

    def _tensorize(self, arr):
        </code></pre><h3>After Change</h3><pre><code class='java'>

    def _make_channels_first(self):
        &#47&#47 Assumes an image in form (C, H, W) or (H, W, C) with H = W != C
        x<a id="change">, y, z</a> = self.observation_shape
        if x != y and y == z:
            self.permutation_tuple = None
        else:
            assert x == y and x != z, "Can only handle square images in format (C, H, W) or (H, W, C)"
            self.observation_shape = (z<a id="change">, x, y</a>)
            self.observation_space = Box(shape=self.observation_shape, low=0, high=255, dtype=np.uint8)
            self.permutation_tuple = (0, 3, 1, 2)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/d1ad577e009bce6e87e589755c40d71337a0e2cd#diff-11bd63b8ace5530605783f45e027231fff8e98dafa1dbb5675fe0c042e1f07dbL92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 94381696</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: d1ad577e009bce6e87e589755c40d71337a0e2cd</div><div id='time'> Time: 2020-07-27</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: _make_channels_first(1)</div><div id='n_method'> N Method Name: _make_channels_first(1)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: algos/representation_learner.py</div><div id='n_file'> N File Name: algos/representation_learner.py</div><div id='m_start'> M Start Line: 95</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 103</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>


def augment_hsv(img, hgain=0.015, sgain=0.7, vgain=0.4):
    r = np<a id="change">.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1</a>  &#47&#47 random gains
    hue, sat, val = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))
    dtype = img.dtype  &#47&#47 uint8

    x<a id="change"> = </a><a id="change">np.arange(</a>0, 256<a id="change">, dtype=np.int16)</a>
    lut_hue = ((x * r[0]) % 180).astype(dtype)
    lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)
    lut_val = np.clip(x * r[2], 0, 255).astype(dtype)

    img_hsv<a id="change"> = </a>cv2.merge(
        (cv2.LUT(hue, lut_hue)<a id="change">, cv2.LUT(sat, lut_sat), cv2.LUT(val, lut_val)</a>)
    ).astype(dtype)
    cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR, dst=img)  &#47&#47 no return needed
</code></pre><h3>After Change</h3><pre><code class='java'>

    hsv_augs = hsv_augs.astype(dtype)
    img_hsv[..., 0] = (img_hsv[..., 0] + hsv_augs[0]) % 180
    img_hsv[..., 1] = np.clip(img_hsv[...<a id="change">, 1</a>] + hsv_augs[1], 0, 255)
    img_hsv[...<a id="change">, 2</a>] = np.clip(img_hsv[..., 2] + hsv_augs[2], 0, 255)

    cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR, dst=img)  &#47&#47 no return needed
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/megvii-basedetection/yolox/commit/a5f629a6d28fcc3742ce9483698b3376ce457533#diff-8979574eb63a17c4616c1e9aa7ff1407320c861206351db916f74f3000ca41cdL21' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 94381729</div><div id='project'> Project Name: megvii-basedetection/yolox</div><div id='commit'> Commit Name: a5f629a6d28fcc3742ce9483698b3376ce457533</div><div id='time'> Time: 2021-10-13</div><div id='author'> Author: 35716746+LGD-Ti-fighting@users.noreply.github.com</div><div id='file'> File Name: yolox/data/data_augment.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: augment_hsv(4)</div><div id='n_method'> N Method Name: augment_hsv(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: yolox/data/data_augment.py</div><div id='n_file'> N File Name: yolox/data/data_augment.py</div><div id='m_start'> M Start Line: 22</div><div id='m_end'> M End Line: 33</div><div id='n_start'> N Start Line: 22</div><div id='n_end'> N End Line: 30</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        channel_dimension = dim_counts.most_common()[-1][0]
        assert dim_counts[channel_dimension] == 1, "This code assumes two spatial dimensions and one channels dimension"
        spatial_indicies = np.arange(len(self.observation_shape))[np.array(self.observation_shape) == spatial_dimension]
        channel_index<a id="change"> = </a><a id="change">np.arange(</a>len(self.observation_shape)<a id="change">)</a>[np.array(self.observation_shape) == channel_dimension].item()

        new_shape = (channel_dimension, spatial_dimension, spatial_dimension)
        required_permutation = (0<a id="change">, channel_index+1, spatial_indicies[0]+1, spatial_indicies[1]+1</a>) &#47&#47 +1 to account for batch
        self.observation_shape = new_shape
        self.observation_space = Box(shape=self.observation_shape, low=0, high=255, dtype=np.uint8)
        self.permutation_tuple<a id="change"> = </a>required_permutation

    def _tensorize(self, arr):
        </code></pre><h3>After Change</h3><pre><code class='java'>

    def _make_channels_first(self):
        &#47&#47 Assumes an image in form (C, H, W) or (H, W, C) with H = W != C
        x<a id="change">, y, z</a> = self.observation_shape
        if x != y and y == z:
            self.permutation_tuple = None
        else:
            assert x == y and x != z, "Can only handle square images in format (C, H, W) or (H, W, C)"
            self.observation_shape = (z<a id="change">, x, y</a>)
            self.observation_space = Box(shape=self.observation_shape, low=0, high=255, dtype=np.uint8)
            self.permutation_tuple = (0, 3, 1, 2)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/f5cbb3623fa01457a4ce34acd05c35f1535ece6c#diff-11bd63b8ace5530605783f45e027231fff8e98dafa1dbb5675fe0c042e1f07dbL92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 94381735</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: f5cbb3623fa01457a4ce34acd05c35f1535ece6c</div><div id='time'> Time: 2020-07-27</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: _make_channels_first(1)</div><div id='n_method'> N Method Name: _make_channels_first(1)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: algos/representation_learner.py</div><div id='n_file'> N File Name: algos/representation_learner.py</div><div id='m_start'> M Start Line: 95</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 103</div><BR>