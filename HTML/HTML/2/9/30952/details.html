<html><h3>Pattern ID :30952
</h3><img src='91019852.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        tokens = tokens + rearrange(pos_emb, &quotn d -&gt; 1 n d&quot)

        text_embeds = self.text_transformer(tokens, mask = text_mask)
        <a id="change">return </a>text_embeds
</code></pre><h3>After Change</h3><pre><code class='java'>
        frame_embeddings = self.image_embedding(frame_indices_input)
        frame_embeddings = self.video_pos_emb(frame_embeddings) + frame_embeddings

        bos<a id="change"> = </a><a id="change">repeat(</a>self.video_bos, <a id="change">&quotd -&gt; b 1 d&quot</a><a id="change">, b = batch)</a>
        frame_embeddings = torch.cat((bos, frame_embeddings), dim = 1)
        frame_embeddings = self.video_transformer(frame_embeddings)

        logits<a id="change"> = </a>self.to_logits(frame_embeddings)

        if not return_loss:
            return logits

        loss<a id="change"> = </a>F.cross_entropy(<a id="change">rearrange(</a>logits, <a id="change">&quotb n c -&gt; b c n&quot</a><a id="change">)</a>, frame_indices)
        <a id="change">return </a>loss
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/nuwa-pytorch/commit/daeefa2be5de809f9003a5333dad62183cf819f7#diff-47b637f0a46bb7e4f245f382a9b47f0351b6a5fda8ab6476a0476b4677441eddL219' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 91019852</div><div id='project'> Project Name: lucidrains/nuwa-pytorch</div><div id='commit'> Commit Name: daeefa2be5de809f9003a5333dad62183cf819f7</div><div id='time'> Time: 2021-12-28</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: nuwa_pytorch/nuwa_pytorch.py</div><div id='m_class'> M Class Name: NUWA</div><div id='n_method'> N Class Name: NUWA</div><div id='m_method'> M Method Name: forward(1)</div><div id='n_method'> N Method Name: forward(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: nuwa_pytorch/nuwa_pytorch.py</div><div id='n_file'> N File Name: nuwa_pytorch/nuwa_pytorch.py</div><div id='m_start'> M Start Line: 219</div><div id='m_end'> M End Line: 227</div><div id='n_start'> N Start Line: 270</div><div id='n_end'> N End Line: 296</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        results_pairwise = rearrange(results_pairwise, &quotb h n d -&gt; b n (h d)&quot, h = h)

        results = torch.cat((results_scalar, results_pairwise), dim = -1)
        <a id="change">return </a>single_repr
</code></pre><h3>After Change</h3><pre><code class='java'>
        point_dist = (point_qk_diff ** 2).sum(dim = -2)

        point_weights = F.softplus(self.point_weights)
        point_weights<a id="change"> = </a><a id="change">repeat(</a>point_weights, <a id="change">&quoth -&gt; (b h) () () ()&quot</a><a id="change">, b = b)</a>

        attn_logits_points<a id="change"> = </a>-0.5 * (point_dist * point_weights).sum(dim = -1)

        &#47&#47 combine attn logits

        attn_logits = attn_logits_scalar + attn_logits_pairwise + attn_logits_points

        &#47&#47 mask

        if exists(mask):
            mask = rearrange(mask, &quotb i -&gt; b i ()&quot) * rearrange(mask, &quotb j -&gt; b () j&quot)
            mask_value = max_neg_value(attn_logits)
            attn_logits = attn_logits.masked_fill(~mask, mask_value)

        &#47&#47 attention

        attn = attn_logits.softmax(dim = - 1)

        &#47&#47 aggregate values

        results_scalar = einsum(&quotb i j, b j d -&gt; b i d&quot, attn, v_scalar)

        attn_with_heads = rearrange(attn, &quot(b h) i j -&gt; b h i j&quot, h = h)
        results_pairwise = einsum(&quotb h i j, b i j d -&gt; b h i d&quot, attn_with_heads, pairwise_repr)

        &#47&#47 aggregate point values

        results_points = einsum(&quotb i j, b j d c -&gt; b i d c&quot, attn, v_point)

        &#47&#47 merge back heads

        results_scalar = rearrange(results_scalar, &quot(b h) n d -&gt; b n (h d)&quot, h = h)
        results_pairwise = rearrange(results_pairwise, &quotb h n d -&gt; b n (h d)&quot, h = h)
        results_points<a id="change"> = </a><a id="change">rearrange(</a>results_points, <a id="change">&quot(b h) n d c -&gt; b n (h d c)&quot</a><a id="change">, h = h)</a>

        results = torch.cat((results_scalar, results_pairwise, results_points), dim = -1)
        <a id="change">return </a>self.to_out(results)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/invariant-point-attention/commit/50b83b2cd424d6d78992e69936604801c9ad9f39#diff-0da2273b318a8de68ee540d826cb25884d25cde25c8c908cdf65788b98c2aac3L75' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 91019887</div><div id='project'> Project Name: lucidrains/invariant-point-attention</div><div id='commit'> Commit Name: 50b83b2cd424d6d78992e69936604801c9ad9f39</div><div id='time'> Time: 2021-07-16</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: invariant_point_attention/invariant_point_attention.py</div><div id='m_class'> M Class Name: InvariantPointAttention</div><div id='n_method'> N Class Name: InvariantPointAttention</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: invariant_point_attention/invariant_point_attention.py</div><div id='n_file'> N File Name: invariant_point_attention/invariant_point_attention.py</div><div id='m_start'> M Start Line: 99</div><div id='m_end'> M End Line: 128</div><div id='n_start'> N Start Line: 87</div><div id='n_end'> N End Line: 148</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        image_embed_dim = self.image_embed_dim

        text_cond = self.get_text_cond(text)
        <a id="change">return </a>self.p_sample_loop((batch_size, image_embed_dim), text_cond = text_cond)

    def q_sample(self, x_start, t, noise=None):
        noise = default(noise, lambda: torch.randn_like(x_start))</code></pre><h3>After Change</h3><pre><code class='java'>
    def sample(self, text, num_samples_per_batch = 2):
        &#47&#47 in the paper, what they did was
        &#47&#47 sample 2 image embeddings, choose the top 1 similarity, as judged by CLIP
        text<a id="change"> = </a><a id="change">repeat(</a>text, <a id="change">&quotb ... -&gt; (b r) ...&quot</a><a id="change">, r = num_samples_per_batch)</a>

        batch_size = text.shape[0]
        image_embed_dim = self.image_embed_dim

        text_cond = self.get_text_cond(text)

        image_embeds<a id="change"> = </a>self.p_sample_loop((batch_size, image_embed_dim), text_cond = text_cond)
        text_embeds = text_cond[&quottext_embeds&quot]

        text_embeds = rearrange(text_embeds, &quot(b r) d -&gt; b r d&quot, r = num_samples_per_batch)
        image_embeds<a id="change"> = </a><a id="change">rearrange(</a>image_embeds, <a id="change">&quot(b r) d -&gt; b r d&quot</a><a id="change">, r = num_samples_per_batch)</a>

        text_image_sims = einsum(&quotb r d, b r d -&gt; b r&quot)
        top_sim_indices = text_image_sims.topk(k = 1).indices

        top_sim_indices = repeat(top_sim_indices, &quotb 1 -&gt; b d&quot, d = image_embed_dim)

        top_image_embeds = image_embeds.gather(1, top_sim_indices)
        <a id="change">return </a>top_image_embeds

    def q_sample(self, x_start, t, noise=None):
        noise = default(noise, lambda: torch.randn_like(x_start))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/d3cded3c6cd76eca7135f669a96658a244d0f49f#diff-038ecede954c29266888cb88e37cc06f61ba2433f8b5142c7b2b2cefde5ed0edL408' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 91019875</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: d3cded3c6cd76eca7135f669a96658a244d0f49f</div><div id='time'> Time: 2022-04-13</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: dalle2_pytorch/dalle2_pytorch.py</div><div id='m_class'> M Class Name: DiffusionPrior</div><div id='n_method'> N Class Name: DiffusionPrior</div><div id='m_method'> M Method Name: sample(3)</div><div id='n_method'> N Method Name: sample(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dalle2_pytorch/dalle2_pytorch.py</div><div id='n_file'> N File Name: dalle2_pytorch/dalle2_pytorch.py</div><div id='m_start'> M Start Line: 413</div><div id='m_end'> M End Line: 413</div><div id='n_start'> N Start Line: 408</div><div id='n_end'> N End Line: 430</div><BR>