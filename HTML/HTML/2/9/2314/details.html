<html><h3>Pattern ID :2314
</h3><img src='9867189.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            edge_weights = torch.ones(edge_index.size(1), dtype=torch.int,
                                      device=edge_index.device)
        else:
            edge_weights = np.ones(<a id="change">edge_index.shape[1]</a>, dtype=np.int)
    degree = weighted_degree(index, edge_weights, num_nodes=num_nodes)
    return edge_index, edge_weights / degree[index]
</code></pre><h3>After Change</h3><pre><code class='java'>

    if backend is torch_sparse:
        assert edge_weights is None
        deg<a id="change"> = </a>edge_index.sum(dim=dim).to(torch.float)
        deg_inv<a id="change"> = </a>deg.pow(-1.0)
        deg_inv[deg_inv == float(&quotinf&quot)]<a id="change"> = </a>0
        edge_index<a id="change"> = </a>deg_inv.view(-1, 1)<a id="change"> * </a>edge_index
        <a id="change">return </a>edge_index<a id="change">, None</a>

    index = edge_index[dim]
    degree = weighted_degree(index, edge_weights, num_nodes=num_nodes)
    return edge_index, edge_weights / degree[index]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/torchspatiotemporal/tsl/commit/f28e5a2fddc34eeb90a13c113512c8ab12b6138b#diff-06bf001f44c985548f88f63f6218b0ffef4949bcba885086f99529d813e75099L181' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9867189</div><div id='project'> Project Name: torchspatiotemporal/tsl</div><div id='commit'> Commit Name: f28e5a2fddc34eeb90a13c113512c8ab12b6138b</div><div id='time'> Time: 2022-07-20</div><div id='author'> Author: ivan.marisca@hotmail.it</div><div id='file'> File Name: tsl/ops/connectivity.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: normalize(4)</div><div id='n_method'> N Method Name: normalize(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tsl/ops/connectivity.py</div><div id='n_file'> N File Name: tsl/ops/connectivity.py</div><div id='m_start'> M Start Line: 181</div><div id='m_end'> M End Line: 187</div><div id='n_start'> N Start Line: 215</div><div id='n_end'> N End Line: 225</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            edge_weights = torch.ones(edge_index.size(1), dtype=torch.int,
                                      device=edge_index.device)
        else:
            edge_weights = np.ones(<a id="change">edge_index.shape[1]</a>, dtype=np.int)
    degree = weighted_degree(index, edge_weights, num_nodes=num_nodes)
    return edge_index, edge_weights / degree[index]
</code></pre><h3>After Change</h3><pre><code class='java'>

    if backend is torch_sparse:
        assert edge_weights is None
        deg<a id="change"> = </a>edge_index.sum(dim=dim).to(torch.float)
        deg_inv<a id="change"> = </a>deg.pow(-1.0)
        deg_inv[deg_inv == float(&quotinf&quot)]<a id="change"> = </a>0
        edge_index<a id="change"> = </a>deg_inv.view(-1, 1)<a id="change"> * </a>edge_index
        <a id="change">return </a>edge_index<a id="change">, None</a>

    index = edge_index[dim]
    degree = weighted_degree(index, edge_weights, num_nodes=num_nodes)
    return edge_index, edge_weights / degree[index]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/torchspatiotemporal/tsl/commit/50089afdf23de12eb6d11e9d5e7e64d949d45611#diff-06bf001f44c985548f88f63f6218b0ffef4949bcba885086f99529d813e75099L165' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9867186</div><div id='project'> Project Name: torchspatiotemporal/tsl</div><div id='commit'> Commit Name: 50089afdf23de12eb6d11e9d5e7e64d949d45611</div><div id='time'> Time: 2022-08-18</div><div id='author'> Author: ivan.marisca@hotmail.it</div><div id='file'> File Name: tsl/ops/connectivity.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: normalize(4)</div><div id='n_method'> N Method Name: normalize(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tsl/ops/connectivity.py</div><div id='n_file'> N File Name: tsl/ops/connectivity.py</div><div id='m_start'> M Start Line: 181</div><div id='m_end'> M End Line: 187</div><div id='n_start'> N Start Line: 215</div><div id='n_end'> N End Line: 225</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    @staticmethod
    def backward(ctx, grad_output):
        gamma = <a id="change">ctx.saved_tensors[0]</a>.item()
        grad_input = _discounted_cumsum_left_dispatcher(grad_output, gamma)
        return grad_input, None
</code></pre><h3>After Change</h3><pre><code class='java'>
        grad_input = _discounted_cumsum_left_dispatcher(grad_output, gamma)
        grad_gamma = None
        if output is not None:
            z<a id="change"> = </a>_discounted_cumsum_right_dispatcher(output, gamma)
            z<a id="change"> = </a>z[:, 1:]
            dLdy<a id="change"> = </a>grad_output[:, :-1]
            grad_gamma<a id="change"> = </a>(z<a id="change"> * </a>dLdy).sum(dim=1)
        <a id="change">return </a>grad_input<a id="change">, grad_gamma, None</a>


def discounted_cumsum_left(input, gamma):
    if not torch.is_tensor(gamma):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/toshas/torch-discounted-cumsum/commit/beef5a507ac68bf6811c9f59a0fd9200dd1ca451#diff-376b6efa6d2393bf0cdfd24bd5377aa16b83bd25838d8b35d453e87e052d311eL88' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9867184</div><div id='project'> Project Name: toshas/torch-discounted-cumsum</div><div id='commit'> Commit Name: beef5a507ac68bf6811c9f59a0fd9200dd1ca451</div><div id='time'> Time: 2021-08-28</div><div id='author'> Author: anton.obukhov@gmail.com</div><div id='file'> File Name: torch_discounted_cumsum/discounted_cumsum.py</div><div id='m_class'> M Class Name: DiscountedCumSumRightFunction</div><div id='n_method'> N Class Name: DiscountedCumSumRightFunction</div><div id='m_method'> M Method Name: backward(2)</div><div id='n_method'> N Method Name: backward(2)</div><div id='m_parent_class'> M Parent Class: torch.autograd.Function</div><div id='n_parent_class'> N Parent Class: torch.autograd.Function</div><div id='m_file'> M File Name: torch_discounted_cumsum/discounted_cumsum.py</div><div id='n_file'> N File Name: torch_discounted_cumsum/discounted_cumsum.py</div><div id='m_start'> M Start Line: 89</div><div id='m_end'> M End Line: 91</div><div id='n_start'> N Start Line: 99</div><div id='n_end'> N End Line: 107</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    @staticmethod
    def backward(ctx, grad_output):
        gamma = <a id="change">ctx.saved_tensors[0]</a>.item()
        grad_input = _discounted_cumsum_right_dispatcher(grad_output, gamma)
        return grad_input, None
</code></pre><h3>After Change</h3><pre><code class='java'>
        grad_input = _discounted_cumsum_right_dispatcher(grad_output, gamma)
        grad_gamma = None
        if output is not None:
            z<a id="change"> = </a>_discounted_cumsum_left_dispatcher(output, gamma)
            z<a id="change"> = </a>z[:, :-1]
            dLdy<a id="change"> = </a>grad_output[:, 1:]
            grad_gamma<a id="change"> = </a>(z<a id="change"> * </a>dLdy).sum(dim=1)
        <a id="change">return </a>grad_input<a id="change">, grad_gamma, None</a>


class DiscountedCumSumRightFunction(torch.autograd.Function):
    @staticmethod</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/toshas/torch-discounted-cumsum/commit/beef5a507ac68bf6811c9f59a0fd9200dd1ca451#diff-376b6efa6d2393bf0cdfd24bd5377aa16b83bd25838d8b35d453e87e052d311eL74' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9867181</div><div id='project'> Project Name: toshas/torch-discounted-cumsum</div><div id='commit'> Commit Name: beef5a507ac68bf6811c9f59a0fd9200dd1ca451</div><div id='time'> Time: 2021-08-28</div><div id='author'> Author: anton.obukhov@gmail.com</div><div id='file'> File Name: torch_discounted_cumsum/discounted_cumsum.py</div><div id='m_class'> M Class Name: DiscountedCumSumLeftFunction</div><div id='n_method'> N Class Name: DiscountedCumSumLeftFunction</div><div id='m_method'> M Method Name: backward(2)</div><div id='n_method'> N Method Name: backward(2)</div><div id='m_parent_class'> M Parent Class: torch.autograd.Function</div><div id='n_parent_class'> N Parent Class: torch.autograd.Function</div><div id='m_file'> M File Name: torch_discounted_cumsum/discounted_cumsum.py</div><div id='n_file'> N File Name: torch_discounted_cumsum/discounted_cumsum.py</div><div id='m_start'> M Start Line: 75</div><div id='m_end'> M End Line: 77</div><div id='n_start'> N Start Line: 79</div><div id='n_end'> N End Line: 87</div><BR>