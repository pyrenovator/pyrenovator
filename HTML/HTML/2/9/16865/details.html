<html><h3>Pattern ID :16865
</h3><img src='56462077.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

def predict(model: nn.Module, *args, **kwargs):
    Makes predictions on a dataset using a single model. See `predict_ensemble` for `args` and `kwargs`.
    <a id="change">return </a>predict_ensemble([model], *args, **kwargs)


def evaluate_ensemble(models: Iterable[nn.Module],</code></pre><h3>After Change</h3><pre><code class='java'>
    :return: A list of lists of predictions. The outer list is examples
    while the inner list is tasks.
    
    <a id="change">with torch.no_grad()</a><a id="change">:
        </a>model.eval()

        preds<a id="change"> = </a>[]
        <a id="change">for </a>i in range(0, len(smiles), batch_size)<a id="change">:
            &#47&#47 Prepare batch
            </a>mol_batch = smiles[i:i + batch_size]
            mol_batch = mol2graph(mol_batch, three_d=three_d)

            &#47&#47 Run model
            batch_preds<a id="change"> = </a>model(mol_batch)
            batch_preds<a id="change"> = </a>batch_preds.data.cpu().numpy()
            if scaler is not None:
                batch_preds = scaler.inverse_transform(batch_preds)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/aamini/chemprop/commit/e50c0d7ca760ff74261cbbd018bea81290599e59#diff-1ae5c6142982c466b6120408cea60c9e765c62ef258032b838fb5274077b166dL71' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 56462077</div><div id='project'> Project Name: aamini/chemprop</div><div id='commit'> Commit Name: e50c0d7ca760ff74261cbbd018bea81290599e59</div><div id='time'> Time: 2018-09-24</div><div id='author'> Author: swansonk.14@gmail.com</div><div id='file'> File Name: train_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: predict(5)</div><div id='n_method'> N Method Name: predict(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_utils.py</div><div id='n_file'> N File Name: train_utils.py</div><div id='m_start'> M Start Line: 117</div><div id='m_end'> M End Line: 119</div><div id='n_start'> N Start Line: 71</div><div id='n_end'> N End Line: 106</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

def predict(model: nn.Module, *args, **kwargs):
    Makes predictions on a dataset using a single model. See `predict_ensemble` for `args` and `kwargs`.
    <a id="change">return </a>predict_ensemble([model], *args, **kwargs)


def evaluate_ensemble(models: Iterable[nn.Module],</code></pre><h3>After Change</h3><pre><code class='java'>
    :return: A list of lists of predictions. The outer list is examples
    while the inner list is tasks.
    
    <a id="change">with torch.no_grad()</a><a id="change">:
        </a>model.eval()

        preds<a id="change"> = </a>[]
        <a id="change">for </a><a id="change">i</a> in range(0, len(smiles), batch_size)<a id="change">:
            &#47&#47 Prepare batch
            </a>mol_batch = smiles[i:i + batch_size]
            mol_batch = mol2graph(mol_batch, three_d=three_d)

            &#47&#47 Run model
            batch_preds<a id="change"> = </a>model(mol_batch)
            batch_preds = batch_preds.data.cpu().numpy()
            if scaler is not None:
                batch_preds<a id="change"> = </a>scaler.inverse_transform(batch_preds)

            preds.extend(batch_preds.tolist())
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/aamini/chemprop/commit/e50c0d7ca760ff74261cbbd018bea81290599e59#diff-1ae5c6142982c466b6120408cea60c9e765c62ef258032b838fb5274077b166dL117' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 56462076</div><div id='project'> Project Name: aamini/chemprop</div><div id='commit'> Commit Name: e50c0d7ca760ff74261cbbd018bea81290599e59</div><div id='time'> Time: 2018-09-24</div><div id='author'> Author: swansonk.14@gmail.com</div><div id='file'> File Name: train_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: predict(5)</div><div id='n_method'> N Method Name: predict(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_utils.py</div><div id='n_file'> N File Name: train_utils.py</div><div id='m_start'> M Start Line: 117</div><div id='m_end'> M End Line: 119</div><div id='n_start'> N Start Line: 71</div><div id='n_end'> N End Line: 106</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            [fn(pred, y) for fn in self.metric_fns]
        result = {type(fn).__name__: fn.compute().item() for fn in self.metric_fns}
        [fn.reset() for fn in self.metric_fns]
        <a id="change">return </a>result
</code></pre><h3>After Change</h3><pre><code class='java'>
        num_batches = 0
        sklearn_intermediates = dict()
        results = dict()
        <a id="change">with torch.no_grad()</a><a id="change">:
            </a>for _, (X, y) in enumerate(test_iterable_ds):
                X = X.to(self.device)
                y = y.to(self.device)
                num_batches<a id="change"> += </a>1
                pred = self.model(X)
                <a id="change">for </a><a id="change">fn</a> in self.metric_fns<a id="change">:
                    </a>if get_package_name(fn) == "torchmetrics":
                        fn(pred, y.int())
                    elif get_package_name(fn) == "sklearn":
                        if type(fn).__name__ not in sklearn_intermediates:
                            sklearn_intermediates[fn.__name__]<a id="change"> = </a>0
                        sklearn_intermediates[fn.__name__]<a id="change"> += </a>fn(
                            y.cpu().data.numpy(), pred.cpu().data.numpy())
        &#47&#47 torchmetrics compute and reset
        for fn in self.metric_fns:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ryantd/veloce/commit/aca7bbb15fbcbae885dd418e7ff969ad4828703e#diff-10a63a56f6f260c3a8cc88a30331e16de36e33f42ccd316cb27d96f83f790d53L125' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 56462110</div><div id='project'> Project Name: ryantd/veloce</div><div id='commit'> Commit Name: aca7bbb15fbcbae885dd418e7ff969ad4828703e</div><div id='time'> Time: 2022-01-04</div><div id='author'> Author: xiaoyu.zhai@hotmail.com</div><div id='file'> File Name: phetware/epochvisor.py</div><div id='m_class'> M Class Name: Epochvisor</div><div id='n_method'> N Class Name: Epochvisor</div><div id='m_method'> M Method Name: test_epoch(2)</div><div id='n_method'> N Method Name: test_epoch(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: phetware/epochvisor.py</div><div id='n_file'> N File Name: phetware/epochvisor.py</div><div id='m_start'> M Start Line: 126</div><div id='m_end'> M End Line: 133</div><div id='n_start'> N Start Line: 128</div><div id='n_end'> N End Line: 154</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    ) -&gt; Awaitable[SparseFeaturesList]:
        lengths_awaitables = self.lengths_dist(ctx, features)
        indices_awaitables = lengths_awaitables.wait()
        <a id="change">return </a>SparseFeaturesListAwaitable(indices_awaitables)

    def compute(
        self, ctx: EmbeddingCollectionContext, dist_input: SparseFeaturesList</code></pre><h3>After Change</h3><pre><code class='java'>
        if self._has_uninitialized_input_dist:
            self._create_input_dist(input_feature_names=features.keys())
            self._has_uninitialized_input_dist = False
        <a id="change">with torch.no_grad()</a><a id="change">:
            </a>if self._features_order:
                features = features.permute(
                    self._features_order,
                    &#47&#47 pyre-ignore [6]
                    self._features_order_tensor,
                )
            features_by_shards = features.split(
                self._feature_splits,
            )
            &#47&#47 save input splits and output splits in sharding context which
            &#47&#47 will be reused in sequence embedding all2all
            awaitables<a id="change"> = </a>[]
            <a id="change">for </a>module, <a id="change">features</a> in zip(self._input_dists, features_by_shards)<a id="change">:
                </a>lengths_awaitable<a id="change"> = </a>module(
                    SparseFeatures(
                        id_list_features=features,
                        id_score_list_features=None,
                    )
                )
                indices_awaitable<a id="change"> = </a>lengths_awaitable.wait()  &#47&#47 finish lengths all2all
                input_splits = []
                output_splits = []
                if isinstance(indices_awaitable, SparseFeaturesIndicesAwaitable):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/facebookresearch/torchrec/commit/6fa750ebd120bb5381c9428a62f3646e99dca7ef#diff-ef14f956164adafc139f5a6d4554edaf589f8e92ac501cad851bb9db40d0e315L533' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 56462104</div><div id='project'> Project Name: facebookresearch/torchrec</div><div id='commit'> Commit Name: 6fa750ebd120bb5381c9428a62f3646e99dca7ef</div><div id='time'> Time: 2022-10-11</div><div id='author'> Author: xingl@meta.com</div><div id='file'> File Name: torchrec/distributed/embedding.py</div><div id='m_class'> M Class Name: ShardedEmbeddingCollection</div><div id='n_method'> N Class Name: ShardedEmbeddingCollection</div><div id='m_method'> M Method Name: input_dist(3)</div><div id='n_method'> N Method Name: input_dist(3)</div><div id='m_parent_class'> M Parent Class: FusedOptimizerModule,Subscript</div><div id='n_parent_class'> N Parent Class: FusedOptimizerModule,Subscript</div><div id='m_file'> M File Name: torchrec/distributed/embedding.py</div><div id='n_file'> N File Name: torchrec/distributed/embedding.py</div><div id='m_start'> M Start Line: 538</div><div id='m_end'> M End Line: 540</div><div id='n_start'> N Start Line: 538</div><div id='n_end'> N End Line: 587</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>


        &#47&#47 batch mean of squared norms of per-panel final points:
        <a id="change">return </a>F.mse_loss(predicted_panels, chosen_panels)
        

&#47&#47 ------- custom quality metrics --------</code></pre><h3>After Change</h3><pre><code class='java'>
        
        chosen_panels = []
        &#47&#47 choose the closest version of original panel for each predicted panel
        <a id="change">with torch.no_grad()</a><a id="change">:
            </a>for el_id in range(predicted_panels.shape[0]):
                num_edges = panel_len_from_padded(gt_panels[el_id], empty_template=self.empty_panel_template)

                &#47&#47 all rotations of GT
                &#47&#47 TODO Faster version? -- I think I already did smth like this somewhere
                shifted_gt_panel = gt_panels[el_id]
                min_dist = ((predicted_panels[el_id] - shifted_gt_panel) ** 2).sum()
                chosen_panel<a id="change"> = </a>shifted_gt_panel
                <a id="change">for </a><a id="change">i</a> in range(1, num_edges)<a id="change">:
                    </a>shifted_gt_panel<a id="change"> = </a>self._rotate_edges(shifted_gt_panel, num_edges)
                    dist<a id="change"> = </a>((predicted_panels[el_id] - shifted_gt_panel) ** 2).sum()
                    if dist &lt; min_dist:
                        min_dist = dist
                        chosen_panel = shifted_gt_panel</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/maria-korosteleva/garment-pattern-estimation/commit/d5249e2d1149a36a28f875d31d10930c53b178d0#diff-66aae7ec57f079963bb4847ebb79bfda4004ba832ee23e11911a14908193967cL222' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 56462096</div><div id='project'> Project Name: maria-korosteleva/garment-pattern-estimation</div><div id='commit'> Commit Name: d5249e2d1149a36a28f875d31d10930c53b178d0</div><div id='time'> Time: 2021-04-13</div><div id='author'> Author: mariako@kaist.ac.kr</div><div id='file'> File Name: nn/metrics.py</div><div id='m_class'> M Class Name: PanelShapeOriginAgnosticLoss</div><div id='n_method'> N Class Name: PanelShapeOriginAgnosticLoss</div><div id='m_method'> M Method Name: __call__(3)</div><div id='n_method'> N Method Name: __call__(3)</div><div id='m_parent_class'> M Parent Class: PanelLoopLoss</div><div id='n_parent_class'> N Parent Class: PanelLoopLoss</div><div id='m_file'> M File Name: nn/metrics.py</div><div id='n_file'> N File Name: nn/metrics.py</div><div id='m_start'> M Start Line: 229</div><div id='m_end'> M End Line: 245</div><div id='n_start'> N Start Line: 228</div><div id='n_end'> N End Line: 261</div><BR>