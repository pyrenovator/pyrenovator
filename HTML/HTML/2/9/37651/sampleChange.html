<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        log_p_x_z = ((recons - input) ** 2).flatten(1).mean(-1)
        pi = torch.tensor(np.pi, dtype=torch.float)
        E_log_q_z = torch.sum(-0.5 * (eps ** 2) - 0.5 * torch.log(<a id="change">2</a><a id="change"> * </a>pi) - log_var, dim = 1)

        E_log_p_z = torch.sum(-0.5 * (z ** 2) - 0.5 * <a id="change">torch.log(2</a><a id="change"> * </a>pi<a id="change">)</a>, dim = 1)

        &#47&#47 Get importance weights
        log_weight = (recons_loss + E_log_p_z - E_log_q_z).detach().data
        weight = F.softmax(log_weight, dim = 0)

        kld_loss = torch.mean(E_log_q_z<a id="change"> - </a>E_log_p_z, dim = 0) &#47&#47torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)

        loss = torch.sum(weight * (recons_loss + kld_weight * kld_loss), dim = 0)

        return {&quotloss&quot: loss, &quotReconstruction Loss&quot:recons_loss.mean(0), &quotKLD&quot:<a id="change">-kld_loss</a>}

    def sample(self, batch_size:int, current_device: int) -&gt; Tensor:
        z = torch.randn(batch_size,</code></pre><h3>After Change</h3><pre><code class='java'>
        z = args[4]
        eps = args[5]

        input<a id="change"> = </a>input.repeat(self.num_samples, 1, 1, 1, 1).permute(1, 0, 2, 3, 4) &#47&#47[B x S x C x H x W]

        kld_weight = kwargs[&quotM_N&quot] &#47&#47 Account for the minibatch samples from the dataset

        log_p_x_z = ((recons - input) ** 2).flatten(2).mean(-1) &#47&#47 Reconstruction Loss
        kld_loss = -0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim=2)
        &#47&#47 Get importance weights
        log_weight = (log_p_x_z + kld_weight * kld_loss) &#47&#47.detach().data

        &#47&#47 Rescale the weights (along the sample dim) to lie in [0, 1] and sum to 1
        weight = F.softmax(log_weight, dim = -1)
        &#47&#47 kld_loss = torch.mean(kld_loss, dim = 0)
        &#47&#47 loss = log_p_x_z.mean(0) + kld_weight * kld_loss

        loss = torch.mean(torch.sum(weight * log_weight, dim=-1), dim = 0)

        return {&quotloss&quot: loss, &quotReconstruction Loss&quot:<a id="change">log_p_x_z.mean()</a>, &quotKLD&quot:-kld_loss.mean()}

    def sample(self,
               num_samples:int,</code></pre>