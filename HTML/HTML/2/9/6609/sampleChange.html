<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    normalization = None
    bias = True

    x<a id="change">, edge_index</a> = create_mock_data(node_count, edge_per_node, node_features)
    model = ASTGCN(nb_block, node_features, K, nb_chev_filter, nb_time_filter, nb_time_strides, num_for_predict, 
            len_input, node_count, normalization, bias).to(device)
    model2 = ASTGCN(nb_block, node_features, K, nb_chev_filter, nb_time_filter, nb_time_strides, num_for_predict, </code></pre><h3>After Change</h3><pre><code class='java'>
    Testing ASTGCN block and its component ChebConvAttention with changing edge index over time or not
    
    in_channels, out_channels = (16, 32)
    batch_size<a id="change"> = </a>3
    edge_index<a id="change"> = </a><a id="change">torch.tensor(</a>[[0, 0, 0, 1, 2, 3], <a id="change">[</a>1, <a id="change">2</a>, <a id="change">3</a>, 0, <a id="change">0</a>, 0<a id="change"></a>]]<a id="change">)</a>
    num_nodes = edge_index.max().item() + 1
    edge_weight = torch.rand(edge_index.size(1))
    x = torch.randn((batch_size, num_nodes, in_channels))
    attention = torch.nn.functional.softmax(torch.rand((batch_size, num_nodes, num_nodes)), dim=1)

    conv = ChebConvAttention(in_channels, out_channels, K=3, normalization=&quotsym&quot)
    out1 = conv(x, edge_index, attention)
    assert out1.size() == (batch_size, num_nodes, out_channels)
    out2<a id="change"> = </a>conv(x, edge_index, attention, edge_weight)
    assert out2.size() == (batch_size, num_nodes, out_channels)
    out3 = conv(x, edge_index, attention, edge_weight, lambda_max=3.0)
    assert out3.size() == (batch_size, num_nodes, out_channels)</code></pre>