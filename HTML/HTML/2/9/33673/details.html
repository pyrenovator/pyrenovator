<html><h3>Pattern ID :33673
</h3><img src='96917255.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        return min_slot_id

    def _find_free_cuda_slot(self) -&gt; int:
        <a id="change">for slot_idx</a> in <a id="change">range(</a>self.cuda_chunk_num<a id="change">):
            if slot_idx not in self.cached_chunk_table</a>:
                return slot_idx
        return -1
</code></pre><h3>After Change</h3><pre><code class='java'>
    def _find_free_cuda_slot(self) -&gt; int:
        if self._cuda_available_chunk_num == 0:
            return -1
        candidates<a id="change"> = </a><a id="change">torch.nonzero(self.cached_chunk_table[:, 0] == -1).squeeze(1</a><a id="change">)</a>
        <a id="change">return </a>candidates[0].item()

    @torch.no_grad()
    def _admit(self, chunk_id: int):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/hpcaitech/cachedembedding/commit/5b9995175361069d8eaa507674a59791f722761a#diff-aab5f7e7e049810d29a74e3eab12af668892a81357998cc464ab0f8cd2272767L233' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 96917255</div><div id='project'> Project Name: hpcaitech/cachedembedding</div><div id='commit'> Commit Name: 5b9995175361069d8eaa507674a59791f722761a</div><div id='time'> Time: 2022-07-26</div><div id='author'> Author: 34452939+zxgx@users.noreply.github.com</div><div id='file'> File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='m_class'> M Class Name: ChunkParamMgr</div><div id='n_method'> N Class Name: ChunkParamMgr</div><div id='m_method'> M Method Name: _find_free_cuda_slot(1)</div><div id='n_method'> N Method Name: _find_free_cuda_slot(1)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='n_file'> N File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='m_start'> M Start Line: 244</div><div id='m_end'> M End Line: 247</div><div id='n_start'> N Start Line: 233</div><div id='n_end'> N End Line: 236</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        y = self.fc_final(out)  &#47&#47 batch_size * state_len * loc_size
        score = F.log_softmax(y, dim=2)
        &#47&#47 因为是补齐了的，所以需要找到真正的 score
        <a id="change">for i</a> in <a id="change">range(</a>score.shape[0]<a id="change">):
            if i == 0</a>:
                true_scores = score[i][loc_len[i] - 1].reshape(1, -1)
            else:
                true_scores = torch.cat(</code></pre><h3>After Change</h3><pre><code class='java'>
        final_out_index = torch.tensor(origin_len) - 1
        final_out_index = final_out_index.reshape(final_out_index.shape[0], 1, -1)
        final_out_index = final_out_index.repeat(1, 1, 2*self.hidden_size).to(self.device)
        out = <a id="change">torch.gather(out, 1, final_out_index).squeeze(1</a><a id="change">)</a>  &#47&#47 batch_size * (2*hidden_size)
        out = self.dropout(out)

        y = self.fc_final(out)  &#47&#47 batch_size * loc_size
        score<a id="change"> = </a>F.log_softmax(y, dim=1)
        <a id="change">return </a>score

    def predict(self, batch):
        return self.forward(batch)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/libcity/bigscity-libcity/commit/ec61c9cd984d1c86ee715380ed3b65b4222c8d1f#diff-e952722699ca3186325fca5947706a0f1eb9b447d1d51063beaddb3480efa998L117' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 96917260</div><div id='project'> Project Name: libcity/bigscity-libcity</div><div id='commit'> Commit Name: ec61c9cd984d1c86ee715380ed3b65b4222c8d1f</div><div id='time'> Time: 2021-05-06</div><div id='author'> Author: 33283819+WenMellors@users.noreply.github.com</div><div id='file'> File Name: trafficdl/model/trajectory_loc_prediction/DeepMove.py</div><div id='m_class'> M Class Name: DeepMove</div><div id='n_method'> N Class Name: DeepMove</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: AbstractModel</div><div id='n_parent_class'> N Parent Class: AbstractModel</div><div id='m_file'> M File Name: trafficdl/model/trajectory_loc_prediction/DeepMove.py</div><div id='n_file'> N File Name: trafficdl/model/trajectory_loc_prediction/DeepMove.py</div><div id='m_start'> M Start Line: 122</div><div id='m_end'> M End Line: 175</div><div id='n_start'> N Start Line: 152</div><div id='n_end'> N End Line: 163</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        score = F.log_softmax(y, dim=2)  &#47&#47 calculate loss by NLLoss
        &#47&#47 因为是补齐了的，所以需要找到真正的 score
        loc_len = batch.get_origin_len(&quotcurrent_loc&quot)
        <a id="change">for i</a> in <a id="change">range(</a>score.shape[0]<a id="change">):
            if i == 0</a>:
                true_scores = score[i][loc_len[i] - 1].reshape(1, -1)
            else:
                true_scores = torch.cat(</code></pre><h3>After Change</h3><pre><code class='java'>
        final_out_index = torch.tensor(origin_len) - 1
        final_out_index = final_out_index.reshape(final_out_index.shape[0], 1, -1)
        final_out_index = final_out_index.repeat(1, 1, self.hidden_size).to(self.device)
        out = <a id="change">torch.gather(out, 1, final_out_index).squeeze(1</a><a id="change">)</a>  &#47&#47 batch_size * hidden_size
        out = F.selu(out)
        out = self.dropout(out)

        y = self.fc(out)
        score<a id="change"> = </a>F.log_softmax(y, dim=1)  &#47&#47 calculate loss by NLLoss
        <a id="change">return </a>score

    def predict(self, batch):
        return self.forward(batch)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/libcity/bigscity-libcity/commit/ec61c9cd984d1c86ee715380ed3b65b4222c8d1f#diff-f7e6a5cf5965e29788168874ecb4a6a81ecf849824f4f08f81428bfb514f6906L60' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 96917258</div><div id='project'> Project Name: libcity/bigscity-libcity</div><div id='commit'> Commit Name: ec61c9cd984d1c86ee715380ed3b65b4222c8d1f</div><div id='time'> Time: 2021-05-06</div><div id='author'> Author: 33283819+WenMellors@users.noreply.github.com</div><div id='file'> File Name: trafficdl/model/trajectory_loc_prediction/RNN.py</div><div id='m_class'> M Class Name: RNN</div><div id='n_method'> N Class Name: RNN</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: AbstractModel</div><div id='n_parent_class'> N Parent Class: AbstractModel</div><div id='m_file'> M File Name: trafficdl/model/trajectory_loc_prediction/RNN.py</div><div id='n_file'> N File Name: trafficdl/model/trajectory_loc_prediction/RNN.py</div><div id='m_start'> M Start Line: 87</div><div id='m_end'> M End Line: 97</div><div id='n_start'> N Start Line: 84</div><div id='n_end'> N End Line: 94</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        return min_slot_id

    def _find_free_cuda_slot(self) -&gt; int:
        <a id="change">for slot_idx</a> in <a id="change">range(</a>self.cuda_chunk_num<a id="change">):
            if slot_idx not in self.cached_chunk_table</a>:
                return slot_idx
        return -1
</code></pre><h3>After Change</h3><pre><code class='java'>
    def _find_free_cuda_slot(self) -&gt; int:
        if self._cuda_available_chunk_num == 0:
            return -1
        candidates<a id="change"> = </a><a id="change">torch.nonzero(self.cached_chunk_table[:, 0] == -1).squeeze(1</a><a id="change">)</a>
        <a id="change">return </a>candidates[0].item()

    @torch.no_grad()
    def _admit(self, chunk_id: int):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hpcaitech/freqcacheembedding/commit/5b9995175361069d8eaa507674a59791f722761a#diff-aab5f7e7e049810d29a74e3eab12af668892a81357998cc464ab0f8cd2272767L243' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 96917257</div><div id='project'> Project Name: hpcaitech/freqcacheembedding</div><div id='commit'> Commit Name: 5b9995175361069d8eaa507674a59791f722761a</div><div id='time'> Time: 2022-07-26</div><div id='author'> Author: 34452939+zxgx@users.noreply.github.com</div><div id='file'> File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='m_class'> M Class Name: ChunkParamMgr</div><div id='n_method'> N Class Name: ChunkParamMgr</div><div id='m_method'> M Method Name: _find_free_cuda_slot(1)</div><div id='n_method'> N Method Name: _find_free_cuda_slot(1)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='n_file'> N File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='m_start'> M Start Line: 244</div><div id='m_end'> M End Line: 247</div><div id='n_start'> N Start Line: 233</div><div id='n_end'> N End Line: 236</div><BR>