<html><h3>Pattern ID :28337
</h3><img src='83661646.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    batched_outputs = self._force_decode(encoded_inputs)

    &#47&#47 Convert to numpy for post-processing ... this doesn&quott work for jax
    detached_outputs<a id="change"> = </a><a id="change">{k: v.numpy() for k, v in batched_outputs.items()}</a>
    &#47&#47 Instead of the above I am trying to implement something like this below for jax
    &#47&#47 ----&gt;
    &#47&#47 predict_answer_tokens = results.input_ids[0, answer_start_index : answer_end_index + 1]
    &#47&#47    &#47&#47 generates answer text</code></pre><h3>After Change</h3><pre><code class='java'>
        question.append(i[&quotquestion&quot])
        context.append(i[&quotcontext&quot])

    prediction = <a id="change">[]</a>
    <a id="change">for </a>i in range(len(inputs))<a id="change">:
        </a>model = FlaxBertForQuestionAnswering.from_pretrained("mrm8488/bert-multi-cased-finedtuned-xquad-tydiqa-goldp")
        inputs = self.tokenizer(question[i], context[i], return_tensors="jax",padding=True)
        outputs = model(**inputs)

        answer_start_index = outputs.start_logits.argmax()

        answer_end_index = outputs.end_logits.argmax()

        predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index<a id="change"> + </a>1]

        <a id="change">prediction.append(</a>self.tokenizer.decode(predict_answer_tokens)<a id="change">)</a>
    print(&quotPredictions for the data is----&gt;/n&quot)
    print(prediction)
    &#47&#47 returning list of prediction
    return prediction</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pair-code/lit/commit/c2fd433b7d7ee04e60dd117c3decc8e22ac42287#diff-e66e2ed65042046b3905d9bc4b44fa2c3bb19cb8c07da5a9540002725714fab0L134' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83661646</div><div id='project'> Project Name: pair-code/lit</div><div id='commit'> Commit Name: c2fd433b7d7ee04e60dd117c3decc8e22ac42287</div><div id='time'> Time: 2022-06-15</div><div id='author'> Author: 31214277+aryan1107@users.noreply.github.com</div><div id='file'> File Name: lit_nlp/examples/models/tydi.py</div><div id='m_class'> M Class Name: TydiModel</div><div id='n_method'> N Class Name: TydiModel</div><div id='m_method'> M Method Name: predict_minibatch(2)</div><div id='n_method'> N Method Name: predict_minibatch(2)</div><div id='m_parent_class'> M Parent Class: lit_model.Model</div><div id='n_parent_class'> N Parent Class: lit_model.Model</div><div id='m_file'> M File Name: lit_nlp/examples/models/tydi.py</div><div id='n_file'> N File Name: lit_nlp/examples/models/tydi.py</div><div id='m_start'> M Start Line: 186</div><div id='m_end'> M End Line: 203</div><div id='n_start'> N Start Line: 134</div><div id='n_end'> N End Line: 156</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                truncation_strategy="longest_first",
            )

            tensors<a id="change"> = </a><a id="change">{k: paddle.to_tensor(v) for (k, v) in features.items()}</a>

            with paddle.no_grad():
                if self.use_en:
                    similarity_scores = self.transformer_model.matching_v2(**tensors).numpy()</code></pre><h3>After Change</h3><pre><code class='java'>

        preds = []
        for cur_queries, cur_docs in batches:
            datasets = <a id="change">[]</a>
            <a id="change">for </a>query, <a id="change">doc</a> in zip(cur_queries, cur_docs)<a id="change">:
                </a>if self.embed_title:
                    <a id="change">datasets.append(</a>[query, doc.meta["name"]<a id="change"> + </a>doc.content]<a id="change">)</a>
                else:
                    datasets.append([query, doc.content])
            outputs = self.transformer_model(datasets)
            similarity_scores = [item["similarity"] for item in outputs]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/35be940d8e29d002d830da63c5923f63b0ec4d5d#diff-e4ecbdd7379c6bb54f6934b38056f91532487822cf4efec218b9a1369b9e3aceL129' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83661647</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 35be940d8e29d002d830da63c5923f63b0ec4d5d</div><div id='time'> Time: 2023-03-06</div><div id='author'> Author: w5688414@gmail.com</div><div id='file'> File Name: pipelines/pipelines/nodes/ranker/ernie_ranker.py</div><div id='m_class'> M Class Name: ErnieRanker</div><div id='n_method'> N Class Name: ErnieRanker</div><div id='m_method'> M Method Name: predict_batch(5)</div><div id='n_method'> N Method Name: predict_batch(5)</div><div id='m_parent_class'> M Parent Class: BaseRanker</div><div id='n_parent_class'> N Parent Class: BaseRanker</div><div id='m_file'> M File Name: pipelines/pipelines/nodes/ranker/ernie_ranker.py</div><div id='n_file'> N File Name: pipelines/pipelines/nodes/ranker/ernie_ranker.py</div><div id='m_start'> M Start Line: 159</div><div id='m_end'> M End Line: 177</div><div id='n_start'> N Start Line: 150</div><div id='n_end'> N End Line: 159</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            truncation_strategy="longest_first",
        )

        tensors<a id="change"> = </a><a id="change">{k: paddle.to_tensor(v) for (k, v) in features.items()}</a>

        with paddle.no_grad():
            if self.use_en:
                similarity_scores = self.transformer_model.matching_v2(**tensors).numpy()</code></pre><h3>After Change</h3><pre><code class='java'>
        
        if top_k is None:
            top_k = self.top_k
        datasets = <a id="change">[]</a>
        <a id="change">for doc</a> in documents<a id="change">:
            </a>if self.embed_title:
                <a id="change">datasets.append(</a>[query, doc.meta["name"]<a id="change"> + </a>doc.content]<a id="change">)</a>
            else:
                datasets.append([query, doc.content])
        outputs = self.transformer_model(datasets)
        similarity_scores = [item["similarity"] for item in outputs]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/35be940d8e29d002d830da63c5923f63b0ec4d5d#diff-e4ecbdd7379c6bb54f6934b38056f91532487822cf4efec218b9a1369b9e3aceL84' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83661648</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 35be940d8e29d002d830da63c5923f63b0ec4d5d</div><div id='time'> Time: 2023-03-06</div><div id='author'> Author: w5688414@gmail.com</div><div id='file'> File Name: pipelines/pipelines/nodes/ranker/ernie_ranker.py</div><div id='m_class'> M Class Name: ErnieRanker</div><div id='n_method'> N Class Name: ErnieRanker</div><div id='m_method'> M Method Name: predict(4)</div><div id='n_method'> N Method Name: predict(4)</div><div id='m_parent_class'> M Parent Class: BaseRanker</div><div id='n_parent_class'> N Parent Class: BaseRanker</div><div id='m_file'> M File Name: pipelines/pipelines/nodes/ranker/ernie_ranker.py</div><div id='n_file'> N File Name: pipelines/pipelines/nodes/ranker/ernie_ranker.py</div><div id='m_start'> M Start Line: 98</div><div id='m_end'> M End Line: 115</div><div id='n_start'> N Start Line: 97</div><div id='n_end'> N End Line: 104</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    batched_outputs = self._force_decode(encoded_inputs)

    &#47&#47 Convert to numpy for post-processing ... this doesn&quott work for jax
    detached_outputs = <a id="change">{k: v.numpy() for k, v in batched_outputs.items()}</a>
    &#47&#47 Instead of the above I am trying to implement something like this below for jax
    &#47&#47 ----&gt;
    &#47&#47 predict_answer_tokens = results.input_ids[0, answer_start_index : answer_end_index + 1]
    &#47&#47    &#47&#47 generates answer text
    &#47&#47 tokenizer.decode(predict_answer_tokens)
    
    &#47&#47 Split up batched outputs, then post-process each example.
    unbatched_outputs<a id="change"> = </a>utils.unbatch_preds(detached_outputs)
    return map(self._postprocess, unbatched_outputs)

  def input_spec(self):</code></pre><h3>After Change</h3><pre><code class='java'>
        question.append(i[&quotquestion&quot])
        context.append(i[&quotcontext&quot])

    prediction = <a id="change">[]</a>
    <a id="change">for i</a> in range(len(inputs))<a id="change">:
        </a>model = FlaxBertForQuestionAnswering.from_pretrained("mrm8488/bert-multi-cased-finedtuned-xquad-tydiqa-goldp")
        inputs = self.tokenizer(question[i], context[i], return_tensors="jax",padding=True)
        outputs = model(**inputs)

        answer_start_index = outputs.start_logits.argmax()

        answer_end_index = outputs.end_logits.argmax()

        predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index<a id="change"> + </a>1]

        <a id="change">prediction.append(</a>self.tokenizer.decode(predict_answer_tokens)<a id="change">)</a>
    print(&quotPredictions for the data is----&gt;/n&quot)
    print(prediction)
    &#47&#47 returning list of prediction
    return prediction</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pair-code/lit/commit/c2fd433b7d7ee04e60dd117c3decc8e22ac42287#diff-e66e2ed65042046b3905d9bc4b44fa2c3bb19cb8c07da5a9540002725714fab0L181' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 83661649</div><div id='project'> Project Name: pair-code/lit</div><div id='commit'> Commit Name: c2fd433b7d7ee04e60dd117c3decc8e22ac42287</div><div id='time'> Time: 2022-06-15</div><div id='author'> Author: 31214277+aryan1107@users.noreply.github.com</div><div id='file'> File Name: lit_nlp/examples/models/tydi.py</div><div id='m_class'> M Class Name: TydiModel</div><div id='n_method'> N Class Name: TydiModel</div><div id='m_method'> M Method Name: predict_minibatch(2)</div><div id='n_method'> N Method Name: predict_minibatch(2)</div><div id='m_parent_class'> M Parent Class: lit_model.Model</div><div id='n_parent_class'> N Parent Class: lit_model.Model</div><div id='m_file'> M File Name: lit_nlp/examples/models/tydi.py</div><div id='n_file'> N File Name: lit_nlp/examples/models/tydi.py</div><div id='m_start'> M Start Line: 186</div><div id='m_end'> M End Line: 203</div><div id='n_start'> N Start Line: 134</div><div id='n_end'> N End Line: 156</div><BR>