<html><h3>Pattern ID :31991
</h3><img src='93502643.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                            dcgm_monitor=dcgm_monitor)

        &#47&#47 Model name here is triton-server, batch and concurrency are defaults
        output_row = <a id="change">[</a>&quottriton-server&quot, default_value, default_value<a id="change"></a>]

        &#47&#47 add the obtained metrics
        for metric in self._monitoring_metrics:
            if metric in server_only_metrics:
                output_row.append(server_only_metrics[metric])
            else:
                <a id="change">output_row.append(</a>default_value<a id="change">)</a>
        self.tables["Server Only:"].add_row(output_row)
        dcgm_monitor.destroy()

    def profile_model(self, run_config, perf_output_writer=None):</code></pre><h3>After Change</h3><pre><code class='java'>
        gpu_metrics = defaultdict(list)
        for _, metric in server_only_gpu_metrics.items():
            for gpu_id, metric_value in metric.items():
                <a id="change">gpu_metrics[gpu_id].append(</a>metric_value<a id="change">)</a>

        <a id="change">for </a>gpu_id, <a id="change">metric</a> in <a id="change">gpu_metrics.items():
            &#47&#47 Model name here is triton-server, batch and concurrency
            &#47&#47 are defaults
            </a>output_row = [
                &quottriton-server&quot, gpu_id, default_value, default_value
            ]
            output_row<a id="change"> += </a>metric
            self._tables[&quotserver_gpu_metrics&quot].add_row(output_row)
        dcgm_monitor.destroy()
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/triton-inference-server/model_analyzer/commit/d04f1be375baf6c4907c314899008efb6e8c928a#diff-bfa8f90a391c1ffdc5f96eac924441f3941ab2aeb9d7784b89ab3f503cd37c8dL90' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 93502643</div><div id='project'> Project Name: triton-inference-server/model_analyzer</div><div id='commit'> Commit Name: d04f1be375baf6c4907c314899008efb6e8c928a</div><div id='time'> Time: 2021-01-06</div><div id='author'> Author: itabrizian@nvidia.com</div><div id='file'> File Name: model_analyzer/analyzer.py</div><div id='m_class'> M Class Name: Analyzer</div><div id='n_method'> N Class Name: Analyzer</div><div id='m_method'> M Method Name: profile_server_only(2)</div><div id='n_method'> N Method Name: profile_server_only(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model_analyzer/analyzer.py</div><div id='n_file'> N File Name: model_analyzer/analyzer.py</div><div id='m_start'> M Start Line: 90</div><div id='m_end'> M End Line: 102</div><div id='n_start'> N Start Line: 96</div><div id='n_end'> N End Line: 112</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                                            dcgm_monitor=dcgm_monitor)

        &#47&#47 Model name here is triton-server, batch and concurrency are defaults
        output_row = <a id="change">[</a>&quottriton-server&quot, default_value, default_value<a id="change"></a>]

        &#47&#47 add the obtained metrics
        for metric in self._monitoring_metrics:
            if metric in server_only_metrics:
                <a id="change">output_row.append(</a>server_only_metrics[metric]<a id="change">)</a>
            else:
                output_row.append(default_value)
        self.tables["Server Only:"].add_row(output_row)
        dcgm_monitor.destroy()</code></pre><h3>After Change</h3><pre><code class='java'>
        server_only_gpu_metrics, _ = self._profile(perf_analyzer=None,
                                                   dcgm_monitor=dcgm_monitor)

        <a id="change">gpu_metrics</a> = defaultdict(list)
        for _, metric in server_only_gpu_metrics.items():
            for gpu_id, metric_value in metric.items():
                <a id="change">gpu_metrics[gpu_id].append(</a>metric_value<a id="change">)</a>

        <a id="change">for </a>gpu_id, <a id="change">metric</a> in <a id="change">gpu_metrics.items():
            &#47&#47 Model name here is triton-server, batch and concurrency
            &#47&#47 are defaults
            </a>output_row<a id="change"> = </a>[
                &quottriton-server&quot, gpu_id, default_value, default_value
            ]
            output_row += metric</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/triton-inference-server/model_analyzer/commit/d04f1be375baf6c4907c314899008efb6e8c928a#diff-bfa8f90a391c1ffdc5f96eac924441f3941ab2aeb9d7784b89ab3f503cd37c8dL72' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 93502641</div><div id='project'> Project Name: triton-inference-server/model_analyzer</div><div id='commit'> Commit Name: d04f1be375baf6c4907c314899008efb6e8c928a</div><div id='time'> Time: 2021-01-06</div><div id='author'> Author: itabrizian@nvidia.com</div><div id='file'> File Name: model_analyzer/analyzer.py</div><div id='m_class'> M Class Name: Analyzer</div><div id='n_method'> N Class Name: Analyzer</div><div id='m_method'> M Method Name: profile_server_only(2)</div><div id='n_method'> N Method Name: profile_server_only(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model_analyzer/analyzer.py</div><div id='n_file'> N File Name: model_analyzer/analyzer.py</div><div id='m_start'> M Start Line: 90</div><div id='m_end'> M End Line: 102</div><div id='n_start'> N Start Line: 96</div><div id='n_end'> N End Line: 112</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        measurements = result.get_measurements()

        gpu_rows = <a id="change">[]</a>
        non_gpu_rows = []
        for measurement in measurements:
            for gpu_row in measurement.gpu_data().values():
                <a id="change">gpu_rows.append(</a>gpu_row<a id="change">)</a>
            non_gpu_rows.append(measurement.non_gpu_data())

        return Measurement(gpu_measurement=aggregation_func(gpu_rows),
                           non_gpu_measurement=aggregation_func(non_gpu_rows),</code></pre><h3>After Change</h3><pre><code class='java'>

        measurements = result.get_measurements()

        <a id="change">gpu_data</a> = defaultdict(list)
        non_gpu_rows = []
        for measurement in measurements:
            gpu_measurement_data = measurement.gpu_data()
            for gpu_id, gpu_row in gpu_measurement_data.items():
                <a id="change">gpu_data[gpu_id].append(</a>gpu_row<a id="change">)</a>
            non_gpu_rows.append(measurement.non_gpu_data())

        &#47&#47 Aggregate the data
        <a id="change">for </a>gpu_id, <a id="change">gpu_rows</a> in <a id="change">gpu_data.items():
            </a>gpu_data[gpu_id]<a id="change"> = </a>aggregation_func(gpu_rows)
        non_gpu_data = aggregation_func(non_gpu_rows)

        return Measurement(gpu_data=gpu_data,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/triton-inference-server/model_analyzer/commit/1e56fa37ca96be01a374687772b14a1cef147ddf#diff-9114f57642ffd5d725835f9f43285c9356a86b899031c3c827d21128881c92f2L178' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 93502645</div><div id='project'> Project Name: triton-inference-server/model_analyzer</div><div id='commit'> Commit Name: 1e56fa37ca96be01a374687772b14a1cef147ddf</div><div id='time'> Time: 2021-02-23</div><div id='author'> Author: asramesh@nvidia.com</div><div id='file'> File Name: model_analyzer/result/result_comparator.py</div><div id='m_class'> M Class Name: ResultComparator</div><div id='n_method'> N Class Name: ResultComparator</div><div id='m_method'> M Method Name: _aggregate_measurements(3)</div><div id='n_method'> N Method Name: _aggregate_measurements(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model_analyzer/result/result_comparator.py</div><div id='n_file'> N File Name: model_analyzer/result/result_comparator.py</div><div id='m_start'> M Start Line: 193</div><div id='m_end'> M End Line: 198</div><div id='n_start'> N Start Line: 180</div><div id='n_end'> N End Line: 191</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if not self._log or (batch_idx + 1) % self._log_every_n_steps != 0:
            return

        named_tensor: List = <a id="change">[]</a>
        tensor, _gt, _ = batch  &#47&#47 tensor, label, batch_size
        if isinstance(outputs, Dict):
            pred = outputs[&quotpred&quot]
        elif isinstance(outputs, Tensor):
            pred = outputs
        else:
            raise Exception(
                f"Except `outputs` to be List or Dict, get {type(outputs)}"
            )

        &#47&#47 this is classification task, it&quotll be moved to another callback soon
        for idx, predict in enumerate(pred):
            image = transforms.ToPILImage()(tensor[idx])
            if self._mapping is not None:
                assert predict &lt;= len(self._mapping), (
                    f"Can&quott mapping because {predict} doesn&quott belong to {self._mapping}"
                )
                predict = self._mapping[predict.item()]  &#47&#47 mapping label
            <a id="change">named_tensor.append(</a>[str(predict), image]<a id="change">)</a>
        self.add_image(tag=&quotMedia/train&quot, batch=named_tensor)

    def on_train_epoch_end(
        self, trainer: "pl.Trainer", pl_module: "pl.LightningModule", unused: Optional = None</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 log every n steps
        if not self._log or (batch_idx + 1) % self._log_every_n_steps != 0:
            return
        <a id="change">compressed_batch</a>: Dict[str, List] = {&quotimages&quot: [], &quotground_truths&quot: [], &quotpredictions&quot: []}
        tensor, gt, _ = batch  &#47&#47 tensor, label, batch_size
        &#47&#47 output must be Tensor or Dict ơf Tensor
        if isinstance(outputs, Dict):
            pred = outputs[&quotpred&quot]
        elif isinstance(outputs, Tensor):
            pred = outputs
        else:
            raise Exception(f"Except `outputs` to be List or Dict, get {type(outputs)}")

        for idx, image in enumerate(tensor):
            transformed_image = transforms.ToPILImage()(image).convert("RGB")  &#47&#47 WxH dimension
            compressed_batch[&quotimages&quot].append(transformed_image)  &#47&#47 batch_size x W x H dimension
            compressed_batch[&quotground_truths&quot].append(gt[idx].item())
            <a id="change">compressed_batch[&quotpredictions&quot].append(</a>pred[idx].item()<a id="change">)</a>
        if self._on_epoch:
            <a id="change">for </a>key, <a id="change">value</a> in <a id="change">compressed_batch.items():
                </a>self._epoch[key]<a id="change"> += </a>value   &#47&#47 epoch:  number_of_data x W x H dimension
        if self._on_step:
            self.add_image(tag=&quotTrain/step_media&quot, media=compressed_batch)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/uetailab/uetai/commit/ac795b0b1d6529a8ef130965ee4028565aa6620e#diff-42e5b743af8efeebd108b8e449932e5601a03753c13be07ff4f16894c2a749b4L36' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 93502648</div><div id='project'> Project Name: uetailab/uetai</div><div id='commit'> Commit Name: ac795b0b1d6529a8ef130965ee4028565aa6620e</div><div id='time'> Time: 2021-09-30</div><div id='author'> Author: manhdung20112000@gmail.com</div><div id='file'> File Name: src/uetai/callbacks/image_monitor.py</div><div id='m_class'> M Class Name: ImageMonitorBase</div><div id='n_method'> N Class Name: ImageMonitorBase</div><div id='m_method'> M Method Name: on_train_batch_end(7)</div><div id='n_method'> N Method Name: on_train_batch_end(7)</div><div id='m_parent_class'> M Parent Class: Callback</div><div id='n_parent_class'> N Parent Class: Callback</div><div id='m_file'> M File Name: src/uetai/callbacks/image_monitor.py</div><div id='n_file'> N File Name: src/uetai/callbacks/image_monitor.py</div><div id='m_start'> M Start Line: 48</div><div id='m_end'> M End Line: 68</div><div id='n_start'> N Start Line: 67</div><div id='n_end'> N End Line: 88</div><BR>