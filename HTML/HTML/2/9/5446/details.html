<html><h3>Pattern ID :5446
</h3><img src='19249317.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        score_of_positive = kg_embedding_model.predict(pos_triple)

        scores_subject_based<a id="change"> = </a>np.append(arr=scores_of_corrupted_subjects, values=score_of_positive)
        indice_of_pos_subject_based = scores_subject_based.size - 1

        scores_object_based = np.append(arr=scores_of_corrupted_objects, values=score_of_positive)
        indice_of_pos_object_based<a id="change"> = </a>scores_object_based.size - 1

        _, sorted_score_indices_subject_based = torch.sort(torch.tensor(scores_subject_based, dtype=torch.float),
                                                           descending=self.kge_to_descend_sorting[
                                                               kg_embedding_model.model_name])
        sorted_score_indices_subject_based = sorted_score_indices_subject_based.cpu().numpy()

        _, sorted_score_indices_object_based = torch.sort(torch.tensor(scores_object_based, dtype=torch.float),
                                                          descending=self.kge_to_descend_sorting[
                                                              kg_embedding_model.model_name])
        sorted_score_indices_object_based<a id="change"> = sorted_score_indices_object_based.cpu()</a><a id="change">.numpy()</a>

        &#47&#47 Get index of first occurrence that fulfills the condition
        rank_of_positive_subject_based = np.where(sorted_score_indices_subject_based == indice_of_pos_subject_based)[0][
            0]
        rank_of_positive_object_based = np.where(sorted_score_indices_object_based == indice_of_pos_object_based)[0][0]

        <a id="change">return </a>(
            rank_of_positive_subject_based<a id="change">,
            rank_of_positive_object_based</a>,
        )

    def evaluate(self, test_triples: np.ndarray):</code></pre><h3>After Change</h3><pre><code class='java'>
        rank_of_positive_object_based = scores_of_corrupted_objects.shape[0] - \
                                        np.greater(scores_of_corrupted_objects, score_of_positive).sum()

        <a id="change">return </a>(
            rank_of_positive_subject_based + 1<a id="change">,
            rank_of_positive_object_based + 1</a>,
        )

    def evaluate(self, test_triples: np.ndarray):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pykeen/pykeen/commit/d0af5f9478b457b561f9e88d53fbe9a18f1c2672#diff-a6024a855f8f100281bf731d896a62044c0b328f1fe84fdfa500129ccb1796efL143' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19249317</div><div id='project'> Project Name: pykeen/pykeen</div><div id='commit'> Commit Name: d0af5f9478b457b561f9e88d53fbe9a18f1c2672</div><div id='time'> Time: 2019-05-15</div><div id='author'> Author: lvermue@users.noreply.github.com</div><div id='file'> File Name: src/poem/evaluation/ranked_based_evaluator.py</div><div id='m_class'> M Class Name: RankBasedEvaluator</div><div id='n_method'> N Class Name: RankBasedEvaluator</div><div id='m_method'> M Method Name: _compute_rank(6)</div><div id='n_method'> N Method Name: _compute_rank(6)</div><div id='m_parent_class'> M Parent Class: AbstractEvalutor</div><div id='n_parent_class'> N Parent Class: AbstractEvalutor</div><div id='m_file'> M File Name: src/poem/evaluation/ranked_based_evaluator.py</div><div id='n_file'> N File Name: src/poem/evaluation/ranked_based_evaluator.py</div><div id='m_start'> M Start Line: 146</div><div id='m_end'> M End Line: 176</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 157</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47compute v loss
        target_v_value = (new_min_curr_state_q_value - new_curr_state_log_pi).detach()
        v_loss = F.mse_loss(curr_state_v_value, target_v_value)
        v_loss_value<a id="change"> = v_loss.detach().cpu()</a><a id="change">.numpy()</a>
        self.v_optimizer.zero_grad()
        v_loss.backward()
        self.v_optimizer.step()
        
        &#47&#47compute q loss
        target_q_value = (reward_batch + (1.0 - done_batch) * self.gamma * next_state_target_v_value).detach()
        q1_loss = F.mse_loss(curr_state_q1_value, target_q_value)
        q2_loss = F.mse_loss(curr_state_q2_value, target_q_value)
        q1_loss_value = q1_loss.detach().cpu().numpy()
        q2_loss_value = q2_loss.detach().cpu().numpy()
        self.q1_optimizer.zero_grad()
        q1_loss.backward()
        self.q1_optimizer.step()
        self.q2_optimizer.zero_grad()
        q2_loss.backward()
        self.q2_optimizer.step()

        &#47&#47compute policy loss
        policy_loss = ((self.alpha * new_curr_state_log_pi) - new_min_curr_state_q_value).mean()
        policy_loss_value = policy_loss.detach().cpu().numpy()
        self.policy_optimizer.zero_grad()
        policy_loss.backward()
        self.policy_optimizer.step()

        &#47&#47compute temperature loss
        if self.automatic_entropy_tuning:
            alpha_loss = -(self.log_alpha * (new_curr_state_log_pi + self.target_entropy).detach()).mean()
            alpha_loss_value = alpha_loss.detach().cpu().numpy()
            self.alpha_optim.zero_grad()
            alpha_loss.backward()
            self.alpha_optim.step()

            self.alpha = self.log_alpha.exp()
            alpha_value = self.alpha.detach().cpu().numpy()
        else:
            alpha_loss = torch.tensor(0.).to(util.device)
            alpha_value = self.alpha.detach().cpu().numpy()

        <a id="change">return </a>q1_loss_value<a id="change">, q2_loss_value, v_loss_value, policy_loss_value, alpha_loss_value, alpha_value</a>

    def select_action(self, state, evaluate=False):
        if type(state) != torch.tensor:
            state = torch.FloatTensor([state]).to(util.device)</code></pre><h3>After Change</h3><pre><code class='java'>
        new_curr_state_q1_value = self.q1_network(state_batch, new_curr_state_action)
        new_curr_state_q2_value = self.q2_network(state_batch, new_curr_state_action)

        next_state_q1_value<a id="change"> = </a>self.target_q1_network(next_state_batch, next_state_action)
        next_state_q2_value<a id="change"> = </a>self.target_q2_network(next_state_batch, next_state_action)
        next_state_min_q = torch.min(next_state_q1_value, next_state_q2_value)
        target_q = (next_state_min_q - self.alpha * next_state_log_pi)
        target_q = reward_batch + self.gamma * (1. - done_batch) * target_q

        new_min_curr_state_q_value = torch.min(new_curr_state_q1_value, new_curr_state_q2_value)

        &#47&#47compute q loss
        q1_loss = F.mse_loss(curr_state_q1_value, target_q.detach())
        q2_loss = F.mse_loss(curr_state_q2_value, target_q.detach())
        q1_loss_value = q1_loss.detach().cpu().numpy()
        q2_loss_value = q2_loss.detach().cpu().numpy()
        self.q1_optimizer.zero_grad()
        q1_loss.backward()
        self.q1_optimizer.step()
        self.q2_optimizer.zero_grad()
        q2_loss.backward()
        self.q2_optimizer.step()

        &#47&#47compute policy loss
        policy_loss = ((self.alpha * new_curr_state_log_pi) - new_min_curr_state_q_value).mean()
        policy_loss_value = policy_loss.detach().cpu().numpy()
        self.policy_optimizer.zero_grad()
        policy_loss.backward()
        self.policy_optimizer.step()

        &#47&#47compute entropy loss
        if self.automatic_entropy_tuning:
            alpha_loss = -(self.log_alpha * (new_curr_state_log_pi + self.target_entropy).detach()).mean()
            alpha_loss_value = alpha_loss.detach().cpu().numpy()
            self.alpha_optim.zero_grad()
            alpha_loss.backward()
            self.alpha_optim.step()

            self.alpha = self.log_alpha.exp()
            alpha_value = self.alpha.detach().cpu().numpy()
        else:
            alpha_loss = torch.tensor(0.).to(util.device)
            alpha_value = self.alpha.detach().cpu().numpy()
        self.tot_update_count += 1
        <a id="change">return </a>q1_loss_value<a id="change">, q2_loss_value, policy_loss_value, alpha_loss_value, alpha_value</a>

    def try_update_target_network(self):
        if self.tot_update_count % self.update_target_network_interval == 0:
            util.soft_update_network(self.q1_network, self.target_q1_network, self.target_smoothing_tau)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/x35f/unstable_baselines/commit/0fc82ae6328814fe2dad0c8e0ae1b172d3e5f981#diff-5db644cd5bd54e3d73a4e86c3b2e245fd8f43751389307d15efbb99043bc1b0fL73' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19249300</div><div id='project'> Project Name: x35f/unstable_baselines</div><div id='commit'> Commit Name: 0fc82ae6328814fe2dad0c8e0ae1b172d3e5f981</div><div id='time'> Time: 2021-03-12</div><div id='author'> Author: ym8411012@126.com</div><div id='file'> File Name: sac/models.py</div><div id='m_class'> M Class Name: SACAgent</div><div id='n_method'> N Class Name: SACAgent</div><div id='m_method'> M Method Name: update(2)</div><div id='n_method'> N Method Name: update(2)</div><div id='m_parent_class'> M Parent Class: BaseAgent,torch.nn.Module</div><div id='n_parent_class'> N Parent Class: BaseAgent,torch.nn.Module</div><div id='m_file'> M File Name: sac/models.py</div><div id='n_file'> N File Name: sac/models.py</div><div id='m_start'> M Start Line: 75</div><div id='m_end'> M End Line: 129</div><div id='n_start'> N Start Line: 83</div><div id='n_end'> N End Line: 129</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            y = torch.from_numpy(y).type(torch.float).view(-1,1).to(device)
            y += shift_label
            y /= max_label
            batch_fake_images<a id="change"> = </a>netG(z, y)
            raw_fake_images[tmp:(tmp+batch_size)] = batch_fake_images.cpu().detach().numpy()
            raw_fake_counts[tmp:(tmp+batch_size)]<a id="change"> = y.cpu()</a><a id="change">.view(-1).detach().numpy()</a>
            tmp += batch_size

    &#47&#47remove extra entries
    raw_fake_images = raw_fake_images[0:NFAKE]
    raw_fake_counts = raw_fake_counts[0:NFAKE]

    <a id="change">return </a>raw_fake_images<a id="change">, raw_fake_counts.reshape(-1)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
        while tmp &lt; NFAKE:
            z = torch.randn(batch_size, GAN_Latent_Length, dtype=torch.float).to(device)
            labels = np.random.choice(np.arange(num_classes),size=batch_size,replace=True)
            raw_fake_labels[tmp:(tmp+batch_size)]<a id="change"> = </a>labels
            labels = torch.from_numpy(labels).type(torch.long).to(device)
            batch_fake_images = netG(z, labels)
            fake_images[tmp:(tmp+batch_size)] = batch_fake_images.cpu().detach().numpy()
            tmp += batch_size

    &#47&#47remove extra entries
    fake_images = fake_images[0:NFAKE]
    raw_fake_labels = raw_fake_labels[0:NFAKE]
    raw_fake_labels = raw_fake_labels.astype(np.float)

    &#47&#47convert class labels to raw labels
    raw_fake_labels = np.array([class2label[raw_fake_labels[i]] for i in range(NFAKE)])

    <a id="change">return </a>fake_images<a id="change">, raw_fake_labels</a>


def SampcDCGAN_given_label(netG, given_label, unique_labels, label2class, GAN_Latent_Length = 128, NFAKE = 10000, batch_size = 500, device="cuda"):
    &quot&quot&quot</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ubcdingxin/improved_ccgan/commit/8a85572c67f2b5e51be8e71eb77edbead26b2c0a#diff-df3c440c73c50b64aefbe69083440a66533d0d3b3c5f056547c895503b9d9f9aL134' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19249380</div><div id='project'> Project Name: ubcdingxin/improved_ccgan</div><div id='commit'> Commit Name: 8a85572c67f2b5e51be8e71eb77edbead26b2c0a</div><div id='time'> Time: 2020-03-11</div><div id='author'> Author: dingx92@gmail.com</div><div id='file'> File Name: CellCounting/Train_cDCGAN.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: SampcDCGAN(7)</div><div id='n_method'> N Method Name: SampcDCGAN(7)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: CellCounting/Train_cDCGAN.py</div><div id='n_file'> N File Name: CellCounting/Train_cDCGAN.py</div><div id='m_start'> M Start Line: 134</div><div id='m_end'> M End Line: 159</div><div id='n_start'> N Start Line: 136</div><div id='n_end'> N End Line: 165</div><BR>