<html><h3>Pattern ID :9129
</h3><img src='33257611.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        
        for doc in docs:
            self.expand_abbreviations_section(doc)
        <a id="change">return </a>docs<a id="change">, []</a>

    def expand_abbreviations(self, section: Section) -&gt; Tuple[str, Dict[CharSpan, CharSpan]]:
        
        processes a document for abbreviations, returning a new string with all abbreviations expanded</code></pre><h3>After Change</h3><pre><code class='java'>
        
        failed_docs = []
        for doc in docs:
            <a id="change">try:
                </a>self.expand_abbreviations_section(doc)
            <a id="change">except </a>Exception:
                <a id="change">doc.metadata[PROCESSING_EXCEPTION] = </a><a id="change">traceback.format_exc()</a>
                <a id="change">failed_docs.append(</a>doc<a id="change">)</a>
        return docs, failed_docs

    def expand_abbreviations(self, section: Section) -&gt; Tuple[str, Dict[CharSpan, CharSpan]]:
        </code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 7</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/astrazeneca/kazu/commit/eef50d44160f87ee71ea605359a5758245d2c45f#diff-4d106121c0345f149805935d52ce06be718fe6b4bec0044f467153f66a399584L269' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33257611</div><div id='project'> Project Name: astrazeneca/kazu</div><div id='commit'> Commit Name: eef50d44160f87ee71ea605359a5758245d2c45f</div><div id='time'> Time: 2021-11-23</div><div id='author'> Author: richard.jackson4@astrazeneca.com</div><div id='file'> File Name: azner/steps/string_preprocessing/scispacy_abbreviation_expansion.py</div><div id='m_class'> M Class Name: SciSpacyAbbreviationExpansionStep</div><div id='n_method'> N Class Name: SciSpacyAbbreviationExpansionStep</div><div id='m_method'> M Method Name: _run(2)</div><div id='n_method'> N Method Name: _run(2)</div><div id='m_parent_class'> M Parent Class: StringPreprocessorStep</div><div id='n_parent_class'> N Parent Class: StringPreprocessorStep</div><div id='m_file'> M File Name: azner/steps/string_preprocessing/scispacy_abbreviation_expansion.py</div><div id='n_file'> N File Name: azner/steps/string_preprocessing/scispacy_abbreviation_expansion.py</div><div id='m_start'> M Start Line: 269</div><div id='m_end'> M End Line: 270</div><div id='n_start'> N Start Line: 269</div><div id='n_end'> N End Line: 276</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                        entity.add_mapping(new_mapping)
                        self.lookup_cache.update_lookup_cache(entity, new_mapping)

        <a id="change">return </a>docs<a id="change">, []</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
        entities = self.lookup_cache.check_lookup_cache(entities)
        if len(entities) &gt; 0:
            for entity in entities:
                <a id="change">try:
                    </a>ontology_name = self.entity_class_to_ontology_mappings[entity.entity_class]
                    index = self.ontology_index_dict.get(ontology_name, None)
                    if index is not None:
                        metadata_df = index.search(entity.match)
                        for i, row in metadata_df.iterrows():
                            row_dict = row.to_dict()
                            ontology_id = row_dict.pop("iri")
                            new_mapping = Mapping(
                                source=ontology_name,
                                idx=ontology_id,
                                mapping_type="direct",
                                metadata=row_dict,
                            )
                            entity.add_mapping(new_mapping)
                            self.lookup_cache.update_lookup_cache(entity, new_mapping)
                <a id="change">except </a>Exception:
                    doc = find_document_from_entity(docs, entity)
                    <a id="change">doc.metadata[PROCESSING_EXCEPTION] = </a><a id="change">traceback.format_exc()</a>
                    <a id="change">failed_docs.append(</a>doc<a id="change">)</a>

        return docs, failed_docs
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/astrazeneca/kazu/commit/0b3ec75ae4936b3e6524a13b44f790bf0755ba4d#diff-70cac163c7415c53bffa43163128a843d246ed07804872cad842462fc7a6df2bL44' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33257610</div><div id='project'> Project Name: astrazeneca/kazu</div><div id='commit'> Commit Name: 0b3ec75ae4936b3e6524a13b44f790bf0755ba4d</div><div id='time'> Time: 2021-11-23</div><div id='author'> Author: richard.jackson4@astrazeneca.com</div><div id='file'> File Name: azner/steps/linking/dictionary.py</div><div id='m_class'> M Class Name: DictionaryEntityLinkingStep</div><div id='n_method'> N Class Name: DictionaryEntityLinkingStep</div><div id='m_method'> M Method Name: _run(2)</div><div id='n_method'> N Method Name: _run(2)</div><div id='m_parent_class'> M Parent Class: BaseStep</div><div id='n_parent_class'> N Parent Class: BaseStep</div><div id='m_file'> M File Name: azner/steps/linking/dictionary.py</div><div id='n_file'> N File Name: azner/steps/linking/dictionary.py</div><div id='m_start'> M Start Line: 61</div><div id='m_end'> M End Line: 77</div><div id='n_start'> N Start Line: 56</div><div id='n_end'> N End Line: 85</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        for doc in docs:
            self.expand_abbreviations_section(doc)
        <a id="change">return </a>docs<a id="change">, []</a>

    def expand_abbreviations(self, section: Section) -&gt; Tuple[str, Dict[CharSpan, CharSpan]]:
        
        processes a document for abbreviations, returning a new string with all abbreviations expanded</code></pre><h3>After Change</h3><pre><code class='java'>
        
        failed_docs = []
        for doc in docs:
            <a id="change">try:
                </a>self.expand_abbreviations_section(doc)
            <a id="change">except </a>Exception:
                <a id="change">doc.metadata[PROCESSING_EXCEPTION] = </a><a id="change">traceback.format_exc()</a>
                <a id="change">failed_docs.append(</a>doc<a id="change">)</a>
        return docs, failed_docs

    def expand_abbreviations(self, section: Section) -&gt; Tuple[str, Dict[CharSpan, CharSpan]]:
        </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/astrazeneca/kazu/commit/453535c28b381c9ae86cd21d10fd8a0157be4f4b#diff-4d106121c0345f149805935d52ce06be718fe6b4bec0044f467153f66a399584L262' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33257615</div><div id='project'> Project Name: astrazeneca/kazu</div><div id='commit'> Commit Name: 453535c28b381c9ae86cd21d10fd8a0157be4f4b</div><div id='time'> Time: 2021-11-23</div><div id='author'> Author: richard.jackson4@astrazeneca.com</div><div id='file'> File Name: azner/steps/string_preprocessing/scispacy_abbreviation_expansion.py</div><div id='m_class'> M Class Name: SciSpacyAbbreviationExpansionStep</div><div id='n_method'> N Class Name: SciSpacyAbbreviationExpansionStep</div><div id='m_method'> M Method Name: _run(2)</div><div id='n_method'> N Method Name: _run(2)</div><div id='m_parent_class'> M Parent Class: StringPreprocessorStep</div><div id='n_parent_class'> N Parent Class: StringPreprocessorStep</div><div id='m_file'> M File Name: azner/steps/string_preprocessing/scispacy_abbreviation_expansion.py</div><div id='n_file'> N File Name: azner/steps/string_preprocessing/scispacy_abbreviation_expansion.py</div><div id='m_start'> M Start Line: 269</div><div id='m_end'> M End Line: 270</div><div id='n_start'> N Start Line: 269</div><div id='n_end'> N End Line: 276</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 reset the entity mapper in preparation for the next section
            self.entity_mapper.reset()

        <a id="change">return </a>docs<a id="change">, []</a>

    def get_list_of_batch_encoding_frames_for_section(
        self, batch_encoding: BatchEncoding, section_index: int
    ) -&gt; List[int]:</code></pre><h3>After Change</h3><pre><code class='java'>

    def _run(self, docs: List[Document]) -&gt; Tuple[List[Document], List[Document]]:
        failed_docs = []
        <a id="change">try:
            </a>loader, id_section_map = self.get_dataloader(docs)
            &#47&#47 run the transformer and get results
            confidence_and_labels_tensor = self.get_confidence_and_labels_tensor(loader)
            for section_index, section in id_section_map.items():
                &#47&#47 for long docs, we need to split section.get_text() into frames (i.e. portions that will fit into Bert or
                &#47&#47 similar)
                ner_processed_section = self.merge_section_frames(
                    section_index=section_index,
                    batch_encoding=loader.dataset.encodings,
                    confidence_and_labels_tensor=confidence_and_labels_tensor,
                )
                all_words = ner_processed_section.to_tokenized_words(self.config.id2label)
                transformed_words = self.bio_preprocessor(all_words)
                for transformed_word in transformed_words:
                    for i, label in enumerate(transformed_word.word_labels_strings):
                        if self.debug:
                            logger.info(
                                f"processing label: {label} for token {section.get_text()[transformed_word.word_offsets[i][0]:transformed_word.word_offsets[i][1]]}"
                            )
                        self.entity_mapper.update_parse_states(
                            label,
                            offsets=transformed_word.word_offsets[i],
                            text=section.get_text(),
                            confidence=transformed_word.word_confidences[i],
                        )

                &#47&#47 at the end of the section, get the results
                section.entities = self.entity_mapper.get_entities()
                &#47&#47 reset the entity mapper in preparation for the next section
                self.entity_mapper.reset()
        <a id="change">except </a>Exception:
            for doc in docs:
                <a id="change">doc.metadata[PROCESSING_EXCEPTION] = </a><a id="change">traceback.format_exc()</a>
                <a id="change">failed_docs.append(</a>doc<a id="change">)</a>

        return docs, failed_docs

    def get_list_of_batch_encoding_frames_for_section(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/astrazeneca/kazu/commit/91e6527408999f960a69d6fe81419870356f3ba1#diff-9ec49f69bf2c8adcd8a03e6c8e31f8cdc4c5d41c030cc74bfd06e94922c367ddL142' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33257614</div><div id='project'> Project Name: astrazeneca/kazu</div><div id='commit'> Commit Name: 91e6527408999f960a69d6fe81419870356f3ba1</div><div id='time'> Time: 2021-11-23</div><div id='author'> Author: richard.jackson4@astrazeneca.com</div><div id='file'> File Name: azner/steps/ner/hf_token_classification.py</div><div id='m_class'> M Class Name: TransformersModelForTokenClassificationNerStep</div><div id='n_method'> N Class Name: TransformersModelForTokenClassificationNerStep</div><div id='m_method'> M Method Name: _run(2)</div><div id='n_method'> N Method Name: _run(2)</div><div id='m_parent_class'> M Parent Class: BaseStep</div><div id='n_parent_class'> N Parent Class: BaseStep</div><div id='m_file'> M File Name: azner/steps/ner/hf_token_classification.py</div><div id='n_file'> N File Name: azner/steps/ner/hf_token_classification.py</div><div id='m_start'> M Start Line: 143</div><div id='m_end'> M End Line: 174</div><div id='n_start'> N Start Line: 144</div><div id='n_end'> N End Line: 181</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                        entity.add_mapping(new_mapping)
                        self.lookup_cache.update_lookup_cache(entity, new_mapping)

        <a id="change">return </a>docs<a id="change">, []</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
        entities = self.lookup_cache.check_lookup_cache(entities)
        if len(entities) &gt; 0:
            for entity in entities:
                <a id="change">try:
                    </a>ontology_name = self.entity_class_to_ontology_mappings[entity.entity_class]
                    index = self.ontology_index_dict.get(ontology_name, None)
                    if index is not None:
                        metadata_df = index.search(entity.match)
                        for i, row in metadata_df.iterrows():
                            row_dict = row.to_dict()
                            ontology_id = row_dict.pop("iri")
                            new_mapping = Mapping(
                                source=ontology_name,
                                idx=ontology_id,
                                mapping_type="direct",
                                metadata=row_dict,
                            )
                            entity.add_mapping(new_mapping)
                            self.lookup_cache.update_lookup_cache(entity, new_mapping)
                <a id="change">except </a>Exception:
                    doc = find_document_from_entity(docs, entity)
                    <a id="change">doc.metadata[PROCESSING_EXCEPTION] = </a><a id="change">traceback.format_exc()</a>
                    <a id="change">failed_docs.append(</a>doc<a id="change">)</a>

        return docs, failed_docs
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/astrazeneca/kazu/commit/f33b69861ab79d94eb78258e6bf9eff3c9f0c3e8#diff-70cac163c7415c53bffa43163128a843d246ed07804872cad842462fc7a6df2bL44' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33257612</div><div id='project'> Project Name: astrazeneca/kazu</div><div id='commit'> Commit Name: f33b69861ab79d94eb78258e6bf9eff3c9f0c3e8</div><div id='time'> Time: 2021-11-23</div><div id='author'> Author: richard.jackson4@astrazeneca.com</div><div id='file'> File Name: azner/steps/linking/dictionary.py</div><div id='m_class'> M Class Name: DictionaryEntityLinkingStep</div><div id='n_method'> N Class Name: DictionaryEntityLinkingStep</div><div id='m_method'> M Method Name: _run(2)</div><div id='n_method'> N Method Name: _run(2)</div><div id='m_parent_class'> M Parent Class: BaseStep</div><div id='n_parent_class'> N Parent Class: BaseStep</div><div id='m_file'> M File Name: azner/steps/linking/dictionary.py</div><div id='n_file'> N File Name: azner/steps/linking/dictionary.py</div><div id='m_start'> M Start Line: 61</div><div id='m_end'> M End Line: 77</div><div id='n_start'> N Start Line: 56</div><div id='n_end'> N End Line: 85</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                else:
                    if self.method == EnsemblMethods.HIGHEST_SCORE.value:
                        entity.metadata.mappings = self.highest_confidence(entity.metadata.mappings)
        <a id="change">return </a>docs<a id="change">, []</a>

    def highest_confidence(self, mappings: List[Mapping]):
        return sorted(mappings, key=lambda x: x.metadata[LINK_SCORE], reverse=True)[
            : self.keep_top_n</code></pre><h3>After Change</h3><pre><code class='java'>
    def _run(self, docs: List[Document]) -&gt; Tuple[List[Document], List[Document]]:
        failed_docs = []
        for doc in docs:
            <a id="change">try:
                </a>entities = doc.get_entities()
                for entity in entities:
                    if entity.metadata is None or entity.metadata.mappings is None:
                        continue
                    else:
                        processing = MappingPostProcessing(entity, self.linker_score_thresholds)
                        entity.metadata.mappings = processing()[: self.keep_top_n]
            <a id="change">except </a>Exception:
                <a id="change">doc.metadata[PROCESSING_EXCEPTION] = </a><a id="change">traceback.format_exc()</a>
                <a id="change">failed_docs.append(</a>doc<a id="change">)</a>
        return docs, failed_docs
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/astrazeneca/kazu/commit/3b6d69a5c17dcbe9d6a7f1a875e4f09511428916#diff-6f2a1caced5d64b7c0fe3963bd802fd1a0844adf491123e48343639b1f710f4dL27' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33257607</div><div id='project'> Project Name: astrazeneca/kazu</div><div id='commit'> Commit Name: 3b6d69a5c17dcbe9d6a7f1a875e4f09511428916</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: richard.jackson4@astrazeneca.com</div><div id='file'> File Name: azner/steps/linking/link_ensembling.py</div><div id='m_class'> M Class Name: EnsembleEntityLinkingStep</div><div id='n_method'> N Class Name: EnsembleEntityLinkingStep</div><div id='m_method'> M Method Name: _run(2)</div><div id='n_method'> N Method Name: _run(2)</div><div id='m_parent_class'> M Parent Class: BaseStep</div><div id='n_parent_class'> N Parent Class: BaseStep</div><div id='m_file'> M File Name: azner/steps/linking/link_ensembling.py</div><div id='n_file'> N File Name: azner/steps/linking/link_ensembling.py</div><div id='m_start'> M Start Line: 29</div><div id='m_end'> M End Line: 36</div><div id='n_start'> N Start Line: 196</div><div id='n_end'> N End Line: 209</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 reset the entity mapper in preparation for the next section
            self.entity_mapper.reset()

        <a id="change">return </a>docs<a id="change">, []</a>

    def get_list_of_batch_encoding_frames_for_section(
        self, batch_encoding: BatchEncoding, section_index: int
    ) -&gt; List[int]:</code></pre><h3>After Change</h3><pre><code class='java'>

    def _run(self, docs: List[Document]) -&gt; Tuple[List[Document], List[Document]]:
        failed_docs = []
        <a id="change">try:
            </a>loader, id_section_map = self.get_dataloader(docs)
            &#47&#47 run the transformer and get results
            confidence_and_labels_tensor = self.get_confidence_and_labels_tensor(loader)
            for section_index, section in id_section_map.items():
                &#47&#47 for long docs, we need to split section.get_text() into frames (i.e. portions that will fit into Bert or
                &#47&#47 similar)
                ner_processed_section = self.merge_section_frames(
                    section_index=section_index,
                    batch_encoding=loader.dataset.encodings,
                    confidence_and_labels_tensor=confidence_and_labels_tensor,
                )
                all_words = ner_processed_section.to_tokenized_words(self.config.id2label)
                transformed_words = self.bio_preprocessor(all_words)
                for transformed_word in transformed_words:
                    for i, label in enumerate(transformed_word.word_labels_strings):
                        if self.debug:
                            logger.info(
                                f"processing label: {label} for token {section.get_text()[transformed_word.word_offsets[i][0]:transformed_word.word_offsets[i][1]]}"
                            )
                        self.entity_mapper.update_parse_states(
                            label,
                            offsets=transformed_word.word_offsets[i],
                            text=section.get_text(),
                            confidence=transformed_word.word_confidences[i],
                        )

                &#47&#47 at the end of the section, get the results
                section.entities = self.entity_mapper.get_entities()
                &#47&#47 reset the entity mapper in preparation for the next section
                self.entity_mapper.reset()
        <a id="change">except </a>Exception:
            for doc in docs:
                <a id="change">doc.metadata[PROCESSING_EXCEPTION] = </a><a id="change">traceback.format_exc()</a>
                <a id="change">failed_docs.append(</a>doc<a id="change">)</a>

        return docs, failed_docs

    def get_list_of_batch_encoding_frames_for_section(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/astrazeneca/kazu/commit/b2a144007ee01cc122f7d69d16cd483936a42289#diff-9ec49f69bf2c8adcd8a03e6c8e31f8cdc4c5d41c030cc74bfd06e94922c367ddL143' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33257606</div><div id='project'> Project Name: astrazeneca/kazu</div><div id='commit'> Commit Name: b2a144007ee01cc122f7d69d16cd483936a42289</div><div id='time'> Time: 2021-11-23</div><div id='author'> Author: richard.jackson4@astrazeneca.com</div><div id='file'> File Name: azner/steps/ner/hf_token_classification.py</div><div id='m_class'> M Class Name: TransformersModelForTokenClassificationNerStep</div><div id='n_method'> N Class Name: TransformersModelForTokenClassificationNerStep</div><div id='m_method'> M Method Name: _run(2)</div><div id='n_method'> N Method Name: _run(2)</div><div id='m_parent_class'> M Parent Class: BaseStep</div><div id='n_parent_class'> N Parent Class: BaseStep</div><div id='m_file'> M File Name: azner/steps/ner/hf_token_classification.py</div><div id='n_file'> N File Name: azner/steps/ner/hf_token_classification.py</div><div id='m_start'> M Start Line: 144</div><div id='m_end'> M End Line: 175</div><div id='n_start'> N Start Line: 145</div><div id='n_end'> N End Line: 182</div><BR>