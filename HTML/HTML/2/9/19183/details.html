<html><h3>Pattern ID :19183
</h3><img src='62406824.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        batch_size = x.shape[0]
        x_len = x.shape[1]
        x_pos = self.pos_emb(torch.arange(x_len).type(torch.cuda.FloatTensor if self.use_cuda else torch.FloatTensor)) &#47&#47 len x n_state
        x_pos = <a id="change">Variable(</a>x_pos.unsqueeze(0).repeat(batch_size, 1, 1)<a id="change">, requires_grad=False)</a>
        <a id="change">if </a><a id="change">self.use_cuda</a>:
            <a id="change">x_pos.cuda()</a>
        x_input = x_emb + x_pos
        h = self.drop(x_input)
        return h
</code></pre><h3>After Change</h3><pre><code class='java'>
        batch_size = x.shape[0]
        x_len = x.shape[1]
        x_pos = self.pos_emb(torch.arange(x_len).type(torch.cuda.FloatTensor if self.use_cuda else torch.FloatTensor)) &#47&#47 len x n_state
        x_pos = <a id="change">Variable(x_pos.unsqueeze(0).repeat(batch_size, 1, 1), requires_grad=False).cuda() if </a><a id="change">self.use_cuda else </a><a id="change">Variable(</a>x_pos.unsqueeze(0).repeat(batch_size, 1, 1)<a id="change">, requires_grad=False)</a>
        x_input = x_emb + x_pos
        h = self.drop(x_input)
        return h
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/yale-lily/summertime/commit/3a7659bf94947c1540b3a628d4bbb58cbd44ce8e#diff-d07348f0d540dbe7aa2fe4a9db296828d5b7db58a8b25c2a4d48b35684e25092L388' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 62406824</div><div id='project'> Project Name: yale-lily/summertime</div><div id='commit'> Commit Name: 3a7659bf94947c1540b3a628d4bbb58cbd44ce8e</div><div id='time'> Time: 2021-08-05</div><div id='author'> Author: troy.feng@yale.edu</div><div id='file'> File Name: model/third_party/HMNet/Models/Networks/Transformer.py</div><div id='m_class'> M Class Name: Embedder</div><div id='n_method'> N Class Name: Embedder</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/third_party/HMNet/Models/Networks/Transformer.py</div><div id='n_file'> N File Name: model/third_party/HMNet/Models/Networks/Transformer.py</div><div id='m_start'> M Start Line: 397</div><div id='m_end'> M End Line: 400</div><div id='n_start'> N Start Line: 388</div><div id='n_end'> N End Line: 391</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        n_head = int(opt[&quotTRANSFORMER_HEAD&quot])
        resid_pdrop = opt[&quotTRANSFORMER_RESIDUAL_DROPOUT&quot]
        attn_pdrop = opt[&quotTRANSFORMER_ATTENTION_DROPOUT&quot]
        <a id="change">use_cuda</a> = opt[&quotcuda&quot]

        assert n_state % n_head == 0
        &#47&#47 if mask is needed, uncomment this
        self.maxlen = 2048 &#47&#47 beyond this scale 
        self.mask = <a id="change">Variable(</a>torch.tril(torch.ones(self.maxlen, self.maxlen)).view(1, 1, self.maxlen, self.maxlen)<a id="change">, requires_grad=False)</a>
        <a id="change">if </a>use_cuda:
            <a id="change">self.mask.cuda()</a>
        self.n_head = n_head
        self.c_proj = Conv1D(n_state, nx)
        self.attn_dropout = nn.Dropout(attn_pdrop)
        self.resid_dropout = nn.Dropout(resid_pdrop)</code></pre><h3>After Change</h3><pre><code class='java'>
        n_head = int(opt[&quotTRANSFORMER_HEAD&quot])
        resid_pdrop = opt[&quotTRANSFORMER_RESIDUAL_DROPOUT&quot]
        attn_pdrop = opt[&quotTRANSFORMER_ATTENTION_DROPOUT&quot]
        <a id="change">use_cuda</a> = opt[&quotcuda&quot]

        assert n_state % n_head == 0
        &#47&#47 if mask is needed, uncomment this
        self.maxlen = 2048 &#47&#47 beyond this scale 
        self.mask = <a id="change">Variable(torch.tril(torch.ones(self.maxlen, self.maxlen)).view(1, 1, self.maxlen, self.maxlen), requires_grad=False).cuda() if </a>use_cuda<a id="change"> else </a><a id="change">Variable(</a>torch.tril(torch.ones(self.maxlen, self.maxlen)).view(1, 1, self.maxlen, self.maxlen)<a id="change">, requires_grad=False)</a>
        self.n_head = n_head
        self.c_proj = Conv1D(n_state, nx)
        self.attn_dropout = nn.Dropout(attn_pdrop)
        self.resid_dropout = nn.Dropout(resid_pdrop)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yale-lily/summertime/commit/3a7659bf94947c1540b3a628d4bbb58cbd44ce8e#diff-d07348f0d540dbe7aa2fe4a9db296828d5b7db58a8b25c2a4d48b35684e25092L121' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 62406825</div><div id='project'> Project Name: yale-lily/summertime</div><div id='commit'> Commit Name: 3a7659bf94947c1540b3a628d4bbb58cbd44ce8e</div><div id='time'> Time: 2021-08-05</div><div id='author'> Author: troy.feng@yale.edu</div><div id='file'> File Name: model/third_party/HMNet/Models/Networks/Transformer.py</div><div id='m_class'> M Class Name: Attention</div><div id='n_method'> N Class Name: Attention</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/third_party/HMNet/Models/Networks/Transformer.py</div><div id='n_file'> N File Name: model/third_party/HMNet/Models/Networks/Transformer.py</div><div id='m_start'> M Start Line: 128</div><div id='m_end'> M End Line: 136</div><div id='n_start'> N Start Line: 128</div><div id='n_end'> N End Line: 133</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if &quotMIN_GEN_LENGTH&quot in self.opt:
            MIN_GEN_LENGTH = int(self.opt[&quotMIN_GEN_LENGTH&quot])
        for l in range(self.max_sent_len):
            y = <a id="change">Variable(</a>torch.LongTensor(sent_ids)<a id="change">)</a> &#47&#47 batch_size x l
            <a id="change">if </a><a id="change">self.use_cuda</a>:
                <a id="change">y.cuda()</a>
            decoder_outputs = self.decoder(x, x_out, y)
            probs = decoder_outputs[:, -1, :] &#47&#47 batch_size x vocab_size (only take the last output)
            for i in range(batch_size):
                topk_probs, _ = torch.topk(probs[i], k)</code></pre><h3>After Change</h3><pre><code class='java'>
        if &quotMIN_GEN_LENGTH&quot in self.opt:
            MIN_GEN_LENGTH = int(self.opt[&quotMIN_GEN_LENGTH&quot])
        for l in range(self.max_sent_len):
            y = <a id="change">Variable(torch.LongTensor(sent_ids)).cuda() if </a><a id="change">self.use_cuda else </a><a id="change">Variable(</a>torch.LongTensor(sent_ids)<a id="change">)</a> &#47&#47 batch_size x l
            decoder_outputs = self.decoder(x, x_out, y)
            probs = decoder_outputs[:, -1, :] &#47&#47 batch_size x vocab_size (only take the last output)
            for i in range(batch_size):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yale-lily/summertime/commit/3a7659bf94947c1540b3a628d4bbb58cbd44ce8e#diff-d07348f0d540dbe7aa2fe4a9db296828d5b7db58a8b25c2a4d48b35684e25092L543' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 62406821</div><div id='project'> Project Name: yale-lily/summertime</div><div id='commit'> Commit Name: 3a7659bf94947c1540b3a628d4bbb58cbd44ce8e</div><div id='time'> Time: 2021-08-05</div><div id='author'> Author: troy.feng@yale.edu</div><div id='file'> File Name: model/third_party/HMNet/Models/Networks/Transformer.py</div><div id='m_class'> M Class Name: TransformerBeam</div><div id='n_method'> N Class Name: TransformerBeam</div><div id='m_method'> M Method Name: topk(3)</div><div id='n_method'> N Method Name: topk(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model/third_party/HMNet/Models/Networks/Transformer.py</div><div id='n_file'> N File Name: model/third_party/HMNet/Models/Networks/Transformer.py</div><div id='m_start'> M Start Line: 559</div><div id='m_end'> M End Line: 562</div><div id='n_start'> N Start Line: 542</div><div id='n_end'> N End Line: 551</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                x_outs.extend([x_out[idx, :, :].unsqueeze(0) for node in last_nodes[idx]])
                xs.extend([x[idx, :].unsqueeze(0) for node in last_nodes[idx]])

            ys = <a id="change">Variable(</a>torch.LongTensor(ys)<a id="change">)</a> &#47&#47 N x l
            <a id="change">if </a><a id="change">self.use_cuda</a>:
                <a id="change">ys.cuda()</a>
            x_outs = torch.cat(x_outs, dim = 0) &#47&#47 N x x_len x n_state
            xs = torch.cat(xs, dim = 0) &#47&#47 N x x_len
            probs = self.decoder(xs, x_outs, ys)
            log_probs = torch.log(probs[:, -1, :] + 1e-15) &#47&#47 N x vocab_size (only take the last output)</code></pre><h3>After Change</h3><pre><code class='java'>
                x_outs.extend([x_out[idx, :, :].unsqueeze(0) for node in last_nodes[idx]])
                xs.extend([x[idx, :].unsqueeze(0) for node in last_nodes[idx]])

            ys = <a id="change">Variable(torch.LongTensor(ys)).cuda() if </a><a id="change">self.use_cuda else </a><a id="change">Variable(</a>torch.LongTensor(ys)<a id="change">)</a> &#47&#47 N x l
            x_outs = torch.cat(x_outs, dim = 0) &#47&#47 N x x_len x n_state
            xs = torch.cat(xs, dim = 0) &#47&#47 N x x_len
            probs = self.decoder(xs, x_outs, ys)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yale-lily/summertime/commit/3a7659bf94947c1540b3a628d4bbb58cbd44ce8e#diff-d07348f0d540dbe7aa2fe4a9db296828d5b7db58a8b25c2a4d48b35684e25092L596' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 62406822</div><div id='project'> Project Name: yale-lily/summertime</div><div id='commit'> Commit Name: 3a7659bf94947c1540b3a628d4bbb58cbd44ce8e</div><div id='time'> Time: 2021-08-05</div><div id='author'> Author: troy.feng@yale.edu</div><div id='file'> File Name: model/third_party/HMNet/Models/Networks/Transformer.py</div><div id='m_class'> M Class Name: TransformerBeam</div><div id='n_method'> N Class Name: TransformerBeam</div><div id='m_method'> M Method Name: beam_search(2)</div><div id='n_method'> N Method Name: beam_search(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model/third_party/HMNet/Models/Networks/Transformer.py</div><div id='n_file'> N File Name: model/third_party/HMNet/Models/Networks/Transformer.py</div><div id='m_start'> M Start Line: 623</div><div id='m_end'> M End Line: 626</div><div id='n_start'> N Start Line: 605</div><div id='n_end'> N End Line: 613</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                if self.use_cuda:
                    mask.cuda()
            else:
                mask = <a id="change">Variable(</a>torch.tril(torch.ones(w.size(-2), w.size(-1))).view(1, 1, w.size(-2), w.size(-1))<a id="change">, requires_grad=False)</a>
                <a id="change">if </a><a id="change">self.use_cuda</a>:
                    <a id="change">mask.cuda()</a>

        if x_mask is not None:
            mask = x_mask.unsqueeze(1).unsqueeze(1).expand_as(w).float()
            &#47&#47 batch x n_head x len x kv_len</code></pre><h3>After Change</h3><pre><code class='java'>
            if w.size(-2) &lt;= self.maxlen and w.size(-1) &lt;= self.maxlen:
                mask = self.mask[:, :, :w.size(-2), :w.size(-1)].cuda() if self.use_cuda else self.mask[:, :, :w.size(-2), :w.size(-1)]
            else:
                mask = <a id="change">Variable(torch.tril(torch.ones(w.size(-2), w.size(-1))).view(1, 1, w.size(-2), w.size(-1)), requires_grad=False).cuda() if </a><a id="change">self.use_cuda else </a><a id="change">Variable(</a>torch.tril(torch.ones(w.size(-2), w.size(-1))).view(1, 1, w.size(-2), w.size(-1))<a id="change">, requires_grad=False)</a>

        if x_mask is not None:
            mask = x_mask.unsqueeze(1).unsqueeze(1).expand_as(w).float()
            &#47&#47 batch x n_head x len x kv_len</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yale-lily/summertime/commit/3a7659bf94947c1540b3a628d4bbb58cbd44ce8e#diff-d07348f0d540dbe7aa2fe4a9db296828d5b7db58a8b25c2a4d48b35684e25092L154' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 62406823</div><div id='project'> Project Name: yale-lily/summertime</div><div id='commit'> Commit Name: 3a7659bf94947c1540b3a628d4bbb58cbd44ce8e</div><div id='time'> Time: 2021-08-05</div><div id='author'> Author: troy.feng@yale.edu</div><div id='file'> File Name: model/third_party/HMNet/Models/Networks/Transformer.py</div><div id='m_class'> M Class Name: Attention</div><div id='n_method'> N Class Name: Attention</div><div id='m_method'> M Method Name: _attn(7)</div><div id='n_method'> N Method Name: _attn(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/third_party/HMNet/Models/Networks/Transformer.py</div><div id='n_file'> N File Name: model/third_party/HMNet/Models/Networks/Transformer.py</div><div id='m_start'> M Start Line: 161</div><div id='m_end'> M End Line: 170</div><div id='n_start'> N Start Line: 155</div><div id='n_end'> N End Line: 164</div><BR>