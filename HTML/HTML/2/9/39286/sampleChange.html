<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        Initialize the tokenization process
        :param args: arguments from Triton config file
        
        current_path: str = <a id="change">os.path.join(args["model_repository"]</a>, <a id="change">args["model_version"])</a>
        self.device = "cpu" if args["model_instance_kind"] == "CPU" else "cuda"
        &#47&#47 more variables in https://github.com/triton-inference-server/python_backend/blob/main/src/python.cc
        model_config = AutoConfig.from_pretrained(current_path)
        target_model = args["model_name"].replace("_generate", "_model")</code></pre><h3>After Change</h3><pre><code class='java'>
        Initialize the tokenization process
        :param args: arguments from Triton config file
        
        current_path: str = <a id="change">str(Path(args["model_repository"]</a><a id="change">).parent.absolute())</a>
        self.device = "cpu" if args["model_instance_kind"] == "CPU" else "cuda"
        &#47&#47 more variables in https://github.com/triton-inference-server/python_backend/blob/main/src/python.cc
        model_config = AutoConfig.from_pretrained(current_path)
        target_model = args["model_name"].replace("_generate", "_model")</code></pre>