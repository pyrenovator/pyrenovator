<html><h3>Pattern ID :22809
</h3><img src='72412625.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            self.state = self.state * self.alpha_mem

            &#47&#47 add recurrent input
            rec_input = self.hidden_layer(<a id="change">self.activations.reshape(</a>batch_size, <a id="change">-1</a><a id="change">)</a>).reshape(input_current[:, step].shape)
            total_input = input_current[:, step] + rec_input

            &#47&#47 Add the input currents which are normalised by tau to membrane potential state
            self.state<a id="change"> = </a>self.state<a id="change"> + </a>total_input * (1-self.alpha_mem)

            &#47&#47 Clip membrane potential that is too low
            if self.threshold_low: self.state<a id="change"> = </a>torch.clamp(self.state, min=self.threshold_low)

        self.tw = time_steps
        self.spikes_number = output_spikes.abs().sum()</code></pre><h3>After Change</h3><pre><code class='java'>
        
        
        batch_size, n_time_steps, *other_dimensions = input_current.shape
        rec_out = <a id="change">torch.zeros(</a>(batch_size<a id="change">, 1, *other_dimensions</a>)<a id="change">)</a>
        output_spikes = torch.zeros_like(input_current)
        
        for step in range(n_time_steps):
            total_input = input_current[:, step:step+1] + rec_out

            &#47&#47 compute output spikes
            output = self.lif(total_input)
            output_spikes[:, step:step+1]<a id="change"> = </a>output
            
            &#47&#47 compute recurrent output that will be added to the input at the next time step
            rec_out = <a id="change">self.rec_weights(output.reshape(batch_size, -1)).reshape(</a>input_current[:, step:step+1].shape<a id="change">)</a>

        return output_spikes

    def reset_states(self, shape=None, randomize=False):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/synsense/sinabs/commit/8c263985e90ff782f31e98955f40fad6e906fdb7#diff-eb45a8f4acbdb2d113b025c3ff70f42dec74f5b5e4a6b38c0b1ce67c660da65fL164' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 72412625</div><div id='project'> Project Name: synsense/sinabs</div><div id='commit'> Commit Name: 8c263985e90ff782f31e98955f40fad6e906fdb7</div><div id='time'> Time: 2021-11-02</div><div id='author'> Author: gregor.lenz@synsense.ai</div><div id='file'> File Name: sinabs/layers/lif.py</div><div id='m_class'> M Class Name: LIFRecurrent</div><div id='n_method'> N Class Name: LIFRecurrent</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: LIF</div><div id='m_file'> M File Name: sinabs/layers/lif.py</div><div id='n_file'> N File Name: sinabs/layers/lif.py</div><div id='m_start'> M Start Line: 165</div><div id='m_end'> M End Line: 192</div><div id='n_start'> N Start Line: 164</div><div id='n_end'> N End Line: 176</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    F, _, KL = weight.shape
    _, _,  OL = grad_output.shape

    grad_out_reshaped = <a id="change">grad_output.data.transpose(1, 2, 0).reshape(</a>F, <a id="change">-1</a><a id="change">)</a>
    grad_weight = (grad_out_reshaped @ x_cols.T).reshape(weight.shape)

    grad_x_cols<a id="change"> = </a>weight.data.reshape(F, -1).T<a id="change"> @ </a>grad_out_reshaped
    grad_x_cols.shape = (C, KL, N, OL)
    grad_x<a id="change"> = </a>col2im(grad_x_cols, x.shape, 1, KL, 0, stride)

    return grad_x, grad_weight
</code></pre><h3>After Change</h3><pre><code class='java'>

    grad_weight = (grad_output.transpose(1, 2, 0).reshape(num_filters, -1) @ x_cols.T).reshape(weight.shape)

    grad_x = <a id="change">np.zeros(</a>(batch_size<a id="change">, in_channel, signal_length</a>)<a id="change">, dtype=grad_output.dtype)</a>

    for k in range(output_length):
        X = k % output_length
        iX = X * stride

        grad_x[:, :, iX:iX+kernel_length]<a id="change"> += </a>np.einsum(&quotik, kjy-&gt;ijy&quot, grad_output[:, :, X], weight)
    
    grad_x = <a id="change">grad_x.reshape(</a>(batch_size, in_channel, signal_length)<a id="change">)</a>

    return grad_x, grad_weight
        
def conv2d_backward(grad_output, x, weight, x_cols, stride):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pabannier/nanograd/commit/442722b1830cdbf5fe8874edf3ecce602b3e9526#diff-ffe32cedb99eac490e9ad9651ff136011036f2f2e60044c1d7c2c0e1b812ad85L224' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 72412690</div><div id='project'> Project Name: pabannier/nanograd</div><div id='commit'> Commit Name: 442722b1830cdbf5fe8874edf3ecce602b3e9526</div><div id='time'> Time: 2021-02-02</div><div id='author'> Author: pierreantoine.bannier@gmail.com</div><div id='file'> File Name: nanograd/nn/ops_cpu.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: conv1d_backward(5)</div><div id='n_method'> N Method Name: conv1d_backward(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: nanograd/nn/ops_cpu.py</div><div id='n_file'> N File Name: nanograd/nn/ops_cpu.py</div><div id='m_start'> M Start Line: 224</div><div id='m_end'> M End Line: 234</div><div id='n_start'> N Start Line: 224</div><div id='n_end'> N End Line: 239</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    grad_out_reshaped = grad_output.transpose(1, 2, 3, 0).reshape(F, -1)
    grad_weight = (grad_out_reshaped @ x_cols.T).reshape(weight.shape)
        
    grad_x_cols<a id="change"> = </a><a id="change">weight.data.reshape(</a>F, <a id="change">-1</a><a id="change">)</a>.T<a id="change"> @ </a>grad_out_reshaped
    grad_x_cols.shape = (C, HH, WW, N, OH, OW)
    grad_x<a id="change"> = </a>col2im(grad_x_cols, x.shape, HH, WW, 0, stride) &#47&#47 Needs to be optimized

    return grad_x, grad_weight</code></pre><h3>After Change</h3><pre><code class='java'>

    grad_weight = (grad_output.transpose(1, 2, 3, 0).reshape(num_filters, -1) @ x_cols.T).reshape(weight.shape)

    grad_x = <a id="change">np.zeros(</a>(batch_size<a id="change">, in_channel, im_height, im_width</a>)<a id="change">, dtype=grad_output.dtype)</a>

    for k in range(output_height * output_width):
        X, Y = k % output_width, k // output_width
        iX, iY = X * stride, Y * stride
        grad_x[:,:, iY:iY+kernel_height, iX:iX+kernel_width]<a id="change"> += </a>np.einsum(&quotik,kjyx-&gt;ijyx&quot, grad_output[:,:,Y,X], weight)

    grad_x = <a id="change">grad_x.reshape(</a>(batch_size, in_channel, im_height, im_width)<a id="change">)</a>

    return grad_x, grad_weight</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pabannier/nanograd/commit/442722b1830cdbf5fe8874edf3ecce602b3e9526#diff-ffe32cedb99eac490e9ad9651ff136011036f2f2e60044c1d7c2c0e1b812ad85L238' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 72412692</div><div id='project'> Project Name: pabannier/nanograd</div><div id='commit'> Commit Name: 442722b1830cdbf5fe8874edf3ecce602b3e9526</div><div id='time'> Time: 2021-02-02</div><div id='author'> Author: pierreantoine.bannier@gmail.com</div><div id='file'> File Name: nanograd/nn/ops_cpu.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: conv2d_backward(5)</div><div id='n_method'> N Method Name: conv2d_backward(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: nanograd/nn/ops_cpu.py</div><div id='n_file'> N File Name: nanograd/nn/ops_cpu.py</div><div id='m_start'> M Start Line: 243</div><div id='m_end'> M End Line: 248</div><div id='n_start'> N Start Line: 248</div><div id='n_end'> N End Line: 257</div><BR>