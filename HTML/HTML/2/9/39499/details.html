<html><h3>Pattern ID :39499
</h3><img src='112153804.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            )),
            (&quotleaky_relu&quot, nn.LeakyReLU(0.2)),
            &#47&#47 _block(in_channels, out_channels, kernel_size, stride, padding)
            (&quotblock1&quot<a id="change">, self._block(features_d, features_d * 2, 4, 2, 1)</a>),
            (&quotblock2&quot, self._block(features_d * 2, features_d * 4, 4, 2, 1)),
            (&quotblock3&quot, self._block(features_d * 4, features_d * 8, 4, 2, 1)),
            &#47&#47 After all _block img output is 4x4 (Conv2d below makes into 1x1)</code></pre><h3>After Change</h3><pre><code class='java'>
            norm="batch_norm", img_size=64, final_sigmoid=True):
        super(Discriminator, self).__init__()
        self.norm = norm
        n_blocks = <a id="change">int(</a>math.log2(img_size<a id="change">//8</a>)<a id="change">)</a>
        block_list<a id="change"> = </a>[
            (f&quotblock{i}&quot, self._block(features_d*(2**(<a id="change">i</a><a id="change">-1</a>)), features_d*(2<a id="change">**i</a>),
                4, 2, 1))
            for <a id="change">i</a> in range(1,n_blocks+1)]
        full_list = [
            (&quotconv_in&quot, nn.Conv2d(
                channels_img, features_d, kernel_size=4,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ebartrum/lightning_gan_zoo/commit/dd5cb05b9edf8b06b7a7277aff29bb4ed0a4506e#diff-13843d1af9a61aa08d2fb6ae82bb335bbf8d79060ea9cbab84a4ddf574240466L11' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 112153804</div><div id='project'> Project Name: ebartrum/lightning_gan_zoo</div><div id='commit'> Commit Name: dd5cb05b9edf8b06b7a7277aff29bb4ed0a4506e</div><div id='time'> Time: 2021-04-21</div><div id='author'> Author: edward.bartrum@gmail.com</div><div id='file'> File Name: core/models/standard_networks.py</div><div id='m_class'> M Class Name: Discriminator</div><div id='n_method'> N Class Name: Discriminator</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: core/models/standard_networks.py</div><div id='n_file'> N File Name: core/models/standard_networks.py</div><div id='m_start'> M Start Line: 13</div><div id='m_end'> M End Line: 29</div><div id='n_start'> N Start Line: 11</div><div id='n_end'> N End Line: 32</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            (&quotleaky_relu&quot, nn.LeakyReLU(0.2)),
            &#47&#47 _block(in_channels, out_channels, kernel_size, stride, padding)
            (&quotblock1&quot, self._block(features_d, features_d * 2, 4, 2, 1)),
            (&quotblock2&quot<a id="change">, self._block(features_d * 2, features_d * 4, 4, 2, 1)</a>),
            (&quotblock3&quot, self._block(features_d * 4, features_d * 8, 4, 2, 1)),
            &#47&#47 After all _block img output is 4x4 (Conv2d below makes into 1x1)
            (&quotconv_out&quot, nn.Conv2d(features_d * 8, 1, kernel_size=4,</code></pre><h3>After Change</h3><pre><code class='java'>
            norm="batch_norm", img_size=64, final_sigmoid=True):
        super(Discriminator, self).__init__()
        self.norm = norm
        n_blocks = <a id="change">int(</a>math.log2(img_size<a id="change">//8</a>)<a id="change">)</a>
        block_list<a id="change"> = </a>[
            (f&quotblock{i}&quot, self._block(features_d*(2**(i<a id="change">-1</a>)), features_d*(2<a id="change">**</a>i),
                4, 2, 1))
            for <a id="change">i</a> in range(1,n_blocks+1)]
        full_list = [
            (&quotconv_in&quot, nn.Conv2d(
                channels_img, features_d, kernel_size=4,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ebartrum/lightning_gan_zoo/commit/dd5cb05b9edf8b06b7a7277aff29bb4ed0a4506e#diff-13843d1af9a61aa08d2fb6ae82bb335bbf8d79060ea9cbab84a4ddf574240466L9' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 112153803</div><div id='project'> Project Name: ebartrum/lightning_gan_zoo</div><div id='commit'> Commit Name: dd5cb05b9edf8b06b7a7277aff29bb4ed0a4506e</div><div id='time'> Time: 2021-04-21</div><div id='author'> Author: edward.bartrum@gmail.com</div><div id='file'> File Name: core/models/standard_networks.py</div><div id='m_class'> M Class Name: Discriminator</div><div id='n_method'> N Class Name: Discriminator</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: core/models/standard_networks.py</div><div id='n_file'> N File Name: core/models/standard_networks.py</div><div id='m_start'> M Start Line: 13</div><div id='m_end'> M End Line: 29</div><div id='n_start'> N Start Line: 11</div><div id='n_end'> N End Line: 32</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    j = torch.arange(heatmaps.shape[1]).reshape(1, -1, 1, 1)
    k = locs[:, :, None, 1, None].type(torch.int64)  &#47&#47 y first
    l = locs[:, :, 0, None, None].type(torch.int64)  &#47&#47 x second
    vals = heatmaps[i<a id="change">, j, k, l</a>].squeeze(-1).squeeze(-1)  &#47&#47 get rid of singleton dims
    return vals
</code></pre><h3>After Change</h3><pre><code class='java'>
    j = torch.arange(heatmaps.shape[1]).reshape(1, -1, 1, 1)
    k = locs[:, :, None, 1, None].type(torch.int64)
    l = locs[:, :, 0, None, None].type(torch.int64)
    <a id="change">pix_to_consider</a> = <a id="change">int(</a>np.ceil(sigma<a id="change"> * 2.0</a>)<a id="change">)</a> &#47&#47get all pixels within two stds.
    offsets<a id="change"> = </a>list(np.arange(<a id="change">-pix_to_consider</a>, pix_to_consider<a id="change">+1</a>))
    vals_all = []
    for offset in offsets:
        k_offset = k + offset</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/danbider/lightning-pose/commit/c2ea4f5fc3841def2213fb073698b9178edea896#diff-9dd67cdb80bc17d35d73536f0d0097629a0d6213a72e69af6280e984b273233fL288' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 112153802</div><div id='project'> Project Name: danbider/lightning-pose</div><div id='commit'> Commit Name: c2ea4f5fc3841def2213fb073698b9178edea896</div><div id='time'> Time: 2022-07-22</div><div id='author'> Author: colehurwitz@gmail.com</div><div id='file'> File Name: lightning_pose/data/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate_heatmaps_at_location(3)</div><div id='n_method'> N Method Name: evaluate_heatmaps_at_location(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: lightning_pose/data/utils.py</div><div id='n_file'> N File Name: lightning_pose/data/utils.py</div><div id='m_start'> M Start Line: 293</div><div id='m_end'> M End Line: 297</div><div id='n_start'> N Start Line: 304</div><div id='n_end'> N End Line: 322</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    j = torch.arange(heatmaps.shape[1]).reshape(1, -1, 1, 1)
    k = locs[:, :, None, 1, None].type(torch.int64)  &#47&#47 y first
    l = locs[:, :, 0, None, None].type(torch.int64)  &#47&#47 x second
    vals = heatmaps[i<a id="change">, j, k, l</a>].squeeze(-1).squeeze(-1)  &#47&#47 get rid of singleton dims
    return vals
</code></pre><h3>After Change</h3><pre><code class='java'>
    j = torch.arange(heatmaps.shape[1]).reshape(1, -1, 1, 1)
    k = locs[:, :, None, 1, None].type(torch.int64)
    l = locs[:, :, 0, None, None].type(torch.int64)
    <a id="change">pix_to_consider</a> = <a id="change">int(</a>np.ceil(sigma<a id="change"> * 2.0</a>)<a id="change">)</a> &#47&#47get all pixels within two stds.
    offsets<a id="change"> = </a>list(np.arange(<a id="change">-pix_to_consider</a>, pix_to_consider<a id="change">+1</a>))
    vals_all = []
    for offset in offsets:
        k_offset = k + offset</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/danbider/lightning-pose/commit/09f58d3175233d5d57b8369d64c9a58e5704bcec#diff-9dd67cdb80bc17d35d73536f0d0097629a0d6213a72e69af6280e984b273233fL288' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 112153801</div><div id='project'> Project Name: danbider/lightning-pose</div><div id='commit'> Commit Name: 09f58d3175233d5d57b8369d64c9a58e5704bcec</div><div id='time'> Time: 2022-07-22</div><div id='author'> Author: colehurwitz@gmail.com</div><div id='file'> File Name: lightning_pose/data/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate_heatmaps_at_location(3)</div><div id='n_method'> N Method Name: evaluate_heatmaps_at_location(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: lightning_pose/data/utils.py</div><div id='n_file'> N File Name: lightning_pose/data/utils.py</div><div id='m_start'> M Start Line: 293</div><div id='m_end'> M End Line: 297</div><div id='n_start'> N Start Line: 304</div><div id='n_end'> N End Line: 322</div><BR>