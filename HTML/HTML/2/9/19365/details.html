<html><h3>Pattern ID :19365
</h3><img src='63146433.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        for i in inputs:
            inf_inputs.append(Perturbation.perturb_tensor(i, self.reg_params.n_samples).float().cuda())

        inf_output<a id="change"> = </a><a id="change">self.model(</a>inf_inputs<a id="change">)</a>
        inf_loss = torch.nn.functional.binary_cross_entropy_with_logits(inf_output, expanded_logits)

        gradients = torch.autograd.grad(inf_loss, inf_inputs, create_graph=True)
        grads = [Regularization.get_batch_norm(gradients[k], loss=inf_loss,
                                            estimation=self.reg_params.estimation) for k in range(2)]

        inf_scores = torch.stack(grads)
        reg_term = Regularization.get_regularization_term(inf_scores, norm=self.reg_params.norm,
                                                        optim_method=self.reg_params.optim_method)

        <a id="change">return </a>self.reg_params.delta<a id="change"> * </a>reg_term</code></pre><h3>After Change</h3><pre><code class='java'>
        expanded_logits = Perturbation.get_expanded_logits(logits, self.reg_params.n_samples)

        inf_inputs = []
        inf_inputs_len = <a id="change">[]</a>
        <a id="change">for </a>ind, <a id="change">i</a> in enumerate(inputs[0])<a id="change">:
            </a>inf_inputs.append(Perturbation.perturb_tensor(i, self.reg_params.n_samples).float().cuda())
            <a id="change">inf_inputs_len.append(</a>Perturbation.perturb_tensor(inputs[1][ind], self.reg_params.n_samples,False)<a id="change">)</a>

        inf_output = self.model([inf_inputs, inf_inputs_len], training=True)
        inf_loss = torch.nn.functional.binary_cross_entropy_with_logits(inf_output, expanded_logits)

        gradients = torch.autograd.grad(inf_loss, inf_inputs, create_graph=True)
        grads = [Regularization.get_batch_norm(gradients[k], loss=inf_loss,
                                            estimation=self.reg_params.estimation) for k in range(2)]

        inf_scores = torch.stack(grads)
        reg_term = Regularization.get_regularization_term(inf_scores, norm=self.reg_params.norm,
                                                        optim_method=self.reg_params.optim_method)

        <a id="change">return </a>self.delta * reg_term</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pliang279/multibench/commit/c54605f2e0f9be6777682e7598449cf2b1cd3898#diff-f4bce8db7d62d54b2e245f6f2fd4f98ade42a4c0b4cea1530884e70b1042de26L228' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63146433</div><div id='project'> Project Name: pliang279/multibench</div><div id='commit'> Commit Name: c54605f2e0f9be6777682e7598449cf2b1cd3898</div><div id='time'> Time: 2021-04-07</div><div id='author'> Author: ztwu_nil@zju.edu.cn</div><div id='file'> File Name: objective_functions/regularization.py</div><div id='m_class'> M Class Name: RegularizationLoss</div><div id='n_method'> N Class Name: RegularizationLoss</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: objective_functions/regularization.py</div><div id='n_file'> N File Name: objective_functions/regularization.py</div><div id='m_start'> M Start Line: 228</div><div id='m_end'> M End Line: 243</div><div id='n_start'> N Start Line: 233</div><div id='n_end'> N End Line: 250</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        image = torch.from_numpy(image).unsqueeze(0).to(device)
        mask = torch.from_numpy(mask).unsqueeze(0).to(device)

        inpainted_image = <a id="change">self.model(</a>image, mask<a id="change">)</a>

        cur_res<a id="change"> = </a>inpainted_image[0].permute(1, 2, 0).detach().cpu().numpy()
        cur_res = cur_res[0:origin_height, 0:origin_width, :]
        cur_res = np.clip(cur_res<a id="change"> * </a>255, 0, 255).astype("uint8")
        cur_res = cv2.cvtColor(cur_res, cv2.COLOR_BGR2RGB)
        <a id="change">return </a>cur_res
</code></pre><h3>After Change</h3><pre><code class='java'>

        print("Trigger crop image")
        boxes = boxes_from_mask(mask)
        crop_result = <a id="change">[]</a>
        <a id="change">for box</a> in boxes<a id="change">:
            </a>crop_image, crop_box = self._run_box(image, mask, box)
            <a id="change">crop_result.append(</a>(crop_image, crop_box)<a id="change">)</a>

        image = (image.transpose(1, 2, 0) * 255).astype(np.uint8)[:, :, ::-1]
        for crop_image, crop_box in crop_result:
            x1, y1, x2, y2 = crop_box
            image[y1:y2, x1:x2, :] = crop_image
        <a id="change">return </a>image

    def _run_box(self, image, mask, box):
        </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sanster/lama-cleaner/commit/43c9c22c7312dd39feac4e3783e9ec080fd64243#diff-c64397576661152777123ab1a485c53dbfa8de21c16999da23c3b18cb8993606L34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63146432</div><div id='project'> Project Name: sanster/lama-cleaner</div><div id='commit'> Commit Name: 43c9c22c7312dd39feac4e3783e9ec080fd64243</div><div id='time'> Time: 2022-03-22</div><div id='author'> Author: cwq1913@gmail.com</div><div id='file'> File Name: lama_cleaner/lama/__init__.py</div><div id='m_class'> M Class Name: LaMa</div><div id='n_method'> N Class Name: LaMa</div><div id='m_method'> M Method Name: __call__(3)</div><div id='n_method'> N Method Name: __call__(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: lama_cleaner/lama/__init__.py</div><div id='n_file'> N File Name: lama_cleaner/lama/__init__.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 55</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 65</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for i in inputs:
            inf_inputs.append(Perturbation.perturb_tensor(i, self.reg_params.n_samples).float().cuda())

        inf_output<a id="change"> = </a><a id="change">self.model(</a>inf_inputs<a id="change">)</a>
        inf_loss = torch.nn.functional.binary_cross_entropy_with_logits(inf_output, expanded_logits)

        gradients = torch.autograd.grad(inf_loss, inf_inputs, create_graph=True)
        grads = [Regularization.get_batch_norm(gradients[k], loss=inf_loss,
                                            estimation=self.reg_params.estimation) for k in range(2)]

        inf_scores = torch.stack(grads)
        reg_term = Regularization.get_regularization_term(inf_scores, norm=self.reg_params.norm,
                                                        optim_method=self.reg_params.optim_method)

        <a id="change">return </a>self.reg_params.delta<a id="change"> * </a>reg_term</code></pre><h3>After Change</h3><pre><code class='java'>
        expanded_logits = Perturbation.get_expanded_logits(logits, self.reg_params.n_samples)

        inf_inputs = []
        inf_inputs_len = <a id="change">[]</a>
        <a id="change">for </a>ind, <a id="change">i</a> in enumerate(inputs[0])<a id="change">:
            </a>inf_inputs.append(Perturbation.perturb_tensor(i, self.reg_params.n_samples).float().cuda())
            <a id="change">inf_inputs_len.append(</a>Perturbation.perturb_tensor(inputs[1][ind], self.reg_params.n_samples,False)<a id="change">)</a>

        inf_output = self.model([inf_inputs, inf_inputs_len], training=True)
        inf_loss = torch.nn.functional.binary_cross_entropy_with_logits(inf_output, expanded_logits)

        gradients = torch.autograd.grad(inf_loss, inf_inputs, create_graph=True)
        grads = [Regularization.get_batch_norm(gradients[k], loss=inf_loss,
                                            estimation=self.reg_params.estimation) for k in range(2)]

        inf_scores = torch.stack(grads)
        reg_term = Regularization.get_regularization_term(inf_scores, norm=self.reg_params.norm,
                                                        optim_method=self.reg_params.optim_method)

        <a id="change">return </a>self.delta * reg_term</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pliang279/multibench/commit/0e0c7a49dc117cdb06f01380158e60a7ab4e0040#diff-f4bce8db7d62d54b2e245f6f2fd4f98ade42a4c0b4cea1530884e70b1042de26L224' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63146430</div><div id='project'> Project Name: pliang279/multibench</div><div id='commit'> Commit Name: 0e0c7a49dc117cdb06f01380158e60a7ab4e0040</div><div id='time'> Time: 2021-04-07</div><div id='author'> Author: ztwu_nil@zju.edu.cn</div><div id='file'> File Name: objective_functions/regularization.py</div><div id='m_class'> M Class Name: RegularizationLoss</div><div id='n_method'> N Class Name: RegularizationLoss</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: objective_functions/regularization.py</div><div id='n_file'> N File Name: objective_functions/regularization.py</div><div id='m_start'> M Start Line: 228</div><div id='m_end'> M End Line: 243</div><div id='n_start'> N Start Line: 233</div><div id='n_end'> N End Line: 250</div><BR>