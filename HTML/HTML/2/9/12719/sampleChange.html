<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        ddpm.set_progress_bar_config(disable=None)

        &#47&#47 Warmup pass when using mps (see &#47&#47372)
        <a id="change">if torch_device == "mps"</a>:
            _<a id="change"> = </a>ddpm(num_inference_steps=1)

        generator = torch.manual_seed(0)
        image = ddpm(generator=generator, num_inference_steps=2, output_type="numpy").images

        generator = torch.manual_seed(0)
        image_from_tuple = ddpm(generator=generator, num_inference_steps=2, output_type="numpy", return_dict=False)[0]

        image_slice = image[0, -3:, -3:, -1]
        image_from_tuple_slice = image_from_tuple[0, -3:, -3:, -1]

        assert image.shape == (1, 32, 32, 3)
        expected_slice = np.array(
            [1.000e00, 5.717e-01, 4.717e-01, 1.000e00, 0.000e00, 1.000e00, 3.000e-04, 0.000e00, 9.000e-04]
        )
        tolerance = 1e-2<a id="change"> if torch_device</a><a id="change"> != "mps" else </a>3e-2
        assert np.abs(image_slice.flatten() - expected_slice).max() &lt; tolerance
        assert np.abs(image_from_tuple_slice.flatten() - expected_slice).max() &lt; tolerance
</code></pre><h3>After Change</h3><pre><code class='java'>
        ddpm.to(device)
        ddpm.set_progress_bar_config(disable=None)

        generator = <a id="change">torch.Generator(device=device)</a>.manual_seed(0)
        image = ddpm(generator=generator, num_inference_steps=2, output_type="numpy").images

        generator = torch.Generator(device=device).manual_seed(0)</code></pre>