<html><h3>Pattern ID :12719
</h3><img src='43071937.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        ddpm.set_progress_bar_config(disable=None)

        &#47&#47 Warmup pass when using mps (see &#47&#47372)
        <a id="change">if torch_device == "mps"</a>:
            _<a id="change"> = </a>ddpm(num_inference_steps=1)

        generator = torch.manual_seed(0)
        image = ddpm(generator=generator, num_inference_steps=2, output_type="numpy").images

        generator = torch.manual_seed(0)
        image_from_tuple = ddpm(generator=generator, num_inference_steps=2, output_type="numpy", return_dict=False)[0]

        image_slice = image[0, -3:, -3:, -1]
        image_from_tuple_slice = image_from_tuple[0, -3:, -3:, -1]

        assert image.shape == (1, 32, 32, 3)
        expected_slice = np.array(
            [1.000e00, 5.717e-01, 4.717e-01, 1.000e00, 0.000e00, 1.000e00, 3.000e-04, 0.000e00, 9.000e-04]
        )
        tolerance = 1e-2<a id="change"> if torch_device</a><a id="change"> != "mps" else </a>3e-2
        assert np.abs(image_slice.flatten() - expected_slice).max() &lt; tolerance
        assert np.abs(image_from_tuple_slice.flatten() - expected_slice).max() &lt; tolerance
</code></pre><h3>After Change</h3><pre><code class='java'>
        ddpm.to(device)
        ddpm.set_progress_bar_config(disable=None)

        generator = <a id="change">torch.Generator(device=device)</a>.manual_seed(0)
        image = ddpm(generator=generator, num_inference_steps=2, output_type="numpy").images

        generator = torch.Generator(device=device).manual_seed(0)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/7d0c2729399c3ce019a30fc175b973e892fd5fc3#diff-54ac33beb8b31a207df4f953f6c6b74e9bf6dff3a4b07f672d2443eb427c8b5aL46' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 43071937</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: 7d0c2729399c3ce019a30fc175b973e892fd5fc3</div><div id='time'> Time: 2022-11-09</div><div id='author'> Author: anton@huggingface.co</div><div id='file'> File Name: tests/pipelines/ddim/test_ddim.py</div><div id='m_class'> M Class Name: DDIMPipelineFastTests</div><div id='n_method'> N Class Name: DDIMPipelineFastTests</div><div id='m_method'> M Method Name: test_inference(1)</div><div id='n_method'> N Method Name: test_inference(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase,PipelineTesterMixin</div><div id='n_parent_class'> N Parent Class: unittest.TestCase,PipelineTesterMixin</div><div id='m_file'> M File Name: tests/pipelines/ddim/test_ddim.py</div><div id='n_file'> N File Name: tests/pipelines/ddim/test_ddim.py</div><div id='m_start'> M Start Line: 54</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 46</div><div id='n_end'> N End Line: 57</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        init_image = self.dummy_image.to(torch_device)

        &#47&#47 Warmup pass when using mps (see &#47&#47372)
        <a id="change">if torch_device == "mps"</a>:
            generator = torch.manual_seed(0)
            _<a id="change"> = </a>ldm(init_image, generator=generator, num_inference_steps=1, output_type="numpy").images

        generator = torch.manual_seed(0)
        image = ldm(init_image, generator=generator, num_inference_steps=2, output_type="numpy").images

        image_slice = image[0, -3:, -3:, -1]

        assert image.shape == (1, 64, 64, 3)
        expected_slice = np.array([0.8634, 0.8186, 0.6416, 0.6846, 0.4427, 0.5676, 0.4679, 0.6247, 0.5176])
        tolerance = 1e-2<a id="change"> if </a><a id="change">torch_device != "mps" else </a>3e-2
        assert np.abs(image_slice.flatten() - expected_slice).max() &lt; tolerance

</code></pre><h3>After Change</h3><pre><code class='java'>

        init_image = self.dummy_image.to(device)

        generator = <a id="change">torch.Generator(device=device)</a>.manual_seed(0)
        image = ldm(init_image, generator=generator, num_inference_steps=2, output_type="numpy").images

        image_slice = image[0, -3:, -3:, -1]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/7d0c2729399c3ce019a30fc175b973e892fd5fc3#diff-e330b4b2bcb242773cd9d994d7415b7a32cb211a1d97f9f68f5ad4e734e5616eL70' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 43071936</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: 7d0c2729399c3ce019a30fc175b973e892fd5fc3</div><div id='time'> Time: 2022-11-09</div><div id='author'> Author: anton@huggingface.co</div><div id='file'> File Name: tests/pipelines/latent_diffusion/test_latent_diffusion_superresolution.py</div><div id='m_class'> M Class Name: LDMSuperResolutionPipelineFastTests</div><div id='n_method'> N Class Name: LDMSuperResolutionPipelineFastTests</div><div id='m_method'> M Method Name: test_inference_superresolution(1)</div><div id='n_method'> N Method Name: test_inference_superresolution(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase,PipelineTesterMixin</div><div id='n_parent_class'> N Parent Class: unittest.TestCase,PipelineTesterMixin</div><div id='m_file'> M File Name: tests/pipelines/latent_diffusion/test_latent_diffusion_superresolution.py</div><div id='n_file'> N File Name: tests/pipelines/latent_diffusion/test_latent_diffusion_superresolution.py</div><div id='m_start'> M Start Line: 79</div><div id='m_end'> M End Line: 93</div><div id='n_start'> N Start Line: 71</div><div id='n_end'> N End Line: 82</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        ddpm.set_progress_bar_config(disable=None)

        &#47&#47 Warmup pass when using mps (see &#47&#47372)
        <a id="change">if torch_device == "mps"</a>:
            _<a id="change"> = </a>ddpm(num_inference_steps=1)

        generator = torch.manual_seed(0)
        image = ddpm(generator=generator, num_inference_steps=2, output_type="numpy").images

        generator = torch.manual_seed(0)
        image_from_tuple = ddpm(generator=generator, num_inference_steps=2, output_type="numpy", return_dict=False)[0]

        image_slice = image[0, -3:, -3:, -1]
        image_from_tuple_slice = image_from_tuple[0, -3:, -3:, -1]

        assert image.shape == (1, 32, 32, 3)
        expected_slice = np.array(
            [5.589e-01, 7.089e-01, 2.632e-01, 6.841e-01, 1.000e-04, 9.999e-01, 1.973e-01, 1.000e-04, 8.010e-02]
        )
        tolerance = 1e-2<a id="change"> if </a><a id="change">torch_device != "mps" else </a>3e-2
        assert np.abs(image_slice.flatten() - expected_slice).max() &lt; tolerance
        assert np.abs(image_from_tuple_slice.flatten() - expected_slice).max() &lt; tolerance
</code></pre><h3>After Change</h3><pre><code class='java'>
        ddpm.to(device)
        ddpm.set_progress_bar_config(disable=None)

        generator = <a id="change">torch.Generator(device=device)</a>.manual_seed(0)
        image = ddpm(generator=generator, num_inference_steps=2, output_type="numpy").images

        generator = torch.Generator(device=device).manual_seed(0)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/7d0c2729399c3ce019a30fc175b973e892fd5fc3#diff-e069d053d70d7f8f66501fcff0941e9a2d0c2855ffeab5ab30d1934067638ef0L46' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 43071939</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: 7d0c2729399c3ce019a30fc175b973e892fd5fc3</div><div id='time'> Time: 2022-11-09</div><div id='author'> Author: anton@huggingface.co</div><div id='file'> File Name: tests/pipelines/ddpm/test_ddpm.py</div><div id='m_class'> M Class Name: DDPMPipelineFastTests</div><div id='n_method'> N Class Name: DDPMPipelineFastTests</div><div id='m_method'> M Method Name: test_inference(1)</div><div id='n_method'> N Method Name: test_inference(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase,PipelineTesterMixin</div><div id='n_parent_class'> N Parent Class: unittest.TestCase,PipelineTesterMixin</div><div id='m_file'> M File Name: tests/pipelines/ddpm/test_ddpm.py</div><div id='n_file'> N File Name: tests/pipelines/ddpm/test_ddpm.py</div><div id='m_start'> M Start Line: 55</div><div id='m_end'> M End Line: 71</div><div id='n_start'> N Start Line: 47</div><div id='n_end'> N End Line: 58</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        ddpm.set_progress_bar_config(disable=None)

        &#47&#47 Warmup pass when using mps (see &#47&#47372)
        <a id="change">if torch_device == "mps"</a>:
            _<a id="change"> = </a>ddpm(num_inference_steps=1)

        generator = torch.manual_seed(0)
        image = ddpm(generator=generator, num_inference_steps=2, output_type="numpy").images

        generator = torch.manual_seed(0)
        image_from_tuple = ddpm(generator=generator, num_inference_steps=2, output_type="numpy", return_dict=False)[0]

        image_slice = image[0, -3:, -3:, -1]
        image_from_tuple_slice = image_from_tuple[0, -3:, -3:, -1]

        assert image.shape == (1, 32, 32, 3)
        expected_slice = np.array(
            [1.000e00, 5.717e-01, 4.717e-01, 1.000e00, 0.000e00, 1.000e00, 3.000e-04, 0.000e00, 9.000e-04]
        )
        tolerance = 1e-2<a id="change"> if </a><a id="change">torch_device != "mps" else </a>3e-2
        assert np.abs(image_slice.flatten() - expected_slice).max() &lt; tolerance
        assert np.abs(image_from_tuple_slice.flatten() - expected_slice).max() &lt; tolerance
</code></pre><h3>After Change</h3><pre><code class='java'>
        generator = torch.Generator(device=device).manual_seed(0)
        image = ddpm(generator=generator, num_inference_steps=2, output_type="numpy").images

        generator = <a id="change">torch.Generator(device=device)</a>.manual_seed(0)
        image_from_tuple = ddpm(generator=generator, num_inference_steps=2, output_type="numpy", return_dict=False)[0]

        image_slice = image[0, -3:, -3:, -1]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/7d0c2729399c3ce019a30fc175b973e892fd5fc3#diff-54ac33beb8b31a207df4f953f6c6b74e9bf6dff3a4b07f672d2443eb427c8b5aL45' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 43071938</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: 7d0c2729399c3ce019a30fc175b973e892fd5fc3</div><div id='time'> Time: 2022-11-09</div><div id='author'> Author: anton@huggingface.co</div><div id='file'> File Name: tests/pipelines/ddim/test_ddim.py</div><div id='m_class'> M Class Name: DDIMPipelineFastTests</div><div id='n_method'> N Class Name: DDIMPipelineFastTests</div><div id='m_method'> M Method Name: test_inference(1)</div><div id='n_method'> N Method Name: test_inference(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase,PipelineTesterMixin</div><div id='n_parent_class'> N Parent Class: unittest.TestCase,PipelineTesterMixin</div><div id='m_file'> M File Name: tests/pipelines/ddim/test_ddim.py</div><div id='n_file'> N File Name: tests/pipelines/ddim/test_ddim.py</div><div id='m_start'> M Start Line: 54</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 46</div><div id='n_end'> N End Line: 57</div><BR>