<html><h3>Pattern ID :27446
</h3><img src='81574456.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        )
        target_dict.update(identity_target)

        tokenised_text<a id="change"> = </a><a id="change">self.tokenizer(
            </a>text<a id="change">, return_tensors="pt", padding=True, truncation=True
        )</a>
        tokenised_text<a id="change"> = </a>tokenised_text.data
        meta["multi_target"] = torch.tensor(
            list(target_dict.values()), dtype=torch.int32
        )
        meta["text_id"] = text_id
        if self.train:
            meta["weights"] = self.weights[index]
        else:
            meta["weights"] = torch.tensor([1], dtype=torch.int32)

        meta["toxicity_ids"] = torch.tensor(
            [True] * len(self.classes) + [False] * len(self.identity_classes)
        )
        <a id="change">return </a>tokenised_text<a id="change">, meta</a>

    def compute_weigths(self, train_df):
        Inspired from 2nd solution.
        Source: https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/100661</code></pre><h3>After Change</h3><pre><code class='java'>
        else:
            meta["weights"] = torch.tensor([1], dtype=torch.int32)

        <a id="change">meta["toxicity_ids"]</a> = torch.tensor(
            [True] * len(self.classes) + [False] * len(self.identity_classes)
        )
        <a id="change">return </a>text<a id="change">, meta</a>

    def compute_weigths(self, train_df):
        Inspired from 2nd solution.
        Source: https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/100661</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/unitaryai/detoxify/commit/78f55b5b0d152a1b464edd9b64e844f676ba80ba#diff-4f64d3cf185856bf97e6aafaf27a45ebbd069972dc408794aeecdde63faaf1fdL154' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 81574456</div><div id='project'> Project Name: unitaryai/detoxify</div><div id='commit'> Commit Name: 78f55b5b0d152a1b464edd9b64e844f676ba80ba</div><div id='time'> Time: 2020-10-02</div><div id='author'> Author: laura.hanu10@gmail.com</div><div id='file'> File Name: src/data_loaders.py</div><div id='m_class'> M Class Name: JigsawDataBiasBERT</div><div id='n_method'> N Class Name: JigsawDataBiasBERT</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: JigsawData</div><div id='n_parent_class'> N Parent Class: JigsawData</div><div id='m_file'> M File Name: src/data_loaders.py</div><div id='n_file'> N File Name: src/data_loaders.py</div><div id='m_start'> M Start Line: 160</div><div id='m_end'> M End Line: 191</div><div id='n_start'> N Start Line: 154</div><div id='n_end'> N End Line: 182</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        )
        target_dict.update(identity_target)

        tokenised_text<a id="change"> = </a><a id="change">self.tokenizer(
            </a>text<a id="change">, return_tensors="pt", padding=True, truncation=True
        )</a>
        tokenised_text<a id="change"> = </a>tokenised_text.data
        meta["multi_target"] = torch.tensor(
            list(target_dict.values()), dtype=torch.int32
        )
        meta["text_id"] = text_id
        if self.train:
            meta["weights"] = self.weights[index]
        else:
            meta["weights"] = torch.tensor([1], dtype=torch.int32)

        <a id="change">meta["toxicity_ids"]</a> = torch.tensor(
            [True] * len(self.classes) + [False] * len(self.identity_classes)
        )
        <a id="change">return </a>tokenised_text<a id="change">, meta</a>

    def compute_weigths(self, train_df):
        Inspired from 2nd solution.
        Source: https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/100661</code></pre><h3>After Change</h3><pre><code class='java'>
        else:
            meta["weights"] = torch.tensor([1], dtype=torch.int32)

        <a id="change">meta["toxicity_ids"]</a> = torch.tensor(
            [True] * len(self.classes) + [False] * len(self.identity_classes)
        )
        <a id="change">return </a>text<a id="change">, meta</a>

    def compute_weigths(self, train_df):
        Inspired from 2nd solution.
        Source: https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/100661</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/unitaryai/detoxify/commit/78f55b5b0d152a1b464edd9b64e844f676ba80ba#diff-4f64d3cf185856bf97e6aafaf27a45ebbd069972dc408794aeecdde63faaf1fdL156' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 81574457</div><div id='project'> Project Name: unitaryai/detoxify</div><div id='commit'> Commit Name: 78f55b5b0d152a1b464edd9b64e844f676ba80ba</div><div id='time'> Time: 2020-10-02</div><div id='author'> Author: laura.hanu10@gmail.com</div><div id='file'> File Name: src/data_loaders.py</div><div id='m_class'> M Class Name: JigsawDataBiasBERT</div><div id='n_method'> N Class Name: JigsawDataBiasBERT</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: JigsawData</div><div id='n_parent_class'> N Parent Class: JigsawData</div><div id='m_file'> M File Name: src/data_loaders.py</div><div id='n_file'> N File Name: src/data_loaders.py</div><div id='m_start'> M Start Line: 160</div><div id='m_end'> M End Line: 191</div><div id='n_start'> N Start Line: 154</div><div id='n_end'> N End Line: 182</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        text = entry["comment_text"]
        target_dict = {label: 1 if entry[label] &gt;= 0.5 else 0 for label in self.classes}

        tokenised_text<a id="change"> = </a><a id="change">self.tokenizer(
            </a>text<a id="change">, return_tensors="pt", padding=True, truncation=True
        )</a>
        tokenised_text<a id="change"> = </a>tokenised_text.data
        meta["target"] = torch.tensor(list(target_dict.values()), dtype=torch.int32)
        <a id="change">meta["text_id"]</a> = text_id

        <a id="change">return </a>tokenised_text<a id="change">, meta</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
        target_dict = {label: 1 if entry[label] &gt;= 0.5 else 0 for label in self.classes}

        meta["target"] = torch.tensor(list(target_dict.values()), dtype=torch.int32)
        <a id="change">meta["text_id"]</a> = text_id

        <a id="change">return </a>text<a id="change">, meta</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/unitaryai/detoxify/commit/78f55b5b0d152a1b464edd9b64e844f676ba80ba#diff-4f64d3cf185856bf97e6aafaf27a45ebbd069972dc408794aeecdde63faaf1fdL234' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 81574452</div><div id='project'> Project Name: unitaryai/detoxify</div><div id='commit'> Commit Name: 78f55b5b0d152a1b464edd9b64e844f676ba80ba</div><div id='time'> Time: 2020-10-02</div><div id='author'> Author: laura.hanu10@gmail.com</div><div id='file'> File Name: src/data_loaders.py</div><div id='m_class'> M Class Name: JigsawDataMultilingualBERT</div><div id='n_method'> N Class Name: JigsawDataMultilingualBERT</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: JigsawData</div><div id='n_parent_class'> N Parent Class: JigsawData</div><div id='m_file'> M File Name: src/data_loaders.py</div><div id='n_file'> N File Name: src/data_loaders.py</div><div id='m_start'> M Start Line: 238</div><div id='m_end'> M End Line: 248</div><div id='n_start'> N Start Line: 228</div><div id='n_end'> N End Line: 234</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            label: value for label, value in entry.items() if label in self.classes
        }

        tokenised_text<a id="change"> = </a><a id="change">self.tokenizer(
            </a>text<a id="change">, return_tensors="pt", padding=True, truncation=True
        )</a>
        tokenised_text<a id="change"> = </a>tokenised_text.data
        meta["multi_target"] = torch.tensor(
            list(target_dict.values()), dtype=torch.int32
        )
        <a id="change">meta["text_id"]</a> = text_id

        <a id="change">return </a>tokenised_text<a id="change">, meta</a>


class JigsawDataBiasBERT(JigsawData):
    Dataloader for the Jigsaw Unintended Bias in Toxicity Classification.</code></pre><h3>After Change</h3><pre><code class='java'>
        meta["multi_target"] = torch.tensor(
            list(target_dict.values()), dtype=torch.int32
        )
        <a id="change">meta["text_id"]</a> = text_id

        <a id="change">return </a>text<a id="change">, meta</a>


class JigsawDataBiasBERT(JigsawData):
    Dataloader for the Jigsaw Unintended Bias in Toxicity Classification.</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/unitaryai/detoxify/commit/78f55b5b0d152a1b464edd9b64e844f676ba80ba#diff-4f64d3cf185856bf97e6aafaf27a45ebbd069972dc408794aeecdde63faaf1fdL83' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 81574448</div><div id='project'> Project Name: unitaryai/detoxify</div><div id='commit'> Commit Name: 78f55b5b0d152a1b464edd9b64e844f676ba80ba</div><div id='time'> Time: 2020-10-02</div><div id='author'> Author: laura.hanu10@gmail.com</div><div id='file'> File Name: src/data_loaders.py</div><div id='m_class'> M Class Name: JigsawDataBERT</div><div id='n_method'> N Class Name: JigsawDataBERT</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: JigsawData</div><div id='n_parent_class'> N Parent Class: JigsawData</div><div id='m_file'> M File Name: src/data_loaders.py</div><div id='n_file'> N File Name: src/data_loaders.py</div><div id='m_start'> M Start Line: 87</div><div id='m_end'> M End Line: 101</div><div id='n_start'> N Start Line: 86</div><div id='n_end'> N End Line: 96</div><BR>