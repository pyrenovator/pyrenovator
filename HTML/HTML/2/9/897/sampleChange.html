<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        mask = torch.gt((key_padding_mask + look_ahead_mask), 0)
        attn_weights = []
        attn_outputs = behavior_list_emb_drop
        <a id="change">for i</a> in <a id="change">range(</a>self.num_blocks<a id="change">):
            </a>attn_outputs<a id="change">, attn</a> = self.multi_head_attention(attn_outputs, attn_outputs, attn_outputs, mask)
            attn_weights.append(attn)
            attn_outputs = self.feedforward(attn_outputs)
        long_term_prefernce = self.gather_indexes(attn_outputs, interaction[self.ITEM_LIST_LEN] - 1)</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, interaction):
        item_list = interaction[self.ITEM_ID_LIST]
        position_ids = torch.arange(item_list.size(1), dtype=torch.long, device=item_list.device)
        position_ids = <a id="change">position_ids.unsqueeze(0).expand_as(</a>item_list<a id="change">)</a>
        position_embedding = self.position_embedding(position_ids)

        item_emb = self.item_embedding(item_list)
        input_emb = item_emb<a id="change"> + </a>position_embedding
        input_emb = self.LayerNorm(input_emb)
        input_emb = self.dropout(input_emb)

        extended_attention_mask = self.get_attention_mask(item_list)

        trm_output = self.trm_encoder(input_emb,
                                      extended_attention_mask,
                                      output_all_encoded_layers=True)
        output<a id="change"> = </a>trm_output[-1]
        output = self.gather_indexes(output, interaction[self.ITEM_LIST_LEN] - 1)
        return output &#47&#47 [B H]
</code></pre>