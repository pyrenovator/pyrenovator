<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                state[&quotstep&quot] += 1

                if group[&quotweight_decay&quot] != 0:
                    grad<a id="change"> = </a><a id="change">grad.add(</a>p<a id="change">, alpha=group[&quotweight_decay&quot])</a>

                &#47&#47 decay term
                p.mul_(1 - group[&quotlambd&quot] * state[&quoteta&quot])
</code></pre><h3>After Change</h3><pre><code class='java'>
            with torch.enable_grad():
                loss = closure()

        <a id="change">for </a>group in self.param_groups<a id="change">:
            </a>params_with_grad = []
            grads = []
            mus = []
            axs = []
            etas = []
            state_steps<a id="change"> = </a>[]

            for p in group[&quotparams&quot]:
                <a id="change">if </a>p.grad is not None:
                    <a id="change">params_with_grad.append(</a>p<a id="change">)</a>
                    if p.grad.is_sparse:
                        raise RuntimeError(&quotASGD does not support sparse gradients&quot)
                    grads.append(p.grad)

                    state<a id="change"> = </a>self.state[p]
                    &#47&#47 State initialization
                    if len(state) == 0:
                        state[&quotstep&quot] = 0
                        state[&quoteta&quot] = group[&quotlr&quot]
                        state[&quotmu&quot] = 1
                        state[&quotax&quot] = torch.zeros_like(p, memory_format=torch.preserve_format)

                    mus.append(state[&quotmu&quot])
                    axs.append(state[&quotax&quot])
                    etas.append(state[&quoteta&quot])

                    state[&quotstep&quot] += 1
                    state_steps.append(state[&quotstep&quot])

            F.asgd(params_with_grad,
                   grads,
                   axs,
                   mus,
                   etas,
                   weight_decay=group[&quotweight_decay&quot],
                   lambd=group[&quotlambd&quot])

            &#47&#47 update eta and mu
            <a id="change">for </a>p, mu, eta in zip(params_with_grad, mus, etas)<a id="change">:
                </a>state = self.state[p]
                state[&quoteta&quot] = (group[&quotlr&quot] /
                                math.pow((1 + group[&quotlambd&quot] * group[&quotlr&quot] * state[&quotstep&quot]), group[&quotalpha&quot]))
                state[&quotmu&quot] = 1 / max(1, state[&quotstep&quot] - group[&quott0&quot])</code></pre>