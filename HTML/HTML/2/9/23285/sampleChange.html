<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    for tuple in subject_relation_pairs:
        indices_duplicates = (subject_relation_pairs == tuple).all(axis=1).nonzero()
        objects = <a id="change">pos_triples[indices_duplicates, 2:3]</a>
        objects = np.unique(np.ndarray.flatten(objects))
        label_vec = np.in1d(entities, objects) * 1
        labels.append(label_vec)
</code></pre><h3>After Change</h3><pre><code class='java'>
    indices = np.arange(pos_triples.shape[0])
    np.random.shuffle(indices)
    pos_triples = pos_triples[indices]
    num_pos_triples<a id="change"> = </a>pos_triples.shape[0]

    &#47&#47 Create labels
    subject_relation_pairs = pos_triples[:, 0:2]
    entities = np.arange(kg_embedding_model.num_entities)
    labels = []

    for subj_rel in subject_relation_pairs:
        subj_rel_rep = np.repeat(subj_rel,axis=0)
        label = (pos_triples[:,0:2] == subj_rel).all(axis=1)
        &#47&#47 objects = pos_triples[mat, 2:3]
        &#47&#47 objects = np.unique(np.ndarray.flatten(objects))
        &#47&#47 label_vec = np.in1d(entities, objects) * 1
        &#47&#47 labels.append(label_vec)

    kg_embedding_model = kg_embedding_model.to(device)
    optimizer = optim.SGD(kg_embedding_model.parameters(), lr=learning_rate)
    total_loss = 0
    loss_per_epoch = []

    log.info(&quot****Run Model On %s****&quot % str(device).upper())
    &#47&#47 Train
    for epoch in range(num_epochs):
        np.random.seed(seed=seed)
        indices<a id="change"> = </a><a id="change">np.arange(</a>num_pos_triples<a id="change">)</a>
        <a id="change">np.random.shuffle(</a>indices<a id="change">)</a>
        pos_triples = pos_triples[indices]
        subject_relation_pairs = pos_triples[:, 0:2]
        start = timeit.default_timer()
        pos_batches = split_list_in_batches(input_list=subject_relation_pairs, batch_size=batch_size)</code></pre>