<html><h3>Pattern ID :17396
</h3><img src='57707809.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 load the audio from the path, clean it, process it into a spectrogram
        &#47&#47 return a pair of cleaned audio and spectrogram
        text = torch.LongTensor(self.feature_list[index][0]).to(self.device)
        text_len = <a id="change">torch.LongTensor([</a>self.feature_list[index][1]<a id="change"></a>]<a id="change">)</a>.to(self.device)
        speech = torch.transpose(torch.Tensor(self.feature_list[index][2]), 0, 1).to(self.device)
        speech_len = <a id="change">torch.LongTensor([</a>self.feature_list[index][3]<a id="change"></a>]<a id="change">)</a>.to(self.device)
        <a id="change">if </a>self.spemb:
            spemb = torch.Tensor(self.feature_list[index][4]).to(self.device)
            <a id="change">return </a>text<a id="change">, text_len, speech, speech_len, spemb</a>
        return text, text_len, speech, speech_len

    def __len__(self):
        return len(self.list_of_paths)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 load the audio from the path, clean it, quantize it, process it into a spectrogram
        &#47&#47 return a pair of cleaned audio and spectrogram
        file_path = self.list_of_paths[index]
        wave<a id="change">, sr</a> = sf.read(file_path)
        if self.ap is None:
            self.ap = AudioPreprocessor(input_sr=sr, output_sr=16000, melspec_buckets=80)
        normalized_wave = self.ap.audio_to_wave_tensor(wave, normalize=True, mulaw=False).to(self.device)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/b43437ffd52b1d82638a75e3648c752f2492652c#diff-6d37714a960ee957f0bd8c25ac6b1f0f61e2e6e8f14e269209172239a689a904L19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 57707809</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: b43437ffd52b1d82638a75e3648c752f2492652c</div><div id='time'> Time: 2021-02-19</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: MelGAN/MelGANDataset.py</div><div id='m_class'> M Class Name: MelGANDataset</div><div id='n_method'> N Class Name: MelGANDataset</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: MelGAN/MelGANDataset.py</div><div id='n_file'> N File Name: MelGAN/MelGANDataset.py</div><div id='m_start'> M Start Line: 19</div><div id='m_end'> M End Line: 26</div><div id='n_start'> N Start Line: 23</div><div id='n_end'> N End Line: 29</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 load the audio from the path, clean it, process it into a spectrogram
        &#47&#47 return a pair of cleaned audio and spectrogram
        text = torch.LongTensor(self.feature_list[index][0]).to(self.device)
        text_len = <a id="change">torch.LongTensor([</a>self.feature_list[index][1]<a id="change"></a>]<a id="change">)</a>.to(self.device)
        speech = torch.transpose(torch.Tensor(self.feature_list[index][2]), 0, 1).to(self.device)
        speech_len = <a id="change">torch.LongTensor([</a>self.feature_list[index][3]<a id="change"></a>]<a id="change">)</a>.to(self.device)
        <a id="change">if </a>self.spemb:
            spemb = torch.Tensor(self.feature_list[index][4]).to(self.device)
            <a id="change">return </a>text<a id="change">, text_len, speech, speech_len, spemb</a>
        return text, text_len, speech, speech_len

    def __len__(self):
        return len(self.list_of_paths)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 load the audio from the path, clean it, quantize it, process it into a spectrogram
        &#47&#47 return a pair of cleaned audio and spectrogram
        file_path = self.list_of_paths[index]
        wave<a id="change">, sr</a> = sf.read(file_path)
        if self.ap is None:
            self.ap = AudioPreprocessor(input_sr=sr, output_sr=16000, melspec_buckets=80)
        normalized_wave = self.ap.audio_to_wave_tensor(wave, normalize=True, mulaw=False).to(self.device)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/b43437ffd52b1d82638a75e3648c752f2492652c#diff-6d37714a960ee957f0bd8c25ac6b1f0f61e2e6e8f14e269209172239a689a904L16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 57707810</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: b43437ffd52b1d82638a75e3648c752f2492652c</div><div id='time'> Time: 2021-02-19</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: MelGAN/MelGANDataset.py</div><div id='m_class'> M Class Name: MelGANDataset</div><div id='n_method'> N Class Name: MelGANDataset</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: MelGAN/MelGANDataset.py</div><div id='n_file'> N File Name: MelGAN/MelGANDataset.py</div><div id='m_start'> M Start Line: 19</div><div id='m_end'> M End Line: 26</div><div id='n_start'> N Start Line: 23</div><div id='n_end'> N End Line: 29</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def __getitem__(self, index):
        &#47&#47 create tensors on correct device
        text = torch.LongTensor(self.feature_list[index][0]).to(self.device)
        text_len = <a id="change">torch.LongTensor([</a>self.feature_list[index][1]<a id="change"></a>]<a id="change">)</a>.to(self.device)
        speech = torch.transpose(torch.Tensor(self.feature_list[index][2]), 0, 1).to(self.device)
        speech_len = <a id="change">torch.LongTensor([</a>self.feature_list[index][3]<a id="change"></a>]<a id="change">)</a>.to(self.device)
        <a id="change">if </a>self.spemb:
            spemb = torch.Tensor(self.feature_list[index][4]).to(self.device)
            <a id="change">return </a>text<a id="change">, text_len, speech, speech_len, spemb</a>
        return text, text_len, speech, speech_len

    def __len__(self):
        return len(self.feature_list)</code></pre><h3>After Change</h3><pre><code class='java'>
    def __getitem__(self, index):
        transcript = self.path_to_transcript_dict[self.key_list[index]]
        path = self.key_list[index]
        wave<a id="change">, sr</a> = sf.read(os.path.join("Corpora/CSS10/", path))
        if self.ap is None:
            self.ap = AudioPreprocessor(input_sr=sr, output_sr=16000, melspec_buckets=80, hop_length=256, n_fft=1024)
        text = self.tf.string_to_tensor(transcript).long()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/1e192df888be8f1dc1c20971132b31fe73153b7d#diff-0965ad6e3a8f04afe3a358a7558e203eaa1f244ad6e8e6fbfe73f8a2052b8cb1L12' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 57707795</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 1e192df888be8f1dc1c20971132b31fe73153b7d</div><div id='time'> Time: 2021-02-22</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_class'> M Class Name: TransformerTTSDataset</div><div id='n_method'> N Class Name: TransformerTTSDataset</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='n_file'> N File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_start'> M Start Line: 14</div><div id='m_end'> M End Line: 21</div><div id='n_start'> N Start Line: 32</div><div id='n_end'> N End Line: 44</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if self.ap is None:
            self.ap = AudioPreprocessor(input_sr=sr, output_sr=16000, melspec_buckets=80, hop_length=256, n_fft=1024)
        text = self.tf.string_to_tensor(transcript).long()
        text_len = <a id="change">torch.LongTensor([</a>len(text)<a id="change"></a>]<a id="change">)</a>
        speech = self.ap.audio_to_mel_spec_tensor(wave).transpose(0, 1)
        speech_len = <a id="change">torch.LongTensor([</a>len(speech)<a id="change"></a>]<a id="change">)</a>
        <a id="change">if </a>self.spemb:
            print("not implemented yet")
            raise NotImplementedError
        <a id="change">return </a>text<a id="change">, text_len, speech, speech_len</a>

    def __len__(self):
        return len(self.key_list)
</code></pre><h3>After Change</h3><pre><code class='java'>
                raise NotImplementedError

    def __getitem__(self, index):
        return self.cached_text[index]<a id="change">, \
               self.cached_text_lens[index], \
               self.cached_speech[index], \
               self.cached_speech_lens[index]</a>

    def __len__(self):
        return len(self.cached_text_lens)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/51675d8bba9cee446d9fe520fde5253af397c61d#diff-0965ad6e3a8f04afe3a358a7558e203eaa1f244ad6e8e6fbfe73f8a2052b8cb1L31' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 57707811</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 51675d8bba9cee446d9fe520fde5253af397c61d</div><div id='time'> Time: 2021-02-23</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_class'> M Class Name: TransformerTTSDataset</div><div id='n_method'> N Class Name: TransformerTTSDataset</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='n_file'> N File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_start'> M Start Line: 32</div><div id='m_end'> M End Line: 44</div><div id='n_start'> N Start Line: 54</div><div id='n_end'> N End Line: 57</div><BR>