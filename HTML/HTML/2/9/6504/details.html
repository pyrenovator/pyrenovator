<html><h3>Pattern ID :6504
</h3><img src='22543046.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                        )
                    except RuntimeError as e:
                        self._free_graph_and_cache()
                        <a id="change">raise_if_not_cuda_oom(exception=e)</a>
                        if sub_batch_size == 1:
                            logger.info(
                                f"Even sub_batch_size={sub_batch_size} does not fit in memory with these parameters")
                            break</code></pre><h3>After Change</h3><pre><code class='java'>
            self._train(num_epochs=1, batch_size=batch_size, sub_batch_size=sub_batch_size, only_size_probing=True)
        except RuntimeError as runtime_error:
            self._free_graph_and_cache()
            <a id="change">if not</a><a id="change"> is_cudnn_error(runtime_error) and not is_cuda_oom_error(runtime_error)</a>:
                <a id="change">raise runtime_error</a>
            logger.debug(f&quotThe batch_size {batch_size} was too big, sub_batching is required.&quot)
            sub_batch_size //= 2
        else:
            finished_search = True</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pykeen/pykeen/commit/0558419743510ce805cc335b15dc46485f55996c#diff-470d2c155c3bc1a16a91aad8d76218a769016ccc6e7a26e9ea250c843c17c980L538' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 22543046</div><div id='project'> Project Name: pykeen/pykeen</div><div id='commit'> Commit Name: 0558419743510ce805cc335b15dc46485f55996c</div><div id='time'> Time: 2020-03-31</div><div id='author'> Author: 33023925+mali-git@users.noreply.github.com</div><div id='file'> File Name: src/pykeen/training/training_loop.py</div><div id='m_class'> M Class Name: TrainingLoop</div><div id='n_method'> N Class Name: TrainingLoop</div><div id='m_method'> M Method Name: _sub_batch_size_search(2)</div><div id='n_method'> N Method Name: _sub_batch_size_search(2)</div><div id='m_parent_class'> M Parent Class: ABC</div><div id='n_parent_class'> N Parent Class: ABC</div><div id='m_file'> M File Name: src/pykeen/training/training_loop.py</div><div id='n_file'> N File Name: src/pykeen/training/training_loop.py</div><div id='m_start'> M Start Line: 538</div><div id='m_end'> M End Line: 566</div><div id='n_start'> N Start Line: 539</div><div id='n_end'> N End Line: 570</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                        )
                    except RuntimeError as e:
                        self._free_graph_and_cache()
                        <a id="change">raise_if_not_cuda_oom(exception=e)</a>
                        if sub_batch_size == 1:
                            logger.info(
                                f"Even sub_batch_size={sub_batch_size} does not fit in memory with these parameters")
                            break</code></pre><h3>After Change</h3><pre><code class='java'>
            self._train(num_epochs=1, batch_size=batch_size, sub_batch_size=sub_batch_size, only_size_probing=True)
        except RuntimeError as runtime_error:
            self._free_graph_and_cache()
            <a id="change">if not</a><a id="change"> is_cudnn_error(runtime_error) and not is_cuda_oom_error(runtime_error)</a>:
                <a id="change">raise </a>runtime_error
            logger.debug(f&quotThe batch_size {batch_size} was too big, sub_batching is required.&quot)
            sub_batch_size //= 2
        else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pykeen/pykeen/commit/0558419743510ce805cc335b15dc46485f55996c#diff-470d2c155c3bc1a16a91aad8d76218a769016ccc6e7a26e9ea250c843c17c980L518' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 22543045</div><div id='project'> Project Name: pykeen/pykeen</div><div id='commit'> Commit Name: 0558419743510ce805cc335b15dc46485f55996c</div><div id='time'> Time: 2020-03-31</div><div id='author'> Author: 33023925+mali-git@users.noreply.github.com</div><div id='file'> File Name: src/pykeen/training/training_loop.py</div><div id='m_class'> M Class Name: TrainingLoop</div><div id='n_method'> N Class Name: TrainingLoop</div><div id='m_method'> M Method Name: _sub_batch_size_search(2)</div><div id='n_method'> N Method Name: _sub_batch_size_search(2)</div><div id='m_parent_class'> M Parent Class: ABC</div><div id='n_parent_class'> N Parent Class: ABC</div><div id='m_file'> M File Name: src/pykeen/training/training_loop.py</div><div id='n_file'> N File Name: src/pykeen/training/training_loop.py</div><div id='m_start'> M Start Line: 538</div><div id='m_end'> M End Line: 566</div><div id='n_start'> N Start Line: 539</div><div id='n_end'> N End Line: 570</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                self._train(num_epochs=1, batch_size=batch_size, sub_batch_size=None, only_size_probing=True)
            except RuntimeError as e:
                self._free_graph_and_cache()
                <a id="change">raise_if_not_cuda_oom(exception=e)</a>
                if batch_size == 1:
                    logger.debug(f"batch_size={batch_size} does not fit into your memory with these parameters.")
                    break
</code></pre><h3>After Change</h3><pre><code class='java'>
                self._train(num_epochs=1, batch_size=batch_size, sub_batch_size=None, only_size_probing=True)
            except RuntimeError as runtime_error:
                self._free_graph_and_cache()
                <a id="change">if not</a><a id="change"> is_cudnn_error(runtime_error) and not is_cuda_oom_error(runtime_error)</a>:
                    <a id="change">raise </a>runtime_error
                if batch_size == 1:
                    logger.debug(f"batch_size={batch_size} does not fit into your memory with these parameters.")
                    break</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pykeen/pykeen/commit/0558419743510ce805cc335b15dc46485f55996c#diff-470d2c155c3bc1a16a91aad8d76218a769016ccc6e7a26e9ea250c843c17c980L419' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 22543044</div><div id='project'> Project Name: pykeen/pykeen</div><div id='commit'> Commit Name: 0558419743510ce805cc335b15dc46485f55996c</div><div id='time'> Time: 2020-03-31</div><div id='author'> Author: 33023925+mali-git@users.noreply.github.com</div><div id='file'> File Name: src/pykeen/training/training_loop.py</div><div id='m_class'> M Class Name: TrainingLoop</div><div id='n_method'> N Class Name: TrainingLoop</div><div id='m_method'> M Method Name: batch_size_search(2)</div><div id='n_method'> N Method Name: batch_size_search(2)</div><div id='m_parent_class'> M Parent Class: ABC</div><div id='n_parent_class'> N Parent Class: ABC</div><div id='m_file'> M File Name: src/pykeen/training/training_loop.py</div><div id='n_file'> N File Name: src/pykeen/training/training_loop.py</div><div id='m_start'> M Start Line: 452</div><div id='m_end'> M End Line: 452</div><div id='n_start'> N Start Line: 452</div><div id='n_end'> N End Line: 454</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            except RuntimeError as e:
                &#47&#47 The cache of the previous run has to be freed to allow accurate memory availability estimates
                torch.cuda.empty_cache()
                <a id="change">raise_if_not_cuda_oom(exception=e)</a>
                if values_dict[key] == 1:
                    logger.debug(
                        f"Even {key} {values_dict[key]} does not fit into your memory with these parameters."
                    )</code></pre><h3>After Change</h3><pre><code class='java'>
            except RuntimeError as runtime_error:
                &#47&#47 The cache of the previous run has to be freed to allow accurate memory availability estimates
                torch.cuda.empty_cache()
                <a id="change">if not</a><a id="change"> is_cudnn_error(runtime_error) and not is_cuda_oom_error(runtime_error)</a>:
                    <a id="change">raise </a>runtime_error
                if values_dict[key] == 1:
                    logger.debug(
                        f"Even {key} {values_dict[key]} does not fit into your memory with these parameters."</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pykeen/pykeen/commit/0558419743510ce805cc335b15dc46485f55996c#diff-1c713ef73beb3ae34d3b24fea3ec3a94e932cadf9a1ba946808517317cc2c515L212' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 22543040</div><div id='project'> Project Name: pykeen/pykeen</div><div id='commit'> Commit Name: 0558419743510ce805cc335b15dc46485f55996c</div><div id='time'> Time: 2020-03-31</div><div id='author'> Author: 33023925+mali-git@users.noreply.github.com</div><div id='file'> File Name: src/pykeen/evaluation/evaluator.py</div><div id='m_class'> M Class Name: Evaluator</div><div id='n_method'> N Class Name: Evaluator</div><div id='m_method'> M Method Name: _param_size_search(7)</div><div id='n_method'> N Method Name: _param_size_search(7)</div><div id='m_parent_class'> M Parent Class: ABC</div><div id='n_parent_class'> N Parent Class: ABC</div><div id='m_file'> M File Name: src/pykeen/evaluation/evaluator.py</div><div id='n_file'> N File Name: src/pykeen/evaluation/evaluator.py</div><div id='m_start'> M Start Line: 255</div><div id='m_end'> M End Line: 255</div><div id='n_start'> N Start Line: 255</div><div id='n_end'> N End Line: 257</div><BR>