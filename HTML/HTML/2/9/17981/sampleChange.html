<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Run a forward chain to collect intermediate inputs
        &#47&#47 Note that we do not forward for the last module since we do not need its output
        inter_inputs = [inputs]
        <a id="change">for </a>backend in requested_backends[:-1]<a id="change">:
            </a><a id="change">assert </a>inputs.ndim == 3, f"inputs to {type(backend)} must be a single 3d tensor of hidden states"
            inputs = <a id="change">await </a><a id="change">backend.forward_pool.submit_task(</a>inputs<a id="change">)</a>
            <a id="change">assert </a>isinstance(inputs, (list, tuple)) and len(inputs) == 1
            inputs<a id="change"> = </a>inputs[0]
            inter_inputs.append(inputs)

        &#47&#47 Run a chain of requested backends</code></pre><h3>After Change</h3><pre><code class='java'>
        requested_uids = self._check_uids(request.uid)
        requested_backends = tuple(self.module_backends[uid] for uid in requested_uids)

        grads = <a id="change">await </a>_rpc_backward(*flat_tensors, requested_backends=requested_backends)

        &#47&#47 Modify grad_inputs_schema to support grad_prompts
        assert len(requested_backends[0].args_schema) == 1 and len(grads) in (1, 2)  &#47&#47 TODO generalize

        grad_inputs_schema_with_prompts = (
            requested_backends[0].args_schema * len(grads)<a id="change">,
            requested_backends[0].kwargs_schema</a>,
        )  &#47&#47 TODO generalize

        &#47&#47 Serialize the overall grad_input and respond</code></pre>