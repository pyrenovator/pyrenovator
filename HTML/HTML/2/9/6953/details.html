<html><h3>Pattern ID :6953
</h3><img src='23288522.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    model.train()
    Dtr, Dte = nn_seq_wind(model.name, args.B)
    model.len = len(Dtr)
    <a id="change">if args.weight_decay != 0</a>:
        lr<a id="change"> = </a>args.lr<a id="change"> * pow(</a>args.weight_decay, global_round<a id="change">)</a>
    else:
        lr = args.lr
    if args.optimizer == &quotadam&quot:
        optimizer = torch.optim.Adam(model.parameters(), lr=lr,</code></pre><h3>After Change</h3><pre><code class='java'>
    else:
        optimizer = torch.optim.SGD(model.parameters(), lr=lr,
                                    momentum=0.9, weight_decay=args.weight_decay)
    lr_step<a id="change"> = </a><a id="change">StepLR(</a>optimizer<a id="change">, step_size=args.step_size, gamma=args.gamma)</a>
    print(&quottraining...&quot)
    loss_function = nn.MSELoss().to(args.device)
    loss = 0
    for epoch in range(args.E):
        for (seq, label) in Dtr:
            seq = seq.to(args.device)
            label = label.to(args.device)
            y_pred = model(seq)
            loss = loss_function(y_pred, label)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        <a id="change">lr_step.step()</a>

        print(&quotepoch&quot, epoch, &quot:&quot, loss.item())

    return model</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ki-ljl/fedper/commit/e96cb6510fd22103ac919dd289bd370c8404ae1c#diff-1ebfaf6cb3592166b73835fa82333cb7109e7c624865c0039a7b22ff34aa27faL18' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23288522</div><div id='project'> Project Name: ki-ljl/fedper</div><div id='commit'> Commit Name: e96cb6510fd22103ac919dd289bd370c8404ae1c</div><div id='time'> Time: 2022-05-12</div><div id='author'> Author: lijunliang.ki@gmail.com</div><div id='file'> File Name: client.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(2)</div><div id='n_method'> N Method Name: train(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: client.py</div><div id='n_file'> N File Name: client.py</div><div id='m_start'> M Start Line: 18</div><div id='m_end'> M End Line: 26</div><div id='n_start'> N Start Line: 23</div><div id='n_end'> N End Line: 43</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    Dtr, Dte = nn_seq_wind(model.name, args.B)
    model.len = len(Dtr)
    global_model = copy.deepcopy(server)
    <a id="change">if args.weight_decay != 0</a>:
        lr<a id="change"> = </a>args.lr<a id="change"> * pow(</a>args.weight_decay, global_round<a id="change">)</a>
    else:
        lr = args.lr
    if args.optimizer == &quotadam&quot:
        optimizer = torch.optim.Adam(model.parameters(), lr=lr,</code></pre><h3>After Change</h3><pre><code class='java'>
    else:
        optimizer = torch.optim.SGD(model.parameters(), lr=lr,
                                    momentum=0.9, weight_decay=args.weight_decay)
    stepLR<a id="change"> = </a><a id="change">StepLR(</a>optimizer<a id="change">, step_size=args.step_size, gamma=args.gamma)</a>
    print(&quottraining...&quot)
    loss_function = nn.MSELoss().to(args.device)
    loss = 0
    for epoch in range(args.E):
        for (seq, label) in Dtr:
            seq = seq.to(args.device)
            label = label.to(args.device)
            y_pred = model(seq)
            optimizer.zero_grad()
            &#47&#47 compute proximal_term
            proximal_term = 0.0
            for w, w_t in zip(model.parameters(), global_model.parameters()):
                proximal_term += (w - w_t).norm(2)

            loss = loss_function(y_pred, label) + (args.mu / 2) * proximal_term
            loss.backward()
            optimizer.step()
        <a id="change">stepLR.step()</a>

        print(&quotepoch&quot, epoch, &quot:&quot, loss.item())

    return model</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ki-ljl/fedprox-pytorch/commit/bc52dcfcf0f3d4231b58be9b3523877036eb7387#diff-1ebfaf6cb3592166b73835fa82333cb7109e7c624865c0039a7b22ff34aa27faL18' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23288521</div><div id='project'> Project Name: ki-ljl/fedprox-pytorch</div><div id='commit'> Commit Name: bc52dcfcf0f3d4231b58be9b3523877036eb7387</div><div id='time'> Time: 2022-05-12</div><div id='author'> Author: lijunliang.ki@gmail.com</div><div id='file'> File Name: client.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(3)</div><div id='n_method'> N Method Name: train(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: client.py</div><div id='n_file'> N File Name: client.py</div><div id='m_start'> M Start Line: 18</div><div id='m_end'> M End Line: 27</div><div id='n_start'> N Start Line: 24</div><div id='n_end'> N End Line: 49</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    device = args.device
    loss_function = nn.MSELoss().to(device)
    loss = 0
    <a id="change">if args.weight_decay != 0</a>:
        lr<a id="change"> = </a>args.lr<a id="change"> * pow(</a>args.weight_decay, global_round<a id="change">)</a>
    else:
        lr = args.lr
    if args.optimizer == &quotadam&quot:
        optimizer = torch.optim.Adam(model.parameters(), lr=lr,</code></pre><h3>After Change</h3><pre><code class='java'>
    else:
        optimizer = torch.optim.SGD(model.parameters(), lr=lr,
                                    momentum=0.9, weight_decay=args.weight_decay)
    lr_step<a id="change"> = </a><a id="change">StepLR(</a>optimizer<a id="change">, step_size=args.step_size, gamma=args.gamma)</a>
    for epoch in range(args.E):
        cnt = 0
        for (seq, label) in Dtr:
            cnt += 1
            seq = seq.to(device)
            label = label.to(device)
            y_pred = model(seq)
            loss = loss_function(y_pred, label)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            <a id="change">lr_step.step()</a>

        print(&quotepoch&quot, epoch, &quot:&quot, loss.item())

    return model</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ki-ljl/fedavg-numpy-pytorch-tff/commit/1ddda69027810715b3d2e12438dd42d952decb69#diff-23d4bb2ba01aa66e0632d18429d5174281f1c47f275b761bd140e5325ef34213L135' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23288520</div><div id='project'> Project Name: ki-ljl/fedavg-numpy-pytorch-tff</div><div id='commit'> Commit Name: 1ddda69027810715b3d2e12438dd42d952decb69</div><div id='time'> Time: 2022-05-12</div><div id='author'> Author: lijunliang.ki@gmail.com</div><div id='file'> File Name: algorithms/fedavg-pytorch.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(2)</div><div id='n_method'> N Method Name: train(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: algorithms/fedavg-pytorch.py</div><div id='n_file'> N File Name: algorithms/fedavg-pytorch.py</div><div id='m_start'> M Start Line: 135</div><div id='m_end'> M End Line: 146</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 162</div><BR>