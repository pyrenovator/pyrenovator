<html><h3>Pattern ID :11829
</h3><img src='39793759.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        mask = (mask &gt; 0) * 1
        image = torch.from_numpy(image).unsqueeze(0).to(device)
        mask = <a id="change">torch.from_numpy(mask).unsqueeze(0</a><a id="change">)</a>.to(device)

        inpainted_image = self.model(image, mask)

        cur_res = inpainted_image[0].permute(1, 2, 0).detach().cpu().numpy()
        cur_res<a id="change"> = </a>cur_res[0:origin_height, 0:origin_width, :]
        cur_res<a id="change"> = </a>np.clip(cur_res * 255, 0, 255).astype("uint8")
        cur_res = cv2.cvtColor(cur_res, cv2.COLOR_BGR2RGB)
        return cur_res
</code></pre><h3>After Change</h3><pre><code class='java'>
        return: BGR IMAGE
        
        area = image.shape[1] * image.shape[2]
        <a id="change">if area &lt; self.crop_trigger_size[0] * self.crop_trigger_size[1]</a>:
            return self._run(image, mask)

        print("Trigger crop image")
        boxes = boxes_from_mask(mask)
        crop_result = []
        for box in boxes:
            crop_image<a id="change">, crop_box = </a>self._run_box(image, mask, box)
            crop_result.append((crop_image, crop_box))

        image = (image.transpose(1, 2, 0) * 255).astype(np.uint8)[:, :, ::-1]
        for crop_image, crop_box in crop_result:
            x1<a id="change">, y1, x2, y2 = </a>crop_box
            image[y1:y2, x1:x2, :] = crop_image
        return image
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/sanster/lama-cleaner/commit/43c9c22c7312dd39feac4e3783e9ec080fd64243#diff-c64397576661152777123ab1a485c53dbfa8de21c16999da23c3b18cb8993606L40' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39793759</div><div id='project'> Project Name: sanster/lama-cleaner</div><div id='commit'> Commit Name: 43c9c22c7312dd39feac4e3783e9ec080fd64243</div><div id='time'> Time: 2022-03-22</div><div id='author'> Author: cwq1913@gmail.com</div><div id='file'> File Name: lama_cleaner/lama/__init__.py</div><div id='m_class'> M Class Name: LaMa</div><div id='n_method'> N Class Name: LaMa</div><div id='m_method'> M Method Name: __call__(3)</div><div id='n_method'> N Method Name: __call__(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: lama_cleaner/lama/__init__.py</div><div id='n_file'> N File Name: lama_cleaner/lama/__init__.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 55</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 65</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            else:
            	audio = audio_path
            feats = self.proc.process_audio(audio).T
            feats = <a id="change">torch.from_numpy(</a>feats<a id="change">)</a>
            feats<a id="change"> = feats.unsqueeze(0</a><a id="change">)</a>
            preds<a id="change"> = </a>self.model(feats)[0]  &#47&#47 extracting the activations by passing the feature through the NN
            preds = self.model.final_pred(preds)
            preds = preds.detach().numpy()
            preds = np.transpose(preds[:2, :])</code></pre><h3>After Change</h3><pre><code class='java'>


    def process(self, audio_path, inference_model, plot = False):
        <a id="change">if inference_model == "PF"</a>:                 &#47&#47 instantiating a Particle Filter decoder - Is Chosen for online inference
            self.estimator<a id="change"> = </a>particle_filter_cascade(beats_per_bar=[], fps=50, plot=plot)
        elif inference_model == "DBN":                &#47&#47 instantiating an HMM decoder - Is chosen for offline inference
            self.estimator<a id="change"> = </a>DBNDownBeatTrackingProcessor(beats_per_bar=[2, 3, 4], fps=50)
        else:
            raise RuntimeError(&quotinference_model can be either "PF" or "DBN"&quot)
        preds = self.activation_extractor(audio_path)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mjhydri/beatnet/commit/0fb33177b8fcafe2daff996b597bcb04eeb71a15#diff-592f3b4d9c6eeded7fac4dbc1ac54ce2d8b7012a1045e4bc17945a64e9ce0a32L47' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39793715</div><div id='project'> Project Name: mjhydri/beatnet</div><div id='commit'> Commit Name: 0fb33177b8fcafe2daff996b597bcb04eeb71a15</div><div id='time'> Time: 2021-10-29</div><div id='author'> Author: mj.hydri@gmail.com</div><div id='file'> File Name: src/BeatNet/BeatNet.py</div><div id='m_class'> M Class Name: BeatNet</div><div id='n_method'> N Class Name: BeatNet</div><div id='m_method'> M Method Name: process(4)</div><div id='n_method'> N Method Name: process(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/BeatNet/BeatNet.py</div><div id='n_file'> N File Name: src/BeatNet/BeatNet.py</div><div id='m_start'> M Start Line: 47</div><div id='m_end'> M End Line: 71</div><div id='n_start'> N Start Line: 39</div><div id='n_end'> N End Line: 51</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    for i in range(x.size(0)):
        mask = Masks.get_ff_mask(height, width)
        mask_all.append(mask)
    mask<a id="change"> = torch.from_numpy(np.asarray(mask_all)).unsqueeze(1</a><a id="change">)</a>.float()
    ones = torch.ones(x.size(0), 1, x.size(2), x.size(3))
    mask<a id="change"> = </a>ones * mask
    if x.is_cuda:
        mask = mask.cuda()
    result = x * (1. - mask)</code></pre><h3>After Change</h3><pre><code class='java'>
    if x.is_cuda:
        mask = mask.cuda()

    <a id="change">if config[&quotmask_type&quot] == &quothole&quot</a>:
        result = x * (1. - mask)
    elif config[&quotmask_type&quot] == &quotmosaic&quot:
        &#47&#47 TODO: Matching the mosaic patch size and the mask size
        mosaic_unit_size<a id="change"> = </a>config[&quotmosaic_unit_size&quot]
        downsampled_image = F.interpolate(x, scale_factor=1. / mosaic_unit_size, mode=&quotnearest&quot)
        upsampled_image = F.interpolate(downsampled_image, size=(height, width), mode=&quotnearest&quot)
        result<a id="change"> = </a>upsampled_image * mask + x * (1. - mask)
    else:
        raise NotImplementedError(&quotNot implemented mask type.&quot)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sayednadim/global-and-local-attention-based-free-form-image-inpainting/commit/aaa17ed332dc95db0f5900a43be179e26569b50c#diff-4a9d05cc3eadd7aa0b347854fe63c55a626198aae56f6d3482457196186e5d60L38' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 39793745</div><div id='project'> Project Name: sayednadim/global-and-local-attention-based-free-form-image-inpainting</div><div id='commit'> Commit Name: aaa17ed332dc95db0f5900a43be179e26569b50c</div><div id='time'> Time: 2020-08-16</div><div id='author'> Author: smnadimuddin@gmail.com</div><div id='file'> File Name: model/mask.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mask_image(2)</div><div id='n_method'> N Method Name: mask_image(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model/mask.py</div><div id='n_file'> N File Name: model/mask.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 49</div><div id='n_start'> N Start Line: 56</div><div id='n_end'> N End Line: 72</div><BR>