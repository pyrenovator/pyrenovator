<html><h3>Pattern ID :5072
</h3><img src='17852945.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def forward(self, x):
        q, k, v = (self.to_q(x), self.to_k(x), self.to_v(x))

        b<a id="change">, _, h, w</a> = q.shape

        q = q.reshape(b, self.heads, -1, h * w)
        k = k.reshape(b, -1, h * w)</code></pre><h3>After Change</h3><pre><code class='java'>
        k = k.reshape(b, -1, h * w)
        v = v.reshape(b, -1, h * w)

        <a id="change">if context is not None</a>:
            context = context.reshape(b, c, 1, -1)
            ck = <a id="change">self.to_k(context).reshape(</a>b, k_dim, <a id="change">-1</a><a id="change">)</a>
            cv<a id="change"> = </a><a id="change">self.to_v(context).reshape(</a>b, k_dim, <a id="change">-1</a><a id="change">)</a>
            k<a id="change"> = </a>torch.cat((k, ck), dim=2)
            v = torch.cat((v, cv), dim=2)

        k = k.softmax(dim=2)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/linear-attention-transformer/commit/f04e0077c5dae59973f4ab232fbaa0b32b37a80e#diff-b2dc3615c724782fa0acd9e683646fb66d6bef0f700e8dbf6bfc378c36b0ad35L23' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17852945</div><div id='project'> Project Name: lucidrains/linear-attention-transformer</div><div id='commit'> Commit Name: f04e0077c5dae59973f4ab232fbaa0b32b37a80e</div><div id='time'> Time: 2020-06-12</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: linear_attention_transformer/images.py</div><div id='m_class'> M Class Name: ImageLinearAttention</div><div id='n_method'> N Class Name: ImageLinearAttention</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: linear_attention_transformer/images.py</div><div id='n_file'> N File Name: linear_attention_transformer/images.py</div><div id='m_start'> M Start Line: 24</div><div id='m_end'> M End Line: 24</div><div id='n_start'> N Start Line: 23</div><div id='n_end'> N End Line: 39</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                                         channel=shape[0],
                                         delay=&quotdelay&quot in layer_config.keys())

        return Dense(**params)<a id="change">, table_entry</a>

    @staticmethod
    def create_conv(layer_config: h5py.Group,
                    input_shape: Tuple[int, int, int],</code></pre><h3>After Change</h3><pre><code class='java'>
        if isinstance(layer_config["weight"], NetDict):
            weight_real = layer_config[&quotweight/real&quot]
            weight_imag = layer_config[&quotweight/imag&quot]
            <a id="change">if weight_real.ndim == 1</a>:
                weight_real<a id="change"> = weight_real.reshape(</a>shape[0], <a id="change">-1</a><a id="change">)</a>
                weight_imag<a id="change"> = </a><a id="change">weight_imag.reshape(</a>shape[0], <a id="change">-1</a><a id="change">)</a>

            opt_weights_real = optimize_weight_bits(weight_real)
            opt_weights_imag = optimize_weight_bits(weight_imag)
            weight_real, num_weight_bits_real, weight_exponent_real,\</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lava-nc/lava-dl/commit/550de8e558f25813ca8c27b04458ed7076627d52#diff-dbb4d73711a9e810c90aadc474172963fe55093cd2d48584023bb34557c4a365L269' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17852953</div><div id='project'> Project Name: lava-nc/lava-dl</div><div id='commit'> Commit Name: 550de8e558f25813ca8c27b04458ed7076627d52</div><div id='time'> Time: 2022-11-17</div><div id='author'> Author: michaeljurado42@gmail.com</div><div id='file'> File Name: src/lava/lib/dl/netx/hdf5.py</div><div id='m_class'> M Class Name: Network</div><div id='n_method'> N Class Name: Network</div><div id='m_method'> M Method Name: create_dense(4)</div><div id='n_method'> N Method Name: create_dense(4)</div><div id='m_parent_class'> M Parent Class: AbstractProcess</div><div id='n_parent_class'> N Parent Class: AbstractProcess</div><div id='m_file'> M File Name: src/lava/lib/dl/netx/hdf5.py</div><div id='n_file'> N File Name: src/lava/lib/dl/netx/hdf5.py</div><div id='m_start'> M Start Line: 299</div><div id='m_end'> M End Line: 323</div><div id='n_start'> N Start Line: 312</div><div id='n_end'> N End Line: 372</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
	)
	network = preds_targets_spikes_chunks["network"]
	n_encoder_steps, n_time_steps, n_units = spikes.shape[1], targets.shape[1], targets.shape[-1]
	preds, targets = preds.reshape(-1, n_units)<a id="change">, targets.reshape(-1, n_units)</a>
	
	viz = VisualiseKMeans(
		nt.to_numpy(preds),
		shape=nt.Size(</code></pre><h3>After Change</h3><pre><code class='java'>
	)
	network = preds_targets_spikes_chunks["network"]
	n_encoder_steps, n_time_steps, n_units = spikes.shape[-2], targets.shape[-2], targets.shape[-1]
	<a id="change">if preds.ndim &gt; 3</a>:
		preds<a id="change"> = </a><a id="change">preds.reshape(</a>preds.shape[0], <a id="change">-1</a>, n_units<a id="change">)</a>
		targets<a id="change"> = np.mean(targets, axis=0).reshape(-1</a>, n_units<a id="change">)</a>
	else:
		preds = preds.reshape(-1, n_units)
		targets = targets.reshape(-1, n_units)
	</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neurotorch/neurotorch/commit/79078f1e2932a5947913fd8bb1978bbebbb02a45#diff-aff5f78b9555bd5040a4af58cb039071f72e13288ee8f728cdf4de462c192c8eL665' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17852955</div><div id='project'> Project Name: neurotorch/neurotorch</div><div id='commit'> Commit Name: 79078f1e2932a5947913fd8bb1978bbebbb02a45</div><div id='time'> Time: 2022-09-14</div><div id='author'> Author: 50332514+JeremieGince@users.noreply.github.com</div><div id='file'> File Name: applications/time_series_forecasting_spiking/results_generation.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: viz_all_chunks_predictions(1)</div><div id='n_method'> N Method Name: viz_all_chunks_predictions(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: applications/time_series_forecasting_spiking/results_generation.py</div><div id='n_file'> N File Name: applications/time_series_forecasting_spiking/results_generation.py</div><div id='m_start'> M Start Line: 669</div><div id='m_end'> M End Line: 696</div><div id='n_start'> N Start Line: 738</div><div id='n_end'> N End Line: 790</div><BR>