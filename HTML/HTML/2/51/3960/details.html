<html><h3>Pattern ID :3960
</h3><img src='14895575.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Contatenate [ Y_t, | X_{t-L},..., X_{t} | F_{t-L},..., F_{t+H} | S ]
        batch_size, windows_size = insample_y.shape[:2]
        if self.hist_exog_size &gt; 0:
            hist_exog = <a id="change">hist_exog.permute(0</a>,<a id="change">2</a>,<a id="change">1</a>,<a id="change">3</a><a id="change">)</a> &#47&#47 [B, C, W, L] -&gt; [B, W, C, L]
            insample_y = torch.cat(( insample_y, <a id="change">hist_exog.reshape(</a>batch_size, windows_size, <a id="change">-1</a><a id="change">)</a> ), dim=2)

        if self.futr_exog_size &gt; 0:
            futr_exog = <a id="change">futr_exog.permute(0</a>,<a id="change">2</a>,<a id="change">1</a>,<a id="change">3</a><a id="change">)</a> &#47&#47 [B, C, W, L] -&gt; [B, W, C, L]
            insample_y = torch.cat(( insample_y, futr_exog.reshape(batch_size, windows_size, -1) ), dim=2)

        <a id="change">if </a>self.stat_exog_size &gt; 0:
            stat_exog = stat_exog.unsqueeze(1).repeat(1, windows_size, 1) &#47&#47 [B, C] -&gt; [B, W, C]
            insample_y<a id="change"> = </a>torch.cat(( insample_y, stat_exog ), dim=2)

        &#47&#47 RNN forward
        insample_y<a id="change">, _ = </a>self.rnn(insample_y)
        insample_y = self.adapterW(insample_y)
        
        <a id="change">return </a>insample_y
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Contatenate [ Y_t, | X_{t-L},..., X_{t} | S ]
        batch_size, seq_len = encoder_input.shape[:2]
        if self.hist_exog_size &gt; 0:
            hist_exog = <a id="change">hist_exog.permute(0,2,1,3).squeeze(-1</a><a id="change">)</a> &#47&#47 [B, X, seq_len, 1] -&gt; [B, seq_len, X]
            <a id="change">encoder_input</a> = torch.cat((encoder_input, hist_exog), dim=2)

        <a id="change">if </a>self.stat_exog_size &gt; 0:
            stat_exog = stat_exog.unsqueeze(1).repeat(1, seq_len, 1) &#47&#47 [B, S] -&gt; [B, seq_len, S]
            encoder_input<a id="change"> = </a><a id="change">torch.cat(</a>(<a id="change">encoder_input</a><a id="change">, stat_exog</a>)<a id="change">, dim=2)</a>

        &#47&#47 RNN forward
        hidden_state<a id="change">, _ = self.hist_encoder(encoder_input</a><a id="change">)</a> &#47&#47 [B, seq_len, rnn_hidden_state]

        if self.futr_exog_size &gt; 0:
            futr_exog = <a id="change">futr_exog.permute(0,2,3,1)[:,:,1:,:]</a>  &#47&#47 [B, F, seq_len, 1+H] -&gt; [B, seq_len, H, F]
            hidden_state = torch.cat(( hidden_state, futr_exog.reshape(batch_size, seq_len, -1)), dim=2)

        &#47&#47 Context adapter
        context = self.context_adapter(hidden_state)
        context<a id="change"> = </a><a id="change">context.reshape(</a>batch_size, seq_len, self.h, self.context_size<a id="change">)</a>

        &#47&#47 Residual connection with futr_exog
        <a id="change">if self.futr_exog_size &gt; 0</a>:
            context<a id="change"> = </a>torch.cat((context, futr_exog), dim=-1)

        &#47&#47 Final forecast
        y_hat<a id="change"> = self</a><a id="change">.mlp_decoder(</a>context<a id="change">)</a>
        
        <a id="change">return </a>y_hat
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 28</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/nixtla/neuralforecast/commit/9cdb8c8ddd592a3acd47aa982f42bf995092e049#diff-740ef2665dc25c93d5965786c1c9ee5ea107d9cdafa2d9adb5073db0b3677541L107' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14895575</div><div id='project'> Project Name: nixtla/neuralforecast</div><div id='commit'> Commit Name: 9cdb8c8ddd592a3acd47aa982f42bf995092e049</div><div id='time'> Time: 2022-11-04</div><div id='author'> Author: mergenthaler.m@gmail.com</div><div id='file'> File Name: neuralforecast/models/rnn.py</div><div id='m_class'> M Class Name: RNN</div><div id='n_method'> N Class Name: RNN</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: BaseRecurrent</div><div id='n_parent_class'> N Parent Class: BaseRecurrent</div><div id='m_file'> M File Name: neuralforecast/models/rnn.py</div><div id='n_file'> N File Name: neuralforecast/models/rnn.py</div><div id='m_start'> M Start Line: 107</div><div id='m_end'> M End Line: 131</div><div id='n_start'> N Start Line: 129</div><div id='n_end'> N End Line: 164</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Contatenate [ Y_t, | X_{t-L},..., X_{t} | F_{t-L},..., F_{t+H} | S ]
        batch_size, windows_size = insample_y.shape[:2]
        if self.hist_exog_size &gt; 0:
            hist_exog = <a id="change">hist_exog.permute(0</a>,<a id="change">2</a>,<a id="change">1</a>,<a id="change">3</a><a id="change">)</a> &#47&#47 [B, C, W, L] -&gt; [B, W, C, L]
            insample_y = torch.cat(( insample_y, <a id="change">hist_exog.reshape(</a>batch_size, windows_size, <a id="change">-1</a><a id="change">)</a> ), dim=2)

        if self.futr_exog_size &gt; 0:
            futr_exog = <a id="change">futr_exog.permute(0</a>,<a id="change">2</a>,<a id="change">1</a>,<a id="change">3</a><a id="change">)</a> &#47&#47 [B, C, W, L] -&gt; [B, W, C, L]
            insample_y = torch.cat(( insample_y, futr_exog.reshape(batch_size, windows_size, -1) ), dim=2)

        <a id="change">if </a>self.stat_exog_size &gt; 0:
            stat_exog = stat_exog.unsqueeze(1).repeat(1, windows_size, 1) &#47&#47 [B, C] -&gt; [B, W, C]
            insample_y<a id="change"> = </a>torch.cat(( insample_y, stat_exog ), dim=2)

        &#47&#47 LSTM forward
        insample_y<a id="change">, _ = </a>self.lstm(insample_y)
        insample_y = self.adapterW(insample_y)
        
        <a id="change">return </a>insample_y
</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, windows_batch):
        
        &#47&#47 Parse windows_batch
        <a id="change">encoder_input</a> = windows_batch[&quotinsample_y&quot] &#47&#47 [B, seq_len, 1]
        futr_exog     = windows_batch[&quotfutr_exog&quot]
        hist_exog     = windows_batch[&quothist_exog&quot]
        stat_exog     = windows_batch[&quotstat_exog&quot]

        &#47&#47 Concatenate y, historic and static inputs
        &#47&#47 [B, C, seq_len, 1] -&gt; [B, seq_len, C]
        &#47&#47 Contatenate [ Y_t, | X_{t-L},..., X_{t} | S ]
        batch_size, seq_len = encoder_input.shape[:2]
        if self.hist_exog_size &gt; 0:
            hist_exog = <a id="change">hist_exog.permute(0,2,1,3).squeeze(-1</a><a id="change">)</a> &#47&#47 [B, X, seq_len, 1] -&gt; [B, seq_len, X]
            <a id="change">encoder_input</a> = torch.cat((encoder_input, hist_exog), dim=2)

        <a id="change">if </a>self.stat_exog_size &gt; 0:
            stat_exog = stat_exog.unsqueeze(1).repeat(1, seq_len, 1) &#47&#47 [B, S] -&gt; [B, seq_len, S]
            encoder_input<a id="change"> = </a><a id="change">torch.cat(</a>(encoder_input<a id="change">, stat_exog</a>)<a id="change">, dim=2)</a>

        &#47&#47 RNN forward
        hidden_state<a id="change">, _ = self.hist_encoder(</a>encoder_input<a id="change">)</a> &#47&#47 [B, seq_len, rnn_hidden_state]

        if self.futr_exog_size &gt; 0:
            futr_exog = <a id="change">futr_exog.permute(0,2,3,1)[:,:,1:,:]</a>  &#47&#47 [B, F, seq_len, 1+H] -&gt; [B, seq_len, H, F]
            hidden_state = torch.cat(( hidden_state, futr_exog.reshape(batch_size, seq_len, -1)), dim=2)

        &#47&#47 Context adapter
        context = self.context_adapter(hidden_state)
        context<a id="change"> = </a><a id="change">context.reshape(</a>batch_size, seq_len, self.h, self.context_size<a id="change">)</a>

        &#47&#47 Residual connection with futr_exog
        <a id="change">if self.futr_exog_size &gt; 0</a>:
            context<a id="change"> = </a>torch.cat((context, futr_exog), dim=-1)

        &#47&#47 Final forecast
        y_hat<a id="change"> = </a><a id="change">self.mlp_decoder(</a>context<a id="change">)</a>
        
        <a id="change">return </a>y_hat
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nixtla/neuralforecast/commit/9cdb8c8ddd592a3acd47aa982f42bf995092e049#diff-37719fefe7fecc63224807f84d904ce7fdaacdc3e4859aedaf6fb16e8fb9220dL75' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14895574</div><div id='project'> Project Name: nixtla/neuralforecast</div><div id='commit'> Commit Name: 9cdb8c8ddd592a3acd47aa982f42bf995092e049</div><div id='time'> Time: 2022-11-04</div><div id='author'> Author: mergenthaler.m@gmail.com</div><div id='file'> File Name: neuralforecast/models/lstm.py</div><div id='m_class'> M Class Name: LSTM</div><div id='n_method'> N Class Name: LSTM</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: BaseRecurrent</div><div id='n_parent_class'> N Parent Class: BaseRecurrent</div><div id='m_file'> M File Name: neuralforecast/models/lstm.py</div><div id='n_file'> N File Name: neuralforecast/models/lstm.py</div><div id='m_start'> M Start Line: 78</div><div id='m_end'> M End Line: 102</div><div id='n_start'> N Start Line: 126</div><div id='n_end'> N End Line: 161</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Contatenate [ Y_t, | X_{t-L},..., X_{t} | F_{t-L},..., F_{t+H} | S ]
        batch_size, windows_size = insample_y.shape[:2]
        if self.hist_exog_size &gt; 0:
            hist_exog = <a id="change">hist_exog.permute(0</a>,<a id="change">2</a>,<a id="change">1</a>,<a id="change">3</a><a id="change">)</a> &#47&#47 [B, C, W, L] -&gt; [B, W, C, L]
            insample_y = torch.cat(( insample_y, <a id="change">hist_exog.reshape(</a>batch_size, windows_size, <a id="change">-1</a><a id="change">)</a> ), dim=2)

        if self.futr_exog_size &gt; 0:
            futr_exog = <a id="change">futr_exog.permute(0</a>,<a id="change">2</a>,<a id="change">1</a>,<a id="change">3</a><a id="change">)</a> &#47&#47 [B, C, W, L] -&gt; [B, W, C, L]
            insample_y = torch.cat(( insample_y, futr_exog.reshape(batch_size, windows_size, -1) ), dim=2)

        <a id="change">if </a>self.stat_exog_size &gt; 0:
            stat_exog = stat_exog.unsqueeze(1).repeat(1, windows_size, 1) &#47&#47 [B, C] -&gt; [B, W, C]
            insample_y<a id="change"> = </a>torch.cat(( insample_y, stat_exog ), dim=2)

        &#47&#47 GRU forward
        insample_y<a id="change">, _ = </a>self.gru(insample_y)
        insample_y = self.adapterW(insample_y)
        
        <a id="change">return </a>insample_y
</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, windows_batch):
        
        &#47&#47 Parse windows_batch
        <a id="change">encoder_input</a> = windows_batch[&quotinsample_y&quot] &#47&#47 [B, seq_len, 1]
        futr_exog     = windows_batch[&quotfutr_exog&quot]
        hist_exog     = windows_batch[&quothist_exog&quot]
        stat_exog     = windows_batch[&quotstat_exog&quot]

        &#47&#47 Concatenate y, historic and static inputs
        &#47&#47 [B, C, seq_len, 1] -&gt; [B, seq_len, C]
        &#47&#47 Contatenate [ Y_t, | X_{t-L},..., X_{t} | S ]
        batch_size, seq_len = encoder_input.shape[:2]
        if self.hist_exog_size &gt; 0:
            hist_exog = <a id="change">hist_exog.permute(0,2,1,3).squeeze(-1</a><a id="change">)</a> &#47&#47 [B, X, seq_len, 1] -&gt; [B, seq_len, X]
            <a id="change">encoder_input</a> = torch.cat((encoder_input, hist_exog), dim=2)

        <a id="change">if </a>self.stat_exog_size &gt; 0:
            stat_exog = stat_exog.unsqueeze(1).repeat(1, seq_len, 1) &#47&#47 [B, S] -&gt; [B, seq_len, S]
            encoder_input<a id="change"> = </a><a id="change">torch.cat(</a>(encoder_input<a id="change">, stat_exog</a>)<a id="change">, dim=2)</a>

        &#47&#47 RNN forward
        hidden_state<a id="change">, _ = self.hist_encoder(</a>encoder_input<a id="change">)</a> &#47&#47 [B, seq_len, rnn_hidden_state]

        if self.futr_exog_size &gt; 0:
            futr_exog = <a id="change">futr_exog.permute(0,2,3,1)[:,:,1:,:]</a>  &#47&#47 [B, F, seq_len, 1+H] -&gt; [B, seq_len, H, F]
            hidden_state = torch.cat(( hidden_state, futr_exog.reshape(batch_size, seq_len, -1)), dim=2)

        &#47&#47 Context adapter
        context = self.context_adapter(hidden_state)
        context<a id="change"> = </a><a id="change">context.reshape(</a>batch_size, seq_len, self.h, self.context_size<a id="change">)</a>

        &#47&#47 Residual connection with futr_exog
        <a id="change">if self.futr_exog_size &gt; 0</a>:
            context<a id="change"> = </a>torch.cat((context, futr_exog), dim=-1)

        &#47&#47 Final forecast
        y_hat<a id="change"> = </a><a id="change">self.mlp_decoder(</a>context<a id="change">)</a>
        
        <a id="change">return </a>y_hat
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nixtla/neuralforecast/commit/9cdb8c8ddd592a3acd47aa982f42bf995092e049#diff-26a5e64852c57050f8309f88df9aab510efda9127357c8ceb412d68766c2eae2L103' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14895578</div><div id='project'> Project Name: nixtla/neuralforecast</div><div id='commit'> Commit Name: 9cdb8c8ddd592a3acd47aa982f42bf995092e049</div><div id='time'> Time: 2022-11-04</div><div id='author'> Author: mergenthaler.m@gmail.com</div><div id='file'> File Name: neuralforecast/models/gru.py</div><div id='m_class'> M Class Name: GRU</div><div id='n_method'> N Class Name: GRU</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: BaseRecurrent</div><div id='n_parent_class'> N Parent Class: BaseRecurrent</div><div id='m_file'> M File Name: neuralforecast/models/gru.py</div><div id='n_file'> N File Name: neuralforecast/models/gru.py</div><div id='m_start'> M Start Line: 106</div><div id='m_end'> M End Line: 130</div><div id='n_start'> N Start Line: 127</div><div id='n_end'> N End Line: 162</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Contatenate [ Y_t, | X_{t-L},..., X_{t} | F_{t-L},..., F_{t+H} | S ]
        batch_size, windows_size = insample_y.shape[:2]
        if self.hist_exog_size &gt; 0:
            hist_exog = <a id="change">hist_exog.permute(0</a>,<a id="change">2</a>,<a id="change">1</a>,<a id="change">3</a><a id="change">)</a> &#47&#47 [B, C, W, L] -&gt; [B, W, C, L]
            insample_y = torch.cat(( insample_y, <a id="change">hist_exog.reshape(</a>batch_size, windows_size, <a id="change">-1</a><a id="change">)</a> ), dim=2)

        if self.futr_exog_size &gt; 0:
            futr_exog = <a id="change">futr_exog.permute(0</a>,<a id="change">2</a>,<a id="change">1</a>,<a id="change">3</a><a id="change">)</a> &#47&#47 [B, C, W, L] -&gt; [B, W, C, L]
            insample_y = torch.cat(( insample_y, futr_exog.reshape(batch_size, windows_size, -1) ), dim=2)

        <a id="change">if </a>self.stat_exog_size &gt; 0:
            stat_exog = stat_exog.unsqueeze(1).repeat(1, windows_size, 1) &#47&#47 [B, C] -&gt; [B, W, C]
            insample_y<a id="change"> = </a>torch.cat(( insample_y, stat_exog ), dim=2)

        &#47&#47 RNN forward
        insample_y<a id="change">, _ = </a>self.rnn(insample_y)
        insample_y = self.adapterW(insample_y)
        
        <a id="change">return </a>insample_y
</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, windows_batch):
        
        &#47&#47 Parse windows_batch
        <a id="change">encoder_input</a> = windows_batch[&quotinsample_y&quot] &#47&#47 [B, seq_len, 1]
        futr_exog     = windows_batch[&quotfutr_exog&quot]
        hist_exog     = windows_batch[&quothist_exog&quot]
        stat_exog     = windows_batch[&quotstat_exog&quot]

        &#47&#47 Concatenate y, historic and static inputs
        &#47&#47 [B, C, seq_len, 1] -&gt; [B, seq_len, C]
        &#47&#47 Contatenate [ Y_t, | X_{t-L},..., X_{t} | S ]
        batch_size, seq_len = encoder_input.shape[:2]
        if self.hist_exog_size &gt; 0:
            hist_exog = <a id="change">hist_exog.permute(0,2,1,3).squeeze(-1</a><a id="change">)</a> &#47&#47 [B, X, seq_len, 1] -&gt; [B, seq_len, X]
            <a id="change">encoder_input</a> = torch.cat((encoder_input, hist_exog), dim=2)

        <a id="change">if </a>self.stat_exog_size &gt; 0:
            stat_exog = stat_exog.unsqueeze(1).repeat(1, seq_len, 1) &#47&#47 [B, S] -&gt; [B, seq_len, S]
            encoder_input<a id="change"> = </a><a id="change">torch.cat(</a>(encoder_input<a id="change">, stat_exog</a>)<a id="change">, dim=2)</a>

        &#47&#47 RNN forward
        hidden_state<a id="change">, _ = self.hist_encoder(</a>encoder_input<a id="change">)</a> &#47&#47 [B, seq_len, rnn_hidden_state]

        if self.futr_exog_size &gt; 0:
            futr_exog = <a id="change">futr_exog.permute(0,2,3,1)[:,:,1:,:]</a>  &#47&#47 [B, F, seq_len, 1+H] -&gt; [B, seq_len, H, F]
            hidden_state = torch.cat(( hidden_state, futr_exog.reshape(batch_size, seq_len, -1)), dim=2)

        &#47&#47 Context adapter
        context = self.context_adapter(hidden_state)
        context<a id="change"> = </a><a id="change">context.reshape(</a>batch_size, seq_len, self.h, self.context_size<a id="change">)</a>

        &#47&#47 Residual connection with futr_exog
        <a id="change">if self.futr_exog_size &gt; 0</a>:
            context<a id="change"> = </a>torch.cat((context, futr_exog), dim=-1)

        &#47&#47 Final forecast
        y_hat<a id="change"> = </a><a id="change">self.mlp_decoder(</a>context<a id="change">)</a>
        
        <a id="change">return </a>y_hat
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nixtla/neuralforecast/commit/9cdb8c8ddd592a3acd47aa982f42bf995092e049#diff-740ef2665dc25c93d5965786c1c9ee5ea107d9cdafa2d9adb5073db0b3677541L104' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14895576</div><div id='project'> Project Name: nixtla/neuralforecast</div><div id='commit'> Commit Name: 9cdb8c8ddd592a3acd47aa982f42bf995092e049</div><div id='time'> Time: 2022-11-04</div><div id='author'> Author: mergenthaler.m@gmail.com</div><div id='file'> File Name: neuralforecast/models/rnn.py</div><div id='m_class'> M Class Name: RNN</div><div id='n_method'> N Class Name: RNN</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: BaseRecurrent</div><div id='n_parent_class'> N Parent Class: BaseRecurrent</div><div id='m_file'> M File Name: neuralforecast/models/rnn.py</div><div id='n_file'> N File Name: neuralforecast/models/rnn.py</div><div id='m_start'> M Start Line: 107</div><div id='m_end'> M End Line: 131</div><div id='n_start'> N Start Line: 129</div><div id='n_end'> N End Line: 164</div><BR>