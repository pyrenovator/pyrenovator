<html><h3>Pattern ID :15084
</h3><img src='50897089.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                inputs = {k:paddle.to_tensor([v]) for (k, v) in inputs.items()}
                logits = model(**inputs)
        
        sequence_output<a id="change">, _</a> = self.ernie_m(input_ids,
                                          position_ids=position_ids,
                                          attention_mask=attention_mask)
</code></pre><h3>After Change</h3><pre><code class='java'>
                               output_hidden_states=output_hidden_states,
                               return_dict=return_dict)

        sequence_output = self.dropout(<a id="change">outputs[0]</a>)
        logits = self.classifier(sequence_output)

        <a id="change">loss = None</a>
        <a id="change">if </a><a id="change">labels is not None</a>:
            loss_fct<a id="change"> = </a><a id="change">paddle.nn.CrossEntropyLoss()</a>
            <a id="change">loss = </a><a id="change">loss_fct(</a>logits.reshape((-1, self.num_classes)),
                            labels.reshape((-1, ))<a id="change">)</a>
        <a id="change">if not return_dict</a>:
            <a id="change">output</a><a id="change"> = </a>(logits<a id="change"></a>, )<a id="change"> + outputs[2:]</a>
            <a id="change">return </a>((<a id="change">loss</a>, )<a id="change"> + output</a>)<a id="change"> if loss</a><a id="change"> is not None else </a>(
                <a id="change">output[0]</a><a id="change"> if len(output) == 1</a><a id="change"> else </a>output)

        <a id="change">return </a>TokenClassifierOutput(
            loss=loss,
            logits=logits,
            hidden_states=outputs.hidden_states,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 27</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/2173cf358b13562d17789889dedcd44a1d2ff270#diff-96abded0993a1d6c809fc53aa1d70c97221cf6fc0bd4cc21c0bce21f43630be1L449' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 50897089</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 2173cf358b13562d17789889dedcd44a1d2ff270</div><div id='time'> Time: 2022-09-13</div><div id='author'> Author: 1435130236@qq.com</div><div id='file'> File Name: paddlenlp/transformers/ernie_m/modeling.py</div><div id='m_class'> M Class Name: ErnieMForTokenClassification</div><div id='n_method'> N Class Name: ErnieMForTokenClassification</div><div id='m_method'> M Method Name: forward(8)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: ErnieMPretrainedModel</div><div id='n_parent_class'> N Parent Class: ErnieMPretrainedModel</div><div id='m_file'> M File Name: paddlenlp/transformers/ernie_m/modeling.py</div><div id='n_file'> N File Name: paddlenlp/transformers/ernie_m/modeling.py</div><div id='m_start'> M Start Line: 449</div><div id='m_end'> M End Line: 482</div><div id='n_start'> N Start Line: 601</div><div id='n_end'> N End Line: 671</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            attention_mask = attention_mask.reshape(
                shape=(-1, attention_mask.shape[-1]))

        _<a id="change">, pooled_output</a> = self.ernie_m(input_ids,
                                        position_ids=position_ids,
                                        attention_mask=attention_mask)
</code></pre><h3>After Change</h3><pre><code class='java'>
            attention_mask = attention_mask.reshape(
                shape=(-1, attention_mask.shape[-1]))

        <a id="change">outputs</a> = self.ernie_m(input_ids,
                               position_ids=position_ids,
                               attention_mask=attention_mask,
                               output_attentions=output_attentions,
                               output_hidden_states=output_hidden_states,
                               return_dict=return_dict)

        pooled_output = self.dropout(<a id="change">outputs[1]</a>)

        logits = self.classifier(pooled_output)  &#47&#47 logits: (bs*num_choice,1)
        reshaped_logits = logits.reshape(
            shape=(-1, self.num_choices))  &#47&#47 logits: (bs, num_choice)

        <a id="change">loss = </a>None
        <a id="change">if </a><a id="change">labels is not None</a>:
            loss_fct<a id="change"> = </a><a id="change">paddle.nn.CrossEntropyLoss()</a>
            <a id="change">loss = </a><a id="change">loss_fct(</a>reshaped_logits, labels<a id="change">)</a>
        <a id="change">if not return_dict</a>:
            <a id="change">output</a><a id="change"> = </a>(reshaped_logits<a id="change"></a>, )<a id="change"> + outputs[2:]</a>
            <a id="change">return </a>((loss<a id="change"></a>, )<a id="change"> + </a>output)<a id="change"> if </a><a id="change">loss is not None else </a>(
                <a id="change">output[0]</a><a id="change"> if len(output) == 1</a><a id="change"> else </a>output)

        <a id="change">return </a>MultipleChoiceModelOutput(
            loss=loss,
            logits=reshaped_logits,
            hidden_states=outputs.hidden_states,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/2173cf358b13562d17789889dedcd44a1d2ff270#diff-96abded0993a1d6c809fc53aa1d70c97221cf6fc0bd4cc21c0bce21f43630be1L510' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 50897090</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 2173cf358b13562d17789889dedcd44a1d2ff270</div><div id='time'> Time: 2022-09-13</div><div id='author'> Author: 1435130236@qq.com</div><div id='file'> File Name: paddlenlp/transformers/ernie_m/modeling.py</div><div id='m_class'> M Class Name: ErnieMForMultipleChoice</div><div id='n_method'> N Class Name: ErnieMForMultipleChoice</div><div id='m_method'> M Method Name: forward(8)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: ErnieMPretrainedModel</div><div id='n_parent_class'> N Parent Class: ErnieMPretrainedModel</div><div id='m_file'> M File Name: paddlenlp/transformers/ernie_m/modeling.py</div><div id='n_file'> N File Name: paddlenlp/transformers/ernie_m/modeling.py</div><div id='m_start'> M Start Line: 510</div><div id='m_end'> M End Line: 546</div><div id='n_start'> N Start Line: 699</div><div id='n_end'> N End Line: 773</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                inputs = {k:paddle.to_tensor([v]) for (k, v) in inputs.items()}
                logits = model(**inputs)
        
        sequence_output<a id="change">, _</a> = self.ernie_gram(input_ids,
                                             token_type_ids=token_type_ids,
                                             position_ids=position_ids,
                                             attention_mask=attention_mask)</code></pre><h3>After Change</h3><pre><code class='java'>
                inputs = {k:paddle.to_tensor([v]) for (k, v) in inputs.items()}
                logits = model(**inputs)
        
        <a id="change">outputs</a> = self.ernie_gram(input_ids,
                                  token_type_ids=token_type_ids,
                                  position_ids=position_ids,
                                  attention_mask=attention_mask,
                                  output_attentions=output_attentions,
                                  output_hidden_states=output_hidden_states,
                                  return_dict=return_dict)

        sequence_output = <a id="change">outputs[0]</a>

        sequence_output = self.dropout(sequence_output)
        logits = self.classifier(sequence_output)

        <a id="change">loss = </a>None
        <a id="change">if </a><a id="change">labels is not None</a>:
            loss_fct<a id="change"> = </a><a id="change">paddle.nn.CrossEntropyLoss()</a>
            <a id="change">loss = </a><a id="change">loss_fct(</a>logits.reshape((-1, self.num_classes)),
                            labels.reshape((-1, ))<a id="change">)</a>
        <a id="change">if not return_dict</a>:
            <a id="change">output</a><a id="change"> = </a>(logits<a id="change"></a>, )<a id="change"> + outputs[2:]</a>
            <a id="change">return </a>((loss<a id="change"></a>, )<a id="change"> + </a>output)<a id="change"> if </a><a id="change">loss is not None else </a>(
                <a id="change">output[0]</a><a id="change"> if len(output) == 1</a><a id="change"> else </a>output)

        <a id="change">return </a>TokenClassifierOutput(
            loss=loss,
            logits=logits,
            hidden_states=outputs.hidden_states,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/2173cf358b13562d17789889dedcd44a1d2ff270#diff-bdcabfa79ed873241a8786d3a690cc85696ec4ebc25cbc2dd29c67211692fa2eL356' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 50897091</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 2173cf358b13562d17789889dedcd44a1d2ff270</div><div id='time'> Time: 2022-09-13</div><div id='author'> Author: 1435130236@qq.com</div><div id='file'> File Name: paddlenlp/transformers/ernie_gram/modeling.py</div><div id='m_class'> M Class Name: ErnieGramForTokenClassification</div><div id='n_method'> N Class Name: ErnieGramForTokenClassification</div><div id='m_method'> M Method Name: forward(9)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: ErnieGramPretrainedModel</div><div id='n_parent_class'> N Parent Class: ErnieGramPretrainedModel</div><div id='m_file'> M File Name: paddlenlp/transformers/ernie_gram/modeling.py</div><div id='n_file'> N File Name: paddlenlp/transformers/ernie_gram/modeling.py</div><div id='m_start'> M Start Line: 389</div><div id='m_end'> M End Line: 396</div><div id='n_start'> N Start Line: 397</div><div id='n_end'> N End Line: 468</div><BR>