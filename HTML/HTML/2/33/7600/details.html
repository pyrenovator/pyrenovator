<html><h3>Pattern ID :7600
</h3><img src='25283777.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            self._run_train()

    def _run_collect(self, n_steps: int = 1) -&gt; None:
        <a id="change">for _</a> in <a id="change">range(</a>n_steps<a id="change">)</a><a id="change">:
            </a>act = self.agent.sample(self.obs)
            next_obs, reward, done, infos = self.envs.step(act)
            real_next_obs = next_obs.copy()

            for idx, d in enumerate(done):
                if d and infos[idx].get("terminal_observation") is not None:
                    real_next_obs[idx] = infos[idx]["terminal_observation"]

            self.buffer.add(self.obs, real_next_obs, act, reward, done, infos)
            self.obs = next_obs

            &#47&#47 logger
            <a id="change">for </a>info in infos<a id="change">:
                </a>if "episode" in info.keys():
                    <a id="change">writer.add_scalar(
                        "collect/episodic_length"</a>,
                        <a id="change">info["episode"]["l"]</a>,
                        self.agent.sample_step<a id="change">,
                    )</a>
                    <a id="change">writer.add_scalar(
                        "collect/episodic_return"</a>,
                        <a id="change">info["episode"]["r"]</a>,
                        self.agent.sample_step<a id="change">,
                    )</a>
                    <a id="change">print(
                        </a><a id="change">f"{self.agent.sample_step}: "</a><a id="change">
                        + f"episodic_length {info[&quotepisode&quot][&quotl&quot]}, "
                        + f"episodic_return {info[&quotepisode&quot][&quotr&quot]}"
                    )</a>
                    <a id="change">break</a>

    def _run_train(self) -&gt; None:
        data = self.buffer.sample(self.kwargs["batch_size"])
        log_data = self.agent.learn(data)</code></pre><h3>After Change</h3><pre><code class='java'>
        self.buffer.add(self.obs, real_next_obs, act, reward, done, infos)
        self.obs = next_obs

        <a id="change">for </a><a id="change">info</a> in infos<a id="change">:
            </a>if "episode" in info.keys():
                <a id="change">return {
                    </a>"log_type": "collect",
                    "sample_step": self.agent.sample_step,
                    "logs": <a id="change">{
                        </a>"episodic_length": <a id="change">info["episode"]["l"]</a>,
                        "episodic_return": <a id="change">info["episode"]["r"],
                    },
                }</a>
        <a id="change">return {</a>"log_type": "collect"<a id="change">}</a>

    def _run_train(self) -&gt; Dict:
        data = self.buffer.sample(self.kwargs["batch_size"])
        log_data = self.agent.learn(data)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 29</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/sdpkjc/abcdrl/commit/cd5af78e4b40905c5824712d1dceccec749b4358#diff-0b5a28f6770b62f9513c45dfb9f342d151daa6eaab474e4f597478a38a60ec42L261' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25283777</div><div id='project'> Project Name: sdpkjc/abcdrl</div><div id='commit'> Commit Name: cd5af78e4b40905c5824712d1dceccec749b4358</div><div id='time'> Time: 2022-10-31</div><div id='author'> Author: 425826492@qq.com</div><div id='file'> File Name: abcdrl/ddpg.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: _run_collect(1)</div><div id='n_method'> N Method Name: _run_collect(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: abcdrl/ddpg.py</div><div id='n_file'> N File Name: abcdrl/ddpg.py</div><div id='m_start'> M Start Line: 286</div><div id='m_end'> M End Line: 319</div><div id='n_start'> N Start Line: 261</div><div id='n_end'> N End Line: 283</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            self._run_train()

    def _run_collect(self, n_steps: int = 1) -&gt; None:
        <a id="change">for _</a> in <a id="change">range(</a>n_steps<a id="change">)</a><a id="change">:
            </a>act = self.agent.sample(self.obs)
            next_obs, reward, done, infos = self.envs.step(act)
            real_next_obs = next_obs.copy()

            for idx, d in enumerate(done):
                if d and infos[idx].get("terminal_observation") is not None:
                    real_next_obs[idx] = infos[idx]["terminal_observation"]

            self.buffer.add(self.obs, real_next_obs, act, reward, done, infos)
            self.obs = next_obs

            &#47&#47 logger
            <a id="change">for </a><a id="change">info</a> in infos<a id="change">:
                </a>if "episode" in info.keys():
                    <a id="change">writer.add_scalar(
                        "collect/episodic_length"</a>,
                        <a id="change">info["episode"]["l"]</a>,
                        self.agent.sample_step<a id="change">,
                    )</a>
                    <a id="change">writer.add_scalar(
                        "collect/episodic_return"</a>,
                        <a id="change">info["episode"]["r"]</a>,
                        self.agent.sample_step<a id="change">,
                    )</a>
                    <a id="change">print(
                        </a><a id="change">f"{self.agent.sample_step}: "</a><a id="change">
                        + f"episodic_length {info[&quotepisode&quot][&quotl&quot]}, "
                        + f"episodic_return {info[&quotepisode&quot][&quotr&quot]}"
                    )</a>
                    <a id="change">break</a>

    def _run_train(self) -&gt; None:
        data = self.buffer.sample(self.kwargs["batch_size"])
        log_data = self.agent.learn(data)</code></pre><h3>After Change</h3><pre><code class='java'>
        self.buffer.add(self.obs, real_next_obs, act, reward, done, infos)
        self.obs = next_obs

        <a id="change">for </a><a id="change">info</a> in infos<a id="change">:
            </a>if "episode" in info.keys():
                <a id="change">return </a><a id="change">{
                    </a>"log_type": "collect",
                    "sample_step": self.agent.sample_step,
                    "logs": <a id="change">{
                        </a>"episodic_length": <a id="change">info["episode"]["l"]</a>,
                        "episodic_return": <a id="change">info["episode"]["r"],
                    }</a><a id="change">,
                }</a>
        <a id="change">return {</a>"log_type": "collect"<a id="change">}</a>

    def _run_train(self) -&gt; Dict:
        data = self.buffer.sample(self.kwargs["batch_size"])
        log_data = self.agent.learn(data)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sdpkjc/abcdrl/commit/cd5af78e4b40905c5824712d1dceccec749b4358#diff-0b5a28f6770b62f9513c45dfb9f342d151daa6eaab474e4f597478a38a60ec42L286' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25283776</div><div id='project'> Project Name: sdpkjc/abcdrl</div><div id='commit'> Commit Name: cd5af78e4b40905c5824712d1dceccec749b4358</div><div id='time'> Time: 2022-10-31</div><div id='author'> Author: 425826492@qq.com</div><div id='file'> File Name: abcdrl/ddpg.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: _run_collect(1)</div><div id='n_method'> N Method Name: _run_collect(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: abcdrl/ddpg.py</div><div id='n_file'> N File Name: abcdrl/ddpg.py</div><div id='m_start'> M Start Line: 286</div><div id='m_end'> M End Line: 319</div><div id='n_start'> N Start Line: 261</div><div id='n_end'> N End Line: 283</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            self._run_train()

    def _run_collect(self, n_steps: int = 1) -&gt; None:
        <a id="change">for _</a> in <a id="change">range(</a>n_steps<a id="change">)</a><a id="change">:
            </a>act = self.agent.sample(self.obs)
            next_obs, reward, done, infos = self.envs.step(act)
            real_next_obs = next_obs.copy()

            for idx, d in enumerate(done):
                if d and infos[idx].get("terminal_observation") is not None:
                    real_next_obs[idx] = infos[idx]["terminal_observation"]

            self.buffer.add(self.obs, real_next_obs, act, reward, done, infos)
            self.obs = next_obs

            &#47&#47 logger
            <a id="change">for </a><a id="change">info</a> in infos<a id="change">:
                </a>if "episode" in info.keys():
                    <a id="change">writer.add_scalar(
                        "collect/episodic_length"</a>,
                        <a id="change">info["episode"]["l"]</a>,
                        self.agent.sample_step<a id="change">,
                    )</a>
                    <a id="change">writer.add_scalar(
                        "collect/episodic_return"</a>,
                        <a id="change">info["episode"]["r"]</a>,
                        self.agent.sample_step<a id="change">,
                    )</a>
                    <a id="change">print(
                        </a><a id="change">f"{self.agent.sample_step}: "</a><a id="change">
                        + f"episodic_length {info[&quotepisode&quot][&quotl&quot]}, "
                        + f"episodic_return {info[&quotepisode&quot][&quotr&quot]}"
                    )</a>
                    <a id="change">break</a>

    def _run_train(self) -&gt; None:
        data = self.buffer.sample(self.kwargs["batch_size"])
        log_data = self.agent.learn(data)</code></pre><h3>After Change</h3><pre><code class='java'>
        self.buffer.add(self.obs, real_next_obs, act, reward, done, infos)
        self.obs = next_obs

        <a id="change">for </a><a id="change">info</a> in infos<a id="change">:
            </a>if "episode" in info.keys():
                <a id="change">return {
                    </a>"log_type": "collect",
                    "sample_step": self.agent.sample_step,
                    "logs": <a id="change">{
                        </a>"episodic_length": <a id="change">info["episode"]["l"]</a>,
                        "episodic_return": <a id="change">info["episode"]["r"],
                    }</a><a id="change">,
                }</a>
        <a id="change">return </a><a id="change">{</a>"log_type": "collect"<a id="change">}</a>

    def _run_train(self) -&gt; Dict:
        data = self.buffer.sample(self.kwargs["batch_size"])
        log_data = self.agent.learn(data)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sdpkjc/abcdrl/commit/cd5af78e4b40905c5824712d1dceccec749b4358#diff-be500802db8d0207abcd2c1bc014c86b950ab17e39629b57bb2e46ed5c7fbc50L225' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25283779</div><div id='project'> Project Name: sdpkjc/abcdrl</div><div id='commit'> Commit Name: cd5af78e4b40905c5824712d1dceccec749b4358</div><div id='time'> Time: 2022-10-31</div><div id='author'> Author: 425826492@qq.com</div><div id='file'> File Name: abcdrl/ddqn.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: _run_collect(1)</div><div id='n_method'> N Method Name: _run_collect(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: abcdrl/ddqn.py</div><div id='n_file'> N File Name: abcdrl/ddqn.py</div><div id='m_start'> M Start Line: 225</div><div id='m_end'> M End Line: 258</div><div id='n_start'> N Start Line: 198</div><div id='n_end'> N End Line: 220</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            self._run_train()

    def _run_collect(self, n_steps: int = 1) -&gt; None:
        <a id="change">for _</a> in <a id="change">range(</a>n_steps<a id="change">)</a><a id="change">:
            </a>act = self.agent.sample(self.obs)
            next_obs, reward, done, infos = self.envs.step(act)
            real_next_obs = next_obs.copy()

            for idx, d in enumerate(done):
                if d and infos[idx].get("terminal_observation") is not None:
                    real_next_obs[idx] = infos[idx]["terminal_observation"]

            self.buffer.add(self.obs, real_next_obs, act, reward, done, infos)
            self.obs = next_obs

            &#47&#47 logger
            <a id="change">for </a><a id="change">info</a> in infos<a id="change">:
                </a>if "episode" in info.keys():
                    <a id="change">writer.add_scalar(
                        "collect/episodic_length"</a>,
                        <a id="change">info["episode"]["l"]</a>,
                        self.agent.sample_step<a id="change">,
                    )</a>
                    <a id="change">writer.add_scalar(
                        "collect/episodic_return"</a>,
                        <a id="change">info["episode"]["r"]</a>,
                        self.agent.sample_step<a id="change">,
                    )</a>
                    <a id="change">print(
                        </a><a id="change">f"{self.agent.sample_step}: "</a><a id="change">
                        + f"episodic_length {info[&quotepisode&quot][&quotl&quot]}, "
                        + f"episodic_return {info[&quotepisode&quot][&quotr&quot]}"
                    )</a>
                    <a id="change">break</a>

    def _run_train(self) -&gt; None:
        data = self.buffer.sample(self.kwargs["batch_size"])
        log_data = self.agent.learn(data)</code></pre><h3>After Change</h3><pre><code class='java'>
        self.buffer.add(self.obs, real_next_obs, act, reward, done, infos)
        self.obs = next_obs

        <a id="change">for </a><a id="change">info</a> in infos<a id="change">:
            </a>if "episode" in info.keys():
                <a id="change">return {
                    </a>"log_type": "collect",
                    "sample_step": self.agent.sample_step,
                    "logs": <a id="change">{
                        </a>"episodic_length": <a id="change">info["episode"]["l"]</a>,
                        "episodic_return": <a id="change">info["episode"]["r"],
                    }</a><a id="change">,
                }</a>
        <a id="change">return </a><a id="change">{</a>"log_type": "collect"<a id="change">}</a>

    def _run_train(self) -&gt; Dict:
        data = self.buffer.sample(self.kwargs["batch_size"])
        log_data = self.agent.learn(data)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sdpkjc/abcdrl/commit/cd5af78e4b40905c5824712d1dceccec749b4358#diff-29f2866d7e445fb48505353d21003754c92acfcceac6c8ed6b81ffca1460997bL223' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25283778</div><div id='project'> Project Name: sdpkjc/abcdrl</div><div id='commit'> Commit Name: cd5af78e4b40905c5824712d1dceccec749b4358</div><div id='time'> Time: 2022-10-31</div><div id='author'> Author: 425826492@qq.com</div><div id='file'> File Name: abcdrl/dqn.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: _run_collect(1)</div><div id='n_method'> N Method Name: _run_collect(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: abcdrl/dqn.py</div><div id='n_file'> N File Name: abcdrl/dqn.py</div><div id='m_start'> M Start Line: 223</div><div id='m_end'> M End Line: 256</div><div id='n_start'> N Start Line: 196</div><div id='n_end'> N End Line: 218</div><BR>