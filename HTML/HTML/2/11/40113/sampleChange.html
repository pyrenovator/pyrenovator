<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 Run a forward chain to collect intermediate inputs
        &#47&#47 Note that we do not forward for the last module since we do not need its output
        inter_inputs<a id="change"> = [</a>inputs<a id="change"></a>]
        <a id="change">for </a>backend in requested_backends[:-1]<a id="change">:
            </a>assert inputs.ndim == 3, f"inputs to {type(backend)} must be a single 3d tensor of hidden states"
            inputs = await backend.forward_pool.submit_task(inputs)
            assert isinstance(inputs, (list, tuple)) and len(inputs) == 1
            inputs<a id="change"> = </a><a id="change">inputs[0]</a>
            <a id="change">inter_inputs.append(</a>inputs<a id="change">)</a>

        &#47&#47 Run a chain of requested backends
        <a id="change">for </a>inp, backend in zip(inter_inputs[::-1], requested_backends[::-1])<a id="change">:
            </a>inputs_and_grads = [inp, grads]
            grads<a id="change"> = await </a>backend.backward_pool.submit_task(*inputs_and_grads)
            assert isinstance(grads, (list, tuple)) and len(grads) == 1
            grads = grads[0]
</code></pre><h3>After Change</h3><pre><code class='java'>
        requested_uids = self._check_uids(request.uid)
        requested_backends = tuple(self.module_backends[uid] for uid in requested_uids)

        grads = <a id="change">await </a>_rpc_backward(*flat_tensors, requested_backends=requested_backends)

        &#47&#47 Modify grad_inputs_schema to support grad_prompts
        assert len(requested_backends[0].args_schema) == 1 and len(grads) in (1, 2)  &#47&#47 TODO generalize</code></pre>