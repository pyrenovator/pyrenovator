<html><h3>Pattern ID :2808
</h3><img src='11238123.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        logp_pi = pi_distribution.log_prob(actions).sum(axis=-1)
        logp_pi -= (2*(np.log(2) - actions - F.softplus(-2*actions))).sum(axis=1)

        <a id="change">return </a>logp_pi


</code></pre><h3>After Change</h3><pre><code class='java'>


    def get_logprob(self, obs, act):
        <a id="change">value</a><a id="change"> = </a><a id="change">torch.clamp(</a>act, -0.999999, 0.999999<a id="change">)</a>
        pre_tanh_value<a id="change"> = </a>torch<a id="change">.log(1+value) / 2 - </a>torch.log(<a id="change">1</a><a id="change">-value</a>)<a id="change"> / </a>2


        net_out = self.net(obs)
        mu = self.mu_layer(net_out)
        log_std = self.log_std_layer(net_out)
        log_std = torch.clamp(log_std, LOG_STD_MIN, LOG_STD_MAX)
        std = torch.exp(log_std)
        &#47&#47 Pre-squash distribution and sample
        pi_distribution = Normal(mu, std)
        log_prob_val = pi_distribution.log_prob(pre_tanh_value)
        
        correction = - 2. * (
            torch.from_numpy(np.log([2.])).to(pre_tanh_value.get_device())
            - pre_tanh_value
            - torch.nn.functional.softplus(-2. * pre_tanh_value)
        ).sum(dim=1)
        
        <a id="change">return </a>log_prob_val.sum(dim=1) + correction


class awacMLPActor(nn.Module):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/hari-sikchi/offline_rl/commit/bf9dfc7b6c75f6f21296e7f7e5190e5abb675603#diff-935bc67832a22823701c35975421947be81615771e83d7ca168792058a15a347L90' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11238123</div><div id='project'> Project Name: hari-sikchi/offline_rl</div><div id='commit'> Commit Name: bf9dfc7b6c75f6f21296e7f7e5190e5abb675603</div><div id='time'> Time: 2021-10-04</div><div id='author'> Author: harshitsikchi8@gmail.com</div><div id='file'> File Name: core.py</div><div id='m_class'> M Class Name: SquashedGaussianMLPActor</div><div id='n_method'> N Class Name: SquashedGaussianMLPActor</div><div id='m_method'> M Method Name: get_logprob(3)</div><div id='n_method'> N Method Name: get_logprob(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: core.py</div><div id='n_file'> N File Name: core.py</div><div id='m_start'> M Start Line: 90</div><div id='m_end'> M End Line: 93</div><div id='n_start'> N Start Line: 97</div><div id='n_end'> N End Line: 116</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        logp_pi = pi_distribution.log_prob(actions).sum(axis=-1)
        logp_pi -= (2*(np.log(2) - actions - F.softplus(-2*actions))).sum(axis=1)

        <a id="change">return </a>logp_pi


</code></pre><h3>After Change</h3><pre><code class='java'>


    def get_logprob(self, obs, act):
        <a id="change">value</a><a id="change"> = </a><a id="change">torch.clamp(</a>act, -0.999999, 0.999999<a id="change">)</a>
        pre_tanh_value = torch<a id="change">.log(1+value) / 2 - </a>torch.log(1<a id="change">-</a>value) / 2


        net_out = self.net(obs)
        mu = self.mu_layer(net_out)
        log_std = self.log_std_layer(net_out)
        log_std = torch.clamp(log_std, LOG_STD_MIN, LOG_STD_MAX)
        std = torch.exp(log_std)
        &#47&#47 Pre-squash distribution and sample
        pi_distribution = Normal(mu, std)
        log_prob_val = pi_distribution.log_prob(pre_tanh_value)
        
        correction<a id="change"> = </a>- 2. * (
            torch.from_numpy(np.log([2.])).to(pre_tanh_value.get_device())
            - pre_tanh_value
            - torch.nn.functional.softplus(-2. * pre_tanh_value)
        ).sum(dim=1)
        
        <a id="change">return </a>log_prob_val.sum(dim=1) + correction


class awacMLPActor(nn.Module):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hari-sikchi/offline_rl/commit/bf9dfc7b6c75f6f21296e7f7e5190e5abb675603#diff-935bc67832a22823701c35975421947be81615771e83d7ca168792058a15a347L83' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11238122</div><div id='project'> Project Name: hari-sikchi/offline_rl</div><div id='commit'> Commit Name: bf9dfc7b6c75f6f21296e7f7e5190e5abb675603</div><div id='time'> Time: 2021-10-04</div><div id='author'> Author: harshitsikchi8@gmail.com</div><div id='file'> File Name: core.py</div><div id='m_class'> M Class Name: SquashedGaussianMLPActor</div><div id='n_method'> N Class Name: SquashedGaussianMLPActor</div><div id='m_method'> M Method Name: get_logprob(3)</div><div id='n_method'> N Method Name: get_logprob(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: core.py</div><div id='n_file'> N File Name: core.py</div><div id='m_start'> M Start Line: 90</div><div id='m_end'> M End Line: 93</div><div id='n_start'> N Start Line: 97</div><div id='n_end'> N End Line: 116</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self, x_curr: TensorType["num_samples", "num_keypoints", 2]
    ) -&gt; TensorType["num_samples", "num_keypoints", 2]:
        &#47&#47 TODO: check dims of x_curr and self.data
        <a id="change">return </a>x_curr - self.lr * self.l2_grad(x_curr - self.data)

    def project(
        self, x_after_step: TensorType["num_samples", "num_keypoints", 2]</code></pre><h3>After Change</h3><pre><code class='java'>
    ) -&gt; TensorType["num_samples", "num_keypoints", 2]:
        norm = torch.linalg.norm(x_curr-self.data, dim=2, keepdim=True)
        step = (self.lr * self.confidences) / (norm + 1e-8)
        <a id="change">step</a><a id="change"> = </a><a id="change">torch.clamp(</a>step<a id="change">, min=0.0, max=1.0)</a>
        x_after_step<a id="change"> = </a>(<a id="change">1-step)*x_curr + </a>step<a id="change">*</a>self.data
        <a id="change">return </a>x_after_step
        &#47&#47 standard way below
        &#47&#47 return x_curr - self.lr * self.l2_grad(x_curr - self.data)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/danbider/lightning-pose/commit/d229e0a7034b2447f996443dd6d81a171429e368#diff-4742a4a7d6bde4f4f4e93adc11ad6455b152ae7e1cd696e98f6991bf8ba43f81L64' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11238120</div><div id='project'> Project Name: danbider/lightning-pose</div><div id='commit'> Commit Name: d229e0a7034b2447f996443dd6d81a171429e368</div><div id='time'> Time: 2022-04-01</div><div id='author'> Author: </div><div id='file'> File Name: lightning_pose/postprocess/projected_gd.py</div><div id='m_class'> M Class Name: ProjectedGD</div><div id='n_method'> N Class Name: ProjectedGD</div><div id='m_method'> M Method Name: grad_step(2)</div><div id='n_method'> N Method Name: grad_step(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: lightning_pose/postprocess/projected_gd.py</div><div id='n_file'> N File Name: lightning_pose/postprocess/projected_gd.py</div><div id='m_start'> M Start Line: 68</div><div id='m_end'> M End Line: 68</div><div id='n_start'> N Start Line: 76</div><div id='n_end'> N End Line: 80</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self, x_curr: TensorType["num_samples", "num_keypoints", 2]
    ) -&gt; TensorType["num_samples", "num_keypoints", 2]:
        &#47&#47 TODO: check dims of x_curr and self.data
        <a id="change">return </a>x_curr - self.lr * self.l2_grad(x_curr - self.data)

    def project(
        self, x_after_step: TensorType["num_samples", "num_keypoints", 2]</code></pre><h3>After Change</h3><pre><code class='java'>
    ) -&gt; TensorType["num_samples", "num_keypoints", 2]:
        norm = torch.linalg.norm(x_curr-self.data, dim=2, keepdim=True)
        step = (self.lr * self.confidences) / (norm + 1e-8)
        <a id="change">step</a><a id="change"> = </a><a id="change">torch.clamp(</a>step<a id="change">, min=0.0, max=1.0)</a>
        x_after_step<a id="change"> = </a>(<a id="change">1-step)*x_curr + </a>step<a id="change">*</a>self.data
        <a id="change">return </a>x_after_step
        &#47&#47 standard way below
        &#47&#47 return x_curr - self.lr * self.l2_grad(x_curr - self.data)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/danbider/lightning-pose/commit/eefeaef320b562367d2e2def54e75bf1f4c0590f#diff-4742a4a7d6bde4f4f4e93adc11ad6455b152ae7e1cd696e98f6991bf8ba43f81L64' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11238115</div><div id='project'> Project Name: danbider/lightning-pose</div><div id='commit'> Commit Name: eefeaef320b562367d2e2def54e75bf1f4c0590f</div><div id='time'> Time: 2022-04-01</div><div id='author'> Author: </div><div id='file'> File Name: lightning_pose/postprocess/projected_gd.py</div><div id='m_class'> M Class Name: ProjectedGD</div><div id='n_method'> N Class Name: ProjectedGD</div><div id='m_method'> M Method Name: grad_step(2)</div><div id='n_method'> N Method Name: grad_step(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: lightning_pose/postprocess/projected_gd.py</div><div id='n_file'> N File Name: lightning_pose/postprocess/projected_gd.py</div><div id='m_start'> M Start Line: 68</div><div id='m_end'> M End Line: 68</div><div id='n_start'> N Start Line: 76</div><div id='n_end'> N End Line: 80</div><BR>