<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                if p.grad is None:
                    continue

                p_data_fp32 = <a id="change">p.data.float()</a>

                d_p = p.grad.data.float()
                param_state = self.state[p]
                if &quotmomentum_buffer&quot not in param_state:
                    param_state[&quotmomentum_buffer&quot] = torch.zeros_like(d_p)
                else:
                    param_state[&quotmomentum_buffer&quot] = param_state[&quotmomentum_buffer&quot].type_as(d_p)

                buf = param_state[&quotmomentum_buffer&quot]

                if weight_decay != 0:
                    p_data_fp32.mul_(1 - lr * weight_decay)
                p_data_fp32.add_(buf, alpha=momentum * momentum * lr_correct)
                p_data_fp32.add_(d_p, alpha=-(1 + momentum) * lr)

                buf.mul_(momentum * lr_correct).add_(d_p, alpha=-lr)

                &#47&#47 TODO: remove check once pyTorch avoids a copy for this case
                if <a id="change">p.data_ptr()</a> != <a id="change">p_data_fp32.data_ptr()</a>:
                    p.data.copy_(p_data_fp32)

            group[&quotlr_old&quot] = lr</code></pre><h3>After Change</h3><pre><code class='java'>
                    continue

                p_data_fp32 = p.data
                <a id="change">if p_data_fp32.dtype in {torch.float16, torch.bfloat16}</a>:
                    p_data_fp32<a id="change"> = </a><a id="change">p_data_fp32.float()</a>

                d_p = p.grad.data.float()
                param_state = self.state[p]
                if &quotmomentum_buffer&quot not in param_state:
                    param_state[&quotmomentum_buffer&quot] = torch.zeros_like(d_p)
                else:
                    param_state[&quotmomentum_buffer&quot] = param_state[&quotmomentum_buffer&quot].to(d_p)

                buf = param_state[&quotmomentum_buffer&quot]

                if weight_decay != 0:
                    p_data_fp32.mul_(1 - lr * weight_decay)
                p_data_fp32.add_(buf, alpha=momentum * momentum * lr_correct)
                p_data_fp32.add_(d_p, alpha=-(1 + momentum) * lr)

                buf.mul_(momentum * lr_correct).add_(d_p, alpha=-lr)

                if p.data.dtype in <a id="change">{</a>torch.float16, torch.bfloat16<a id="change"></a>}:
                    p.data.copy_(p_data_fp32)

            group[&quotlr_old&quot] = lr</code></pre>