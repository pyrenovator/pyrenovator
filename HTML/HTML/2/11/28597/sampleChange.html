<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.loss = nn.CrossEntropyLoss(ignore_index=self.padding_token_idx, reduction=&quotnone&quot)

    def generate(self, batch_data, eval_data):
        generate_corpus<a id="change"> = </a><a id="change">[]</a>
        source_text = batch_data[&quotsource_text&quot]
        <a id="change">for </a>text in source_text<a id="change">:
            </a>text<a id="change"> = </a><a id="change">&quot &quot.join(text</a><a id="change">)</a>
            encoding_dict<a id="change"> = </a><a id="change">self.tokenizer(</a>text<a id="change">, return_tensors=&quotpt&quot)</a>
            input_ids = encoding_dict[&quotinput_ids&quot].to(self.device)

            output_ids = self.model.generate(input_ids, max_length=self.max_target_length, early_stopping=True)

            generate_text = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)
            <a id="change">generate_corpus.append(</a>generate_text.lower().split()<a id="change">)</a>

        return generate_corpus

    def forward(self, corpus, epoch_idx=-1):</code></pre><h3>After Change</h3><pre><code class='java'>

    def generate(self, batch_data, eval_data):
        source_text = batch_data[&quotsource_text&quot]
        input_ids, attn_masks = <a id="change">self.tokenize_text(</a>source_text<a id="change">)</a>

        sample_outputs = self.model.generate(
            input_ids, attention_mask=attn_masks, num_beams=5, max_length=self.max_target_length, early_stopping=True
        )</code></pre>