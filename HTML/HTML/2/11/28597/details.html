<html><h3>Pattern ID :28597
</h3><img src='84461128.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.loss = nn.CrossEntropyLoss(ignore_index=self.padding_token_idx, reduction=&quotnone&quot)

    def generate(self, batch_data, eval_data):
        generate_corpus<a id="change"> = </a><a id="change">[]</a>
        source_text = batch_data[&quotsource_text&quot]
        <a id="change">for </a>text in source_text<a id="change">:
            </a>text<a id="change"> = </a><a id="change">&quot &quot.join(text</a><a id="change">)</a>
            encoding_dict<a id="change"> = </a><a id="change">self.tokenizer(</a>text<a id="change">, return_tensors=&quotpt&quot)</a>
            input_ids = encoding_dict[&quotinput_ids&quot].to(self.device)

            output_ids = self.model.generate(input_ids, max_length=self.max_target_length, early_stopping=True)

            generate_text = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)
            <a id="change">generate_corpus.append(</a>generate_text.lower().split()<a id="change">)</a>

        return generate_corpus

    def forward(self, corpus, epoch_idx=-1):</code></pre><h3>After Change</h3><pre><code class='java'>

    def generate(self, batch_data, eval_data):
        source_text = batch_data[&quotsource_text&quot]
        input_ids, attn_masks = <a id="change">self.tokenize_text(</a>source_text<a id="change">)</a>

        sample_outputs = self.model.generate(
            input_ids, attention_mask=attn_masks, num_beams=5, max_length=self.max_target_length, early_stopping=True
        )</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/47a1a3dc1eee71dd585124dbf1786e2508d34561#diff-256d1cc3e26719e1a4665d427f3287df187da7886f0bdca794d1e8832f37233cL38' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84461128</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 47a1a3dc1eee71dd585124dbf1786e2508d34561</div><div id='time'> Time: 2021-04-15</div><div id='author'> Author: 1020139164@qq.com</div><div id='file'> File Name: textbox/model/Seq2Seq/prophetnet.py</div><div id='m_class'> M Class Name: ProphetNet</div><div id='n_method'> N Class Name: ProphetNet</div><div id='m_method'> M Method Name: generate(3)</div><div id='n_method'> N Method Name: generate(3)</div><div id='m_parent_class'> M Parent Class: Seq2SeqGenerator</div><div id='n_parent_class'> N Parent Class: Seq2SeqGenerator</div><div id='m_file'> M File Name: textbox/model/Seq2Seq/prophetnet.py</div><div id='n_file'> N File Name: textbox/model/Seq2Seq/prophetnet.py</div><div id='m_start'> M Start Line: 38</div><div id='m_end'> M End Line: 50</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 45</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        input_ids = torch.cat(input_ids, dim=0).to(self.device)
        encoder_attn_masks = torch.cat(encoder_attn_masks, dim=0).to(self.device)

        target_ids<a id="change"> = </a><a id="change">[]</a>
        decoder_attn_masks = []
        <a id="change">for text</a> in target_text<a id="change">:
            </a>sentence<a id="change"> = </a><a id="change">&quot &quot.join(</a>text<a id="change">)</a>
            decoding_dict<a id="change"> = </a><a id="change">self.tokenizer(
                </a>sentence<a id="change">, max_length=self.max_target_length, padding="max_length", truncation=True, return_tensors="pt"
            )</a>
            <a id="change">target_ids.append(</a>decoding_dict[&quotinput_ids&quot]<a id="change">)</a>
            decoder_attn_masks.append(decoding_dict[&quotattention_mask&quot])
        target_ids = torch.cat(target_ids, dim=0).to(self.device)
        decoder_attn_masks = torch.cat(decoder_attn_masks, dim=0).to(self.device)
</code></pre><h3>After Change</h3><pre><code class='java'>
        source_text = corpus[&quotsource_text&quot]
        target_text = corpus[&quottarget_text&quot]

        input_ids, attn_masks = <a id="change">self.tokenize_text(</a>source_text<a id="change">)</a>
        target_ids, decoder_attn_masks = self.tokenize_text(target_text)

        decoder_input_ids = target_ids[:, :-1].contiguous()
        decoder_attn_masks = decoder_attn_masks[:, :-1].contiguous()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/47a1a3dc1eee71dd585124dbf1786e2508d34561#diff-5ba12174fffeb3fd53e2c105a099aab14ea3dd0e5a7b6af3d1c5ba1b2230f4b9L77' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84461144</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 47a1a3dc1eee71dd585124dbf1786e2508d34561</div><div id='time'> Time: 2021-04-15</div><div id='author'> Author: 1020139164@qq.com</div><div id='file'> File Name: textbox/model/Seq2Seq/bert2bert.py</div><div id='m_class'> M Class Name: BERT2BERT</div><div id='n_method'> N Class Name: BERT2BERT</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: Seq2SeqGenerator</div><div id='n_parent_class'> N Parent Class: Seq2SeqGenerator</div><div id='m_file'> M File Name: textbox/model/Seq2Seq/bert2bert.py</div><div id='n_file'> N File Name: textbox/model/Seq2Seq/bert2bert.py</div><div id='m_start'> M Start Line: 78</div><div id='m_end'> M End Line: 127</div><div id='n_start'> N Start Line: 86</div><div id='n_end'> N End Line: 109</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        attn_masks = torch.cat(attn_masks, dim=0).to(self.device)

        target_ids = []
        decoder_attn_masks<a id="change"> = </a><a id="change">[]</a>
        <a id="change">for text</a> in target_text<a id="change">:
            </a>sentence<a id="change"> = </a><a id="change">&quot &quot.join(</a>text<a id="change">)</a>
            decoding_dict<a id="change"> = </a><a id="change">self.tokenizer(
                </a>sentence<a id="change">, max_length=self.max_target_length, padding="max_length", truncation=True, return_tensors="pt"
            )</a>
            target_ids.append(decoding_dict[&quotinput_ids&quot])
            <a id="change">decoder_attn_masks.append(</a>decoding_dict[&quotattention_mask&quot]<a id="change">)</a>
        target_ids = torch.cat(target_ids, dim=0).to(self.device)
        decoder_attn_masks = torch.cat(decoder_attn_masks, dim=0).to(self.device)

        decoder_input_ids = target_ids[:, :-1].contiguous()</code></pre><h3>After Change</h3><pre><code class='java'>
        source_text = corpus[&quotsource_text&quot]
        target_text = corpus[&quottarget_text&quot]

        input_ids, attn_masks = <a id="change">self.tokenize_text(</a>source_text<a id="change">)</a>
        target_ids, decoder_attn_masks = self.tokenize_text(target_text)

        decoder_input_ids = target_ids[:, :-1].contiguous()
        decoder_attn_masks = decoder_attn_masks[:, :-1].contiguous()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/47a1a3dc1eee71dd585124dbf1786e2508d34561#diff-cb6154a8f614953fc099f2d791b0b41c862387b24dc8dc538bfe98ebbaa4a3b7L56' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84461117</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 47a1a3dc1eee71dd585124dbf1786e2508d34561</div><div id='time'> Time: 2021-04-15</div><div id='author'> Author: 1020139164@qq.com</div><div id='file'> File Name: textbox/model/Seq2Seq/bart.py</div><div id='m_class'> M Class Name: BART</div><div id='n_method'> N Class Name: BART</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: Seq2SeqGenerator</div><div id='n_parent_class'> N Parent Class: Seq2SeqGenerator</div><div id='m_file'> M File Name: textbox/model/Seq2Seq/bart.py</div><div id='n_file'> N File Name: textbox/model/Seq2Seq/bart.py</div><div id='m_start'> M Start Line: 57</div><div id='m_end'> M End Line: 101</div><div id='n_start'> N Start Line: 63</div><div id='n_end'> N End Line: 86</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.loss = nn.CrossEntropyLoss(ignore_index=self.padding_token_idx, reduction=&quotnone&quot)

    def generate(self, batch_data, eval_dataloader):
        generate_corpus<a id="change"> = </a><a id="change">[]</a>
        source_text = batch_data["source_text"]
        <a id="change">for text</a> in source_text<a id="change">:
            </a>sentence<a id="change"> = </a><a id="change">&quot &quot.join(</a>text<a id="change">)</a>
            encoding_dict<a id="change"> = </a><a id="change">self.tokenizer(</a>sentence<a id="change">, return_tensors="pt")</a>
            input_ids = encoding_dict[&quotinput_ids&quot].to(self.device)
            sample_outputs = self.decoder.generate(
                input_ids, num_beams=5, max_length=self.max_target_length, early_stopping=True
            )
            generated_text = self.tokenizer.decode(sample_outputs[0], skip_special_tokens=True)
            <a id="change">generate_corpus.append(</a>generated_text.lower().split()<a id="change">)</a>
        return generate_corpus

    def forward(self, corpus, epoch_idx=-1):
        source_text = corpus[&quotsource_text&quot]</code></pre><h3>After Change</h3><pre><code class='java'>

    def generate(self, batch_data, eval_data):
        source_text = batch_data[&quotsource_text&quot]
        input_ids, attn_masks = <a id="change">self.tokenize_text(</a>source_text<a id="change">)</a>

        sample_outputs = self.model.generate(
            input_ids, attention_mask=attn_masks, num_beams=5, max_length=self.max_target_length, early_stopping=True
        )</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/textbox/commit/47a1a3dc1eee71dd585124dbf1786e2508d34561#diff-cb6154a8f614953fc099f2d791b0b41c862387b24dc8dc538bfe98ebbaa4a3b7L42' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84461137</div><div id='project'> Project Name: rucaibox/textbox</div><div id='commit'> Commit Name: 47a1a3dc1eee71dd585124dbf1786e2508d34561</div><div id='time'> Time: 2021-04-15</div><div id='author'> Author: 1020139164@qq.com</div><div id='file'> File Name: textbox/model/Seq2Seq/bart.py</div><div id='m_class'> M Class Name: BART</div><div id='n_method'> N Class Name: BART</div><div id='m_method'> M Method Name: generate(3)</div><div id='n_method'> N Method Name: generate(3)</div><div id='m_parent_class'> M Parent Class: Seq2SeqGenerator</div><div id='n_parent_class'> N Parent Class: Seq2SeqGenerator</div><div id='m_file'> M File Name: textbox/model/Seq2Seq/bart.py</div><div id='n_file'> N File Name: textbox/model/Seq2Seq/bart.py</div><div id='m_start'> M Start Line: 43</div><div id='m_end'> M End Line: 54</div><div id='n_start'> N Start Line: 41</div><div id='n_end'> N End Line: 48</div><BR>