<html><h3>Pattern ID :18509
</h3><img src='60476440.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            if img is None:
                if len(frames) &gt; 0: img = frames[-1]
                else: img = np.zeros((112, 112, 3), dtype=np.uint8)
            if crop_augment: <a id="change">pass</a> &#47&#47 TODO: implement random crop
            if mirror_augment: img = cv2.flip(img, 1)
            &#47&#47 TODO: add temporal augmentation (repeat, deletion)
            frames.append(img)</code></pre><h3>After Change</h3><pre><code class='java'>
            if len(frames) &gt; 0: img = frames[-1]
            else: img = np.zeros((112, 112, 3), dtype=np.uint8)
        if crop_augment:
            <a id="change">img = </a>cv2.resize(img, (128, 128))
            if is_training:
                crop_x = random.randint(0, 16)
                crop_y = random.randint(0, 16)
                img = <a id="change">img[crop_y: crop_y + 112, crop_x: crop_x + 112]</a>
            else:
                img = <a id="change">img[8: 120, 8: 120]</a>
        if mirror_augment and is_training: img = cv2.flip(img, 1)
        &#47&#47 TODO: add temporal augmentation (repeat, deletion)
        frames.append(img)
    seq = np.stack(frames).transpose(3, 0, 1, 2).astype(np.float32) &#47&#47 THWC-&gt;CTHW</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/sailordiary/m3f.pytorch/commit/639f60090b44d3fdb3b40ae0df467ffed523da9e#diff-2730a8c5bd5549f02454fcdfd4a30faef0d608acd1627662eacd9e71c765c6feL47' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60476440</div><div id='project'> Project Name: sailordiary/m3f.pytorch</div><div id='commit'> Commit Name: 639f60090b44d3fdb3b40ae0df467ffed523da9e</div><div id='time'> Time: 2020-02-01</div><div id='author'> Author: me@sailorzhang.com</div><div id='file'> File Name: models/dataset.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: load_video(7)</div><div id='n_method'> N Method Name: load_video(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: models/dataset.py</div><div id='n_file'> N File Name: models/dataset.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 75</div><div id='n_start'> N Start Line: 47</div><div id='n_end'> N End Line: 70</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        This method must be overridden in child classes.
        
        <a id="change">pass</a>

    @abstractmethod
    def splat(
            self, x_proj, y_proj, dist, xyz, img_extrinsic, crop_top=0,</code></pre><h3>After Change</h3><pre><code class='java'>
    def project(self, vertices, frameId, inverse=True):

        &#47&#47 current camera pose
        <a id="change">curr_pose = </a>self.cam2world[frameId]
        T = <a id="change">curr_pose[:3, 3]</a>
        R = <a id="change">curr_pose[:3, :3]</a>

        &#47&#47 convert points from world coordinate to local coordinate
        points_local = self.world2cam(vertices, R, T, inverse)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/drprojects/deepviewagg/commit/57899df2507b6838676f63101013607f3f23c17d#diff-c3ecb4032ea531044fa80fa232d99862aa2a9b7ab2e1c9e2fb924142c6fbfbaaL274' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60476427</div><div id='project'> Project Name: drprojects/deepviewagg</div><div id='commit'> Commit Name: 57899df2507b6838676f63101013607f3f23c17d</div><div id='time'> Time: 2022-04-04</div><div id='author'> Author: wl5719@engie.com</div><div id='file'> File Name: torch_points3d/core/multimodal/camera.py</div><div id='m_class'> M Class Name: Camera</div><div id='n_method'> N Class Name: Camera</div><div id='m_method'> M Method Name: project(4)</div><div id='n_method'> N Method Name: project(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: ABC</div><div id='m_file'> M File Name: torch_points3d/core/multimodal/camera.py</div><div id='n_file'> N File Name: torch_points3d/core/multimodal/camera.py</div><div id='m_start'> M Start Line: 280</div><div id='m_end'> M End Line: 280</div><div id='n_start'> N Start Line: 56</div><div id='n_end'> N End Line: 66</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
&#47&#47 according to calculated weights (of proposal net) and indices of inverse sampling, calculate the bounds required for loss computation
&#47&#47 input weights (from proposal net) shape: (ray_num, num of proposal interval), inds shape (ray_num, fine_sample num + 1? TODO, 2)
def getBounds(weights:torch.Tensor, inds:torch.Tensor):
    <a id="change">pass</a>

class NeRF(nn.Module):
    @staticmethod
    def init_weight(m):</code></pre><h3>After Change</h3><pre><code class='java'>
&#47&#47 输入的inds应该是sample_pdf中的 below，每个点将有两个值。考虑到sample_pdf得到的点数量为(cone_num + 1)
def getBounds(weights:torch.Tensor, inds:torch.Tensor, sort_inds:torch.Tensor):
    ray_num, target_device = weights.shape[0], weights.device
    <a id="change">inds = </a>torch.gather(inds, -1, sort_inds)
    starts, ends = <a id="change">inds[:, :-1]</a>, <a id="change">inds[:, 1:]</a> + 1
    sat:torch.Tensor = torch.cat((torch.zeros(ray_num, 1, device = target_device), torch.cumsum(weights, dim = -1)), dim = -1)                  &#47&#47 输入的 weights是什么？proposal net 的weights
    return torch.gather(sat, -1, ends) - torch.gather(sat, -1, starts)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/enigmatisms/nerf/commit/c9ee74d3e40962cee741ca883d6a6a7b46ee6557#diff-897a048870ecd0bb721718d01966c8294ffbea27ff0403dfc03cf778a1f4b0abL16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60476456</div><div id='project'> Project Name: enigmatisms/nerf</div><div id='commit'> Commit Name: c9ee74d3e40962cee741ca883d6a6a7b46ee6557</div><div id='time'> Time: 2022-04-24</div><div id='author'> Author: 984041003@qq.com</div><div id='file'> File Name: py/addtional.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: getBounds(3)</div><div id='n_method'> N Method Name: getBounds(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: py/addtional.py</div><div id='n_file'> N File Name: py/addtional.py</div><div id='m_start'> M Start Line: 17</div><div id='m_end'> M End Line: 17</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 22</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            if img is None:
                if len(frames) &gt; 0: img = frames[-1]
                else: img = np.zeros((112, 112, 3), dtype=np.uint8)
            if crop_augment: <a id="change">pass</a> &#47&#47 TODO: implement random crop
            if mirror_augment: img = cv2.flip(img, 1)
            &#47&#47 TODO: add temporal augmentation (repeat, deletion)
            frames.append(img)</code></pre><h3>After Change</h3><pre><code class='java'>
            if len(frames) &gt; 0: img = frames[-1]
            else: img = np.zeros((112, 112, 3), dtype=np.uint8)
        if crop_augment:
            <a id="change">img = </a>cv2.resize(img, (128, 128))
            if is_training:
                crop_x = random.randint(0, 16)
                crop_y = random.randint(0, 16)
                img = <a id="change">img[crop_y: crop_y + 112, crop_x: crop_x + 112]</a>
            else:
                img = <a id="change">img[8: 120, 8: 120]</a>
        if mirror_augment and is_training: img = cv2.flip(img, 1)
        &#47&#47 TODO: add temporal augmentation (repeat, deletion)
        frames.append(img)
    seq = np.stack(frames).transpose(3, 0, 1, 2).astype(np.float32) &#47&#47 THWC-&gt;CTHW</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sailordiary/m3f.pytorch/commit/639f60090b44d3fdb3b40ae0df467ffed523da9e#diff-2730a8c5bd5549f02454fcdfd4a30faef0d608acd1627662eacd9e71c765c6feL46' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60476377</div><div id='project'> Project Name: sailordiary/m3f.pytorch</div><div id='commit'> Commit Name: 639f60090b44d3fdb3b40ae0df467ffed523da9e</div><div id='time'> Time: 2020-02-01</div><div id='author'> Author: me@sailorzhang.com</div><div id='file'> File Name: models/dataset.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: load_video(7)</div><div id='n_method'> N Method Name: load_video(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: models/dataset.py</div><div id='n_file'> N File Name: models/dataset.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 75</div><div id='n_start'> N Start Line: 47</div><div id='n_end'> N End Line: 70</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 TODO
    def test_conv_kb(self):
        Tests that ConvKB can be executed.
        <a id="change">pass</a>
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 Dummy forward passes
        &#47&#47 TODO: Use triple factory
        batch_size<a id="change"> = </a>16
        <a id="change">triples</a> = torch.zeros(batch_size, 3, dtype=torch.long)

        &#47&#47 TODO: Refactor common tests for all models, e.g. shape checking
        &#47&#47 Test forward_owa
        scores = model.forward_owa(triples)
        &#47&#47 Check shape
        assert scores.shape == (batch_size, 1)

        &#47&#47 Test forward_cwa
        scores = model.forward_cwa(<a id="change">triples[:, :2]</a>)
        &#47&#47 Check shape
        assert scores.shape == (batch_size, model.num_entities)

        &#47&#47 Test forward_inverse_cwa
        scores = model.forward_inverse_cwa(<a id="change">triples[:, 1:]</a>)
        &#47&#47 Check shape
        assert scores.shape == (batch_size, model.num_entities)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pykeen/pykeen/commit/69db6cbe5781b7cd552cd7102216e5e10a423089#diff-0adb667cd397bd56edce10eec11e1b10821740a10d72bd148b09645fc9108968L74' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 60476430</div><div id='project'> Project Name: pykeen/pykeen</div><div id='commit'> Commit Name: 69db6cbe5781b7cd552cd7102216e5e10a423089</div><div id='time'> Time: 2019-07-29</div><div id='author'> Author: berrendorf@dbs.ifi.lmu.de</div><div id='file'> File Name: tests/test_models.py</div><div id='m_class'> M Class Name: TestModels</div><div id='n_method'> N Class Name: TestModels</div><div id='m_method'> M Method Name: test_conv_kb(1)</div><div id='n_method'> N Method Name: test_conv_kb(1)</div><div id='m_parent_class'> M Parent Class: unittest.TestCase</div><div id='n_parent_class'> N Parent Class: unittest.TestCase</div><div id='m_file'> M File Name: tests/test_models.py</div><div id='n_file'> N File Name: tests/test_models.py</div><div id='m_start'> M Start Line: 76</div><div id='m_end'> M End Line: 76</div><div id='n_start'> N Start Line: 78</div><div id='n_end'> N End Line: 100</div><BR>