<html><h3>Pattern ID :39324
</h3><img src='111542876.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            wavs = torch.cat([wavs, wavs_noise], dim=0)
            wav_lens = torch.cat([wav_lens, wav_lens])

        <a id="change">if </a><a id="change">hasattr(self</a>, <a id="change">"augmentation"</a><a id="change">)</a>:
            wavs<a id="change"> = self</a><a id="change">.augmentation(</a>wavs, wav_lens<a id="change">)</a>
        feats = self.compute_features(wavs)
        feats = self.normalize(feats, wav_lens)
        out = self.enc(feats)
        out = self.output(out)</code></pre><h3>After Change</h3><pre><code class='java'>
                wavs_noise = self.hparams.env_corrupt(wavs, wav_lens)
                wavs = torch.cat([wavs, wavs_noise], dim=0)
                wav_lens = torch.cat([wav_lens, wav_lens])
            <a id="change">if hasattr(</a>self.hparams, <a id="change">"augmentation"</a><a id="change">)</a>:
                wavs<a id="change"> = </a><a id="change">self.hparams.augmentation(</a>wavs, wav_lens<a id="change">)</a>

        feats = self.hparams.compute_features(wavs)
        feats = self.hparams.normalize(feats, wav_lens)
        out = self.jit_modules.enc(feats)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/2632c7ca72ae1b904874576ec373ae89ff524731#diff-1e446a48e9ee0d179c098c95bbc48d47c154f3d625c3cc783146741cf860b00cL14' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111542876</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 2632c7ca72ae1b904874576ec373ae89ff524731</div><div id='time'> Time: 2020-09-22</div><div id='author'> Author: plantinga.peter@protonmail.com</div><div id='file'> File Name: recipes/LibriSpeech/ASR/CTC/experiment.py</div><div id='m_class'> M Class Name: ASR</div><div id='n_method'> N Class Name: ASR</div><div id='m_method'> M Method Name: compute_forward(3)</div><div id='n_method'> N Method Name: compute_forward(3)</div><div id='m_parent_class'> M Parent Class: sb.Brain</div><div id='n_parent_class'> N Parent Class: sb.Brain</div><div id='m_file'> M File Name: recipes/LibriSpeech/ASR/CTC/experiment.py</div><div id='n_file'> N File Name: recipes/LibriSpeech/ASR/CTC/experiment.py</div><div id='m_start'> M Start Line: 14</div><div id='m_end'> M End Line: 25</div><div id='n_start'> N Start Line: 14</div><div id='n_end'> N End Line: 26</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            wav_lens = torch.cat([wav_lens, wav_lens])

        &#47&#47 Adding time-domain SpecAugment if specified
        <a id="change">if </a><a id="change">hasattr(</a>self, <a id="change">"augmentation"</a><a id="change">)</a>:
            wavs<a id="change"> = </a><a id="change">self.augmentation(</a>wavs, wav_lens<a id="change">)</a>

        feats = self.compute_features(wavs)
        feats = self.normalize(feats, wav_lens)
        out = self.model(feats)</code></pre><h3>After Change</h3><pre><code class='java'>
                wavs_noise = self.hparams.env_corrupt(wavs, wav_lens)
                wavs = torch.cat([wavs, wavs_noise], dim=0)
                wav_lens = torch.cat([wav_lens, wav_lens])
            <a id="change">if hasattr(</a>self.hparams, <a id="change">"augmentation"</a><a id="change">)</a>:
                wavs<a id="change"> = </a><a id="change">self.hparams.augmentation(</a>wavs, wav_lens<a id="change">)</a>

        feats = self.hparams.compute_features(wavs)
        feats = self.hparams.normalize(feats, wav_lens)
        out = self.jit_modules.model(feats)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/2632c7ca72ae1b904874576ec373ae89ff524731#diff-a1d1b869291fc80e4b9cf01b5d416c0cf4e608663111025c45c1b3b4ae5ed0dfL24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111542877</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 2632c7ca72ae1b904874576ec373ae89ff524731</div><div id='time'> Time: 2020-09-22</div><div id='author'> Author: plantinga.peter@protonmail.com</div><div id='file'> File Name: recipes/TIMIT/ASR/CTC/experiment.py</div><div id='m_class'> M Class Name: ASR_Brain</div><div id='n_method'> N Class Name: ASR_Brain</div><div id='m_method'> M Method Name: compute_forward(3)</div><div id='n_method'> N Method Name: compute_forward(3)</div><div id='m_parent_class'> M Parent Class: sb.Brain</div><div id='n_parent_class'> N Parent Class: sb.Brain</div><div id='m_file'> M File Name: recipes/TIMIT/ASR/CTC/experiment.py</div><div id='n_file'> N File Name: recipes/TIMIT/ASR/CTC/experiment.py</div><div id='m_start'> M Start Line: 29</div><div id='m_end'> M End Line: 42</div><div id='n_start'> N Start Line: 29</div><div id='n_end'> N End Line: 41</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                wav_lens = torch.cat([wav_lens, wav_lens])
                words = torch.cat([words, words], dim=0)
                word_lens = torch.cat([word_lens, word_lens])
            <a id="change">if </a><a id="change">hasattr(</a>self, <a id="change">"augmentation"</a><a id="change">)</a>:
                wavs<a id="change"> = </a><a id="change">self.augmentation(</a>wavs, wav_lens<a id="change">)</a>

        &#47&#47 Prepare labels
        bpe, _ = self.bpe_tokenizer(
            words, word_lens, self.index2lab, task="encode"</code></pre><h3>After Change</h3><pre><code class='java'>
                wav_lens = torch.cat([wav_lens, wav_lens])
                words = torch.cat([words, words], dim=0)
                word_lens = torch.cat([word_lens, word_lens])
            <a id="change">if hasattr(</a>self.hparams, <a id="change">"augmentation"</a><a id="change">)</a>:
                wavs<a id="change"> = </a><a id="change">self.hparams.augmentation(</a>wavs, wav_lens<a id="change">)</a>

        &#47&#47 Prepare labels
        bpe, _ = self.hparams.bpe_tokenizer(
            words, word_lens, self.hparams.index2lab, task="encode"</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/2632c7ca72ae1b904874576ec373ae89ff524731#diff-177d1fc874eac756c81d03e04e7ee9b9199d7b1f4d8116af49ed88466f19c3bfL12' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111542875</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 2632c7ca72ae1b904874576ec373ae89ff524731</div><div id='time'> Time: 2020-09-22</div><div id='author'> Author: plantinga.peter@protonmail.com</div><div id='file'> File Name: recipes/LibriSpeech/ASR/seq2seq/experiment.py</div><div id='m_class'> M Class Name: ASR</div><div id='n_method'> N Class Name: ASR</div><div id='m_method'> M Method Name: compute_forward(4)</div><div id='n_method'> N Method Name: compute_forward(4)</div><div id='m_parent_class'> M Parent Class: sb.Brain</div><div id='n_parent_class'> N Parent Class: sb.Brain</div><div id='m_file'> M File Name: recipes/LibriSpeech/ASR/seq2seq/experiment.py</div><div id='n_file'> N File Name: recipes/LibriSpeech/ASR/seq2seq/experiment.py</div><div id='m_start'> M Start Line: 18</div><div id='m_end'> M End Line: 62</div><div id='n_start'> N Start Line: 18</div><div id='n_end'> N End Line: 63</div><BR>