<html><h3>Pattern ID :17910
</h3><img src='58804609.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    n_chan_out = min(n_chan_ref, n_chan_est)

    if n_chan_ref &gt; n_chan_est:
        SDR<a id="change"> = </a>SDR.transpose(-2, -1)
        SIR = SIR.transpose(-2, -1)
        SAR<a id="change"> = </a><a id="change">SAR.transpose(-2</a>, <a id="change">-1</a><a id="change">)</a>

    SIR_npy = SIR.cpu().detach().numpy()

    SDR_out = SDR.new_zeros(b_shape + (n_chan_out,))
    SIR_out = SIR.new_zeros(b_shape + (n_chan_out,))
    SAR_out = SAR.new_zeros(b_shape + (n_chan_out,))

    p_opts = np.zeros(b_shape + (n_chan_out,), dtype=np.int64)
    for m in np.ndindex(b_shape):
        dum, p_opt = _linear_sum_assignment_with_inf(-SIR_npy[m])
        SDR_out[m]<a id="change"> = </a>SDR[m + (dum, p_opt)]
        SIR_out[m] = SIR[m + (dum, p_opt)]
        SAR_out[m] = SAR[m + (dum, p_opt)]
        p_opts[m] = p_opt

    p_opts<a id="change"> = </a>pt.from_numpy(p_opts).to(SDR_out.device)
    <a id="change">return </a>SDR_out<a id="change">, SIR_out, SAR_out, p_opts</a>


def _linear_sum_assignment_with_inf(
    cost_matrix: np.ndarray,</code></pre><h3>After Change</h3><pre><code class='java'>
        p_opts[m] = p_opt

    if return_perm:
        <a id="change">return </a>(loss_out<a id="change"></a>,) + tuple(args_out) + (p_opt,)
    else:
        return (loss_out,) + args_out
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/fakufaku/torchiva/commit/d2b2bceef6944715a6274920e6ec7b0374367ccd#diff-197c29dbd626b108268ccbbec7fc6fb34484f6a7171f68f333aea506de020431L150' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58804609</div><div id='project'> Project Name: fakufaku/torchiva</div><div id='commit'> Commit Name: d2b2bceef6944715a6274920e6ec7b0374367ccd</div><div id='time'> Time: 2022-01-31</div><div id='author'> Author: robin.scheibler@linecorp.com</div><div id='file'> File Name: torchiva/metrics.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _solve_permutation(1)</div><div id='n_method'> N Method Name: _solve_permutation(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchiva/metrics.py</div><div id='n_file'> N File Name: torchiva/metrics.py</div><div id='m_start'> M Start Line: 204</div><div id='m_end'> M End Line: 234</div><div id='n_start'> N Start Line: 150</div><div id='n_end'> N End Line: 182</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        w = w_1 / w_2

        out<a id="change"> = </a>torch.matmul(<a id="change">w.transpose(1</a>, <a id="change">2</a><a id="change">)</a>, encoder_outputs)

        <a id="change">return </a>out<a id="change">, w</a>


class DurationPredictor(nn.Module):
     Duration Parameter Predictor </code></pre><h3>After Change</h3><pre><code class='java'>
        c = c.unsqueeze(2)
        s = self.range_param_predictor(encoder_outputs, duration, mask).unsqueeze(-1)

        g<a id="change"> = </a>torch.distributions.normal.Normal(loc=c, scale=s)

        w = self.get_alignment_energies(g, t)  &#47&#47 [B, L, T]

        if mask is not None:
            w<a id="change"> = </a>w.masked_fill(mask.unsqueeze(-1), 0.0)

        attn = w / (torch.sum(w, dim=1).unsqueeze(1) + 1e-8)  &#47&#47 [B, L, T]
        out<a id="change"> = </a>torch.bmm(attn.transpose(1, 2), encoder_outputs)

        <a id="change">return </a>out<a id="change">, attn</a>


class DurationPredictor(nn.Module):
     Duration Parameter Predictor </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/keonlee9420/wavegrad2/commit/523ec241c64ab635218f32d071fd85fbc469e178#diff-44dac3f4f06b62a8129520d279f589b0b2144de4f2a7720992f263c496651b43L105' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58804752</div><div id='project'> Project Name: keonlee9420/wavegrad2</div><div id='commit'> Commit Name: 523ec241c64ab635218f32d071fd85fbc469e178</div><div id='time'> Time: 2021-07-13</div><div id='author'> Author: keonlee9420@gmail.com</div><div id='file'> File Name: model/modules.py</div><div id='m_class'> M Class Name: GaussianUpsampling</div><div id='n_method'> N Class Name: GaussianUpsampling</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/modules.py</div><div id='n_file'> N File Name: model/modules.py</div><div id='m_start'> M Start Line: 115</div><div id='m_end'> M End Line: 135</div><div id='n_start'> N Start Line: 120</div><div id='n_end'> N End Line: 134</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.ap = None

    def __getitem__(self, index):
        transcript<a id="change"> = </a>self.path_to_transcript_dict[self.key_list[index]]
        path = self.key_list[index]
        wave, sr = sf.read(os.path.join("Corpora/CSS10/", path))
        if self.ap is None:
            self.ap = AudioPreprocessor(input_sr=sr, output_sr=16000, melspec_buckets=80, hop_length=256, n_fft=1024)
        text<a id="change"> = </a>self.tf.string_to_tensor(transcript).long()
        text_len<a id="change"> = </a>torch.LongTensor([len(text)])
        speech<a id="change"> = </a><a id="change">self.ap.audio_to_mel_spec_tensor(wave).transpose(0</a>, <a id="change">1</a><a id="change">)</a>
        speech_len = torch.LongTensor([len(speech)])
        if self.spemb:
            print("not implemented yet")
            raise NotImplementedError
        <a id="change">return </a>text<a id="change">, text_len, speech, speech_len</a>

    def __len__(self):
        return len(self.key_list)
</code></pre><h3>After Change</h3><pre><code class='java'>
                raise NotImplementedError

    def __getitem__(self, index):
        <a id="change">return </a>self.cached_text[index]<a id="change">, \
               self.cached_text_lens[index], \
               self.cached_speech[index], \
               self.cached_speech_lens[index]</a>

    def __len__(self):
        return len(self.cached_text_lens)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/51675d8bba9cee446d9fe520fde5253af397c61d#diff-0965ad6e3a8f04afe3a358a7558e203eaa1f244ad6e8e6fbfe73f8a2052b8cb1L31' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 58804645</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 51675d8bba9cee446d9fe520fde5253af397c61d</div><div id='time'> Time: 2021-02-23</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_class'> M Class Name: TransformerTTSDataset</div><div id='n_method'> N Class Name: TransformerTTSDataset</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='n_file'> N File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_start'> M Start Line: 32</div><div id='m_end'> M End Line: 44</div><div id='n_start'> N Start Line: 54</div><div id='n_end'> N End Line: 57</div><BR>