<html><h3>Pattern ID :13184
</h3><img src='44575144.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 compute gradient and Hessian costs
    gc = torch.einsum(&quotbcnp,bcnp-&gt;bcp&quot, j, f[..., None])
    Hc<a id="change"> = </a>torch.einsum(&quotbcnp,bcni-&gt;bcpi&quot, j, j)

    &#47&#47 reduce multiple costs dimension through weighting
    g<a id="change"> = </a>torch.einsum(&quotbcp,c-&gt;bp&quot, gc, wvec)
    H<a id="change"> = </a><a id="change">torch.einsum(&quotbcpi,c-&gt;bpi&quot</a>, Hc, wvec<a id="change">)</a>

    p_list = []
    while len(p_list) &lt; max_iter:
        h<a id="change"> = </a>-<a id="change">l*</a>torch.linalg.lstsq(H, g, rcond=None, driver=None)[0]
        p = p + h
        p_list.append(p.detach())
        f_prev = f.clone()
        f<a id="change"> = </a>fun(p)
        j<a id="change"> = </a>jac_fun(p)
        gc = torch.einsum(&quotbcnp,bcnp-&gt;bcp&quot, j, f[..., None])
        Hc = torch.einsum(&quotbcnp,bcni-&gt;bcpi&quot, j, j)
        g<a id="change"> = </a>torch.einsum(&quotbcp,c-&gt;bp&quot, gc, wvec)
        H = torch.einsum(&quotbcpi,c-&gt;bpi&quot, Hc, wvec)

        &#47&#47 stop conditions</code></pre><h3>After Change</h3><pre><code class='java'>
    p_list = []
    while len(p_list) &lt; max_iter:
        f_prev = f.clone()
        p<a id="change">, f, g, h</a> = gauss_newton_step(p, fun, jac_fun, wvec, l)
        p_list.append(p.detach())

        &#47&#47 stop conditions</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/hahnec/torchimize/commit/54df16c1b0213a9a4c30d489f484e630cddf1cd1#diff-c05188355c6af07b8a965d6cc795d0ed247203d3ff12709891e7696864af4005L46' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 44575144</div><div id='project'> Project Name: hahnec/torchimize</div><div id='commit'> Commit Name: 54df16c1b0213a9a4c30d489f484e630cddf1cd1</div><div id='time'> Time: 2022-05-17</div><div id='author'> Author: christopher.hahne@unibe.ch</div><div id='file'> File Name: torchimize/functions/gna_fun_parallel.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: lsq_gna_parallel(10)</div><div id='n_method'> N Method Name: lsq_gna_parallel(10)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchimize/functions/gna_fun_parallel.py</div><div id='n_file'> N File Name: torchimize/functions/gna_fun_parallel.py</div><div id='m_start'> M Start Line: 46</div><div id='m_end'> M End Line: 75</div><div id='n_start'> N Start Line: 70</div><div id='n_end'> N End Line: 77</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 I think if we include z_i here, we should use a mask (as in SymmetricContrastiveLoss) to subtract the column
        &#47&#47 on which the similarity is calculated with an image itself?
        mask<a id="change"> = </a>torch.eye(num_contexts).to(self.device)

        &#47&#47 Simplify the code
        z_all<a id="change"> = </a>torch.cat([z_i, z_j], 0)
        if num_targets &gt; num_contexts:
            z_j = z_j[:num_contexts]

        &#47&#47 zi and zj are both matrices of dim (n x c), since they are z vectors of dim c for every element in the batch
        &#47&#47 This einsum is constructing a vector of size n, where the nth element is a sum over C of the NCth elements
        &#47&#47 That is to say, the nth element is a dot product between the Nth C-dim vector of each matrix
        sim_ij = torch.einsum(&quotnc,nc-&gt;n&quot, [z_i, z_j]).unsqueeze(-1)  &#47&#47 Nx1

        &#47&#47 Calculate similarity of current batch&quots images and other images.
        sim_ik<a id="change"> = </a><a id="change">torch.einsum(&quotnc,ck-&gt;nk&quot</a>, [z_i, z_all.T]<a id="change">)</a>
        sim_ik<a id="change"> = </a>sim_ik<a id="change"> - </a>mask  &#47&#47 TODO: Check if the diagonal line are all 1s.

        logits<a id="change"> = </a>torch.cat((sim_ij, sim_ik), 1)
        logits<a id="change"> /= </a>self.temp

        labels<a id="change"> = </a>torch.zeros(logits.shape[0], dtype=torch.long, device=self.device)
        return self.criterion(logits, labels)

</code></pre><h3>After Change</h3><pre><code class='java'>
        z_i = F.normalize(z_i, dim=1)
        z_j = F.normalize(z_j, dim=1)

        logits<a id="change">, labels</a> = self.calculate_logits_and_labels(z_i, z_j)
        return self.criterion(logits, labels)

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/0b5a5b2dd10965fd9b63fb82899690b1461adab4#diff-094460a9fbb96d5a5e5e0ff351a3d7aaa4cc4fae9d4c22cbb890b6d29832d85eL34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 44575017</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: 0b5a5b2dd10965fd9b63fb82899690b1461adab4</div><div id='time'> Time: 2020-08-05</div><div id='author'> Author: RPC2@users.noreply.github.com</div><div id='file'> File Name: algos/losses.py</div><div id='m_class'> M Class Name: AsymmetricContrastiveLoss</div><div id='n_method'> N Class Name: AsymmetricContrastiveLoss</div><div id='m_method'> M Method Name: __call__(4)</div><div id='n_method'> N Method Name: __call__(4)</div><div id='m_parent_class'> M Parent Class: RepresentationLoss</div><div id='n_parent_class'> N Parent Class: RepresentationLoss</div><div id='m_file'> M File Name: algos/losses.py</div><div id='n_file'> N File Name: algos/losses.py</div><div id='m_start'> M Start Line: 43</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 45</div><div id='n_end'> N End Line: 48</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 I think if we include z_i here, we should use a mask (as in SymmetricContrastiveLoss) to subtract the column
        &#47&#47 on which the similarity is calculated with an image itself?
        mask<a id="change"> = </a>torch.eye(num_contexts).to(self.device)

        &#47&#47 Simplify the code
        z_all<a id="change"> = </a>torch.cat([z_i, z_j], 0)
        if num_targets &gt; num_contexts:
            z_j = z_j[:num_contexts]

        &#47&#47 zi and zj are both matrices of dim (n x c), since they are z vectors of dim c for every element in the batch
        &#47&#47 This einsum is constructing a vector of size n, where the nth element is a sum over C of the NCth elements
        &#47&#47 That is to say, the nth element is a dot product between the Nth C-dim vector of each matrix
        sim_ij = torch.einsum(&quotnc,nc-&gt;n&quot, [z_i, z_j]).unsqueeze(-1)  &#47&#47 Nx1

        &#47&#47 Calculate similarity of current batch&quots images and other images.
        sim_ik<a id="change"> = </a><a id="change">torch.einsum(&quotnc,ck-&gt;nk&quot</a>, [z_i, z_all.T]<a id="change">)</a>
        sim_ik<a id="change"> = </a>sim_ik<a id="change"> - </a>mask  &#47&#47 TODO: Check if the diagonal line are all 1s.

        logits<a id="change"> = </a>torch.cat((sim_ij, sim_ik), 1)
        logits<a id="change"> /= </a>self.temp

        labels<a id="change"> = </a>torch.zeros(logits.shape[0], dtype=torch.long, device=self.device)
        return self.criterion(logits, labels)

</code></pre><h3>After Change</h3><pre><code class='java'>
        z_i = F.normalize(z_i, dim=1)
        z_j = F.normalize(z_j, dim=1)

        logits<a id="change">, labels</a> = self.calculate_logits_and_labels(z_i, z_j)
        return self.criterion(logits, labels)

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/981a74b28e3324eda2b2e15aad0a115c6ec0e8da#diff-094460a9fbb96d5a5e5e0ff351a3d7aaa4cc4fae9d4c22cbb890b6d29832d85eL34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 44575138</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: 981a74b28e3324eda2b2e15aad0a115c6ec0e8da</div><div id='time'> Time: 2020-08-05</div><div id='author'> Author: RPC2@users.noreply.github.com</div><div id='file'> File Name: algos/losses.py</div><div id='m_class'> M Class Name: AsymmetricContrastiveLoss</div><div id='n_method'> N Class Name: AsymmetricContrastiveLoss</div><div id='m_method'> M Method Name: __call__(4)</div><div id='n_method'> N Method Name: __call__(4)</div><div id='m_parent_class'> M Parent Class: RepresentationLoss</div><div id='n_parent_class'> N Parent Class: RepresentationLoss</div><div id='m_file'> M File Name: algos/losses.py</div><div id='n_file'> N File Name: algos/losses.py</div><div id='m_start'> M Start Line: 43</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 45</div><div id='n_end'> N End Line: 48</div><BR>