<html><h3>Pattern ID :38715
</h3><img src='110670850.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Assumes a square image

        dim_counts = Counter(self.observation_shape)
        spatial_dimension<a id="change"> = </a>dim_counts.most_common()[0][0]
        assert dim_counts[spatial_dimension] == 2, "This code assumes a square image, implying at least one dimension size repeated"
        channel_dimension<a id="change"> = </a>dim_counts.most_common()[-1][0]
        assert dim_counts[channel_dimension] == 1, "This code assumes two spatial dimensions and one channels dimension"
        spatial_indicies = <a id="change">np.arange(</a>len(self.observation_shape)<a id="change">)</a>[np.array(self.observation_shape) == spatial_dimension]
        channel_index = <a id="change">np.arange(</a>len(self.observation_shape)<a id="change">)</a>[np.array(self.observation_shape) == channel_dimension].item()

        new_shape = (channel_dimension, spatial_dimension, spatial_dimension)
        required_permutation = (0, channel_index+1, spatial_indicies[0]+1, spatial_indicies[1]+1) &#47&#47 +1 to account for batch
        self.observation_shape = new_shape
        self.observation_space = Box(shape=self.observation_shape, low=0, high=255, dtype=np.uint8)
        self.permutation_tuple<a id="change"> = </a>required_permutation

    def _tensorize(self, arr):
        </code></pre><h3>After Change</h3><pre><code class='java'>
    def _make_channels_first(self):
        &#47&#47 Assumes an image in form (C, H, W) or (H, W, C) with H = W != C
        x, y, z = self.observation_shape
        <a id="change">if x != y</a><a id="change"> and y == z</a>:
            self.permutation_tuple<a id="change"> = </a>None
        else:
            assert x == y and x != z, "Can only handle square images in format (C, H, W) or (H, W, C)"
            self.observation_shape = (z, x, y)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/d1ad577e009bce6e87e589755c40d71337a0e2cd#diff-11bd63b8ace5530605783f45e027231fff8e98dafa1dbb5675fe0c042e1f07dbL94' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110670850</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: d1ad577e009bce6e87e589755c40d71337a0e2cd</div><div id='time'> Time: 2020-07-27</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: _make_channels_first(1)</div><div id='n_method'> N Method Name: _make_channels_first(1)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: algos/representation_learner.py</div><div id='n_file'> N File Name: algos/representation_learner.py</div><div id='m_start'> M Start Line: 95</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 103</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        dim_counts = Counter(self.observation_shape)
        spatial_dimension = dim_counts.most_common()[0][0]
        assert dim_counts[spatial_dimension] == 2, "This code assumes a square image, implying at least one dimension size repeated"
        channel_dimension<a id="change"> = </a>dim_counts.most_common()[-1][0]
        assert dim_counts[channel_dimension] == 1, "This code assumes two spatial dimensions and one channels dimension"
        spatial_indicies = <a id="change">np.arange(</a>len(self.observation_shape)<a id="change">)</a>[np.array(self.observation_shape) == spatial_dimension]
        channel_index = <a id="change">np.arange(</a>len(self.observation_shape)<a id="change">)</a>[np.array(self.observation_shape) == channel_dimension].item()

        new_shape = (channel_dimension, spatial_dimension, spatial_dimension)
        required_permutation = (0, channel_index+1, spatial_indicies[0]+1, spatial_indicies[1]+1) &#47&#47 +1 to account for batch
        self.observation_shape<a id="change"> = </a>new_shape
        self.observation_space = Box(shape=self.observation_shape, low=0, high=255, dtype=np.uint8)
        self.permutation_tuple<a id="change"> = </a>required_permutation

    def _tensorize(self, arr):
        </code></pre><h3>After Change</h3><pre><code class='java'>
    def _make_channels_first(self):
        &#47&#47 Assumes an image in form (C, H, W) or (H, W, C) with H = W != C
        x, y, z = self.observation_shape
        <a id="change">if x != y</a><a id="change"> and y == z</a>:
            self.permutation_tuple<a id="change"> = </a>None
        else:
            assert x == y and x != z, "Can only handle square images in format (C, H, W) or (H, W, C)"
            self.observation_shape = (z, x, y)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/f5cbb3623fa01457a4ce34acd05c35f1535ece6c#diff-11bd63b8ace5530605783f45e027231fff8e98dafa1dbb5675fe0c042e1f07dbL92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110670769</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: f5cbb3623fa01457a4ce34acd05c35f1535ece6c</div><div id='time'> Time: 2020-07-27</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: _make_channels_first(1)</div><div id='n_method'> N Method Name: _make_channels_first(1)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: algos/representation_learner.py</div><div id='n_file'> N File Name: algos/representation_learner.py</div><div id='m_start'> M Start Line: 95</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 103</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        dim_counts = Counter(self.observation_shape)
        spatial_dimension = dim_counts.most_common()[0][0]
        assert dim_counts[spatial_dimension] == 2, "This code assumes a square image, implying at least one dimension size repeated"
        channel_dimension<a id="change"> = </a>dim_counts.most_common()[-1][0]
        assert dim_counts[channel_dimension] == 1, "This code assumes two spatial dimensions and one channels dimension"
        spatial_indicies = <a id="change">np.arange(</a>len(self.observation_shape)<a id="change">)</a>[np.array(self.observation_shape) == spatial_dimension]
        channel_index = <a id="change">np.arange(</a>len(self.observation_shape)<a id="change">)</a>[np.array(self.observation_shape) == channel_dimension].item()

        new_shape = (channel_dimension, spatial_dimension, spatial_dimension)
        required_permutation = (0, channel_index+1, spatial_indicies[0]+1, spatial_indicies[1]+1) &#47&#47 +1 to account for batch
        self.observation_shape<a id="change"> = </a>new_shape
        self.observation_space = Box(shape=self.observation_shape, low=0, high=255, dtype=np.uint8)
        self.permutation_tuple<a id="change"> = </a>required_permutation

    def _tensorize(self, arr):
        </code></pre><h3>After Change</h3><pre><code class='java'>
    def _make_channels_first(self):
        &#47&#47 Assumes an image in form (C, H, W) or (H, W, C) with H = W != C
        x, y, z = self.observation_shape
        <a id="change">if x != y</a><a id="change"> and y == z</a>:
            self.permutation_tuple<a id="change"> = </a>None
        else:
            assert x == y and x != z, "Can only handle square images in format (C, H, W) or (H, W, C)"
            self.observation_shape = (z, x, y)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/d1ad577e009bce6e87e589755c40d71337a0e2cd#diff-11bd63b8ace5530605783f45e027231fff8e98dafa1dbb5675fe0c042e1f07dbL92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110670851</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: d1ad577e009bce6e87e589755c40d71337a0e2cd</div><div id='time'> Time: 2020-07-27</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: _make_channels_first(1)</div><div id='n_method'> N Method Name: _make_channels_first(1)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: algos/representation_learner.py</div><div id='n_file'> N File Name: algos/representation_learner.py</div><div id='m_start'> M Start Line: 95</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 103</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        neg_idxs = torch.randint(low=0, high=high, size=(bsz, self.n_negatives * tsz))

        if self.sample_distance is not None and self.sample_distance &lt; tsz:
            neg_idxs<a id="change"> += </a>torch.cat(
                [<a id="change">torch.arange(start=1, end=tsz - self.sample_distance, device=neg_idxs.device, dtype=neg_idxs.dtype)</a>,
                 <a id="change">torch.arange(start=tsz - self.sample_distance, end=tsz - self.sample_distance * 2 - 1, step=-1,
                              device=neg_idxs.device, dtype=neg_idxs.dtype)</a>])

        if not self.cross_sample_negatives:
            for i in range(1, bsz):</code></pre><h3>After Change</h3><pre><code class='java'>
                    .flatten()
                )

                neg_idxs<a id="change"> = </a>torch.randint(
                    low=0, high=high - 1, size=(bsz, self.n_negatives * tsz)
                )
                neg_idxs[neg_idxs &gt;= tszs] += 1

            if self.cross_sample_negatives &gt; 0:
                tszs = (
                    buffered_arange(tsz)
                    .unsqueeze(-1)
                    .expand(-1, self.cross_sample_negatives)
                    .flatten()
                )

                cross_neg_idxs = torch.randint(
                    low=0,
                    high=cross_high - 1,
                    size=(bsz, self.cross_sample_negatives * tsz),
                )
                cross_neg_idxs[cross_neg_idxs &gt;= tszs] += 1

        if self.n_negatives &gt; 0:
            for i in range(1, bsz):
                neg_idxs[i] += i * high
        else:
            neg_idxs<a id="change"> = </a>cross_neg_idxs

        <a id="change">if self.cross_sample_negatives &gt; 0</a><a id="change"> and self.n_negatives &gt; 0</a>:
            neg_idxs<a id="change"> = </a>torch.cat([neg_idxs, cross_neg_idxs], dim=1)

        negs = y[..., neg_idxs.view(-1)]
        negs = negs.view(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mohammadkhalifa/fairseq-tagging/commit/3335de5f441ee1b3824e16dcd98db620e40beaba#diff-9b4dd2bdb515c86c631253c805af3041e9bbf4ce7f68af6a1900ef5b4ffa5c5aL379' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 110670854</div><div id='project'> Project Name: mohammadkhalifa/fairseq-tagging</div><div id='commit'> Commit Name: 3335de5f441ee1b3824e16dcd98db620e40beaba</div><div id='time'> Time: 2020-02-29</div><div id='author'> Author: alexei.b@gmail.com</div><div id='file'> File Name: fairseq/models/wav2vec.py</div><div id='m_class'> M Class Name: Wav2VecPredictionsModel</div><div id='n_method'> N Class Name: Wav2VecPredictionsModel</div><div id='m_method'> M Method Name: sample_negatives(2)</div><div id='n_method'> N Method Name: sample_negatives(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: fairseq/models/wav2vec.py</div><div id='n_file'> N File Name: fairseq/models/wav2vec.py</div><div id='m_start'> M Start Line: 385</div><div id='m_end'> M End Line: 404</div><div id='n_start'> N Start Line: 583</div><div id='n_end'> N End Line: 629</div><BR>