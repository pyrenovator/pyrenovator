<html><h3>Pattern ID :16384
</h3><img src='55194362.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.use_guided_attn_loss = use_guided_attn_loss
        self.loss_type = loss_type
        if self.spk_embed_dim is not None:
            self.spk_embed_integration_type<a id="change"> = spk_embed_integration_type</a>

        &#47&#47 define activation function for the final output
        if output_activation is None:
            self.output_activation_fn = None
        elif hasattr(F, output_activation):
            self.output_activation_fn = getattr(F, output_activation)
        else:
            raise ValueError(f"there is no such activation function. " f"({output_activation})")

        self.language_embedding = None
        if language_embedding_amount is not None:
            self.language_embedding = torch.nn.Embedding(language_embedding_amount, eunits)

        &#47&#47 set padding idx
        self.padding_idx = torch.zeros(idim)

        &#47&#47 define network modules
        self.enc = Encoder(idim=idim,
                           input_layer=input_layer_type,
                           embed_dim=embed_dim,
                           elayers=elayers,
                           eunits=eunits,
                           econv_layers=econv_layers,
                           econv_chans=econv_chans,
                           econv_filts=econv_filts,
                           use_batch_norm=use_batch_norm,
                           use_residual=use_residual,
                           dropout_rate=dropout_rate)

        if spk_embed_dim is None:
            dec_idim = eunits
        elif <a id="change">spk_embed_integration_type == "concat"</a>:
            dec_idim = eunits + spk_embed_dim
        elif spk_embed_integration_type == "add":
            dec_idim = eunits
            self.projection = torch.nn.Linear(self.spk_embed_dim, eunits)
        else:
            <a id="change">raise ValueError(f"{spk_embed_integration_type} is not supported."</a><a id="change">)</a>

        if atype == "location":
            att = AttLoc(dec_idim, dunits, adim, aconv_chans, aconv_filts)
        elif atype == "forward":</code></pre><h3>After Change</h3><pre><code class='java'>
                           dropout_rate=dropout_rate)

        if spk_embed_dim is not None:
            self.projection = <a id="change">torch.nn.Sequential(</a>torch.nn.Linear(eunits + spk_embed_dim, eunits),
                                                  <a id="change">torch.nn.Tanh()</a>,
                                                  <a id="change">torch.nn.Linear(</a>eunits, eunits<a id="change">)</a><a id="change">)</a>
        dec_idim = eunits

        if atype == "location":
            att = AttLoc(dec_idim, dunits, adim, aconv_chans, aconv_filts)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/1adfce3a2d99089f295ed62e2becd4a51e6b441a#diff-f8d05eb08ac38b212e3d3c6104a5e5618a8484d7eb2df04df282d6599e5473daL59' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55194362</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 1adfce3a2d99089f295ed62e2becd4a51e6b441a</div><div id='time'> Time: 2021-09-23</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/Tacotron2.py</div><div id='m_class'> M Class Name: Tacotron2</div><div id='n_method'> N Class Name: Tacotron2</div><div id='m_method'> M Method Name: __init__(44)</div><div id='n_method'> N Method Name: __init__(45)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/Tacotron2.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/Tacotron2.py</div><div id='m_start'> M Start Line: 59</div><div id='m_end'> M End Line: 130</div><div id='n_start'> N Start Line: 120</div><div id='n_end'> N End Line: 123</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.use_guided_attn_loss = use_guided_attn_loss
        self.loss_type = loss_type
        if self.spk_embed_dim is not None:
            self.spk_embed_integration_type<a id="change"> = </a>spk_embed_integration_type

        &#47&#47 define activation function for the final output
        if output_activation is None:
            self.output_activation_fn = None
        elif hasattr(F, output_activation):
            self.output_activation_fn = getattr(F, output_activation)
        else:
            raise ValueError(f"there is no such an activation function. " f"({output_activation})")

        &#47&#47 set padding idx
        padding_idx = 0
        self.padding_idx = padding_idx

        &#47&#47 define network modules
        self.enc = Encoder(idim=idim,
                           input_layer="linear",
                           embed_dim=embed_dim,
                           elayers=elayers,
                           eunits=eunits,
                           econv_layers=econv_layers,
                           econv_chans=econv_chans,
                           econv_filts=econv_filts,
                           use_batch_norm=use_batch_norm,
                           use_residual=use_residual,
                           dropout_rate=dropout_rate,
                           padding_idx=padding_idx, )

        if spk_embed_dim is None:
            dec_idim = eunits
        elif spk_embed_integration_type == "concat":
            dec_idim = eunits + spk_embed_dim
        elif <a id="change">spk_embed_integration_type == "add"</a>:
            dec_idim = eunits
            self.projection = torch.nn.Linear(self.spk_embed_dim, eunits)
        else:
            <a id="change">raise ValueError(f"{spk_embed_integration_type} is not supported."</a><a id="change">)</a>

        if atype == "location":
            att = AttLoc(dec_idim, dunits, adim, aconv_chans, aconv_filts)
        elif atype == "forward":</code></pre><h3>After Change</h3><pre><code class='java'>
                           padding_idx=padding_idx, )

        if spk_embed_dim is not None:
            self.projection = <a id="change">torch.nn.Sequential(</a>torch.nn.Linear(eunits + spk_embed_dim, eunits),
                                                  <a id="change">torch.nn.Tanh()</a>,
                                                  <a id="change">torch.nn.Linear(</a>eunits, eunits<a id="change">)</a><a id="change">)</a>
        dec_idim = eunits

        if atype == "location":
            att = AttLoc(dec_idim, dunits, adim, aconv_chans, aconv_filts)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/a90b6475ad86b161a101abe3ed1ef4c2bcf925b5#diff-aa1ec5a7ad03c08f5a47e2566025b56ea0c77934bc7a50297017f10f44d1d54dL16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55194360</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: a90b6475ad86b161a101abe3ed1ef4c2bcf925b5</div><div id='time'> Time: 2021-09-24</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/InferenceArchitectures/InferenceTacotron2.py</div><div id='m_class'> M Class Name: Tacotron2</div><div id='n_method'> N Class Name: Tacotron2</div><div id='m_method'> M Method Name: __init__(38)</div><div id='n_method'> N Method Name: __init__(39)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/InferenceArchitectures/InferenceTacotron2.py</div><div id='n_file'> N File Name: InferenceInterfaces/InferenceArchitectures/InferenceTacotron2.py</div><div id='m_start'> M Start Line: 46</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 96</div><div id='n_end'> N End Line: 99</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.use_guided_attn_loss = use_guided_attn_loss
        self.loss_type = loss_type
        if self.spk_embed_dim is not None:
            self.spk_embed_integration_type<a id="change"> = </a>spk_embed_integration_type

        &#47&#47 define activation function for the final output
        if output_activation is None:
            self.output_activation_fn = None
        elif hasattr(F, output_activation):
            self.output_activation_fn = getattr(F, output_activation)
        else:
            raise ValueError(f"there is no such activation function. " f"({output_activation})")

        self.language_embedding = None
        if language_embedding_amount is not None:
            self.language_embedding = torch.nn.Embedding(language_embedding_amount, eunits)

        &#47&#47 set padding idx
        self.padding_idx = torch.zeros(idim)

        &#47&#47 define network modules
        self.enc = Encoder(idim=idim,
                           input_layer=input_layer_type,
                           embed_dim=embed_dim,
                           elayers=elayers,
                           eunits=eunits,
                           econv_layers=econv_layers,
                           econv_chans=econv_chans,
                           econv_filts=econv_filts,
                           use_batch_norm=use_batch_norm,
                           use_residual=use_residual,
                           dropout_rate=dropout_rate)

        if spk_embed_dim is None:
            dec_idim = eunits
        elif spk_embed_integration_type == "concat":
            dec_idim = eunits + spk_embed_dim
        elif <a id="change">spk_embed_integration_type == "add"</a>:
            dec_idim = eunits
            self.projection = torch.nn.Linear(self.spk_embed_dim, eunits)
        else:
            <a id="change">raise ValueError(f"{spk_embed_integration_type} is not supported."</a><a id="change">)</a>

        if atype == "location":
            att = AttLoc(dec_idim, dunits, adim, aconv_chans, aconv_filts)
        elif atype == "forward":</code></pre><h3>After Change</h3><pre><code class='java'>
                           dropout_rate=dropout_rate)

        if spk_embed_dim is not None:
            self.projection = <a id="change">torch.nn.Sequential(</a>torch.nn.Linear(eunits + spk_embed_dim, eunits),
                                                  <a id="change">torch.nn.Tanh()</a>,
                                                  <a id="change">torch.nn.Linear(</a>eunits, eunits<a id="change">)</a><a id="change">)</a>
        dec_idim = eunits

        if atype == "location":
            att = AttLoc(dec_idim, dunits, adim, aconv_chans, aconv_filts)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/1adfce3a2d99089f295ed62e2becd4a51e6b441a#diff-f8d05eb08ac38b212e3d3c6104a5e5618a8484d7eb2df04df282d6599e5473daL30' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55194358</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 1adfce3a2d99089f295ed62e2becd4a51e6b441a</div><div id='time'> Time: 2021-09-23</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/Tacotron2.py</div><div id='m_class'> M Class Name: Tacotron2</div><div id='n_method'> N Class Name: Tacotron2</div><div id='m_method'> M Method Name: __init__(44)</div><div id='n_method'> N Method Name: __init__(45)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/Tacotron2.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/Tacotron2.py</div><div id='m_start'> M Start Line: 59</div><div id='m_end'> M End Line: 130</div><div id='n_start'> N Start Line: 120</div><div id='n_end'> N End Line: 123</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.margin = config[&quotmargin&quot]
        self.negative_weight = config[&quotnegative_weight&quot]
        self.gamma = config[&quotgamma&quot]
        <a id="change">neg_num_dict</a> = config[&quotneg_sampling&quot]
        if &quotuniform&quot in neg_num_dict:
            self.neg_seq_len<a id="change"> = </a>neg_num_dict[&quotuniform&quot]
        elif <a id="change">&quotpopularity&quot in neg_num_dict</a>:
            self.neg_seq_len = neg_num_dict[&quotpopularity&quot]
        else:
            <a id="change">raise ValueError(&quotneg_sampling must be uniform or popularity&quot</a><a id="change">)</a>
        self.reg_weight = config[&quotreg_weight&quot]

        &#47&#47 Get user transaction history
        self.history_item_id, _, self.history_item_len = dataset.history_item_matrix()</code></pre><h3>After Change</h3><pre><code class='java'>
        self.UI_map = nn.Linear(self.embedding_size,
                                self.embedding_size, bias=False)
        if self.aggregator in [&quotuser_attention&quot, &quotself_attention&quot]:
            self.W_k = <a id="change">nn.Sequential(nn.Linear(</a>self.embedding_size, self.embedding_size<a id="change">)</a>,
                                     <a id="change">nn.Tanh())</a>
            if self.aggregator == &quotself_attention&quot:
                self.W_q = nn.Linear(self.embedding_size, 1, bias=False)
        &#47&#47 dropout
        self.dropout = nn.Dropout(0.1)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rucaibox/recbole/commit/283d4a486cc57cae7a4680e08c29c9302f307a0e#diff-1616debdea916026d29c3f84ac8cccd5371107ae8f554fc98b0313b2aa3c1023L39' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 55194359</div><div id='project'> Project Name: rucaibox/recbole</div><div id='commit'> Commit Name: 283d4a486cc57cae7a4680e08c29c9302f307a0e</div><div id='time'> Time: 2022-05-07</div><div id='author'> Author: 18697951462@qq.com</div><div id='file'> File Name: recbole/model/general_recommender/simplex.py</div><div id='m_class'> M Class Name: SimpleX</div><div id='n_method'> N Class Name: SimpleX</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: GeneralRecommender</div><div id='n_parent_class'> N Parent Class: GeneralRecommender</div><div id='m_file'> M File Name: recbole/model/general_recommender/simplex.py</div><div id='n_file'> N File Name: recbole/model/general_recommender/simplex.py</div><div id='m_start'> M Start Line: 47</div><div id='m_end'> M End Line: 57</div><div id='n_start'> N Start Line: 43</div><div id='n_end'> N End Line: 71</div><BR>