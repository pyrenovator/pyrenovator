<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        text_lens = torch.tensor(input_zipped[1], dtype=torch.int)
        target = torch.tensor(pad_to_max(batch_zipped[2], pad_value=-1), dtype=torch.long)

        batch = <a id="change">{
            </a>&quotid&quot: ids,
            &quotinput&quot: [texts, text_lens],
            &quottarget&quot: target<a id="change">
        }</a>

        return batch

    @staticmethod</code></pre><h3>After Change</h3><pre><code class='java'>
        )
        batched_char_words_len = torch.tensor(list(itertools.chain.from_iterable(input_zipped[1])), dtype=torch.int)

        nbs_accumulated = <a id="change">list(</a><a id="change">itertools.accumulate(</a>[1] + list(input_zipped[3])<a id="change">))</a>
        indices = [list(range(nbs_accumulated[i], nbs_accumulated[i + 1])) for i in range(len(nbs_accumulated)<a id="change"> - </a>1)]
        batched_char_word_index<a id="change"> = torch</a><a id="change">.tensor(</a>pad_to_max(indices)<a id="change">, dtype=torch.long)</a>

        batched_tokens<a id="change"> = torch</a><a id="change">.tensor(</a>pad_to_max(input_zipped[2])<a id="change">, dtype=torch.long)</a>
        batched_tokens_len<a id="change"> = torch</a><a id="change">.tensor(</a>input_zipped[3]<a id="change">, dtype=torch.int)</a>

        target = torch.tensor(pad_to_max(batch_zipped[2], pad_value=-1), dtype=torch.long)

        return {</code></pre>