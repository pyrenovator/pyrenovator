<html><h3>Pattern ID :21797
</h3><img src='69447010.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        text_lens = torch.tensor(input_zipped[1], dtype=torch.int)
        target = torch.tensor(pad_to_max(batch_zipped[2], pad_value=-1), dtype=torch.long)

        batch = <a id="change">{
            </a>&quotid&quot: ids,
            &quotinput&quot: [texts, text_lens],
            &quottarget&quot: target<a id="change">
        }</a>

        return batch

    @staticmethod</code></pre><h3>After Change</h3><pre><code class='java'>
        )
        batched_char_words_len = torch.tensor(list(itertools.chain.from_iterable(input_zipped[1])), dtype=torch.int)

        nbs_accumulated = <a id="change">list(</a><a id="change">itertools.accumulate(</a>[1] + list(input_zipped[3])<a id="change">))</a>
        indices = [list(range(nbs_accumulated[i], nbs_accumulated[i + 1])) for i in range(len(nbs_accumulated)<a id="change"> - </a>1)]
        batched_char_word_index<a id="change"> = torch</a><a id="change">.tensor(</a>pad_to_max(indices)<a id="change">, dtype=torch.long)</a>

        batched_tokens<a id="change"> = torch</a><a id="change">.tensor(</a>pad_to_max(input_zipped[2])<a id="change">, dtype=torch.long)</a>
        batched_tokens_len<a id="change"> = torch</a><a id="change">.tensor(</a>input_zipped[3]<a id="change">, dtype=torch.int)</a>

        target = torch.tensor(pad_to_max(batch_zipped[2], pad_value=-1), dtype=torch.long)

        return {</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/nlpaueb/greek-bert/commit/77a770a62c3e0b388614c042af3fedc2ca55026b#diff-5b04d2c8e744c0f9777464d2ca4acd9a481148da65bcec4542ccdfe5147c9f4bL57' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69447010</div><div id='project'> Project Name: nlpaueb/greek-bert</div><div id='commit'> Commit Name: 77a770a62c3e0b388614c042af3fedc2ca55026b</div><div id='time'> Time: 2020-05-17</div><div id='author'> Author: jkoutsikakis@gmail.com</div><div id='file'> File Name: examples/ud/rnn/dataset.py</div><div id='m_class'> M Class Name: UDRNNDataset</div><div id='n_method'> N Class Name: UDRNNDataset</div><div id='m_method'> M Method Name: collate_fn(1)</div><div id='n_method'> N Method Name: collate_fn(1)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: examples/ud/rnn/dataset.py</div><div id='n_file'> N File Name: examples/ud/rnn/dataset.py</div><div id='m_start'> M Start Line: 57</div><div id='m_end'> M End Line: 69</div><div id='n_start'> N Start Line: 69</div><div id='n_end'> N End Line: 99</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        batch = {
            &quotid&quot: ids,
            &quotinput&quot: <a id="change">[</a>texts, text_lens<a id="change"></a>],
            &quottarget&quot: target
        }
</code></pre><h3>After Change</h3><pre><code class='java'>
        )
        batched_char_words_len = torch.tensor(list(itertools.chain.from_iterable(input_zipped[1])), dtype=torch.int)

        nbs_accumulated = <a id="change">list(</a><a id="change">itertools.accumulate(</a>[1] + list(input_zipped[3])<a id="change">))</a>
        indices = [list(range(nbs_accumulated[i], nbs_accumulated[i + 1])) for i in range(len(nbs_accumulated)<a id="change"> - </a>1)]
        batched_char_word_index<a id="change"> = </a><a id="change">torch.tensor(</a>pad_to_max(indices)<a id="change">, dtype=torch.long)</a>

        batched_tokens<a id="change"> = </a><a id="change">torch.tensor(</a>pad_to_max(input_zipped[2])<a id="change">, dtype=torch.long)</a>
        batched_tokens_len<a id="change"> = </a><a id="change">torch.tensor(</a>input_zipped[3]<a id="change">, dtype=torch.int)</a>

        target = torch.tensor(pad_to_max(batch_zipped[2], pad_value=-1), dtype=torch.long)

        return {</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nlpaueb/greek-bert/commit/77a770a62c3e0b388614c042af3fedc2ca55026b#diff-5b04d2c8e744c0f9777464d2ca4acd9a481148da65bcec4542ccdfe5147c9f4bL55' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69447042</div><div id='project'> Project Name: nlpaueb/greek-bert</div><div id='commit'> Commit Name: 77a770a62c3e0b388614c042af3fedc2ca55026b</div><div id='time'> Time: 2020-05-17</div><div id='author'> Author: jkoutsikakis@gmail.com</div><div id='file'> File Name: examples/ud/rnn/dataset.py</div><div id='m_class'> M Class Name: UDRNNDataset</div><div id='n_method'> N Class Name: UDRNNDataset</div><div id='m_method'> M Method Name: collate_fn(1)</div><div id='n_method'> N Method Name: collate_fn(1)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: examples/ud/rnn/dataset.py</div><div id='n_file'> N File Name: examples/ud/rnn/dataset.py</div><div id='m_start'> M Start Line: 57</div><div id='m_end'> M End Line: 69</div><div id='n_start'> N Start Line: 69</div><div id='n_end'> N End Line: 99</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            itertools.accumulate(batch_size_per_feature)
        )
        recat_per_feature = recat
        recat = <a id="change">[]</a>
        for r in recat_per_feature:
            recat.extend(
                list(
                    range(</code></pre><h3>After Change</h3><pre><code class='java'>
            )
            permuted_batch_size_per_feature = [batch_size_per_feature[r] for r in recat]
            input_offset = [0] + list(itertools.accumulate(batch_size_per_feature))
            output_offset = [0]<a id="change"> + list(
                </a><a id="change">itertools.accumulate(</a>permuted_batch_size_per_feature<a id="change">)
            )</a>
            recat_tensor<a id="change"> = </a><a id="change">torch.tensor(
                </a>recat<a id="change">,
                device=device,
                dtype=torch.int32,
            )</a>
            input_offset_tensor<a id="change"> = </a><a id="change">torch.tensor(
                </a>input_offset<a id="change">,
                device=device,
                dtype=torch.int32,
            )</a>
            output_offset_tensor<a id="change"> = </a><a id="change">torch.tensor(
                </a>output_offset<a id="change">,
                device=device,
                dtype=torch.int32,
            )</a>
            recat = torch.ops.fbgemm.expand_into_jagged_permute(
                recat_tensor,
                input_offset_tensor,
                output_offset_tensor,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/facebookresearch/torchrec/commit/860d5740f4a0f3c39b09457e6e3f83c71d3589d6#diff-b6e190b5c72ee118670ea8a50a0fbd5ceb0e88769d9bb88e1e61982a27762389L40' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69446951</div><div id='project'> Project Name: facebookresearch/torchrec</div><div id='commit'> Commit Name: 860d5740f4a0f3c39b09457e6e3f83c71d3589d6</div><div id='time'> Time: 2022-03-30</div><div id='author'> Author: leongao@fb.com</div><div id='file'> File Name: torchrec/distributed/dist_data.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _get_recat(5)</div><div id='n_method'> N Method Name: _get_recat(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchrec/distributed/dist_data.py</div><div id='n_file'> N File Name: torchrec/distributed/dist_data.py</div><div id='m_start'> M Start Line: 67</div><div id='m_end'> M End Line: 101</div><div id='n_start'> N Start Line: 44</div><div id='n_end'> N End Line: 120</div><BR>