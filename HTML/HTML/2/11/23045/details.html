<html><h3>Pattern ID :23045
</h3><img src='73041646.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        src_model = copy.deepcopy(model)
        src_model.freeze_grad()
        model.train()
        data_loader<a id="change"> = </a><a id="change">self.calculator.get_data_loader(</a>self.train_data<a id="change">, batch_size=self.batch_size)</a>
        optimizer = self.calculator.get_optimizer(self.optimizer_name, model, lr=self.learning_rate, weight_decay=self.weight_decay, momentum=self.momentum)
        <a id="change">for </a><a id="change">iter</a> in <a id="change">range(</a>self.epochs<a id="change">):
            </a><a id="change">for </a><a id="change">batch_idx</a>, batch_data in enumerate(data_loader)<a id="change">:
                </a>model.zero_grad()
                original_loss = self.calculator.get_loss(model, batch_data)
                &#47&#47 proximal term
                loss_proximal = 0</code></pre><h3>After Change</h3><pre><code class='java'>
        src_model.freeze_grad()
        model.train()
        optimizer = self.calculator.get_optimizer(self.optimizer_name, model, lr=self.learning_rate, weight_decay=self.weight_decay, momentum=self.momentum)
        <a id="change">for </a><a id="change">iter</a> in range(self.num_steps)<a id="change">:
            &#47&#47 get a batch of data
            </a>batch_data<a id="change"> = </a><a id="change">self.get_batch_data()</a>
            model.zero_grad()
            &#47&#47 calculate the loss of the model on batched dataset through task-specified calculator
            loss = self.calculator.train(model, batch_data)
            loss_proximal = 0</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/wwzzz/easyfl/commit/0f1f8b5f7345f8d85477170c1df940e264d32898#diff-08d1f45f1dd24f3fd71ae2b6f358d3c2ead3ef37bd7b2cca9e6264c3136237d1L20' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73041646</div><div id='project'> Project Name: wwzzz/easyfl</div><div id='commit'> Commit Name: 0f1f8b5f7345f8d85477170c1df940e264d32898</div><div id='time'> Time: 2022-04-22</div><div id='author'> Author: zzz510711928@gmail.com</div><div id='file'> File Name: algorithm/fedprox.py</div><div id='m_class'> M Class Name: Client</div><div id='n_method'> N Class Name: Client</div><div id='m_method'> M Method Name: train(2)</div><div id='n_method'> N Method Name: train(2)</div><div id='m_parent_class'> M Parent Class: BasicClient</div><div id='n_parent_class'> N Parent Class: BasicClient</div><div id='m_file'> M File Name: algorithm/fedprox.py</div><div id='n_file'> N File Name: algorithm/fedprox.py</div><div id='m_start'> M Start Line: 20</div><div id='m_end'> M End Line: 33</div><div id='n_start'> N Start Line: 21</div><div id='n_end'> N End Line: 33</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        :return
        
        model.train()
        data_loader<a id="change"> = </a><a id="change">self.calculator.get_data_loader(</a>self.train_data<a id="change">, batch_size=self.batch_size)</a>
        optimizer = self.calculator.get_optimizer(self.optimizer_name, model, lr = self.learning_rate, weight_decay=self.weight_decay, momentum=self.momentum)
        <a id="change">for </a><a id="change">iter</a> in <a id="change">range(</a>self.epochs<a id="change">):
            </a><a id="change">for </a><a id="change">batch_id</a>, batch_data in enumerate(data_loader)<a id="change">:
                </a>model.zero_grad()
                loss = self.calculator.get_loss(model, batch_data)
                loss.backward()
                optimizer.step()</code></pre><h3>After Change</h3><pre><code class='java'>
        
        model.train()
        optimizer = self.calculator.get_optimizer(self.optimizer_name, model, lr = self.learning_rate, weight_decay=self.weight_decay, momentum=self.momentum)
        <a id="change">for </a><a id="change">iter</a> in range(self.num_steps)<a id="change">:
            &#47&#47 get a batch of data
            </a>batch_data<a id="change"> = </a><a id="change">self.get_batch_data()</a>
            model.zero_grad()
            &#47&#47 calculate the loss of the model on batched dataset through task-specified calculator
            loss = self.calculator.train(model, batch_data)
            loss.backward()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/wwzzz/easyfl/commit/0f1f8b5f7345f8d85477170c1df940e264d32898#diff-5f5b152f80519d24105a5156c0f8a01b58fecc1555b880ef3bdbe342000e778fL296' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73041650</div><div id='project'> Project Name: wwzzz/easyfl</div><div id='commit'> Commit Name: 0f1f8b5f7345f8d85477170c1df940e264d32898</div><div id='time'> Time: 2022-04-22</div><div id='author'> Author: zzz510711928@gmail.com</div><div id='file'> File Name: algorithm/fedbase.py</div><div id='m_class'> M Class Name: BasicClient</div><div id='n_method'> N Class Name: BasicClient</div><div id='m_method'> M Method Name: train(2)</div><div id='n_method'> N Method Name: train(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: algorithm/fedbase.py</div><div id='n_file'> N File Name: algorithm/fedbase.py</div><div id='m_start'> M Start Line: 304</div><div id='m_end'> M End Line: 312</div><div id='n_start'> N Start Line: 297</div><div id='n_end'> N End Line: 305</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        src_model = copy.deepcopy(model)
        src_model.freeze_grad()
        cg.freeze_grad()
        data_loader<a id="change"> = </a><a id="change">self.calculator.get_data_loader(</a>self.train_data<a id="change">, batch_size=self.batch_size)</a>
        optimizer = self.calculator.get_optimizer(self.optimizer_name, model, lr = self.learning_rate, weight_decay=self.weight_decay, momentum=self.momentum)
        num_batches = 0
        <a id="change">for </a><a id="change">iter</a> in <a id="change">range(</a>self.epochs<a id="change">):
            </a><a id="change">for </a><a id="change">batch_idx</a>, batch_data in enumerate(data_loader)<a id="change">:
                </a>model.zero_grad()
                loss = self.calculator.get_loss(model, batch_data)
                loss.backward()
                for pm, pcg, pc in zip(model.parameters(), cg.parameters(), self.c.parameters()):</code></pre><h3>After Change</h3><pre><code class='java'>
        src_model.freeze_grad()
        cg.freeze_grad()
        optimizer = self.calculator.get_optimizer(self.optimizer_name, model, lr = self.learning_rate, weight_decay=self.weight_decay, momentum=self.momentum)
        <a id="change">for </a><a id="change">iter</a> in range(self.num_steps)<a id="change">:
            </a>batch_data<a id="change"> = </a><a id="change">self.get_batch_data()</a>
            model.zero_grad()
            loss = self.calculator.train(model, batch_data)
            loss.backward()
            for pm, pcg, pc in zip(model.parameters(), cg.parameters(), self.c.parameters()):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/wwzzz/easyfl/commit/0f1f8b5f7345f8d85477170c1df940e264d32898#diff-86c7387192f0079f5e309b56ead857ff0247b9d0da65a80d7e32fb81672e9d65L46' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73041648</div><div id='project'> Project Name: wwzzz/easyfl</div><div id='commit'> Commit Name: 0f1f8b5f7345f8d85477170c1df940e264d32898</div><div id='time'> Time: 2022-04-22</div><div id='author'> Author: zzz510711928@gmail.com</div><div id='file'> File Name: algorithm/scaffold.py</div><div id='m_class'> M Class Name: Client</div><div id='n_method'> N Class Name: Client</div><div id='m_method'> M Method Name: train(3)</div><div id='n_method'> N Method Name: train(3)</div><div id='m_parent_class'> M Parent Class: BasicClient</div><div id='n_parent_class'> N Parent Class: BasicClient</div><div id='m_file'> M File Name: algorithm/scaffold.py</div><div id='n_file'> N File Name: algorithm/scaffold.py</div><div id='m_start'> M Start Line: 55</div><div id='m_end'> M End Line: 68</div><div id='n_start'> N Start Line: 51</div><div id='n_end'> N End Line: 60</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        src_model = copy.deepcopy(model)
        src_model.freeze_grad()
        model.train()
        data_loader<a id="change"> = </a><a id="change">self.calculator.get_data_loader(</a>self.train_data<a id="change">, batch_size=self.batch_size)</a>
        optimizer = self.calculator.get_optimizer(self.optimizer_name, model, lr=self.learning_rate, weight_decay=self.weight_decay, momentum=self.momentum)
        <a id="change">for </a><a id="change">iter</a> in <a id="change">range(</a>self.epochs<a id="change">):
            </a><a id="change">for </a><a id="change">batch_idx</a>, batch_data in enumerate(data_loader)<a id="change">:
                </a>model.zero_grad()
                l1 = self.calculator.get_loss(model, batch_data)
                l2 = 0
                l3 = 0</code></pre><h3>After Change</h3><pre><code class='java'>
        src_model.freeze_grad()
        model.train()
        optimizer = self.calculator.get_optimizer(self.optimizer_name, model, lr=self.learning_rate, weight_decay=self.weight_decay, momentum=self.momentum)
        <a id="change">for </a><a id="change">iter</a> in range(self.num_steps)<a id="change">:
            </a>batch_data<a id="change"> = </a><a id="change">self.get_batch_data()</a>
            model.zero_grad()
            l1 = self.calculator.train(model, batch_data)
            l2 = 0
            l3 = 0</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/wwzzz/easyfl/commit/0f1f8b5f7345f8d85477170c1df940e264d32898#diff-683ff65d7e62c96212b2ffb1838d51d6379c97dfcd0cd8ff7977756c3c196033L24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 73041649</div><div id='project'> Project Name: wwzzz/easyfl</div><div id='commit'> Commit Name: 0f1f8b5f7345f8d85477170c1df940e264d32898</div><div id='time'> Time: 2022-04-22</div><div id='author'> Author: zzz510711928@gmail.com</div><div id='file'> File Name: algorithm/feddyn.py</div><div id='m_class'> M Class Name: Client</div><div id='n_method'> N Class Name: Client</div><div id='m_method'> M Method Name: train(2)</div><div id='n_method'> N Method Name: train(2)</div><div id='m_parent_class'> M Parent Class: BasicClient</div><div id='n_parent_class'> N Parent Class: BasicClient</div><div id='m_file'> M File Name: algorithm/feddyn.py</div><div id='n_file'> N File Name: algorithm/feddyn.py</div><div id='m_start'> M Start Line: 31</div><div id='m_end'> M End Line: 47</div><div id='n_start'> N Start Line: 31</div><div id='n_end'> N End Line: 45</div><BR>