<html><h3>Pattern ID :20453
</h3><img src='66185649.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            if not self.deterministic
            else actor_critic_output.distributions.mode()
        )
        <a id="change">if </a><a id="change">self.teacher_forcing is not None</a> and self.teacher_forcing() &gt; 0:
            <a id="change">raise NotImplementedError()</a>
            &#47&#47 teacher_forcing_mask = torch.bernoulli(actions.shape, p=self.teacher_forcing())
            &#47&#47 teacher_forcing_mask *= step_observation["expert_actions"]
            &#47&#47 actions = teacher_forcing_mask * step_observation["expert_actions"] + (1-teacher_forcing_mask)
</code></pre><h3>After Change</h3><pre><code class='java'>
            if not self.deterministic
            else actor_critic_output.distributions.mode()
        )
        <a id="change">if </a>(
            <a id="change">self.teacher_forcing is not None</a>
            and self.teacher_forcing(self.rollout_count) &gt; 0
        ):
            tf_mask_shape = step_observation["expert_action"].shape[:-1] + (1,)
            expert_actions = (
                step_observation["expert_action"].view(-1, 2)[:, 0].view(*tf_mask_shape)
            )
            expert_action_exists_mask<a id="change"> = </a>(
                <a id="change">step_observation["expert_action"].view(-1, 2)[:, 1]</a>.view(*tf_mask_shape)
            )
            teacher_forcing_mask = (
                torch.distributions.bernoulli.Bernoulli(
                    torch.tensor(self.teacher_forcing(self.rollout_count))
                )
                .sample(tf_mask_shape)
                .long()
                .to(self.device)
            ) * expert_action_exists_mask
            actions<a id="change"> = </a>(
                teacher_forcing_mask * expert_actions
                + (1 - teacher_forcing_mask) * actions
            )</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/allenai/allenact/commit/8e313465b05e6546339b02ea73bc1ded059bab14#diff-8f5bf720a80a4913f8c876005730914b873c5b458dba881a99dcb04b54de373fL168' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66185649</div><div id='project'> Project Name: allenai/allenact</div><div id='commit'> Commit Name: 8e313465b05e6546339b02ea73bc1ded059bab14</div><div id='time'> Time: 2020-01-20</div><div id='author'> Author: lucaw@allenai.org</div><div id='file'> File Name: onpolicy_sync/trainer.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: collect_rollout_step(2)</div><div id='n_method'> N Method Name: collect_rollout_step(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: onpolicy_sync/trainer.py</div><div id='n_file'> N File Name: onpolicy_sync/trainer.py</div><div id='m_start'> M Start Line: 168</div><div id='m_end'> M End Line: 194</div><div id='n_start'> N Start Line: 184</div><div id='n_end'> N End Line: 213</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    if not self.are_parameters_frozen:
                        self.randomize_parameters(cloned_samples, sample_rate)
                    return self.apply_transform(cloned_samples, sample_rate)
                elif <a id="change">self.mode == "per_channel"</a>:
                    <a id="change">raise NotImplementedError()</a>  &#47&#47 TODO
                else:
                    raise Exception("Invalid mode")
            else:</code></pre><h3>After Change</h3><pre><code class='java'>
                    if not self.are_parameters_frozen:
                        self.randomize_parameters(cloned_samples, sample_rate)
                    return self.apply_transform(cloned_samples, sample_rate)
                elif <a id="change">self.mode == "per_channel"</a>:
                    batch_size = cloned_samples.shape[0]
                    num_channels = cloned_samples.shape[1]
                    cloned_samples = <a id="change">cloned_samples.view(
                        </a>batch_size * num_channels, <a id="change">1</a>, cloned_samples.shape[2]<a id="change">
                    )</a>

                    if not self.are_parameters_frozen:
                        self.randomize_parameters(cloned_samples, sample_rate)

                    perturbed_samples<a id="change"> = </a>self.apply_transform(cloned_samples, sample_rate)

                    perturbed_samples<a id="change"> = </a>perturbed_samples.view(
                        batch_size, num_channels, <a id="change">cloned_samples.shape[2]</a>
                    )
                    return perturbed_samples
                else:
                    raise Exception("Invalid mode")</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/asteroid-team/torch-audiomentations/commit/5381f525146d60ecaa1daa052dc906e6df4bc801#diff-3c20bbdd5135ce0280a31bab7f4144d222a9d22ca7af0323bfe1c71bd66ebe2aL76' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66185593</div><div id='project'> Project Name: asteroid-team/torch-audiomentations</div><div id='commit'> Commit Name: 5381f525146d60ecaa1daa052dc906e6df4bc801</div><div id='time'> Time: 2020-10-27</div><div id='author'> Author: iver56@hotmail.com</div><div id='file'> File Name: torch_audiomentations/core/transforms_interface.py</div><div id='m_class'> M Class Name: BaseWaveformTransform</div><div id='n_method'> N Class Name: BaseWaveformTransform</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: torch_audiomentations/core/transforms_interface.py</div><div id='n_file'> N File Name: torch_audiomentations/core/transforms_interface.py</div><div id='m_start'> M Start Line: 191</div><div id='m_end'> M End Line: 194</div><div id='n_start'> N Start Line: 116</div><div id='n_end'> N End Line: 208</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                else:
                    raise Exception("Invalid mode/p_mode combination")
            elif self.p_mode == "per_batch":
                <a id="change">if </a><a id="change">self.mode == "per_batch"</a>:
                    raise NotImplementedError()
                elif self.mode == "per_example":
                    <a id="change">raise NotImplementedError()</a>
                elif self.mode == "per_channel":
                    raise NotImplementedError()
                else:
                    raise Exception("Invalid mode")</code></pre><h3>After Change</h3><pre><code class='java'>
                else:
                    raise Exception("Invalid mode/p_mode combination")
            elif self.p_mode == "per_batch":
                <a id="change">if self.mode == "per_batch"</a>:
                    batch_size = cloned_samples.shape[0]
                    num_channels = cloned_samples.shape[1]
                    cloned_samples = <a id="change">cloned_samples.view(
                        1</a>, batch_size * num_channels, cloned_samples.shape[2]<a id="change">
                    )</a>

                    if not self.are_parameters_frozen:
                        self.randomize_parameters(cloned_samples, sample_rate)

                    perturbed_samples<a id="change"> = </a>self.apply_transform(cloned_samples, sample_rate)
                    perturbed_samples<a id="change"> = </a>perturbed_samples.view(
                        batch_size, num_channels, <a id="change">cloned_samples.shape[2]</a>
                    )
                    return perturbed_samples
                elif self.mode == "per_example":
                    if not self.are_parameters_frozen:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/asteroid-team/torch-audiomentations/commit/042316421b72a3bff8168be9e8fdf324b233e22b#diff-3c20bbdd5135ce0280a31bab7f4144d222a9d22ca7af0323bfe1c71bd66ebe2aL77' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 66185598</div><div id='project'> Project Name: asteroid-team/torch-audiomentations</div><div id='commit'> Commit Name: 042316421b72a3bff8168be9e8fdf324b233e22b</div><div id='time'> Time: 2020-10-27</div><div id='author'> Author: iver56@hotmail.com</div><div id='file'> File Name: torch_audiomentations/core/transforms_interface.py</div><div id='m_class'> M Class Name: BaseWaveformTransform</div><div id='n_method'> N Class Name: BaseWaveformTransform</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: torch_audiomentations/core/transforms_interface.py</div><div id='n_file'> N File Name: torch_audiomentations/core/transforms_interface.py</div><div id='m_start'> M Start Line: 173</div><div id='m_end'> M End Line: 181</div><div id='n_start'> N Start Line: 116</div><div id='n_end'> N End Line: 195</div><BR>