<html><h3>Pattern ID :3113
</h3><img src='11954032.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        mask = Masks.get_ff_mask(height, width)
        mask_all.append(mask)
    mask = torch.from_numpy(np.asarray(mask_all)).unsqueeze(1).float()
    ones = <a id="change">torch.ones(x.size(</a>0<a id="change">)</a>, 1, x.size(2), x.size(3)<a id="change">)</a>
    mask<a id="change"> = </a>ones * mask
    if x.is_cuda:
        mask = mask.cuda()
    result = x * (1. - mask)</code></pre><h3>After Change</h3><pre><code class='java'>
    if x.is_cuda:
        mask = mask.cuda()

    <a id="change">if config[&quotmask_type&quot] == &quothole&quot</a>:
        result = x * (1. - mask)
    elif <a id="change">config[&quotmask_type&quot] == &quotmosaic&quot</a>:
        &#47&#47 TODO: Matching the mosaic patch size and the mask size
        mosaic_unit_size = config[&quotmosaic_unit_size&quot]
        downsampled_image<a id="change"> = </a>F.interpolate(x, scale_factor=1. / mosaic_unit_size, mode=&quotnearest&quot)
        upsampled_image = F.interpolate(downsampled_image, size=(height, width), mode=&quotnearest&quot)
        result = upsampled_image * mask + x * (1. - mask)
    else:
        <a id="change">raise NotImplementedError(&quotNot implemented mask type.&quot</a><a id="change">)</a>

    return result, mask</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/sayednadim/global-and-local-attention-based-free-form-image-inpainting/commit/aaa17ed332dc95db0f5900a43be179e26569b50c#diff-4a9d05cc3eadd7aa0b347854fe63c55a626198aae56f6d3482457196186e5d60L40' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11954032</div><div id='project'> Project Name: sayednadim/global-and-local-attention-based-free-form-image-inpainting</div><div id='commit'> Commit Name: aaa17ed332dc95db0f5900a43be179e26569b50c</div><div id='time'> Time: 2020-08-16</div><div id='author'> Author: smnadimuddin@gmail.com</div><div id='file'> File Name: model/mask.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mask_image(2)</div><div id='n_method'> N Method Name: mask_image(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model/mask.py</div><div id='n_file'> N File Name: model/mask.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 49</div><div id='n_start'> N Start Line: 56</div><div id='n_end'> N End Line: 72</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)
        self.mask1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)
        self.mask1.weight.data<a id="change"> = </a><a id="change">torch.ones(self.mask1.weight.size()</a><a id="change">)</a>
        self.bn1   = nn.BatchNorm2d(planes)

        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)
        self.mask2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)</code></pre><h3>After Change</h3><pre><code class='java'>
        super(BasicBlock, self).__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        <a id="change">if </a>groups != 1 or <a id="change">base_width != 64</a>:
            raise ValueError(&quotBasicBlock only supports groups=1 and base_width=64&quot)
        <a id="change">if dilation &gt; 1</a>:
            <a id="change">raise NotImplementedError("Dilation &gt; 1 not supported in BasicBlock"</a><a id="change">)</a>
        &#47&#47 Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride<a id="change"> = </a>stride

    def forward(self, x):
        identity = x</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/incheon-cho/dynamic_model_pruning_with_feedback/commit/12bd228dc14e0c422c262bcbc1b81cb435e05a4d#diff-da62ce430302dcb6718b9a6a36a17d97e7ef64d1ecba8920e816a058c59c6816L31' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11954033</div><div id='project'> Project Name: incheon-cho/dynamic_model_pruning_with_feedback</div><div id='commit'> Commit Name: 12bd228dc14e0c422c262bcbc1b81cb435e05a4d</div><div id='time'> Time: 2020-09-06</div><div id='author'> Author: dlscjs5362@gmail.com</div><div id='file'> File Name: models/resnet.py</div><div id='m_class'> M Class Name: BasicBlock</div><div id='n_method'> N Class Name: BasicBlock</div><div id='m_method'> M Method Name: __init__(9)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/resnet.py</div><div id='n_file'> N File Name: models/resnet.py</div><div id='m_start'> M Start Line: 31</div><div id='m_end'> M End Line: 47</div><div id='n_start'> N Start Line: 24</div><div id='n_end'> N End Line: 40</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
def mask_image(x, config):
    height, width, _ = config[&quotimage_shape&quot]
    mask = torch.ones(x.size(0), 1, x.size(2), x.size(3))
    temp = <a id="change">torch.ones(x.size(</a>0<a id="change">)</a>, 1, x.size(2), x.size(3)<a id="change">)</a>
    for i in range(x.size(0)):
        mask_temp = Masks.get_ff_mask(height, width)
        mask_temp = torch.from_numpy(mask_temp)
        mask[i,:,:,:]<a id="change"> = </a>temp[i,:,:,:] * mask_temp
    if x.is_cuda:
        mask = mask.cuda()
    result = x * (1. - mask)</code></pre><h3>After Change</h3><pre><code class='java'>
    if x.is_cuda:
        mask = mask.cuda()

    <a id="change">if config[&quotmask_type&quot] == &quothole&quot</a>:
        result = x * (1. - mask)
    elif <a id="change">config[&quotmask_type&quot] == &quotmosaic&quot</a>:
        &#47&#47 TODO: Matching the mosaic patch size and the mask size
        mosaic_unit_size = config[&quotmosaic_unit_size&quot]
        downsampled_image = F.interpolate(x, scale_factor=1. / mosaic_unit_size, mode=&quotnearest&quot)
        upsampled_image = F.interpolate(downsampled_image, size=(height, width), mode=&quotnearest&quot)
        result<a id="change"> = </a>upsampled_image * mask + x * (1. - mask)
    else:
        <a id="change">raise NotImplementedError(&quotNot implemented mask type.&quot</a><a id="change">)</a>

    return result, mask</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sayednadim/global-and-local-attention-based-free-form-image-inpainting/commit/2e453ae0b658395a88acb8db67115db86d9274ea#diff-4a9d05cc3eadd7aa0b347854fe63c55a626198aae56f6d3482457196186e5d60L38' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11954026</div><div id='project'> Project Name: sayednadim/global-and-local-attention-based-free-form-image-inpainting</div><div id='commit'> Commit Name: 2e453ae0b658395a88acb8db67115db86d9274ea</div><div id='time'> Time: 2020-08-16</div><div id='author'> Author: smnadimuddin@gmail.com</div><div id='file'> File Name: model/mask.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mask_image(2)</div><div id='n_method'> N Method Name: mask_image(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model/mask.py</div><div id='n_file'> N File Name: model/mask.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 48</div><div id='n_start'> N Start Line: 56</div><div id='n_end'> N End Line: 72</div><BR>