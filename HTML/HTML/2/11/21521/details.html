<html><h3>Pattern ID :21521
</h3><img src='68830840.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                continue
            &#47&#47update network
            data_batch = self.buffer.sample_batch(self.batch_size)
            q_losses<a id="change">, policy_loss, entropy_loss, alpha</a> = self.agent.update(data_batch)
            self.logger.log_var("loss/q_min",np.min(q_losses),ite)
            self.logger.log_var("loss/q_max",np.max(q_losses),ite)
            self.logger.log_var("loss/q_mean",np.mean(q_losses),ite)
            self.logger.log_var("loss/q_std",np.std(q_losses),ite)
            <a id="change">self.logger.log_var("loss/policy"</a>,<a id="change">policy_loss</a>,ite<a id="change">)</a>
            self.logger.log_var("loss/entropy",entropy_loss,ite)
            <a id="change">self.logger.log_var("others/entropy_alpha"</a>,alpha,ite<a id="change">)</a>
            self.agent.try_update_target_network()
            tot_num_updates += 1
       
            iteration_end_time = time()</code></pre><h3>After Change</h3><pre><code class='java'>
            durations.append(duration)
            
            if ite % self.log_interval == 0:
                <a id="change">for </a>loss_name in loss_dict<a id="change">:
                    </a><a id="change">self.logger.log_var(</a>loss_name, <a id="change">loss_dict[loss_name]</a>, ite<a id="change">)</a>
            if ite % self.test_interval == 0:
                log_dict = self.test()
                avg_test_reward = log_dict[&quotreturn/test&quot]
                for log_key in log_dict:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/x35f/unstable_baselines/commit/29d21b411c02aa5529540bac557cbb9cd79e7f17#diff-fe98381d15d030f360073153b6a8279153209b72bac992a65d2b18064d47a9fbL43' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 68830840</div><div id='project'> Project Name: x35f/unstable_baselines</div><div id='commit'> Commit Name: 29d21b411c02aa5529540bac557cbb9cd79e7f17</div><div id='time'> Time: 2021-03-23</div><div id='author'> Author: 1621322691@qq.com</div><div id='file'> File Name: redq/trainer.py</div><div id='m_class'> M Class Name: REDQTrainer</div><div id='n_method'> N Class Name: REDQTrainer</div><div id='m_method'> M Method Name: train(1)</div><div id='n_method'> N Method Name: train(1)</div><div id='m_parent_class'> M Parent Class: BaseTrainer</div><div id='n_parent_class'> N Parent Class: BaseTrainer</div><div id='m_file'> M File Name: redq/trainer.py</div><div id='n_file'> N File Name: redq/trainer.py</div><div id='m_start'> M Start Line: 48</div><div id='m_end'> M End Line: 91</div><div id='n_start'> N Start Line: 43</div><div id='n_end'> N End Line: 87</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                continue
            &#47&#47update network
            data_batch = self.buffer.sample_batch(self.batch_size)
            q_losses<a id="change">, policy_loss, entropy_loss, alpha</a> = self.agent.update(data_batch)
            self.logger.log_var("loss/q_min",np.min(q_losses),ite)
            self.logger.log_var("loss/q_max",np.max(q_losses),ite)
            self.logger.log_var("loss/q_mean",np.mean(q_losses),ite)
            self.logger.log_var("loss/q_std",np.std(q_losses),ite)
            self.logger.log_var("loss/policy",policy_loss,ite)
            <a id="change">self.logger.log_var("loss/entropy"</a>,entropy_loss,ite<a id="change">)</a>
            <a id="change">self.logger.log_var("others/entropy_alpha"</a>,alpha,ite<a id="change">)</a>
            self.agent.try_update_target_network()
            tot_num_updates += 1
       
            iteration_end_time = time()</code></pre><h3>After Change</h3><pre><code class='java'>
            durations.append(duration)
            
            if ite % self.log_interval == 0:
                <a id="change">for loss_name</a> in loss_dict<a id="change">:
                    </a><a id="change">self.logger.log_var(</a>loss_name, <a id="change">loss_dict[loss_name]</a>, ite<a id="change">)</a>
            if ite % self.test_interval == 0:
                log_dict = self.test()
                avg_test_reward = log_dict[&quotreturn/test&quot]
                for log_key in log_dict:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/x35f/unstable_baselines/commit/29d21b411c02aa5529540bac557cbb9cd79e7f17#diff-fe98381d15d030f360073153b6a8279153209b72bac992a65d2b18064d47a9fbL39' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 68830841</div><div id='project'> Project Name: x35f/unstable_baselines</div><div id='commit'> Commit Name: 29d21b411c02aa5529540bac557cbb9cd79e7f17</div><div id='time'> Time: 2021-03-23</div><div id='author'> Author: 1621322691@qq.com</div><div id='file'> File Name: redq/trainer.py</div><div id='m_class'> M Class Name: REDQTrainer</div><div id='n_method'> N Class Name: REDQTrainer</div><div id='m_method'> M Method Name: train(1)</div><div id='n_method'> N Method Name: train(1)</div><div id='m_parent_class'> M Parent Class: BaseTrainer</div><div id='n_parent_class'> N Parent Class: BaseTrainer</div><div id='m_file'> M File Name: redq/trainer.py</div><div id='n_file'> N File Name: redq/trainer.py</div><div id='m_start'> M Start Line: 48</div><div id='m_end'> M End Line: 91</div><div id='n_start'> N Start Line: 43</div><div id='n_end'> N End Line: 87</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                self.logger.log_var("loss/entropy",entropy_loss,tot_env_steps)
                self.logger.log_var("others/entropy_alpha",alpha,tot_env_steps)
            if ite % self.test_interval == 0:
                avg_test_reward<a id="change">, avg_test_length</a> = self.test()
                <a id="change">self.logger.log_var("return/test"</a>, avg_test_reward, tot_env_steps<a id="change">)</a>
                <a id="change">self.logger.log_var("length/test"</a>, avg_test_length, tot_env_steps<a id="change">)</a>
                time_remaining_str = second_to_time_str(int((self.max_iteration - ite + 1) * np.mean(iteration_durations[-100:])))
                summary_str = "iteration {}/{}:\ttrain return {:.02f}\ttest return {:02f}\teta: {}".format(ite, self.max_iteration, train_traj_rewards[-1],avg_test_reward,time_remaining_str)
                self.logger.log_str(summary_str)
            if ite % self.save_model_interval == 0:</code></pre><h3>After Change</h3><pre><code class='java'>
                    self.logger.log_var(loss_name, loss_dict[loss_name], tot_env_steps)
            if ite % self.test_interval == 0:
                log_dict = self.test()
                <a id="change">for log_key</a> in log_dict<a id="change">:
                    </a><a id="change">self.logger.log_var(</a>log_key, <a id="change">log_dict[log_key]</a>, tot_env_steps<a id="change">)</a>
                remaining_seconds = int((self.max_iteration - ite + 1) * np.mean(iteration_durations[-100:]))
                time_remaining_str = second_to_time_str(remaining_seconds)
                summary_str = "iteration {}/{}:\ttrain return {:.02f}\ttest return {:02f}\teta: {}".format(ite, self.max_iteration, train_traj_rewards[-1],avg_test_reward,time_remaining_str)
                self.logger.log_str(summary_str)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/x35f/unstable_baselines/commit/fa96126eb19efa9718949b1a5f62bfb6e48eb842#diff-a34b216e3cbb15e5638a392fca1ded59237d9cba3769fbdf2fa9f4cc8ddbd78cL45' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 68830854</div><div id='project'> Project Name: x35f/unstable_baselines</div><div id='commit'> Commit Name: fa96126eb19efa9718949b1a5f62bfb6e48eb842</div><div id='time'> Time: 2021-03-22</div><div id='author'> Author: 1621322691@qq.com</div><div id='file'> File Name: sac/trainer.py</div><div id='m_class'> M Class Name: SACTrainer</div><div id='n_method'> N Class Name: SACTrainer</div><div id='m_method'> M Method Name: train(1)</div><div id='n_method'> N Method Name: train(1)</div><div id='m_parent_class'> M Parent Class: BaseTrainer</div><div id='n_parent_class'> N Parent Class: BaseTrainer</div><div id='m_file'> M File Name: sac/trainer.py</div><div id='n_file'> N File Name: sac/trainer.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 99</div><div id='n_start'> N Start Line: 80</div><div id='n_end'> N End Line: 97</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                self.logger.log_var("loss/entropy",entropy_loss,tot_env_steps)
                self.logger.log_var("others/entropy_alpha",alpha,tot_env_steps)
            if ite % self.test_interval == 0:
                avg_test_reward<a id="change">, avg_test_length</a> = self.test()
                <a id="change">self.logger.log_var("return/test"</a>, avg_test_reward, tot_env_steps<a id="change">)</a>
                <a id="change">self.logger.log_var("length/test"</a>, avg_test_length, tot_env_steps<a id="change">)</a>
                time_remaining_str = second_to_time_str(int((self.max_iteration - ite + 1) * np.mean(iteration_durations[-100:])))
                summary_str = "iteration {}/{}:\ttrain return {:.02f}\ttest return {:02f}\teta: {}".format(ite, self.max_iteration, train_traj_rewards[-1],avg_test_reward,time_remaining_str)
                self.logger.log_str(summary_str)
            if ite % self.save_model_interval == 0:</code></pre><h3>After Change</h3><pre><code class='java'>
            if ite % self.test_interval == 0:
                log_dict = self.test()
                avg_test_reward = log_dict[&quotreturn/test&quot]
                <a id="change">for log_key</a> in log_dict<a id="change">:
                    </a><a id="change">self.logger.log_var(</a>log_key, <a id="change">log_dict[log_key]</a>, tot_env_steps<a id="change">)</a>
                remaining_seconds = int((self.max_iteration - ite + 1) * np.mean(iteration_durations[-100:]))
                time_remaining_str = second_to_time_str(remaining_seconds)
                summary_str = "iteration {}/{}:\ttrain return {:.02f}\ttest return {:02f}\teta: {}".format(ite, self.max_iteration, train_traj_rewards[-1],avg_test_reward,time_remaining_str)
                self.logger.log_str(summary_str)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/x35f/unstable_baselines/commit/70df2e4ddafc2aa9884b10ba8a3a257b3daaae1d#diff-d26efc3152f62fe56d2265601c9f2db8e403b5b6e1650a9661cbce7e0611a930L45' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 68830852</div><div id='project'> Project Name: x35f/unstable_baselines</div><div id='commit'> Commit Name: 70df2e4ddafc2aa9884b10ba8a3a257b3daaae1d</div><div id='time'> Time: 2021-03-23</div><div id='author'> Author: 1621322691@qq.com</div><div id='file'> File Name: tdn_sac/trainer.py</div><div id='m_class'> M Class Name: TDNSACTrainer</div><div id='n_method'> N Class Name: TDNSACTrainer</div><div id='m_method'> M Method Name: train(1)</div><div id='n_method'> N Method Name: train(1)</div><div id='m_parent_class'> M Parent Class: BaseTrainer</div><div id='n_parent_class'> N Parent Class: BaseTrainer</div><div id='m_file'> M File Name: tdn_sac/trainer.py</div><div id='n_file'> N File Name: tdn_sac/trainer.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 99</div><div id='n_start'> N Start Line: 96</div><div id='n_end'> N End Line: 101</div><BR>