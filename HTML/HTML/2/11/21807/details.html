<html><h3>Pattern ID :21807
</h3><img src='69451147.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
def flops_adaptive_avgpool(module: _AdaptiveAvgPoolNd, inputs: Tuple[Tensor, ...], output: Tensor) -&gt; int:
    FLOPs estimation for `torch.nn.modules.pooling._AdaptiveAvgPoolNd`

    <a id="change">if </a><a id="change">isinstance(</a>module.output_size, tuple<a id="change">)</a>:
        o_sizes<a id="change"> = </a>module.output_size
    else:
        o_sizes<a id="change"> = </a>(module.output_size<a id="change"></a>,)<a id="change"> * </a>(inputs[0].ndim<a id="change"> - 2</a>)  &#47&#47 type: ignore[attr-defined]
    &#47&#47 Approximate kernel_size using ratio of spatial shapes between input and output
    kernel_size = tuple(i_size // o_size if (i_size % o_size) == 0 else i_size - o_size * (i_size // o_size) + 1
                        for i_size, o_size in zip(inputs[0].shape[2:], o_sizes))</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 Approximate kernel_size using ratio of spatial shapes between input and output
    kernel_size = tuple(
        i_size // o_size if (i_size % o_size) == 0 else i_size - o_size * (i_size // o_size) + 1
        for i_size, o_size in zip(inputs[0].shape[2:], <a id="change">output.shape[2:]</a>)
    )

    &#47&#47 for each spatial output element, sum elements in kernel scope and div by kernel size</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/frgfm/torch-scan/commit/579c189f54d2de7a04cb75d2478a075cd5724625#diff-eae7b5beb783fdbf4783f5316fdbf8c2ad04f2b7f516fe1ec3556ea48b77f65cL228' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69451147</div><div id='project'> Project Name: frgfm/torch-scan</div><div id='commit'> Commit Name: 579c189f54d2de7a04cb75d2478a075cd5724625</div><div id='time'> Time: 2022-05-31</div><div id='author'> Author: 26927750+frgfm@users.noreply.github.com</div><div id='file'> File Name: torchscan/modules/flops.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: flops_adaptive_avgpool(3)</div><div id='n_method'> N Method Name: flops_adaptive_avgpool(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchscan/modules/flops.py</div><div id='n_file'> N File Name: torchscan/modules/flops.py</div><div id='m_start'> M Start Line: 228</div><div id='m_end'> M End Line: 234</div><div id='n_start'> N Start Line: 229</div><div id='n_end'> N End Line: 229</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
def macs_adaptive_avgpool(module: _AdaptiveAvgPoolNd, input: Tensor, output: Tensor) -&gt; int:
    MACs estimation for `torch.nn.modules.pooling._AdaptiveAvgPoolNd`

    <a id="change">if </a><a id="change">isinstance(</a>module.output_size, tuple<a id="change">)</a>:
        o_sizes<a id="change"> = </a>module.output_size
    else:
        o_sizes<a id="change"> = </a>(module.output_size<a id="change"></a>,)<a id="change"> * </a>(input.ndim<a id="change"> - 2</a>)  &#47&#47 type: ignore[attr-defined]
    &#47&#47 Approximate kernel_size using ratio of spatial shapes between input and output
    kernel_size = tuple(i_size // o_size if (i_size % o_size) == 0 else i_size - o_size * (i_size // o_size) + 1
                        for i_size, o_size in zip(input.shape[2:], o_sizes))</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 Approximate kernel_size using ratio of spatial shapes between input and output
    kernel_size = tuple(
        i_size // o_size if (i_size % o_size) == 0 else i_size - o_size * (i_size // o_size) + 1
        for i_size, o_size in zip(input.shape[2:], <a id="change">output.shape[2:]</a>)
    )

    &#47&#47 for each spatial output element, sum elements in kernel scope and div by kernel size</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/frgfm/torch-scan/commit/579c189f54d2de7a04cb75d2478a075cd5724625#diff-a48756fbb08ca61c335020635b47700170f474c40253df2963dc2d5b949b6ea8L152' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69451153</div><div id='project'> Project Name: frgfm/torch-scan</div><div id='commit'> Commit Name: 579c189f54d2de7a04cb75d2478a075cd5724625</div><div id='time'> Time: 2022-05-31</div><div id='author'> Author: 26927750+frgfm@users.noreply.github.com</div><div id='file'> File Name: torchscan/modules/macs.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: macs_adaptive_avgpool(3)</div><div id='n_method'> N Method Name: macs_adaptive_avgpool(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchscan/modules/macs.py</div><div id='n_file'> N File Name: torchscan/modules/macs.py</div><div id='m_start'> M Start Line: 155</div><div id='m_end'> M End Line: 161</div><div id='n_start'> N Start Line: 156</div><div id='n_end'> N End Line: 156</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
def dmas_adaptive_pool(module: Union[_AdaptiveMaxPoolNd, _AdaptiveAvgPoolNd], input: Tensor, output: Tensor) -&gt; int:
    DMAs estimation for adaptive spatial pooling modules

    <a id="change">if </a><a id="change">isinstance(</a>module.output_size, tuple<a id="change">)</a>:
        o_sizes<a id="change"> = </a>module.output_size
    else:
        o_sizes<a id="change"> = </a>(module.output_size<a id="change"></a>,)<a id="change"> * </a>(input.ndim<a id="change"> - 2</a>)  &#47&#47 type: ignore[attr-defined]
    &#47&#47 Approximate kernel_size using ratio of spatial shapes between input and output
    kernel_size = tuple(i_size // o_size if (i_size % o_size) == 0 else i_size - o_size * (i_size // o_size) + 1
                        for i_size, o_size in zip(input.shape[2:], o_sizes))</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 Approximate kernel_size using ratio of spatial shapes between input and output
    kernel_size = tuple(
        i_size // o_size if (i_size % o_size) == 0 else i_size - o_size * (i_size // o_size) + 1
        for i_size, o_size in zip(input.shape[2:], <a id="change">output.shape[2:]</a>)
    )
    &#47&#47 Each output element required K ** 2 memory accesses
    input_dma = reduce(mul, kernel_size) * output.numel()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/frgfm/torch-scan/commit/579c189f54d2de7a04cb75d2478a075cd5724625#diff-9658ad4c69f4238b399d45b324ab874dbb56458236a0f992b1cb8e167bcda986L220' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69451157</div><div id='project'> Project Name: frgfm/torch-scan</div><div id='commit'> Commit Name: 579c189f54d2de7a04cb75d2478a075cd5724625</div><div id='time'> Time: 2022-05-31</div><div id='author'> Author: 26927750+frgfm@users.noreply.github.com</div><div id='file'> File Name: torchscan/modules/memory.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: dmas_adaptive_pool(3)</div><div id='n_method'> N Method Name: dmas_adaptive_pool(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchscan/modules/memory.py</div><div id='n_file'> N File Name: torchscan/modules/memory.py</div><div id='m_start'> M Start Line: 223</div><div id='m_end'> M End Line: 229</div><div id='n_start'> N Start Line: 226</div><div id='n_end'> N End Line: 226</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
def macs_adaptive_maxpool(module: _AdaptiveMaxPoolNd, input: Tensor, output: Tensor) -&gt; int:
    MACs estimation for `torch.nn.modules.pooling._AdaptiveMaxPoolNd`

    <a id="change">if </a><a id="change">isinstance(</a>module.output_size, tuple<a id="change">)</a>:
        o_sizes<a id="change"> = </a>module.output_size
    else:
        o_sizes<a id="change"> = </a>(module.output_size<a id="change"></a>,)<a id="change"> * </a>(input.ndim<a id="change"> - 2</a>)  &#47&#47 type: ignore[attr-defined]
    &#47&#47 Approximate kernel_size using ratio of spatial shapes between input and output
    kernel_size = tuple(i_size // o_size if (i_size % o_size) == 0 else i_size - o_size * (i_size // o_size) + 1
                        for i_size, o_size in zip(input.shape[2:], o_sizes))</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 Approximate kernel_size using ratio of spatial shapes between input and output
    kernel_size = tuple(
        i_size // o_size if (i_size % o_size) == 0 else i_size - o_size * (i_size // o_size) + 1
        for i_size, o_size in zip(input.shape[2:], <a id="change">output.shape[2:]</a>)
    )

    &#47&#47 for each spatial output element, check max element in kernel scope</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/frgfm/torch-scan/commit/579c189f54d2de7a04cb75d2478a075cd5724625#diff-a48756fbb08ca61c335020635b47700170f474c40253df2963dc2d5b949b6ea8L137' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69451145</div><div id='project'> Project Name: frgfm/torch-scan</div><div id='commit'> Commit Name: 579c189f54d2de7a04cb75d2478a075cd5724625</div><div id='time'> Time: 2022-05-31</div><div id='author'> Author: 26927750+frgfm@users.noreply.github.com</div><div id='file'> File Name: torchscan/modules/macs.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: macs_adaptive_maxpool(3)</div><div id='n_method'> N Method Name: macs_adaptive_maxpool(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchscan/modules/macs.py</div><div id='n_file'> N File Name: torchscan/modules/macs.py</div><div id='m_start'> M Start Line: 140</div><div id='m_end'> M End Line: 146</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 143</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
def flops_adaptive_maxpool(module: _AdaptiveMaxPoolNd, inputs: Tuple[Tensor, ...], output: Tensor) -&gt; int:
    FLOPs estimation for `torch.nn.modules.pooling._AdaptiveMaxPoolNd`

    <a id="change">if </a><a id="change">isinstance(</a>module.output_size, tuple<a id="change">)</a>:
        o_sizes<a id="change"> = </a>module.output_size
    else:
        o_sizes<a id="change"> = </a>(module.output_size<a id="change"></a>,)<a id="change"> * </a>(inputs[0].ndim<a id="change"> - 2</a>)  &#47&#47 type: ignore[attr-defined]
    &#47&#47 Approximate kernel_size using ratio of spatial shapes between input and output
    kernel_size = tuple(i_size // o_size if (i_size % o_size) == 0 else i_size - o_size * (i_size // o_size) + 1
                        for i_size, o_size in zip(inputs[0].shape[2:], o_sizes))</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 Approximate kernel_size using ratio of spatial shapes between input and output
    kernel_size = tuple(
        i_size // o_size if (i_size % o_size) == 0 else i_size - o_size * (i_size // o_size) + 1
        for i_size, o_size in zip(inputs[0].shape[2:], <a id="change">output.shape[2:]</a>)
    )

    &#47&#47 for each spatial output element, check max element in kernel scope</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/frgfm/torch-scan/commit/579c189f54d2de7a04cb75d2478a075cd5724625#diff-eae7b5beb783fdbf4783f5316fdbf8c2ad04f2b7f516fe1ec3556ea48b77f65cL210' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69451151</div><div id='project'> Project Name: frgfm/torch-scan</div><div id='commit'> Commit Name: 579c189f54d2de7a04cb75d2478a075cd5724625</div><div id='time'> Time: 2022-05-31</div><div id='author'> Author: 26927750+frgfm@users.noreply.github.com</div><div id='file'> File Name: torchscan/modules/flops.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: flops_adaptive_maxpool(3)</div><div id='n_method'> N Method Name: flops_adaptive_maxpool(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchscan/modules/flops.py</div><div id='n_file'> N File Name: torchscan/modules/flops.py</div><div id='m_start'> M Start Line: 213</div><div id='m_end'> M End Line: 219</div><div id='n_start'> N Start Line: 216</div><div id='n_end'> N End Line: 216</div><BR>