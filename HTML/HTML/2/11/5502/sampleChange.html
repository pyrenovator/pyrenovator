<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                &#47&#47 expand the latents if we are doing classifier free guidance
                latent_model_input = np.concatenate([latents] * 2) if do_classifier_free_guidance else latents
                latent_model_input = self.scheduler.scale_model_input(paddle.to_tensor(latent_model_input), tensor_t)
                latent_model_input<a id="change"> = </a><a id="change">latent_model_input.numpy()</a>

                &#47&#47 predict the noise residual
                noise_pred = <a id="change">self.unet(
                    sample=latent_model_input.astype(np.float32),
                    timestep=np.array([t], dtype=np.int64),
                    encoder_hidden_states=text_embeddings.astype(np.float32),
                )</a>[0]

                &#47&#47 perform guidance
                if do_classifier_free_guidance:
                    noise_pred_uncond, noise_pred_text = np.split(noise_pred, 2)
                    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)

                &#47&#47 compute the previous noisy sample x_t -&gt; x_t-1
                scheduler_output = self.scheduler.step(
                    <a id="change">paddle.to_tensor(</a>noise_pred<a id="change">)</a>, tensor_t, <a id="change">paddle.to_tensor(</a>latents<a id="change">)</a>, **extra_step_kwargs
                )
                latents = <a id="change">scheduler_output.prev_sample.numpy()</a>

                &#47&#47 call the callback, if provided
                if i == len(timesteps) - 1 or ((i + 1) &gt; num_warmup_steps and (i + 1) % self.scheduler.order == 0):
                    progress_bar.update()</code></pre><h3>After Change</h3><pre><code class='java'>
        num_warmup_steps = len(timesteps) - num_inference_steps * self.scheduler.order
        with self.progress_bar(total=num_inference_steps) as progress_bar:
            text_embeddings = paddle.to_tensor(text_embeddings)
            for i, <a id="change">t</a> in enumerate(timesteps):
                &#47&#47 expand the latents if we are doing classifier free guidance
                latent_model_input = paddle.concat([latents] * 2) if do_classifier_free_guidance else latents
                latent_model_input = self.scheduler.scale_model_input(latent_model_input, t)

                &#47&#47 predict the noise residual
                noise_pred = <a id="change">self.unet.zero_copy_infer(
                    sample=latent_model_input, timestep=t, encoder_hidden_states=text_embeddings
                )</a>[0]
                &#47&#47 perform guidance
                if do_classifier_free_guidance:
                    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)
                    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)

                &#47&#47 compute the previous noisy sample x_t -&gt; x_t-1
                scheduler_output = self.scheduler.step(noise_pred, t, latents, **extra_step_kwargs)
                latents = scheduler_output.prev_sample

                &#47&#47 call the callback, if provided
                if i == len(timesteps) - 1 or ((i + 1) &gt; num_warmup_steps and (i + 1) % self.scheduler.order == 0):
                    progress_bar.update()
                    if callback is not None and i % callback_steps == 0:
                        callback(i, t, latents)

        &#47&#47 9. Post-processing
        image = self.decode_latents(<a id="change">latents.numpy()</a>)

        &#47&#47 10. Run safety checker
        image, has_nsfw_concept = self.run_safety_checker(image, text_embeddings.dtype)</code></pre>