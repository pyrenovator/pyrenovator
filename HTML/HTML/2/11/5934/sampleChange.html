<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    loss: `torch.autograd.Variable`
        :math:`-\mathrm{logpreds} \cdot \mathrm{targets}`
    
    <a id="change">assert </a>logpreds.size() == targets.size()
    result = -logpreds * targets
    &#47&#47 Sum across dims if axis given or more than 1 dim
    if dims is not None:</code></pre><h3>After Change</h3><pre><code class='java'>

    loss: `torch.autograd.Variable`
    
    <a id="change">if log_preds.size() == targets.size()</a>:
        <a id="change">return </a>log_categorical_crossentropy_1_hot(log_preds, targets)
    n_classes = log_preds.size()[1]
    n_elements = 0
    losses<a id="change"> = </a><a id="change">[]</a>
    <a id="change">for </a>i_class in range(n_classes)<a id="change">:
        </a>mask = targets == i_class
        mask<a id="change"> = </a>mask.type_as(log_preds)
        n_elements -= th.sum(mask)
        <a id="change">losses.append(</a>th.sum(mask * log_preds[:,i_class])<a id="change">)</a>
    <a id="change">return </a>th.sum(th.stack(losses)) / n_elements


def l2_loss(model):</code></pre>