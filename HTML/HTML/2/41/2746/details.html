<html><h3>Pattern ID :2746
</h3><img src='11068969.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def __init__(self, in_planes, planes, stride=1):
        super(BasicBlock, self).__init__()
        self.conv1 = <a id="change">nn.Conv2d(in_planes</a>, planes<a id="change">, kernel_size=3, stride=stride, padding=1, bias=False)</a>
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = <a id="change">nn.Conv2d(</a>planes, planes<a id="change">, kernel_size=3, stride=1, padding=1, bias=False)</a>
        self.bn2 = nn.BatchNorm2d(planes)

        self.shortcut<a id="change"> = nn</a><a id="change">.Sequential()</a>
        <a id="change">if stride != 1 or in_planes != self.expansion * planes</a>:
            self.shortcut<a id="change"> = nn</a><a id="change">.Sequential(
                nn.Conv2d(in_planes</a>, self.expansion<a id="change"> * </a>planes<a id="change">, kernel_size=1, stride=stride, bias=False)</a>,
                <a id="change">nn.BatchNorm2d(</a>self.expansion<a id="change"> * </a>planes<a id="change">)
            )</a>

    def forward(self, x):
        print(&quot\n input of first convolution:{}&quot.format(x.size()))
        out = F.relu(self.bn1(self.conv1(x)))</code></pre><h3>After Change</h3><pre><code class='java'>
        super(BasicBlock, self).__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        <a id="change">if </a><a id="change">groups != 1 or base_width != 64</a>:
            <a id="change">raise ValueError(&quotBasicBlock only supports groups=1 and base_width=64&quot</a><a id="change">)</a>
        <a id="change">if dilation &gt; 1</a>:
            <a id="change">raise NotImplementedError("Dilation &gt; 1 not supported in BasicBlock"</a><a id="change">)</a>
        &#47&#47 Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = <a id="change">conv3x3(</a>inplanes, <a id="change">planes</a>, <a id="change">stride</a><a id="change">)</a>
        self.bn1 = norm_layer(planes)
        self.relu<a id="change"> = nn.ReLU(inplace=True)</a>
        self.conv2 = <a id="change">conv3x3(planes</a>, <a id="change">planes</a><a id="change">)</a>
        self.bn2 = norm_layer(planes)
        self.downsample<a id="change"> = </a>downsample
        self.stride<a id="change"> = stride</a>

    def forward(self, x):
        identity = x
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 31</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/mdiephuis/simclr/commit/cded7358aca8d4b0d4043c06952a30a0882c05f1#diff-dcfeaa5ac3dffd54264034760914588d92fc7395c81eaa9274715840dc28100bL15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11068969</div><div id='project'> Project Name: mdiephuis/simclr</div><div id='commit'> Commit Name: cded7358aca8d4b0d4043c06952a30a0882c05f1</div><div id='time'> Time: 2020-03-05</div><div id='author'> Author: shideh.rezaeifar@unige.ch</div><div id='file'> File Name: models.py</div><div id='m_class'> M Class Name: BasicBlock</div><div id='n_method'> N Class Name: BasicBlock</div><div id='m_method'> M Method Name: __init__(9)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models.py</div><div id='n_file'> N File Name: models.py</div><div id='m_start'> M Start Line: 15</div><div id='m_end'> M End Line: 29</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 46</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def __init__(self, in_planes, planes, stride=1, sketch_rate=1):
        super(BasicBlock, self).__init__()
        self.conv1 = <a id="change">nn.Conv2d(</a>in_planes, int(planes * sketch_rate)<a id="change">, kernel_size=3, stride=stride, padding=1, bias=False)</a>
        self.bn1 = nn.BatchNorm2d(int(planes * sketch_rate))
        self.conv2 = <a id="change">nn.Conv2d(</a>int(planes * sketch_rate), planes<a id="change">, kernel_size=3, stride=1, padding=1, bias=False)</a>
        self.bn2 = nn.BatchNorm2d(planes)

        self.downsample<a id="change"> = </a><a id="change">nn.Sequential()</a>
        <a id="change">if stride != 1 or in_planes != self.expansion*planes</a>:
            self.downsample<a id="change"> = </a><a id="change">nn.Sequential(
                nn.Conv2d(</a>in_planes, self.expansion<a id="change">*</a>planes<a id="change">, kernel_size=1, stride=stride, bias=False)</a>,
                <a id="change">nn.BatchNorm2d(</a>self.expansion<a id="change">*</a>planes<a id="change">)
            )</a>

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))</code></pre><h3>After Change</h3><pre><code class='java'>
        super(BasicBlock, self).__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        <a id="change">if </a><a id="change">groups != 1 or base_width != 64</a>:
            <a id="change">raise ValueError(&quotBasicBlock only supports groups=1 and base_width=64&quot</a><a id="change">)</a>
        <a id="change">if dilation &gt; 1</a>:
            <a id="change">raise NotImplementedError("Dilation &gt; 1 not supported in BasicBlock"</a><a id="change">)</a>
        &#47&#47 Both self.conv1 and self.downsample layers downsample the input when stride != 1
        if conv1_planes is None:
            <a id="change">conv1_planes</a> = planes
        self.conv1 = <a id="change">conv3x3(</a>inplanes, conv1_planes, stride<a id="change">)</a>
        self.bn1 = norm_layer(conv1_planes)
        self.relu<a id="change"> = nn.ReLU(inplace=True)</a>
        self.conv2 = <a id="change">conv3x3(</a>conv1_planes, planes<a id="change">)</a>
        self.bn2 = norm_layer(planes)
        self.downsample<a id="change"> = </a>downsample
        self.stride<a id="change"> = </a>stride

    def forward(self, x):
        identity = x</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lmbxmu/epruner/commit/6250a88e8504c685486d149f1c99ec05235666e1#diff-5afd6eb184151d0b8e9873dda78ff1b9e6b5b36126bc95a03b5f687d7c298125L8' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11068970</div><div id='project'> Project Name: lmbxmu/epruner</div><div id='commit'> Commit Name: 6250a88e8504c685486d149f1c99ec05235666e1</div><div id='time'> Time: 2020-02-12</div><div id='author'> Author: 864589477@qq.com</div><div id='file'> File Name: model/resnet_imagenet.py</div><div id='m_class'> M Class Name: BasicBlock</div><div id='n_method'> N Class Name: BasicBlock</div><div id='m_method'> M Method Name: __init__(11)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/resnet_imagenet.py</div><div id='n_file'> N File Name: model/resnet_imagenet.py</div><div id='m_start'> M Start Line: 8</div><div id='m_end'> M End Line: 22</div><div id='n_start'> N Start Line: 19</div><div id='n_end'> N End Line: 37</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def __init__(self, in_planes, planes, stride=1):
        super(BasicBlock, self).__init__()
        self.conv1 = <a id="change">nn.Conv2d(</a>in_planes, planes<a id="change">, kernel_size=3, stride=stride, padding=1, bias=False)</a>
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = <a id="change">nn.Conv2d(</a>planes, planes<a id="change">, kernel_size=3, stride=1, padding=1, bias=False)</a>
        self.bn2 = nn.BatchNorm2d(planes)

        self.shortcut<a id="change"> = </a><a id="change">nn.Sequential()</a>
        <a id="change">if stride != 1 or in_planes != self.expansion*planes</a>:
            self.shortcut<a id="change"> = </a><a id="change">nn.Sequential(
                nn.Conv2d(</a>in_planes, self.expansion<a id="change">*</a>planes<a id="change">, kernel_size=1, stride=stride, bias=False)</a>,
                <a id="change">nn.BatchNorm2d(</a>self.expansion<a id="change">*</a>planes<a id="change">)
            )</a>

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))</code></pre><h3>After Change</h3><pre><code class='java'>
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        <a id="change">if </a><a id="change">groups != 1 or base_width != 64</a>:
            <a id="change">raise ValueError("BasicBlock only supports groups=1 and base_width=64"</a><a id="change">)</a>
        <a id="change">if dilation &gt; 1</a>:
            <a id="change">raise NotImplementedError("Dilation &gt; 1 not supported in BasicBlock"</a><a id="change">)</a>
        &#47&#47 Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = <a id="change">conv3x3(</a>inplanes, planes, stride<a id="change">)</a>
        self.bn1 = norm_layer(planes)
        self.relu<a id="change"> = nn.ReLU(inplace=True)</a>
        self.conv2 = <a id="change">conv3x3(</a>planes, planes<a id="change">)</a>
        self.bn2 = norm_layer(planes)
        self.downsample<a id="change"> = </a>downsample
        self.stride<a id="change"> = </a>stride

    def forward(self, x: Tensor) -&gt; Tensor:
        identity = x</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/decile-team/cords/commit/931f2dbbb853ea9beb25e72b69e473c0365e60ca#diff-580e0813097d831f8f05a21aa69ba247d29cf468b66c336c92f2ad30fa9aa7d9L17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11068972</div><div id='project'> Project Name: decile-team/cords</div><div id='commit'> Commit Name: 931f2dbbb853ea9beb25e72b69e473c0365e60ca</div><div id='time'> Time: 2023-02-04</div><div id='author'> Author: 61333497+krishnatejakk@users.noreply.github.com</div><div id='file'> File Name: cords/utils/models/resnet.py</div><div id='m_class'> M Class Name: BasicBlock</div><div id='n_method'> N Class Name: BasicBlock</div><div id='m_method'> M Method Name: __init__(9)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: cords/utils/models/resnet.py</div><div id='n_file'> N File Name: cords/utils/models/resnet.py</div><div id='m_start'> M Start Line: 17</div><div id='m_end'> M End Line: 31</div><div id='n_start'> N Start Line: 66</div><div id='n_end'> N End Line: 90</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def __init__(self, in_planes, planes, stride=1):
        super(BasicBlock, self).__init__()
        self.conv1 = <a id="change">nn.Conv2d(</a>in_planes, planes<a id="change">, kernel_size=3, stride=stride, padding=1, bias=False)</a>
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = <a id="change">nn.Conv2d(</a>planes, planes<a id="change">, kernel_size=3, stride=1, padding=1, bias=False)</a>
        self.bn2 = nn.BatchNorm2d(planes)

        self.shortcut<a id="change"> = </a><a id="change">nn.Sequential()</a>
        <a id="change">if stride != 1 or in_planes != self.expansion * planes</a>:
            self.shortcut<a id="change"> = </a><a id="change">nn.Sequential(
                nn.Conv2d(</a>in_planes, self.expansion<a id="change"> * </a>planes<a id="change">, kernel_size=1, stride=stride, bias=False)</a>,
                <a id="change">nn.BatchNorm2d(</a>self.expansion<a id="change"> * </a>planes<a id="change">)
            )</a>

    def forward(self, x):
        print(&quot\n input of first convolution:{}&quot.format(x.size()))
        out = F.relu(self.bn1(self.conv1(x)))</code></pre><h3>After Change</h3><pre><code class='java'>
        super(BasicBlock, self).__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        <a id="change">if </a><a id="change">groups != 1 or base_width != 64</a>:
            <a id="change">raise ValueError(&quotBasicBlock only supports groups=1 and base_width=64&quot</a><a id="change">)</a>
        <a id="change">if dilation &gt; 1</a>:
            <a id="change">raise NotImplementedError("Dilation &gt; 1 not supported in BasicBlock"</a><a id="change">)</a>
        &#47&#47 Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = <a id="change">conv3x3(</a>inplanes, planes, stride<a id="change">)</a>
        self.bn1 = norm_layer(planes)
        self.relu<a id="change"> = nn.ReLU(inplace=True)</a>
        self.conv2 = <a id="change">conv3x3(</a>planes, planes<a id="change">)</a>
        self.bn2 = norm_layer(planes)
        self.downsample<a id="change"> = </a>downsample
        self.stride<a id="change"> = </a>stride

    def forward(self, x):
        identity = x</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mdiephuis/simclr/commit/cded7358aca8d4b0d4043c06952a30a0882c05f1#diff-dcfeaa5ac3dffd54264034760914588d92fc7395c81eaa9274715840dc28100bL15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 11068977</div><div id='project'> Project Name: mdiephuis/simclr</div><div id='commit'> Commit Name: cded7358aca8d4b0d4043c06952a30a0882c05f1</div><div id='time'> Time: 2020-03-05</div><div id='author'> Author: shideh.rezaeifar@unige.ch</div><div id='file'> File Name: models.py</div><div id='m_class'> M Class Name: BasicBlock</div><div id='n_method'> N Class Name: BasicBlock</div><div id='m_method'> M Method Name: __init__(9)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models.py</div><div id='n_file'> N File Name: models.py</div><div id='m_start'> M Start Line: 15</div><div id='m_end'> M End Line: 29</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 46</div><BR>