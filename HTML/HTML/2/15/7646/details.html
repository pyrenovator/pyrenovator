<html><h3>Pattern ID :7646
</h3><img src='25389440.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        assert all(kwargs[&quotd_inner&quot][0] == d_inner for d_inner in kwargs[&quotd_inner&quot]), &quotHF Transfo xl does not support heterogenous arch.&quot
        assert all(kwargs[&quotd_head&quot][0] == d_head for d_head in kwargs[&quotd_head&quot]), &quotHF Transfo xl does not support heterogenous arch.&quot
        <a id="change">assert </a>all(kwargs[&quotn_head&quot][0] == n_head for n_head in kwargs[&quotn_head&quot]), &quotHF Transfo xl does not support heterogenous arch.&quot

        kwargs[&quotd_inner&quot] = kwargs[&quotd_inner&quot][0]
        kwargs[&quotn_head&quot] = kwargs[&quotn_head&quot][0]</code></pre><h3>After Change</h3><pre><code class='java'>
    def __init__(self, **kwargs) -&gt; None:
        super(HfTransfoXL, self).__init__()

        <a id="change">kwargs[&quotd_inner&quot] = </a><a id="change">map_to_list(kwargs[&quotd_inner&quot]</a>, <a id="change">kwargs[&quotn_layer&quot]</a><a id="change">)</a>
        kwargs[&quotn_head&quot] = map_to_list(kwargs[&quotn_head&quot], kwargs[&quotn_layer&quot])
        kwargs[&quotd_head&quot] = [kwargs[&quotd_model&quot] // n_h for n_h in kwargs[&quotn_head&quot]] if kwargs[&quotd_head&quot] &lt; 0 else map_to_list(<a id="change">kwargs[&quotd_head&quot]</a>, <a id="change">kwargs[&quotn_layer&quot]</a>)

        assert len(kwargs[&quotd_inner&quot]) == kwargs[&quotn_layer&quot] and len(kwargs[&quotn_head&quot]) == kwargs[&quotn_layer&quot] and len(kwargs[&quotd_head&quot]) == kwargs[&quotn_layer&quot]

        kwargs[&quotd_inner&quot] = kwargs[&quotd_inner&quot][0]
        kwargs[&quotn_head&quot] = kwargs[&quotn_head&quot][0]
        kwargs[&quotd_head&quot] = kwargs[&quotd_head&quot][0]

        if <a id="change">kwargs[&quotd_embed&quot]</a> &lt; 0:
            kwargs[&quotd_embed&quot] = <a id="change">kwargs[&quotd_model&quot]</a>

        &#47&#47 Translate the hyperparameters into Huggingface&quots TransfoXL hyperparameters,
        &#47&#47 and creates the model with the proper configuration
        self.config = self._generate_config(**kwargs)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/microsoft/archai/commit/cbbbc86b6b694e283c9e9f55d2a11b01cb0c6b0f#diff-a95154bb9bee9d8a7137b30d548a8bb3eab76cc227677849de9f6e32f3d71032L45' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25389440</div><div id='project'> Project Name: microsoft/archai</div><div id='commit'> Commit Name: cbbbc86b6b694e283c9e9f55d2a11b01cb0c6b0f</div><div id='time'> Time: 2022-12-16</div><div id='author'> Author: gth.rosa@uol.com.br</div><div id='file'> File Name: archai/nlp/models/hf_transfo_xl/model_hf_transfo_xl.py</div><div id='m_class'> M Class Name: HfTransfoXL</div><div id='n_method'> N Class Name: HfTransfoXL</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: ArchaiModel</div><div id='n_parent_class'> N Parent Class: ArchaiModel</div><div id='m_file'> M File Name: archai/nlp/models/hf_transfo_xl/model_hf_transfo_xl.py</div><div id='n_file'> N File Name: archai/nlp/models/hf_transfo_xl/model_hf_transfo_xl.py</div><div id='m_start'> M Start Line: 54</div><div id='m_end'> M End Line: 56</div><div id='n_start'> N Start Line: 45</div><div id='n_end'> N End Line: 60</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        assert all([n_head * d_head == kwargs[&quotd_embed&quot] for n_head, d_head in zip(kwargs[&quotn_head&quot], kwargs[&quotd_head&quot])]), &quotGPT2 does not support n_head*d_head != d_embed&quot
        assert kwargs[&quotd_model&quot] == kwargs[&quotd_embed&quot], &quotGPT2 does not support d_model != d_embed&quot

        <a id="change">assert </a>all(kwargs[&quotd_inner&quot][0] == d_inner for d_inner in kwargs[&quotd_inner&quot]), &quotGPT2 does not support heterogenous arch.&quot
        assert all(kwargs[&quotd_head&quot][0] == d_head for d_head in kwargs[&quotd_head&quot]), &quotGPT2 does not support heterogenous arch.&quot
        assert all(kwargs[&quotn_head&quot][0] == n_head for n_head in kwargs[&quotn_head&quot]), &quotGPT2 does not support heterogenous arch.&quot
</code></pre><h3>After Change</h3><pre><code class='java'>
    def __init__(self, **kwargs) -&gt; None:
        super(HfGPT2, self).__init__()

        if <a id="change">kwargs[&quotd_embed&quot]</a> &lt; 0:
            kwargs[&quotd_embed&quot] = <a id="change">kwargs[&quotd_model&quot]</a>

        <a id="change">kwargs[&quotd_inner&quot] = </a><a id="change">map_to_list(kwargs[&quotd_inner&quot]</a>, <a id="change">kwargs[&quotn_layer&quot]</a><a id="change">)</a>
        kwargs[&quotn_head&quot] = map_to_list(kwargs[&quotn_head&quot], kwargs[&quotn_layer&quot])
        kwargs[&quotd_head&quot] = [<a id="change">kwargs[&quotd_model&quot]</a> // n_h for n_h in kwargs[&quotn_head&quot]] if kwargs[&quotd_head&quot] &lt; 0 else map_to_list(kwargs[&quotd_head&quot], <a id="change">kwargs[&quotn_layer&quot]</a>)

        assert len(kwargs[&quotd_inner&quot]) == kwargs[&quotn_layer&quot] and len(kwargs[&quotn_head&quot]) == kwargs[&quotn_layer&quot] and len(kwargs[&quotd_head&quot]) == kwargs[&quotn_layer&quot]
        </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/archai/commit/cbbbc86b6b694e283c9e9f55d2a11b01cb0c6b0f#diff-7bbb75d054315a2e3b8cdfea6ab9cb5923bcba124b97bf2d8a357d4f10061867L38' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25389315</div><div id='project'> Project Name: microsoft/archai</div><div id='commit'> Commit Name: cbbbc86b6b694e283c9e9f55d2a11b01cb0c6b0f</div><div id='time'> Time: 2022-12-16</div><div id='author'> Author: gth.rosa@uol.com.br</div><div id='file'> File Name: archai/nlp/models/hf_gpt2/model_hf_gpt2.py</div><div id='m_class'> M Class Name: HfGPT2</div><div id='n_method'> N Class Name: HfGPT2</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: ArchaiModel</div><div id='n_parent_class'> N Parent Class: ArchaiModel</div><div id='m_file'> M File Name: archai/nlp/models/hf_gpt2/model_hf_gpt2.py</div><div id='n_file'> N File Name: archai/nlp/models/hf_gpt2/model_hf_gpt2.py</div><div id='m_start'> M Start Line: 46</div><div id='m_end'> M End Line: 55</div><div id='n_start'> N Start Line: 37</div><div id='n_end'> N End Line: 48</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        assert all(kwargs[&quotd_inner&quot][0] == d_inner for d_inner in kwargs[&quotd_inner&quot]), &quotHF Transfo xl does not support heterogenous arch.&quot
        assert all(kwargs[&quotd_head&quot][0] == d_head for d_head in kwargs[&quotd_head&quot]), &quotHF Transfo xl does not support heterogenous arch.&quot
        <a id="change">assert </a>all(kwargs[&quotn_head&quot][0] == n_head for n_head in kwargs[&quotn_head&quot]), &quotHF Transfo xl does not support heterogenous arch.&quot

        kwargs[&quotd_inner&quot] = kwargs[&quotd_inner&quot][0]
        kwargs[&quotn_head&quot] = kwargs[&quotn_head&quot][0]</code></pre><h3>After Change</h3><pre><code class='java'>
    def __init__(self, **kwargs) -&gt; None:
        super(HfTransfoXL, self).__init__()

        <a id="change">kwargs[&quotd_inner&quot] = </a><a id="change">map_to_list(kwargs[&quotd_inner&quot]</a>, <a id="change">kwargs[&quotn_layer&quot]</a><a id="change">)</a>
        kwargs[&quotn_head&quot] = map_to_list(kwargs[&quotn_head&quot], kwargs[&quotn_layer&quot])
        <a id="change">kwargs[&quotd_head&quot]</a> = [kwargs[&quotd_model&quot] // n_h for n_h in kwargs[&quotn_head&quot]] if kwargs[&quotd_head&quot] &lt; 0 else map_to_list(<a id="change">kwargs[&quotd_head&quot]</a>, <a id="change">kwargs[&quotn_layer&quot]</a>)

        assert len(kwargs[&quotd_inner&quot]) == kwargs[&quotn_layer&quot] and len(kwargs[&quotn_head&quot]) == kwargs[&quotn_layer&quot] and len(kwargs[&quotd_head&quot]) == kwargs[&quotn_layer&quot]

        kwargs[&quotd_inner&quot] = kwargs[&quotd_inner&quot][0]
        kwargs[&quotn_head&quot] = kwargs[&quotn_head&quot][0]
        kwargs[&quotd_head&quot] = kwargs[&quotd_head&quot][0]

        if <a id="change">kwargs[&quotd_embed&quot]</a> &lt; 0:
            kwargs[&quotd_embed&quot] = kwargs[&quotd_model&quot]

        &#47&#47 Translate the hyperparameters into Huggingface&quots TransfoXL hyperparameters,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/archai/commit/cbbbc86b6b694e283c9e9f55d2a11b01cb0c6b0f#diff-a95154bb9bee9d8a7137b30d548a8bb3eab76cc227677849de9f6e32f3d71032L45' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25389446</div><div id='project'> Project Name: microsoft/archai</div><div id='commit'> Commit Name: cbbbc86b6b694e283c9e9f55d2a11b01cb0c6b0f</div><div id='time'> Time: 2022-12-16</div><div id='author'> Author: gth.rosa@uol.com.br</div><div id='file'> File Name: archai/nlp/models/hf_transfo_xl/model_hf_transfo_xl.py</div><div id='m_class'> M Class Name: HfTransfoXL</div><div id='n_method'> N Class Name: HfTransfoXL</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: ArchaiModel</div><div id='n_parent_class'> N Parent Class: ArchaiModel</div><div id='m_file'> M File Name: archai/nlp/models/hf_transfo_xl/model_hf_transfo_xl.py</div><div id='n_file'> N File Name: archai/nlp/models/hf_transfo_xl/model_hf_transfo_xl.py</div><div id='m_start'> M Start Line: 54</div><div id='m_end'> M End Line: 56</div><div id='n_start'> N Start Line: 45</div><div id='n_end'> N End Line: 60</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if kwargs[&quotd_embed&quot] == -1:
            kwargs[&quotd_embed&quot] = kwargs[&quotd_model&quot]

        <a id="change">assert </a>all(elem == kwargs[&quotn_head&quot][0] for elem in kwargs[&quotn_head&quot]), &quotGPT2 does not accept heterogenous arch.&quot
        assert all(elem == kwargs[&quotd_head&quot][0] for elem in kwargs[&quotd_head&quot]), &quotGPT2 does not accept heterogenous arch.&quot
        assert all(elem == kwargs[&quotd_inner&quot][0] for elem in kwargs[&quotd_inner&quot]), &quotGPT2 does not accept heterogenous arch.&quot
</code></pre><h3>After Change</h3><pre><code class='java'>
        if kwargs[&quotd_embed&quot] == -1:
            kwargs[&quotd_embed&quot] = kwargs[&quotd_model&quot]

        d_inner = <a id="change">map_to_list(kwargs[&quotd_inner&quot]</a>, <a id="change">kwargs[&quotn_layer&quot]</a><a id="change">)</a>
        n_head = map_to_list(<a id="change">kwargs[&quotn_head&quot]</a>, <a id="change">kwargs[&quotn_layer&quot]</a>)
        d_head = [<a id="change">kwargs[&quotd_model&quot]</a> // n_h for n_h in kwargs[&quotn_head&quot]] if kwargs[&quotd_head&quot] is None else map_to_list(kwargs[&quotd_head&quot], <a id="change">kwargs[&quotn_layer&quot]</a>)

        assert len(d_inner) == kwargs[&quotn_layer&quot] and len(n_head) == kwargs[&quotn_layer&quot] and len(d_head) == kwargs[&quotn_layer&quot]

        <a id="change">kwargs[&quotd_inner&quot] = </a>d_inner[0]
        kwargs[&quotn_head&quot] = n_head[0]
        kwargs[&quotd_head&quot] = d_head[0]
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/archai/commit/62e9f8d85e3bb623cd54851042810ed285f7500a#diff-3e61c829b327d2c58f1109f07973467803821d3efbb62dbb835d96a1e645e85bL32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25389502</div><div id='project'> Project Name: microsoft/archai</div><div id='commit'> Commit Name: 62e9f8d85e3bb623cd54851042810ed285f7500a</div><div id='time'> Time: 2022-12-16</div><div id='author'> Author: gth.rosa@uol.com.br</div><div id='file'> File Name: archai/nlp/nvidia_transformer_xl/models/hf_gpt2.py</div><div id='m_class'> M Class Name: HfGPT2</div><div id='n_method'> N Class Name: HfGPT2</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: ArchaiModel</div><div id='n_parent_class'> N Parent Class: ArchaiModel</div><div id='m_file'> M File Name: archai/nlp/nvidia_transformer_xl/models/hf_gpt2.py</div><div id='n_file'> N File Name: archai/nlp/nvidia_transformer_xl/models/hf_gpt2.py</div><div id='m_start'> M Start Line: 36</div><div id='m_end'> M End Line: 44</div><div id='n_start'> N Start Line: 37</div><div id='n_end'> N End Line: 47</div><BR>