<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        return loss

    def validation_step(self, batch: TransformerSpanClassificationModelStepBatchEncoding, batch_idx):  &#47&#47 type: ignore
        <a id="change">input_</a><a id="change">, target_tuples</a> = batch
        assert target_tuples is not None, "target has to be available for validation"

        output = <a id="change">self(input_</a><a id="change">)</a>

        logits = output["logits"]

        batch_size, seq_length = input_["input_ids"].shape
        seq_lengths = None
        if "attention_mask" in input_:
            seq_lengths = torch.sum(input_["attention_mask"], dim=-1)

        &#47&#47 TODO: Why is this not happening in TransformerSpanClassificationTaskModule.collate?
        target = self._expand_target_tuples(
            target_tuples=target_tuples,
            batch_size=batch_size,
            max_seq_length=seq_length,
            seq_lengths=seq_lengths,
        )
        target<a id="change"> = </a>target.to(logits.device)

        <a id="change">loss</a><a id="change"> = self.loss_fct(</a>logits, target<a id="change">)</a>

        <a id="change">self.log("val/loss"</a>, <a id="change">loss</a><a id="change">, on_step=False, on_epoch=True, prog_bar=True)</a>

        self.val_f1(logits, target)
        <a id="change">self.log("val/f1"</a>, self.val_f1<a id="change">, on_step=False, on_epoch=True, prog_bar=True)</a>

        <a id="change">return loss</a>

    def configure_optimizers(self):
        param_optimizer = list(self.named_parameters())
        &#47&#47 TODO: this needs fixing (does not work models other than BERT)</code></pre><h3>After Change</h3><pre><code class='java'>
        return self.step(stage=TRAINING, batch=batch, batch_idx=batch_idx)

    def validation_step(self, batch: TransformerSpanClassificationModelStepBatchEncoding, batch_idx: int):  &#47&#47 type: ignore
        <a id="change">return </a><a id="change">self.step(stage=VALIDATION, batch=batch, batch_idx=batch_idx)</a>

    def test_step(self, batch: TransformerSpanClassificationModelStepBatchEncoding, batch_idx: int):  &#47&#47 type: ignore
        return self.step(stage=TEST, batch=batch, batch_idx=batch_idx)
</code></pre>