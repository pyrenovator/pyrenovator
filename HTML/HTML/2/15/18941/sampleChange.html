<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 Forward through models
    target = trans([example_clip])[0]

    outputs = <a id="change">[]</a>
    &#47&#47 Manual zero pad (due to padding=1 in trans.b Conv3d)
    zeros = torch.zeros_like(example_clip[:, :, 0])
    outputs.append(cotrans.forward([zeros])[0])
    outputs.append(cotrans.forward([zeros])[0])
    <a id="change">for i</a> in <a id="change">range(example_clip.shape[2]</a><a id="change">):
        outputs.append(</a>cotrans.forward(<a id="change">[example_clip</a><a id="change">[:, :, i]</a>])[0]<a id="change">)</a>
    outputs.append(cotrans.forward([zeros])[0])
    outputs.append(cotrans.forward([zeros])[0])

    &#47&#47 For debugging:
    &#47&#47 close = []
    &#47&#47 for t in range(target.shape[2]):
    &#47&#47     for i in range(len(outputs)):
    &#47&#47         if torch.allclose(target[:, :, t], outputs[i], atol=5e-4):
    &#47&#47             close.append(f"t = {t}, o = {i}")

    shift = 4  &#47&#47 kernel[0] - 1

    for t in range(1, target.shape[2]):
        assert torch.allclose(target[:, :, t], outputs[t + shift])

    &#47&#47 forward_steps also works
    outputs2 = <a id="change">cotrans.forward_steps([example_clip])[0]</a>
    assert torch.allclose(target, outputs2)
</code></pre><h3>After Change</h3><pre><code class='java'>
        temporal_fill="zeros",
    )
    cotrans.load_state_dict(trans.state_dict(), flatten=True)
    <a id="change">assert </a>cotrans.delay == 2

    &#47&#47 Training mode has large effect on BatchNorm result - test will fail otherwise
    trans.eval()</code></pre>