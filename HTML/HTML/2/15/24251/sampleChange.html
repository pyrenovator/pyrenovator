<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    updater = NoisyGradientAscent(env_discrete, model_discrete)
    updater.initialize_population(starting_point=model_discrete.numpy())
    assert np.issubdtype(updater.population.dtype, np.integer)
    np.testing.assert_allclose(<a id="change">np.std(</a>updater.population<a id="change">, axis=0)</a>, <a id="change">np.ones(1</a><a id="change">)</a>, rtol=0.1)
    np.testing.assert_allclose(
        np.mean(updater.population, axis=0), np.array([5]), rtol=0.1
    )</code></pre><h3>After Change</h3><pre><code class='java'>
        space=env_discrete.single_action_space, state=np.array([5])
    )
    critic = DummyCritic(space=env_discrete.single_action_space)
    <a id="change">model_discrete = </a><a id="change">ActorCritic(
        actor=actor_discrete,
        critic=critic,
        population_settings=PopulationSettings(actor_population_size=POPULATION_SIZE),
    )</a>

    &#47&#47 ASSERT POPULATION STATS
    updater<a id="change"> = </a>NoisyGradientAscent(model_discrete)
    &#47&#47 make sure the population has been discretized
    assert np.issubdtype(model_discrete.numpy_actors().dtype, np.integer)
    &#47&#47 make sure starting population mean is correct
    np.testing.assert_allclose(
        np.mean(<a id="change">model_discrete.numpy_actors()</a>, axis=0), np.array([5]), rtol=0.1
    )

    &#47&#47 Test call
    old_model<a id="change"> = </a><a id="change">copy.deepcopy(model_discrete</a><a id="change">)</a>
    old_population<a id="change"> = model_discrete</a><a id="change">.numpy_actors()</a>
    action = model_discrete(np.zeros(POPULATION_SIZE))
    _, rewards, _, _ = env_discrete.step(action)
    scaled_rewards = (rewards - np.mean(rewards)) / np.std(rewards)
    optimization_direction = np.dot(updater.normal_dist.T, scaled_rewards)
    log = updater(learning_rate=1e-5, optimization_direction=optimization_direction)
    new_population<a id="change"> = model_discrete</a><a id="change">.numpy_actors()</a>
    assert log.divergence &gt; 0
    &#47&#47 make sure the nerual network has been updated by the updater
    assert model_discrete != old_model
    assert np.not_equal(old_population, new_population).any()</code></pre>