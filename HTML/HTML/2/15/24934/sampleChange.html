<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        else:
            p_ctc, p_seq, wav_lens, hyps = predictions

        ids<a id="change">, phns, phn_lens</a> = targets
        phns, phn_lens = phns.to(self.device), phn_lens.to(self.device)

        if hasattr(self.hparams, "env_corrupt") and stage == sb.Stage.TRAIN:
            phns = torch.cat([phns, phns], dim=0)
            phn_lens = torch.cat([phn_lens, phn_lens], dim=0)

        &#47&#47 Add phn_lens by one for eos token
        abs_length = <a id="change">torch.round(phn_lens</a><a id="change"> * phns.shape[1]</a><a id="change">)</a>

        &#47&#47 Append eos token at the end of the label sequences
        phns_with_eos<a id="change"> = sb.data_io.data_io.append_eos_token(
            </a>phns<a id="change">, length=abs_length, eos_index=self.hparams.eos_index
        )</a>

        &#47&#47 convert to speechbrain-style relative length
        rel_length<a id="change"> = </a>(abs_length<a id="change"> + 1</a>)<a id="change"> / phns_with_eos.shape[1]</a>

        loss_ctc = self.hparams.ctc_cost(p_ctc, phns, wav_lens, phn_lens)
        loss_seq = self.hparams.seq_cost(p_seq, phns_with_eos, rel_length)
        loss = self.hparams.ctc_weight * loss_ctc</code></pre><h3>After Change</h3><pre><code class='java'>
            p_ctc, p_seq, wav_lens, hyps = predictions

        ids = batch.id
        phns_eos<a id="change">, phn_lens_eos</a> = batch.phn_encoded_eos
        phns, phn_lens = batch.phn_encoded

        if hasattr(self.modules, "env_corrupt") and stage == sb.Stage.TRAIN:</code></pre>