<html><h3>Pattern ID :36987
</h3><img src='105243589.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            raise NotImplementedError
        policy_loss_value = policy_loss.detach().cpu().numpy()
        self.policy_optimizer.zero_grad()
        <a id="change">policy_loss.backward()</a>
        self.policy_optimizer.step()

        self.tot_update_count += 1
        </code></pre><h3>After Change</h3><pre><code class='java'>
        policy_loss_value = policy_loss.detach().cpu().numpy()

        &#47&#47entropy loss
        entropy_loss<a id="change"> = </a>-torch.mean(dist_entropy)
        entropy_loss_value<a id="change"> =  </a><a id="change">entropy_loss.detach()</a>.cpu().numpy()
        tot_loss = v_loss + entropy_loss + policy_loss

        self.policy_optimizer.zero_grad()</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/x35f/unstable_baselines/commit/5af9f89c6d399a424b451a524af66c97ab900df8#diff-52f03432c99c716ff4dd3aab99ae6fafde4ebca9abe1cdbec481a8fee78251bcL78' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 105243589</div><div id='project'> Project Name: x35f/unstable_baselines</div><div id='commit'> Commit Name: 5af9f89c6d399a424b451a524af66c97ab900df8</div><div id='time'> Time: 2021-03-30</div><div id='author'> Author: 1621322691@qq.com</div><div id='file'> File Name: ppo/model.py</div><div id='m_class'> M Class Name: PPOAgent</div><div id='n_method'> N Class Name: PPOAgent</div><div id='m_method'> M Method Name: update(2)</div><div id='n_method'> N Method Name: update(2)</div><div id='m_parent_class'> M Parent Class: BaseAgent,torch.nn.Module</div><div id='n_parent_class'> N Parent Class: BaseAgent,torch.nn.Module</div><div id='m_file'> M File Name: ppo/model.py</div><div id='n_file'> N File Name: ppo/model.py</div><div id='m_start'> M Start Line: 78</div><div id='m_end'> M End Line: 118</div><div id='n_start'> N Start Line: 79</div><div id='n_end'> N End Line: 125</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 if do_Dmain:
            &#47&#47     loss4 += loss3
            &#47&#47 loss4.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。
            <a id="change">(real_logits * 0 + loss_Dreal + loss_Dr1).mean().mul(gain).backward()</a>
        return loss_numpy

    def train_iter(self, optimizers=None):
        phase_real_img = self.input[0]</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 print(&quotddd=%.6f&quot % ddd)

            loss_Gmain = torch.nn.functional.softplus(-gen_logits)  &#47&#47 -log(sigmoid(gen_logits))
            loss_Gmain<a id="change"> = </a>loss_Gmain.mean()
            loss_numpy[&quotloss_Gmain&quot]<a id="change"> = </a><a id="change">loss_Gmain.cpu().detach()</a>.numpy()

            loss_G = loss_Gmain
            loss_G = loss_G * float(gain)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/miemie2013/miemiegan/commit/fbc8738996ce75111be885ba7ac313d85969a2b8#diff-c3be3e49b4968a2ee433a8b0d38c7aa9f68d5116602220ff22567e41b765b44bL134' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 105243591</div><div id='project'> Project Name: miemie2013/miemiegan</div><div id='commit'> Commit Name: fbc8738996ce75111be885ba7ac313d85969a2b8</div><div id='time'> Time: 2022-02-25</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_class'> M Class Name: StyleGANv2ADAModel</div><div id='n_method'> N Class Name: StyleGANv2ADAModel</div><div id='m_method'> M Method Name: accumulate_gradients(8)</div><div id='n_method'> N Method Name: accumulate_gradients(8)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='n_file'> N File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_start'> M Start Line: 138</div><div id='m_end'> M End Line: 260</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 262</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                              mix_data[x][&quotrdf_range&quot],
                              f&quot{model_path}/x_{x}_{str(i).zfill(3)}_rdf.pdf&quot)

        <a id="change">loss.backward()</a>
        optimizer.step()
        optimizer.zero_grad()

        print(loss.item())</code></pre><h3>After Change</h3><pre><code class='java'>

        all_rdf11 = []
        all_rdf12 = []
        all_rdf22<a id="change"> = </a>[] 

        for epoch in range(params[&quotupdate_epoch&quot]):
            for x in params[&quottrainx&quot]:
                tau = params[&quotnsteps&quot]
                v_t, q_t, pv_t = train_sys[x].sim.simulate(steps=tau, dt=0.005, frequency=tau)

                &#47&#47 check for NaN
                if torch.isnan(q_t.reshape(-1)).sum().item() &gt; 0:
                    print("encounter NaN")
                    return 10.0, True 

                _, _, sim_rdf11 = train_sys[x].rdf11(q_t)
                _, _, sim_rdf12 = train_sys[x].rdf12(q_t)
                _, _, sim_rdf22 = train_sys[x].rdf22(q_t)

                loss_ = (sim_rdf11 - torch.Tensor(train_sys[x].target_rdf11).to(device) ).pow(2).mean() + \
                        (sim_rdf12 - torch.Tensor(train_sys[x].target_rdf12).to(device) ).pow(2).mean() + \
                        (sim_rdf22 - torch.Tensor(train_sys[x].target_rdf22).to(device) ).pow(2).mean() 

                all_rdf11.append(sim_rdf11)
                all_rdf12.append(sim_rdf12)
                all_rdf22.append(sim_rdf22)

                loss_.backward()

                loss += loss_.item()
        
        optimizer.step()
        optimizer.zero_grad()
 
        if i % 5 == 0:

            mean_all_rdf11 = torch.stack(all_rdf11).detach().cpu().mean(0)
            mean_all_rdf12 = torch.stack(all_rdf12).detach().cpu().mean(0)
            mean_all_rdf22<a id="change"> = </a><a id="change">torch.stack(all_rdf22).detach()</a>.cpu().mean(0)

            plot_pairs(train_sys[x].sim, pair11, pair12, pair22, fn=f&quot{model_path}/x_{x}_{str(i).zfill(3)}_pot.pdf&quot)
            plot_sim_rdfs(mean_all_rdf11, mean_all_rdf12, mean_all_rdf22, </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/torchmd/mdgrad/commit/4a43676cd6950ce8bf34276d9c4fefcd081b35d7#diff-d331fc48ce4f2b9fd362780953537bd16aa4b7953175b6398d824bf57f626df7L137' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 105243590</div><div id='project'> Project Name: torchmd/mdgrad</div><div id='commit'> Commit Name: 4a43676cd6950ce8bf34276d9c4fefcd081b35d7</div><div id='time'> Time: 2022-01-28</div><div id='author'> Author: wwj@mit.edu</div><div id='file'> File Name: scripts/fit_mix.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: run_mix(1)</div><div id='n_method'> N Method Name: run_mix(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/fit_mix.py</div><div id='n_file'> N File Name: scripts/fit_mix.py</div><div id='m_start'> M Start Line: 199</div><div id='m_end'> M End Line: 230</div><div id='n_start'> N Start Line: 202</div><div id='n_end'> N End Line: 250</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        policy_loss = torch.mean( (self.alpha * new_curr_state_log_pi) - min_curr_state_q_value)
        policy_loss_value = policy_loss.detach().cpu().numpy()
        self.policy_optimizer.zero_grad()
        <a id="change">self.policy_loss.backward()</a>
        self.policy_optimizer.step()

        &#47&#47compute temperature loss
        if self.automatic_entropy_tuning:</code></pre><h3>After Change</h3><pre><code class='java'>

    def update(self, data_batch):
        state_batch, action_batch, next_state_batch, reward_batch, done_batch = data_batch
        curr_state_q1_value<a id="change"> = </a>self.q1_network(state_batch, action_batch)
        curr_state_q2_value = self.q2_network(state_batch, action_batch)
        new_curr_state_action, new_curr_state_log_pi, _ = self.policy_network.sample(state_batch)
        next_state_target_v_value = self.target_v_network(next_state_batch)
        curr_state_v_value = self.v_network(state_batch)
        new_curr_state_q1_value = self.q1_network(state_batch, new_curr_state_action)
        new_curr_state_q2_value = self.q2_network(state_batch, new_curr_state_action)

        min_curr_state_q_value = torch.min(curr_state_q1_value, curr_state_q2_value)
        new_min_curr_state_q_value = torch.min(new_curr_state_q1_value, new_curr_state_q2_value)


        &#47&#47compute v loss
        target_v_value<a id="change"> = </a><a id="change">(min_curr_state_q_value - new_curr_state_log_pi).detach()</a>
        v_loss = F.mse_loss(curr_state_v_value, target_v_value)
        v_loss_value = v_loss.detach().cpu().numpy()
        self.v_optimizer.zero_grad()
        v_loss.backward()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/x35f/unstable_baselines/commit/e977236fade6fe13bf98ed7225bf269e766b9ecc#diff-5db644cd5bd54e3d73a4e86c3b2e245fd8f43751389307d15efbb99043bc1b0fL70' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 105243581</div><div id='project'> Project Name: x35f/unstable_baselines</div><div id='commit'> Commit Name: e977236fade6fe13bf98ed7225bf269e766b9ecc</div><div id='time'> Time: 2021-03-09</div><div id='author'> Author: 1621322691@qq.com</div><div id='file'> File Name: sac/models.py</div><div id='m_class'> M Class Name: SACAgent</div><div id='n_method'> N Class Name: SACAgent</div><div id='m_method'> M Method Name: update(2)</div><div id='n_method'> N Method Name: update(2)</div><div id='m_parent_class'> M Parent Class: BaseAgent,torch.nn.Module</div><div id='n_parent_class'> N Parent Class: BaseAgent,torch.nn.Module</div><div id='m_file'> M File Name: sac/models.py</div><div id='n_file'> N File Name: sac/models.py</div><div id='m_start'> M Start Line: 73</div><div id='m_end'> M End Line: 121</div><div id='n_start'> N Start Line: 72</div><div id='n_end'> N End Line: 124</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            raise NotImplementedError
        policy_loss_value = policy_loss.detach().cpu().numpy()
        self.policy_optimizer.zero_grad()
        <a id="change">policy_loss.backward()</a>
        self.policy_optimizer.step()

        &#47&#47compute value loss
        v_loss = F.mse_loss(curr_state_v, future_return_batch)</code></pre><h3>After Change</h3><pre><code class='java'>
        state_batch, action_batch, log_pi_batch, next_state_batch, reward_batch, future_return_batch, done_batch = data_batch
        
        curr_state_v = self.v_network(state_batch)
        next_state_v<a id="change"> = </a>self.v_network(next_state_batch)
        new_log_pi, dist_entropy = self.policy_network.evaluate_actions(state_batch, action_batch)
        ratio_batch = torch.exp(new_log_pi - log_pi_batch)
        
        &#47&#47delta = reward_batch + self.gamma * (1 - done_batch) * next_state_v - curr_state_v
        if self.advantage_type == "mc":
            advantages = future_return_batch - curr_state_v.detach()
        elif self.advantage_type == &quottd&quot:
            advantages<a id="change"> = </a><a id="change">(reward_batch + (1.0 - done_batch) * self.gamma * next_state_v - curr_state_v).detach()</a>
        elif self.advantage_type == "gae":
            raise NotImplementedError
        else:
            raise NotImplementedError</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/x35f/unstable_baselines/commit/f41e2cf788d0214add3fb342aee698910c63e651#diff-52f03432c99c716ff4dd3aab99ae6fafde4ebca9abe1cdbec481a8fee78251bcL74' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 105243614</div><div id='project'> Project Name: x35f/unstable_baselines</div><div id='commit'> Commit Name: f41e2cf788d0214add3fb342aee698910c63e651</div><div id='time'> Time: 2021-04-01</div><div id='author'> Author: 1621322691@qq.com</div><div id='file'> File Name: ppo/model.py</div><div id='m_class'> M Class Name: PPOAgent</div><div id='n_method'> N Class Name: PPOAgent</div><div id='m_method'> M Method Name: update(2)</div><div id='n_method'> N Method Name: update(2)</div><div id='m_parent_class'> M Parent Class: BaseAgent,torch.nn.Module</div><div id='n_parent_class'> N Parent Class: BaseAgent,torch.nn.Module</div><div id='m_file'> M File Name: ppo/model.py</div><div id='n_file'> N File Name: ppo/model.py</div><div id='m_start'> M Start Line: 83</div><div id='m_end'> M End Line: 126</div><div id='n_start'> N Start Line: 79</div><div id='n_end'> N End Line: 137</div><BR>