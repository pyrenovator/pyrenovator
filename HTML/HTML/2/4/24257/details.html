<html><h3>Pattern ID :24257
</h3><img src='75312061.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            mean_entity = 0.
            real_number = real_number_tensor[i]
            real_number = real_number if real_number != 0 else 1
            <a id="change">for </a>j, entity in <a id="change">enumerate(</a>batch<a id="change">):
                </a>if j &gt;= real_number_tensor[i]:
                    break        
                mean_entity = mean_entity + entity
            mean_entity = mean_entity / (real_number)</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 generate the mask for transformer
        mask = torch.arange(0, self.max_entities).float()
        mask = <a id="change">mask.repeat(</a>batch_size, 1<a id="change">)</a>
        mask = mask &lt; entity_num.unsqueeze(dim=1)

        print(&quotmask:&quot, mask) if debug else None
        print(&quotmask.shape:&quot, mask.shape) if debug else None

        &#47&#47 mask: [batch_size, max_entities]
        device = next(self.parameters()).device
        mask = mask.to(device)

        &#47&#47 assert the input shape is : batch_seq_size x entities_size x embeding_size
        &#47&#47 note: because the feature size of entity is not equal to 256, so it can not fed into transformer directly.
        &#47&#47 thus, we add a embedding layer to transfer it to right size.
        &#47&#47 x is batch_entities_tensor (dim = 3). Shape: batch_seq_size x entities_size x embeding_size
        x = self.embedd(x)
        print(&quotx.shape:&quot, x.shape) if debug else None

        &#47&#47 mask for transformer need a special format
        mask_seq_len<a id="change"> = </a>mask.shape[-1]
        tran_mask = mask.unsqueeze(1)

        &#47&#47 tran_mask: [batch_seq_size x max_entities x max_entities]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/liuruoze/mini-alphastar/commit/612d42a7bf5ef827e1e919198d839fce106155cd#diff-71869e70f9cb835282d541d2d3529d25b6ed6795c79bc770e860e9318619f6b1L716' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75312061</div><div id='project'> Project Name: liuruoze/mini-alphastar</div><div id='commit'> Commit Name: 612d42a7bf5ef827e1e919198d839fce106155cd</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: liuruoze@163.com</div><div id='file'> File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_class'> M Class Name: EntityEncoder</div><div id='n_method'> N Class Name: EntityEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='n_file'> N File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_start'> M Start Line: 721</div><div id='m_end'> M End Line: 758</div><div id='n_start'> N Start Line: 716</div><div id='n_end'> N End Line: 778</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        res = (random_uni + indices) * dy

        &#47&#47 Note this loop is tricky to vectorize as cubes have different N
        <a id="change">for </a>idx, N in <a id="change">enumerate(</a>nevals<a id="change">):
            </a>res_in_all_cubes.append(res[idx, 0:N, :])

        return anp.concatenate(res_in_all_cubes, axis=0, like=res)
</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 Autoray doesn&quott yet support repeat.
            position_indices = anp.repeat_interleave(nevals_arange, nevals)
        else:
            position_indices<a id="change"> = </a><a id="change">anp.repeat(</a>nevals_arange, nevals<a id="change">)</a>
        positions = positions[position_indices, :]

        &#47&#47 Convert the positions to float, add random offsets to them and scale
        &#47&#47 the result so that each point is in [0, 1)^dim</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/esa/torchquad/commit/3d6c190f15cccfe658bb7d78ffdd0977d65b38c2#diff-043ebca7e1b0e1177dca8d0ce7bca0efc00f0a68c90edeea6b272ff39505e0e2L150' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75312013</div><div id='project'> Project Name: esa/torchquad</div><div id='commit'> Commit Name: 3d6c190f15cccfe658bb7d78ffdd0977d65b38c2</div><div id='time'> Time: 2022-03-14</div><div id='author'> Author: ga84muv@mytum.de</div><div id='file'> File Name: torchquad/integration/vegas_stratification.py</div><div id='m_class'> M Class Name: VEGASStratification</div><div id='n_method'> N Class Name: VEGASStratification</div><div id='m_method'> M Method Name: get_Y(2)</div><div id='n_method'> N Method Name: get_Y(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torchquad/integration/vegas_stratification.py</div><div id='n_file'> N File Name: torchquad/integration/vegas_stratification.py</div><div id='m_start'> M Start Line: 159</div><div id='m_end'> M End Line: 187</div><div id='n_start'> N Start Line: 161</div><div id='n_end'> N End Line: 179</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    
    batch_size, seq_len, vocab_size = logits.size()
    mask_positions_after_reshaped = []
    for batch, mask_pos in <a id="change">enumerate(</a>mask_positions.detach().cpu().numpy().tolist()<a id="change">)</a>:
        <a id="change">for </a>pos in mask_pos<a id="change">:
            </a>mask_positions_after_reshaped.append(batch * seq_len + pos)
    
    logits = logits.reshape(batch_size * seq_len, -1)                           &#47&#47 (batch_size * seq_len, vocab_size)
    mask_logits = logits[mask_positions_after_reshaped]                         &#47&#47 (batch * label_num, vocab_size)</code></pre><h3>After Change</h3><pre><code class='java'>
    loss = None
    for single_logits, single_sub_mask_labels, single_mask_positions in zip(logits, sub_mask_labels, mask_positions):
        single_mask_logits = single_logits[single_mask_positions]                           &#47&#47 (mask_label_num, vocab_size)
        single_mask_logits = <a id="change">single_mask_logits.repeat(</a>len(single_sub_mask_labels), 1, 1<a id="change">)</a>   &#47&#47 (sub_label_num, mask_label_num, vocab_size)
        single_mask_logits = single_mask_logits.reshape(-1, vocab_size)                     &#47&#47 (sub_label_num * mask_label_num, vocab_size)
        single_sub_mask_labels = torch.LongTensor(single_sub_mask_labels).to(device)        &#47&#47 (sub_label_num, mask_label_num)
        single_sub_mask_labels = single_sub_mask_labels.reshape(-1, 1).squeeze()            &#47&#47 (sub_label_num * mask_label_num)
        cur_loss = cross_entropy_criterion(single_mask_logits, single_sub_mask_labels)
        cur_loss = cur_loss / len(single_sub_mask_labels)
        if not loss:
            loss = cur_loss
        else:
            loss<a id="change"> += </a>cur_loss
    loss = loss / batch_size                                                                &#47&#47 (1,)
    return loss / masked_lm_scale
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/harderthenharder/transformers_tasks/commit/bf825bb22c43795f1e3a08cf8969ddc613051e76#diff-8c36ce9e3ab2da910c520055f7c89509da251069c3ed661eb343bdade6fe30edL181' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75312062</div><div id='project'> Project Name: harderthenharder/transformers_tasks</div><div id='commit'> Commit Name: bf825bb22c43795f1e3a08cf8969ddc613051e76</div><div id='time'> Time: 2022-11-30</div><div id='author'> Author: pankeyu@pankeyus-MacBook-Pro.local</div><div id='file'> File Name: prompt_tasks/p-tuning/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mlm_loss(6)</div><div id='n_method'> N Method Name: mlm_loss(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: prompt_tasks/p-tuning/utils.py</div><div id='n_file'> N File Name: prompt_tasks/p-tuning/utils.py</div><div id='m_start'> M Start Line: 204</div><div id='m_end'> M End Line: 212</div><div id='n_start'> N Start Line: 190</div><div id='n_end'> N End Line: 203</div><BR>