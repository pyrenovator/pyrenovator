<html><h3>Pattern ID :37607
</h3><img src='108140328.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

def main():
    config = load_config()
    tokenizer<a id="change"> = </a>BertTokenizer.from_pretrained(TOKENIZER_DIR)
    transformer = Transformer.load_from_checkpoint(TRANSFORMER_CKPT)
    transformer.eval()
    seoul2jeju = load_seoul2jeju()[:10]
    seouls = [seoul <a id="change">for</a> seoul, _ in seoul2jeju]
    jejus = [jeju for _, jeju in seoul2jeju]
    X = InferInputsBuilder(tokenizer, config[&quotmax_length&quot])(srcs=jejus)
    tgt_ids = transformer.predict(X)
    for pred, ans in <a id="change">zip(</a>tgt_ids.tolist(), seouls<a id="change">)</a>:
        print(tokenizer.decode(pred), "|", ans)

</code></pre><h3>After Change</h3><pre><code class='java'>
    parser.add_argument("--jeju", type=str, default="딱 그 말을 허드라게")
    args = parser.parse_args()
    config = load_config()
    <a id="change">config.update(</a>vars(args)<a id="change">)</a>
    with wandb.init(entity="eubinecto", project="dekorde") as run:
        artifact = run.use_artifact("transformer:latest")
        artifact.checkout()
    transformer_ckpt, tokenizer_dir = transformer_paths()</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/eubinecto/dekorde/commit/fd3b05ba0d98e727d7c58233ac0e8c0449890275#diff-239c9195f0b1188d5807fd9c603d9918e73ee42ade63e6f829ba093be9ee0f2fL10' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 108140328</div><div id='project'> Project Name: eubinecto/dekorde</div><div id='commit'> Commit Name: fd3b05ba0d98e727d7c58233ac0e8c0449890275</div><div id='time'> Time: 2021-12-06</div><div id='author'> Author: eubinecto</div><div id='file'> File Name: main_predict.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: main_predict.py</div><div id='n_file'> N File Name: main_predict.py</div><div id='m_start'> M Start Line: 10</div><div id='m_end'> M End Line: 19</div><div id='n_start'> N Start Line: 11</div><div id='n_end'> N End Line: 27</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        expected = [(key, func(x)) for key, x in all_examples]
    else:
        &#47&#47 For batched map we have to format the examples as a batch (i.e. in one single dictionary) to pass the batch to the function
        expected_examples_per_batch<a id="change"> = </a>[
            list(_batch_to_examples(func(_examples_to_batch([x for _, x in all_examples[i : i + batch_size]]))))
            for i in range(0, len(all_examples), batch_size)
        ]
        &#47&#47 The new key is the concatenation of the keys of each example in the batch
        expected_keys_per_batch = [
            ["_".join(key <a id="change">for</a> key, _ in all_examples[i : i + batch_size])] * len(examples)
            for i, examples in zip(range(0, len(all_examples), batch_size), expected_examples_per_batch)
        ]
        &#47&#47 Combine keys and examples
        expected = [
            (key, example)
            for expected_keys, expected_examples in <a id="change">zip(</a>expected_keys_per_batch, expected_examples_per_batch<a id="change">)</a>
            for key, example in zip(expected_keys, expected_examples)
        ]
    assert next(iter(ex_iterable)) == expected[0]
    assert list(ex_iterable) == expected</code></pre><h3>After Change</h3><pre><code class='java'>
            transformed_batch = func(batch)
            all_transformed_examples.extend(_batch_to_examples(transformed_batch))
        expected = _examples_to_batch(all_examples)
        <a id="change">expected.update(</a>_examples_to_batch(all_transformed_examples)<a id="change">)</a>
        expected = list(_batch_to_examples(expected))
    assert next(iter(ex_iterable))[1] == expected[0]
    assert list(x for _, x in ex_iterable) == expected
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/datasets/commit/4b9334007e069ad71630ba36283d3abafba42174#diff-17766e93a3448f2734ed819adaf8c1d84dacece94f0f8c19687002c62071700dL186' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 108140345</div><div id='project'> Project Name: huggingface/datasets</div><div id='commit'> Commit Name: 4b9334007e069ad71630ba36283d3abafba42174</div><div id='time'> Time: 2022-03-07</div><div id='author'> Author: 42851186+lhoestq@users.noreply.github.com</div><div id='file'> File Name: tests/test_iterable_dataset.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_mapped_examples_iterable(4)</div><div id='n_method'> N Method Name: test_mapped_examples_iterable(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/test_iterable_dataset.py</div><div id='n_file'> N File Name: tests/test_iterable_dataset.py</div><div id='m_start'> M Start Line: 189</div><div id='m_end'> M End Line: 208</div><div id='n_start'> N Start Line: 184</div><div id='n_end'> N End Line: 197</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        matcher = PhraseMatcher(self.nlp.vocab, attr=attr)
        for name, df in dfs.items():
            df = df[df.apply((lambda x: self.entry_filter(x, lowercase=lowercase)), axis=1)]
            terms = list([syn <a id="change">for</a> syn in df[SYN]])
            iris<a id="change"> = </a>list(df[IDX])
            assert len(list(terms)) == len(list(iris))
            for iri, term in <a id="change">zip(</a>iris, terms<a id="change">)</a>:
                if lowercase:
                    term = term.lower()
                variant_terms = list(self.variant_generator(term))</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 TODO: fix api call
            synonym_data = parser.collect_aggregate_synonym_data(False)
            generated_synonym_data = parser.generate_synonyms()
            <a id="change">generated_synonym_data.update(</a>synonym_data<a id="change">)</a>

            logging.info(f"generating {len(generated_synonym_data)} patterns for {parser.name}")
            patterns = list(self.nlp.tokenizer.pipe(generated_synonym_data.keys()))
            for i, (syn, syn_data_list) in enumerate(generated_synonym_data.items()):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/astrazeneca/kazu/commit/e6b1e7e6235e8562c8164e4a5b1d6b4f946c3fab#diff-ec730aab051edf2ba7b89f163cda2f2499c14d8d87a4b422587f8edcaec3d078L340' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 108140332</div><div id='project'> Project Name: astrazeneca/kazu</div><div id='commit'> Commit Name: e6b1e7e6235e8562c8164e4a5b1d6b4f946c3fab</div><div id='time'> Time: 2022-11-30</div><div id='author'> Author: richard.jackson4@astrazeneca.com</div><div id='file'> File Name: kazu/modelling/ontology_matching/ontology_matcher.py</div><div id='m_class'> M Class Name: OntologyMatcher</div><div id='n_method'> N Class Name: OntologyMatcher</div><div id='m_method'> M Method Name: _create_phrasematcher(2)</div><div id='n_method'> N Method Name: _create_phrasematcher(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: kazu/modelling/ontology_matching/ontology_matcher.py</div><div id='n_file'> N File Name: kazu/modelling/ontology_matching/ontology_matcher.py</div><div id='m_start'> M Start Line: 340</div><div id='m_end'> M End Line: 356</div><div id='n_start'> N Start Line: 339</div><div id='n_end'> N End Line: 366</div><BR>