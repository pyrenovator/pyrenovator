<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        dataset = &quottraining-test-data&quot
        tests_data_path = &quottests/data/&quot
        repository = TrainingDataRepository(tests_data_path, dataset)
        model_trainer<a id="change"> = </a>ModelTrainer(GraphEncoder, loss_function, optimizer)
        training = GridSearch(repository, model_trainer, epochs=10)

        features = BASE_GRAPH_NODE_FEATURES
        labels = BASE_GRAPH
        features_filenames = [str(i) + &quot_training_features&quot + &quot.pickle&quot for i in range(dataset_size)]
        labels_filenames = [str(i) + &quot_training_labels&quot &quot.pickle&quot for i in range(dataset_size)]
        for i in range(dataset_size):
            repository.save(features_filenames[i], features)
            repository.save(labels_filenames[i], labels)

        &#47&#47 When
        training_loss, validation_loss, test_loss = <a id="change">training.start(</a>batch_size, validation_split, test_split<a id="change">)</a>

        &#47&#47 Then
        self.assertTrue(training_loss &gt; 0.0)
        self.assertTrue(validation_loss &gt; 0.0)</code></pre><h3>After Change</h3><pre><code class='java'>
    def test_start_for_multiple_batches_of_differing_size(self):
        &#47&#47 Given
        dataset_size = 5
        grid_search_dictionary = <a id="change">{
            </a>"epochs": [10],
            "batch_size": [3],
            "validation_split": [0.2],
            "test_split": [0.1],
            "loss_function": [nn.MSELoss()],
            "optimizer": [to.optim.SGD],
            "time_steps": [1],
            "validation_period": [5]<a id="change">
        }</a>
        dataset = &quottraining-test-data&quot
        tests_data_path = &quottests/data/&quot
        repository = TrainingDataRepository(tests_data_path, dataset)
        model_trainer = ModelTrainer(GraphEncoder)
        grid_search = GridSearch(repository, model_trainer, grid_search_dictionary)

        features = BASE_GRAPH_NODE_FEATURES
        labels = BASE_GRAPH
        features_filenames = [str(i) + &quot_training_features&quot + &quot.pickle&quot for i in range(dataset_size)]
        labels_filenames = [str(i) + &quot_training_labels&quot &quot.pickle&quot for i in range(dataset_size)]
        for i in range(dataset_size):
            repository.save(features_filenames[i], features)
            repository.save(labels_filenames[i], labels)

        &#47&#47 When
        losses<a id="change"> = </a>grid_search.start()

        &#47&#47 Then
        configuration_id = list(losses["training_loss"].keys())[0]</code></pre>