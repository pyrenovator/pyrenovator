<html><h3>Pattern ID :39029
</h3><img src='111187234.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        for name, param in self._module_to_wrap.named_parameters():

            &#47&#47 Store current weight for use later on
            shadow_params[name]<a id="change"> = </a><a id="change">param.detach().clone()</a>
            &#47&#47 Create a list of encoding parameters for params
            if self.param_quantizers[name].enabled:
                encoding_list_for_params.append(self._parameters[name + &quot_encoding_min&quot])
                encoding_list_for_params.append(self._parameters[name + &quot_encoding_max&quot])</code></pre><h3>After Change</h3><pre><code class='java'>
        if isinstance(quantized_inputs, torch.Tensor):
            quantized_inputs = [quantized_inputs]

        <a id="change">with </a><a id="change">self._quantize_params(quantized_inputs):
            &#47&#47 Call the forward of the wrapped module
            </a>wrapped_output = self._module_to_wrap(*quantized_inputs)

        &#47&#47 Quantize the outputs
        &#47&#47 pylint: disable=all</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/quic/aimet/commit/c9cadfe0cede11da01757e9e189988fa912b05dd#diff-e539521643643e71817d62bf10237ce2573286f0a9b3800d46a4f3c6a51c23baL733' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111187234</div><div id='project'> Project Name: quic/aimet</div><div id='commit'> Commit Name: c9cadfe0cede11da01757e9e189988fa912b05dd</div><div id='time'> Time: 2022-05-19</div><div id='author'> Author: quic_kyunggeu@quicinc.com</div><div id='file'> File Name: TrainingExtensions/torch/src/python/aimet_torch/qc_quantize_op.py</div><div id='m_class'> M Class Name: LearnedGridQuantWrapper</div><div id='n_method'> N Class Name: LearnedGridQuantWrapper</div><div id='m_method'> M Method Name: forward(1)</div><div id='n_method'> N Method Name: forward(1)</div><div id='m_parent_class'> M Parent Class: QcQuantizeWrapper</div><div id='n_parent_class'> N Parent Class: QcQuantizeWrapper</div><div id='m_file'> M File Name: TrainingExtensions/torch/src/python/aimet_torch/qc_quantize_op.py</div><div id='n_file'> N File Name: TrainingExtensions/torch/src/python/aimet_torch/qc_quantize_op.py</div><div id='m_start'> M Start Line: 733</div><div id='m_end'> M End Line: 763</div><div id='n_start'> N Start Line: 737</div><div id='n_end'> N End Line: 751</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        )
        return updated_inputs["a"].item()

    data_x_np = <a id="change">data_x.detach().clone()</a>.numpy()
    dfit_x = nd.Gradient(fit_x)
    da_dx_numeric<a id="change"> = </a>torch.from_numpy(dfit_x(data_x_np)).float()

    theseus_inputs["x"] = data_x
    updated_inputs, _ = theseus_optim.forward(</code></pre><h3>After Change</h3><pre><code class='java'>
def test_backwards():
    &#47&#47 First we use torch.autograd.functional to numerically compute the gradient
    &#47&#47 the optimal a w.r.t. the x part of the data
    <a id="change">with </a><a id="change">torch.no_grad():

        </a>def fn(data_x_torch):
            theseus_inputs["x"] = data_x_torch
            updated_inputs, _ = theseus_optim.forward(
                theseus_inputs,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/facebookresearch/theseus/commit/3bbbb15c55d341b4aab095345d9beb841056b57a#diff-2dd2a3eed5f7329761cd451a4c2229fa7d0edfceab10484727720a434cdbae61L65' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111187235</div><div id='project'> Project Name: facebookresearch/theseus</div><div id='commit'> Commit Name: 3bbbb15c55d341b4aab095345d9beb841056b57a</div><div id='time'> Time: 2022-11-07</div><div id='author'> Author: luisen.p@gmail.com</div><div id='file'> File Name: tests/optimizer/nonlinear/test_backwards.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_backwards(0)</div><div id='n_method'> N Method Name: test_backwards(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/optimizer/nonlinear/test_backwards.py</div><div id='n_file'> N File Name: tests/optimizer/nonlinear/test_backwards.py</div><div id='m_start'> M Start Line: 78</div><div id='m_end'> M End Line: 80</div><div id='n_start'> N Start Line: 67</div><div id='n_end'> N End Line: 79</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                        &#47&#47 NOTE: this happends on the main stream FIXME?
                        event = torch.cuda.Event(blocking=True)
                        with torch.no_grad():
                            t<a id="change"> = </a><a id="change">x.clone()</a>
                            event.record()

                        reuse_q = self.buffer_reuse_queues[receive_rank][self.rank]
                        &#47&#47 sync clone event</code></pre><h3>After Change</h3><pre><code class='java'>
                          is_activations):
        try:
            stream = self.grad_recv_stream if not is_activations else self.acti_recv_stream
            <a id="change">with </a><a id="change">torch.cuda.stream(stream):
                </a>request_objects = []
                if not is_activations:
                    ranks_dict_items = reversed(ranks_dict_items)
                for (tensor_name, receive_ranks) in ranks_dict_items:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/saareliad/ftpipe/commit/2cc10d5a34ef54c6fe4eb864a72f9063c1396579#diff-e8a3a19b1943afe92b627d303a564e72a2ad183b89af477fbd5c65031cec3416L171' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111187230</div><div id='project'> Project Name: saareliad/ftpipe</div><div id='commit'> Commit Name: 2cc10d5a34ef54c6fe4eb864a72f9063c1396579</div><div id='time'> Time: 2020-08-25</div><div id='author'> Author: saareliad@campus.technion.ac.il</div><div id='file'> File Name: pipeline/communication/multiprocessing.py</div><div id='m_class'> M Class Name: MultiprocessingCommunicationHandler</div><div id='n_method'> N Class Name: MultiprocessingCommunicationHandler</div><div id='m_method'> M Method Name: _recv_tensors_p2p(4)</div><div id='n_method'> N Method Name: _recv_tensors_p2p(5)</div><div id='m_parent_class'> M Parent Class: SimpleCommBase</div><div id='n_parent_class'> N Parent Class: SimpleCommBase</div><div id='m_file'> M File Name: pipeline/communication/multiprocessing.py</div><div id='n_file'> N File Name: pipeline/communication/multiprocessing.py</div><div id='m_start'> M Start Line: 171</div><div id='m_end'> M End Line: 235</div><div id='n_start'> N Start Line: 162</div><div id='n_end'> N End Line: 217</div><BR>