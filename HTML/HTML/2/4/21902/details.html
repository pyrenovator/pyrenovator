<html><h3>Pattern ID :21902
</h3><img src='69701734.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        policy = policy_class(**policy_kwargs)
    else:
        <a id="change">raise </a>NotImplementedError

    if print_policy_summary:
        &#47&#47 print policy info in case it is useful for the caller</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 training we still need the full encoder (linear layers included),
        &#47&#47 so here we load the weights for conv layers, and leave linear
        &#47&#47 layers randomly initialized.
        <a id="change">if </a>hasattr(encoder, &quotnetwork&quot) and \
           not isinstance(encoder.network.shared_network[-1], th.nn.Linear):
            full_encoder = BaseEncoder(observation_space,
                                       **encoder_kwargs)

            partial_encoder_dict = encoder.state_dict()
            full_encoder_dict = <a id="change">full_encoder.state_dict()</a>

            &#47&#47 pretrained_dict contains weights & bias for conv layers only.
            pretrained_dict = {k: v for k, v in partial_encoder_dict.items() if
                               k in full_encoder_dict}
            full_encoder_dict.update(pretrained_dict)
            full_encoder.load_state_dict(full_encoder_dict)

            encoder<a id="change"> = </a>full_encoder

        policy_kwargs = {
            &quotfeatures_extractor_class&quot: EncoderFeatureExtractor,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/bd5e3f1d81db75a1241a9fd43d7b1daba1286152#diff-c89e267c35244f4a7b1392541f3a998a20951f7d934bb7dc532f18d3bdc5ab04L49' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69701734</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: bd5e3f1d81db75a1241a9fd43d7b1daba1286152</div><div id='time'> Time: 2021-10-18</div><div id='author'> Author: cyn0531@hku.hk</div><div id='file'> File Name: src/il_representations/scripts/policy_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: make_policy(0)</div><div id='n_method'> N Method Name: make_policy(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/il_representations/scripts/policy_utils.py</div><div id='n_file'> N File Name: src/il_representations/scripts/policy_utils.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 87</div><div id='n_start'> N Start Line: 57</div><div id='n_end'> N End Line: 118</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    ):
        if use_existing_trainer:
            train_trainer = self.trainers["train"]
            <a id="change">raise </a>NotImplementedError()
        else:
            if not root_dir:
                root_dir = f"{self.exp_dir}/checkpoints"</code></pre><h3>After Change</h3><pre><code class='java'>
            and "logger" in self.logger_and_callbacks
        ):
            self.logger_and_callbacks["logger"].experiment.finish()
        <a id="change">if </a>save_path is not None:
            root_path<a id="change"> = </a>os.path.dirname(f"{self.exp_dir}/{save_path}")
            if not os.path.exists(root_path):
                os.makedirs(root_path)
            torch.save(<a id="change">self.model.state_dict()</a>, f"{self.exp_dir}/{save_path}")
        return res

    def predict(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/krenerd/awesome-modular-pytorch-lightning/commit/42153bc05718dcfa90fa3620fdbf9bd8f28d813c#diff-b10564ab7d2c520cdd0243874879fb0a782862c3c902ab535faabe57d5a505e1L173' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69701728</div><div id='project'> Project Name: krenerd/awesome-modular-pytorch-lightning</div><div id='commit'> Commit Name: 42153bc05718dcfa90fa3620fdbf9bd8f28d813c</div><div id='time'> Time: 2022-06-13</div><div id='author'> Author: 48239275+krenerd@users.noreply.github.com</div><div id='file'> File Name: main.py</div><div id='m_class'> M Class Name: Experiment</div><div id='n_method'> N Class Name: Experiment</div><div id='m_method'> M Method Name: train(7)</div><div id='n_method'> N Method Name: train(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: main.py</div><div id='n_file'> N File Name: main.py</div><div id='m_start'> M Start Line: 183</div><div id='m_end'> M End Line: 187</div><div id='n_start'> N Start Line: 297</div><div id='n_end'> N End Line: 342</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        else:
            print("Warn: model has no attribute &quotclassifier&quot and fixbase_epoch is reset to 0")
            args.fixbase_epoch = 0
        <a id="change">raise </a>NotImplementedError

    if args.load_weights and check_isfile(args.load_weights):
        &#47&#47 load pretrained weights but ignore layers that don&quott match in size</code></pre><h3>After Change</h3><pre><code class='java'>
    train_time = 0
    print("==&gt; Start training")

    <a id="change">if </a>args.fixbase_epoch &gt; 0:
        print("Train {} for {} epochs while keeping other layers frozen".format(args.open_layers, args.fixbase_epoch))
        initial_optim_state = <a id="change">optimizer.state_dict()</a>

        for epoch in range(args.fixbase_epoch):
            start_train_time<a id="change"> = </a>time.time()
            train(epoch, model, criterion, optimizer, trainloader, use_gpu, fixbase=True)
            train_time += round(time.time() - start_train_time)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/vlsomers/bpbreid/commit/b85e1b59d6bac874d270d2604977e9ec8bd60851#diff-e6c0c833279ad43f0c76b2e4799c36ce85c9cbbcd1aeb2f6e0af3401a600792eL35' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 69701726</div><div id='project'> Project Name: vlsomers/bpbreid</div><div id='commit'> Commit Name: b85e1b59d6bac874d270d2604977e9ec8bd60851</div><div id='time'> Time: 2018-11-08</div><div id='author'> Author: k.zhou@qmul.ac.uk</div><div id='file'> File Name: train_vidreid_xent.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_vidreid_xent.py</div><div id='n_file'> N File Name: train_vidreid_xent.py</div><div id='m_start'> M Start Line: 65</div><div id='m_end'> M End Line: 127</div><div id='n_start'> N Start Line: 40</div><div id='n_end'> N End Line: 119</div><BR>