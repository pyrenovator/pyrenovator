<html><h3>Pattern ID :5333
</h3><img src='19038417.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            self._client.wait_for_model_ready(
                model_name=model.model_name(),
                num_retries=self._config.max_retries)
            <a id="change">try:
                &#47&#47 Send objectives and constraints to result manager
                </a>self._metrics_manager.configure_result_manager(
                    config_model=model)

                for run_config in FullRunConfigGenerator(</code></pre><h3>After Change</h3><pre><code class='java'>
                    config_model=model)
            run_config_generator = RunConfigGenerator(model,
                                                 analyzer_config=self._config)
            <a id="change">for </a>run_config in run_config_generator.get_run_configs()<a id="change">:
                </a>model_config = run_config.model_config()
                original_model_name = run_config.model_name()
                model_name<a id="change"> = </a>model_config.get_field(&quotname&quot)

                &#47&#47 Create the directory for the new model
                os.mkdir(f&quot{output_model_repo_path}/{model_name}&quot)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/triton-inference-server/model_analyzer/commit/a4a6ea24a86f6d853076a7e524ad96b6ad6ec483#diff-bfa8f90a391c1ffdc5f96eac924441f3941ab2aeb9d7784b89ab3f503cd37c8dL69' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19038417</div><div id='project'> Project Name: triton-inference-server/model_analyzer</div><div id='commit'> Commit Name: a4a6ea24a86f6d853076a7e524ad96b6ad6ec483</div><div id='time'> Time: 2021-02-26</div><div id='author'> Author: itabrizian@nvidia.com</div><div id='file'> File Name: model_analyzer/analyzer.py</div><div id='m_class'> M Class Name: Analyzer</div><div id='n_method'> N Class Name: Analyzer</div><div id='m_method'> M Method Name: run(1)</div><div id='n_method'> N Method Name: run(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model_analyzer/analyzer.py</div><div id='n_file'> N File Name: model_analyzer/analyzer.py</div><div id='m_start'> M Start Line: 73</div><div id='m_end'> M End Line: 106</div><div id='n_start'> N Start Line: 69</div><div id='n_end'> N End Line: 126</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        global _is_fx_tracing_flag
        old_is_fx_tracing_flag = _is_fx_tracing_flag
        _is_fx_tracing_flag = True
        <a id="change">try:
            </a>graph = super().trace(
                root,
                concrete_args,
            )</code></pre><h3>After Change</h3><pre><code class='java'>
        old_is_fx_tracing_flag = _is_fx_tracing_flag
        _is_fx_tracing_flag = True
        if isinstance(root, torch.nn.Module):
            <a id="change">for </a>prefix, <a id="change">module</a> in root.named_modules()<a id="change">:
                &#47&#47 TODO(T140754678): Remove this workaround to _fx_path
                </a>module._fx_path<a id="change"> = </a>prefix

        try:
            &#47&#47 TODO(ivankobzarev): support DMP not only on the root level</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/facebookresearch/torchrec/commit/8e56e2fffb2bec78e42709e8d54c79b4be373530#diff-840e11b12e25c025afd9877fd2fe3567ae91a058dbca2bbe87533030947d203bL47' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19038410</div><div id='project'> Project Name: facebookresearch/torchrec</div><div id='commit'> Commit Name: 8e56e2fffb2bec78e42709e8d54c79b4be373530</div><div id='time'> Time: 2023-01-23</div><div id='author'> Author: ivankobzarev@meta.com</div><div id='file'> File Name: torchrec/fx/tracer.py</div><div id='m_class'> M Class Name: Tracer</div><div id='n_method'> N Class Name: Tracer</div><div id='m_method'> M Method Name: trace(3)</div><div id='n_method'> N Method Name: trace(3)</div><div id='m_parent_class'> M Parent Class: torch.fx.Tracer</div><div id='n_parent_class'> N Parent Class: torch.fx.Tracer</div><div id='m_file'> M File Name: torchrec/fx/tracer.py</div><div id='n_file'> N File Name: torchrec/fx/tracer.py</div><div id='m_start'> M Start Line: 56</div><div id='m_end'> M End Line: 63</div><div id='n_start'> N Start Line: 57</div><div id='n_end'> N End Line: 84</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            self._client.wait_for_model_ready(
                model_name=model.model_name(),
                num_retries=self._config.max_retries)
            <a id="change">try:
                &#47&#47 Send objectives and constraints to result manager
                </a>self._metrics_manager.configure_result_manager(
                    config_model=model)

                for run_config in FullRunConfigGenerator(</code></pre><h3>After Change</h3><pre><code class='java'>
                    config_model=model)
            run_config_generator = RunConfigGenerator(model,
                                                 analyzer_config=self._config)
            <a id="change">for run_config</a> in run_config_generator.get_run_configs()<a id="change">:
                </a>model_config<a id="change"> = </a>run_config.model_config()
                original_model_name = run_config.model_name()
                model_name = model_config.get_field(&quotname&quot)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/triton-inference-server/model_analyzer/commit/a4a6ea24a86f6d853076a7e524ad96b6ad6ec483#diff-bfa8f90a391c1ffdc5f96eac924441f3941ab2aeb9d7784b89ab3f503cd37c8dL58' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19038415</div><div id='project'> Project Name: triton-inference-server/model_analyzer</div><div id='commit'> Commit Name: a4a6ea24a86f6d853076a7e524ad96b6ad6ec483</div><div id='time'> Time: 2021-02-26</div><div id='author'> Author: itabrizian@nvidia.com</div><div id='file'> File Name: model_analyzer/analyzer.py</div><div id='m_class'> M Class Name: Analyzer</div><div id='n_method'> N Class Name: Analyzer</div><div id='m_method'> M Method Name: run(1)</div><div id='n_method'> N Method Name: run(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model_analyzer/analyzer.py</div><div id='n_file'> N File Name: model_analyzer/analyzer.py</div><div id='m_start'> M Start Line: 73</div><div id='m_end'> M End Line: 106</div><div id='n_start'> N Start Line: 69</div><div id='n_end'> N End Line: 126</div><BR>