<html><h3>Pattern ID :248
</h3><img src='1926433.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                    if self.pl_module.trainer.lr_scheduler_configs:
                        for config in self.pl_module.trainer.lr_scheduler_configs:
                            show_warn_lambdas = (
                                <a id="change">hasattr(</a>config.scheduler, <a id="change">"lr_lambdas"</a><a id="change">)</a>
                                and config.scheduler.lr_lambdas[-1] is not None  &#47&#47 type: ignore[union-attr]
                                and not self.apply_lambdas_new_pgs
                            )
                            <a id="change">if </a>show_warn_lambdas:
                                rank_zero_warn(
                                    "The lr scheduler used in this phase has lr_lambdas but will use a "
                                    "configured lr for new parameter groups because `apply_lambdas_new_pgs` is "</code></pre><h3>After Change</h3><pre><code class='java'>
        assert isinstance(self.pl_module.trainer, pl.Trainer)
        &#47&#47 if the target depth is 0, implicit optimizer reinitialization should not be executed
        new_optimizer_cfg = (
            self.reinit_optim_cfg or <a id="change">self.ft_schedule[depth].get(</a>"new_optimizer", None<a id="change">)</a> if depth &gt; 0 else None
        )
        restored_depth = -1 if new_optimizer_cfg else self._fts_state._best_ckpt_depth
        if depth_sync or new_optimizer_cfg:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/speediedan/finetuning-scheduler/commit/3822650061e2c56b5d05f7b277a6e824920a358e#diff-1e40f5edc419001c8841d4ee49ba3fe40f5c1a9f4122eff482a4037740bd7683L341' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1926433</div><div id='project'> Project Name: speediedan/finetuning-scheduler</div><div id='commit'> Commit Name: 3822650061e2c56b5d05f7b277a6e824920a358e</div><div id='time'> Time: 2023-03-30</div><div id='author'> Author: danny.dale@gmail.com</div><div id='file'> File Name: src/finetuning_scheduler/fts.py</div><div id='m_class'> M Class Name: FinetuningScheduler</div><div id='n_method'> N Class Name: FinetuningScheduler</div><div id='m_method'> M Method Name: step_pg(5)</div><div id='n_method'> N Method Name: step_pg(4)</div><div id='m_parent_class'> M Parent Class: ScheduleImplMixin,ScheduleParsingMixin,CallbackDepMixin,BaseFinetuning</div><div id='n_parent_class'> N Parent Class: ScheduleImplMixin,ScheduleParsingMixin,CallbackDepMixin,BaseFinetuning</div><div id='m_file'> M File Name: src/finetuning_scheduler/fts.py</div><div id='n_file'> N File Name: src/finetuning_scheduler/fts.py</div><div id='m_start'> M Start Line: 341</div><div id='m_end'> M End Line: 381</div><div id='n_start'> N Start Line: 342</div><div id='n_end'> N End Line: 385</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    optimizer = torch.optim.Adam(
        parameters, lr=cfg_opt.lr, weight_decay=cfg_opt.weight_decay,
    )
    <a id="change">if </a><a id="change">hasattr(</a>cfg_opt, <a id="change">"is_lars"</a><a id="change">)</a> and cfg_opt.is_lars:
        optimizer = LARSWrapper(optimizer)

    scheduler = get_lr_scheduler(</code></pre><h3>After Change</h3><pre><code class='java'>
    optimizers += [optimizer]

    for mode in hparams_sch.modes:
        sch_kwargs = <a id="change">hparams_sch.kwargs.get(</a>mode, {}<a id="change">)</a>
        scheduler = get_lr_scheduler(optimizer, mode, **sch_kwargs)
        schedulers += [scheduler]

    return optimizers, schedulers</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yanndubs/lossyless/commit/1d3581b865e12149571c434670da69cfcc12490a#diff-ba2db6a7ed79d2fb968c2737361a3e18fec7d218f75e89d30143679dc6744dfaL449' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1926432</div><div id='project'> Project Name: yanndubs/lossyless</div><div id='commit'> Commit Name: 1d3581b865e12149571c434670da69cfcc12490a</div><div id='time'> Time: 2021-02-09</div><div id='author'> Author: yanndubois96@gmail.com</div><div id='file'> File Name: lossyless/helpers.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: append_optimizer_scheduler_(5)</div><div id='n_method'> N Method Name: append_optimizer_scheduler_(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: lossyless/helpers.py</div><div id='n_file'> N File Name: lossyless/helpers.py</div><div id='m_start'> M Start Line: 453</div><div id='m_end'> M End Line: 467</div><div id='n_start'> N Start Line: 473</div><div id='n_end'> N End Line: 478</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &quot&quot&quot
        if estimator_name in self._search_states:
            state = self._search_states[estimator_name]
            <a id="change">if </a><a id="change">hasattr(</a>state, <a id="change">&quottrained_estimator&quot</a><a id="change">)</a>:
                return state.trained_estimator
        return None
</code></pre><h3>After Change</h3><pre><code class='java'>
            An object with `predict()` and `predict_proba()` method (for
        classification), storing the best trained model for estimator_name.
        &quot&quot&quot
        state = <a id="change">self._search_states.get(</a>estimator_name<a id="change">)</a>
        return state and getattr(state, &quottrained_estimator&quot, None)

    @property
    def best_estimator(self):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/flaml/commit/e46573a01d077b999f669f072ed41a40ac76c37b#diff-47aff7bcc3e528c362ea162261b640e1e276e2bce981dfafc6cce49d3d81e324L324' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1926435</div><div id='project'> Project Name: microsoft/flaml</div><div id='commit'> Commit Name: e46573a01d077b999f669f072ed41a40ac76c37b</div><div id='time'> Time: 2021-09-04</div><div id='author'> Author: wang.chi@microsoft.com</div><div id='file'> File Name: flaml/automl.py</div><div id='m_class'> M Class Name: AutoML</div><div id='n_method'> N Class Name: AutoML</div><div id='m_method'> M Method Name: best_model_for_estimator(2)</div><div id='n_method'> N Method Name: best_model_for_estimator(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: flaml/automl.py</div><div id='n_file'> N File Name: flaml/automl.py</div><div id='m_start'> M Start Line: 334</div><div id='m_end'> M End Line: 338</div><div id='n_start'> N Start Line: 329</div><div id='n_end'> N End Line: 330</div><BR>