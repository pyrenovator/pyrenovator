<html><h3>Pattern ID :7871
</h3><img src='28051628.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
def switch_model_on(model, list_trained_pars, update_mode):
    for _n, _p in model.named_parameters():
        _p.requires_grad_(True)
        <a id="change">if </a>&quotnew&quot in _n or update_mode == &quotheads_bn&quot and &quotbn&quot in _n or update_mode == "full":
            list_trained_pars.append(_p)
            print(_n, &quottrainable parameters&quot)
</code></pre><h3>After Change</h3><pre><code class='java'>
def switch_model_on(model, ckpt, list_trained_pars):
    param_names = ckpt[&quotmodel_weights&quot].keys()
    for _n,_p in model.named_parameters():
      <a id="change">if _p.dtype==torch.float32</a> and _n in param_names:
         if not &quotnew&quot in _n and not &quotbn&quot in _n:
            _p.requires_grad_(True)
            print(_n, "grads on")
         else:
            _p.requires_grad_(True)
            list_trained_pars.append(_p)
            print(_n, "trainable pars")
      elif _p.dtype==torch.float32 and not _n in param_names:
         <a id="change">_p.requires_grad_(</a>True<a id="change">)</a>
         list_trained_pars.append(_p)
         print(_n, "new pars, trainable")
&#47&#47 AVERAGE PRECISION COMPUTATION
&#47&#47 adapted from Matterport Mask R-CNN implementation</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/alexts1980/covid-ct-mask-net/commit/18c185c1d9c418f255497fa3159a2fae0f4aa8bc#diff-09d0cbaf891d623ac245ccf84485a687b554217349ca55557c60b33234b969aeL15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 28051628</div><div id='project'> Project Name: alexts1980/covid-ct-mask-net</div><div id='commit'> Commit Name: 18c185c1d9c418f255497fa3159a2fae0f4aa8bc</div><div id='time'> Time: 2020-10-21</div><div id='author'> Author: ater1980@gmail.com</div><div id='file'> File Name: utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: switch_model_on(3)</div><div id='n_method'> N Method Name: switch_model_on(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: utils.py</div><div id='n_file'> N File Name: utils.py</div><div id='m_start'> M Start Line: 21</div><div id='m_end'> M End Line: 29</div><div id='n_start'> N Start Line: 15</div><div id='n_end'> N End Line: 33</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.image_size = image_size
        fpn_norm_layer = kwargs.pop("fpn_norm_layer", nn.BatchNorm2d)
        &#47&#47 create modules
        <a id="change">if </a>pretrained_backbone:
            backbone_norm_layer = FrozenBatchNorm2d
        else:
            backbone_norm_layer = nn.BatchNorm2d</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 freeze layers (自己看效果)进行freeze
        for freeze_layer in backbone_freeze:
            for name, parameter in backbone.named_parameters():
                <a id="change">if freeze_layer in name</a>:
                    <a id="change">parameter.requires_grad_(</a>False<a id="change">)</a>

        return_layers = {"layer3": "P3", "layer5": "P4", "layer7": "P5"}  &#47&#47 "layer2": "P2",
        in_channels_list = efficientnet_out_channels[backbone_name]  &#47&#47 bifpn
        super(EfficientNetBackBoneWithBiFPN, self).__init__(OrderedDict({</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jintao-huang/efficientdet_pytorch/commit/63fbf56348d5f299bf5757f5c4b0fa68a0a7adca#diff-258d0736f4ec16a45bec12b84352faf736ace909e51d18ff8a8c09fc0e1a5b98L24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 28051643</div><div id='project'> Project Name: jintao-huang/efficientdet_pytorch</div><div id='commit'> Commit Name: 63fbf56348d5f299bf5757f5c4b0fa68a0a7adca</div><div id='time'> Time: 2020-05-24</div><div id='author'> Author: hjt_study@qq.com</div><div id='file'> File Name: models/backbone.py</div><div id='m_class'> M Class Name: EfficientNetBackBoneWithBiFPN</div><div id='n_method'> N Class Name: EfficientNetBackBoneWithBiFPN</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: nn.Sequential</div><div id='n_parent_class'> N Parent Class: nn.Sequential</div><div id='m_file'> M File Name: models/backbone.py</div><div id='n_file'> N File Name: models/backbone.py</div><div id='m_start'> M Start Line: 24</div><div id='m_end'> M End Line: 34</div><div id='n_start'> N Start Line: 24</div><div id='n_end'> N End Line: 45</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        if self.AUG.apply_ada:
            assert self.AUG.ada_aug_type != "W/O", "Please select diffentiable augmentation type!"
            <a id="change">if </a>self.AUG.ada_aug_type == "cr":
                self.AUG.series_augment = cr.apply_cr_aug
            elif self.AUG.ada_aug_type == "diffaug":
                self.AUG.series_augment = diffaug.apply_diffaug</code></pre><h3>After Change</h3><pre><code class='java'>
            else:
                raise NotImplementedError

        <a id="change">if self.AUG.series_augment in ["simclr_basic", "simclr_hq", "simclr_hq_cutout", "byol", \
            "blit", "geom", "color", "filter", "noise", "cutout", "bg", "bgc", "bgcf", "bgcfn", "bgcfnc"]</a> and DDP:
            self.AUG.series_augment = DDP(self.AUG.series_augment, device_ids=[device], broadcast_buffers=False)
            <a id="change">self.AUG.series_augment.requires_grad_(</a>False<a id="change">)</a>
        if self.AUG.parallel_augment in ["simclr_basic", "simclr_hq", "simclr_hq_cutout", "byol", \
            "blit", "geom", "color", "filter", "noise", "cutout", "bg", "bgc", "bgcf", "bgcfn", "bgcfnc"] and DDP:
            self.AUG.parallel_augment = DDP(self.AUG.parallel_augment, device_ids=[device], broadcast_buffers=False)
            self.AUG.parallel_augment.requires_grad_(False)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/postech-cvlab/pytorch-studiogan/commit/8ca218606f1796f48b734942ce21d931a54cc3d1#diff-24a3fe5c783755412cb9de83238b4dfd0699345bf50dcadc3ec23c6749361592L481' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 28051623</div><div id='project'> Project Name: postech-cvlab/pytorch-studiogan</div><div id='commit'> Commit Name: 8ca218606f1796f48b734942ce21d931a54cc3d1</div><div id='time'> Time: 2021-10-05</div><div id='author'> Author: joonghyuk4727@gmail.com</div><div id='file'> File Name: src/config.py</div><div id='m_class'> M Class Name: Configurations</div><div id='n_method'> N Class Name: Configurations</div><div id='m_method'> M Method Name: define_augments(3)</div><div id='n_method'> N Method Name: define_augments(1)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: src/config.py</div><div id='n_file'> N File Name: src/config.py</div><div id='m_start'> M Start Line: 481</div><div id='m_end'> M End Line: 544</div><div id='n_start'> N Start Line: 481</div><div id='n_end'> N End Line: 548</div><BR>