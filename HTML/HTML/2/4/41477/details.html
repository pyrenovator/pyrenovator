<html><h3>Pattern ID :41477
</h3><img src='116574899.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        cuda_visible_gpus = GPUDeviceFactory.get_cuda_visible_gpus().keys()

        if len(requested_gpus) == 1 and requested_gpus[0] == &quotall&quot:
            <a id="change">return </a>list(cuda_visible_gpus)

        available_gpus = list(set(cuda_visible_gpus) & set(requested_gpus))
        return available_gpus</code></pre><h3>After Change</h3><pre><code class='java'>
                try:
                    requested_gpus.append(self.get_device_by_cuda_index(idx))
                except TritonModelAnalyzerException:
                    <a id="change">raise </a><a id="change">TritonModelAnalyzerException(
                        f"Requested GPU with device id : {idx}. This GPU is not supported by DCGM."</a><a id="change">
                    )</a>
        except ValueError:
            &#47&#47 requested_gpus are assumed to be UUIDs
            requested_gpus = [
                self.get_device_by_uuid(uuid) for uuid in requested_gpus</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/triton-inference-server/model_analyzer/commit/5d5c49f409fc7cc14c21529e8424729b0cc57627#diff-69f5c5932d534d9be65eb697ab539e44ea1cf3d8be28196fde7309993ae77360L163' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116574899</div><div id='project'> Project Name: triton-inference-server/model_analyzer</div><div id='commit'> Commit Name: 5d5c49f409fc7cc14c21529e8424729b0cc57627</div><div id='time'> Time: 2021-09-03</div><div id='author'> Author: asramesh@nvidia.com</div><div id='file'> File Name: model_analyzer/device/gpu_device_factory.py</div><div id='m_class'> M Class Name: GPUDeviceFactory</div><div id='n_method'> N Class Name: GPUDeviceFactory</div><div id='m_method'> M Method Name: verify_requested_gpus(2)</div><div id='n_method'> N Method Name: verify_requested_gpus(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model_analyzer/device/gpu_device_factory.py</div><div id='n_file'> N File Name: model_analyzer/device/gpu_device_factory.py</div><div id='m_start'> M Start Line: 167</div><div id='m_end'> M End Line: 170</div><div id='n_start'> N Start Line: 163</div><div id='n_end'> N End Line: 214</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def parse(self, argv):
        &#47&#47 Remove the first argument which is the program name
        <a id="change">return </a>self._parser.parse_args(argv[1:])
</code></pre><h3>After Change</h3><pre><code class='java'>
                    raise TritonModelAnalyzerException(
                        f"Export path {args.export_path} is not a directory")
                if not (args.filename_model and args.filename_server_only):
                    <a id="change">raise </a><a id="change">TritonModelAnalyzerException(
                        "--filename-model and --filename-server-only must be specified"</a><a id="change">
                    )</a>
        return args
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/triton-inference-server/model_analyzer/commit/c56ce95ea91dc842faf12a9f8b8da0075734f4a1#diff-482fe20b77860750035a291798ebb2b92cd74a6982ecc0363cd62a835a2311c0L74' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116574902</div><div id='project'> Project Name: triton-inference-server/model_analyzer</div><div id='commit'> Commit Name: c56ce95ea91dc842faf12a9f8b8da0075734f4a1</div><div id='time'> Time: 2020-11-24</div><div id='author'> Author: asramesh@nvidia.com</div><div id='file'> File Name: model_analyzer/cli/cli.py</div><div id='m_class'> M Class Name: CLI</div><div id='n_method'> N Class Name: CLI</div><div id='m_method'> M Method Name: parse(1)</div><div id='n_method'> N Method Name: parse(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model_analyzer/cli/cli.py</div><div id='n_file'> N File Name: model_analyzer/cli/cli.py</div><div id='m_start'> M Start Line: 74</div><div id='m_end'> M End Line: 76</div><div id='n_start'> N Start Line: 144</div><div id='n_end'> N End Line: 159</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                model_name]:
            logger.error(
                f&quotNo results found for model config: {model_config_name}&quot)
            <a id="change">return </a>(None, [])
        else:
            model_config_data = results[model_name][model_config_name]
            return model_config_data[0], list(model_config_data[1].values())</code></pre><h3>After Change</h3><pre><code class='java'>

        if model_name not in results or model_config_name not in results[
                model_name]:
            <a id="change">raise </a><a id="change">TritonModelAnalyzerException(
                f"Model Config {model_config_name} requested for report step but no results were found. "
                "Double check the name and ensure that this model config was actually profiled."</a><a id="change">
            )</a>
        else:
            model_config_data = results[model_name][model_config_name]
            return model_config_data[0], list(model_config_data[1].values())
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/triton-inference-server/model_analyzer/commit/8ba6b554811c3542a51e1ffccd0c300d78f446c6#diff-875262876cc7d75df5768fbcc371cbee49fd2fad1dbe10dfece1fdd16b5087b5L329' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116574901</div><div id='project'> Project Name: triton-inference-server/model_analyzer</div><div id='commit'> Commit Name: 8ba6b554811c3542a51e1ffccd0c300d78f446c6</div><div id='time'> Time: 2022-03-07</div><div id='author'> Author: 50968584+tgerdesnv@users.noreply.github.com</div><div id='file'> File Name: model_analyzer/result/result_manager.py</div><div id='m_class'> M Class Name: ResultManager</div><div id='n_method'> N Class Name: ResultManager</div><div id='m_method'> M Method Name: get_model_config_measurements(2)</div><div id='n_method'> N Method Name: get_model_config_measurements(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: model_analyzer/result/result_manager.py</div><div id='n_file'> N File Name: model_analyzer/result/result_manager.py</div><div id='m_start'> M Start Line: 354</div><div id='m_end'> M End Line: 356</div><div id='n_start'> N Start Line: 355</div><div id='n_end'> N End Line: 358</div><BR>