<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    mode = &quotrandom_sampling&quot

    today = date.today().strftime("%d_%m_%Y")
    <a id="change">if </a>LOCAL: 
        checkpoint_folder = &quotcheckpoints/{}/&quot.format(today)
        try:
            <a id="change">os.makedirs(</a>checkpoint_folder<a id="change">)</a>
        except:
            print(&quotcheckpoint_folder already exists&quot)
            
        if mode == &quotbit_corruption&quot:</code></pre><h3>After Change</h3><pre><code class='java'>

    checkpoint_folder, base_path, cluster_path, sparseFP_vocab_path = setup_paths(expt_name, mode, LOCAL, cosine, multi) 

    trainargs<a id="change"> = </a><a id="change">{
    </a>&quotmodel&quot: &quotFeedforward&quot,
    &quothidden_sizes&quot: [1024, 256],  
    &quotoutput_size&quot: 1,
    &quotdropout&quot: 0.1,  
    
    &quotbatch_size&quot: 64,
    &quotactivation&quot: &quotReLU&quot,  
    &quotoptimizer&quot: torch.optim.Adam,
    &quotlearning_rate&quot:  3e-3, &#47&#47 to try: lr_finder & lr_schedulers 
    &quotepochs&quot: 50,
    &quotearly_stop&quot: True,
    &quotmin_delta&quot: 1e-5, &#47&#47 we just want to watch out for when val_loss increases
    &quotpatience&quot: 3,
    &quotnum_workers&quot: 4,

    &quotcheckpoint&quot: True,
    &quotmodel_seed&quot: 1337,
    &quotrandom_seed&quot: 0, &#47&#47 affects neg rxn sampling since it is random
    
    &quotrctfp_size&quot: 4096, &#47&#47 if fp_type == &quotdiff&quot, ensure that both rctfp_size & prodfp_size are identical!
    &quotprodfp_size&quot: 4096,
    &quotfp_radius&quot: 3,
    &quotfp_type&quot: &quotdiff&quot,
    
    &quotnum_neg_prod&quot: 5, 
    &quotnum_neg_rct&quot: 5,
    &quotnum_bits&quot: 3, 
    &quotnum_neg&quot: 10,
    
    &quotbase_path&quot: base_path, &#47&#47 refer to top of notebook 
    &quotcheckpoint_path&quot: checkpoint_folder,
    &quotcluster_path&quot: cluster_path,
    &quotsparseFP_vocab_path&quot: sparseFP_vocab_path,
    &quotquery_params&quot: {&quotefSearch&quot: 100}, &#47&#47 good value to hit 96% recall
 
    &quotexpt_name&quot: expt_name,
    &quotdevice&quot: torch.device("cuda" if torch.cuda.is_available() else "cpu")<a id="change">
    }</a>   

    model = FeedforwardEBM(trainargs)
    experiment = Experiment(model, trainargs, mode=mode)</code></pre>