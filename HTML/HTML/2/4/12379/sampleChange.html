<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

            output_tc = self.teacher(data)
            &#47&#47 TODO: Find an elegant way to free the feature map and computation graph
            output_tc = <a id="change">torch.tensor(output_tc.detach().cpu().numpy()).cuda()</a>
            
            output_st = self.student(data)
            supervised_loss = self.criterion(output_st, target)/self.accumulation_steps
            kd_loss = self.kd_criterion(output_st, output_tc)/self.accumulation_steps</code></pre><h3>After Change</h3><pre><code class='java'>
        for batch_idx, (data, target) in enumerate(self.train_data_loader):
            data, target = data.to(self.device), target.to(self.device)

            <a id="change">with torch</a><a id="change">.no_grad():
                </a>output_tc = self.teacher(data)
                &#47&#47 TODO: Find an elegant way to free the feature map and computation graph
                &#47&#47output_tc = torch.tensor(output_tc.detach().cpu().numpy()).cuda()
            </code></pre>