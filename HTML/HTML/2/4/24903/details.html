<html><h3>Pattern ID :24903
</h3><img src='76731091.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

                mask = (predictions[batch_id][0].cpu().numpy() &gt; 0).astype(np.uint8) * 255
                mask = unpad_from_size(pads, image=mask)["image"]
                mask<a id="change"> = </a><a id="change">cv2.resize(
                    </a>mask, (widths[batch_id].item()<a id="change">, heights[batch_id].item()</a>)<a id="change">, interpolation=cv2.INTER_NEAREST
                )</a>

                (hparams["output_mask_path"] / folder_name).mkdir(exist_ok=True, parents=True)
                cv2.imwrite(str(hparams["output_mask_path"] / folder_name / f"{file_id}.png"), mask)
</code></pre><h3>After Change</h3><pre><code class='java'>

                prob = predictions[batch_id][0].cpu().numpy().astype(np.float16)

                with open(str(<a id="change">hparams["output_path"]</a> / folder_name / f"{file_id}.txt")) as f:
                    f.write(prob)

</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ternaus/check_orientation/commit/a75e3361032928b0a9d2215da376432ed9119128#diff-088a6b4cc7e4b8e8313060a6863c3897dc0f891b4b7450f49f791c225f97abd3L123' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76731091</div><div id='project'> Project Name: ternaus/check_orientation</div><div id='commit'> Commit Name: a75e3361032928b0a9d2215da376432ed9119128</div><div id='time'> Time: 2020-11-12</div><div id='author'> Author: iglovikov@gmail.com</div><div id='file'> File Name: check_orientation/inference.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: predict(4)</div><div id='n_method'> N Method Name: predict(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: check_orientation/inference.py</div><div id='n_file'> N File Name: check_orientation/inference.py</div><div id='m_start'> M Start Line: 123</div><div id='m_end'> M End Line: 149</div><div id='n_start'> N Start Line: 142</div><div id='n_end'> N End Line: 149</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        height = int(img.size[1] * ratio)
        img = img.resize((width, height), Image.ANTIALIAS)
    elif size is not None:
        img<a id="change"> = </a><a id="change">img.resize(</a>(size<a id="change">, size</a>), Image.ANTIALIAS<a id="change">)</a>
    elif scale is not None:
        img = img.resize((int(img.size[0] / scale), int(img.size[1] / scale)), Image.ANTIALIAS)
    return img if return_pil else np.array(img)
</code></pre><h3>After Change</h3><pre><code class='java'>
def load_image(img_path, width=None):
    img = sio.imread(img_path).astype(np.float32)
    if img.shape[2] == 4:  &#47&#47 remove alpha channel
        img = <a id="change">img[:, :, :3]</a>
    img /= 255.0  &#47&#47 get to [0, 1] range
    if width is not None and width != -1:
        ratio = width / img.shape[0]
        height = int(img.shape[1] * ratio)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/gordicaleksa/pytorch-neural-style-transfer/commit/6856e5796971c3fb5e77c0a798b35e6e106b5bcb#diff-9653b8c2ce917a6134298b00c8b3f7d4b7c4dc473a752303f37a870392742127L12' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76731094</div><div id='project'> Project Name: gordicaleksa/pytorch-neural-style-transfer</div><div id='commit'> Commit Name: 6856e5796971c3fb5e77c0a798b35e6e106b5bcb</div><div id='time'> Time: 2020-03-30</div><div id='author'> Author: gordicaleksa@gmail.com</div><div id='file'> File Name: utils/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: load_image(2)</div><div id='n_method'> N Method Name: load_image(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: utils/utils.py</div><div id='n_file'> N File Name: utils/utils.py</div><div id='m_start'> M Start Line: 12</div><div id='m_end'> M End Line: 22</div><div id='n_start'> N Start Line: 18</div><div id='n_end'> N End Line: 27</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if self.backend == "pil":
            image = Image.open(self.image_paths[item])
            if self.resize is not None:
                image<a id="change"> = </a><a id="change">image.resize(
                    </a>(self.resize[1]<a id="change">, self.resize[0]</a>)<a id="change">, resample=Image.BILINEAR
                )</a>
            image = np.array(image)
            if self.augmentations is not None:
                augmented = self.augmentations(image=image)
                image = augmented["image"]</code></pre><h3>After Change</h3><pre><code class='java'>
                image = cv2.imread(self.image_paths[item])
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            else:
                image = cv2.imread(<a id="change">self.image_paths[item]</a>, cv2.IMREAD_GRAYSCALE)
            if self.augmentations is not None:
                augmented = self.augmentations(image=image)
                image = augmented["image"]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/abhi1thakur/tez/commit/dda5ac9c1e1ea0e43e08f5f490b86ea8eb413efd#diff-4ed97dde92087ca0faa613483bfa26f208e8a5b16830036867bb4c1d668c877aL38' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76731092</div><div id='project'> Project Name: abhi1thakur/tez</div><div id='commit'> Commit Name: dda5ac9c1e1ea0e43e08f5f490b86ea8eb413efd</div><div id='time'> Time: 2020-12-26</div><div id='author'> Author: abhishek4@gmail.com</div><div id='file'> File Name: tez/datasets/image_classification.py</div><div id='m_class'> M Class Name: ImageDataset</div><div id='n_method'> N Class Name: ImageDataset</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tez/datasets/image_classification.py</div><div id='n_file'> N File Name: tez/datasets/image_classification.py</div><div id='m_start'> M Start Line: 41</div><div id='m_end'> M End Line: 67</div><div id='n_start'> N Start Line: 46</div><div id='n_end'> N End Line: 63</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    input_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    &#47&#47 Resize input image
    input_img<a id="change"> = </a><a id="change">cv2.resize(</a>input_img, (input_width<a id="change">, input_height</a>)<a id="change">)</a>
    &#47&#47 Scale input pixel values to 0 to 1
    input_img = input_img / 255.0
    input_img = input_img.transpose(2, 0, 1)
    input_tensor = input_img[np.newaxis, :, :, :].astype(np.float32)</code></pre><h3>After Change</h3><pre><code class='java'>

def prepare_input(image, input_shape, stride, pt):
    input_tensor = LetterBox(input_shape, auto=pt, stride=stride)(image=image)
    input_tensor = <a id="change">input_tensor.transpose((2, 0, 1))[::-1]</a>  &#47&#47 HWC to CHW, BGR to RGB
    input_tensor = np.ascontiguousarray(input_tensor).astype(np.float32)  &#47&#47 contiguous
    input_tensor /= 255.0  &#47&#47 0 - 255 to 0.0 - 1.0
    input_tensor = input_tensor[None].astype(np.float32)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/augmentedstartups/as-one/commit/37de4fbaee82f479c5ca8d53a2450c7083056ef1#diff-d61e7a74edf85fb756c9fddd73b1db5b9e6605fdd3ea4cd7acbbe0aa056a27e1L6' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76731098</div><div id='project'> Project Name: augmentedstartups/as-one</div><div id='commit'> Commit Name: 37de4fbaee82f479c5ca8d53a2450c7083056ef1</div><div id='time'> Time: 2023-01-16</div><div id='author'> Author: umair.imran@axcelerate.ai</div><div id='file'> File Name: asone/detectors/yolov8/utils/yolov8_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: prepare_input(4)</div><div id='n_method'> N Method Name: prepare_input(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: asone/detectors/yolov8/utils/yolov8_utils.py</div><div id='n_file'> N File Name: asone/detectors/yolov8/utils/yolov8_utils.py</div><div id='m_start'> M Start Line: 7</div><div id='m_end'> M End Line: 15</div><div id='n_start'> N Start Line: 7</div><div id='n_end'> N End Line: 12</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    
    &#47&#47 rgb_img = img_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()  &#47&#47 [1,C,H,W]-&gt;[H,W,C]
    bgr_img = cv2.imread(img_path, 1)
    bgr_img<a id="change"> = </a><a id="change">cv2.resize(</a>bgr_img, (224<a id="change">, 224</a>)<a id="change">, interpolation=cv2.INTER_CUBIC)</a>
    bgr_img = np.float32(bgr_img) / 255  &#47&#47 归一化

    with GradCAM(model=model, target_layers=target_layers) as cam:
        cam.batch_size = 32</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 1. [B,C,H,W]-&gt;[C,H,W] 2. 反归一化
    rgb_img = img_tensor.cpu().squeeze(0) * t_std + t_mean
    &#47&#47 1. RGB-&gt;BGR 2. [C,H,W] -&gt; [H,W,C]
    bgr_img = <a id="change">rgb_img[[2, 1, 0], :, :]</a>.permute(1, 2, 0).numpy()

    try:
        with cam_algorithm(model=model, target_layers=target_layers) as cam:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bobo0810/classification/commit/1836c97e5c32c77787b9748173377cbabfa908dc#diff-250ec34c3f0b096a90b0d3e2de8d11fa993caf6e891f81fa69cc0f507171db56L98' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76731096</div><div id='project'> Project Name: bobo0810/classification</div><div id='commit'> Commit Name: 1836c97e5c32c77787b9748173377cbabfa908dc</div><div id='time'> Time: 2022-03-30</div><div id='author'> Author: lipengbo@kanzhun.com</div><div id='file'> File Name: Utils/tools.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: vis_cam(4)</div><div id='n_method'> N Method Name: vis_cam(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: Utils/tools.py</div><div id='n_file'> N File Name: Utils/tools.py</div><div id='m_start'> M Start Line: 105</div><div id='m_end'> M End Line: 120</div><div id='n_start'> N Start Line: 130</div><div id='n_end'> N End Line: 161</div><BR>