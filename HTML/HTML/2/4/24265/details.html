<html><h3>Pattern ID :24265
</h3><img src='75317148.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    optimizer = init_optimizer(model.parameters(), **optimizer_kwargs(args))
    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=args.stepsize, gamma=args.gamma)

    <a id="change">if </a>args.fixbase_epoch &gt; 0:
        if hasattr(model, &quotclassifier&quot) and isinstance(model.classifier, nn.Module):
            optimizer_tmp = init_optimizer(model.classifier.parameters(), **optimizer_kwargs(args))
        else:
            print("Warn: model has no attribute &quotclassifier&quot and fixbase_epoch is reset to 0")
            args.fixbase_epoch = 0
        <a id="change">raise </a>NotImplementedError

    if args.load_weights and check_isfile(args.load_weights):
        &#47&#47 load pretrained weights but ignore layers that don&quott match in size</code></pre><h3>After Change</h3><pre><code class='java'>

    if args.fixbase_epoch &gt; 0:
        print("Train {} for {} epochs while keeping other layers frozen".format(args.open_layers, args.fixbase_epoch))
        initial_optim_state<a id="change"> = </a>optimizer.state_dict()

        for epoch in range(args.fixbase_epoch):
            start_train_time = time.time()
            train(epoch, model, criterion, optimizer, trainloader, use_gpu, fixbase=True)
            train_time += round(time.time() - start_train_time)

        print("Done. All layers are open to train for {} epochs".format(args.max_epoch))
        <a id="change">optimizer.load_state_dict(</a>initial_optim_state<a id="change">)</a>

    for epoch in range(args.start_epoch, args.max_epoch):
        start_train_time = time.time()
        train(epoch, model, criterion, optimizer, trainloader, use_gpu)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/vlsomers/bpbreid/commit/b85e1b59d6bac874d270d2604977e9ec8bd60851#diff-e6c0c833279ad43f0c76b2e4799c36ce85c9cbbcd1aeb2f6e0af3401a600792eL40' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75317148</div><div id='project'> Project Name: vlsomers/bpbreid</div><div id='commit'> Commit Name: b85e1b59d6bac874d270d2604977e9ec8bd60851</div><div id='time'> Time: 2018-11-08</div><div id='author'> Author: k.zhou@qmul.ac.uk</div><div id='file'> File Name: train_vidreid_xent.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_vidreid_xent.py</div><div id='n_file'> N File Name: train_vidreid_xent.py</div><div id='m_start'> M Start Line: 65</div><div id='m_end'> M End Line: 127</div><div id='n_start'> N Start Line: 40</div><div id='n_end'> N End Line: 119</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    for nested_path in potential_model_paths:
        maybe_model = ckpt_dir.joinpath(*nested_path)
        <a id="change">if </a>maybe_model.exists():
            break

    if not maybe_model.exists():
        <a id="change">raise </a>AssertionError("checkpoint at {} doesn&quott include a model.pth file".format(ckpt_dir))

    code_subdirs = [str(x) for x in code_path.iterdir() if x.is_dir()]
    sys.path = [str(code_path)] + code_subdirs + sys.path</code></pre><h3>After Change</h3><pre><code class='java'>

    trial = cast(PyTorchTrial, trial)
    model = trial.build_model()
    checkpoint<a id="change"> = </a>torch.load(ckpt_dir.joinpath("state_dict.pth"), map_location="cpu")  &#47&#47 type: ignore
    <a id="change">model.load_state_dict(</a>checkpoint["model_state_dict"]<a id="change">)</a>

    return model
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/determined-ai/determined/commit/47ec6cc32234d8e797d9ae3c23d70bfb6d3a64a9#diff-90f3e871b5e54da58a3ae07e1fb06d8e642ed76363902f85b3282af52795790fL9' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75317151</div><div id='project'> Project Name: determined-ai/determined</div><div id='commit'> Commit Name: 47ec6cc32234d8e797d9ae3c23d70bfb6d3a64a9</div><div id='time'> Time: 2020-05-18</div><div id='author'> Author: sidney@determined.ai</div><div id='file'> File Name: common/determined_common/experimental/checkpoint/_torch.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: load_model(2)</div><div id='n_method'> N Method Name: load_model(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: common/determined_common/experimental/checkpoint/_torch.py</div><div id='n_file'> N File Name: common/determined_common/experimental/checkpoint/_torch.py</div><div id='m_start'> M Start Line: 10</div><div id='m_end'> M End Line: 28</div><div id='n_start'> N Start Line: 10</div><div id='n_end'> N End Line: 22</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        (lambda _: 1e100) if lr_schedule is None else lr_schedule,
    }

    <a id="change">if </a>isinstance(encoder, policy_class):
        policy = encoder
    elif policy_class == sb3_pols.ActorCriticCnnPolicy:
        policy_kwargs.update({&quotortho_init&quot: ortho_init,
                              &quotlog_std_init&quot: log_std_init})

        policy = policy_class(**policy_kwargs)
    elif policy_class == CnnPolicy:
        policy_kwargs.update({&quotoptimizer_class&quot: optimizer_class,
                              &quotoptimizer_kwargs&quot: optimizer_kwargs,
                              })

        policy = policy_class(**policy_kwargs)
    else:
        <a id="change">raise </a>NotImplementedError

    if print_policy_summary:
        &#47&#47 print policy info in case it is useful for the caller</code></pre><h3>After Change</h3><pre><code class='java'>
                                       **encoder_kwargs)

            partial_encoder_dict = encoder.state_dict()
            full_encoder_dict<a id="change"> = </a>full_encoder.state_dict()

            &#47&#47 pretrained_dict contains weights & bias for conv layers only.
            pretrained_dict = {k: v for k, v in partial_encoder_dict.items() if
                               k in full_encoder_dict}
            full_encoder_dict.update(pretrained_dict)
            <a id="change">full_encoder.load_state_dict(</a>full_encoder_dict<a id="change">)</a>

            encoder = full_encoder

        policy_kwargs = {</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/bd5e3f1d81db75a1241a9fd43d7b1daba1286152#diff-c89e267c35244f4a7b1392541f3a998a20951f7d934bb7dc532f18d3bdc5ab04L32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75317140</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: bd5e3f1d81db75a1241a9fd43d7b1daba1286152</div><div id='time'> Time: 2021-10-18</div><div id='author'> Author: cyn0531@hku.hk</div><div id='file'> File Name: src/il_representations/scripts/policy_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: make_policy(0)</div><div id='n_method'> N Method Name: make_policy(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/il_representations/scripts/policy_utils.py</div><div id='n_file'> N File Name: src/il_representations/scripts/policy_utils.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 87</div><div id='n_start'> N Start Line: 57</div><div id='n_end'> N End Line: 118</div><BR>