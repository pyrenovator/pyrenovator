<html><h3>Pattern ID :39057
</h3><img src='111252066.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

            loss_G = loss_Gmain

            loss_G = loss_G<a id="change"> * </a><a id="change">float(</a>gain<a id="change">)</a>
            loss_G.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。

        &#47&#47 Gpl: Apply path length regularization.
        if do_Gpl:</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 if do_Dmain:
            &#47&#47     loss4 += loss3
            &#47&#47 loss4.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。
            <a id="change">(real_logits * 0 + loss_Dreal + loss_Dr1).mean().mul(gain).backward()</a>
        return loss_numpy

    def train_iter(self, optimizers=None):
        phase_real_img = self.input[0]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/miemie2013/miemiegan/commit/cf43a0a8db722386b89e71d5d33b472774867ea1#diff-c3be3e49b4968a2ee433a8b0d38c7aa9f68d5116602220ff22567e41b765b44bL148' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111252066</div><div id='project'> Project Name: miemie2013/miemiegan</div><div id='commit'> Commit Name: cf43a0a8db722386b89e71d5d33b472774867ea1</div><div id='time'> Time: 2022-02-24</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_class'> M Class Name: StyleGANv2ADAModel</div><div id='n_method'> N Class Name: StyleGANv2ADAModel</div><div id='m_method'> M Method Name: accumulate_gradients(8)</div><div id='n_method'> N Method Name: accumulate_gradients(8)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='n_file'> N File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_start'> M Start Line: 148</div><div id='m_end'> M End Line: 236</div><div id='n_start'> N Start Line: 176</div><div id='n_end'> N End Line: 268</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                loss_numpy[&quotloss_Gmain&quot] = loss_Gmain.cpu().detach().numpy()

                loss_G = loss_Gmain
                loss_G = loss_G<a id="change"> * </a><a id="change">float(</a>gain<a id="change">)</a>
            with torch.autograd.profiler.record_function(&quotGmain_backward&quot):
                loss_G.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。
                if self.align_grad:
                    mapping = self.mapping.module if self.is_distributed else self.mapping</code></pre><h3>After Change</h3><pre><code class='java'>
                &#47&#47     loss4 += loss3
            with torch.autograd.profiler.record_function(name + &quot_backward&quot):
                &#47&#47 loss4.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。
                <a id="change">(real_logits * 0 + loss_Dreal + loss_Dr1).mean().mul(gain).backward()</a>
                if self.align_grad:
                    mapping = self.mapping.module if self.is_distributed else self.mapping
                    synthesis = self.synthesis.module if self.is_distributed else self.synthesis
                    discriminator = self.discriminator.module if self.is_distributed else self.discriminator</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/miemie2013/miemiegan/commit/308da226a2d1e0dc4f2c0543c80e1904d79a3bf1#diff-c3be3e49b4968a2ee433a8b0d38c7aa9f68d5116602220ff22567e41b765b44bL177' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111252071</div><div id='project'> Project Name: miemie2013/miemiegan</div><div id='commit'> Commit Name: 308da226a2d1e0dc4f2c0543c80e1904d79a3bf1</div><div id='time'> Time: 2022-04-09</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_class'> M Class Name: StyleGANv2ADAModel</div><div id='n_method'> N Class Name: StyleGANv2ADAModel</div><div id='m_method'> M Method Name: accumulate_gradients(9)</div><div id='n_method'> N Method Name: accumulate_gradients(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='n_file'> N File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_start'> M Start Line: 184</div><div id='m_end'> M End Line: 353</div><div id='n_start'> N Start Line: 208</div><div id='n_end'> N End Line: 356</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                output = model(data_batch)
                loss = loss_func(output, target_batch)
                loss_ = loss.detach().clone()
                loss.div_(math.ceil(<a id="change">float(</a>len(data)<a id="change">) / </a>args.batch_size))
                loss.backward()
            
                with torch.no_grad():</code></pre><h3>After Change</h3><pre><code class='java'>
                output = model(data_batch)
                loss = loss_func(output, target_batch)
                loss_ = loss.detach().clone() 
                loss = loss<a id="change"> / </a>args.batches_per_allreduce
                if args.horovod:
                    loss.backward()
                else:
                    if i &lt; args.batches_per_allreduce:
                        with model.no_sync():
                            loss.backward()
                    else:
                        <a id="change">loss.backward()</a>

                with torch.no_grad():            
                    train_loss.update(loss_)
                    train_accuracy.update(accuracy(output, target_batch))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/gpauloski/kfac-pytorch/commit/c3fcd61225f75c5c0e412d60183be6c62599bfae#diff-921ec75f8ca15d3d54be394e907c34938d5a1a7a8f29de98be9e97f32bc1ead5L9' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 111252107</div><div id='project'> Project Name: gpauloski/kfac-pytorch</div><div id='commit'> Commit Name: c3fcd61225f75c5c0e412d60183be6c62599bfae</div><div id='time'> Time: 2020-06-28</div><div id='author'> Author: gpauloski@yahoo.com</div><div id='file'> File Name: examples/cnn_utils/engine.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(9)</div><div id='n_method'> N Method Name: train(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/cnn_utils/engine.py</div><div id='n_file'> N File Name: examples/cnn_utils/engine.py</div><div id='m_start'> M Start Line: 21</div><div id='m_end'> M End Line: 57</div><div id='n_start'> N Start Line: 21</div><div id='n_end'> N End Line: 65</div><BR>