<html><h3>Pattern ID :19380
</h3><img src='63257708.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            collation_fn=default_collate))

        &#47&#47 do not start more workers than the number of shards
        wds_workers = <a id="change">min(</a>len(dataset.urls), self.dataset_max_workers<a id="change">)</a>
        assert wds_workers &gt; 0
        &#47&#47 TODO(sam): this isn&quott guaranteed to interleave data from different
        &#47&#47 shards randomly. The optimal solution is to write a new
        &#47&#47 IterableDataset that joins several individual datasets by taking a</code></pre><h3>After Change</h3><pre><code class='java'>
            f"Training for {n_epochs} epochs, each of {batches_per_epoch} "
            f"batches (batch size {self.batch_size})")

        for epoch_num in <a id="change">range(</a>1, n_epochs<a id="change"> + 1</a><a id="change">)</a>:
            loss_meter = AverageMeter()
            &#47&#47 Set encoder and decoder to be in training mode
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/ccdc28141c799043c5385b20f1201bc6971e462b#diff-da75b71a2421881ac87f16bdedbc66a6eee21a60650cb052fb123cfe1436b72fL220' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63257708</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: ccdc28141c799043c5385b20f1201bc6971e462b</div><div id='time'> Time: 2020-11-19</div><div id='author'> Author: sam@qxcv.net</div><div id='file'> File Name: src/il_representations/algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: learn(4)</div><div id='n_method'> N Method Name: learn(4)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: src/il_representations/algos/representation_learner.py</div><div id='n_file'> N File Name: src/il_representations/algos/representation_learner.py</div><div id='m_start'> M Start Line: 220</div><div id='m_end'> M End Line: 354</div><div id='n_start'> N Start Line: 220</div><div id='n_end'> N End Line: 343</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            collation_fn=default_collate))

        &#47&#47 do not start more workers than the number of shards
        wds_workers = <a id="change">min(</a>len(dataset.urls), self.dataset_max_workers<a id="change">)</a>
        assert wds_workers &gt; 0
        &#47&#47 TODO(sam): this isn&quott guaranteed to interleave data from different
        &#47&#47 shards randomly. The optimal solution is to write a new
        &#47&#47 IterableDataset that joins several individual datasets by taking a</code></pre><h3>After Change</h3><pre><code class='java'>
            f"Training for {n_epochs} epochs, each of {batches_per_epoch} "
            f"batches (batch size {self.batch_size})")

        for epoch_num in <a id="change">range(</a>1, n_epochs<a id="change"> + 1</a><a id="change">)</a>:
            loss_meter = AverageMeter()
            &#47&#47 Set encoder and decoder to be in training mode
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/579e0a8ca8ba0c924b8c8f393d9445915448617d#diff-da75b71a2421881ac87f16bdedbc66a6eee21a60650cb052fb123cfe1436b72fL215' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63257710</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: 579e0a8ca8ba0c924b8c8f393d9445915448617d</div><div id='time'> Time: 2020-11-19</div><div id='author'> Author: sam@qxcv.net</div><div id='file'> File Name: src/il_representations/algos/representation_learner.py</div><div id='m_class'> M Class Name: RepresentationLearner</div><div id='n_method'> N Class Name: RepresentationLearner</div><div id='m_method'> M Method Name: learn(4)</div><div id='n_method'> N Method Name: learn(4)</div><div id='m_parent_class'> M Parent Class: BaseEnvironmentLearner</div><div id='n_parent_class'> N Parent Class: BaseEnvironmentLearner</div><div id='m_file'> M File Name: src/il_representations/algos/representation_learner.py</div><div id='n_file'> N File Name: src/il_representations/algos/representation_learner.py</div><div id='m_start'> M Start Line: 220</div><div id='m_end'> M End Line: 354</div><div id='n_start'> N Start Line: 220</div><div id='n_end'> N End Line: 343</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    else:
        x_range = (
            <a id="change">min(</a>dist.min(), dist.min()<a id="change">)</a>,
            max(dist.max(), dist.max())
        )
</code></pre><h3>After Change</h3><pre><code class='java'>
            xs = sorted(np.unique(dist))
            if len(xs) &gt; 50:
                &#47&#47 If there are too many values, we take only 50, using a constant interval between them:
                xs = list(<a id="change">range(</a>int(xs[0]), int(xs[-1]) + 1, int((xs[-1] - xs[0])<a id="change"> // 50</a>)<a id="change">)</a>)
        else:
            &#47&#47 Heuristically take points on x-axis to show on the plot
            &#47&#47 The intuition is the graph will look "smooth" wherever we will zoom it</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/deepchecks/deepchecks/commit/0bd8be4792b38c96daa3fdb0c303db46fe3d49ef#diff-8a379fe2136e3990478a4d396e8db9801297ad87205363039c96402acd64e935L26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 63257707</div><div id='project'> Project Name: deepchecks/deepchecks</div><div id='commit'> Commit Name: 0bd8be4792b38c96daa3fdb0c303db46fe3d49ef</div><div id='time'> Time: 2023-04-02</div><div id='author'> Author: 92314933+nirhutnik@users.noreply.github.com</div><div id='file'> File Name: deepchecks/nlp/utils/nlp_plot.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: get_text_outliers_graph(6)</div><div id='n_method'> N Method Name: get_text_outliers_graph(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: deepchecks/nlp/utils/nlp_plot.py</div><div id='n_file'> N File Name: deepchecks/nlp/utils/nlp_plot.py</div><div id='m_start'> M Start Line: 113</div><div id='m_end'> M End Line: 123</div><div id='n_start'> N Start Line: 123</div><div id='n_end'> N End Line: 141</div><BR>