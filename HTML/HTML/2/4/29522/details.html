<html><h3>Pattern ID :29522
</h3><img src='87522326.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 text, text_len, speech, speech_len, durations, energy, pitch, utterance condition, language_id
    return (pad_sequence([datapoint[0] for datapoint in batch], batch_first=True),
            torch.stack([datapoint[1] for datapoint in batch]).squeeze(1),
            pad_to_multiple_of_n(<a id="change">pad_sequence([datapoint[2] for datapoint in batch]</a><a id="change">, batch_first=True)</a>),
            torch.stack([datapoint[3] for datapoint in batch]).squeeze(1),
            pad_sequence([datapoint[4] for datapoint in batch], batch_first=True),
            pad_sequence([datapoint[5] for datapoint in batch], batch_first=True),</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 text, text_len, speech, speech_len, durations, energy, pitch, utterance condition, language_id
    return (pad_sequence([datapoint[0] for datapoint in batch], batch_first=True),
            torch.stack([datapoint[1] for datapoint in batch]).squeeze(1),
            <a id="change">pad_sequence([datapoint[2] for datapoint in batch]</a><a id="change">, batch_first=True)</a>,
            torch.stack([datapoint[3] for datapoint in batch]).squeeze(1),
            pad_sequence([datapoint[4] for datapoint in batch], batch_first=True),
            pad_sequence([datapoint[5] for datapoint in batch], batch_first=True),</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/25d5dd64db2eb9b9512b343ad11ef047c1fe09cc#diff-241ea0a4da614fa4b0dbd748ea10aae1c34265d57f46001c62ec2994245ee0f7L25' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87522326</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 25d5dd64db2eb9b9512b343ad11ef047c1fe09cc</div><div id='time'> Time: 2022-12-27</div><div id='author'> Author: lux.florian@gmail.com</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/PortaSpeech/portaspeech_train_loop.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: collate_and_pad(1)</div><div id='n_method'> N Method Name: collate_and_pad(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/PortaSpeech/portaspeech_train_loop.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/PortaSpeech/portaspeech_train_loop.py</div><div id='m_start'> M Start Line: 27</div><div id='m_end'> M End Line: 27</div><div id='n_start'> N Start Line: 25</div><div id='n_end'> N End Line: 25</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 text, text_len, speech, speech_len, speaker_emb, language_id
            return (pad_sequence([datapoint[0] for datapoint in batch], batch_first=True),
                    torch.stack([datapoint[1] for datapoint in batch]).squeeze(1),
                    <a id="change">pad_sequence([datapoint[2] for datapoint in batch]</a><a id="change">, batch_first=True)</a>,
                    torch.stack([datapoint[3] for datapoint in batch]).squeeze(1),
                    torch.stack([datapoint[4] for datapoint in batch]),
                    torch.stack([torch.LongTensor([datapoint[5]]) for datapoint in batch]).squeeze(1))</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 text, text_len, speech, speech_len, speaker_emb, prior, language_id
            return (pad_sequence([datapoint[0] for datapoint in batch], batch_first=True),
                    torch.stack([datapoint[1] for datapoint in batch]).squeeze(1),
                    <a id="change">pad_sequence([datapoint[2] for datapoint in batch]</a><a id="change">, batch_first=True)</a>,
                    torch.stack([datapoint[3] for datapoint in batch]).squeeze(1),
                    torch.stack([datapoint[4] for datapoint in batch]),
                    pad_sequence([datapoint[5] for datapoint in batch], batch_first=True),</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/eb086a77e9b9c7491b724043fd222771d9b62250#diff-50506526d43ed453ff387fee15511f145ae91f8e336dbcc118883a5d89a1232cL75' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87522336</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: eb086a77e9b9c7491b724043fd222771d9b62250</div><div id='time'> Time: 2021-10-12</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/tacotron2_train_loop.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: collate_and_pad(1)</div><div id='n_method'> N Method Name: collate_and_pad(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/tacotron2_train_loop.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/tacotron2_train_loop.py</div><div id='m_start'> M Start Line: 77</div><div id='m_end'> M End Line: 93</div><div id='n_start'> N Start Line: 77</div><div id='n_end'> N End Line: 110</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 text, text_len, speech, speech_len, durations, energy, pitch, utterance condition, language_id
    return (pad_sequence([datapoint[0] for datapoint in batch], batch_first=True),
            torch.stack([datapoint[1] for datapoint in batch]).squeeze(1),
            <a id="change">pad_sequence([datapoint[2] for datapoint in batch]</a><a id="change">, batch_first=True)</a>,
            torch.stack([datapoint[3] for datapoint in batch]).squeeze(1),
            pad_sequence([datapoint[4] for datapoint in batch], batch_first=True),
            pad_sequence([datapoint[5] for datapoint in batch], batch_first=True),</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 text, text_len, speech, speech_len, durations, energy, pitch, utterance condition, language_id
    return (pad_sequence([datapoint[0] for datapoint in batch], batch_first=True),
            torch.stack([datapoint[1] for datapoint in batch]).squeeze(1),
            pad_to_multiple_of_n(<a id="change">pad_sequence([datapoint[2] for datapoint in batch]</a><a id="change">, batch_first=True)</a>),
            torch.stack([datapoint[3] for datapoint in batch]).squeeze(1),
            pad_sequence([datapoint[4] for datapoint in batch], batch_first=True),
            pad_sequence([datapoint[5] for datapoint in batch], batch_first=True),</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/6ee8e5267500b1fcf21eeef1e4c083525bcd090b#diff-241ea0a4da614fa4b0dbd748ea10aae1c34265d57f46001c62ec2994245ee0f7L22' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87522335</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 6ee8e5267500b1fcf21eeef1e4c083525bcd090b</div><div id='time'> Time: 2022-12-26</div><div id='author'> Author: lux.florian@gmail.com</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/PortaSpeech/portaspeech_train_loop.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: collate_and_pad(1)</div><div id='n_method'> N Method Name: collate_and_pad(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/PortaSpeech/portaspeech_train_loop.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/PortaSpeech/portaspeech_train_loop.py</div><div id='m_start'> M Start Line: 26</div><div id='m_end'> M End Line: 26</div><div id='n_start'> N Start Line: 27</div><div id='n_end'> N End Line: 27</div><BR>