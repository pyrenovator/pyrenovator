<html><h3>Pattern ID :31263
</h3><img src='91648158.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        for pipeline in pipelines:
            if pipeline.sequence_length &gt; current_seq_len:
                return pipeline
        <a id="change">return </a>pipelines[-1]

    @staticmethod
    def _get_current_sequence_length(input_schema):</code></pre><h3>After Change</h3><pre><code class='java'>
        :return: The correct Pipeline object (or Bucket) to route input to
        
        tokenizer = pipelines[0].tokenizer
        tokens<a id="change"> = </a><a id="change">tokenizer(
            </a>input_schema.sequences<a id="change">,
            add_special_tokens=True,
            return_tensors="np",
            padding=False,
            truncation=False,
        )</a>
        input_seq_len = len(tokens)
        <a id="change">return </a>TransformersPipeline.select_bucket_by_seq_len(input_seq_len, pipelines)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/neuralmagic/deepsparse/commit/20f708e7d739d5395b74dcbdcca1e48811d4bda1#diff-34d1b69d4854619e33f49d324826752e0354b65434899ce3e161cbd5e5c841e4L308' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 91648158</div><div id='project'> Project Name: neuralmagic/deepsparse</div><div id='commit'> Commit Name: 20f708e7d739d5395b74dcbdcca1e48811d4bda1</div><div id='time'> Time: 2022-07-28</div><div id='author'> Author: rahul@neuralmagic.com</div><div id='file'> File Name: src/deepsparse/transformers/pipelines/text_classification.py</div><div id='m_class'> M Class Name: TextClassificationPipeline</div><div id='n_method'> N Class Name: TextClassificationPipeline</div><div id='m_method'> M Method Name: route_input_to_bucket(0)</div><div id='n_method'> N Method Name: route_input_to_bucket(0)</div><div id='m_parent_class'> M Parent Class: TransformersPipeline</div><div id='n_parent_class'> N Parent Class: TransformersPipeline</div><div id='m_file'> M File Name: src/deepsparse/transformers/pipelines/text_classification.py</div><div id='n_file'> N File Name: src/deepsparse/transformers/pipelines/text_classification.py</div><div id='m_start'> M Start Line: 308</div><div id='m_end'> M End Line: 315</div><div id='n_start'> N Start Line: 308</div><div id='n_end'> N End Line: 317</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for pipeline in pipelines:
            if pipeline.sequence_length &gt; current_seq_len:
                return pipeline
        <a id="change">return </a>pipelines[-1]

    &#47&#47 utilities below adapted from transformers
</code></pre><h3>After Change</h3><pre><code class='java'>
        :return: The correct Pipeline object (or Bucket) to route input to
        
        tokenizer = pipelines[0].tokenizer
        tokens = <a id="change">tokenizer(
            </a>input_schema.inputs<a id="change">,
            add_special_tokens=True,
            return_tensors="np",
            padding=False,
            truncation=False,
        )</a>
        input_seq_len<a id="change"> = </a>len(tokens)
        <a id="change">return </a>TransformersPipeline.select_bucket_by_seq_len(input_seq_len, pipelines)

    &#47&#47 utilities below adapted from transformers
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neuralmagic/deepsparse/commit/20f708e7d739d5395b74dcbdcca1e48811d4bda1#diff-79e61bee1aadf04d6fd38371cf45def5472039227cde7f4e9bd194e76fe373bcL400' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 91648157</div><div id='project'> Project Name: neuralmagic/deepsparse</div><div id='commit'> Commit Name: 20f708e7d739d5395b74dcbdcca1e48811d4bda1</div><div id='time'> Time: 2022-07-28</div><div id='author'> Author: rahul@neuralmagic.com</div><div id='file'> File Name: src/deepsparse/transformers/pipelines/token_classification.py</div><div id='m_class'> M Class Name: TokenClassificationPipeline</div><div id='n_method'> N Class Name: TokenClassificationPipeline</div><div id='m_method'> M Method Name: route_input_to_bucket(0)</div><div id='n_method'> N Method Name: route_input_to_bucket(0)</div><div id='m_parent_class'> M Parent Class: TransformersPipeline</div><div id='n_parent_class'> N Parent Class: TransformersPipeline</div><div id='m_file'> M File Name: src/deepsparse/transformers/pipelines/token_classification.py</div><div id='n_file'> N File Name: src/deepsparse/transformers/pipelines/token_classification.py</div><div id='m_start'> M Start Line: 408</div><div id='m_end'> M End Line: 421</div><div id='n_start'> N Start Line: 408</div><div id='n_end'> N End Line: 417</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    
    doc_section_to_text_map = documents_to_document_section_text_map(docs)
    batch_encodings = tokenizer(list(doc_section_to_text_map.values()))
    <a id="change">return </a>batch_encodings, list(doc_section_to_text_map.keys())


def get_match_entity_class_hash(ent: Entity) -&gt; int:</code></pre><h3>After Change</h3><pre><code class='java'>
    id_section_map = documents_to_id_section_map(docs)
    strings = [section.text for section in id_section_map.values()]

    batch_encodings<a id="change"> = </a><a id="change">tokenizer(
        </a>strings<a id="change">,
        stride=stride,
        max_length=max_length,
        truncation=TruncationStrategy.LONGEST_FIRST,
        return_overflowing_tokens=True,
        padding=PaddingStrategy.MAX_LENGTH,
    )</a>
    <a id="change">return </a>batch_encodings, id_section_map


def get_match_entity_class_hash(ent: Entity) -&gt; int:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/astrazeneca/kazu/commit/6d3b478711b45c3afe0cbf978e7a51942d53e0c2#diff-09e98109421c3cb1e7150e2396b31d07503b6c23682596a5b11807e15893eef3L32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 91648152</div><div id='project'> Project Name: astrazeneca/kazu</div><div id='commit'> Commit Name: 6d3b478711b45c3afe0cbf978e7a51942d53e0c2</div><div id='time'> Time: 2021-11-16</div><div id='author'> Author: richard.jackson4@astrazeneca.com</div><div id='file'> File Name: azner/utils/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: documents_to_document_section_batch_encodings_map(4)</div><div id='n_method'> N Method Name: documents_to_document_section_batch_encodings_map(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: azner/utils/utils.py</div><div id='n_file'> N File Name: azner/utils/utils.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 42</div><div id='n_start'> N Start Line: 51</div><div id='n_end'> N End Line: 69</div><BR>