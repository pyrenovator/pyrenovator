<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                    step=4, allow_overlap=VID_DATA_ALLOW_OVERLAP)
    test_loader = DataLoader(test_data, batch_size=1, shuffle=True, num_workers=4)

    i<a id="change"> = </a>0
    loop = tqdm(test_loader)
    for batch_idx, frames in enumerate(loop):

        if i &gt;= 10: <a id="change">break</a>

        frames = frames.to(DEVICE)  &#47&#47 [1, T, 3, h, w]
        frames_vis = postprocess_img(frames.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
        input = frames[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 3, h, w]</code></pre><h3>After Change</h3><pre><code class='java'>
            pred_rgb = pred_rgb.argmax(dim=2).squeeze()  &#47&#47 [T, h, w]
            pred_then_colorized_vis = colorize_semseg(postprocess_mask(pred_rgb), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2) &#47&#47 [T, 3, h, w]

            frames_seg = <a id="change">torch.stack([seg_model(frames[:, i]) for i in range(frames.shape[1])], dim=1).argmax(dim=2)</a>  &#47&#47 [1, T, 1, h, w]
            frames_seg_in = torch.stack([(frames_seg == i) for i in range(SYNPICK_CLASSES)], dim=2).float()  &#47&#47 [1, T, c, h, w] one-hot float
            input_seg = frames_seg_in[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, c, h, w]
            pred_mask = pred_mask_model.pred_n(input_seg, pred_length=VIDEO_PRED_LENGTH).argmax(dim=2)  &#47&#47 [1, n, 1, h, w]
            pred_mask = torch.cat([input_seg.argmax(dim=2), pred_mask], dim=1).squeeze()  &#47&#47 [T, h, w]
            pred_mask_vis = colorize_semseg(postprocess_mask(pred_mask), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2)  &#47&#47 [T, 3, h, w]

            frames_colorized = colorize_semseg(postprocess_mask(frames_seg.squeeze()), num_classes=SYNPICK_CLASSES)
            frames_colorized_vis<a id="change"> = </a>frames_colorized.transpose(0, 3, 1, 2)  &#47&#47 [T, 3, h, w]

            input_colorized = preprocess_img(frames_colorized[:VIDEO_IN_LENGTH]).to(DEVICE).unsqueeze(dim=0)  &#47&#47 [b, t, 3, h, w]
            colorized_then_pred = pred_colorized_mask_model.pred_n(input_colorized, pred_length=VIDEO_PRED_LENGTH)</code></pre>