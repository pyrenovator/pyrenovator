<html><h3>Pattern ID :7384
</h3><img src='24575894.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    weight_shape = [ctx.dims.spatial_mixing_kernel] * 2
    for i in range(items):
        mask = jnp.triu(jnp.ones(weight_shape, dtype=ctx.model.computation_dtype)) if ctx.model.autoregressive else 1
        wgt<a id="change"> = </a><a id="change">get_param(</a>ctx, <a id="change">f"mix_{i}"</a>, weight_shape<a id="change">)</a> * mask
        if ctx.is_initializing:
            continue
        if i != 0:</code></pre><h3>After Change</h3><pre><code class='java'>
    inp = inp.transpose(0, 3, 1, 2)
    shape = inp.shape
    transposed_shape = list(shape)
    transposed_shape[3], transposed_shape[2] = transposed_shape[2]<a id="change">, transposed_shape[3]</a>
    for i, wgt in enumerate(weights):
        wgt = wgt * mask
        if i != 0:
            inp = inp.reshape(*transposed_shape)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/homebrewnlp/homebrewnlp-jax/commit/bfe53eb59aee047d89cd71559ff88ff3db2ff840#diff-efcd90cee8fb4dad861da47df28097bc6935541500854b8e2d68e0970e05f748L15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24575894</div><div id='project'> Project Name: homebrewnlp/homebrewnlp-jax</div><div id='commit'> Commit Name: bfe53eb59aee047d89cd71559ff88ff3db2ff840</div><div id='time'> Time: 2022-08-31</div><div id='author'> Author: 39779310+ClashLuke@users.noreply.github.com</div><div id='file'> File Name: src/model/mixer.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mix(2)</div><div id='n_method'> N Method Name: mix(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/model/mixer.py</div><div id='n_file'> N File Name: src/model/mixer.py</div><div id='m_start'> M Start Line: 15</div><div id='m_end'> M End Line: 31</div><div id='n_start'> N Start Line: 15</div><div id='n_end'> N End Line: 36</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def instantiate_net(architecture: Union[torch.nn.Module, SgModule.__class__, str], arch_params: dict,
                        checkpoint_params: dict, *args, **kwargs) -&gt; tuple:

        student<a id="change"> = </a><a id="change">get_param(</a>kwargs, <a id="change">"student"</a><a id="change">)</a>
        teacher = get_param(kwargs, "teacher")
        run_teacher_on_eval = get_param(kwargs, "run_teacher_on_eval", default_val=False)

        architecture_cls = None</code></pre><h3>After Change</h3><pre><code class='java'>
        student_pretrained_weights = get_param(checkpoint_params, &quotstudent_pretrained_weights&quot)
        teacher_pretrained_weights = get_param(checkpoint_params, &quotteacher_pretrained_weights&quot)

        student<a id="change">, _</a> = SgModel.instantiate_net(student_architecture, student_arch_params,
                                             {"pretrained_weights": student_pretrained_weights})

        teacher, _ = SgModel.instantiate_net(teacher_architecture, teacher_arch_params,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/deci-ai/super-gradients/commit/fd2982220f15bdc2ae747f74573fc5e04ea57442#diff-163a30a858b14940bfef49f7c8c9937e0812d0af5eae9857cbf03a64b2d2f19fL203' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24575892</div><div id='project'> Project Name: deci-ai/super-gradients</div><div id='commit'> Commit Name: fd2982220f15bdc2ae747f74573fc5e04ea57442</div><div id='time'> Time: 2022-03-29</div><div id='author'> Author: shay.aharon@deci.ai</div><div id='file'> File Name: src/super_gradients/training/kd_model/kd_model.py</div><div id='m_class'> M Class Name: KDModel</div><div id='n_method'> N Class Name: KDModel</div><div id='m_method'> M Method Name: instantiate_net(3)</div><div id='n_method'> N Method Name: instantiate_net(3)</div><div id='m_parent_class'> M Parent Class: SgModel</div><div id='n_parent_class'> N Parent Class: SgModel</div><div id='m_file'> M File Name: src/super_gradients/training/kd_model/kd_model.py</div><div id='n_file'> N File Name: src/super_gradients/training/kd_model/kd_model.py</div><div id='m_start'> M Start Line: 206</div><div id='m_end'> M End Line: 207</div><div id='n_start'> N Start Line: 173</div><div id='n_end'> N End Line: 186</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    for i, old_stat in enumerate(preconditioner.statistics_from_grad(grad)):
        new_stat = ema(ctx, old_stat, step, 1 - ctx.optimizer.shampoo_beta2, f"statistics_{i}", True,
                       jnp.eye(old_stat.shape[0], dtype=ctx.model.storage_dtype) * ctx.optimizer.epsilon)
        prev_p<a id="change"> = </a><a id="change">get_param(</a>ctx, <a id="change">f&quotpreconditioner_{i}&quot</a>, old_stat.shape<a id="change">, dtype=ctx.model.storage_dtype,
                           init_val=jnp.eye(old_stat.shape[0], dtype=ctx.model.storage_dtype))</a>
        if ctx.is_initializing:
            continue

        new_p, error = matrix_inverse_pth_root(new_stat, preconditioner.exponent_for_preconditioner(),</code></pre><h3>After Change</h3><pre><code class='java'>

def shampoo(ctx: Context, grad: jnp.ndarray, step: jnp.ndarray) -&gt; jnp.ndarray:
    last_size = grad.shape[-1]
    kernel_sizes = (ctx.dims.pointwise_kernel<a id="change">, ctx.dims.outer_bottleneck_kernel, ctx.dims.inner_bottleneck_kernel</a>)
    if grad.ndim != 3 or last_size not in kernel_sizes:
        return _shampoo(ctx, grad, step)
    return jnp.stack([_shampoo(ctx, grad[:, :, i], step) for i in range(last_size)])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/homebrewnlp/homebrewnlp-jax/commit/cee3cb499f3e75c256827c8b9e52ebe1d028e39d#diff-4540d7c8541eb25568b448ea775d64c43be83ce020bc67dd8340da4d4e804846L69' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24575890</div><div id='project'> Project Name: homebrewnlp/homebrewnlp-jax</div><div id='commit'> Commit Name: cee3cb499f3e75c256827c8b9e52ebe1d028e39d</div><div id='time'> Time: 2022-06-28</div><div id='author'> Author: 39779310+ClashLuke@users.noreply.github.com</div><div id='file'> File Name: src/optimizer.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: shampoo(3)</div><div id='n_method'> N Method Name: shampoo(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/optimizer.py</div><div id='n_file'> N File Name: src/optimizer.py</div><div id='m_start'> M Start Line: 70</div><div id='m_end'> M End Line: 89</div><div id='n_start'> N Start Line: 93</div><div id='n_end'> N End Line: 97</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if weight is None:
        weight = get_param(ctx, "scale", [feature_dim], std=0, mean=1, dtype=run_type)
        if not ctx.is_initializing:
            weight_sq<a id="change"> = </a><a id="change">get_param(</a>ctx, <a id="change">"scale_sq"</a><a id="change">, dtype=run_type)</a>
    elif weight is False:
        weight_sq = weight = 1
    else:
        weight, weight_sq = weight</code></pre><h3>After Change</h3><pre><code class='java'>
                   psum: bool = False, act: bool = True, dim: int = 2) -&gt; jnp.ndarray:
    run_type = jnp.promote_types(ctx.model.computation_dtype, jnp.float32)
    if weight is None:
        weight<a id="change">, weight_sq</a> = get_param(ctx, "scale", [feature_dim], std=0, mean=1, dtype=run_type, return_sq=True)
    elif weight is False:
        weight_sq = weight = 1
    else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/homebrewnlp/homebrewnlp-jax/commit/1f17f878634d2acb4d95303f4f0a6c3a0650fbba#diff-d6f894a983edd688b2548ed7bc5a87c1055c329cb7a6340bc0674de70cfbd5d7L54' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24575903</div><div id='project'> Project Name: homebrewnlp/homebrewnlp-jax</div><div id='commit'> Commit Name: 1f17f878634d2acb4d95303f4f0a6c3a0650fbba</div><div id='time'> Time: 2022-12-06</div><div id='author'> Author: 39779310+ClashLuke@users.noreply.github.com</div><div id='file'> File Name: src/model/norm.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: scale_norm_act(7)</div><div id='n_method'> N Method Name: scale_norm_act(7)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/model/norm.py</div><div id='n_file'> N File Name: src/model/norm.py</div><div id='m_start'> M Start Line: 59</div><div id='m_end'> M End Line: 62</div><div id='n_start'> N Start Line: 59</div><div id='n_end'> N End Line: 59</div><BR>