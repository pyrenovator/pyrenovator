<html><h3>Pattern ID :39780
</h3><img src='113229543.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        speech = torch.transpose(torch.Tensor(self.feature_list[index][2]), 0, 1).to(self.device)
        speech_len = torch.LongTensor([self.feature_list[index][3]]).to(self.device)
        if self.spemb:
            spemb = torch.Tensor(<a id="change">self.feature_list[index][4]</a>).to(self.device)
            return text, text_len, speech, speech_len, spemb
        return text, text_len, speech, speech_len
</code></pre><h3>After Change</h3><pre><code class='java'>
    def __getitem__(self, index):
        transcript = self.path_to_transcript_dict[self.key_list[index]]
        path = self.key_list[index]
        wave<a id="change">, sr = </a><a id="change">sf.read(</a>os.path.join("Corpora/CSS10/", path)<a id="change">)</a>
        if self.ap is None:
            self.ap = AudioPreprocessor(input_sr=sr, output_sr=16000, melspec_buckets=80, hop_length=256, n_fft=1024)
        text = self.tf.string_to_tensor(transcript).long()
        text_len = torch.LongTensor(text.shape(0))</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/1e192df888be8f1dc1c20971132b31fe73153b7d#diff-0965ad6e3a8f04afe3a358a7558e203eaa1f244ad6e8e6fbfe73f8a2052b8cb1L14' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113229543</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 1e192df888be8f1dc1c20971132b31fe73153b7d</div><div id='time'> Time: 2021-02-22</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_class'> M Class Name: TransformerTTSDataset</div><div id='n_method'> N Class Name: TransformerTTSDataset</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='n_file'> N File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_start'> M Start Line: 14</div><div id='m_end'> M End Line: 21</div><div id='n_start'> N Start Line: 32</div><div id='n_end'> N End Line: 44</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                                   self.list_of_eligible_wave_paths) // loading_processes])
        for path_split in path_splits:
            process_list.append(Process(target=self.ram_loader_process, args=(path_split,), daemon=True))
            <a id="change">process_list[-1]</a>.start()
        for process in process_list:
            process.join()
        self.waves = list(self.waves)</code></pre><h3>After Change</h3><pre><code class='java'>
        self.waves = list()
        for path in tqdm(self.list_of_eligible_wave_paths):
            with open(path, "rb") as audio_file:
                wave_orig<a id="change">, _ = </a><a id="change">sf.read(</a>audio_file<a id="change">)</a>
            self.waves.append(self.preprocess_ap.audio_to_wave_tensor(wave_orig, normalize=True, mulaw=False))
        print("{} eligible audios found".format(len(self.waves)))

    def cache_builder_process(self, path_split, samples_per_segment):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/bf3c0336c113f8ff2464d60bc18f46c482b2000e#diff-6d37714a960ee957f0bd8c25ac6b1f0f61e2e6e8f14e269209172239a689a904L16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113229541</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: bf3c0336c113f8ff2464d60bc18f46c482b2000e</div><div id='time'> Time: 2021-04-04</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: MelGAN/MelGANDataset.py</div><div id='m_class'> M Class Name: MelGANDataset</div><div id='n_method'> N Class Name: MelGANDataset</div><div id='m_method'> M Method Name: __init__(5)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: MelGAN/MelGANDataset.py</div><div id='n_file'> N File Name: MelGAN/MelGANDataset.py</div><div id='m_start'> M Start Line: 47</div><div id='m_end'> M End Line: 71</div><div id='n_start'> N Start Line: 26</div><div id='n_end'> N End Line: 61</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

def load_audio(audio_file_path, sample_rate):
    Loads the audio given the path of an audio file.
    return <a id="change">librosa.load(audio_file_path, sr=sample_rate)[0]</a>
</code></pre><h3>After Change</h3><pre><code class='java'>

def load_audio(audio_file_path, sample_rate=None, start=0, stop=None):
    Loads the audio given the path of an audio file.
    audio<a id="change">, source_sample_rate = </a><a id="change">soundfile.read(</a>audio_file_path<a id="change">, start=start, stop=stop)</a>

    if sample_rate:
        audio = resample_audio(audio, source_sample_rate, sample_rate)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/asteroid-team/torch-audiomentations/commit/17530f4674a4200c8b8975ce8825a2ebafe4b74c#diff-1475c4909da1c234c947187cc6c91507dfc05f49b5764ad927ef30cc2535495eL19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113229540</div><div id='project'> Project Name: asteroid-team/torch-audiomentations</div><div id='commit'> Commit Name: 17530f4674a4200c8b8975ce8825a2ebafe4b74c</div><div id='time'> Time: 2020-09-28</div><div id='author'> Author: francisalbertlata@gmail.com</div><div id='file'> File Name: torch_audiomentations/utils/file.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: load_audio(4)</div><div id='n_method'> N Method Name: load_audio(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torch_audiomentations/utils/file.py</div><div id='n_file'> N File Name: torch_audiomentations/utils/file.py</div><div id='m_start'> M Start Line: 19</div><div id='m_end'> M End Line: 21</div><div id='n_start'> N Start Line: 20</div><div id='n_end'> N End Line: 27</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        super().handle_input(data_type)
        filepath = os.path.join(self.artifact.uri, PROFILE_FILENAME)
        with fileio.open(filepath, "rb") as f:
            protobuf = <a id="change">DatasetProfile.parse_delimited(f.read())[0]</a>
        return protobuf

    def handle_return(self, profile: DatasetProfile) -&gt; None:
        Writes a whylogs DatasetProfile.</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 Copy from artifact store to temporary file
        fileio.copy(filepath, temp_file)
        profile_view<a id="change"> = </a><a id="change">DatasetProfileView.read(</a>temp_file<a id="change">)</a>

        &#47&#47 Cleanup and return
        fileio.rmtree(temp_dir)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/maiot-io/zenml/commit/d90521e30f11b4d501f47777fab7ebe1e70940ef#diff-23fdb53275336f42984b00b183bafc79a65016b3c30f3d47a1e35d4e0655de77L35' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113229539</div><div id='project'> Project Name: maiot-io/zenml</div><div id='commit'> Commit Name: d90521e30f11b4d501f47777fab7ebe1e70940ef</div><div id='time'> Time: 2022-07-11</div><div id='author'> Author: stefan@zenml.io</div><div id='file'> File Name: src/zenml/integrations/whylogs/materializers/whylogs_materializer.py</div><div id='m_class'> M Class Name: WhylogsMaterializer</div><div id='n_method'> N Class Name: WhylogsMaterializer</div><div id='m_method'> M Method Name: handle_input(2)</div><div id='n_method'> N Method Name: handle_input(2)</div><div id='m_parent_class'> M Parent Class: BaseMaterializer</div><div id='n_parent_class'> N Parent Class: BaseMaterializer</div><div id='m_file'> M File Name: src/zenml/integrations/whylogs/materializers/whylogs_materializer.py</div><div id='n_file'> N File Name: src/zenml/integrations/whylogs/materializers/whylogs_materializer.py</div><div id='m_start'> M Start Line: 45</div><div id='m_end'> M End Line: 48</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 63</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        total_uploaded_size = 0
        total_dataset_nbytes = 0
        info_to_dump: DatasetInfo = next(iter(self.values())).info.copy()
        dataset_name = <a id="change">repo_id.split("/")[-1]</a>
        info_to_dump.splits = SplitDict(dataset_name=dataset_name)

        for split in self.keys():
            if not re.match(_split_re, split):</code></pre><h3>After Change</h3><pre><code class='java'>
            )
            dataset_metadata = DatasetMetadata.from_readme(Path(dataset_readme_path))
            with open(dataset_readme_path, encoding="utf-8") as readme_file:
                readme_content<a id="change"> = </a><a id="change">readme_file.read()</a>
        else:
            dataset_metadata = DatasetMetadata()
            readme_content = f&quot&#47&#47 Dataset Card for "{repo_id.split("/")[-1]}"\n\n[More Information needed](https://github.com/huggingface/datasets/blob/main/CONTRIBUTING.md&#47&#47how-to-contribute-to-the-dataset-cards)&quot
        DatasetInfosDict({"default": info_to_dump}).to_metadata(dataset_metadata)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/datasets/commit/67e65c90e9490810b89ee140da11fdd13c356c9c#diff-a03fe8c218f22c8b26cc51f588cf5466c27f433373033d8724f66f996c2beda8L1284' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 113229537</div><div id='project'> Project Name: huggingface/datasets</div><div id='commit'> Commit Name: 67e65c90e9490810b89ee140da11fdd13c356c9c</div><div id='time'> Time: 2022-10-03</div><div id='author'> Author: 42851186+lhoestq@users.noreply.github.com</div><div id='file'> File Name: src/datasets/dataset_dict.py</div><div id='m_class'> M Class Name: DatasetDict</div><div id='n_method'> N Class Name: DatasetDict</div><div id='m_method'> M Method Name: push_to_hub(8)</div><div id='n_method'> N Method Name: push_to_hub(8)</div><div id='m_parent_class'> M Parent Class: dict</div><div id='n_parent_class'> N Parent Class: dict</div><div id='m_file'> M File Name: src/datasets/dataset_dict.py</div><div id='n_file'> N File Name: src/datasets/dataset_dict.py</div><div id='m_start'> M Start Line: 1346</div><div id='m_end'> M End Line: 1386</div><div id='n_start'> N Start Line: 1350</div><div id='n_end'> N End Line: 1416</div><BR>