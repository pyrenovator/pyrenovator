<html><h3>Pattern ID :25917
</h3><img src='78318875.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            for j in range(0, len(train_smiles), self.args.batch_size):
                train_batches.append(train_smiles[j:j + self.args.batch_size])
            batch_encs = [self.encoder(train_batch) for train_batch in train_batches]
            means<a id="change"> = </a>[<a id="change">torch.mean(</a>batch_encs[i]<a id="change">, dim=0, keepdim=True)</a> for i in range(len(batch_encs))]
            domain_encs.append(torch.mean(torch.cat(means, dim=0), dim=0))
        self.domain_encs = domain_encs
</code></pre><h3>After Change</h3><pre><code class='java'>
            train_batches = []
            for j in range(0, len(train_smiles), self.args.batch_size):
                train_batches.append(train_smiles[j:j + self.args.batch_size])
            means_sum<a id="change"> = </a><a id="change">torch.zeros(</a>self.args.hidden_size<a id="change">)</a>
            if self.args.cuda:
                means_sum = means_sum.cuda()
            for train_batch in train_batches:
                with torch.no_grad():</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/aamini/chemprop/commit/ce09638e4df7666a5cbdc5297eda15364cb46add#diff-eee12f70990be22455041e206b0ab84ff5903fea7888f4b78e4089cf96e59988L164' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78318875</div><div id='project'> Project Name: aamini/chemprop</div><div id='commit'> Commit Name: ce09638e4df7666a5cbdc5297eda15364cb46add</div><div id='time'> Time: 2018-10-28</div><div id='author'> Author: yangk@mit.edu</div><div id='file'> File Name: moe.py</div><div id='m_class'> M Class Name: MOE</div><div id='n_method'> N Class Name: MOE</div><div id='m_method'> M Method Name: compute_domain_encs(2)</div><div id='n_method'> N Method Name: compute_domain_encs(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: moe.py</div><div id='n_file'> N File Name: moe.py</div><div id='m_start'> M Start Line: 164</div><div id='m_end'> M End Line: 169</div><div id='n_start'> N Start Line: 164</div><div id='n_end'> N End Line: 174</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            valid_bleu_scores.append(valid_bleu_score)

        mean_valid_loss = np.mean(valid_losses)
        mean_bleu_score<a id="change"> = </a><a id="change">np.mean(</a>valid_bleu_scores<a id="change">)</a>

        return mean_valid_loss, mean_bleu_score
</code></pre><h3>After Change</h3><pre><code class='java'>
            src_input, tar_output, encoder_mask = \
                src_input.to(device), tar_output.to(device), encoder_mask.to(device)

            tar_input = <a id="change">torch.zeros(</a>tar_output.shape[0], tar_output.shape[1]<a id="change">)</a>.long()
            for seq in tar_input:
                seq[0] = sos_id

            output = self.model(src_input, tar_input, encoder_mask)  &#47&#47 (B, L, vocab_size)
            loss = self.criterion(output.view(-1, sp_vocab_size), tar_output.view(batch_size * seq_len))

            valid_losses.append(loss.item())

            output_list = torch.argmax(output, dim=-1).tolist()
            tar_output_list = tar_output.tolist()

            trimmed_output_list<a id="change">, trimmed_tar_output_list = </a>self.trim_output(output_list, tar_output_list)

            valid_pred_outputs += trimmed_output_list
            valid_true_outputs += trimmed_tar_output_list</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/devjwsong/transformer-translator-pytorch/commit/fe38eabe05fbd7e2b1b7a1077aee5f1563dba374#diff-2e5ad92c43aa96cc3a9cef6c6aec998b216f1379c43b1f651013d25e55989312L114' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78318878</div><div id='project'> Project Name: devjwsong/transformer-translator-pytorch</div><div id='commit'> Commit Name: fe38eabe05fbd7e2b1b7a1077aee5f1563dba374</div><div id='time'> Time: 2020-04-27</div><div id='author'> Author: enflwodn@gmail.com</div><div id='file'> File Name: src/main.py</div><div id='m_class'> M Class Name: Manager</div><div id='n_method'> N Class Name: Manager</div><div id='m_method'> M Method Name: validation(1)</div><div id='n_method'> N Method Name: validation(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/main.py</div><div id='n_file'> N File Name: src/main.py</div><div id='m_start'> M Start Line: 118</div><div id='m_end'> M End Line: 141</div><div id='n_start'> N Start Line: 120</div><div id='n_end'> N End Line: 148</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 attention is batch x time x heads x time_to_attend
        &#47&#47 average over batches, heads + only keep prediction attention and attention on observed timesteps
        if attention_prediction_horizon is None:  &#47&#47 average over all horizons
            attention<a id="change"> = </a><a id="change">out["attention"][..., : self.hparams.encode_length].mean(
                dim=average_dims + [2]
            )</a>  &#47&#47 todo: how to handle zero attention due to shorter encode length?
            attention = attention / attention.sum(-1).unsqueeze(-1)  &#47&#47 renormalize
            attention = attention.mean(0)  &#47&#47 average attention over all predictions
        else:</code></pre><h3>After Change</h3><pre><code class='java'>
            attention = attention.mean(dim=0)
            attention = attention / attention.sum(-1).unsqueeze(-1)  &#47&#47 renormalize

            attention<a id="change"> = </a><a id="change">torch.zeros(</a>self.hparams.max_encode_length<a id="change">)</a>.scatter(
                dim=0,
                index=torch.arange(self.hparams.max_encode_length - attention.size(0), self.hparams.max_encode_length),
                src=attention,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jdb78/pytorch-forecasting/commit/79cfec0818dbe78d8773534e6ce8f5fd578c3c3a#diff-326fa71fa47eb2d5a00ea5fa14cac5f65c967b6856192e5c0e687cbce8b581e3L551' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78318861</div><div id='project'> Project Name: jdb78/pytorch-forecasting</div><div id='commit'> Commit Name: 79cfec0818dbe78d8773534e6ce8f5fd578c3c3a</div><div id='time'> Time: 2020-06-22</div><div id='author'> Author: beitner.jan@bcg.com</div><div id='file'> File Name: temporal_fusion_transformer_pytorch/model/__init__.py</div><div id='m_class'> M Class Name: TemporalFusionTransformer</div><div id='n_method'> N Class Name: TemporalFusionTransformer</div><div id='m_method'> M Method Name: interpret_output(4)</div><div id='n_method'> N Method Name: interpret_output(4)</div><div id='m_parent_class'> M Parent Class: pl.LightningModule</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: temporal_fusion_transformer_pytorch/model/__init__.py</div><div id='n_file'> N File Name: temporal_fusion_transformer_pytorch/model/__init__.py</div><div id='m_start'> M Start Line: 555</div><div id='m_end'> M End Line: 605</div><div id='n_start'> N Start Line: 553</div><div id='n_end'> N End Line: 610</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    for i in range(len(areaNames)):
        area_ps = ps[..., i, 0]
        figure_title = iou_type + "-" + class_name + "-" + areaNames[i]
        aps<a id="change"> = </a>[<a id="change">ps_.mean()</a> for ps_ in area_ps]
        ps_curve = [ps_.mean(axis=1) if ps_.ndim &gt; 1 else ps_ for ps_ in area_ps]
        ps_curve.insert(0, np.zeros(ps_curve[0].shape))
        fig = plt.figure()</code></pre><h3>After Change</h3><pre><code class='java'>
        ps_curve = []
        for ps_ in area_ps:
            if ps_.ndim &gt; 1:
                ps_mean<a id="change"> = </a><a id="change">np.zeros(</a>(ps_.shape[0],)<a id="change">)</a>
                for ind, ps_threshold in enumerate(ps_):
                    ps_mean[ind] = ps_threshold[ps_threshold &gt; -1].mean()
                ps_curve.append(ps_mean)
            else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/obss/sahi/commit/c358cc200a67ed985790bc19deccec5fe1c4e75d#diff-d11dc70f88d3abdb3482cd1519b9fd9561abb05aefa1dfe38df27b06c3136786L11' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 78318869</div><div id='project'> Project Name: obss/sahi</div><div id='commit'> Commit Name: c358cc200a67ed985790bc19deccec5fe1c4e75d</div><div id='time'> Time: 2022-01-08</div><div id='author'> Author: 34196005+fcakyon@users.noreply.github.com</div><div id='file'> File Name: sahi/scripts/coco_error_analysis.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _makeplot(5)</div><div id='n_method'> N Method Name: _makeplot(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: sahi/scripts/coco_error_analysis.py</div><div id='n_file'> N File Name: sahi/scripts/coco_error_analysis.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 32</div><div id='n_start'> N Start Line: 31</div><div id='n_end'> N End Line: 43</div><BR>