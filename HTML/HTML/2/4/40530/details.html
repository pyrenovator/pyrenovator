<html><h3>Pattern ID :40530
</h3><img src='114761695.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 loss_Gpl = (gen_img[:, 0, 0, 0] * 0 + loss_Gpl).mean() * float(gain)
            &#47&#47 loss_numpy[&quotloss_Gpl&quot] = loss_Gpl.cpu().detach().numpy()
            &#47&#47 loss_Gpl.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。
            <a id="change">(gen_img[:, 0, 0, 0] * 0 + loss_Gpl).mean().mul(gain).backward()</a>

        &#47&#47 Dmain: Minimize logits for generated images.
        &#47&#47 loss3 = 0.0
        if do_Dmain:</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 print(&quotddd=%.6f&quot % ddd)

            loss_Gmain = torch.nn.functional.softplus(-gen_logits)  &#47&#47 -log(sigmoid(gen_logits))
            loss_Gmain<a id="change"> = </a>loss_Gmain.mean()
            loss_numpy[&quotloss_Gmain&quot]<a id="change"> = </a><a id="change">loss_Gmain.cpu()</a>.detach().numpy()

            loss_G = loss_Gmain
            loss_G = loss_G * float(gain)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/miemie2013/miemiegan/commit/fbc8738996ce75111be885ba7ac313d85969a2b8#diff-c3be3e49b4968a2ee433a8b0d38c7aa9f68d5116602220ff22567e41b765b44bL138' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 114761695</div><div id='project'> Project Name: miemie2013/miemiegan</div><div id='commit'> Commit Name: fbc8738996ce75111be885ba7ac313d85969a2b8</div><div id='time'> Time: 2022-02-25</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_class'> M Class Name: StyleGANv2ADAModel</div><div id='n_method'> N Class Name: StyleGANv2ADAModel</div><div id='m_method'> M Method Name: accumulate_gradients(8)</div><div id='n_method'> N Method Name: accumulate_gradients(8)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='n_file'> N File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_start'> M Start Line: 138</div><div id='m_end'> M End Line: 260</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 262</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                              mix_data[x][&quotrdf_range&quot],
                              f&quot{model_path}/x_{x}_{str(i).zfill(3)}_rdf.pdf&quot)

        <a id="change">loss.backward()</a>
        optimizer.step()
        optimizer.zero_grad()

        print(loss.item())</code></pre><h3>After Change</h3><pre><code class='java'>

        all_rdf11 = []
        all_rdf12 = []
        all_rdf22<a id="change"> = </a>[] 

        for epoch in range(params[&quotupdate_epoch&quot]):
            for x in params[&quottrainx&quot]:
                tau = params[&quotnsteps&quot]
                v_t, q_t, pv_t = train_sys[x].sim.simulate(steps=tau, dt=0.005, frequency=tau)

                &#47&#47 check for NaN
                if torch.isnan(q_t.reshape(-1)).sum().item() &gt; 0:
                    print("encounter NaN")
                    return 10.0, True 

                _, _, sim_rdf11 = train_sys[x].rdf11(q_t)
                _, _, sim_rdf12 = train_sys[x].rdf12(q_t)
                _, _, sim_rdf22 = train_sys[x].rdf22(q_t)

                loss_ = (sim_rdf11 - torch.Tensor(train_sys[x].target_rdf11).to(device) ).pow(2).mean() + \
                        (sim_rdf12 - torch.Tensor(train_sys[x].target_rdf12).to(device) ).pow(2).mean() + \
                        (sim_rdf22 - torch.Tensor(train_sys[x].target_rdf22).to(device) ).pow(2).mean() 

                all_rdf11.append(sim_rdf11)
                all_rdf12.append(sim_rdf12)
                all_rdf22.append(sim_rdf22)

                loss_.backward()

                loss += loss_.item()
        
        optimizer.step()
        optimizer.zero_grad()
 
        if i % 5 == 0:

            mean_all_rdf11 = torch.stack(all_rdf11).detach().cpu().mean(0)
            mean_all_rdf12 = torch.stack(all_rdf12).detach().cpu().mean(0)
            mean_all_rdf22<a id="change"> = </a><a id="change">torch.stack(all_rdf22).detach().cpu()</a>.mean(0)

            plot_pairs(train_sys[x].sim, pair11, pair12, pair22, fn=f&quot{model_path}/x_{x}_{str(i).zfill(3)}_pot.pdf&quot)
            plot_sim_rdfs(mean_all_rdf11, mean_all_rdf12, mean_all_rdf22, </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/torchmd/mdgrad/commit/4a43676cd6950ce8bf34276d9c4fefcd081b35d7#diff-d331fc48ce4f2b9fd362780953537bd16aa4b7953175b6398d824bf57f626df7L137' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 114761702</div><div id='project'> Project Name: torchmd/mdgrad</div><div id='commit'> Commit Name: 4a43676cd6950ce8bf34276d9c4fefcd081b35d7</div><div id='time'> Time: 2022-01-28</div><div id='author'> Author: wwj@mit.edu</div><div id='file'> File Name: scripts/fit_mix.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: run_mix(1)</div><div id='n_method'> N Method Name: run_mix(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/fit_mix.py</div><div id='n_file'> N File Name: scripts/fit_mix.py</div><div id='m_start'> M Start Line: 199</div><div id='m_end'> M End Line: 230</div><div id='n_start'> N Start Line: 202</div><div id='n_end'> N End Line: 250</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            raise NotImplementedError
        policy_loss_value = policy_loss.detach().cpu().numpy()
        self.policy_optimizer.zero_grad()
        <a id="change">policy_loss.backward()</a>
        self.policy_optimizer.step()

        self.tot_update_count += 1
        </code></pre><h3>After Change</h3><pre><code class='java'>
        policy_loss_value = policy_loss.detach().cpu().numpy()

        &#47&#47entropy loss
        entropy_loss<a id="change"> = </a>-torch.mean(dist_entropy)
        entropy_loss_value<a id="change"> =  </a><a id="change">entropy_loss.detach().cpu()</a>.numpy()
        tot_loss = v_loss + entropy_loss + policy_loss

        self.policy_optimizer.zero_grad()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/x35f/unstable_baselines/commit/5af9f89c6d399a424b451a524af66c97ab900df8#diff-52f03432c99c716ff4dd3aab99ae6fafde4ebca9abe1cdbec481a8fee78251bcL74' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 114761699</div><div id='project'> Project Name: x35f/unstable_baselines</div><div id='commit'> Commit Name: 5af9f89c6d399a424b451a524af66c97ab900df8</div><div id='time'> Time: 2021-03-30</div><div id='author'> Author: 1621322691@qq.com</div><div id='file'> File Name: ppo/model.py</div><div id='m_class'> M Class Name: PPOAgent</div><div id='n_method'> N Class Name: PPOAgent</div><div id='m_method'> M Method Name: update(2)</div><div id='n_method'> N Method Name: update(2)</div><div id='m_parent_class'> M Parent Class: BaseAgent,torch.nn.Module</div><div id='n_parent_class'> N Parent Class: BaseAgent,torch.nn.Module</div><div id='m_file'> M File Name: ppo/model.py</div><div id='n_file'> N File Name: ppo/model.py</div><div id='m_start'> M Start Line: 78</div><div id='m_end'> M End Line: 118</div><div id='n_start'> N Start Line: 79</div><div id='n_end'> N End Line: 125</div><BR>