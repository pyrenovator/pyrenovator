<html><h3>Pattern ID :6110
</h3><img src='21128274.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 if do_Dmain:
            &#47&#47     loss4 += loss3
            &#47&#47 loss4.backward()  &#47&#47 咩酱：gain即上文提到的这个阶段的训练间隔。
            <a id="change">(real_logits * 0 + loss_Dreal + loss_Dr1).mean()</a>.mul(gain).backward()
        return loss_numpy

    def train_iter(self, optimizers=None):</code></pre><h3>After Change</h3><pre><code class='java'>
                &#47&#47 ddd = np.mean((dic2[phase + &quotr1_penalty&quot] - r1_penalty.cpu().detach().numpy()) ** 2)
                &#47&#47 print(&quotddd=%.6f&quot % ddd)
                loss_Dr1 = r1_penalty * (self.r1_gamma / 2)
                loss_numpy[&quotloss_Dr1&quot]<a id="change"> = loss_Dr1.cpu().detach()</a><a id="change">.numpy()</a>.mean()

            loss4 = (loss_Dreal + loss_Dr1).mean() * float(gain)
            &#47&#47 if do_Dmain:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/miemie2013/miemiegan/commit/fbc8738996ce75111be885ba7ac313d85969a2b8#diff-c3be3e49b4968a2ee433a8b0d38c7aa9f68d5116602220ff22567e41b765b44bL138' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21128274</div><div id='project'> Project Name: miemie2013/miemiegan</div><div id='commit'> Commit Name: fbc8738996ce75111be885ba7ac313d85969a2b8</div><div id='time'> Time: 2022-02-25</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_class'> M Class Name: StyleGANv2ADAModel</div><div id='n_method'> N Class Name: StyleGANv2ADAModel</div><div id='m_method'> M Method Name: accumulate_gradients(8)</div><div id='n_method'> N Method Name: accumulate_gradients(8)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='n_file'> N File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_start'> M Start Line: 138</div><div id='m_end'> M End Line: 260</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 262</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            loss.backward()
            optimizer.step()
        target_hr_list.append(data["target"].item())
        predicted_list.append(<a id="change">outputs[2].mean()</a>.item())
        fin_loss += loss.item()

    return target_hr_list, predicted_list, fin_loss / len(data_loader)</code></pre><h3>After Change</h3><pre><code class='java'>
        target_hr_batch = list(data["target"].mean(dim=1, keepdim=True).squeeze(1).detach().numpy())
        target_hr_list.extend(target_hr_batch)

        predicted_hr_batch<a id="change"> = </a>list(<a id="change">outputs.squeeze(2).mean(dim=1, keepdim=True).squeeze(1).detach().numpy()</a>)
        predicted_hr_list.extend(predicted_hr_batch)
        fin_loss += loss.item()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/anweshcr7/rhythmnet/commit/465030f9efb5f86a94572239a5147c1c667f24fd#diff-865c0134cc71b80102811a3e1216d5dad097594d0a4cabcb4dfc077d925af689L7' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21128275</div><div id='project'> Project Name: anweshcr7/rhythmnet</div><div id='commit'> Commit Name: 465030f9efb5f86a94572239a5147c1c667f24fd</div><div id='time'> Time: 2021-02-23</div><div id='author'> Author: anwesh.marwade@beyondsports.nl</div><div id='file'> File Name: src/engine.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train_fn(4)</div><div id='n_method'> N Method Name: train_fn(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/engine.py</div><div id='n_file'> N File Name: src/engine.py</div><div id='m_start'> M Start Line: 12</div><div id='m_end'> M End Line: 28</div><div id='n_start'> N Start Line: 12</div><div id='n_end'> N End Line: 33</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 loss = loss_fn(out, data["target"])
            &#47&#47 _, batch_preds = torch.max(out.data, 1)
            &#47&#47 fin_loss += loss.item()
            predicted_list.append(<a id="change">out.mean()</a>.item())
            target_hr_list.append(data["target"].item())

        return target_hr_list, predicted_list</code></pre><h3>After Change</h3><pre><code class='java'>
            target_hr_batch = list(data["target"].mean(dim=1, keepdim=True).squeeze(1).detach().numpy())
            target_hr_list.extend(target_hr_batch)

            predicted_hr_batch<a id="change"> = </a>list(<a id="change">outputs.squeeze(2).mean(dim=1, keepdim=True).squeeze(1).detach().numpy()</a>)
            predicted_list.extend(predicted_hr_batch)

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/anweshcr7/rhythmnet/commit/465030f9efb5f86a94572239a5147c1c667f24fd#diff-865c0134cc71b80102811a3e1216d5dad097594d0a4cabcb4dfc077d925af689L34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21128278</div><div id='project'> Project Name: anweshcr7/rhythmnet</div><div id='commit'> Commit Name: 465030f9efb5f86a94572239a5147c1c667f24fd</div><div id='time'> Time: 2021-02-23</div><div id='author'> Author: anwesh.marwade@beyondsports.nl</div><div id='file'> File Name: src/engine.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: eval_fn(3)</div><div id='n_method'> N Method Name: eval_fn(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/engine.py</div><div id='n_file'> N File Name: src/engine.py</div><div id='m_start'> M Start Line: 37</div><div id='m_end'> M End Line: 51</div><div id='n_start'> N Start Line: 41</div><div id='n_end'> N End Line: 63</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        value_loss_buffer = []
        for _ in range(self.value_update_iter):
            value = self.value_net.forward(obs)
            value_loss = <a id="change">(ret - value).pow(2).mean()</a>
            value_loss_buffer.append(value_loss.item())
            self.value_optimizer.zero_grad()
            value_loss.backward()
            self.value_optimizer.step()</code></pre><h3>After Change</h3><pre><code class='java'>
        for _ in range(self.value_update_iter):
            td_target = rew + self.gamma * self.value_net.forward(next_obs) * (1 - don)
            delta = td_target - self.value_net.forward(obs)
            delta = <a id="change">delta.detach().numpy()</a>

            advantage_lst = []
            advantage = 0.0
            for delta_t in delta[::-1]:
                advantage = self.gamma * self.lam * advantage + delta_t[0]
                advantage_lst.append([advantage])

            advantage_lst.reverse()
            advantage = torch.FloatTensor(advantage_lst)

            value = self.value_net.forward(obs)
            &#47&#47value_loss = (ret - value).pow(2).mean()
            value_loss = F.smooth_l1_loss(td_target.detach(), value)
            value_loss_buffer.append(value_loss.item())
            self.value_optimizer.zero_grad()
            value_loss.backward()
            self.value_optimizer.step()
            if self.log:
                self.writer.add_scalar(&quotvalue_loss&quot, np.mean(value_loss_buffer), self.train_count)

            probs = self.policy_net.forward(obs)
            probs = probs.gather(1, act).squeeze(1)
            ratio = probs / old_probs
            surr1<a id="change"> = </a>ratio * advantage
            surr2 = torch.clamp(ratio, 1. - self.epsilon, 1. + self.epsilon) * advantage
            policy_loss = - torch.min(surr1, surr2).mean()
            policy_loss_buffer.append(policy_loss.item())</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/deligentfool/policy_based_rl/commit/3ee3f4f7f6374ecc0a4efef5d67cc2399eab43a4#diff-b41d7291908ffbc2ef8802c64617b48dda2a61a944b3a415d9f9b4564c13b595L120' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 21128271</div><div id='project'> Project Name: deligentfool/policy_based_rl</div><div id='commit'> Commit Name: 3ee3f4f7f6374ecc0a4efef5d67cc2399eab43a4</div><div id='time'> Time: 2020-05-30</div><div id='author'> Author: 1027660817@qq.com</div><div id='file'> File Name: PPO_CLIP/ppo_cartpole.py</div><div id='m_class'> M Class Name: ppo_clip</div><div id='n_method'> N Class Name: ppo_clip</div><div id='m_method'> M Method Name: train(1)</div><div id='n_method'> N Method Name: train(1)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: PPO_CLIP/ppo_cartpole.py</div><div id='n_file'> N File Name: PPO_CLIP/ppo_cartpole.py</div><div id='m_start'> M Start Line: 121</div><div id='m_end'> M End Line: 159</div><div id='n_start'> N Start Line: 106</div><div id='n_end'> N End Line: 156</div><BR>