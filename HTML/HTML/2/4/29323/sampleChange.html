<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    with utils.in_eval_mode(model), torch.no_grad():
        device = utils.get_device(model)

        <a id="change">try:
            &#47&#47 If model is not on CPU, convert it to CPU
            </a>model.cpu()

            for conv, bn in conv_bn_pairs:
                _fold(conv, bn, fold_backward=True, fold_to_scale=fold_to_scale)</code></pre><h3>After Change</h3><pre><code class='java'>

    for bn, conv in bn_conv_pairs:
        if isinstance(conv, QcQuantizeWrapper):
            <a id="change">raise RuntimeError(f"Forward folding to scale is not possible. Got {conv}"</a><a id="change">)</a>

    def _fold(conv, bn, fold_backward):
        if isinstance(conv, QcQuantizeWrapper) or isinstance(bn, QcQuantizeWrapper):
            assert isinstance(conv, QcQuantizeWrapper) and isinstance(bn, QcQuantizeWrapper)</code></pre>