<html><h3>Pattern ID :8108
</h3><img src='28718823.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        if self.output_layer.bias is not None:
            new_bias = torch.empty(n_classes_to_add)
            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.output_layer.weight)
            bound = 1<a id="change"> / </a><a id="change">math.sqrt(</a>fan_in<a id="change">)</a> if fan_in &gt; 0 else 0
            nn.init.uniform_(new_bias, -bound, bound)
            self.output_layer.bias = nn.parameter.Parameter(
                torch.cat([self.output_layer.bias, new_bias], axis=0)</code></pre><h3>After Change</h3><pre><code class='java'>
        n_classes_to_add
            Number of output dimensions to add.
        
        new_weights = <a id="change">torch.mean(self.output_layer.weight,dim=0).unsqueeze(1</a><a id="change">)</a>.T
        if n_classes_to_add &gt; 1:
            new_weights = new_weights.unsqueeze(1).T.repeat(1,n_classes_to_add, 1).squeeze()
        self.output_layer.weight = nn.parameter.Parameter(</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/online-ml/river-torch/commit/27f914a787bc844de5af4720487e2314f206960d#diff-b7b3dc93db412db0f1b244453a944c127c40d624ca0330c220405196365d357aL300' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 28718823</div><div id='project'> Project Name: online-ml/river-torch</div><div id='commit'> Commit Name: 27f914a787bc844de5af4720487e2314f206960d</div><div id='time'> Time: 2022-09-26</div><div id='author'> Author: cedric.kulbach@googlemail.com</div><div id='file'> File Name: river_torch/classification/classifier.py</div><div id='m_class'> M Class Name: Classifier</div><div id='n_method'> N Class Name: Classifier</div><div id='m_method'> M Method Name: _add_output_features(2)</div><div id='n_method'> N Method Name: _add_output_features(2)</div><div id='m_parent_class'> M Parent Class: DeepEstimator,base.Classifier</div><div id='n_parent_class'> N Parent Class: DeepEstimator,base.Classifier</div><div id='m_file'> M File Name: river_torch/classification/classifier.py</div><div id='n_file'> N File Name: river_torch/classification/classifier.py</div><div id='m_start'> M Start Line: 300</div><div id='m_end'> M End Line: 310</div><div id='n_start'> N Start Line: 300</div><div id='n_end'> N End Line: 311</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        maxlen, batch_size = src.shape[0], src.shape[1]  &#47&#47 src.shape = [215, 128, 36]

        Question: why 72 features (36 feature + 36 mask)?
        src = self.encoder(src)<a id="change"> * </a><a id="change">math.sqrt(</a>self.d_model<a id="change">)</a>  &#47&#47 linear layer: 36 --&gt; 36 &#47&#47 Mapping

        &#47&#47 src = src* math.sqrt(self.d_model)
</code></pre><h3>After Change</h3><pre><code class='java'>
        elif masked_agg ==False:
            Without masked aggregation across rows
            &#47&#47 output = r_out[-1, :, :].squeeze(0) &#47&#47 take the last step&quots output, shape[128, 36]
            output = torch.sum(r_out, dim=0) / (<a id="change">lengths.unsqueeze(1</a><a id="change">)</a> + 1)

        concat static
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mims-harvard/raindrop/commit/0b0a19b4ba53c4a1303ef507483e994acffac9b8#diff-b7c638e744cc24cbf0e26b15a5dd347480335d7c3d444eb55d211866066c5266L1328' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 28718821</div><div id='project'> Project Name: mims-harvard/raindrop</div><div id='commit'> Commit Name: 0b0a19b4ba53c4a1303ef507483e994acffac9b8</div><div id='time'> Time: 2021-09-09</div><div id='author'> Author: xiang.alan.zhang@gmail.com</div><div id='file'> File Name: code/baselines/models.py</div><div id='m_class'> M Class Name: Simple_classifier</div><div id='n_method'> N Class Name: Simple_classifier</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: code/baselines/models.py</div><div id='n_file'> N File Name: code/baselines/models.py</div><div id='m_start'> M Start Line: 1329</div><div id='m_end'> M End Line: 1378</div><div id='n_start'> N Start Line: 1358</div><div id='n_end'> N End Line: 1385</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
		src_embedding = src_embedding + src_embedding_p
		tgt_embedding = tgt_embedding + tgt_embedding_p

		scores = torch.matmul(src_embedding.transpose(2, 1).contiguous(), tgt_embedding)<a id="change"> / </a><a id="change">math.sqrt(</a>self.emb_dims<a id="change">)</a>
		scores = torch.softmax(scores, dim=2)
		&#47&#47 b x points x points
		feat1_corr = torch.matmul(feat2, scores.transpose(2, 1).contiguous())
		rotation_ab, translation_ab = self.head(feat1, feat1_corr)</code></pre><h3>After Change</h3><pre><code class='java'>

        else:
            rotation_ba = rotation_ab.transpose(2, 1).contiguous()
            translation_ba = -torch.matmul(rotation_ba, <a id="change">translation_ab.unsqueeze(2</a><a id="change">)</a>).squeeze(2)
        
        T_12 = rt_to_transformation(rotation_ab, translation_ab.unsqueeze(2))
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/paul007pl/mvp_benchmark/commit/cb5622fec6ad947b57a83033563a402533978c61#diff-b0b2731ff940d2b158077f966e3841337bc29d9303d97f5bbc31253fe6eaf136L269' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 28718818</div><div id='project'> Project Name: paul007pl/mvp_benchmark</div><div id='commit'> Commit Name: cb5622fec6ad947b57a83033563a402533978c61</div><div id='time'> Time: 2021-07-12</div><div id='author'> Author: panliang_de2007@qq.com</div><div id='file'> File Name: registration/models/dcp.py</div><div id='m_class'> M Class Name: Model</div><div id='n_method'> N Class Name: Model</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: registration/models/dcp.py</div><div id='n_file'> N File Name: registration/models/dcp.py</div><div id='m_start'> M Start Line: 270</div><div id='m_end'> M End Line: 294</div><div id='n_start'> N Start Line: 394</div><div id='n_end'> N End Line: 425</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        temporal_mask = temporal[:, temporal_cols.get_loc(&quotavailable_mask&quot), :]

        y_means = torch.sum(temporal_y * temporal_mask, dim=-1, keepdim=True) / torch.sum(temporal_mask, dim=-1, keepdim=True)
        y_stds = <a id="change">torch.sqrt(</a>torch.sum(temporal_mask*(temporal_y-y_means)**2, dim=-1, keepdim=True)/ \
                            torch.sum(temporal_mask, dim=-1, keepdim=True)<a id="change"> )</a>

        temporal_y = (temporal_y - y_means)<a id="change"> / </a>y_stds
        temporal[:, temporal_cols.get_loc(&quoty&quot), :] = temporal_y
        
        return batch, y_means, y_stds</code></pre><h3>After Change</h3><pre><code class='java'>
            temporal_mask[:, -cutoff:] = 0

        &#47&#47 Normalize. self.scaler stores the shift and scale for inverse transform
        temporal_mask = <a id="change">temporal_mask.unsqueeze(1</a><a id="change">)</a> &#47&#47 Add channel dimension for scaler.transform.
        temporal_data = self.scaler.transform(x=temporal_data, mask=temporal_mask)

        &#47&#47 Replace values in windows dict</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nixtla/neuralforecast/commit/73dab945c58726e3f150b851bb94e3a003a590a0#diff-0cdc48ec55ce1c327b6316201813cea3fd20ef83eed8571090ee63e103951c18L105' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 28718828</div><div id='project'> Project Name: nixtla/neuralforecast</div><div id='commit'> Commit Name: 73dab945c58726e3f150b851bb94e3a003a590a0</div><div id='time'> Time: 2022-11-02</div><div id='author'> Author: mergenthaler.m@gmail.com</div><div id='file'> File Name: neuralforecast/common/_base_recurrent.py</div><div id='m_class'> M Class Name: BaseRecurrent</div><div id='n_method'> N Class Name: BaseRecurrent</div><div id='m_method'> M Method Name: _normalization(2)</div><div id='n_method'> N Method Name: _normalization(2)</div><div id='m_parent_class'> M Parent Class: pl.LightningModule</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: neuralforecast/common/_base_recurrent.py</div><div id='n_file'> N File Name: neuralforecast/common/_base_recurrent.py</div><div id='m_start'> M Start Line: 106</div><div id='m_end'> M End Line: 124</div><div id='n_start'> N Start Line: 104</div><div id='n_end'> N End Line: 125</div><BR>