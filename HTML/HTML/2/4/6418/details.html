<html><h3>Pattern ID :6418
</h3><img src='22329670.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                        buff = buff_q.get()
                        &#47&#47 send tensor.
                        a = buff.clone()
                        <a id="change">del buff</a>
                        &#47&#47 buff.copy_(tensor)
                        &#47&#47 TODO: check it does do problems with memory
                        stream.synchronize()
                        out_q.put(a)</code></pre><h3>After Change</h3><pre><code class='java'>
        return self._recv_tensors_p2p(x, batch_idx, self.grad_rcv_items, False)

    def _send_tensors_p2p(self, x, batch_idx, ranks_dict_items, is_grad):
        request_objects<a id="change"> = </a><a id="change">[]</a>
        with torch.no_grad():
            for tensor, (tensor_name, send_ranks) in zip(x, ranks_dict_items):
                &#47&#47 tag for minibatch idx too

                if isinstance(tensor, torch.nn.Parameter):
                    tensor.share_memory_()
                    for send_rank in send_ranks:
                        if tensor_name not in self.send_shared_parameters or send_rank not in self.send_shared_parameters[
                                tensor_name]:
                            stream = self.grad_send_stream if is_grad else self.acti_send_stream
                            with torch.cuda.stream(stream):
                                out_q = self.rcv_queues[send_rank][self.rank]
                                event = stream.record_event()
                                <a id="change">request_objects.append(</a>event<a id="change">)</a>
                                stream.wait_event(event)  &#47&#47 FIXME
                                &#47&#47 stream.synchronize()
                                out_q.put(tensor)
                            self.send_shared_parameters[tensor_name].add(</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/saareliad/ftpipe/commit/5f01da818be8cc4a3c079626b2df11584d242ed6#diff-e8a3a19b1943afe92b627d303a564e72a2ad183b89af477fbd5c65031cec3416L168' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 22329670</div><div id='project'> Project Name: saareliad/ftpipe</div><div id='commit'> Commit Name: 5f01da818be8cc4a3c079626b2df11584d242ed6</div><div id='time'> Time: 2020-05-10</div><div id='author'> Author: saareliad@campus.technion.ac.il</div><div id='file'> File Name: pipeline/communication/multiprocessing.py</div><div id='m_class'> M Class Name: MultiprocessingCommunicationHandler</div><div id='n_method'> N Class Name: MultiprocessingCommunicationHandler</div><div id='m_method'> M Method Name: _send_tensors_p2p(5)</div><div id='n_method'> N Method Name: _send_tensors_p2p(5)</div><div id='m_parent_class'> M Parent Class: SimpleCommBase</div><div id='n_parent_class'> N Parent Class: SimpleCommBase</div><div id='m_file'> M File Name: pipeline/communication/multiprocessing.py</div><div id='n_file'> N File Name: pipeline/communication/multiprocessing.py</div><div id='m_start'> M Start Line: 168</div><div id='m_end'> M End Line: 197</div><div id='n_start'> N Start Line: 188</div><div id='n_end'> N End Line: 239</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if pad:
        sequence = pad_ends(sequence)
    ngrams = []
    <a id="change">del ngrams</a>  &#47&#47 TODO
</code></pre><h3>After Change</h3><pre><code class='java'>
            yield (token,)
        return
    iterator = iter(sequence)
    history<a id="change"> = </a><a id="change">[]</a>
    for hist_length, token in enumerate(iterator, start=1):
        history.append(token)
        if hist_length == n - 1:
            break
    else:  &#47&#47 For-else is obscure but fits here perfectly
        return
    for token in iterator:
        yield tuple(history) + (token,)
        <a id="change">history.append(</a>token<a id="change">)</a>
        del history[0]
    return

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/4bf0b4e0a864cf1beeb97bf43633deffd3b359fc#diff-6ca7347bd9744bf6f8a97608c20968593fa26ad82a918dab7a9e509b9116a046L33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 22329665</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 4bf0b4e0a864cf1beeb97bf43633deffd3b359fc</div><div id='time'> Time: 2020-05-15</div><div id='author'> Author: aku.rouhe@aalto.fi</div><div id='file'> File Name: speechbrain/lm/counting.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: ngrams(2)</div><div id='n_method'> N Method Name: ngrams(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: speechbrain/lm/counting.py</div><div id='n_file'> N File Name: speechbrain/lm/counting.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 46</div><div id='n_start'> N Start Line: 43</div><div id='n_end'> N End Line: 62</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    )
                    if correct_res:
                        continue
                    <a id="change">del f[rescaled_name]</a>

                print("Resizing", pp, name)
                print("from resolution (microns)", native_resolution, "to", target_resolution)
                print("with scale factor", scale_factor)</code></pre><h3>After Change</h3><pre><code class='java'>
    paths = glob(os.path.join(path, "*.h5"))

    &#47&#47 check if anything needs to be resized
    need_resize<a id="change"> = </a><a id="change">[]</a>
    for pp in paths:
        with open_file(pp, "r") as f:
            for name, obj in f.items():
                rescaled_name = f"rescaled/{name}"
                if is_group(obj):
                    continue
                if rescaled_name in f:
                    this_resolution = f[rescaled_name].attrs["resolution"]
                    correct_res = all(
                        np.isclose(this_re, target_re) for this_re, target_re in zip(this_resolution, target_resolution)
                    )
                    if correct_res:
                        continue
                <a id="change">need_resize.append(</a>path<a id="change">)</a>

    &#47&#47 resize if necessary
    need_resize = list(set(need_resize))
    for pp in need_resize:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/constantinpape/torch-em/commit/3cf0d33425e065fd543a9e7b9727786d953229c6#diff-9ece3e332156ea93bb98651a41cce3671fe493eb8a70be9f2129287e9d9c4129L41' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 22329662</div><div id='project'> Project Name: constantinpape/torch-em</div><div id='commit'> Commit Name: 3cf0d33425e065fd543a9e7b9727786d953229c6</div><div id='time'> Time: 2022-03-19</div><div id='author'> Author: constantin.pape@embl.de</div><div id='file'> File Name: torch_em/data/datasets/plantseg.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _resize(3)</div><div id='n_method'> N Method Name: _resize(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torch_em/data/datasets/plantseg.py</div><div id='n_file'> N File Name: torch_em/data/datasets/plantseg.py</div><div id='m_start'> M Start Line: 44</div><div id='m_end'> M End Line: 61</div><div id='n_start'> N Start Line: 44</div><div id='n_end'> N End Line: 69</div><BR>