<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                        buff = buff_q.get()
                        &#47&#47 send tensor.
                        a = buff.clone()
                        <a id="change">del buff</a>
                        &#47&#47 buff.copy_(tensor)
                        &#47&#47 TODO: check it does do problems with memory
                        stream.synchronize()
                        out_q.put(a)</code></pre><h3>After Change</h3><pre><code class='java'>
        return self._recv_tensors_p2p(x, batch_idx, self.grad_rcv_items, False)

    def _send_tensors_p2p(self, x, batch_idx, ranks_dict_items, is_grad):
        request_objects<a id="change"> = </a><a id="change">[]</a>
        with torch.no_grad():
            for tensor, (tensor_name, send_ranks) in zip(x, ranks_dict_items):
                &#47&#47 tag for minibatch idx too

                if isinstance(tensor, torch.nn.Parameter):
                    tensor.share_memory_()
                    for send_rank in send_ranks:
                        if tensor_name not in self.send_shared_parameters or send_rank not in self.send_shared_parameters[
                                tensor_name]:
                            stream = self.grad_send_stream if is_grad else self.acti_send_stream
                            with torch.cuda.stream(stream):
                                out_q = self.rcv_queues[send_rank][self.rank]
                                event = stream.record_event()
                                <a id="change">request_objects.append(</a>event<a id="change">)</a>
                                stream.wait_event(event)  &#47&#47 FIXME
                                &#47&#47 stream.synchronize()
                                out_q.put(tensor)
                            self.send_shared_parameters[tensor_name].add(</code></pre>