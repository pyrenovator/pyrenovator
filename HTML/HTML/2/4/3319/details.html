<html><h3>Pattern ID :3319
</h3><img src='12754947.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        seq_length = input_ids.shape[1]
        if position_ids is None:
            position_ids = paddle.arange(start_idx_pos_encodings, start_idx_pos_encodings + seq_length)
            position_ids = <a id="change">position_ids.unsqueeze(0</a><a id="change">)</a>.expand_as(input_ids)

        inputs_embeds = self.word_embeddings(input_ids)
</code></pre><h3>After Change</h3><pre><code class='java'>
            input_shape = paddle.shape(inputs_embeds)[:-1]

        if position_ids is None:
            ones<a id="change"> = </a><a id="change">paddle.ones(</a>input_shape<a id="change">, dtype="int64")</a>
            seq_length = paddle.cumsum(ones, axis=1)
            position_ids = start_idx_pos_encodings + seq_length - start_idx_pos_encodings - ones
            position_ids.stop_gradient = True
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/paddlepaddle/paddlenlp/commit/7c75f5983d9a09617f1492345c65cfe1087338b5#diff-2b88f6901da7b46addcc8593f924d2f5b35bbf3fe795de42918a8d350b6af03eL458' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 12754947</div><div id='project'> Project Name: paddlepaddle/paddlenlp</div><div id='commit'> Commit Name: 7c75f5983d9a09617f1492345c65cfe1087338b5</div><div id='time'> Time: 2023-03-13</div><div id='author'> Author: 115528288+tsinghua-zhang@users.noreply.github.com</div><div id='file'> File Name: paddlenlp/transformers/reformer/modeling.py</div><div id='m_class'> M Class Name: ReformerEmbeddings</div><div id='n_method'> N Class Name: ReformerEmbeddings</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Layer</div><div id='n_parent_class'> N Parent Class: nn.Layer</div><div id='m_file'> M File Name: paddlenlp/transformers/reformer/modeling.py</div><div id='n_file'> N File Name: paddlenlp/transformers/reformer/modeling.py</div><div id='m_start'> M Start Line: 458</div><div id='m_end'> M End Line: 477</div><div id='n_start'> N Start Line: 460</div><div id='n_end'> N End Line: 488</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        his_vectors = his_vectors + pos_vectors

        &#47&#47 Self-attention
        attn_mask = 1 - <a id="change">valid_his.unsqueeze(1</a><a id="change">)</a>.repeat(1, seq_len, 1)
        for i in range(self.num_layers):
            residual = his_vectors
            &#47&#47 self-attention</code></pre><h3>After Change</h3><pre><code class='java'>
        his_vectors = his_vectors + pos_vectors

        &#47&#47 Self-attention
        causality_mask = np.tril(<a id="change">np.ones(</a>(1, 1, seq_len, seq_len)<a id="change">, dtype=np.int)</a>)
        attn_mask = torch.from_numpy(causality_mask).to(self.device)
        &#47&#47 attn_mask = valid_his.view(batch_size, 1, 1, seq_len)
        for block in self.transformer_block:
            his_vectors<a id="change"> = </a>block(his_vectors, attn_mask)
        his_vectors = his_vectors * valid_his[:, :, None].float()

        his_vector = (his_vectors * (position == 1).float()[:, :, None]).sum(1)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuwangcy/rechorus/commit/dba1d0bd7b6d7296ed6c730793e0f61278007dc2#diff-cdd126f2420ce18169e295f58055586bada35bf4c9417ee5d8a4ffd826a65370L37' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 12754944</div><div id='project'> Project Name: thuwangcy/rechorus</div><div id='commit'> Commit Name: dba1d0bd7b6d7296ed6c730793e0f61278007dc2</div><div id='time'> Time: 2020-11-08</div><div id='author'> Author: THUwangcy@gmail.com</div><div id='file'> File Name: src/models/sequential/SASRec.py</div><div id='m_class'> M Class Name: SASRec</div><div id='n_method'> N Class Name: SASRec</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: GRU4Rec</div><div id='n_parent_class'> N Parent Class: GRU4Rec</div><div id='m_file'> M File Name: src/models/sequential/SASRec.py</div><div id='n_file'> N File Name: src/models/sequential/SASRec.py</div><div id='m_start'> M Start Line: 41</div><div id='m_end'> M End Line: 72</div><div id='n_start'> N Start Line: 41</div><div id='n_end'> N End Line: 66</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                mask = np.expand_dims(mask, axis=0)

            if mask.shape[-2] == 1:  &#47&#47 1D mask
                mask = <a id="change">torch.from_numpy(mask.astype(np.float32)).unsqueeze(0).unsqueeze(-1</a><a id="change">)</a>
                &#47&#47 shape = np.array(kspace.shape)
                &#47&#47 num_cols = shape[-2]
                &#47&#47 shape[:-3] = 1
                &#47&#47 mask_shape = [1] * len(shape)</code></pre><h3>After Change</h3><pre><code class='java'>
                        [masked_kspace.shape[-3], masked_kspace.shape[-2]], dtype=torch.float32  &#47&#47 type: ignore
                    )
            else:
                mask<a id="change"> = </a><a id="change">torch.ones(
                    </a>[masked_kspace.shape[-3], masked_kspace.shape[-2]]<a id="change">, dtype=torch.float32  &#47&#47 type: ignore
                )</a>

            if mask.ndim == 1:
                mask = np.expand_dims(mask, axis=0)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/wdika/mridc/commit/c2a867923121b2e496c03be5818eae6c76dfe881#diff-ac1fd66d83af654880547d6031addeda54c90409df96b304cee60527ef084c67L64' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 12754951</div><div id='project'> Project Name: wdika/mridc</div><div id='commit'> Commit Name: c2a867923121b2e496c03be5818eae6c76dfe881</div><div id='time'> Time: 2022-03-26</div><div id='author'> Author: 62050782+deepsource-autofix[bot]@users.noreply.github.com</div><div id='file'> File Name: mridc/collections/reconstruction/parts/transforms.py</div><div id='m_class'> M Class Name: MRIDataTransforms</div><div id='n_method'> N Class Name: MRIDataTransforms</div><div id='m_method'> M Method Name: __call__(9)</div><div id='n_method'> N Method Name: __call__(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: mridc/collections/reconstruction/parts/transforms.py</div><div id='n_file'> N File Name: mridc/collections/reconstruction/parts/transforms.py</div><div id='m_start'> M Start Line: 167</div><div id='m_end'> M End Line: 252</div><div id='n_start'> N Start Line: 233</div><div id='n_end'> N End Line: 253</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def make_mask(self, input_tensor):
        mask = (input_tensor != self.config[&quotpad_id&quot]).float()  &#47&#47 (B, L)
        mask = mask.view(input_tensor.shape[0], -1)
        mask = <a id="change">mask.unsqueeze(1).unsqueeze(2</a><a id="change">)</a>  &#47&#47 (B, 1, 1, L)
        mask = mask.to(dtype=next(self.decoder.parameters()).dtype)
        
        return (1.0 - mask) * self.config[&quotinf&quot]  &#47&#47 (B, 1, 1, L)</code></pre><h3>After Change</h3><pre><code class='java'>
        e_mask = (src_input != self.config[&quotpad_id&quot]).unsqueeze(1)  &#47&#47 (B, 1, L)
        d_mask = (trg_input != self.config[&quotpad_id&quot]).unsqueeze(1)  &#47&#47 (B, 1, L)

        nopeak_mask = <a id="change">torch.ones(</a>[1, self.config[&quotmax_len&quot], self.config[&quotmax_len&quot]]<a id="change">, dtype=torch.bool)</a>  &#47&#47 (1, L, L)
        nopeak_mask = torch.tril(nopeak_mask)  &#47&#47 (1, L, L) to triangular shape
        d_mask<a id="change"> = </a>d_mask & nopeak_mask  &#47&#47 (B, L, L) padding false

        return e_mask, d_mask
    </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/devjwsong/recosa-dialogue-generation-pytorch/commit/80bce80842f7d7d8da42b8b0a6d36a1fa2432768#diff-6e62d5b18655b1b16cdb4bfa4bd41a7d5478b653ef335189aba77389696e3b41L101' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 12754953</div><div id='project'> Project Name: devjwsong/recosa-dialogue-generation-pytorch</div><div id='commit'> Commit Name: 80bce80842f7d7d8da42b8b0a6d36a1fa2432768</div><div id='time'> Time: 2020-08-25</div><div id='author'> Author: enflwodn@gmail.com</div><div id='file'> File Name: src/dialogue_model.py</div><div id='m_class'> M Class Name: DialogueModel</div><div id='n_method'> N Class Name: DialogueModel</div><div id='m_method'> M Method Name: make_mask(3)</div><div id='n_method'> N Method Name: make_mask(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/dialogue_model.py</div><div id='n_file'> N File Name: src/dialogue_model.py</div><div id='m_start'> M Start Line: 102</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 75</div><div id='n_end'> N End Line: 83</div><BR>