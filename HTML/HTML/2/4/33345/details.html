<html><h3>Pattern ID :33345
</h3><img src='96075546.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 Computing False Rejection Rate (miss detection)
    positive_scores = torch.cat(
        len(thresholds) * [<a id="change">positive_scores.unsqueeze(0</a><a id="change">)</a>]
    )
    pos_scores_threshold = positive_scores.transpose(0, 1) &lt;= thresholds
    FRR = (pos_scores_threshold.sum(0)).float() / positive_scores.shape[1]</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 Variable to store the min FRR, min FAR and their corresponding index
    min_index = 0
    final_FRR = 0
    final_FAR<a id="change"> = </a>0

    for i, cur_thresh in enumerate(thresholds):
        pos_scores_threshold = positive_scores &lt;= cur_thresh
        FRR = (pos_scores_threshold.sum(0)).float() / positive_scores.shape[0]
        del pos_scores_threshold

        neg_scores_threshold = negative_scores &gt; cur_thresh
        FAR = (neg_scores_threshold.sum(0)).float() / negative_scores.shape[0]
        del neg_scores_threshold

        &#47&#47 Finding the threshold for EER
        if (FAR - FRR).abs().item() &lt; <a id="change">abs(</a>final_FAR - final_FRR<a id="change">)</a> or i == 0:
           min_index = i
           final_FRR = FRR.item()
           final_FAR = FAR.item()</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/f1fd2091d053c0c34e88b134495f9b791037b3dd#diff-e9bc95358c9483b7f6d69eb19959955a841d3dfb6f3565b07cbce482cfe77aa9L477' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 96075546</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: f1fd2091d053c0c34e88b134495f9b791037b3dd</div><div id='time'> Time: 2022-06-23</div><div id='author'> Author: tplink312@gmail.com</div><div id='file'> File Name: speechbrain/utils/metric_stats.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: EER(2)</div><div id='n_method'> N Method Name: EER(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: speechbrain/utils/metric_stats.py</div><div id='n_file'> N File Name: speechbrain/utils/metric_stats.py</div><div id='m_start'> M Start Line: 477</div><div id='m_end'> M End Line: 505</div><div id='n_start'> N Start Line: 477</div><div id='n_end'> N End Line: 504</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 Computing False Rejection Rate (miss detection)
    positive_scores = torch.cat(
        len(thresholds) * [<a id="change">positive_scores.unsqueeze(0</a><a id="change">)</a>]
    )
    pos_scores_threshold = positive_scores.transpose(0, 1) &lt;= thresholds
    FRR = (pos_scores_threshold.sum(0)).float() / positive_scores.shape[1]</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 Variable to store the min FRR, min FAR and their corresponding index
    min_index = 0
    final_FRR = 0
    final_FAR<a id="change"> = </a>0

    for i, cur_thresh in enumerate(thresholds):
        pos_scores_threshold = positive_scores &lt;= cur_thresh
        FRR = (pos_scores_threshold.sum(0)).float() / positive_scores.shape[0]
        del pos_scores_threshold

        neg_scores_threshold = negative_scores &gt; cur_thresh
        FAR = (neg_scores_threshold.sum(0)).float() / negative_scores.shape[0]
        del neg_scores_threshold

        &#47&#47 Finding the threshold for EER
        if (FAR - FRR).abs().item() &lt; <a id="change">abs(</a>final_FAR - final_FRR<a id="change">)</a> or i == 0:
            min_index = i
            final_FRR = FRR.item()
            final_FAR = FAR.item()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/84bca108f8c3739bc2f058bab7e43db32c46e090#diff-e9bc95358c9483b7f6d69eb19959955a841d3dfb6f3565b07cbce482cfe77aa9L456' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 96075530</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 84bca108f8c3739bc2f058bab7e43db32c46e090</div><div id='time'> Time: 2022-07-01</div><div id='author'> Author: dominik.wagner@th-nuernberg.de</div><div id='file'> File Name: speechbrain/utils/metric_stats.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: EER(2)</div><div id='n_method'> N Method Name: EER(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: speechbrain/utils/metric_stats.py</div><div id='n_file'> N File Name: speechbrain/utils/metric_stats.py</div><div id='m_start'> M Start Line: 477</div><div id='m_end'> M End Line: 505</div><div id='n_start'> N Start Line: 477</div><div id='n_end'> N End Line: 504</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if (torch.sum(torch.isnan(cam_coords)) &gt; 0) or (torch.sum(torch.isinf(cam_coords)) &gt; 0):
            print(&quotWarning: Nan or Inf values in camera coordinate tensor.&quot)

        T_c2_c0 = <a id="change">cam_calib[&quotT_c2_c0&quot].unsqueeze(0</a><a id="change">)</a>.expand(batch_size, 4, 4).cuda()
        cam_coords = se3_inv(T_c2_c0).bmm(cam_coords)

        return cam_coords[:, :3, :], valid_points</code></pre><h3>After Change</h3><pre><code class='java'>

        K2, K3 = cam_calib[&quotK2&quot].cuda(), cam_calib[&quotK3&quot].cuda()
        T_c2_c0 = cam_calib[&quotT_c2_c0&quot][:batch_size, :, :].float().cuda()
        T_c3_c0<a id="change"> = </a>cam_calib[&quotT_c3_c0&quot][:batch_size, :, :].float().cuda()
        self.b = <a id="change">abs(</a>T_c3_c0.bmm(se3_inv(T_c2_c0))[0, 0, 3]<a id="change">)</a>
        self.fl = K2[0, 0, 0]

        self.M, self.Q = self.set_camera_model_matrices(K2[0, 0, 0], K2[0, 0, 2], K2[0, 1, 2],
                                                        K3[0, 0, 0], K3[0, 0, 2], K3[0, 1, 2], self.b)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/utiasasrl/hero_radar_odometry/commit/4eb1bdf7c40f496a3cd9fb79125911fcbf880f89#diff-a87808e398bbe5556e0bcab7c9a1127424e926136cf458eacb604bb416eefb69L164' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 96075549</div><div id='project'> Project Name: utiasasrl/hero_radar_odometry</div><div id='commit'> Commit Name: 4eb1bdf7c40f496a3cd9fb79125911fcbf880f89</div><div id='time'> Time: 2020-08-17</div><div id='author'> Author: mona.gridseth@robotics.utias.utoronto.ca</div><div id='file'> File Name: utils/stereo_camera_model.py</div><div id='m_class'> M Class Name: StereoCameraModel</div><div id='n_method'> N Class Name: StereoCameraModel</div><div id='m_method'> M Method Name: inverse_camera_model(4)</div><div id='n_method'> N Method Name: inverse_camera_model(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: utils/stereo_camera_model.py</div><div id='n_file'> N File Name: utils/stereo_camera_model.py</div><div id='m_start'> M Start Line: 178</div><div id='m_end'> M End Line: 191</div><div id='n_start'> N Start Line: 185</div><div id='n_end'> N End Line: 202</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        batch_size = cam_coords.size(0)

        T_c2_c0 = <a id="change">cam_calib[&quotT_c2_c0&quot].unsqueeze(0</a><a id="change">)</a>.expand(batch_size, 4, 4).cuda()
        if cam_coords.size(1) == 4:
            cam_coords = T_c2_c0.bmm(cam_coords)
        else:</code></pre><h3>After Change</h3><pre><code class='java'>

        K2, K3 = cam_calib[&quotK2&quot].cuda(), cam_calib[&quotK3&quot].cuda()
        T_c2_c0 = cam_calib[&quotT_c2_c0&quot][:batch_size, :, :].float().cuda()
        T_c3_c0<a id="change"> = </a>cam_calib[&quotT_c3_c0&quot][:batch_size, :, :].float().cuda()
        self.b = <a id="change">abs(</a>T_c3_c0.bmm(se3_inv(T_c2_c0))[0, 0, 3]<a id="change">)</a>
        self.fl = K2[0, 0, 0]

        if cam_coords.size(1) == 4:
            cam_coords = T_c2_c0.bmm(cam_coords)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/utiasasrl/hero_radar_odometry/commit/4eb1bdf7c40f496a3cd9fb79125911fcbf880f89#diff-a87808e398bbe5556e0bcab7c9a1127424e926136cf458eacb604bb416eefb69L132' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 96075551</div><div id='project'> Project Name: utiasasrl/hero_radar_odometry</div><div id='commit'> Commit Name: 4eb1bdf7c40f496a3cd9fb79125911fcbf880f89</div><div id='time'> Time: 2020-08-17</div><div id='author'> Author: mona.gridseth@robotics.utias.utoronto.ca</div><div id='file'> File Name: utils/stereo_camera_model.py</div><div id='m_class'> M Class Name: StereoCameraModel</div><div id='n_method'> N Class Name: StereoCameraModel</div><div id='m_method'> M Method Name: camera_model(3)</div><div id='n_method'> N Method Name: camera_model(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: utils/stereo_camera_model.py</div><div id='n_file'> N File Name: utils/stereo_camera_model.py</div><div id='m_start'> M Start Line: 141</div><div id='m_end'> M End Line: 154</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 160</div><BR>