<html><h3>Pattern ID :5367
</h3><img src='19120450.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                row = {}
                for _, col_name in enumerate(self.entity_columns):
                    row[col_name] = entity_id
                <a id="change">for </a>j, col_name in enumerate(self.context_columns)<a id="change">:
                    </a>row[col_name] = context[j]
                for j, col_name in enumerate(self.data_columns):
                    row[col_name] = data[j][i]
                rows.append(row)</code></pre><h3>After Change</h3><pre><code class='java'>
        
        columns = self.entity_columns + self.context_columns + self.data_columns

        groups = <a id="change">pd.DataFrame()</a>
        for entity_id in range(num_entities):
            &#47&#47 Sample data, given resampled context
            context = self._context.sample(1).iloc[0].tolist()
            sequence = self.sample_sequence(context)

            &#47&#47 Reformat as a DataFrame
            group = pd.DataFrame(dict(zip(self.data_columns, sequence)), columns=columns)
            group[self.entity_columns]<a id="change"> = </a>entity_id
            group[self.context_columns] = context

            groups<a id="change"> = </a>groups.append(group)

        return groups
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/sdv-dev/deepecho/commit/1e8ddefc8bf9828847c2deb06084e962a8870c45#diff-b77bd867af44f00d2a4f6508af37f7632252dce8b86c615f93813c5b0cae0f48L168' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19120450</div><div id='project'> Project Name: sdv-dev/deepecho</div><div id='commit'> Commit Name: 1e8ddefc8bf9828847c2deb06084e962a8870c45</div><div id='time'> Time: 2020-07-16</div><div id='author'> Author: carles@pythiac.com</div><div id='file'> File Name: deepecho/base.py</div><div id='m_class'> M Class Name: DeepEcho</div><div id='n_method'> N Class Name: DeepEcho</div><div id='m_method'> M Method Name: sample(2)</div><div id='n_method'> N Method Name: sample(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: deepecho/base.py</div><div id='n_file'> N File Name: deepecho/base.py</div><div id='m_start'> M Start Line: 168</div><div id='m_end'> M End Line: 187</div><div id='n_start'> N Start Line: 168</div><div id='n_end'> N End Line: 183</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        time.sleep(3)
        driver.quit()

        <a id="change">for </a>retailer in soup.find_all(&quottd&quot, attrs={&quotclass&quot: &quottd__logo&quot})<a id="change">:
            </a>link = &quothttps://www.pcpartpicker.com&quot + retailer.find(&quota&quot)[&quothref&quot]

            if &quotamazon&quot in link:
                driver = webdriver.Chrome()</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 Left off on Kingston HyperX Fury RGB 32 GB (line 224 of ram_links.txt)
    link_file = open(&quotdata/pcpartpicker_links/ram_links.txt&quot, &quotr&quot)
    column_names = [&quotamazon&quot, &quotbestbuy&quot, &quotnewegg&quot, &quotwalmart&quot, &quotmemoryc&quot]
    df<a id="change"> = </a>pd.DataFrame(columns = column_names)

    try:
        for link in link_file:
            driver = webdriver.Chrome()
            driver.get(link)
            soup = BeautifulSoup(driver.page_source, &quotlxml&quot)
            time.sleep(3)
            driver.quit()
            title_dict = {&quotamazon&quot: &quot&quot, &quotbestbuy&quot: &quot&quot, &quotnewegg&quot: &quot&quot, &quotwalmart&quot: &quot&quot, &quotmemoryc&quot: &quot&quot}

            for retailer in soup.find_all(&quottd&quot, attrs={&quotclass&quot: &quottd__logo&quot}):
                link = &quothttps://www.pcpartpicker.com&quot + retailer.find(&quota&quot)[&quothref&quot]

                if &quotamazon&quot in link:
                    driver = webdriver.Chrome()
                    driver.get(link)
                    soup = BeautifulSoup(driver.page_source, &quotlxml&quot)
                    driver.quit()

                    title_dict[&quotamazon&quot] = soup.find(&quotspan&quot, attrs={&quotid&quot: &quotproductTitle&quot}).text.strip()
                    print(&quotamazon&quot, title_dict[&quotamazon&quot])

                elif &quotbestbuy&quot in link:
                    driver = webdriver.Chrome()
                    driver.get(link)
                    soup = BeautifulSoup(driver.page_source, &quotlxml&quot)
                    driver.quit()

                    title_dict[&quotbestbuy&quot] = soup.find(&quoth1&quot, attrs={&quotclass&quot: &quotheading-5 v-fw-regular&quot}).text.strip()
                    print(&quotbestbuy&quot, title_dict[&quotbestbuy&quot])

                elif &quotnewegg&quot in link:
                    driver = webdriver.Chrome()
                    driver.get(link)
                    soup = BeautifulSoup(driver.page_source, &quotlxml&quot)
                    driver.quit()

                    title_dict[&quotnewegg&quot] = soup.find(&quoth1&quot, attrs={&quotid&quot: &quotgrpDescrip_h&quot}).text.strip()
                    print(&quotnewegg&quot, title_dict[&quotnewegg&quot])

                elif &quotwalmart&quot in link:
                    driver = webdriver.Chrome()
                    driver.get(link)
                    soup = BeautifulSoup(driver.page_source, &quotlxml&quot)
                    driver.quit()

                    title_dict[&quotwalmart&quot] = soup.find(&quoth1&quot, attrs={&quotclass&quot: &quotprod-ProductTitle prod-productTitle-buyBox font-bold&quot}).text.strip()
                    print(&quotwalmart&quot, title_dict[&quotwalmart&quot])
                
                elif &quotmemoryc&quot in link:
                    driver = webdriver.Chrome()
                    driver.get(link)
                    soup = BeautifulSoup(driver.page_source, &quotlxml&quot)
                    driver.quit()

                    title_dict[&quotmemoryc&quot] = soup.find(&quotsection&quot, attrs={&quotclass&quot: &quotforCartImageItem&quot}).find(&quoth1&quot).text.strip()
                    print(&quotmemoryc&quot, title_dict[&quotmemoryc&quot])
                
                else:
                    continue
                
            df<a id="change"> = </a>df.append(<a id="change">pd.DataFrame(</a>[list(title_dict.values())]<a id="change">, columns=column_names)</a>)

    except Exception:
        df.to_csv(&quotdata/train/pos_ram_titles.csv&quot)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mascerade/supervised-product-matching/commit/80d220a63cc6aabe912f2c799ed361e294bef8cb#diff-03d7558f1e1c30cb6e152c38680a1939ccab8ace16aebb35860a5fe271f16151L79' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19120433</div><div id='project'> Project Name: mascerade/supervised-product-matching</div><div id='commit'> Commit Name: 80d220a63cc6aabe912f2c799ed361e294bef8cb</div><div id='time'> Time: 2020-07-30</div><div id='author'> Author: Ultimi450@gmail.com</div><div id='file'> File Name: data_scrapers/pcpartpicker.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: get_pos_data(0)</div><div id='n_method'> N Method Name: get_pos_data(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: data_scrapers/pcpartpicker.py</div><div id='n_file'> N File Name: data_scrapers/pcpartpicker.py</div><div id='m_start'> M Start Line: 82</div><div id='m_end'> M End Line: 137</div><div id='n_start'> N Start Line: 83</div><div id='n_end'> N End Line: 151</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        uw = country_holidays_config["upper_window"]
        year_list = list({x.year for x in df.ds})
        country_holidays_dict = make_country_specific_holidays_df(year_list, country_holidays_config["country"])
        <a id="change">for </a>holiday, dates in country_holidays_dict.items()<a id="change">:
            </a>if holiday in country_holidays_config["holiday_names"]:
                all_events_list.append(holiday)
                feature = pd.Series([0.] * df.shape[0])
                feature[df.ds.isin(dates)] = 1.</code></pre><h3>After Change</h3><pre><code class='java'>
    

    additive_events = pd.DataFrame()
    multiplicative_events = <a id="change">pd.DataFrame()</a>

    &#47&#47 create all user specified events
    if events_config is not None:
        for event, configs in events_config.items():
            if event not in df.columns:
                df[event] = 0.
            feature = df[event]
            lw = configs.lower_window
            uw = configs.upper_window
            mode = configs["mode"]
            &#47&#47 create lower and upper window features
            for offset in range(lw, uw + 1):
                key = utils.create_event_names_for_offsets(event, offset)
                offset_feature = feature.shift(periods=offset, fill_value=0)
                if mode == "additive":
                    additive_events[key] = offset_feature
                else:
                    multiplicative_events[key] = offset_feature

    &#47&#47 create all country specific holidays
    if country_holidays_config is not None:
        lw = country_holidays_config["lower_window"]
        uw = country_holidays_config["upper_window"]
        mode = country_holidays_config["mode"]
        year_list = list({x.year for x in df.ds})
        country_holidays_dict = make_country_specific_holidays_df(year_list, country_holidays_config["country"])
        for holiday in country_holidays_config["holiday_names"]:
            feature = pd.Series([0.] * df.shape[0])
            if holiday in country_holidays_dict.keys():
                dates<a id="change"> = </a>country_holidays_dict[holiday]
                feature[df.ds.isin(dates)] = 1.
            for offset in range(lw, uw + 1):
                key = utils.create_event_names_for_offsets(holiday, offset)
                offset_feature = feature.shift(periods=offset, fill_value=0)
                if mode == "additive":
                    additive_events[key] = offset_feature
                else:
                    multiplicative_events[key] = offset_feature

    &#47&#47 Make sure column order is consistent
    additive_events = additive_events[sorted(additive_events.columns.tolist())]
    multiplicative_events<a id="change"> = </a>multiplicative_events[sorted(multiplicative_events.columns.tolist())]

    &#47&#47 convert to numpy array
    additive_events = additive_events.values</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ourownstory/neural_prophet/commit/3e3146ddae5b180c2c2f6bd90bbdb650e9d8d6af#diff-19e8b8bb76c45be0b19f9651c6c08d9e4641f5f993cdbaa581338cc45aff7516L271' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 19120453</div><div id='project'> Project Name: ourownstory/neural_prophet</div><div id='commit'> Commit Name: 3e3146ddae5b180c2c2f6bd90bbdb650e9d8d6af</div><div id='time'> Time: 2020-08-19</div><div id='author'> Author: hansika.hewamalage@monash.edu</div><div id='file'> File Name: neuralprophet/time_dataset.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: make_events_features(3)</div><div id='n_method'> N Method Name: make_events_features(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: neuralprophet/time_dataset.py</div><div id='n_file'> N File Name: neuralprophet/time_dataset.py</div><div id='m_start'> M Start Line: 286</div><div id='m_end'> M End Line: 332</div><div id='n_start'> N Start Line: 301</div><div id='n_end'> N End Line: 349</div><BR>