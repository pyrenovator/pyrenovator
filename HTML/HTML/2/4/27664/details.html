<html><h3>Pattern ID :27664
</h3><img src='82100216.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                                                        covariance_matrix=target_dist.covariance_matrix)

        if self.sample:
            z = <a id="change">normalized_context_dist.sample()</a> &#47&#47 B x Z
        else:
            z = normalized_context_dist.loc
</code></pre><h3>After Change</h3><pre><code class='java'>
        z = normalized_context_dist.loc
        if self.sample:
            &#47&#47 Take the diagonal variance vector and stack batch-wise. Result: [B, Z]
            covariance_diagonals<a id="change"> = </a>torch.stack([batch_cov.diag() for batch_cov in normalized_context_dist.covariance_matrix])
            &#47&#47 Elementwise multiply each N(0, 1) sample by the covariance diagonal for that dimension
            noise = <a id="change">torch.randn(</a>z.shape<a id="change">)</a> * covariance_diagonals
            z<a id="change"> += </a>noise

        if self.rsample:
            z = normalized_context_dist.rsample()</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/c8f17c857b7cb963d9240e08f63a88d936f020bc#diff-094460a9fbb96d5a5e5e0ff351a3d7aaa4cc4fae9d4c22cbb890b6d29832d85eL136' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 82100216</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: c8f17c857b7cb963d9240e08f63a88d936f020bc</div><div id='time'> Time: 2020-08-04</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/losses.py</div><div id='m_class'> M Class Name: CEBLoss</div><div id='n_method'> N Class Name: CEBLoss</div><div id='m_method'> M Method Name: __call__(4)</div><div id='n_method'> N Method Name: __call__(4)</div><div id='m_parent_class'> M Parent Class: RepresentationLoss</div><div id='n_parent_class'> N Parent Class: RepresentationLoss</div><div id='m_file'> M File Name: algos/losses.py</div><div id='n_file'> N File Name: algos/losses.py</div><div id='m_start'> M Start Line: 136</div><div id='m_end'> M End Line: 144</div><div id='n_start'> N Start Line: 137</div><div id='n_end'> N End Line: 154</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                                                                        covariance_matrix=target_dist.covariance_matrix)

        if self.sample:
            z = <a id="change">normalized_context_dist.sample()</a> &#47&#47 B x Z
        else:
            z = normalized_context_dist.loc
</code></pre><h3>After Change</h3><pre><code class='java'>
        z = normalized_context_dist.loc
        if self.sample:
            &#47&#47 Take the diagonal variance vector and stack batch-wise. Result: [B, Z]
            covariance_diagonals<a id="change"> = </a>torch.stack([batch_cov.diag() for batch_cov in normalized_context_dist.covariance_matrix])
            &#47&#47 Elementwise multiply each N(0, 1) sample by the covariance diagonal for that dimension
            noise = <a id="change">torch.randn(</a>z.shape<a id="change">)</a> * covariance_diagonals
            z<a id="change"> += </a>noise

        if self.rsample:
            z = normalized_context_dist.rsample()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/02ed93387eee8c6b90c4dba3c91fe6bbe53a48fc#diff-094460a9fbb96d5a5e5e0ff351a3d7aaa4cc4fae9d4c22cbb890b6d29832d85eL133' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 82100218</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: 02ed93387eee8c6b90c4dba3c91fe6bbe53a48fc</div><div id='time'> Time: 2020-08-04</div><div id='author'> Author: codywild@berkeley.edu</div><div id='file'> File Name: algos/losses.py</div><div id='m_class'> M Class Name: CEBLoss</div><div id='n_method'> N Class Name: CEBLoss</div><div id='m_method'> M Method Name: __call__(4)</div><div id='n_method'> N Method Name: __call__(4)</div><div id='m_parent_class'> M Parent Class: RepresentationLoss</div><div id='n_parent_class'> N Parent Class: RepresentationLoss</div><div id='m_file'> M File Name: algos/losses.py</div><div id='n_file'> N File Name: algos/losses.py</div><div id='m_start'> M Start Line: 136</div><div id='m_end'> M End Line: 144</div><div id='n_start'> N Start Line: 137</div><div id='n_end'> N End Line: 154</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        P = 10
        points = np.concatenate(
            [X.projection(<a id="change">_G.sample()</a>) for _ in range(P)],
            axis=1
        )
        </code></pre><h3>After Change</h3><pre><code class='java'>
            return
        
        P = 10
        points = <a id="change">torch.randn(</a>X.dimensionality, P<a id="change">, dtype=torch.float32)</a>

        assert points.shape == (X.dimensionality, P)
        
        B = 5
        
        features = torch.randn(B, in_rep.size, P, dtype=torch.float32)
        
        filters = torch.zeros((out_rep.size, in_rep.size, basis.dim, P), dtype=torch.float32)
        
        filters = basis.sample(points, out=filters)
        
        self.assertFalse(torch.isnan(filters).any())
        self.assertFalse(torch.allclose(filters, torch.zeros_like(filters)))
        
        a = basis.sample(points)
        b = basis.sample(points)
        assert torch.allclose(a, b)

        output = torch.einsum("oifp,bip-&gt;bof", filters, features)
        
        for _ in range(20):
            g<a id="change"> = </a>G.sample()
            
            output1 = torch.einsum("oi,bif-&gt;bof",
                                   torch.tensor(out_rep(g), dtype=output.dtype),
                                   output)

            transformed_points = torch.tensor(
                X.action(inclusion(g)),
            dtype=points.dtype) @ points

            transformed_filters = basis.sample(transformed_points)
            
            transformed_features = torch.einsum("oi,bip-&gt;bop",
                                                torch.tensor(in_rep(g), dtype=features.dtype),
                                                features)
            output2<a id="change"> = </a>torch.einsum("oifp,bip-&gt;bof", transformed_filters, transformed_features)

            if not torch.allclose(output1, output2, atol=1e-5, rtol=1e-4):
                print(f"{in_rep.name}, {out_rep.name}: Error at {g}")</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/quva-lab/escnn/commit/98a89c5f80da2d489df613d8c73d943c69fb7f51#diff-8d6bcc0f6859181422be994b4b08f7ec20605bab877c007080bdf43f58b446d5L216' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 82100219</div><div id='project'> Project Name: quva-lab/escnn</div><div id='commit'> Commit Name: 98a89c5f80da2d489df613d8c73d943c69fb7f51</div><div id='time'> Time: 2022-08-28</div><div id='author'> Author: gabriele.cesa@gmail.com</div><div id='file'> File Name: test/kernelspaces/test_restrictedwignereckart.py</div><div id='m_class'> M Class Name: TestWEbasis</div><div id='n_method'> N Class Name: TestWEbasis</div><div id='m_method'> M Method Name: _check_irreps(6)</div><div id='n_method'> N Method Name: _check_irreps(6)</div><div id='m_parent_class'> M Parent Class: TestCase</div><div id='n_parent_class'> N Parent Class: TestCase</div><div id='m_file'> M File Name: test/kernelspaces/test_restrictedwignereckart.py</div><div id='n_file'> N File Name: test/kernelspaces/test_restrictedwignereckart.py</div><div id='m_start'> M Start Line: 224</div><div id='m_end'> M End Line: 274</div><div id='n_start'> N Start Line: 309</div><div id='n_end'> N End Line: 353</div><BR>