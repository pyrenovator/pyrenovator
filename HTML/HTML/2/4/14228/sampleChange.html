<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    cotrans.eval()

    &#47&#47 Forward through models
    target = <a id="change">trans(</a>example_clip<a id="change">)</a>

    outputs = []
    &#47&#47 Manual zero pad (due to padding=1 in trans.b Conv3d)
    zeros = torch.zeros_like(example_clip[:, :, 0])
    outputs.append(cotrans.forward(zeros))
    for i in range(example_clip.shape[2]):
        outputs.append(cotrans.forward(example_clip[:, :, i]))
    outputs.append(cotrans.forward(zeros))
    outputs.append(cotrans.forward(zeros))
    outputs.append(cotrans.forward(zeros))

    &#47&#47 For debugging:
    &#47&#47 close = []
    &#47&#47 for t in range(target.shape[2]):
    &#47&#47     for i in range(len(outputs)):
    &#47&#47         if torch.allclose(target[:, :, t], outputs[i], atol=5e-2):
    &#47&#47             close.append(f"t = {t}, o = {i}")

    shift = example_clip.shape[2] - 1  &#47&#47 From SE

    &#47&#47 Not very precise because SE block still initializes
    for t in range(1, <a id="change">target.shape[2]</a>):
        assert torch.allclose(target[:, :, t], outputs[t + shift], atol=5e-2)

    &#47&#47 After temporal_window_size inputs it also produces precise computation</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 Broken up
    cotrans.clean_state()
    nothing = cotrans.forward_steps(sample[:, :, :-1], pad_end=False)  &#47&#47 init
    <a id="change">assert </a>isinstance(nothing, TensorPlaceholder)

    lasts = cotrans.forward_steps(sample[:, :, -1:], pad_end=True)
    assert torch.allclose(lasts, target)</code></pre>