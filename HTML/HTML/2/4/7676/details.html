<html><h3>Pattern ID :7676
</h3><img src='25434293.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
		src_embedding = src_embedding + src_embedding_p
		tgt_embedding = tgt_embedding + tgt_embedding_p

		scores = torch.matmul(src_embedding.transpose(2, 1).contiguous(), tgt_embedding)<a id="change"> / </a><a id="change">math.sqrt(</a>self.emb_dims<a id="change">)</a>
		scores = torch.softmax(scores, dim=2)
		&#47&#47 b x points x points
		feat1_corr = torch.matmul(feat2, scores.transpose(2, 1).contiguous())
		rotation_ab, translation_ab = self.head(feat1, feat1_corr)</code></pre><h3>After Change</h3><pre><code class='java'>
            rotation_ba, translation_ba = self.head(tgt_embedding, src_embedding, tgt, src)

        else:
            rotation_ba = <a id="change">rotation_ab.transpose(</a>2, 1<a id="change">)</a>.contiguous()
            translation_ba = <a id="change">-torch.matmul(rotation_ba, translation_ab.unsqueeze(2)).squeeze(2)</a>
        
        T_12 = rt_to_transformation(rotation_ab, translation_ab.unsqueeze(2))

        if T_gt == None:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/paul007pl/mvp_benchmark/commit/cb5622fec6ad947b57a83033563a402533978c61#diff-b0b2731ff940d2b158077f966e3841337bc29d9303d97f5bbc31253fe6eaf136L270' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25434293</div><div id='project'> Project Name: paul007pl/mvp_benchmark</div><div id='commit'> Commit Name: cb5622fec6ad947b57a83033563a402533978c61</div><div id='time'> Time: 2021-07-12</div><div id='author'> Author: panliang_de2007@qq.com</div><div id='file'> File Name: registration/models/dcp.py</div><div id='m_class'> M Class Name: Model</div><div id='n_method'> N Class Name: Model</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: registration/models/dcp.py</div><div id='n_file'> N File Name: registration/models/dcp.py</div><div id='m_start'> M Start Line: 270</div><div id='m_end'> M End Line: 294</div><div id='n_start'> N Start Line: 394</div><div id='n_end'> N End Line: 425</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        key_dim = make_divisible(cc * key_dim, divisor=8) // num_heads  &#47&#47 regard as key_dim_ratio
    else:
        key_dim = cc // num_heads  &#47&#47 Default value
    qk_scale = float(1.0<a id="change"> / </a><a id="change">tf.math.sqrt(</a>tf.cast(key_dim, "float32")<a id="change">)</a>)
    out_shape = cc if out_shape is None else out_shape
    emb_dim = num_heads * key_dim
    kv_kernel = block_size + halo_size * 2</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 print(f"&gt;&gt;&gt;&gt; {attn_query.shape = }, {key.shape = }, {value.shape = }, {kv_inp.shape = }, {pos_query.shape = }, {num_heads = }")
    &#47&#47 attention_scores = [batch, num_heads, hh, ww, query_block * query_block, kv_kernel * kv_kernel]
    &#47&#47 attention_scores = layers.Lambda(lambda xx: functional.matmul(xx[0], xx[1], transpose_b=True))([attn_query, key])
    attention_scores = attn_query @ <a id="change">functional.transpose(</a>key, [0, 1, 2, 3, 5, 4]<a id="change">)</a>
    &#47&#47 pos = [batch, num_heads * hh * ww, query_block, query_block, kv_kernel, kv_kernel]
    pos = RelativePositionalEmbedding(position_height=kv_kernel, name=name and name + "pos_emb")(pos_query)
    &#47&#47 print(f"&gt;&gt;&gt;&gt; {pos.shape = }, {attention_scores.shape = }")
    pos = functional.reshape(pos, [-1, *attention_scores.shape[1:]])
    attention_scores = layers.Add()([attention_scores, pos])
    &#47&#47 attention_scores = tf.nn.softmax(attention_scores, axis=-1)
    attention_scores = layers.Softmax(axis=-1, name=name and name + "attention_scores")(attention_scores)

    if attn_dropout &gt; 0:
        attention_scores = layers.Dropout(attn_dropout, name=name and name + "attn_drop")(attention_scores)

    &#47&#47 attention_output = [batch, num_heads, hh, ww, query_block * query_block, out_dim]
    &#47&#47 attention_output = layers.Lambda(lambda xx: functional.matmul(xx[0], xx[1]))([attention_scores, value])
    attention_output = attention_scores<a id="change"> @ </a>value
    &#47&#47 attention_output = rearrange(attention_output, "B hd h w (hb wb) c -&gt; B (h hb) (w wb) (hd c)", hb=query_block, wb=query_block)
    _, heads, hh_aa, ww_aa, patch, cc_aa = attention_output.shape
    attention_output = functional.reshape(attention_output, [-1, heads, hh_aa, ww_aa, query_block, query_block, cc_aa])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/e05e233f369a1d58f912872b1581a80d15cacc3f#diff-5a0036f02e35afe08c2170dc9b0e1131865080e554a879c04557e7a873330e74L18' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25434294</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: e05e233f369a1d58f912872b1581a80d15cacc3f</div><div id='time'> Time: 2023-02-07</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/halonet/halonet.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: halo_attention(11)</div><div id='n_method'> N Method Name: halo_attention(11)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/halonet/halonet.py</div><div id='n_file'> N File Name: keras_cv_attention_models/halonet/halonet.py</div><div id='m_start'> M Start Line: 23</div><div id='m_end'> M End Line: 98</div><div id='n_start'> N Start Line: 28</div><div id='n_end'> N End Line: 106</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    matmul_qk = tf.matmul(q, k, transpose_b=True)  &#47&#47 (..., seq_len_q, seq_len_k)
    &#47&#47 scale matmul_qk
    dk = tf.cast(tf.shape(k)[-1], q.dtype)
    scaled_attention_logits = matmul_qk<a id="change"> / </a><a id="change">tf.math.sqrt(</a>dk<a id="change">)</a>
    &#47&#47 add the mask to the scaled tensor.
    if mask is not None:
        scaled_attention_logits += (tf.cast(mask, dtype=q.dtype) * -1e9)
    &#47&#47 softmax is normalized on the last axis (seq_len_k) so that the scores</code></pre><h3>After Change</h3><pre><code class='java'>
) -&gt; Tuple[tf.Tensor, tf.Tensor]:
     Scaled Dot-Product Attention 

    scores = tf.matmul(query, <a id="change">tf.transpose(</a>key<a id="change">, perm=[0, 1, 3, 2])</a>)<a id="change"> / </a>math.sqrt(query.shape[-1])
    if mask is not None:
        scores = tf.where(mask == 0, -1e9, scores)
    p_attn = tf.nn.softmax(scores, axis=-1)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mindee/doctr/commit/9530f81d15395006b4844299236bdadba11c1dde#diff-e1106a3628d5365c5fe2e4fec7304ea8e40c58a5439f23d8f20513e722955178L70' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25434305</div><div id='project'> Project Name: mindee/doctr</div><div id='commit'> Commit Name: 9530f81d15395006b4844299236bdadba11c1dde</div><div id='time'> Time: 2022-07-01</div><div id='author'> Author: felixdittrich92@gmail.com</div><div id='file'> File Name: doctr/models/recognition/transformer/tensorflow.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: scaled_dot_product_attention(4)</div><div id='n_method'> N Method Name: scaled_dot_product_attention(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: doctr/models/recognition/transformer/tensorflow.py</div><div id='n_file'> N File Name: doctr/models/recognition/transformer/tensorflow.py</div><div id='m_start'> M Start Line: 88</div><div id='m_end'> M End Line: 99</div><div id='n_start'> N Start Line: 63</div><div id='n_end'> N End Line: 67</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        imgRep = np.matmul(P, objPts_w_ex.T).T
        imgRep[:, 0] = imgRep[:, 0] / imgRep[:, 2]
        imgRep[:, 1] = imgRep[:, 1] / imgRep[:, 2]
        error = <a id="change">np.sqrt(</a>(imgPts[:, 0] - imgRep[:, 0].reshape((self.n, 1))) ** 2 + (
                    imgPts[:, 1] - imgRep[:, 1].reshape((self.n, 1))) ** 2<a id="change">)</a>
        error = np.sum(error, axis=0)<a id="change"> / </a>self.n

        return error[0]
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 concat 1 to the last column of objPts_w
        objPts_w_ex = torch.cat((objPts_w, torch.ones_like(objPts_w[:, :, :1])), dim=-1)
        &#47&#47 Calculate the image points
        imgRep = torch.bmm(P, <a id="change">objPts_w_ex.transpose(dim0=-1, dim1=-2)</a>).transpose(dim0=-1, dim1=-2)

        &#47&#47 Normalize the image points
        imgRep = imgRep[:, :, :2] / imgRep[:, :, 2:]

        error = torch.linalg.norm(imgRep<a id="change"> - </a>imgPts, dim=-1)
        error = torch.sum(error, dim=-1)

        return error</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pypose/pypose/commit/f93c59c3ad352fe90aa3072311a7ca67fa442243#diff-052b8dfcb4f5d16ac2df9676fd039e877588b354a969db2f245a098529fc6d31L455' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 25434303</div><div id='project'> Project Name: pypose/pypose</div><div id='commit'> Commit Name: f93c59c3ad352fe90aa3072311a7ca67fa442243</div><div id='time'> Time: 2023-02-25</div><div id='author'> Author: zitongz3@illinois.edu</div><div id='file'> File Name: pypose/module/pnp.py</div><div id='m_class'> M Class Name: EPnP</div><div id='n_method'> N Class Name: EPnP</div><div id='m_method'> M Method Name: reprojection_error(5)</div><div id='n_method'> N Method Name: reprojection_error(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: pypose/module/pnp.py</div><div id='n_file'> N File Name: pypose/module/pnp.py</div><div id='m_start'> M Start Line: 456</div><div id='m_end'> M End Line: 466</div><div id='n_start'> N Start Line: 469</div><div id='n_end'> N End Line: 492</div><BR>