<html><h3>Pattern ID :2357
</h3><img src='9986008.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                path=path + vid_name,
                                **kwargs)
    if None in rst_dict:
        <a id="change">return</a>

    &#47&#47 ppg, sbp, dbp, hr
    &#47&#47 if preprocess_type in ["DeepPhys", "PhysNet", "PhysNet_LSTM"]:
    return_dict[path.replace(&quot/&quot, &quot&quot) + str(kwargs[&quotflip_flag&quot])] = {</code></pre><h3>After Change</h3><pre><code class='java'>

    
    save_root_path = kwargs[&quotsave_root_path&quot]
    dataset_name<a id="change"> = </a>kwargs[&quotdataset_name&quot]

    preprocessed_label = label_preprocess(preprocess_type=preprocess_type,
                                          path=path + ground_truth_name,
                                          **kwargs)

    raw_video = video_preprocess(preprocess_type=preprocess_type,
                                path=path + vid_name,
                                **kwargs)
    if None in raw_video:
        return

    path = path.split(&quot/&quot)

    add_info<a id="change"> = </a>&quot&quot

    if dataset_name == "VIPL_HR":
        add_info = path[-3] + "/" + path[-2] + "/"

    dir_path = save_root_path + "/" + dataset_name + "/" + preprocess_type + "/" + add_info
    if not os.path.isdir(dir_path):
        mkdir_p(dir_path)

    data = h5py.File(dir_path +   path[-1] + ".hdf5","w")
    data.create_dataset(&quotraw_video&quot,data=raw_video)
    data.create_dataset(&quotpreprocessed_label&quot, data=preprocessed_label[0])
    data.create_dataset(&quotpreprocessed_hr&quot,data=preprocessed_label[1])
    <a id="change">data.close()</a>



def chunk_preprocessing(preprocess_type,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tvs-ai/pytorch_rppgs/commit/dcf5888afdf58407808ef89276c597ae7489ca2e#diff-f946f01ef839653e9ccb7b5681037e960dd77fd43b4d5d2317da521af818231bL127' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9986008</div><div id='project'> Project Name: tvs-ai/pytorch_rppgs</div><div id='commit'> Commit Name: dcf5888afdf58407808ef89276c597ae7489ca2e</div><div id='time'> Time: 2023-05-12</div><div id='author'> Author: spicyyeol@gmail.com</div><div id='file'> File Name: rppg/preprocessing/dataset_preprocess.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: preprocess_Dataset(5)</div><div id='n_method'> N Method Name: preprocess_Dataset(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: rppg/preprocessing/dataset_preprocess.py</div><div id='n_file'> N File Name: rppg/preprocessing/dataset_preprocess.py</div><div id='m_start'> M Start Line: 127</div><div id='m_end'> M End Line: 145</div><div id='n_start'> N Start Line: 138</div><div id='n_end'> N End Line: 166</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    if _use_new_zipfile_serialization:
        with _open_zipfile_writer(f) as opened_file:
            _save(obj, opened_file, pickle_module, pickle_protocol)
            <a id="change">return</a>

    with _open_file_like(f, &quotwb&quot) as opened_file:
        _legacy_save(obj, opened_file, pickle_module, pickle_protocol)
</code></pre><h3>After Change</h3><pre><code class='java'>
        _legacy_save(obj, opened_file, pickle_module, pickle_protocol)

    if is_compressed:
        f_pickle<a id="change"> = </a>&quot&quot
        if isinstance(f, str):
            f_pickle = f
        elif hasattr(f, &quotflush&quot) and hasattr(f, &quotwrite&quot):
            f_pickle<a id="change"> = </a>f.name

        fp = tarfile.open(f_pickle + &quot_&quot, &quotw&quot)
        fp.add(f_pickle)
        <a id="change">fp.close()</a>
        os.remove(f_pickle)
        os.rename(f_pickle + &quot_&quot, f_pickle)

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/allanyiin/trident/commit/bcdf7620a1a14d84309f2b5340cbe3cdd22f286e#diff-cec44eeee3e0d5403b00ecc51cd8bdaa4fbfb788f971a8bb8c508e61786c8671L363' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9986042</div><div id='project'> Project Name: allanyiin/trident</div><div id='commit'> Commit Name: bcdf7620a1a14d84309f2b5340cbe3cdd22f286e</div><div id='time'> Time: 2020-08-30</div><div id='author'> Author: allan@asiaminer.com.tw</div><div id='file'> File Name: trident/backend/tensorflow_serialization.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: save(5)</div><div id='n_method'> N Method Name: save(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: trident/backend/tensorflow_serialization.py</div><div id='n_file'> N File Name: trident/backend/tensorflow_serialization.py</div><div id='m_start'> M Start Line: 393</div><div id='m_end'> M End Line: 398</div><div id='n_start'> N Start Line: 393</div><div id='n_end'> N End Line: 412</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        stacked_maps[map_index, :, :, :] = spatio_temporal_map
        map_index += 1

    <a id="change">return </a>True, stacked_maps.astype(np.uint8).transpose((1, 0, 2))</code></pre><h3>After Change</h3><pre><code class='java'>
    min_max_scaler = preprocessing.MinMaxScaler()
    detector = get_haarcascade()
    eye_detector = get_eye_haarcascade()
    pbar<a id="change"> = </a>tqdm(total=num_frames, position=0, leave=True, desc=video_path+&quot Detecting Faces&quot)
    &#47&#47 First we process all the frames and then work with sliding window to save repeated processing for the same frame index
    for idx, frame in enumerate(frames):
        &#47&#47 spatio_temporal_map = np.zeros((fr, 25, 3))
        &quot&quot&quot
           Preprocess the Image
           Step 1: Use cv2 face detector based on Haar cascades
           Step 2: Crop the frame based on the face co-ordinates (we need to do 160%)
           Step 3: Downsample the face cropped frame to output_shape = 36x36
       &quot&quot&quot
        faces = detector.detectMultiScale(frame, 1.3, 5)
        if len(faces) is not 0:
            (x, y, w, d) = faces[0]
            frame_cropped = frame[y:(y + d), x:(x + w)]
            &#47&#47 eyes = eye_detector.detectMultiScale(frame_cropped, 1.2, 3)
            &#47&#47 if len(eyes) &gt; 0:
            &#47&#47     &#47&#47 for having the same radius in both eyes
            &#47&#47     (eye_x, eye_y, eye_w, eye_h) = eyes[0]
            &#47&#47     eye_radius = (eye_w + eye_h) // 5
            &#47&#47     mask = np.ones(frame_cropped.shape[:2], dtype="uint8")
            &#47&#47     for (ex, ey, ew, eh) in eyes[:2]:
            &#47&#47         eye_center = (ex + ew // 2, ey + eh // 2)
            &#47&#47         &#47&#47 if eye_radius
            &#47&#47         cv2.circle(mask, eye_center, eye_radius, 0, -1)
            &#47&#47         &#47&#47 eh = int(0.8*eh)
            &#47&#47         &#47&#47 ew = int(0.8*ew)
            &#47&#47         &#47&#47 cv2.rectangle(mask, (ex, ey), (ex+ew, ey+eh), 0, -1)
            &#47&#47
            &#47&#47     frame_masked = cv2.bitwise_and(frame_cropped, frame_cropped, mask=mask)
            &#47&#47 else:
            &#47&#47     frame_masked = frame_cropped
            &#47&#47     &#47&#47 plot_image(frame_masked)

            frame_masked = frame_cropped
        else:
            &#47&#47 The problemis that this doesn&quott get cropped :/
            &#47&#47 (x, y, w, d) = (308, 189, 215, 215)
            &#47&#47 frame_masked = frame[y:(y + d), x:(x + w)]

            &#47&#47 print("face detection failed, image frame will be masked")
            mask = np.zeros(frame.shape[:2], dtype="uint8")
            frame_masked = cv2.bitwise_and(frame, frame, mask=mask)
            &#47&#47 plot_image(frame_masked)

        &#47&#47 frame_cropped = frame[y:(y + d), x:(x + w)]

        try:
            &#47&#47 frame_resized = cv2.resize(frame_masked, output_shape, interpolation=cv2.INTER_CUBIC)
            frame_resized = cv2.cvtColor(frame_masked, cv2.COLOR_BGR2YUV)

        except:
            print(&quot\n--------- ERROR! -----------\nUsual cv empty error&quot)
            print(f&quotShape of img1: {frame.shape}&quot)
            &#47&#47 print(f&quotbbox: {bbox}&quot)
            print(f&quotThis is at idx: {idx}&quot)
            return False, None

            &#47&#47 exit(666)

        processed_frames.append(frame_resized)
        pbar.update(1)
    pbar.close()
    &#47&#47 roi_blocks = chunkify(frame_resized)
    &#47&#47 for block_idx, block in enumerate(roi_blocks):
    &#47&#47     avg_pixels = cv2.mean(block)
    &#47&#47     processed_maps[idx, block_idx, 0] = avg_pixels[0]
    &#47&#47     processed_maps[idx, block_idx, 1] = avg_pixels[1]
    &#47&#47     processed_maps[idx, block_idx, 2] = avg_pixels[2]
    pbar<a id="change"> = </a>tqdm(total=num_maps, position=0, leave=True, desc=video_path+&quot Making STMAPS&quot)
    &#47&#47 At this point we have the processed maps from all the frames in a video and now we do the sliding window part.
    for start_frame_index in range(0, num_frames, sliding_window_stride):
        end_frame_index = start_frame_index + clip_size
        if end_frame_index &gt; num_frames:
            break
        &#47&#47 &#47&#47 print(f"start_idx: {start_frame_index} | end_idx: {end_frame_index}")
        spatio_temporal_map = np.zeros((clip_size, 25, 3))
        &#47&#47
        &#47&#47 spatio_temporal_map = processed_maps[start_frame_index:end_frame_index, :, :]

        for idx, frame in enumerate(processed_frames[start_frame_index:end_frame_index]):
            roi_blocks = chunkify(frame)
            for block_idx, block in enumerate(roi_blocks):
                avg_pixels = cv2.mean(block)
                spatio_temporal_map[idx, block_idx, 0] = avg_pixels[0]
                spatio_temporal_map[idx, block_idx, 1] = avg_pixels[1]
                spatio_temporal_map[idx, block_idx, 2] = avg_pixels[2]

        for block_idx in range(spatio_temporal_map.shape[1]):
            &#47&#47 Not sure about uint8
            fn_scale_0_255 = lambda x: (x * 255.0).astype(np.uint8)
            scaled_channel_0 = min_max_scaler.fit_transform(spatio_temporal_map[:, block_idx, 0].reshape(-1, 1))
            spatio_temporal_map[:, block_idx, 0] = fn_scale_0_255(scaled_channel_0.flatten())
            scaled_channel_1 = min_max_scaler.fit_transform(spatio_temporal_map[:, block_idx, 1].reshape(-1, 1))
            spatio_temporal_map[:, block_idx, 1] = fn_scale_0_255(scaled_channel_1.flatten())
            scaled_channel_2 = min_max_scaler.fit_transform(spatio_temporal_map[:, block_idx, 2].reshape(-1, 1))
            spatio_temporal_map[:, block_idx, 2] = fn_scale_0_255(scaled_channel_2.flatten())

        stacked_maps[map_index, :, :, :] = spatio_temporal_map
        map_index += 1
        pbar.update(1)
    <a id="change">pbar.close()</a>

    (idx, w, h, c) = stacked_maps.shape
    stacked_maps = stacked_maps.reshape((idx, h, w, c))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tvs-ai/pytorch_rppgs/commit/fb7669c43864d13d11528ad55745d21e2ce0635e#diff-9e56f945a06ad9d7c0b5eef59c8b6c9d69ad066e7a42e26909c38d0277fcb94cL981' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9985989</div><div id='project'> Project Name: tvs-ai/pytorch_rppgs</div><div id='commit'> Commit Name: fb7669c43864d13d11528ad55745d21e2ce0635e</div><div id='time'> Time: 2022-10-19</div><div id='author'> Author: 57242033+najy97@users.noreply.github.com</div><div id='file'> File Name: utils/image_preprocess.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: RhythmNet_preprocessor(2)</div><div id='n_method'> N Method Name: RhythmNet_preprocessor(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: utils/image_preprocess.py</div><div id='n_file'> N File Name: utils/image_preprocess.py</div><div id='m_start'> M Start Line: 984</div><div id='m_end'> M End Line: 1102</div><div id='n_start'> N Start Line: 1004</div><div id='n_end'> N End Line: 1109</div><BR>