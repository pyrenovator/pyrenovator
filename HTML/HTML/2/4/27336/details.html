<html><h3>Pattern ID :27336
</h3><img src='81249879.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                if ap is None:
                    ap = AudioPreprocessor(input_sr=sr, output_sr=16000, melspec_buckets=80, hop_length=256, n_fft=1024)
                self.cached_text.append(tf.string_to_tensor(transcript).long())
                self.cached_text_lens.append(<a id="change">torch.LongTensor(</a>[len(self.cached_text[-1])]<a id="change">)</a>)
                self.cached_speech.append(ap.audio_to_mel_spec_tensor(wave).transpose(0, 1))
                self.cached_speech_lens.append(<a id="change">torch.LongTensor(</a>[len(self.cached_speech[-1])]<a id="change">)</a>)
                if self.spemb:
                    print("not implemented yet")
                    raise NotImplementedError</code></pre><h3>After Change</h3><pre><code class='java'>
            thread_list.append(Thread(target=self.cache_builder_thread, args=(key_split,)))
            thread_list[-1].start()
        for thread in thread_list:
            <a id="change">thread.join()</a>

    def cache_builder_thread(self, path_list):
        for path in path_list:
            transcript = self.path_to_transcript_dict[path]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/21527c7e2ea36abafa7885cef64519affbb0e587#diff-0965ad6e3a8f04afe3a358a7558e203eaa1f244ad6e8e6fbfe73f8a2052b8cb1L14' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 81249879</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 21527c7e2ea36abafa7885cef64519affbb0e587</div><div id='time'> Time: 2021-03-01</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_class'> M Class Name: TransformerTTSDataset</div><div id='n_method'> N Class Name: TransformerTTSDataset</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='n_file'> N File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_start'> M Start Line: 14</div><div id='m_end'> M End Line: 51</div><div id='n_start'> N Start Line: 15</div><div id='n_end'> N End Line: 47</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def __getitem__(self, index):
        &#47&#47 create tensors on correct device
        text = <a id="change">torch.LongTensor(</a>self.feature_list[index][0]<a id="change">)</a>.to(self.device)
        text_len = <a id="change">torch.LongTensor(</a>[self.feature_list[index][1]]<a id="change">)</a>.to(self.device)
        speech = torch.transpose(torch.Tensor(self.feature_list[index][2]), 0, 1).to(self.device)
        speech_len = torch.LongTensor([self.feature_list[index][3]]).to(self.device)
        if self.spemb:</code></pre><h3>After Change</h3><pre><code class='java'>
    def __getitem__(self, index):
        transcript = self.path_to_transcript_dict[self.key_list[index]]
        path = self.key_list[index]
        wave, sr = sf.read(<a id="change">os.path.join(</a>"Corpora/CSS10/", path<a id="change">)</a>)
        if self.ap is None:
            self.ap = AudioPreprocessor(input_sr=sr, output_sr=16000, melspec_buckets=80, hop_length=256, n_fft=1024)
        text = self.tf.string_to_tensor(transcript).long()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/1e192df888be8f1dc1c20971132b31fe73153b7d#diff-0965ad6e3a8f04afe3a358a7558e203eaa1f244ad6e8e6fbfe73f8a2052b8cb1L12' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 81249863</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 1e192df888be8f1dc1c20971132b31fe73153b7d</div><div id='time'> Time: 2021-02-22</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_class'> M Class Name: TransformerTTSDataset</div><div id='n_method'> N Class Name: TransformerTTSDataset</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='n_file'> N File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_start'> M Start Line: 14</div><div id='m_end'> M End Line: 21</div><div id='n_start'> N Start Line: 32</div><div id='n_end'> N End Line: 44</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            else:
                for datapoint in tqdm(self.datapoints):
                    tensored_datapoints.append([torch.Tensor(datapoint[0]),
                                                <a id="change">torch.LongTensor(</a>datapoint[1]<a id="change">)</a>,
                                                torch.Tensor(datapoint[2]),
                                                <a id="change">torch.LongTensor(</a>datapoint[3]<a id="change">)</a>,
                                                torch.LongTensor(datapoint[4]),
                                                torch.Tensor(datapoint[5]),
                                                torch.Tensor(datapoint[6])])</code></pre><h3>After Change</h3><pre><code class='java'>
                                max_len_in_seconds=max_len_in_seconds,
                                cut_silences=cut_silence,
                                rebuild_cache=True)
                datapoints = torch.load(<a id="change">os.path.join(</a>cache_dir, "taco_train_cache.pt"<a id="change">)</a>, map_location=&quotcpu&quot)
            dataset = datapoints[0]
            norm_waves = datapoints[1]
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/d75af2f091227a4695d4887a9a8f23dc5d22b12b#diff-528f1d1f9b65f826c6eec25f3934452fe1a81965d76a0070a71db9ef9ef36aa0L22' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 81249877</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: d75af2f091227a4695d4887a9a8f23dc5d22b12b</div><div id='time'> Time: 2021-09-15</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='m_class'> M Class Name: FastSpeechDataset</div><div id='n_method'> N Class Name: FastSpeechDataset</div><div id='m_method'> M Method Name: __init__(13)</div><div id='n_method'> N Method Name: __init__(13)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='m_start'> M Start Line: 36</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 36</div><div id='n_end'> N End Line: 109</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                if ap is None:
                    ap = AudioPreprocessor(input_sr=sr, output_sr=16000, melspec_buckets=80, hop_length=256, n_fft=1024)
                self.cached_text.append(tf.string_to_tensor(transcript).long())
                self.cached_text_lens.append(<a id="change">torch.LongTensor(</a>[len(self.cached_text[-1])]<a id="change">)</a>)
                self.cached_speech.append(ap.audio_to_mel_spec_tensor(wave).transpose(0, 1))
                self.cached_speech_lens.append(<a id="change">torch.LongTensor(</a>[len(self.cached_speech[-1])]<a id="change">)</a>)
                if self.spemb:
                    print("not implemented yet")
                    raise NotImplementedError</code></pre><h3>After Change</h3><pre><code class='java'>
            thread_list.append(Thread(target=self.cache_builder_thread, args=(key_split,)))
            thread_list[-1].start()
        for thread in thread_list:
            <a id="change">thread.join()</a>

    def cache_builder_thread(self, path_list):
        for path in path_list:
            transcript = self.path_to_transcript_dict[path]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/21527c7e2ea36abafa7885cef64519affbb0e587#diff-0965ad6e3a8f04afe3a358a7558e203eaa1f244ad6e8e6fbfe73f8a2052b8cb1L13' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 81249884</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 21527c7e2ea36abafa7885cef64519affbb0e587</div><div id='time'> Time: 2021-03-01</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_class'> M Class Name: TransformerTTSDataset</div><div id='n_method'> N Class Name: TransformerTTSDataset</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='n_file'> N File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_start'> M Start Line: 14</div><div id='m_end'> M End Line: 51</div><div id='n_start'> N Start Line: 15</div><div id='n_end'> N End Line: 47</div><BR>