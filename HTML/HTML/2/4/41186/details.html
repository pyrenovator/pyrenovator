<html><h3>Pattern ID :41186
</h3><img src='116186350.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        print(average_energy)
        print(highest_energy)
        print(lowest_energy)
        <a id="change">print(</a>std_dev_energy<a id="change">)</a>
        print(average_pitch)
        print(highest_pitch)
        print(lowest_pitch)
        print(std_dev_pitch)</code></pre><h3>After Change</h3><pre><code class='java'>
        lowest_pitch = pitch[pitch[0] != 0.0].min().unsqueeze(0)
        std_dev_pitch = pitch[pitch[0] != 0.0].std().unsqueeze(0)
        spk_emb = self.speaker_embedding_func.encode_batch(wavs=norm_wave.unsqueeze(0)).squeeze()
        lang_emb<a id="change"> = </a><a id="change">self.language_embedding_func.encode_batch(wavs=norm_wave.unsqueeze(0)).squeeze()</a>
        combined_utt_condition<a id="change"> = </a>torch.cat([average_energy,
                                            highest_energy,
                                            lowest_energy,
                                            std_dev_energy,</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 6</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/92714ccec18bcb46fcb397bd8fbecc293e9d7066#diff-1d8ab6434eacf351a1a0e9997c0db4b4d8db7486e2e4e427c85619e7ef79ba80L21' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116186350</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 92714ccec18bcb46fcb397bd8fbecc293e9d7066</div><div id='time'> Time: 2022-01-05</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/ProsodicConditionExtractor.py</div><div id='m_class'> M Class Name: ProsodicConditionExtractor</div><div id='n_method'> N Class Name: ProsodicConditionExtractor</div><div id='m_method'> M Method Name: extract_condition_from_reference_wave(2)</div><div id='n_method'> N Method Name: extract_condition_from_reference_wave(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/ProsodicConditionExtractor.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/ProsodicConditionExtractor.py</div><div id='m_start'> M Start Line: 21</div><div id='m_end'> M End Line: 37</div><div id='n_start'> N Start Line: 32</div><div id='n_end'> N End Line: 53</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        fastraster_time_gpu = time.time() - tic

    print("Runtimes:")
    <a id="change">print(
        </a>"Fast Marching: {:.6f} s \nGeodisTk raster: {:.6f} s \nFastGeodis CPU raster: {:.6f} s".format(
            fastmarch_time, geodistkraster_time, fastraster_time_cpu
        )<a id="change">
    )</a>

    if device:
        print("FastGeodis GPU raster: {:.6f} s".format(fastraster_time_gpu))
</code></pre><h3>After Change</h3><pre><code class='java'>
    )

    tic = time.time()
    toivanenraster_output<a id="change"> = </a><a id="change">np.squeeze(
        </a>FastGeodis.generalised_geodesic2d_toivanen(input_image_pt, seed_image_pt, v, lamb, iterations).cpu().numpy()<a id="change">
    )</a>
    toivanenraster_time = time.time() - tic

    tic = time.time()
    fastraster_output_cpu = np.squeeze(
        FastGeodis.generalised_geodesic2d(input_image_pt, seed_image_pt, v, lamb, iterations).cpu().numpy()
    )
    fastraster_time_cpu = time.time() - tic

    device = "cuda" if torch.cuda.is_available() else None
    if device:
        input_image_pt = input_image_pt.to(device)
        seed_image_pt = seed_image_pt.to(device)

        tic = time.time()
        fastraster_output_gpu = np.squeeze(
            FastGeodis.generalised_geodesic2d(input_image_pt, seed_image_pt, v, lamb, iterations).cpu().numpy()
        )
        fastraster_time_gpu = time.time() - tic

    print("Runtimes:")
    print(
        "Toivanen&quots CPU raster: {:.6f} s \nFastGeodis CPU raster: {:.6f} s".format(
            toivanenraster_time, fastraster_time_cpu
        )
    )

    if device:
        print("FastGeodis GPU raster: {:.6f} s".format(fastraster_time_gpu))

    plt.figure(figsize=(18, 6))
    plt.subplot(2, 4, 1)
    plt.imshow(image, cmap="gray")
    plt.autoscale(False)
    plt.plot([seed_pos[0]], [seed_pos[1]], "ro")
    plt.axis("off")
    plt.title("(a) Input image")

    plt.subplot(2, 4, 2)
    plt.imshow(toivanenraster_output)
    plt.axis("off")
    plt.title("(b) Toivanen&quots Raster (cpu) | ({:.4f} s)".format(toivanenraster_time))

    plt.subplot(2, 4, 3)
    plt.imshow(fastraster_output_cpu)
    plt.axis("off")
    plt.title("(c) FastGeodis (cpu) | ({:.4f} s)".format(fastraster_time_cpu))

    plt.subplot(2, 4, 6)
    plt.imshow(toivanenraster_output)
    plt.axis("off")
    plt.title("(d) Toivanen&quots Raster (cpu) | ({:.4f} s)".format(toivanenraster_time))

    if device:
        plt.subplot(2, 4, 7)
        plt.imshow(fastraster_output_gpu)
        plt.axis("off")
        plt.title("(e) FastGeodis (gpu) | ({:.4f} s)".format(fastraster_time_gpu))

    diff<a id="change"> = </a>(
        abs(toivanenraster_output - fastraster_output_cpu) / (toivanenraster_output + 1e-7) * 100
    )
    plt.subplot(2, 4, 4)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/masadcv/fastgeodis/commit/a1906e989649c1f0b8fdbed147c1d576ac5c41f3#diff-c6567a84a23f27eb1443122b56b63757dea429e19a3d3c58c88e6c34596a2e13L26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116186351</div><div id='project'> Project Name: masadcv/fastgeodis</div><div id='commit'> Commit Name: a1906e989649c1f0b8fdbed147c1d576ac5c41f3</div><div id='time'> Time: 2022-07-22</div><div id='author'> Author: muhammad.asad@kcl.ac.uk</div><div id='file'> File Name: samples/demo2d.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate_geodesic_distance2d(2)</div><div id='n_method'> N Method Name: evaluate_geodesic_distance2d(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: samples/demo2d.py</div><div id='n_file'> N File Name: samples/demo2d.py</div><div id='m_start'> M Start Line: 29</div><div id='m_end'> M End Line: 158</div><div id='n_start'> N Start Line: 18</div><div id='n_end'> N End Line: 100</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    err = np.mean(
        np.abs(np.concatenate(coeffs) - torch.cat(coeffs2, -1).squeeze().numpy())
    )
    <a id="change">print(</a>"haar coefficient error scale 2", err, ["ok" if err &lt; 1e-4 else "failed!"]<a id="change">)</a>
    assert err &lt; 1e-4


def test_conv_fwt_haar_lvl2_odd():</code></pre><h3>After Change</h3><pre><code class='java'>
    err = np.mean(np.abs(pywt_coeffs - ptwt_coeffs))
    print("haar coefficient error scale 2", err, ["ok" if err &lt; 1e-6 else "failed!"])
    assert np.allclose(pywt_coeffs, ptwt_coeffs)
    rec<a id="change"> = </a><a id="change">waverec(coeffs2, wavelet).squeeze()</a>.numpy()
    err<a id="change"> = </a>np.mean(np.abs((data - rec)))
    print("haar reconstruction error scale 2", err, ["ok" if err &lt; 1e-6 else "failed!"])
    assert np.allclose(data, rec)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/v0lta/pytorch-wavelet-toolbox/commit/c52a0038ca7ceb817da834840a1655d55ff6f1a3#diff-499aa4727e73e6303fe60bf9cdec38d37980e9804f8f1d9d678da5ee867366b3L19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116186346</div><div id='project'> Project Name: v0lta/pytorch-wavelet-toolbox</div><div id='commit'> Commit Name: c52a0038ca7ceb817da834840a1655d55ff6f1a3</div><div id='time'> Time: 2021-07-02</div><div id='author'> Author: moritz@wolter.tech</div><div id='file'> File Name: tests/test_convolution_fwt.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_conv_fwt_haar_lvl2(0)</div><div id='n_method'> N Method Name: test_conv_fwt_haar_lvl2(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/test_convolution_fwt.py</div><div id='n_file'> N File Name: tests/test_convolution_fwt.py</div><div id='m_start'> M Start Line: 42</div><div id='m_end'> M End Line: 49</div><div id='n_start'> N Start Line: 22</div><div id='n_end'> N End Line: 56</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                else:
                    loss=criterion(out, j[-1].cuda())
                totalloss += loss*len(j[-1])
                <a id="change">print(</a>totalloss<a id="change">)</a>
                if task == "classification":
                    pred.append(torch.argmax(out, 1))
                elif task == "multilabel":
                    pred.append(torch.sigmoid(out).round())</code></pre><h3>After Change</h3><pre><code class='java'>
                    loss=criterion(out, j[-1].float().cuda())
                else:
                    if len(j[-1].size())&gt;1:
                        j[-1]<a id="change"> = </a><a id="change">j[-1].squeeze()</a>
                    loss<a id="change">=</a>criterion(out, j[-1].long().cuda())
                totalloss += loss*len(j[-1])
                &#47&#47print(totalloss)
                if task == "classification":</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pliang279/multibench/commit/e854effb566a45ddcf8788685b859e545feb70c0#diff-d3849819d29a68870215319efee82c37d9369ee66a16c6d341a3d7442791395eL33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116186411</div><div id='project'> Project Name: pliang279/multibench</div><div id='commit'> Commit Name: e854effb566a45ddcf8788685b859e545feb70c0</div><div id='time'> Time: 2021-05-23</div><div id='author'> Author: blairc@andrew.cmu.edu</div><div id='file'> File Name: training_structures/Simple_Late_Fusion.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(16)</div><div id='n_method'> N Method Name: train(16)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: training_structures/Simple_Late_Fusion.py</div><div id='n_file'> N File Name: training_structures/Simple_Late_Fusion.py</div><div id='m_start'> M Start Line: 67</div><div id='m_end'> M End Line: 105</div><div id='n_start'> N Start Line: 55</div><div id='n_end'> N End Line: 107</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            cv2.imshow(&quotinput&quot, center_img)


            <a id="change">print(</a>vid_path<a id="change">)</a>
            cv2.waitKey()

            &#47&#47break</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47mask = torch.round(masks)

            center_img_salient = rgb_center_img_tensor*mask     &#47&#47 3 channels x 1 frame x H x W
            center_img_salient = <a id="change">center_img_salient.squeeze(</a>1<a id="change">)</a>

            &#47&#47 Put image values into range [0, 1] and then normalize using 
            &#47&#47 mean and std for ImageNet
            &#47&#47 https://pytorch.org/docs/stable/torchvision/models.html

            center_img_salient<a id="change"> = </a>tensor_min_max_normalize(center_img_salient)
            normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
            center_img_salient = normalize(center_img_salient)

            &#47&#47print (&quotInput size&quot, input.size())      
            &#47&#47print (&quotsalient&quot, center_img_salient.size())    
            &#47&#47print(vid_path)

            &#47&#47 Visualize mask region
            &#47&#47center_img = vid_tensor_to_numpy(center_img_salient.unsqueeze(1))[0]
            &#47&#47center_img = cv2.cvtColor(center_img, cv2.COLOR_RGB2BGR)
            &#47&#47center_img = cv_f32_to_u8(center_img)
            &#47&#47cv2.imshow(&quotinput&quot, center_img)
            &#47&#47cv2.waitKey()

            &#47&#47&#47&#47 Visual mask
            &#47&#47&#47&#47mask = vid_tensor_to_numpy(input[3].unsqueeze(0))[0]
            &#47&#47&#47&#47print(mask)
            &#47&#47&#47&#47mask = cv2.merge([mask, mask, mask])

            center_img_salient<a id="change"> = </a>center_img_salient.unsqueeze(0)
            if cuda:
                center_img_salient = center_img_salient.to(device)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rvl-lab-utoronto/video_similarity_search/commit/e5eeb446b18f40a7af123ef6d93ea24c32cc0538#diff-98f1ab4b8aa34886d0f0a9d861b630e102aafdb9b6fed0569e138b1facf9d4efL41' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116186340</div><div id='project'> Project Name: rvl-lab-utoronto/video_similarity_search</div><div id='commit'> Commit Name: e5eeb446b18f40a7af123ef6d93ea24c32cc0538</div><div id='time'> Time: 2020-08-28</div><div id='author'> Author: salar77h@gmail.com</div><div id='file'> File Name: clustering/cluster_masks.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: get_embeddings_mask_regions(3)</div><div id='n_method'> N Method Name: get_embeddings_mask_regions(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: clustering/cluster_masks.py</div><div id='n_file'> N File Name: clustering/cluster_masks.py</div><div id='m_start'> M Start Line: 46</div><div id='m_end'> M End Line: 109</div><div id='n_start'> N Start Line: 51</div><div id='n_end'> N End Line: 127</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                else:
                    loss=criterion(out, j[-1].cuda())
                totalloss += loss*len(j[-1])
                <a id="change">print(</a>totalloss<a id="change">)</a>
                if task == "classification":
                    pred.append(torch.argmax(out, 1))
                elif task == "multilabel":
                    pred.append(torch.sigmoid(out).round())</code></pre><h3>After Change</h3><pre><code class='java'>
                    loss=criterion(out, j[-1].float().cuda())
                else:
                    if len(j[-1].size())&gt;1:
                        j[-1]<a id="change"> = </a><a id="change">j[-1].squeeze()</a>
                    loss<a id="change">=</a>criterion(out, j[-1].long().cuda())
                totalloss += loss*len(j[-1])
                &#47&#47print(totalloss)
                if task == "classification":</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pliang279/multibench/commit/1c128af16e3b49797aee4b1097382015f746c920#diff-d3849819d29a68870215319efee82c37d9369ee66a16c6d341a3d7442791395eL33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 116186405</div><div id='project'> Project Name: pliang279/multibench</div><div id='commit'> Commit Name: 1c128af16e3b49797aee4b1097382015f746c920</div><div id='time'> Time: 2021-05-23</div><div id='author'> Author: blairc@andrew.cmu.edu</div><div id='file'> File Name: training_structures/Simple_Late_Fusion.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(16)</div><div id='n_method'> N Method Name: train(16)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: training_structures/Simple_Late_Fusion.py</div><div id='n_file'> N File Name: training_structures/Simple_Late_Fusion.py</div><div id='m_start'> M Start Line: 67</div><div id='m_end'> M End Line: 105</div><div id='n_start'> N Start Line: 55</div><div id='n_end'> N End Line: 107</div><BR>