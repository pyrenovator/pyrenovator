<html><h3>Pattern ID :36579
</h3><img src='103941590.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    Uses hugginface generate (https://huggingface.co/transformers/main_classes/model.html?highlight=generate&#47&#47transformers.TFPreTrainedModel.generate)
    With tokenizer.padding size = left, otherwise generation is random (issue https://github.com/huggingface/transformers/issues/3021)
    
    encodings_dict<a id="change"> = </a><a id="change">tokenizer(
        </a>prompts<a id="change">, truncation=True, max_length=constants.MAX_SEQ_LEN)</a>
    prompts_ids = torch.tensor(
        encodings_dict[&quotinput_ids&quot], device=device, dtype=torch.long)
    first_idx = len(prompts_ids[0]) if first_idx else 0
</code></pre><h3>After Change</h3><pre><code class='java'>
    With tokenizer.padding size = left, otherwise generation is random (issue https://github.com/huggingface/transformers/issues/3021)
    
    assert len(prompts) == 1, "Generate function assumes one prompt"
    encodings_dict = <a id="change">tokenizer(
        </a>prompts<a id="change">)</a>
    &#47&#47 Truncates tokens from the end of the sequence.
    sliced_inputs = [encodings_dict[&quotinput_ids&quot][0][-constants.MAX_SEQ_LEN:]]
    prompts_ids<a id="change"> = </a>torch.tensor(
        sliced_inputs, device=device, dtype=torch.long)
    first_idx = len(prompts_ids[0]) if first_idx else 0
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/edenbd/multimodalstory-demo/commit/6417dcd958f24787fbfe75678705ccd8c5312f4a#diff-4c2116e7cd9352d743e0bed65f5a02f6fc208db101bc941a08ef87a3adfb8912L53' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 103941590</div><div id='project'> Project Name: edenbd/multimodalstory-demo</div><div id='commit'> Commit Name: 6417dcd958f24787fbfe75678705ccd8c5312f4a</div><div id='time'> Time: 2021-04-21</div><div id='author'> Author: edenoosh15@gmail.com</div><div id='file'> File Name: backend/story_generator/generation_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: _sample_demo_sequence(7)</div><div id='n_method'> N Method Name: _sample_demo_sequence(7)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: backend/story_generator/generation_utils.py</div><div id='n_file'> N File Name: backend/story_generator/generation_utils.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 56</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    text = utils.read_string(eval_file)

    &#47&#47 below will be just one giant tensor of all tokens
    encodings<a id="change"> = </a><a id="change">tokenizer(</a>text<a id="change">)</a>

    max_length = model.config.n_positions
    context_len = max_length // 2
</code></pre><h3>After Change</h3><pre><code class='java'>
        text = text[:max_eval_len] if len(text) &gt; max_eval_len else text

    &#47&#47 below will be just one giant tensor of all tokens
    encodings<a id="change"> = </a><a id="change">tokenizer(</a>text<a id="change">, return_tensors=&quotpt&quot)</a>

    &#47&#47 max input segment length for the model
    max_length = model.config.n_positions
    &#47&#47 on avg, context length is half of segment length</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/archai/commit/23005fb5d1669142d55bbdabce71be2de7d9f7f1#diff-699c4cd8188fe9a3e97e5253b1b936f2b99f6bbcd9dba29e659f3365f50345d4L187' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 103941588</div><div id='project'> Project Name: microsoft/archai</div><div id='commit'> Commit Name: 23005fb5d1669142d55bbdabce71be2de7d9f7f1</div><div id='time'> Time: 2022-12-16</div><div id='author'> Author: shitals@microsoft.com</div><div id='file'> File Name: archai/nlp/gpt2_trainer_atg.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate(4)</div><div id='n_method'> N Method Name: evaluate(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: archai/nlp/gpt2_trainer_atg.py</div><div id='n_file'> N File Name: archai/nlp/gpt2_trainer_atg.py</div><div id='m_start'> M Start Line: 187</div><div id='m_end'> M End Line: 205</div><div id='n_start'> N Start Line: 213</div><div id='n_end'> N End Line: 245</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
  counterfactuals.append(sentence)

  tokens = tokenizer(sentence)
  counterfactual_tokens<a id="change"> = </a>[<a id="change">tokenizer(</a>sentence<a id="change">)</a> for sentence in counterfactuals]

  if lowercase_tokens:
    tokens = [token.lower() for token in tokens]</code></pre><h3>After Change</h3><pre><code class='java'>
  &#47&#47 Include the original sentence in the list of counterfactuals for
  &#47&#47 explanation.
  counterfactuals.append(sentence)
  counterfactual_tokens<a id="change"> = </a>[<a id="change">tokenizer(</a>s<a id="change">)</a> for s in counterfactuals]

  if lowercase_tokens:
    tokens = [token.lower() for token in tokens]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pair-code/lit/commit/be51efda3b7fb32a219fa389f28aa17ce19a4dd0#diff-95a5e33893be4435f8cbd15217134a7d9e3d79655774f1b722115e2f6291c0aaL97' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 103941592</div><div id='project'> Project Name: pair-code/lit</div><div id='commit'> Commit Name: be51efda3b7fb32a219fa389f28aa17ce19a4dd0</div><div id='time'> Time: 2022-10-17</div><div id='author'> Author: iftenney@google.com</div><div id='file'> File Name: lit_nlp/components/citrus/lemon.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: explain(15)</div><div id='n_method'> N Method Name: explain(15)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: lit_nlp/components/citrus/lemon.py</div><div id='n_file'> N File Name: lit_nlp/components/citrus/lemon.py</div><div id='m_start'> M Start Line: 158</div><div id='m_end'> M End Line: 194</div><div id='n_start'> N Start Line: 147</div><div id='n_end'> N End Line: 190</div><BR>