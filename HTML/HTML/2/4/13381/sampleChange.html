<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        adjust_learning_rate(optimizer, epoch, args)

        &#47&#47 train for one epoch
        <a id="change">train(</a>train_loader, model, criterion, optimizer, epoch, local_rank, args<a id="change">)</a>

        &#47&#47 evaluate on validation set
        acc1 = validate(val_loader, model, criterion, local_rank, args)
</code></pre><h3>After Change</h3><pre><code class='java'>
        for step, (images, labels) in enumerate(train_loader):
            &#47&#47 将对应进程的数据放到对应 GPU 上
            images = images.cuda(local_rank, non_blocking=True)
            labels = <a id="change">labels.cuda(</a>local_rank<a id="change">, non_blocking=True)</a>

            outputs = model(images)
            loss<a id="change"> = </a>criterion(outputs, labels)

            &#47&#47 torch.distributed.barrier()的作用是，阻塞进程，保证每个进程运行完这一行代码之前的所有代码，才能继续执行，这样才计算平均loss和平均acc的时候不会出现因为进程执行速度不一致的错误
            torch.distributed.barrier()
            reduced_loss<a id="change"> = </a>reduce_mean(loss, args.nprocs)

            &#47&#47 更新优化模型权重
            optimizer.zero_grad()</code></pre>