<html><h3>Pattern ID :26798
</h3><img src='80150734.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                "message": message,
                "date": date_string,
            }
            <a id="change">with thread_lock</a><a id="change">:
                </a>if key in PROCESS_STATUS.value:
                    temp = PROCESS_STATUS.value
                    tempProcess = temp.pop(key, None)
                    if key in temp["flags"]:</code></pre><h3>After Change</h3><pre><code class='java'>
                "message": message,
                "date": date_string,
            }
            with <a id="change">thread_lock</a>:
                if thread_id in PROCESS_STATUS.value:
                    temp = PROCESS_STATUS.value
                    temp.pop(thread_id, None)
                    if name in temp["flags"]:
                        temp["flags"][name] = True
                    PROCESS_STATUS.value = temp
                    if thread_id in running_threads:
                        <a id="change">del running_threads[thread_id]</a>
                    if failed:
                        completed[&quotdate&quot] = &quotFailed&quot

                completed_list = COMPLETED_PROCESS.value</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/dod-advana/gamechanger-ml/commit/2ffda5dc72b1535bd870c7c485024c68e4a2f3bc#diff-a2dc48f2da564a3f1e022c2b66408f08f7219a8e7c054b10decb41c28900ca38L50' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 80150734</div><div id='project'> Project Name: dod-advana/gamechanger-ml</div><div id='commit'> Commit Name: 2ffda5dc72b1535bd870c7c485024c68e4a2f3bc</div><div id='time'> Time: 2022-03-08</div><div id='author'> Author: Ross_Jared@bah.com</div><div id='file'> File Name: gamechangerml/api/utils/processmanager.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: update_status(7)</div><div id='n_method'> N Method Name: update_status(7)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: gamechangerml/api/utils/processmanager.py</div><div id='n_file'> N File Name: gamechangerml/api/utils/processmanager.py</div><div id='m_start'> M Start Line: 54</div><div id='m_end'> M End Line: 92</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 93</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    logger.info("Forward outputs are finite")

    if REF_NAME:
        <a id="change">with torch</a><a id="change">.no_grad():
            </a>ref_model = transformers.AutoModelForCausalLM.from_pretrained(REF_NAME)
            dummy_mask = torch.ones_like(test_inputs, dtype=torch.bool)
            &#47&#47 note: this creates a dummy mask to make the test compatible with older transformer versions
            &#47&#47 prior to https://github.com/huggingface/transformers/pull/17837</code></pre><h3>After Change</h3><pre><code class='java'>

    test_inputs = tokenizer("A cat sat on a mat", return_tensors="pt")["input_ids"]

    with <a id="change">torch</a>.no_grad():
        parallel_outputs = model.forward(test_inputs).logits
        assert torch.all(torch.isfinite(parallel_outputs))
        logger.info("Forward outputs are finite")

        embs = model.transformer.word_embeddings(test_inputs)
        embs = model.transformer.word_embeddings_layernorm(embs)
        recurrent_outputs = []
        with model.transformer.h.inference_session() as sess:
            for t in range(embs.shape[1]):
                recurrent_outputs.append(sess.step(embs[:, t : t + 1, :]))
        recurrent_outputs = torch.cat(recurrent_outputs, dim=1)
        recurrent_outputs = model.transformer.ln_f(recurrent_outputs)

        dictionary = model.transformer.word_embeddings.weight.t()
        recurrent_outputs = recurrent_outputs.to(dictionary.dtype)
        recurrent_outputs = (recurrent_outputs @ dictionary).float()
        assert torch.allclose(recurrent_outputs, parallel_outputs, rtol=0, atol=atol_inference)
        logger.info("Inference is consistent with forward")

        del model, recurrent_outputs

        if REF_NAME:
            ref_model = transformers.AutoModelForCausalLM.from_pretrained(REF_NAME)
            dummy_mask = torch.ones_like(test_inputs, dtype=torch.bool)
            &#47&#47 note: this creates a dummy mask to make the test compatible with older transformer versions
            &#47&#47 prior to https://github.com/huggingface/transformers/pull/17837
            ref_outputs = ref_model.forward(test_inputs, attention_mask=dummy_mask).logits
            assert torch.allclose(ref_outputs, parallel_outputs, rtol=0, atol=atol_forward)
            logger.warning(f"Distributed forward is consistent with {type(ref_model)}.forward")
            <a id="change">del ref_model, ref_outputs, dummy_mask</a>
        else:
            logger.warning("Did not test exact match with local model: REF_NAME environment variable is not set")
            assert False
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bigscience-workshop/distributed-bloom/commit/f0c73831812c3c5a93264e176ac8f90fd88a3c46#diff-6a113b3db74ee5ffa31d650ce95a873a59c221d1b4690db27ec12e16b911b577L27' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 80150732</div><div id='project'> Project Name: bigscience-workshop/distributed-bloom</div><div id='commit'> Commit Name: f0c73831812c3c5a93264e176ac8f90fd88a3c46</div><div id='time'> Time: 2022-07-18</div><div id='author'> Author: justheuristic@gmail.com</div><div id='file'> File Name: tests/test_full_model.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_full_model_exact_match(2)</div><div id='n_method'> N Method Name: test_full_model_exact_match(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/test_full_model.py</div><div id='n_file'> N File Name: tests/test_full_model.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 64</div><div id='n_start'> N Start Line: 16</div><div id='n_end'> N End Line: 55</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            else simultaneous_tasks

    def execute_tasks(self, tasks):
        <a id="change">with concurrent</a><a id="change">.futures.ThreadPoolExecutor(
            max_workers=self.simultaneous_tasks) as executor:
            &#47&#47 Schedule the first N futures.  We don&quott want to schedule them all
            &#47&#47 at once, to avoid consuming excessive amounts of memory.

            </a>futures = [
                executor.submit(self.compute_func, task) \
                    for task in tasks
            ]</code></pre><h3>After Change</h3><pre><code class='java'>
    def execute_tasks(self, tasks, n_tasks):
        result_list = []
        with tqdm(total=n_tasks) as pbar:
            with <a id="change">concurrent</a>.futures.ThreadPoolExecutor(
                max_workers=self.simultaneous_tasks) as executor:
                &#47&#47 Schedule the first N futures.  We don&quott want to schedule them all
                &#47&#47 at once, to avoid consuming excessive amounts of memory.
                futures = {
                    executor.submit(self.compute_func, task): task
                    for task in itertools.islice(tasks, self.simultaneous_tasks)
                }
                while futures:
                    done, _ = concurrent.futures.wait(
                        futures, return_when=concurrent.futures.FIRST_COMPLETED
                    )
                    new_tasks_to_schedule = 0
                    for fut in done:
                        original_task = futures.pop(fut)
                        result_list.append(fut.result())
                        <a id="change">del original_task, fut</a>
                        new_tasks_to_schedule += 1
                        pbar.update(1)
                    for task in itertools.islice(tasks, new_tasks_to_schedule):
                        fut = executor.submit(self.compute_func, task)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/dsgoficial/pytorch_segmentation_models_trainer/commit/8310105da45a252880fa3cc8f6405e70c05722fc#diff-b124c057b8031099a9ee98d2fefd82adb1053cb9883bc49f1a5601a4b25bda94L32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 80150728</div><div id='project'> Project Name: dsgoficial/pytorch_segmentation_models_trainer</div><div id='commit'> Commit Name: 8310105da45a252880fa3cc8f6405e70c05722fc</div><div id='time'> Time: 2021-05-27</div><div id='author'> Author: philipeborba@gmail.com</div><div id='file'> File Name: pytorch_segmentation_models_trainer/tools/parallel_processing/process_executor.py</div><div id='m_class'> M Class Name: Executor</div><div id='n_method'> N Class Name: Executor</div><div id='m_method'> M Method Name: execute_tasks(3)</div><div id='n_method'> N Method Name: execute_tasks(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: pytorch_segmentation_models_trainer/tools/parallel_processing/process_executor.py</div><div id='n_file'> N File Name: pytorch_segmentation_models_trainer/tools/parallel_processing/process_executor.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 50</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 58</div><BR>