<html><h3>Pattern ID :31429
</h3><img src='92095484.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 flatten patches with channels last like the paper (likely using TF)
            x = x.unfold(2, Ph, Ph).unfold(3, Pw, Pw).permute(0, 2, 3, 4, 5, 1).reshape(B, -1, Ph * Pw * C)
        else:
            x = <a id="change">x.permute(0</a>, 2, 3, <a id="change">1</a><a id="change">)</a>.unfold(1, Ph, Ph).unfold(2, Pw, Pw).reshape(B, -1, C * Ph * Pw)
        x = self.proj(x)
        return x
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 FIXME look at relaxing size constraints
        assert H == self.img_size[0] and W == self.img_size[1], \
            f"Input image size ({H}*{W}) doesn&quott match model ({self.img_size[0]}*{self.img_size[1]})."
        x = <a id="change">self.proj(x).flatten(</a>2<a id="change">)</a>.transpose(1, 2)
        return x

</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 2</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/feng-lab/pytorch-image-models/commit/736f209e7d7ebe9a6ac9acf9967a7aba0a86aa4e#diff-a457ded0c066f18843cce88854130edb587dffef98fef0189c9442093ac110abL160' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 92095484</div><div id='project'> Project Name: feng-lab/pytorch-image-models</div><div id='commit'> Commit Name: 736f209e7d7ebe9a6ac9acf9967a7aba0a86aa4e</div><div id='time'> Time: 2020-10-26</div><div id='author'> Author: rwightman@gmail.com</div><div id='file'> File Name: timm/models/vision_transformer.py</div><div id='m_class'> M Class Name: PatchEmbed</div><div id='n_method'> N Class Name: PatchEmbed</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: timm/models/vision_transformer.py</div><div id='n_file'> N File Name: timm/models/vision_transformer.py</div><div id='m_start'> M Start Line: 160</div><div id='m_end'> M End Line: 168</div><div id='n_start'> N Start Line: 161</div><div id='n_end'> N End Line: 161</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        patches = self.proj(x)  &#47&#47 BCHW

        B, C, H, W = patches.size()
        patches = <a id="change">patches.view(B, C, -1).permute(</a>0, <a id="change">2</a>, <a id="change">1</a><a id="change">)</a>  &#47&#47 (batch_size, num_patches, d_model)
        cls_tokens = self.cls_token.expand(B, -1, -1)  &#47&#47 (batch_size, 1, d_model)
        &#47&#47 concate cls_tokens to patches
        embeddings = torch.cat([cls_tokens, patches], dim=1)  &#47&#47 (batch_size, num_patches + 1, d_model)</code></pre><h3>After Change</h3><pre><code class='java'>
            B, C, (H // self.patch_size[0]), self.patch_size[0], (W // self.patch_size[1]), self.patch_size[1]
        )
        &#47&#47 (B, H&quot, W&quot, C, ph, pw) -&gt; (B, H&quot*W&quot, C*ph*pw)
        patches = <a id="change">x.permute(0, 2, 4, 1, 3, 5).flatten(1, 2).flatten(</a>2, 4<a id="change">)</a>
        patches = self.proj(patches)  &#47&#47 (batch_size, num_patches, d_model)

        cls_tokens = self.cls_token.expand(B, -1, -1)  &#47&#47 (batch_size, 1, d_model)
        &#47&#47 concate cls_tokens to patches</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mindee/doctr/commit/a95baaa8c71b859eae1c3292b3bd4225aa410ee5#diff-04ca7e6665eabb9cbda92aaf29511903a29d37ba7549ec61189157307f2fca1aL37' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 92095486</div><div id='project'> Project Name: mindee/doctr</div><div id='commit'> Commit Name: a95baaa8c71b859eae1c3292b3bd4225aa410ee5</div><div id='time'> Time: 2022-09-15</div><div id='author'> Author: felixdittrich92@gmail.com</div><div id='file'> File Name: doctr/models/modules/vision_transformer/pytorch.py</div><div id='m_class'> M Class Name: PatchEmbedding</div><div id='n_method'> N Class Name: PatchEmbedding</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: doctr/models/modules/vision_transformer/pytorch.py</div><div id='n_file'> N File Name: doctr/models/modules/vision_transformer/pytorch.py</div><div id='m_start'> M Start Line: 42</div><div id='m_end'> M End Line: 45</div><div id='n_start'> N Start Line: 45</div><div id='n_end'> N End Line: 50</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 input should be (seq_len, batch, input_size)

        &#47&#47 the features extracted from the backbone CNN are fed to a one-layer GRU structure.
        output_seq = <a id="change">torch.stack(batched_output_per_clip, dim=0).permute(1</a>,<a id="change">0</a><a id="change">)</a>
        &#47&#47 gru_output, h_n = self.rnn(output_seq.unsqueeze(1))
        &#47&#47 gru_output = gru_output.squeeze(1)
        &#47&#47 for i in range(gru_output.size(0)):
        &#47&#47     hr = self.fc_resnet(gru_output[i, :])</code></pre><h3>After Change</h3><pre><code class='java'>
        for i in range(gru_output.size(0)):
            hr = self.gru_fc_out(gru_output[i, :, :])
        &#47&#47     &#47&#47 hr = hr * 25.0
            hr_per_clip.append(<a id="change">hr.flatten()</a>)

        output_seq = torch.stack(hr_per_clip, dim=0).permute(1,0)
        &#47&#47 return output_seq, gru_output.squeeze(0), fc_out</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/anweshcr7/rhythmnet/commit/0f9fc9b96933c04f723fbfa5b80cdf1a398828c3#diff-3fc5bf831ef8bd1cc5d50189ec691215fb3d3ae0cbb974e736200edc7f8c65cdL32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 92095480</div><div id='project'> Project Name: anweshcr7/rhythmnet</div><div id='commit'> Commit Name: 0f9fc9b96933c04f723fbfa5b80cdf1a398828c3</div><div id='time'> Time: 2021-03-14</div><div id='author'> Author: anwesh.marwade@beyondsports.nl</div><div id='file'> File Name: src/models/rhythmNet.py</div><div id='m_class'> M Class Name: RhythmNet</div><div id='n_method'> N Class Name: RhythmNet</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/models/rhythmNet.py</div><div id='n_file'> N File Name: src/models/rhythmNet.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 56</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 64</div><BR>