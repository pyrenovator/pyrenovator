<html><h3>Pattern ID :22083
</h3><img src='70045069.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

            &#47&#47 add noise to latents using the timesteps
            if device.type == "mps":
                noise<a id="change"> = </a><a id="change">torch.randn(</a>shape<a id="change">, generator=generator, device="cpu", dtype=dtype)</a>.to(device)
            else:
                noise = torch.randn(shape, generator=generator, device=device, dtype=dtype)
            latents = self.scheduler.add_noise(init_latents, noise, timestep)</code></pre><h3>After Change</h3><pre><code class='java'>
        if image is None:
            batch_size = batch_size * num_images_per_prompt
            shape = (batch_size, num_channels_latents, height // self.vae_scale_factor, width // self.vae_scale_factor)
            <a id="change">if </a><a id="change">isinstance(generator, list) and len(generator) != batch_size</a>:
                raise ValueError(
                    f"You have passed a list of generators of length {len(generator)}, but requested an effective batch"
                    f" size of {batch_size}. Make sure the batch size matches the length of the generators."</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/9965cb50eac12e397473f01535aab43aae76b4ab#diff-137485cb3293be40e8fbae3f413853388988a06e9c6c73352686946677ad2eb3L628' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70045069</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: 9965cb50eac12e397473f01535aab43aae76b4ab</div><div id='time'> Time: 2023-04-22</div><div id='author'> Author: SKYTNT@outlook.com</div><div id='file'> File Name: examples/community/lpw_stable_diffusion.py</div><div id='m_class'> M Class Name: StableDiffusionLongPromptWeightingPipeline</div><div id='n_method'> N Class Name: StableDiffusionLongPromptWeightingPipeline</div><div id='m_method'> M Method Name: prepare_latents(12)</div><div id='n_method'> N Method Name: prepare_latents(10)</div><div id='m_parent_class'> M Parent Class: DiffusionPipeline,TextualInversionLoaderMixin,FromCkptMixin,LoraLoaderMixin</div><div id='n_parent_class'> N Parent Class: StableDiffusionPipeline</div><div id='m_file'> M File Name: examples/community/lpw_stable_diffusion.py</div><div id='n_file'> N File Name: examples/community/lpw_stable_diffusion.py</div><div id='m_start'> M Start Line: 628</div><div id='m_end'> M End Line: 662</div><div id='n_start'> N Start Line: 822</div><div id='n_end'> N End Line: 862</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            if latents is None:
                if device.type == "mps":
                    &#47&#47 randn does not work reproducibly on mps
                    latents<a id="change"> = </a><a id="change">torch.randn(</a>shape<a id="change">, generator=generator, device="cpu", dtype=dtype)</a>.to(device)
                else:
                    latents = torch.randn(shape, generator=generator, device=device, dtype=dtype)
            else:</code></pre><h3>After Change</h3><pre><code class='java'>
        if image is None:
            batch_size = batch_size * num_images_per_prompt
            shape = (batch_size, num_channels_latents, height // self.vae_scale_factor, width // self.vae_scale_factor)
            <a id="change">if </a><a id="change">isinstance(generator, list) and len(generator) != batch_size</a>:
                raise ValueError(
                    f"You have passed a list of generators of length {len(generator)}, but requested an effective batch"
                    f" size of {batch_size}. Make sure the batch size matches the length of the generators."</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/huggingface/diffusers/commit/2ced899cc7cff5c37f2186819c90538ce301908c#diff-137485cb3293be40e8fbae3f413853388988a06e9c6c73352686946677ad2eb3L626' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70045070</div><div id='project'> Project Name: huggingface/diffusers</div><div id='commit'> Commit Name: 2ced899cc7cff5c37f2186819c90538ce301908c</div><div id='time'> Time: 2023-04-27</div><div id='author'> Author: patrick.v.platen@gmail.com</div><div id='file'> File Name: examples/community/lpw_stable_diffusion.py</div><div id='m_class'> M Class Name: StableDiffusionLongPromptWeightingPipeline</div><div id='n_method'> N Class Name: StableDiffusionLongPromptWeightingPipeline</div><div id='m_method'> M Method Name: prepare_latents(12)</div><div id='n_method'> N Method Name: prepare_latents(10)</div><div id='m_parent_class'> M Parent Class: DiffusionPipeline,TextualInversionLoaderMixin,FromCkptMixin,LoraLoaderMixin</div><div id='n_parent_class'> N Parent Class: StableDiffusionPipeline</div><div id='m_file'> M File Name: examples/community/lpw_stable_diffusion.py</div><div id='n_file'> N File Name: examples/community/lpw_stable_diffusion.py</div><div id='m_start'> M Start Line: 628</div><div id='m_end'> M End Line: 662</div><div id='n_start'> N Start Line: 822</div><div id='n_end'> N End Line: 862</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    npt = pt.eval().half().cuda()
    cpt = build_composite_mha_from_nn_mha(npt)

    x<a id="change"> = </a><a id="change">torch.randn(</a>batch_size, L, D<a id="change">)</a>
    x = x.half().cuda()

    pt_output, _ = pt(x, x, x, mask)
    cp_output, _ = cpt(x, x, x, mask)</code></pre><h3>After Change</h3><pre><code class='java'>
            cpt_output, _ = cpt(x, x, x, mask)

            &#47&#47 First order sanity check. Not a replacement for rigorous tests.
            <a id="change">if </a><a id="change">pt_output.is_nested and cpt_output.is_nested</a>:
                for a, b in zip(pt_output.unbind(), cpt_output.unbind()):
                    assert torch.allclose(a, b, atol=1e-3, rtol=1e-3)
            else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/d06d569e90f3ca3e721b679be285385e5bd3eea9#diff-a448dc0556e0de2ca5fa51c2ecf64422e62bcdce6232979511e141485be0a330L78' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 70045071</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: d06d569e90f3ca3e721b679be285385e5bd3eea9</div><div id='time'> Time: 2022-10-18</div><div id='author'> Author: drisspg@fb.com</div><div id='file'> File Name: benchmarks/transformer/sdp.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: run_timing(7)</div><div id='n_method'> N Method Name: run_timing(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: benchmarks/transformer/sdp.py</div><div id='n_file'> N File Name: benchmarks/transformer/sdp.py</div><div id='m_start'> M Start Line: 78</div><div id='m_end'> M End Line: 104</div><div id='n_start'> N Start Line: 93</div><div id='n_end'> N End Line: 120</div><BR>