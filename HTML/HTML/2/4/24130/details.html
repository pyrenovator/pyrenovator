<html><h3>Pattern ID :24130
</h3><img src='74840308.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                with open(path, "rb") as audio_file:
                    wave, sr = sf.read(audio_file)
            except RuntimeError:
                <a id="change">print(</a><a id="change">"Could not read {}".format(</a>path<a id="change">))</a>
                continue
            if min_len &lt;= len(wave) / sr &lt;= max_len:
                norm_wave = ap.audio_to_wave_tensor(audio=wave, normalize=True, mulaw=False)
                norm_wave_length = torch.LongTensor([len(norm_wave)])</code></pre><h3>After Change</h3><pre><code class='java'>
                                                           cached_speech_len.numpy(),
                                                           cached_duration.cpu().numpy(),
                                                           cached_energy.cpu().numpy(),
                                                           <a id="change">cached_pitch.cpu().numpy()</a>,
                                                           cached_speaker_embedding.detach().cpu().numpy()])
        self.datapoints += process_internal_dataset_chunk
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/435d8aac1d0d8fd6534e6c64454c1a665ddf8f77#diff-528f1d1f9b65f826c6eec25f3934452fe1a81965d76a0070a71db9ef9ef36aa0L82' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74840308</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 435d8aac1d0d8fd6534e6c64454c1a665ddf8f77</div><div id='time'> Time: 2021-09-05</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='m_class'> M Class Name: FastSpeechDataset</div><div id='n_method'> N Class Name: FastSpeechDataset</div><div id='m_method'> M Method Name: cache_builder_process(11)</div><div id='n_method'> N Method Name: cache_builder_process(11)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='m_start'> M Start Line: 82</div><div id='m_end'> M End Line: 158</div><div id='n_start'> N Start Line: 107</div><div id='n_end'> N End Line: 178</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                with open(path, "rb") as audio_file:
                    wave, sr = sf.read(audio_file)
            except RuntimeError:
                <a id="change">print(</a><a id="change">"Could not read {}".format(</a>path<a id="change">))</a>
                continue
            if min_len &lt;= len(wave) / sr &lt;= max_len:
                cached_text = tf.string_to_tensor(transcript).squeeze(0).cpu()
                cached_text_len = torch.LongTensor([len(cached_text)])</code></pre><h3>After Change</h3><pre><code class='java'>
                    mel_tensor = wav2mel(wav_tensor, sample_rate)
                    emb_tensor = dvector.embed_utterance(mel_tensor)
                    cached_speaker_embedding = emb_tensor.detach().cpu()
                    process_internal_dataset_chunk.append([<a id="change">cached_text.numpy()</a>,
                                                           cached_text_len.numpy(),
                                                           cached_speech.numpy(),
                                                           cached_speech_len.numpy(),</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/435d8aac1d0d8fd6534e6c64454c1a665ddf8f77#diff-a49dac0d7d67877dcf8511175f18c0155a9aba98acf2e0ee7bfd3a2ed69fb144L56' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74840305</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 435d8aac1d0d8fd6534e6c64454c1a665ddf8f77</div><div id='time'> Time: 2021-09-05</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/TacotronDataset.py</div><div id='m_class'> M Class Name: TacotronDataset</div><div id='n_method'> N Class Name: TacotronDataset</div><div id='m_method'> M Method Name: cache_builder_process(7)</div><div id='n_method'> N Method Name: cache_builder_process(7)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/TacotronDataset.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/Tacotron2/TacotronDataset.py</div><div id='m_start'> M Start Line: 64</div><div id='m_end'> M End Line: 84</div><div id='n_start'> N Start Line: 83</div><div id='n_end'> N End Line: 105</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                                         vis=os.path.join(cache_dir, "durations_visualization",
                                                          str(int(focus_rate * 10000)) + "_" + path.split("/")[-1].rstrip(".wav") + ".png"))[0].cpu()
                    if np.count_nonzero(cached_duration.numpy() == 0) &gt; 5:
                        <a id="change">print(</a><a id="change">"exclude file {} because it has too many zero duration frames".format(</a>path<a id="change">))</a>
                        continue
                else:
                    wav_tensor, sample_rate = torchaudio.load(path)
                    mel_tensor = wav2mel(wav_tensor, sample_rate)</code></pre><h3>After Change</h3><pre><code class='java'>
                                                             use_att_constraint=True)[2]
                    cached_duration = dc(attention_map, vis=os.path.join(cache_dir, "durations_visualization",
                                                                         path.split("/")[-1].rstrip(".wav") + ".png"))[0].cpu()
                    if np.count_nonzero(<a id="change">cached_duration.numpy()</a> == 0) &gt; 4:
                        continue
                cached_energy = energy_calc(input=norm_wave.unsqueeze(0),
                                            input_lengths=norm_wave_length,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/efd63af066258a09362aa9896e7a58c38edef5f2#diff-528f1d1f9b65f826c6eec25f3934452fe1a81965d76a0070a71db9ef9ef36aa0L97' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74840297</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: efd63af066258a09362aa9896e7a58c38edef5f2</div><div id='time'> Time: 2021-09-05</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='m_class'> M Class Name: FastSpeechDataset</div><div id='n_method'> N Class Name: FastSpeechDataset</div><div id='m_method'> M Method Name: cache_builder_process(11)</div><div id='n_method'> N Method Name: cache_builder_process(11)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='m_start'> M Start Line: 124</div><div id='m_end'> M End Line: 167</div><div id='n_start'> N Start Line: 157</div><div id='n_end'> N End Line: 159</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        fastraster_time_gpu = time.time() - tic

    print("Runtimes:")
    <a id="change">print(
        </a><a id="change">"Fast Marching: {:.6f} s \nGeodisTk raster: {:.6f} s \nFastGeodis CPU raster: {:.6f} s".format(
            </a>fastmarch_time, geodistkraster_time, fastraster_time_cpu<a id="change">
        )
    )</a>

    if device:
        print("FastGeodis GPU raster: {:.6f} s".format(fastraster_time_gpu))
</code></pre><h3>After Change</h3><pre><code class='java'>

    tic = time.time()
    toivanenraster_output = np.squeeze(
        <a id="change">FastGeodis.generalised_geodesic2d_toivanen(input_image_pt, seed_image_pt, v, lamb, iterations).cpu().numpy()</a>
    )
    toivanenraster_time = time.time() - tic

    tic = time.time()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/masadcv/fastgeodis/commit/a1906e989649c1f0b8fdbed147c1d576ac5c41f3#diff-c6567a84a23f27eb1443122b56b63757dea429e19a3d3c58c88e6c34596a2e13L26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74840283</div><div id='project'> Project Name: masadcv/fastgeodis</div><div id='commit'> Commit Name: a1906e989649c1f0b8fdbed147c1d576ac5c41f3</div><div id='time'> Time: 2022-07-22</div><div id='author'> Author: muhammad.asad@kcl.ac.uk</div><div id='file'> File Name: samples/demo2d.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: evaluate_geodesic_distance2d(2)</div><div id='n_method'> N Method Name: evaluate_geodesic_distance2d(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: samples/demo2d.py</div><div id='n_file'> N File Name: samples/demo2d.py</div><div id='m_start'> M Start Line: 29</div><div id='m_end'> M End Line: 158</div><div id='n_start'> N Start Line: 18</div><div id='n_end'> N End Line: 100</div><BR>