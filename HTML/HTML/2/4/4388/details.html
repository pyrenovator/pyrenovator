<html><h3>Pattern ID :4388
</h3><img src='16169692.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            tuple -- (position, energy, variance)
        

        <a id="change">self.wf.eval()</a>
        num_threads = 1
        hvd.broadcast_parameters(self.wf.state_dict(), root_rank=0)
        torch.set_num_threads(num_threads)
</code></pre><h3>After Change</h3><pre><code class='java'>
             nw=self.sampler.nwalkers, ns=self.sampler.nstep))

        &#47&#47 check if we have to compute and store the grads
        grad_mode = <a id="change">torch.no_grad()</a>
        if self.wf.kinetic == &quotauto&quot:
            grad_mode = torch.enable_grad()

        &#47&#47 distribute the calculation
        num_threads = 1
        hvd.broadcast_parameters(self.wf.state_dict(), root_rank=0)
        torch.set_num_threads(num_threads)

        <a id="change">with grad_mode</a><a id="change">:

            &#47&#47 sample the wave function
            </a>pos = self.sampler(self.wf.pdf)
            if self.wf.cuda and pos.device.type == &quotcpu&quot:
                pos = pos.to(self.device)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/nlesc-jcer/qmctorch/commit/9c3e63cd2b3fe345a850beb13cc978a28a4945b0#diff-206aab14cee0e8ea5262ba9aaa6a708e355e80f8966baa86084dff7c9740452eL220' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 16169692</div><div id='project'> Project Name: nlesc-jcer/qmctorch</div><div id='commit'> Commit Name: 9c3e63cd2b3fe345a850beb13cc978a28a4945b0</div><div id='time'> Time: 2020-07-16</div><div id='author'> Author: nicolas.gm.renaud@gmail.com</div><div id='file'> File Name: qmctorch/solver/solver_orbital_horovod.py</div><div id='m_class'> M Class Name: SolverOrbitalHorovod</div><div id='n_method'> N Class Name: SolverOrbitalHorovod</div><div id='m_method'> M Method Name: single_point(3)</div><div id='n_method'> N Method Name: single_point(3)</div><div id='m_parent_class'> M Parent Class: SolverOrbital</div><div id='n_parent_class'> N Parent Class: SolverOrbital</div><div id='m_file'> M File Name: qmctorch/solver/solver_orbital_horovod.py</div><div id='n_file'> N File Name: qmctorch/solver/solver_orbital_horovod.py</div><div id='m_start'> M Start Line: 223</div><div id='m_end'> M End Line: 279</div><div id='n_start'> N Start Line: 220</div><div id='n_end'> N End Line: 276</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.replay_buffer.store(
            self._states, self._actions, reward, states)
        self._states = states
        actions = <a id="change">self.policy.eval(</a>states.to(self.device)<a id="change">)</a>
        actions = actions + self._noise_policy.sample([actions.shape[0]])
        self._actions = Action(actions).to("cpu")
        return self._actions
</code></pre><h3>After Change</h3><pre><code class='java'>
        self._replay_buffer.store(
            self._states, self._actions, reward, states)
        self._states = states
        <a id="change">with torch.no_grad()</a><a id="change">:
            </a>actions = self._policy_model(states)
            actions = actions + self._noise_policy.sample([actions.shape[0]])
        self._actions = Action(actions)
        return self._actions</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/syuntoku14/pytorch-rl-il/commit/76defe6cb7c6e9bab65823acd587275d83d1ea9c#diff-9f0056bb754f3c4cad05f0f077874206d410e8b870fc1df576c0c8559c0737dcL134' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 16169690</div><div id='project'> Project Name: syuntoku14/pytorch-rl-il</div><div id='commit'> Commit Name: 76defe6cb7c6e9bab65823acd587275d83d1ea9c</div><div id='time'> Time: 2020-04-08</div><div id='author'> Author: syuntoku14@gmail.com</div><div id='file'> File Name: rlil/agents/td3.py</div><div id='m_class'> M Class Name: TD3LazyAgent</div><div id='n_method'> N Class Name: TD3LazyAgent</div><div id='m_method'> M Method Name: act(3)</div><div id='n_method'> N Method Name: act(3)</div><div id='m_parent_class'> M Parent Class: LazyAgent</div><div id='n_parent_class'> N Parent Class: LazyAgent</div><div id='m_file'> M File Name: rlil/agents/td3.py</div><div id='n_file'> N File Name: rlil/agents/td3.py</div><div id='m_start'> M Start Line: 138</div><div id='m_end'> M End Line: 140</div><div id='n_start'> N Start Line: 149</div><div id='n_end'> N End Line: 152</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
  beliefs, prior_states, prior_means, prior_std_devs = [torch.empty(0)] * T, [torch.empty(0)] * T, [torch.empty(0)] * T, [torch.empty(0)] * T
  beliefs[0], prior_states[0] = prev_belief, prev_state

  <a id="change">transition_model.eval()</a>&#47&#47&#47&#47&#47&#47&#47&#47 added to make sure that the gradient does not backprop through when we train actor_model
  &#47&#47 Loop over time sequence
  for t in range(T - 1):
    _state = prior_states[t]</code></pre><h3>After Change</h3><pre><code class='java'>
          torch.Size([49, 50, 200]) torch.Size([49, 50, 30]) torch.Size([49, 50, 30]) torch.Size([49, 50, 30])
  &quot&quot&quot
  flatten = lambda x: x.view([-1]+list(x.size()[2:]))
  <a id="change">with torch.no_grad()</a><a id="change">: &#47&#47 Delete the gradient from transition_model
    </a>prev_belief = flatten(prev_belief)
    prev_state = flatten(prev_state)
  
  &#47&#47 Create lists for hidden states (cannot use single tensor as buffer because autograd won&quott work with inplace writes)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yusukeurakami/dreamer-pytorch/commit/e331a0af2cd9f5c3ed3cb218560d9556de47e5cc#diff-09d0cbaf891d623ac245ccf84485a687b554217349ca55557c60b33234b969aeL43' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 16169691</div><div id='project'> Project Name: yusukeurakami/dreamer-pytorch</div><div id='commit'> Commit Name: e331a0af2cd9f5c3ed3cb218560d9556de47e5cc</div><div id='time'> Time: 2020-06-22</div><div id='author'> Author: you@example.com</div><div id='file'> File Name: utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: imagine_ahead(5)</div><div id='n_method'> N Method Name: imagine_ahead(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: utils.py</div><div id='n_file'> N File Name: utils.py</div><div id='m_start'> M Start Line: 51</div><div id='m_end'> M End Line: 75</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 58</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
class MockLazyAgent(LazyAgent):
    def act(self, states, reward=None):
        self._states = states
        actions = <a id="change">self.models["policy"].eval(</a>states.to(self.device)<a id="change">)</a>
        actions += self._noise.sample([actions.shape[0]])
        self._actions = Action(actions).to("cpu")
        return self._actions
</code></pre><h3>After Change</h3><pre><code class='java'>

        self._state = state

        <a id="change">with torch.no_grad()</a><a id="change">:
            </a>action = self.policy_model(
                state.to(self.policy_model.device))

        self._action = Action(action).to("cpu")</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/syuntoku14/pytorch-rl-il/commit/17b19de93a6ea81a39eba48bf58330970ecdc6a5#diff-ec7966e733eed23a03906386364f67593b8a9b0192519f2525c25af8d35a3cafL15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 16169689</div><div id='project'> Project Name: syuntoku14/pytorch-rl-il</div><div id='commit'> Commit Name: 17b19de93a6ea81a39eba48bf58330970ecdc6a5</div><div id='time'> Time: 2020-04-04</div><div id='author'> Author: syuntoku14@gmail.com</div><div id='file'> File Name: rlil/samplers/tests/sampler_test.py</div><div id='m_class'> M Class Name: MockLazyAgent</div><div id='n_method'> N Class Name: MockLazyAgent</div><div id='m_method'> M Method Name: act(3)</div><div id='n_method'> N Method Name: act(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: LazyAgent</div><div id='m_file'> M File Name: rlil/samplers/tests/sampler_test.py</div><div id='n_file'> N File Name: rlil/samplers/tests/sampler_test.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 19</div><div id='n_start'> N Start Line: 34</div><div id='n_end'> N End Line: 46</div><BR>