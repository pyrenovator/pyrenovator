<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        for i in range(len(hidden_dims)-1):
            curr_shape, next_shape = hidden_dims[i], hidden_dims[i+1]
            curr_network = get_network([curr_shape, next_shape])
            <a id="change">if </a>use_batch_norm:
                self.networks.extend([curr_network, act_cls()])
            else:
                bn_layer = torch.nn.BatchNorm1d(hidden_dims[i<a id="change">+</a>1])
                <a id="change">self.networks.extend(</a>[curr_network, act_cls(), bn_layer]<a id="change">)</a>
        final_network = get_network([hidden_dims[-1],out_dim])
        self.networks.extend([final_network, out_act_cls()])
        self.networks = nn.ModuleList(self.networks)
    </code></pre><h3>After Change</h3><pre><code class='java'>

class QNetwork(nn.Module):
    def __init__(self,input_dim, out_dim, hidden_dims, act_fn="relu", out_act_fn="identity", **kwargs):
        <a id="change">print(</a>"redundant parameters for Q network: {}".format(kwargs)<a id="change">)</a>
        super(QNetwork, self).__init__()
        if type(hidden_dims) == int:
            hidden_dims = [hidden_dims]
        hidden_dims = [input_dim] + hidden_dims </code></pre>