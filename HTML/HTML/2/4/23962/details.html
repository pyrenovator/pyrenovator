<html><h3>Pattern ID :23962
</h3><img src='74528149.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        output_trt = slice_layer.get_output(0)

    &#47&#47 Step 3.5 - Add gather layer if necessary
    gather_index = [e for e, s in enumerate(slices) if <a id="change">isinstance(s, torch.Tensor) and (s.dtype==torch.int32 or s.dtype==torch.long)</a>]
    for gidx in gather_index:
        index_tensor = slices[gidx]
        index_tensor_trt = trt_(ctx.network, index_tensor)</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 Step 3.5 - Add gather layer if necessary
    for gidx, gather_value in enumerate(new_gather):
        <a id="change">if </a>gather_value is None:
            continue
        if isinstance(gather_value, torch.Tensor):
            index_tensor = gather_value
            if not hasattr(index_tensor, "_trt"):
                index_tensor = index_tensor.int()
        else:
            index_tensor<a id="change"> = </a><a id="change">input.new_tensor(gather_value).int()</a>
        index_tensor_trt = trt_(ctx.network, index_tensor)
        output_trt = ctx.network.add_gather(output_trt, index_tensor_trt, gidx).get_output(0)
    
    &#47&#47 Step 4 - Add shuffle layer to insert dimensions for &quotNone&quot slices and remove dimensions for &quotint&quot slices</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/grimoire/torch2trt_dynamic/commit/aa3a7dcd4cac8b43d220a57e5d9a3d52064f9049#diff-c56858b4c6fd1c8b8aabee085a4bde38dfaff3cf74202fc20b073bd2f6d4c424L29' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74528149</div><div id='project'> Project Name: grimoire/torch2trt_dynamic</div><div id='commit'> Commit Name: aa3a7dcd4cac8b43d220a57e5d9a3d52064f9049</div><div id='time'> Time: 2020-07-24</div><div id='author'> Author: streetyao@live.com</div><div id='file'> File Name: torch2trt/converters/getitem.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: convert_tensor_getitem(1)</div><div id='n_method'> N Method Name: convert_tensor_getitem(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: torch2trt/converters/getitem.py</div><div id='n_file'> N File Name: torch2trt/converters/getitem.py</div><div id='m_start'> M Start Line: 29</div><div id='m_end'> M End Line: 149</div><div id='n_start'> N Start Line: 29</div><div id='n_end'> N End Line: 166</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        except AssertionError:
            return
        &#47&#47 Only need to evaluate integration within working image
        <a id="change">if </a>"window" in self.integrate_mode:
            working_window = self.integrate_window & working_image.window
        elif "full" in self.integrate_mode:
            working_window = working_image.window</code></pre><h3>After Change</h3><pre><code class='java'>
            return
        &#47&#47 Determine the on-sky window in which to integrate
        try:
            <a id="change">if </a>window.overlap_frac(working_image.window) &lt;= 0.:
                return
        except AssertionError:
            return
        
        &#47&#47 Only need to evaluate integration within working image
        working_window = window & working_image.window
            
        &#47&#47 Determine the upsampled pixelscale 
        integrate_pixelscale = working_image.pixelscale / self.integrate_factor

        &#47&#47 Build an image to hold the integration data
        integrate_image = Model_Image(pixelscale = integrate_pixelscale, window = working_window, dtype = self.dtype, device = self.device)
        &#47&#47 Evaluate the model at the fine sampling points
        X, Y = integrate_image.get_coordinate_meshgrid_torch(self["center"].value[0], self["center"].value[1])
        integrate_image.data = self.evaluate_model(integrate_image)

        &#47&#47 If needed, recursively evaluates smaller windows
        recursive_shape = window.shape/integrate_pixelscale &#47&#47 get the number of pixels across the integrate window
        recursive_shape = <a id="change">(recursive_shape/self.integrate_recursion_factor).int()</a> &#47&#47 divide window by recursion factor, ensure integer result
        recursive_shape<a id="change"> = </a>(recursive_shape + 1 - (recursive_shape % 2)) * integrate_pixelscale &#47&#47 ensure odd number of pixels in shape
        self.integrate_model(
            integrate_image,
            Window(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/connorstoneastro/autoprof/commit/5f175ee9348203672f89393da85d19ce9f131375#diff-f48e7e4f4617c56a91cecf87400e1b8c67ec5491c53dceae61328526ff99ebfeL188' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74528151</div><div id='project'> Project Name: connorstoneastro/autoprof</div><div id='commit'> Commit Name: 5f175ee9348203672f89393da85d19ce9f131375</div><div id='time'> Time: 2022-12-14</div><div id='author'> Author: connorstone628@gmail.com</div><div id='file'> File Name: autoprof/models/model_object.py</div><div id='m_class'> M Class Name: BaseModel</div><div id='n_method'> N Class Name: BaseModel</div><div id='m_method'> M Method Name: integrate_model(4)</div><div id='n_method'> N Method Name: integrate_model(2)</div><div id='m_parent_class'> M Parent Class: AutoProf_Model</div><div id='n_parent_class'> N Parent Class: AutoProf_Model</div><div id='m_file'> M File Name: autoprof/models/model_object.py</div><div id='n_file'> N File Name: autoprof/models/model_object.py</div><div id='m_start'> M Start Line: 188</div><div id='m_end'> M End Line: 226</div><div id='n_start'> N Start Line: 193</div><div id='n_end'> N End Line: 239</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    seq = seq[batch_indices, keep_indices]

    <a id="change">if </a>exists(mask):
        mask = mask[batch_indices, keep_indices]

    return seq, mask</code></pre><h3>After Change</h3><pre><code class='java'>

    seq = seq[batch_indices, keep_indices]

    <a id="change">if </a>exists(mask):
        seq_counts = mask.sum(dim = -1)
        seq_keep_counts<a id="change"> = </a><a id="change">torch.ceil(seq_counts * keep_prob).int()</a>
        keep_mask = torch.arange(num_keep, device = device) &lt; rearrange(seq_keep_counts, &quotb -&gt; b 1&quot)

        mask = mask[batch_indices, keep_indices] & keep_mask
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/perceiver-pytorch/commit/c8c5f5721520460369a66b8a0e9c5147df4a883e#diff-d109c4942e7a2f6d51cd8e55cbab114efc5eb0b0ce37d8e682449385df84ec13L33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 74528159</div><div id='project'> Project Name: lucidrains/perceiver-pytorch</div><div id='commit'> Commit Name: c8c5f5721520460369a66b8a0e9c5147df4a883e</div><div id='time'> Time: 2022-12-04</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: perceiver_pytorch/perceiver_io.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: dropout_seq(3)</div><div id='n_method'> N Method Name: dropout_seq(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: perceiver_pytorch/perceiver_io.py</div><div id='n_file'> N File Name: perceiver_pytorch/perceiver_io.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 51</div><div id='n_start'> N Start Line: 40</div><div id='n_end'> N End Line: 56</div><BR>