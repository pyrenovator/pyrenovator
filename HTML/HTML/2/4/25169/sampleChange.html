<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    loss: `torch.autograd.Variable`
        :math:`-\mathrm{logpreds} \cdot \mathrm{targets}`
    
    <a id="change">assert </a>logpreds.size() == targets.size()
    result = -logpreds * targets
    &#47&#47 Sum across dims if axis given or more than 1 dim
    if dims is not None:</code></pre><h3>After Change</h3><pre><code class='java'>
        return log_categorical_crossentropy_1_hot(log_preds, targets)
    n_classes = log_preds.size()[1]
    n_elements = 0
    losses<a id="change"> = []</a>
    for i_class in range(n_classes):
        mask = targets == i_class
        mask = mask.type_as(log_preds)
        n_elements -= th.sum(mask)
        losses.append(th.sum(mask * log_preds[:,i_class]))
    return th.sum(<a id="change">th.stack(</a>losses<a id="change">)</a>) / n_elements


def l2_loss(model):</code></pre>