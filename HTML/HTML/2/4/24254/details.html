<html><h3>Pattern ID :24254
</h3><img src='75311580.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        level_high = torch.ones([1]).to(torch.int8) * level_high
        level_low = level_low.to(y_zero_point.device)
        level_high = level_high.to(y_zero_point.device)
        y_zero_point<a id="change"> = </a>min(<a id="change">max(</a>level_low, (y_zero_point.to(torch.int8))<a id="change">)</a>, level_high)
    else:
        level_low = torch.ones([1]).to(torch.uint8) * level_low
        level_high = torch.ones([1]).to(torch.uint8) * level_high</code></pre><h3>After Change</h3><pre><code class='java'>

    type_ = torch.int8 if level_low &lt; 0 else torch.uint8
    level_low *= torch.ones_like(y_zero_point).to(type_)
    level_high<a id="change"> *= </a><a id="change">torch.ones_like(y_zero_point).to(</a>type_<a id="change">)</a>
    level_low = level_low.to(y_zero_point.device)
    level_high = level_high.to(y_zero_point.device)
    y_zero_point = torch.min(torch.max(level_low, y_zero_point.to(type_)), level_high)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/openvinotoolkit/nncf/commit/23610df53be6cb3c36a8f5ec6aaf7ab8f4fc757e#diff-79eba4eaba4a6497a26f88dd22fb2c4ca247d8745f0763dbe56801ee3188ce1aL153' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75311580</div><div id='project'> Project Name: openvinotoolkit/nncf</div><div id='commit'> Commit Name: 23610df53be6cb3c36a8f5ec6aaf7ab8f4fc757e</div><div id='time'> Time: 2020-11-06</div><div id='author'> Author: aleksei.kashapov@intel.com</div><div id='file'> File Name: nncf/quantization/quantize_functions.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: get_scale_zp_from_input_low_input_high(4)</div><div id='n_method'> N Method Name: get_scale_zp_from_input_low_input_high(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: nncf/quantization/quantize_functions.py</div><div id='n_file'> N File Name: nncf/quantization/quantize_functions.py</div><div id='m_start'> M Start Line: 154</div><div id='m_end'> M End Line: 169</div><div id='n_start'> N Start Line: 153</div><div id='n_end'> N End Line: 164</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 ps = torch.exp(out)
            ps = out
            prediction_percentages = (ps.cpu().numpy()[0]).tolist()
            pred<a id="change"> = </a>prediction_percentages.index(<a id="change">max(</a>prediction_percentages<a id="change">)</a>)
            pred_labels.append(pred)
    show_roc(true_labels, pred_labels, auc=auc, figure_size=figure_size)
</code></pre><h3>After Change</h3><pre><code class='java'>
    target_data_loader = torch.utils.data.DataLoader(target_data_set,batch_size=10,shuffle=False)

    for i, (imgs, labels) in enumerate(target_data_loader):
        imgs = <a id="change">imgs.to(</a>device<a id="change">)</a>
        labels = labels.to(device)
        true_labels.append(labels.tolist())

        with torch.no_grad():
            model.eval()
            out<a id="change"> = </a>model(imgs)
            &#47&#47 ps = torch.exp(out)
            ps = out
            print(ps.shape)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/radtorch/radtorch/commit/74b5ef917af3aebdf033166bf8b81cbc9ceb9b6e#diff-ea0c5d78e98f3b87371717beabaf20a4c1a834cd943d71bad1e08f7fc9e04250L176' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75311567</div><div id='project'> Project Name: radtorch/radtorch</div><div id='commit'> Commit Name: 74b5ef917af3aebdf033166bf8b81cbc9ceb9b6e</div><div id='time'> Time: 2020-03-01</div><div id='author'> Author: elbanan@users.noreply.github.com</div><div id='file'> File Name: radtorch/visutils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: show_nn_roc(5)</div><div id='n_method'> N Method Name: show_nn_roc(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: radtorch/visutils.py</div><div id='n_file'> N File Name: radtorch/visutils.py</div><div id='m_start'> M Start Line: 199</div><div id='m_end'> M End Line: 216</div><div id='n_start'> N Start Line: 201</div><div id='n_end'> N End Line: 215</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        _, _, height, width = inputs.shape
        targets = target.clone()
        if self.normalize_targets:
            targets[:, 2:]<a id="change"> /= </a><a id="change">max(</a>height, width<a id="change">)</a>
        preds = self.post_prediction_callback(preds, device=device)

        metrics, batch_images_counter = calc_batch_prediction_accuracy(preds, targets, height, width,
                                                                       self.iou_thres)</code></pre><h3>After Change</h3><pre><code class='java'>
        :param crowd_targets: Crowd targets for all images of shape (total_num_targets, 6)
                                 format:  (index, x, y, w, h, label) where x,y,w,h are in range [0,1]
        
        self.iou_thresholds<a id="change"> = </a><a id="change">self.iou_thresholds.to(</a>device<a id="change">)</a>
        _, _, height, width = inputs.shape

        targets = target.clone()
        crowd_targets = torch.zeros(size=(0, 6), device=device) if crowd_targets is None else crowd_targets.clone()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/deci-ai/super-gradients/commit/90fb0a6d0e7aa883b1f583c9c83b4c2d3525e9d2#diff-af6a25abebd6c5c98274636ae8cb47c3b632aa27a0fdbf6ef7b6bef8f8405851L136' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 75311576</div><div id='project'> Project Name: deci-ai/super-gradients</div><div id='commit'> Commit Name: 90fb0a6d0e7aa883b1f583c9c83b4c2d3525e9d2</div><div id='time'> Time: 2022-07-28</div><div id='author'> Author: 80472096+shaydeci@users.noreply.github.com</div><div id='file'> File Name: src/super_gradients/training/metrics/detection_metrics.py</div><div id='m_class'> M Class Name: DetectionMetrics</div><div id='n_method'> N Class Name: DetectionMetrics</div><div id='m_method'> M Method Name: update(6)</div><div id='n_method'> N Method Name: update(6)</div><div id='m_parent_class'> M Parent Class: Metric</div><div id='n_parent_class'> N Parent Class: Metric</div><div id='m_file'> M File Name: src/super_gradients/training/metrics/detection_metrics.py</div><div id='n_file'> N File Name: src/super_gradients/training/metrics/detection_metrics.py</div><div id='m_start'> M Start Line: 136</div><div id='m_end'> M End Line: 150</div><div id='n_start'> N Start Line: 65</div><div id='n_end'> N End Line: 93</div><BR>