<html><h3>Pattern ID :9890
</h3><img src='35368783.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        whole_bond_idxs = native_idxs

    &#47&#47 2. ATTRS: encode bond -&gt; attrs
    bond_norms = dist_mat[ <a id="change">whole_bond_idxs[0]</a> , whole_bond_idxs[1] ]
    bond_vecs  = x[ whole_bond_idxs[0] ] - x[ whole_bond_idxs[1] ]
    bond_vecs /= (bond_norms + eps).unsqueeze(-1)
    bond_norms_enc = encode_dist(bond_norms, scales=needed_info["bond_scales"]).squeeze()</code></pre><h3>After Change</h3><pre><code class='java'>
        dist_mat = torch.cdist(x, x, p=2)

    &#47&#47 normal buckets
    bond_buckets<a id="change"> = </a><a id="change">torch.zeros(x.shape[:-1], x.shape[-2], device=device).type(</a>precise<a id="change">)</a>
    if buckets:
        &#47&#47 count from latest degree of adjacency given
        bond_buckets = torch.bucketize(dist_mat, cutoffs)
        bond_buckets[native_idxs[0], native_idxs[1]] = cutoffs.shape[0]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/geometric-vector-perceptron/commit/5a40792004e203e994ed7c0cf6dbf25d7312c8c5#diff-3c4d3e9b2d9cca8bf55129be87f3334c429ad0ab75a5329f0d84e34cb61d4021L390' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 35368783</div><div id='project'> Project Name: lucidrains/geometric-vector-perceptron</div><div id='commit'> Commit Name: 5a40792004e203e994ed7c0cf6dbf25d7312c8c5</div><div id='time'> Time: 2021-03-28</div><div id='author'> Author: ericalcaide1@gmail.com</div><div id='file'> File Name: examples/data_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: encode_whole_bonds(6)</div><div id='n_method'> N Method Name: encode_whole_bonds(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: examples/data_utils.py</div><div id='n_file'> N File Name: examples/data_utils.py</div><div id='m_start'> M Start Line: 408</div><div id='m_end'> M End Line: 452</div><div id='n_start'> N Start Line: 390</div><div id='n_end'> N End Line: 456</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            length * targets.shape[1], max_len=targets.shape[1],
        )
        if len(targets.shape) == 3:
            mask = mask.unsqueeze(2).repeat(1, 1, <a id="change">targets.shape[2]</a>)

    &#47&#47 Compute, then reduce loss
    loss = loss_fn(predictions, targets) * mask</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Handle any dimensionality of input
        while len(length_mask.shape) &lt; len(mask.shape):
            length_mask = length_mask.unsqueeze(-1)
        length_mask = <a id="change">length_mask.type(</a>mask.dtype<a id="change">)</a>
        mask<a id="change"> *= </a>length_mask

    &#47&#47 Compute, then reduce loss
    loss = loss_fn(predictions, targets) * mask</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/f9198e1170fc6123693643401693dc6da9308f3f#diff-dacadc87130a104a9b34b5d369c53e34f52662470ff3e0d91783d3ede95fee82L588' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 35368787</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: f9198e1170fc6123693643401693dc6da9308f3f</div><div id='time'> Time: 2020-11-30</div><div id='author'> Author: plantinga.peter@protonmail.com</div><div id='file'> File Name: speechbrain/nnet/losses.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: compute_masked_loss(6)</div><div id='n_method'> N Method Name: compute_masked_loss(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: speechbrain/nnet/losses.py</div><div id='n_file'> N File Name: speechbrain/nnet/losses.py</div><div id='m_start'> M Start Line: 621</div><div id='m_end'> M End Line: 628</div><div id='n_start'> N Start Line: 619</div><div id='n_end'> N End Line: 629</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.cheb_polynomials = cheb_polynomials
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.DEVICE = <a id="change">cheb_polynomials[0]</a>.device
        self.Theta = nn.ParameterList([nn.Parameter(torch.FloatTensor(in_channels, out_channels).to(self.DEVICE)) for _ in range(K)])

    def forward(self, x, spatial_attention):</code></pre><h3>After Change</h3><pre><code class='java'>
        cheb_polynomials = [np.identity(L_tilde.shape[0]), L_tilde.copy()]
        for i in range(2, K):
            cheb_polynomials.append(2 * L_tilde * cheb_polynomials[i - 1] - cheb_polynomials[i - 2])
        self.cheb_polynomials<a id="change"> = </a>[<a id="change">torch.from_numpy(i).type(</a>torch.FloatTensor<a id="change">)</a>.to(DEVICE) for i in cheb_polynomials]
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.DEVICE = DEVICE</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/benedekrozemberczki/pytorch_geometric_temporal/commit/2775ce5253580a592becb764f1a76d82c8e76e6e#diff-22584f32d844ec418fe6465eae4a50e8e2e4a6fdedbbb0dd117c022b7bba99d3L50' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 35368786</div><div id='project'> Project Name: benedekrozemberczki/pytorch_geometric_temporal</div><div id='commit'> Commit Name: 2775ce5253580a592becb764f1a76d82c8e76e6e</div><div id='time'> Time: 2021-03-17</div><div id='author'> Author: He_YX@outlook.com</div><div id='file'> File Name: torch_geometric_temporal/nn/convolutional/astgcn.py</div><div id='m_class'> M Class Name: cheb_conv_withSAt</div><div id='n_method'> N Class Name: cheb_conv_withSAt</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: torch_geometric_temporal/nn/convolutional/astgcn.py</div><div id='n_file'> N File Name: torch_geometric_temporal/nn/convolutional/astgcn.py</div><div id='m_start'> M Start Line: 58</div><div id='m_end'> M End Line: 61</div><div id='n_start'> N Start Line: 52</div><div id='n_end'> N End Line: 75</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        z_q = self.embedding(encoding_indices).view(z.shape)
        perplexity = None
        &#47&#47Using F.one_hot causes num_class error
        encodings = torch.zeros(<a id="change">encoding_indices.shape[0]</a>, self.num_tokens, device=z.device)
        encodings.scatter_(1, encoding_indices.unsqueeze(1), 1)

        &#47&#47 Use EMA to update the embedding vectors</code></pre><h3>After Change</h3><pre><code class='java'>
        z_q = self.embedding(encoding_indices).view(z.shape)
        perplexity = None
        
        encodings = <a id="change">F.one_hot(encoding_indices, self.num_tokens).type(</a>z.dtype<a id="change">)</a>

        &#47&#47 Use EMA to update the embedding vectors
        if self.training:
            &#47&#47EMA cluster size
            encodings_sum<a id="change"> = </a>torch.sum(encodings)
            self.cluster_size.data.mul_(self.decay).add_(encodings_sum, alpha=1 - self.decay)
            
            &#47&#47EMA embedding weight</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tgisaturday/dalle-lightning/commit/ea9b0b9a5ec09e67761b1588106f670a3ad7bd77#diff-5cc0cb1395e7634e216d321d933d7868cc1ee34fa25763750d65126b9ad1ea15L61' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 35368785</div><div id='project'> Project Name: tgisaturday/dalle-lightning</div><div id='commit'> Commit Name: ea9b0b9a5ec09e67761b1588106f670a3ad7bd77</div><div id='time'> Time: 2021-07-28</div><div id='author'> Author: jamesk1228@gmail.com</div><div id='file'> File Name: pl_dalle/modules/vqvae/quantize.py</div><div id='m_class'> M Class Name: EMAVectorQuantizer</div><div id='n_method'> N Class Name: EMAVectorQuantizer</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: pl_dalle/modules/vqvae/quantize.py</div><div id='n_file'> N File Name: pl_dalle/modules/vqvae/quantize.py</div><div id='m_start'> M Start Line: 72</div><div id='m_end'> M End Line: 83</div><div id='n_start'> N Start Line: 64</div><div id='n_end'> N End Line: 83</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        cur_schema = torch.tensor(int_to_binary_label_list(int(schema), num_classes)[::-1], dtype=torch.int8)
        cand_idx = weight == float(schema)
        if use_vfl:
            cand_idx = <a id="change">cand_idx.nonzero(as_tuple=True)[0]</a>
            cand_idx = torch.tensor(np.intersect1d(neg_idx.cpu().numpy(), cand_idx.cpu().numpy()))
        else:
            cand_idx *= neg_mask
            cand_idx = torch.nonzero(cand_idx, as_tuple=True)</code></pre><h3>After Change</h3><pre><code class='java'>
    if valid_label_mask is not None:
        neg_mask = targets.sum(axis=1) == 0 if use_vfl else targets == num_classes
        neg_idx = neg_mask.nonzero(as_tuple=True)[0]
        cross_mask[neg_idx]<a id="change"> = </a><a id="change">valid_label_mask[neg_idx].type(</a>torch.int8<a id="change">)</a>

    if use_vfl:
        loss = varifocal_loss(inputs, targets,
                              weight=weight,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/openvinotoolkit/model_preparation_algorithm/commit/422e1c4fb8c3e8efc7f584902a0cdbbb895387cd#diff-102419dd4e63e58d66e469df486b84b2bd5b676350136bce74ee0d644b5565eaL17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 35368784</div><div id='project'> Project Name: openvinotoolkit/model_preparation_algorithm</div><div id='commit'> Commit Name: 422e1c4fb8c3e8efc7f584902a0cdbbb895387cd</div><div id='time'> Time: 2022-06-15</div><div id='author'> Author: harim.kang@intel.com</div><div id='file'> File Name: mpa/modules/models/losses/cross_focal_loss.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: cross_sigmoid_focal_loss(10)</div><div id='n_method'> N Method Name: cross_sigmoid_focal_loss(10)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: mpa/modules/models/losses/cross_focal_loss.py</div><div id='n_file'> N File Name: mpa/modules/models/losses/cross_focal_loss.py</div><div id='m_start'> M Start Line: 38</div><div id='m_end'> M End Line: 64</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 39</div><BR>