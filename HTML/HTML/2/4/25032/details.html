<html><h3>Pattern ID :25032
</h3><img src='76857076.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
		self.num_class 	= num_class
		self.p 		= params

		self.tokenizer 	= <a id="change">BertTokenizer.from_pretrained(</a>params.bert_model<a id="change">)</a>
		self.cls_tok 	= self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(&quot[CLS]&quot))
		self.sep_tok 	= self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(&quot[SEP]&quot))

	def __len__(self):</code></pre><h3>After Change</h3><pre><code class='java'>

		self.cls_tok 	= self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(&quot[CLS]&quot))
		self.sep_tok 	= self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(&quot[SEP]&quot))
		self.men_start  = self.tokenizer.convert_tokens_to_ids(<a id="change">self.tokenizer.tokenize(</a>&quot[MENTION]&quot<a id="change">)</a>)
		self.men_end 	= self.tokenizer.convert_tokens_to_ids(<a id="change">self.tokenizer.tokenize(</a>&quot[/MENTION]&quot<a id="change">)</a>)

	def __len__(self):
		return len(self.dataset)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/svjan5/medtype/commit/160813be93a76d6c1b00fdb9c8a86726c73e1803#diff-5caabdac897a484bcce9a9e2e7daf54ef2260fe156320820c03b70afa0b9a526L4' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76857076</div><div id='project'> Project Name: svjan5/medtype</div><div id='commit'> Commit Name: 160813be93a76d6c1b00fdb9c8a86726c73e1803</div><div id='time'> Time: 2021-03-19</div><div id='author'> Author: shikharvashishth@gmail.com</div><div id='file'> File Name: medtype-as-service/server/medtype_serving/server/medtype/dataloader.py</div><div id='m_class'> M Class Name: BertDataset</div><div id='n_method'> N Class Name: BertDataset</div><div id='m_method'> M Method Name: __init__(5)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: medtype-as-service/server/medtype_serving/server/medtype/dataloader.py</div><div id='n_file'> N File Name: medtype-as-service/server/medtype_serving/server/medtype/dataloader.py</div><div id='m_start'> M Start Line: 9</div><div id='m_end'> M End Line: 9</div><div id='n_start'> N Start Line: 4</div><div id='n_end'> N End Line: 13</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
		self.num_class 	= num_class
		self.p 		= params

		self.tokenizer 	= <a id="change">BertTokenizer.from_pretrained(</a>params.bert_model<a id="change">)</a>
		self.cls_tok 	= self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(&quot[CLS]&quot))
		self.sep_tok 	= self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(&quot[SEP]&quot))

	def __len__(self):</code></pre><h3>After Change</h3><pre><code class='java'>
		self.dataset	= dataset
		self.num_class 	= num_class
		self.p 		= params
		<a id="change">self.tokenizer</a> 	= tokenizer

		self.cls_tok 	= self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(&quot[CLS]&quot))
		self.sep_tok 	= self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(&quot[SEP]&quot))
		self.men_start  = self.tokenizer.convert_tokens_to_ids(<a id="change">self.tokenizer.tokenize(</a>&quot[MENTION]&quot<a id="change">)</a>)
		self.men_end 	= self.tokenizer.convert_tokens_to_ids(<a id="change">self.tokenizer.tokenize(</a>&quot[/MENTION]&quot<a id="change">)</a>)

	def __len__(self):
		return len(self.dataset)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/svjan5/medtype/commit/982c7e977da2c4dea0263c22ce8f8185e016839f#diff-b20a232bfa237962d6a647587b0de4552058fdeb7df910d4076e729afa31e8dfL7' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76857077</div><div id='project'> Project Name: svjan5/medtype</div><div id='commit'> Commit Name: 982c7e977da2c4dea0263c22ce8f8185e016839f</div><div id='time'> Time: 2021-03-19</div><div id='author'> Author: shikharvashishth@gmail.com</div><div id='file'> File Name: medtype-trainer/dataloader.py</div><div id='m_class'> M Class Name: MedTypeDataset</div><div id='n_method'> N Class Name: MedTypeDataset</div><div id='m_method'> M Method Name: __init__(5)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: medtype-trainer/dataloader.py</div><div id='n_file'> N File Name: medtype-trainer/dataloader.py</div><div id='m_start'> M Start Line: 12</div><div id='m_end'> M End Line: 12</div><div id='n_start'> N Start Line: 7</div><div id='n_end'> N End Line: 16</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
		self.num_class 	= num_class
		self.p 		= params

		self.tokenizer 	= <a id="change">BertTokenizer.from_pretrained(</a>params.bert_model<a id="change">)</a>
		self.cls_tok 	= self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(&quot[CLS]&quot))
		self.sep_tok 	= self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(&quot[SEP]&quot))

	def __len__(self):</code></pre><h3>After Change</h3><pre><code class='java'>
		self.dataset	= dataset
		self.num_class 	= num_class
		self.p 		= params
		<a id="change">self.tokenizer</a> 	= tokenizer

		self.cls_tok 	= self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(&quot[CLS]&quot))
		self.sep_tok 	= self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(&quot[SEP]&quot))
		self.men_start  = self.tokenizer.convert_tokens_to_ids(<a id="change">self.tokenizer.tokenize(</a>&quot[MENTION]&quot<a id="change">)</a>)
		self.men_end 	= self.tokenizer.convert_tokens_to_ids(<a id="change">self.tokenizer.tokenize(</a>&quot[/MENTION]&quot<a id="change">)</a>)

	def __len__(self):
		return len(self.dataset)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/svjan5/medtype/commit/160813be93a76d6c1b00fdb9c8a86726c73e1803#diff-5caabdac897a484bcce9a9e2e7daf54ef2260fe156320820c03b70afa0b9a526L4' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76857079</div><div id='project'> Project Name: svjan5/medtype</div><div id='commit'> Commit Name: 160813be93a76d6c1b00fdb9c8a86726c73e1803</div><div id='time'> Time: 2021-03-19</div><div id='author'> Author: shikharvashishth@gmail.com</div><div id='file'> File Name: medtype-as-service/server/medtype_serving/server/medtype/dataloader.py</div><div id='m_class'> M Class Name: BertDataset</div><div id='n_method'> N Class Name: BertDataset</div><div id='m_method'> M Method Name: __init__(5)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: medtype-as-service/server/medtype_serving/server/medtype/dataloader.py</div><div id='n_file'> N File Name: medtype-as-service/server/medtype_serving/server/medtype/dataloader.py</div><div id='m_start'> M Start Line: 9</div><div id='m_end'> M End Line: 9</div><div id='n_start'> N Start Line: 4</div><div id='n_end'> N End Line: 13</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                fp.write(word + &quot\n&quot)

    def build_vocab(self, vectors, vocab_fields, vocab_sets):
        self.config = <a id="change">BertConfig.from_pretrained(</a>self._pretrained_name<a id="change">, cache_dir=self._cache)</a>
        self._tokenizer = MaskedBertTokenizer.from_pretrained(self._pretrained_name, config=self.config, cache_dir=self._cache)

        &#47&#47 ensure that init, eos, unk and pad are set
        &#47&#47 this method has no effect if the tokens are already set according to the tokenizer class</code></pre><h3>After Change</h3><pre><code class='java'>
                fp.write(word + &quot\n&quot)

    def build_vocab(self, vocab_fields, vocab_sets):
        <a id="change">self._tokenizer</a> = MaskedBertTokenizer.from_pretrained(self._pretrained_name, config=self.config, cache_dir=self._cache)
        &#47&#47 HACK we cannot save the tokenizer without this
        del self._tokenizer.init_kwargs[&quotconfig&quot]

        &#47&#47 ensure that init, eos, unk and pad are set
        &#47&#47 this method has no effect if the tokens are already set according to the tokenizer class
        self._tokenizer.add_special_tokens({
            &quotbos_token&quot: &quot[CLS]&quot,
            &quoteos_token&quot: &quot[SEP]&quot,
            &quotunk_token&quot: &quot[UNK]&quot,
            &quotpad_token&quot: &quot[PAD]&quot
        })

        &#47&#47 do a pass over all the data in the dataset
        &#47&#47 in this pass, we
        &#47&#47 1) tokenize everything, to ensure we account for all added tokens
        &#47&#47 2) we construct a counter of wordpieces in the answers, for the decoder vocabulary
        decoder_words = collections.Counter()
        for dataset in vocab_sets:
            for example in dataset:
                <a id="change">self._tokenizer.tokenize(</a>example.context, example.context_word_mask<a id="change">)</a>
                <a id="change">self._tokenizer.tokenize(</a>example.question, example.question_word_mask<a id="change">)</a>

                tokens = self._tokenizer.tokenize(example.answer, example.answer_word_mask)
                decoder_words.update(tokens)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/1f7edc7b24193960b989f2dad95241b0cc1b18fa#diff-37cc25423ec560c2c4333d2995f10402b85d1f635d53c0dd4f71b3808c3e0f1cL73' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76857080</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: 1f7edc7b24193960b989f2dad95241b0cc1b18fa</div><div id='time'> Time: 2020-01-16</div><div id='author'> Author: gcampagn@cs.stanford.edu</div><div id='file'> File Name: decanlp/data/numericalizer/bert.py</div><div id='m_class'> M Class Name: BertNumericalizer</div><div id='n_method'> N Class Name: BertNumericalizer</div><div id='m_method'> M Method Name: build_vocab(3)</div><div id='n_method'> N Method Name: build_vocab(4)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: decanlp/data/numericalizer/bert.py</div><div id='n_file'> N File Name: decanlp/data/numericalizer/bert.py</div><div id='m_start'> M Start Line: 73</div><div id='m_end'> M End Line: 93</div><div id='n_start'> N Start Line: 79</div><div id='n_end'> N End Line: 105</div><BR>