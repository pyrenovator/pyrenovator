<html><h3>Pattern ID :32055
</h3><img src='93970941.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        super().__init__(num_classes=num_classes, **kwargs)
        self.norm_par = None
        if norm_par:
            self.norm_par = {key: <a id="change">torch.as_tensor(value).pin_memory()</a>
                             for key, value in norm_par.items()}

    &#47&#47 This is defined by Pytorch documents
    &#47&#47 See https://pytorch.org/docs/stable/torchvision/models.html for more details</code></pre><h3>After Change</h3><pre><code class='java'>
        if norm_par:
            self.norm_par = {key: torch.as_tensor(value)
                             for key, value in norm_par.items()}
            <a id="change">if </a>env[&quotnum_gpus&quot]:
                self.norm_par<a id="change"> = </a>{key: <a id="change">value.pin_memory()</a>
                                 for key, value in norm_par.items()}

    &#47&#47 This is defined by Pytorch documents
    &#47&#47 See https://pytorch.org/docs/stable/torchvision/models.html for more details</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ain-soph/trojanzoo/commit/6db9e1093a1c57355371acded3524e02f64baa3a#diff-2e5a199c407507ee95051b9d3c697f33888e4d96925f51e508939244c2f34dbeL41' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 93970941</div><div id='project'> Project Name: ain-soph/trojanzoo</div><div id='commit'> Commit Name: 6db9e1093a1c57355371acded3524e02f64baa3a</div><div id='time'> Time: 2020-08-10</div><div id='author'> Author: ain-soph@live.com</div><div id='file'> File Name: trojanzoo/model/imagemodel.py</div><div id='m_class'> M Class Name: _ImageModel</div><div id='n_method'> N Class Name: _ImageModel</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: _Model</div><div id='n_parent_class'> N Parent Class: _Model</div><div id='m_file'> M File Name: trojanzoo/model/imagemodel.py</div><div id='n_file'> N File Name: trojanzoo/model/imagemodel.py</div><div id='m_start'> M Start Line: 41</div><div id='m_end'> M End Line: 42</div><div id='n_start'> N Start Line: 41</div><div id='n_end'> N End Line: 52</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Divides cleanly the inputs into batches and trims the remaining elements
        n_step = input_ids.size(0) // bsz
        input_ids = input_ids[: n_step * bsz]
        self.input_ids = <a id="change">input_ids.view(bsz, -1).contiguous().pin_memory()</a>

        &#47&#47 Creates warmup batches if memory is being used
        if mem_len and warmup:
            self.warmup_batches = (mem_len + bptt - 1) // bptt</code></pre><h3>After Change</h3><pre><code class='java'>
        n_step = input_ids.size(0) // bsz
        input_ids = input_ids[: n_step * bsz]
        self.input_ids = input_ids.view(bsz, -1).contiguous()
        <a id="change">if </a>device != "cpu":
            self.input_ids<a id="change"> = </a><a id="change">self.input_ids.pin_memory()</a>

        &#47&#47 Creates warmup batches if memory is being used
        if mem_len and warmup:
            self.warmup_batches = (mem_len + bptt - 1) // bptt</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/archai/commit/b0e38830e7b6701ceceeb8271210fc19523d50ea#diff-5229439aa2914deb53f1806607407c5e67e21e37b80ca9cf1d77070d76827759L19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 93970942</div><div id='project'> Project Name: microsoft/archai</div><div id='commit'> Commit Name: b0e38830e7b6701ceceeb8271210fc19523d50ea</div><div id='time'> Time: 2023-01-13</div><div id='author'> Author: gth.rosa@uol.com.br</div><div id='file'> File Name: archai/nlp/datasets/nvidia/lm_iterators.py</div><div id='m_class'> M Class Name: LMOrderedIterator</div><div id='n_method'> N Class Name: LMOrderedIterator</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: archai/nlp/datasets/nvidia/lm_iterators.py</div><div id='n_file'> N File Name: archai/nlp/datasets/nvidia/lm_iterators.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 53</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 58</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Divides cleanly the inputs into batches and trims the remaining elements
        n_step = input_ids.size(0) // bsz
        input_ids = input_ids[: n_step * bsz]
        self.input_ids = <a id="change">input_ids.view(bsz, -1).contiguous().pin_memory()</a>

        &#47&#47 Creates warmup batches if memory is being used
        if mem_len and warmup:
            self.warmup_batches = (mem_len + bptt - 1) // bptt</code></pre><h3>After Change</h3><pre><code class='java'>
        n_step = input_ids.size(0) // bsz
        input_ids = input_ids[: n_step * bsz]
        self.input_ids = input_ids.view(bsz, -1).contiguous()
        <a id="change">if </a>device != "cpu":
            self.input_ids<a id="change"> = </a><a id="change">self.input_ids.pin_memory()</a>

        &#47&#47 Creates warmup batches if memory is being used
        if mem_len and warmup:
            self.warmup_batches = (mem_len + bptt - 1) // bptt</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/archai/commit/2dfc0e198f117c72b0c45c1e4ac07756133a4e0a#diff-5229439aa2914deb53f1806607407c5e67e21e37b80ca9cf1d77070d76827759L19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 93970949</div><div id='project'> Project Name: microsoft/archai</div><div id='commit'> Commit Name: 2dfc0e198f117c72b0c45c1e4ac07756133a4e0a</div><div id='time'> Time: 2023-01-06</div><div id='author'> Author: gth.rosa@uol.com.br</div><div id='file'> File Name: archai/nlp/datasets/nvidia/lm_iterators.py</div><div id='m_class'> M Class Name: LMOrderedIterator</div><div id='n_method'> N Class Name: LMOrderedIterator</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: archai/nlp/datasets/nvidia/lm_iterators.py</div><div id='n_file'> N File Name: archai/nlp/datasets/nvidia/lm_iterators.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 53</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 58</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    dtype=gradient_dtype,
                    device=self.device)
            elif self.cpu_offload_use_pin_memory:
                self.fp32_partitioned_groups_flat[i].grad = <a id="change">torch.zeros(
                    num_elements,
                    dtype=gradient_dtype,
                    device=self.device).pin_memory()</a>
            else:
                self.fp32_partitioned_groups_flat[i].grad = gradient_buffer.narrow(
                    0,</code></pre><h3>After Change</h3><pre><code class='java'>
                subgroup_gradient_buffer = torch.zeros(num_elements,
                                                       dtype=gradient_dtype,
                                                       device=self.device)
                <a id="change">if </a>self.offload_optimizer_pin_memory:
                    subgroup_gradient_buffer<a id="change"> = </a><a id="change">subgroup_gradient_buffer.pin_memory()</a>
                self.fp32_partitioned_groups_flat[i].grad = subgroup_gradient_buffer
            else:
                self.fp32_partitioned_groups_flat[i].grad = gradient_buffer.narrow(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/0d4a54a04d658db40a120bc10c6f1f1a4478f6f1#diff-1ad5daa1b31aa5573616024068d646f0c38e88d4d3a71d3d0e4bc352ea232178L1173' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 93970948</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: 0d4a54a04d658db40a120bc10c6f1f1a4478f6f1</div><div id='time'> Time: 2021-04-18</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/runtime/zero/stage3.py</div><div id='m_class'> M Class Name: FP16_DeepSpeedZeroOptimizer_Stage3</div><div id='n_method'> N Class Name: FP16_DeepSpeedZeroOptimizer_Stage3</div><div id='m_method'> M Method Name: initialize_optimizer_states(1)</div><div id='n_method'> N Method Name: initialize_optimizer_states(1)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: deepspeed/runtime/zero/stage3.py</div><div id='n_file'> N File Name: deepspeed/runtime/zero/stage3.py</div><div id='m_start'> M Start Line: 1176</div><div id='m_end'> M End Line: 1214</div><div id='n_start'> N Start Line: 1625</div><div id='n_end'> N End Line: 1690</div><BR>