<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        x_lazy = x.detach().clone().to(device=device)
        bn = bn.to(device=device)
        for i in range(10):
            z_lazy = <a id="change">bn(</a>x_lazy<a id="change">)</a>
            torch._lazy.mark_step()

        torch.testing.assert_close(z.cpu(), z_lazy.cpu())
        assert metrics.counter_value("IrNodeReused_torch::lazy::TSNativeBatchNormForward") &gt;= 7</code></pre><h3>After Change</h3><pre><code class='java'>
        for i in range(10):
            &#47&#47 BatchNorm2d does extra checks on dimensions which SymInts don&quott support yet
            &#47&#47 so we call `torch.ops.aten.native_batch_norm` to bypass the checks.
            z<a id="change">, _, _</a> = torch.ops.aten.native_batch_norm(x, weight, bias, None, None, True, 0.1, 1e-5)

        device = "lazy"
        x_lazy = x.detach().clone().to(device=device)
        weight_lazy = weight.detach().clone().to(device=device)
        bias_lazy = bias.detach().clone().to(device=device)
        for i in range(10):
            z_lazy<a id="change">, _, _</a> = torch.ops.aten.native_batch_norm(x_lazy, weight_lazy, bias_lazy, None, None, True, 0.1, 1e-5)
            torch._lazy.mark_step()

        torch.testing.assert_close(z.cpu(), z_lazy.cpu())</code></pre>