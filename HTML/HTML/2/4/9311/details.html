<html><h3>Pattern ID :9311
</h3><img src='33437534.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        if hasattr(params, "augmentation"):
            wavs = params.augmentation(wavs, wav_lens, init_params)
        feats = params.compute_features(wavs, init_params)
        feats<a id="change"> = </a><a id="change">params.normalize(</a>feats, wav_lens<a id="change">)</a>
        out = params.model(feats, init_params)
        out = params.output(out, init_params)
        pout = params.log_softmax(out)
        return pout, wav_lens</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 feats = params.normalize(feats, wav_lens)
        out = params.model(feats, init_params)
        out = params.output(out, init_params)
        out = out - <a id="change">out.mean(1).unsqueeze(1</a><a id="change">)</a>
        pout = params.log_softmax(out)
        return pout, wav_lens

    def compute_objectives(self, predictions, targets, stage="train"):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/e9ed4e3ab7fb882beb259c7cf412107ad1b1497e#diff-25148d5a446dc1c3c57b3caa4054b83d1e1616b39a92400a7b383331f560dbb5L38' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33437534</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: e9ed4e3ab7fb882beb259c7cf412107ad1b1497e</div><div id='time'> Time: 2020-06-16</div><div id='author'> Author: elenaras@yahoo.co.uk</div><div id='file'> File Name: recipes/TIMIT/ASR_alignment/experiment.py</div><div id='m_class'> M Class Name: ASR</div><div id='n_method'> N Class Name: ASR</div><div id='m_method'> M Method Name: compute_forward(4)</div><div id='n_method'> N Method Name: compute_forward(4)</div><div id='m_parent_class'> M Parent Class: sb.core.Brain</div><div id='n_parent_class'> N Parent Class: sb.core.Brain</div><div id='m_file'> M File Name: recipes/TIMIT/ASR_alignment/experiment.py</div><div id='n_file'> N File Name: recipes/TIMIT/ASR_alignment/experiment.py</div><div id='m_start'> M Start Line: 38</div><div id='m_end'> M End Line: 39</div><div id='n_start'> N Start Line: 41</div><div id='n_end'> N End Line: 42</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            index=sample[:, 1]
        ).unsqueeze(1)

        norm = <a id="change">F.normalize(</a>norm<a id="change">, p=2, dim=-1)</a>
        head = head - torch.sum(head * norm, dim=-1, keepdim=True) * norm
        tail<a id="change"> = </a>tail - torch.sum(tail * norm, dim=-1, keepdim=True) * norm

        score = (head + relation) - tail
</code></pre><h3>After Change</h3><pre><code class='java'>
        t = t.squeeze(1)

        if len(sample.shape) == 3:
            sample = <a id="change">sample.unsqueeze(1</a><a id="change">)</a>

        norm = self.relation_norm(sample[:, 1])

        h = self._transfer(e=h, norm=norm)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/raphaelsty/mkb/commit/b011b91b4468b0d642af90229fa132774ea1e0d3#diff-b9b50058a107fc657ae969749f1656e6a0f30a08144b19b1325165baf2676617L62' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33437535</div><div id='project'> Project Name: raphaelsty/mkb</div><div id='commit'> Commit Name: b011b91b4468b0d642af90229fa132774ea1e0d3</div><div id='time'> Time: 2020-09-21</div><div id='author'> Author: raphael.sourty@gmail.com</div><div id='file'> File Name: kdmkb/models/transh.py</div><div id='m_class'> M Class Name: TransH</div><div id='n_method'> N Class Name: TransH</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: base.BaseModel</div><div id='n_parent_class'> N Parent Class: base.BaseModel</div><div id='m_file'> M File Name: kdmkb/models/transh.py</div><div id='n_file'> N File Name: kdmkb/models/transh.py</div><div id='m_start'> M Start Line: 62</div><div id='m_end'> M End Line: 79</div><div id='n_start'> N Start Line: 64</div><div id='n_end'> N End Line: 89</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

            unit = torch.cat([pe_, values_, variable_], dim=1)
            Add Normalization across samples here, to make all 48-dimensions are in similar scale
            unit<a id="change"> = </a><a id="change">F.normalize(</a>unit<a id="change">, dim=1)</a>

            &#47&#47 use 2-layer transformer to get f&quot
            &#47&#47 trans_unit = self.transformer_encoder_f_prime(unit.unsqueeze(1))
            &#47&#47 f_prime = torch.mean(trans_unit, dim=0) &#47&#47 [435, 34] --&gt; [1,34]</code></pre><h3>After Change</h3><pre><code class='java'>
            pe_ = self.pos_encoder(time_points.unsqueeze(1)).squeeze(1)
            variable = nonzero_index[:,1] &#47&#47 the dimensions of variables. The m value in SEFT paper.

            unit = torch.cat([pe_, <a id="change">values.unsqueeze(1</a><a id="change">)</a>, variable.unsqueeze(1)], dim=1)

            &#47&#47 &#47&#47 positional encoding  AUROC ~0.86 Why positional encoding works?
            &#47&#47 &#47&#47 values_ = self.pos_encoder_value(values.unsqueeze(1)).squeeze(1)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mims-harvard/raindrop/commit/0b0a19b4ba53c4a1303ef507483e994acffac9b8#diff-b7c638e744cc24cbf0e26b15a5dd347480335d7c3d444eb55d211866066c5266L293' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33437524</div><div id='project'> Project Name: mims-harvard/raindrop</div><div id='commit'> Commit Name: 0b0a19b4ba53c4a1303ef507483e994acffac9b8</div><div id='time'> Time: 2021-09-09</div><div id='author'> Author: xiang.alan.zhang@gmail.com</div><div id='file'> File Name: code/baselines/models.py</div><div id='m_class'> M Class Name: SEFT</div><div id='n_method'> N Class Name: SEFT</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: code/baselines/models.py</div><div id='n_file'> N File Name: code/baselines/models.py</div><div id='m_start'> M Start Line: 304</div><div id='m_end'> M End Line: 327</div><div id='n_start'> N Start Line: 311</div><div id='n_end'> N End Line: 318</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        scale = min(scale1, scale2)
        out_h, out_w = in_h * scale, in_w * scale
        img = sktsf.resize(img, (in_c, out_h, out_w), mode=&quotreflect&quot, anti_aliasing=False)  &#47&#47 np.float64
        img<a id="change"> = </a><a id="change">self.normalize(</a>torch.from_numpy(img)<a id="change">)</a>.numpy()
        &#47&#47 img = F.interpolate(img.unsqueeze(0), size=(round(in_h * scale), round(in_w * scale)), mode="nearest").squeeze(0)
        &#47&#47 img = tvtsf.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)
        return img_path, img, img.shape[1:]</code></pre><h3>After Change</h3><pre><code class='java'>
        scale1 = 600 / min(in_h, in_w)
        scale2 = 1000 / max(in_h, in_w)
        scale = min(scale1, scale2)
        img = F.interpolate(<a id="change">img.unsqueeze(0</a><a id="change">)</a>, size=(round(in_h * scale), round(in_w * scale)), mode="nearest").squeeze(0)
        img = tvtsf.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)
        return img_path, img, img.shape[1:]
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pangkun248/faster-rcnn-pytorch/commit/9f846e1554bc021a8736389744969d0dd7f97321#diff-11bb3b632c84e01e0bf1b576e72c513fd062811e900ebcb5f22df0eac7d3b0d9L105' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33437523</div><div id='project'> Project Name: pangkun248/faster-rcnn-pytorch</div><div id='commit'> Commit Name: 9f846e1554bc021a8736389744969d0dd7f97321</div><div id='time'> Time: 2021-08-30</div><div id='author'> Author: 39581901+pangkun248@users.noreply.github.com</div><div id='file'> File Name: dataset.py</div><div id='m_class'> M Class Name: ImageFolder</div><div id='n_method'> N Class Name: ImageFolder</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: dataset.py</div><div id='n_file'> N File Name: dataset.py</div><div id='m_start'> M Start Line: 110</div><div id='m_end'> M End Line: 119</div><div id='n_start'> N Start Line: 91</div><div id='n_end'> N End Line: 99</div><BR>