<html><h3>Pattern ID :15359
</h3><img src='52076058.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def forward(self, input, hidden):
        embedded = self.embedding(input).view(1, 1, -1)
        output = embedded
        output<a id="change">, hidden</a> = self.gru(output, hidden)
        return output<a id="change">, hidden</a>

    def initHidden(self):
        return torch.zeros(1, 1, self.hidden_size, device=DEVICE)
</code></pre><h3>After Change</h3><pre><code class='java'>
        self.gru = nn.GRU(HIDDEN_SIZE, HIDDEN_SIZE, num_layers=NUM_LAYERS_ENCODER)

    def forward(self, _input, hidden):
        return self.gru(<a id="change">self.embedding(</a>_input<a id="change">)</a>.view(1, 1, -1), hidden)

    @staticmethod
    def init_hidden():</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/asahi417/lm-question-generation/commit/807e2131b9e761d29682f6ddb83c19ca665d4f44#diff-e793d015281df863ed8422944b8e6710874153c91d0860536cbd78aa762e3e53L53' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 52076058</div><div id='project'> Project Name: asahi417/lm-question-generation</div><div id='commit'> Commit Name: 807e2131b9e761d29682f6ddb83c19ca665d4f44</div><div id='time'> Time: 2022-12-25</div><div id='author'> Author: asahi1992ushio@gmail.com</div><div id='file'> File Name: misc/qag_model/lstm_model/model_training.py</div><div id='m_class'> M Class Name: EncoderRNN</div><div id='n_method'> N Class Name: EncoderRNN</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: misc/qag_model/lstm_model/model_training.py</div><div id='n_file'> N File Name: misc/qag_model/lstm_model/model_training.py</div><div id='m_start'> M Start Line: 60</div><div id='m_end'> M End Line: 63</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 53</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def forward(self, input, hidden):
        embedded = self.embedding(input).view(1, 1, -1)
        <a id="change">output</a> = embedded
        output<a id="change">, hidden</a> = self.gru(output, hidden)
        return output<a id="change">, hidden</a>

    def initHidden(self):
        return torch.zeros(1, 1, self.hidden_size, device=DEVICE)
</code></pre><h3>After Change</h3><pre><code class='java'>
        self.gru = nn.GRU(HIDDEN_SIZE, HIDDEN_SIZE, num_layers=NUM_LAYERS_ENCODER)

    def forward(self, _input, hidden):
        return self.gru(<a id="change">self.embedding(</a>_input<a id="change">)</a>.view(1, 1, -1), hidden)

    @staticmethod
    def init_hidden():</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/asahi417/lm-question-generation/commit/807e2131b9e761d29682f6ddb83c19ca665d4f44#diff-e793d015281df863ed8422944b8e6710874153c91d0860536cbd78aa762e3e53L59' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 52076059</div><div id='project'> Project Name: asahi417/lm-question-generation</div><div id='commit'> Commit Name: 807e2131b9e761d29682f6ddb83c19ca665d4f44</div><div id='time'> Time: 2022-12-25</div><div id='author'> Author: asahi1992ushio@gmail.com</div><div id='file'> File Name: misc/qag_model/lstm_model/model_training.py</div><div id='m_class'> M Class Name: EncoderRNN</div><div id='n_method'> N Class Name: EncoderRNN</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: misc/qag_model/lstm_model/model_training.py</div><div id='n_file'> N File Name: misc/qag_model/lstm_model/model_training.py</div><div id='m_start'> M Start Line: 60</div><div id='m_end'> M End Line: 63</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 53</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            h_label = self.embedding(label)
            proj = torch.mul(h, h_label)
            cls_output = torch.sum(proj, dim=[1])
            return None<a id="change">, None, authen_output + cls_output</a>

        elif self.auxiliary_classifier and not self.projection_discriminator and not self.contrastive_training:
            authen_output = torch.squeeze(self.linear5(h))
            cls_output = self.linear6(h)
            return None, cls_output, authen_output
        else:
            authen_output = torch.squeeze(self.linear5(h))
            return None<a id="change">, None, authen_output</a>
</code></pre><h3>After Change</h3><pre><code class='java'>

        elif self.conditional_strategy == &quotcGAN&quot:
            authen_output = torch.squeeze(self.linear1(h))
            proj = torch.sum(torch.mul(<a id="change">self.embedding(</a>label<a id="change">)</a>, h), 1)
            return authen_output + proj
        
        elif self.conditional_strategy == &quotACGAN&quot:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/postech-cvlab/pytorch-studiogan/commit/a7dd19bc6a2a26dd21c0cb59ccfe0c4933e669ef#diff-2e6916ee9e1af6f41f85b32c146ce90020727a88123a5eedeb90e2fa9399fa4fL217' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 52076056</div><div id='project'> Project Name: postech-cvlab/pytorch-studiogan</div><div id='commit'> Commit Name: a7dd19bc6a2a26dd21c0cb59ccfe0c4933e669ef</div><div id='time'> Time: 2020-07-18</div><div id='author'> Author: first287@naver.com</div><div id='file'> File Name: models/dcgan.py</div><div id='m_class'> M Class Name: Discriminator</div><div id='n_method'> N Class Name: Discriminator</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/dcgan.py</div><div id='n_file'> N File Name: models/dcgan.py</div><div id='m_start'> M Start Line: 226</div><div id='m_end'> M End Line: 252</div><div id='n_start'> N Start Line: 232</div><div id='n_end'> N End Line: 259</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        )

    def forward(self, batch):
        x<a id="change">, y, mask</a> = batch["x"], batch["y"], batch["mask"]
        bs, njoints, nfeats, nframes = x.shape
        x = x.permute((3, 0, 1, 2)).reshape(nframes, bs, njoints * nfeats)

        &#47&#47 embedding of the skeleton
        x = self.skelEmbedding(x)

        &#47&#47 only for ablation / not used in the final model
        if self.ablation == "average_encoder":
            &#47&#47 add positional encoding
            x = self.sequence_pos_encoder(x)

            &#47&#47 transformer layers
            final = self.seqTransEncoder(x, src_key_padding_mask=~mask)
            &#47&#47 get the average of the output
            z = final.mean(axis=0)

            &#47&#47 extract mu and logvar
            mu = self.mu_layer(z)
            logvar = self.sigma_layer(z)
        else:
            &#47&#47 adding the mu and sigma queries
            xseq = torch.cat(
                (self.muQuery[y][None], self.sigmaQuery[y][None], x), axis=0
            )

            &#47&#47 add positional encoding
            xseq = self.sequence_pos_encoder(xseq)

            &#47&#47 create a bigger mask, to allow attend to mu and sigma
            muandsigmaMask = torch.ones((bs, 2), dtype=bool, device=x.device)
            maskseq = torch.cat((muandsigmaMask<a id="change">, mask</a>), axis=1)

            final = self.seqTransEncoder(xseq, src_key_padding_mask=~maskseq)
            mu = final[0]</code></pre><h3>After Change</h3><pre><code class='java'>
        assert input_dim == self.input_dim

        &#47&#47 embedding of the skeleton
        x = <a id="change">self.embedding(</a>x<a id="change">)</a>

        &#47&#47 adding the mu and sigma queries
        xseq = torch.cat((self.mu_query[y][None], self.sigma_query[y][None], x), axis=0)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bioshape-lab/pirounet/commit/fd4ab8620c53c7aba42f8d9f52634ccba9fabe1f#diff-3ed776694d395bbb1ca9c69cc2114789e99ce0146953fc5639501a64a99f648eL188' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 52076057</div><div id='project'> Project Name: bioshape-lab/pirounet</div><div id='commit'> Commit Name: fd4ab8620c53c7aba42f8d9f52634ccba9fabe1f</div><div id='time'> Time: 2022-05-25</div><div id='author'> Author: nmiolane@harold.ece.ucsb.edu</div><div id='file'> File Name: move/models/classifiers.py</div><div id='m_class'> M Class Name: ActorClassifier</div><div id='n_method'> N Class Name: ActorClassifier</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: move/models/classifiers.py</div><div id='n_file'> N File Name: move/models/classifiers.py</div><div id='m_start'> M Start Line: 189</div><div id='m_end'> M End Line: 226</div><div id='n_start'> N Start Line: 177</div><div id='n_end'> N End Line: 199</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        embeddings = self.embedding(encoded_captions)  &#47&#47 (batch_size, max_caption_length, embed_dim)

        &#47&#47 初始化LSTM状态
        h<a id="change">, c</a> = self.init_hidden_state(encoder_out)  &#47&#47 (batch_size, decoder_dim)

        &#47&#47 我们一旦生成了&lt;end&gt;就已经完成了解码
        &#47&#47 因此需要解码的长度实际是 lengths - 1
        decode_lengths = (caption_lengths - 1).tolist()
        &#47&#47 新建两个张量用于存放 word predicion scores and alphas
        global device
        predictions = torch.zeros(batch_size, max(decode_lengths), vocab_size).to(device)
        alphas = torch.zeros(batch_size, max(decode_lengths), num_pixels).to(device)

        &#47&#47 在每一个时间步根据解码器的前一个状态以及经过attention加权后的encoder输出进行解码
        for t in range(max(decode_lengths)):
            batch_size_t = sum([l &gt; t for l in decode_lengths])
            attention_weighted_encoding, alpha = self.attention(encoder_out[:batch_size_t],
                                                                h[:batch_size_t])
            gate = self.sigmoid(self.f_beta(h[:batch_size_t]))  &#47&#47 gating scalar, (batch_size_t, encoder_dim)
            attention_weighted_encoding = gate * attention_weighted_encoding
            h<a id="change">, c</a> = self.decode_step(
                torch.cat([embeddings[:batch_size_t, t, :], attention_weighted_encoding], dim=1),
                (h[:batch_size_t], c[:batch_size_t]))  &#47&#47 (batch_size_t, decoder_dim)
            preds = self.fc(self.dropout(h))  &#47&#47 (batch_size_t, vocab_size)</code></pre><h3>After Change</h3><pre><code class='java'>
                    h[:batch_size_t])  &#47&#47 (batch_size_t, decoder_dim)
            else:
                h = self.decode_step(
                    torch.cat([<a id="change">self.embedding(</a>torch.argmax(predictions[:batch_size_t, t, :],dim = 1)<a id="change">)</a>, attention_weighted_encoding], dim=1),
                    h[:batch_size_t])  &#47&#47 (batch_size_t, decoder_dim)
            preds = self.fc(self.dropout(h))  &#47&#47 (batch_size_t, vocab_size)
            predictions[:batch_size_t, t, :] = preds</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/qs956/latex_ocr_pytorch/commit/0455746d6d3141dfc06cd15fb9cd67a0b9defcfc#diff-62e0d959e50d9f4003df8124a1c19d98c77320268642d433b1cc28c58cf73a85L205' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 52076063</div><div id='project'> Project Name: qs956/latex_ocr_pytorch</div><div id='commit'> Commit Name: 0455746d6d3141dfc06cd15fb9cd67a0b9defcfc</div><div id='time'> Time: 2020-03-21</div><div id='author'> Author: qs956@163.com</div><div id='file'> File Name: model/model.py</div><div id='m_class'> M Class Name: DecoderWithAttention</div><div id='n_method'> N Class Name: DecoderWithAttention</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/model.py</div><div id='n_file'> N File Name: model/model.py</div><div id='m_start'> M Start Line: 231</div><div id='m_end'> M End Line: 250</div><div id='n_start'> N Start Line: 214</div><div id='n_end'> N End Line: 271</div><BR>