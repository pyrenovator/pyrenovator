<html><h3>Pattern ID :7437
</h3><img src='24634197.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                mask = np.expand_dims(mask, axis=0)

            if mask.shape[-2] == 1:  &#47&#47 1D mask
                mask<a id="change"> = </a><a id="change">torch.from_numpy(</a>mask.astype(np.float32)<a id="change">)</a>.unsqueeze(0).unsqueeze(-1)
                &#47&#47 shape = np.array(kspace.shape)
                &#47&#47 num_cols = shape[-2]
                &#47&#47 shape[:-3] = 1</code></pre><h3>After Change</h3><pre><code class='java'>
                mask = np.expand_dims(mask, axis=0)

            if mask.shape[-2] == 1:  &#47&#47 1D mask
                mask = <a id="change">torch.from_numpy(mask).unsqueeze(0).unsqueeze(-1</a><a id="change">)</a>
            else:  &#47&#47 2D mask
                &#47&#47 Crop loaded mask.
                if self.crop_size is not None and self.crop_size not in ("", "None"):
                    mask = center_crop(mask, self.crop_size)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/wdika/mridc/commit/c2a867923121b2e496c03be5818eae6c76dfe881#diff-ac1fd66d83af654880547d6031addeda54c90409df96b304cee60527ef084c67L167' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24634197</div><div id='project'> Project Name: wdika/mridc</div><div id='commit'> Commit Name: c2a867923121b2e496c03be5818eae6c76dfe881</div><div id='time'> Time: 2022-03-26</div><div id='author'> Author: 62050782+deepsource-autofix[bot]@users.noreply.github.com</div><div id='file'> File Name: mridc/collections/reconstruction/parts/transforms.py</div><div id='m_class'> M Class Name: MRIDataTransforms</div><div id='n_method'> N Class Name: MRIDataTransforms</div><div id='m_method'> M Method Name: __call__(9)</div><div id='n_method'> N Method Name: __call__(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: mridc/collections/reconstruction/parts/transforms.py</div><div id='n_file'> N File Name: mridc/collections/reconstruction/parts/transforms.py</div><div id='m_start'> M Start Line: 167</div><div id='m_end'> M End Line: 252</div><div id='n_start'> N Start Line: 233</div><div id='n_end'> N End Line: 253</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        scale = min(scale1, scale2)
        out_h, out_w = in_h * scale, in_w * scale
        img = sktsf.resize(img, (in_c, out_h, out_w), mode=&quotreflect&quot, anti_aliasing=False)  &#47&#47 np.float64
        img<a id="change"> = </a>self.normalize(<a id="change">torch.from_numpy(</a>img<a id="change">)</a>).numpy()
        &#47&#47 img = F.interpolate(img.unsqueeze(0), size=(round(in_h * scale), round(in_w * scale)), mode="nearest").squeeze(0)
        &#47&#47 img = tvtsf.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)
        return img_path, img, img.shape[1:]</code></pre><h3>After Change</h3><pre><code class='java'>
        scale1 = 600 / min(in_h, in_w)
        scale2 = 1000 / max(in_h, in_w)
        scale = min(scale1, scale2)
        img = F.interpolate(<a id="change">img.unsqueeze(0</a><a id="change">)</a>, size=(round(in_h * scale), round(in_w * scale)), mode="nearest").squeeze(0)
        img = tvtsf.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)
        return img_path, img, img.shape[1:]
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pangkun248/faster-rcnn-pytorch/commit/9f846e1554bc021a8736389744969d0dd7f97321#diff-11bb3b632c84e01e0bf1b576e72c513fd062811e900ebcb5f22df0eac7d3b0d9L105' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24634205</div><div id='project'> Project Name: pangkun248/faster-rcnn-pytorch</div><div id='commit'> Commit Name: 9f846e1554bc021a8736389744969d0dd7f97321</div><div id='time'> Time: 2021-08-30</div><div id='author'> Author: 39581901+pangkun248@users.noreply.github.com</div><div id='file'> File Name: dataset.py</div><div id='m_class'> M Class Name: ImageFolder</div><div id='n_method'> N Class Name: ImageFolder</div><div id='m_method'> M Method Name: __getitem__(2)</div><div id='n_method'> N Method Name: __getitem__(2)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: dataset.py</div><div id='n_file'> N File Name: dataset.py</div><div id='m_start'> M Start Line: 110</div><div id='m_end'> M End Line: 119</div><div id='n_start'> N Start Line: 91</div><div id='n_end'> N End Line: 99</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        _device = next(self.parameters()).device
        if isinstance(input, np.ndarray):
            _input<a id="change"> = </a><a id="change">torch.from_numpy(</a>input<a id="change">)</a>.to(_device)
        else:
            _input = input.to(_device)
        pred = self.forward(_input)</code></pre><h3>After Change</h3><pre><code class='java'>
        _dtype = next(self.parameters()).dtype
        _input = torch.as_tensor(input, dtype=_dtype, device=_device)
        if _input.ndim == 2:
            _input = <a id="change">_input.unsqueeze(0</a><a id="change">)</a>  &#47&#47 add a batch dimension
        pred = self.forward(_input)
        pred = self.sigmoid(pred)
        bin_pred = (pred&gt;=bin_pred_thr).int()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/deeppsp/torch_ecg/commit/a9fb65d4abae9cfa6e51ff1425979881a154b22d#diff-d5df3651356b7a5f58541a9071a7620635c9c0f5f980075d4b02d2c95b1bf6a5L50' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 24634202</div><div id='project'> Project Name: deeppsp/torch_ecg</div><div id='commit'> Commit Name: a9fb65d4abae9cfa6e51ff1425979881a154b22d</div><div id='time'> Time: 2021-10-12</div><div id='author'> Author: wenh06@gmail.com</div><div id='file'> File Name: benchmarks/train_crnn_cpsc2020/model.py</div><div id='m_class'> M Class Name: ECG_CRNN_CPSC2020</div><div id='n_method'> N Class Name: ECG_CRNN_CPSC2020</div><div id='m_method'> M Method Name: inference(4)</div><div id='n_method'> N Method Name: inference(4)</div><div id='m_parent_class'> M Parent Class: ECG_CRNN</div><div id='n_parent_class'> N Parent Class: ECG_CRNN</div><div id='m_file'> M File Name: benchmarks/train_crnn_cpsc2020/model.py</div><div id='n_file'> N File Name: benchmarks/train_crnn_cpsc2020/model.py</div><div id='m_start'> M Start Line: 75</div><div id='m_end'> M End Line: 80</div><div id='n_start'> N Start Line: 75</div><div id='n_end'> N End Line: 81</div><BR>