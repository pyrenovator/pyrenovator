<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.layers = nn.Sequential()
        for index, output_size in enumerate(output_sizes):
            &#47&#47 self.layers.add_module("linear_%d" % index, LazyLinear(output_size))
            <a id="change">self.layers.add_module(</a>"linear_%d" % index, nn.LazyLinear(output_size)<a id="change">)</a>
        &#47&#47 self.layers.add_module("relu", nn.ReLU6())

    def forward(self, input):
        input = input.to(device)</code></pre><h3>After Change</h3><pre><code class='java'>
class LazyMLP(nn.Module):
    def __init__(self, output_sizes):
        super().__init__()
        num_layers<a id="change"> = </a>len(output_sizes)
        self._layers_ordered_dict = OrderedDict()
        for index, output_size in enumerate(output_sizes):
            self._layers_ordered_dict["linear_" + str(index)] = nn.LazyLinear(output_size)
            &#47&#47 self.layers.add_module("linear_%d" % index, LazyLinear(output_size))
            <a id="change">if </a>index &lt; (num_layers<a id="change"> - </a>1):
                self._layers_ordered_dict["relu_" + str(index)] = nn.ReLU()
        self.layers = nn.Sequential(self._layers_ordered_dict)
</code></pre>