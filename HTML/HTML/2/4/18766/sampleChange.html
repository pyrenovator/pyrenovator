<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    losses = AverageMeter(&quotLoss&quot, &quot:.4e&quot)
    top1 = AverageMeter(&quotAcc@1&quot, &quot:6.2f&quot)
    top5 = AverageMeter(&quotAcc@5&quot, &quot:6.2f&quot)
    speed = <a id="change">AverageMeter(&quotSpeed&quot</a>, &quot:6.2f&quot<a id="change">)</a>
    progress = ProgressMeter(
        len(train_loader),
        [top1, top5, speed, batch_time, losses],
        prefix="Epoch: [{}]".format(epoch))

    &#47&#47 switch to train mode
    model.train()

    end = time.time()
    for i, (images, target) in enumerate(train_loader):
        &#47&#47 measure data loading time
        data_time.update(time.time() - end)

        images = images.cuda(gpu, non_blocking=True)
        target = target.cuda(gpu, non_blocking=True)

        &#47&#47 compute output
        output = model(images)
        loss = criterion(output, target)

        &#47&#47 measure accuracy and record loss
        acc1, acc5 = accuracy(output, target, topk=(1, 5))
        losses.update(loss.item(), images.size(0))
        top1.update(acc1[0], images.size(0))
        top5.update(acc5[0], images.size(0))

        &#47&#47 compute gradient and do SGD step
        optimizer.zero_grad()
        &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
        &#47&#47 Mixed-precision training requires that the loss is scaled in order
        &#47&#47 to prevent the gradients from underflowing.
        with amp.scale_loss(loss, optimizer) as scaled_loss:
            scaled_loss.backward()
        &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
        optimizer.step()

        &#47&#47 measure elapsed time
        t = time.time() - end
        batch_time.update(t)
        <a id="change">speed.update(</a>args.world_size*args.batch_size/t<a id="change">)</a>
        end = time.time()

        if i % args.print_freq == 0:
            progress.display(i)</code></pre><h3>After Change</h3><pre><code class='java'>
        images = images.cuda(gpu, non_blocking=True)
        target = target.cuda(gpu, non_blocking=True)

        adjust_learning_rate(optimizer, epoch, i, <a id="change">len(</a>train_loader<a id="change">)</a>, args)

        &#47&#47 compute output
        output = model(images)</code></pre>