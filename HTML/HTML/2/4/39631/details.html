<html><h3>Pattern ID :39631
</h3><img src='112696759.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                    tensored_datapoints.append([torch.Tensor(datapoint[0]),
                                                torch.LongTensor(datapoint[1]),
                                                torch.Tensor(datapoint[2]),
                                                <a id="change">torch.LongTensor(</a>datapoint[3]<a id="change">)</a>,
                                                torch.LongTensor(datapoint[4]),
                                                torch.Tensor(datapoint[5]),
                                                torch.Tensor(datapoint[6])])</code></pre><h3>After Change</h3><pre><code class='java'>
            process_list = list()
            for i in range(loading_processes):
                datapoint_splits.append(dataset[i * len(dataset) // loading_processes:(i + 1) * len(dataset) // loading_processes])
                norm_wave_splits.append(norm_waves[i * len(norm_waves) // loading_processes:(<a id="change">i + 1) * len(norm_waves) // </a>loading_processes])
            for index, _ in enumerate(datapoint_splits):
                process_list.append(Process(target=self.cache_builder_process,
                                            args=(datapoint_splits[index],</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/d75af2f091227a4695d4887a9a8f23dc5d22b12b#diff-528f1d1f9b65f826c6eec25f3934452fe1a81965d76a0070a71db9ef9ef36aa0L36' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 112696759</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: d75af2f091227a4695d4887a9a8f23dc5d22b12b</div><div id='time'> Time: 2021-09-15</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='m_class'> M Class Name: FastSpeechDataset</div><div id='n_method'> N Class Name: FastSpeechDataset</div><div id='m_method'> M Method Name: __init__(13)</div><div id='n_method'> N Method Name: __init__(13)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='m_start'> M Start Line: 36</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 36</div><div id='n_end'> N End Line: 109</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        unk_idx = self.data.word_field.vocab.stoi[self.data.word_field.unk_token]
        unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]
        &#47&#47 begin prediction
        token_tensor = <a id="change">torch.LongTensor(</a>numericalized_tokens<a id="change">)</a>
        token_tensor = token_tensor.unsqueeze(-1)
        predictions = self.model(token_tensor)
        &#47&#47 convert results to tags
        top_predictions = predictions.argmax(-1)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 tokenize sentence
        nlp = Indonesian()
        tokens = [token.text for token in nlp(sentence)]
        max_word_len = max([<a id="change">len(</a>token<a id="change">)</a> for token in tokens])
        &#47&#47 transform to indices based on corpus vocab
        numericalized_tokens = [self.data.word_field.vocab.stoi[token.lower()] for token in tokens]
        numericalized_chars = []
        char_pad_id = self.data.char_pad_idx
        for token in tokens:
            numericalized_chars.append(
                [self.data.char_field.vocab.stoi[char] for char in token]<a id="change">
                + </a>[char_pad_id for _ in range(max_word_len<a id="change"> - </a>len(token))]
            )
        &#47&#47 find unknown words
        unk_idx = self.data.word_field.vocab.stoi[self.data.word_field.unk_token]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yoseflaw/nerindo/commit/a70e55e7c0489cba1290ebd51512a9e878c6e0ed#diff-8cab4f44e154e1111c4ee01fed014cbc93efbaa697c98a0f44a624cd8e8f013fL84' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 112696754</div><div id='project'> Project Name: yoseflaw/nerindo</div><div id='commit'> Commit Name: a70e55e7c0489cba1290ebd51512a9e878c6e0ed</div><div id='time'> Time: 2020-08-09</div><div id='author'> Author: yosefardhitowin@gmail.com</div><div id='file'> File Name: nerindo/trainer.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: infer(3)</div><div id='n_method'> N Method Name: infer(3)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: nerindo/trainer.py</div><div id='n_file'> N File Name: nerindo/trainer.py</div><div id='m_start'> M Start Line: 88</div><div id='m_end'> M End Line: 100</div><div id='n_start'> N Start Line: 184</div><div id='n_end'> N End Line: 205</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                self.cached_text.append(tf.string_to_tensor(transcript).long())
                self.cached_text_lens.append(torch.LongTensor([len(self.cached_text[-1])]))
                self.cached_speech.append(ap.audio_to_mel_spec_tensor(wave).transpose(0, 1))
                self.cached_speech_lens.append(<a id="change">torch.LongTensor(</a>[len(self.cached_speech[-1])]<a id="change">)</a>)
                if self.spemb:
                    print("not implemented yet")
                    raise NotImplementedError</code></pre><h3>After Change</h3><pre><code class='java'>
        key_splits = list()
        thread_list = list()
        for i in range(loading_threads):
            key_splits.append(key_list[i<a id="change"> * len(key_list) / </a>loading_threads:i + 1 * len(key_list) / loading_threads])
        for key_split in key_splits:
            thread_list.append(Thread(target=self.cache_builder_thread, args=(key_split,)))
            thread_list[-1].start()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/21527c7e2ea36abafa7885cef64519affbb0e587#diff-0965ad6e3a8f04afe3a358a7558e203eaa1f244ad6e8e6fbfe73f8a2052b8cb1L13' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 112696752</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 21527c7e2ea36abafa7885cef64519affbb0e587</div><div id='time'> Time: 2021-03-01</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_class'> M Class Name: TransformerTTSDataset</div><div id='n_method'> N Class Name: TransformerTTSDataset</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='n_file'> N File Name: TransformerTTS/TransformerTTSDataset.py</div><div id='m_start'> M Start Line: 14</div><div id='m_end'> M End Line: 51</div><div id='n_start'> N Start Line: 15</div><div id='n_end'> N End Line: 47</div><BR>