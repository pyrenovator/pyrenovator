<html><h3>Pattern ID :9689
</h3><img src='34880052.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def forward(self, text, view=False):
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = <a id="change">self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0</a>, <a id="change">1</a><a id="change">)</a>
            wave = self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0)
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd</code></pre><h3>After Change</h3><pre><code class='java'>
            ax[1].xaxis.grid(True, which=&quotminor&quot)
            ax[1].set_xticks(label_positions, minor=False)
            ax[1].set_xticklabels(self.text2phone.get_phone_string(text))
            <a id="change">ax[0].set_title(</a>text<a id="change">)</a>
            plt.subplots_adjust(left=0.05, bottom=0.1, right=0.95, top=.9, wspace=0.0, hspace=0.0)
            plt.show()
        return wave
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 2</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/4bbfcda47cf77f65ad0e557f8a06a174197d1bfc#diff-74abc2e7bebe273ec5fa359ca3a9ef79f13947e109a095575f6b818f4e7f438cL34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 34880052</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 4bbfcda47cf77f65ad0e557f8a06a174197d1bfc</div><div id='time'> Time: 2021-07-24</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/LibriTTS_FastSpeechInference.py</div><div id='m_class'> M Class Name: LibriTTS_FastSpeechInference</div><div id='n_method'> N Class Name: LibriTTS_FastSpeechInference</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/LibriTTS_FastSpeechInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/LibriTTS_FastSpeechInference.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 34</div><div id='n_end'> N End Line: 58</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def forward(self, text, view=False):
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = <a id="change">self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0</a>, <a id="change">1</a><a id="change">)</a>
            wave = self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0)
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd</code></pre><h3>After Change</h3><pre><code class='java'>
            ax[1].xaxis.grid(True, which=&quotminor&quot)
            ax[1].set_xticks(label_positions, minor=False)
            ax[1].set_xticklabels(self.text2phone.get_phone_string(text))
            <a id="change">ax[0].set_title(</a>text<a id="change">)</a>
            plt.subplots_adjust(left=0.05, bottom=0.1, right=0.95, top=.9, wspace=0.0, hspace=0.0)
            plt.show()
        return wave
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/4bbfcda47cf77f65ad0e557f8a06a174197d1bfc#diff-7d3b87a93b0bc1f791ef878d1df587515e570f34cd1a868873e0fd6e7f941af5L31' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 34880048</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 4bbfcda47cf77f65ad0e557f8a06a174197d1bfc</div><div id='time'> Time: 2021-07-24</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/Nancy_FastSpeechInference.py</div><div id='m_class'> M Class Name: Nancy_FastSpeechInference</div><div id='n_method'> N Class Name: Nancy_FastSpeechInference</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/Nancy_FastSpeechInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/Nancy_FastSpeechInference.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 57</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def forward(self, text, view=False):
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = <a id="change">self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0</a>, <a id="change">1</a><a id="change">)</a>
            wave = self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0)
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd</code></pre><h3>After Change</h3><pre><code class='java'>
            ax[1].xaxis.grid(True, which=&quotminor&quot)
            ax[1].set_xticks(label_positions, minor=False)
            ax[1].set_xticklabels(self.text2phone.get_phone_string(text))
            <a id="change">ax[0].set_title(</a>text<a id="change">)</a>
            plt.subplots_adjust(left=0.05, bottom=0.1, right=0.95, top=.9, wspace=0.0, hspace=0.0)
            plt.show()
        return wave
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/4bbfcda47cf77f65ad0e557f8a06a174197d1bfc#diff-98c0a7845dd35e306bac5af5963f246159ffc54c9cc93cdac53373929d69df73L31' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 34880049</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 4bbfcda47cf77f65ad0e557f8a06a174197d1bfc</div><div id='time'> Time: 2021-07-24</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/LJSpeech_FastSpeechInference.py</div><div id='m_class'> M Class Name: LJSpeech_FastSpeechInference</div><div id='n_method'> N Class Name: LJSpeech_FastSpeechInference</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/LJSpeech_FastSpeechInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/LJSpeech_FastSpeechInference.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 57</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    elif lang == "de":
        sentence = "Dies ist ein ungesehener Satz."
    text = tf.string_to_tensor(sentence).long().squeeze(0).to(device)
    spec = <a id="change">net.inference(text=text, speaker_embeddings=reference_speaker_embedding_for_plot).transpose(0</a>, <a id="change">1</a><a id="change">)</a>.to("cpu").numpy()
    if not os.path.exists(os.path.join(save_dir, "spec")):
        os.makedirs(os.path.join(save_dir, "spec"))
    fig, ax = plt.subplots(nrows=1, ncols=1)</code></pre><h3>After Change</h3><pre><code class='java'>
    ax.xaxis.grid(True, which=&quotminor&quot)
    ax.set_xticks(label_positions, minor=False)
    ax.set_xticklabels(tf.get_phone_string(sentence))
    <a id="change">ax.set_title(</a>sentence<a id="change">)</a>
    plt.savefig(os.path.join(os.path.join(save_dir, "spec"), str(step) + ".png"))
    plt.clf()
    plt.close()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/4bbfcda47cf77f65ad0e557f8a06a174197d1bfc#diff-1988a4cedcd0412bf08be68eb840ca996e1dbe491b7519d2153870a127712118L19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 34880050</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 4bbfcda47cf77f65ad0e557f8a06a174197d1bfc</div><div id='time'> Time: 2021-07-24</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: FastSpeech2/fastspeech2_train_loop.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: plot_progress_spec(6)</div><div id='n_method'> N Method Name: plot_progress_spec(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: FastSpeech2/fastspeech2_train_loop.py</div><div id='n_file'> N File Name: FastSpeech2/fastspeech2_train_loop.py</div><div id='m_start'> M Start Line: 27</div><div id='m_end'> M End Line: 27</div><div id='n_start'> N Start Line: 21</div><div id='n_end'> N End Line: 46</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def forward(self, text, view=False):
        with torch.no_grad():
            phones = self.text2phone.string_to_tensor(text).squeeze(0).long().to(torch.device(self.device))
            mel = <a id="change">self.phone2mel(phones, speaker_embedding=self.speaker_embedding).transpose(0</a>, <a id="change">1</a><a id="change">)</a>
            wave = self.mel2wav(mel.unsqueeze(0)).squeeze(0).squeeze(0)
        if view:
            import matplotlib.pyplot as plt
            import librosa.display as lbd</code></pre><h3>After Change</h3><pre><code class='java'>
            ax[1].xaxis.grid(True, which=&quotminor&quot)
            ax[1].set_xticks(label_positions, minor=False)
            ax[1].set_xticklabels(self.text2phone.get_phone_string(text))
            <a id="change">ax[0].set_title(</a>text<a id="change">)</a>
            plt.subplots_adjust(left=0.05, bottom=0.1, right=0.95, top=.9, wspace=0.0, hspace=0.0)
            plt.show()
        return wave
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/4bbfcda47cf77f65ad0e557f8a06a174197d1bfc#diff-4b2f26f3d3287b567ffaec37b852ede237af7e76f93c389c33396f41ee6a1cf0L30' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 34880044</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 4bbfcda47cf77f65ad0e557f8a06a174197d1bfc</div><div id='time'> Time: 2021-07-24</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: InferenceInterfaces/Thorsten_FastSpeechInference.py</div><div id='m_class'> M Class Name: Thorsten_FastSpeechInference</div><div id='n_method'> N Class Name: Thorsten_FastSpeechInference</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: InferenceInterfaces/Thorsten_FastSpeechInference.py</div><div id='n_file'> N File Name: InferenceInterfaces/Thorsten_FastSpeechInference.py</div><div id='m_start'> M Start Line: 32</div><div id='m_end'> M End Line: 41</div><div id='n_start'> N Start Line: 32</div><div id='n_end'> N End Line: 56</div><BR>