<html><h3>Pattern ID :25089
</h3><img src='76875111.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.evict_backlist.clear()
        &#47&#47 new ids chunk_offset + offset_in_chunk
        with record_function("(zhg) embed idx -&gt; cache chunk id"):
            mapped_ids = <a id="change">torch.tensor(</a>[self._id_to_cached_cuda_id(id) for id in ids.view(-1)]<a id="change">,
                                      device=ids.device,
                                      dtype=ids.dtype)</a>.view(ids.shape)

        return mapped_ids
</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 self.IMT_Embedding(ids)

            chunk_id_set = torch.unique(self.IMP_chunkid_Embedding(ids))
            chunk_id_set<a id="change"> = </a>set(<a id="change">chunk_id_set.cpu().numpy()</a>)

            assert len(chunk_id_set) &lt;= self.cuda_chunk_num, \
                f"the input indices pull {len(chunk_id_set)} chunks, " \</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/hpcaitech/freqcacheembedding/commit/5062f1cff105e81702e90439e652d412e4950718#diff-aab5f7e7e049810d29a74e3eab12af668892a81357998cc464ab0f8cd2272767L126' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76875111</div><div id='project'> Project Name: hpcaitech/freqcacheembedding</div><div id='commit'> Commit Name: 5062f1cff105e81702e90439e652d412e4950718</div><div id='time'> Time: 2022-07-25</div><div id='author'> Author: fangjiarui123@gmail.com</div><div id='file'> File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='m_class'> M Class Name: ChunkParamMgr</div><div id='n_method'> N Class Name: ChunkParamMgr</div><div id='m_method'> M Method Name: prepare_ids(2)</div><div id='n_method'> N Method Name: prepare_ids(2)</div><div id='m_parent_class'> M Parent Class: object</div><div id='n_parent_class'> N Parent Class: object</div><div id='m_file'> M File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='n_file'> N File Name: recsys/modules/embeddings/chunk_param_mgr.py</div><div id='m_start'> M Start Line: 126</div><div id='m_end'> M End Line: 165</div><div id='n_start'> N Start Line: 152</div><div id='n_end'> N End Line: 189</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                labels = torch.tensor(np.array([self.video_id_to_label[vid] for vid in video_ids if vid in self.video_id_to_label.keys()]), dtype=video_ids.dtype, device=video_ids.device)
                if len(labels) == 0:
                    return None, None, None
                video_ids = <a id="change">torch.tensor(</a>np.array([video_ids[idx] for idx, vid in enumerate(video_ids) if vid in self.video_id_to_label.keys()])<a id="change">, dtype=video_ids.dtype, device=video_ids.device)</a>
                clip_predictions = torch.tensor(np.array([clip_predictions[idx] for idx, vid in enumerate(video_ids) if vid in self.video_id_to_label.keys()]), dtype=video_ids.dtype, device=video_ids.device)

        video_ids, clip_predictions, labels = self._check_data_shape(video_ids, clip_predictions, labels)
</code></pre><h3>After Change</h3><pre><code class='java'>
                elif self.video_id_to_label_missing_action == &quotoriginal_label&quot:
                    labels = torch.tensor(np.array([self.video_id_to_label[vid] if vid in self.video_id_to_label.keys() else labels[idx] for idx, vid in enumerate(video_ids)]), dtype=video_ids.dtype, device=video_ids.device)
                else:   &#47&#47 skip
                    video_ids_numpy<a id="change"> = </a><a id="change">video_ids.cpu().numpy()</a>.astype(int)
                    labels = torch.tensor(np.array([self.video_id_to_label[vid] for vid in video_ids_numpy if vid in self.video_id_to_label.keys()]), dtype=video_ids.dtype, device=video_ids.device)
                    if len(labels) == 0:
                        return None, None, None</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/kiyoon/pyvideoai/commit/5883573ab16166263f88cafbb0f2f84a44d44105#diff-9c73601aa918974365fb7bf3192601a041f45f39a8743863e91dd5ba9be714bdL77' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76875110</div><div id='project'> Project Name: kiyoon/pyvideoai</div><div id='commit'> Commit Name: 5883573ab16166263f88cafbb0f2f84a44d44105</div><div id='time'> Time: 2022-02-28</div><div id='author'> Author: yoonkr33@gmail.com</div><div id='file'> File Name: pyvideoai/metrics/metric.py</div><div id='m_class'> M Class Name: Metric</div><div id='n_method'> N Class Name: Metric</div><div id='m_method'> M Method Name: add_clip_predictions(4)</div><div id='n_method'> N Method Name: add_clip_predictions(4)</div><div id='m_parent_class'> M Parent Class: ABC</div><div id='n_parent_class'> N Parent Class: ABC</div><div id='m_file'> M File Name: pyvideoai/metrics/metric.py</div><div id='n_file'> N File Name: pyvideoai/metrics/metric.py</div><div id='m_start'> M Start Line: 88</div><div id='m_end'> M End Line: 100</div><div id='n_start'> N Start Line: 91</div><div id='n_end'> N End Line: 105</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

            norm_wave = norm_wave_list[index]
            print(norm_wave)
            <a id="change">torch.tensor(</a>[1.0]<a id="change">)</a>
            print(norm_wave.shape)
            norm_wave = torch.tensor(trim_zeros(norm_wave.numpy()))
            norm_wave_length = torch.LongTensor([len(norm_wave)])
</code></pre><h3>After Change</h3><pre><code class='java'>

            norm_wave = norm_wave_list[index]
            print(norm_wave)
            norm_wave<a id="change"> = </a>trim_zeros(<a id="change">norm_wave.cpu().detach().numpy()</a>)
            print(norm_wave)
            norm_wave = torch.tensor(norm_wave)
            norm_wave_length = torch.LongTensor([len(norm_wave)])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/6a1f29b3122302047443067293d4c72e45e93a69#diff-528f1d1f9b65f826c6eec25f3934452fe1a81965d76a0070a71db9ef9ef36aa0L131' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76875113</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 6a1f29b3122302047443067293d4c72e45e93a69</div><div id='time'> Time: 2021-10-06</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='m_class'> M Class Name: FastSpeechDataset</div><div id='n_method'> N Class Name: FastSpeechDataset</div><div id='m_method'> M Method Name: cache_builder_process(9)</div><div id='n_method'> N Method Name: cache_builder_process(9)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='m_start'> M Start Line: 150</div><div id='m_end'> M End Line: 154</div><div id='n_start'> N Start Line: 150</div><div id='n_end'> N End Line: 154</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 this means it is a 3-channel RGB label, so 2 channels can be safely ignored
        &#47&#47 to ensure coherence of dimensions, we remove the last and add in dim_0
        &#47&#47 reference_array = one_hot(target[:,0,...].unsqueeze(0),params["model"]["class_list"]).squeeze(0).cpu().detach().numpy()
        return <a id="change">torch.tensor(</a>0<a id="change">)</a>

    hd1 = __surface_distances(result_array, reference_array, params["subject_spacing"])
    hd2 = __surface_distances(reference_array, result_array, params["subject_spacing"])
    hd_95 = numpy.percentile(numpy.hstack((hd1, hd2)), 95)</code></pre><h3>After Change</h3><pre><code class='java'>
    This is a real metric. The binary images can therefore be supplied in any order.
    
    &#47&#47 result_array = reverse_one_hot(inp, params["model"]["class_list"])
    result_array<a id="change"> = </a><a id="change">inp.cpu().detach().numpy()</a>
    &#47&#47 ensure that we are dealing with a binary array
    result_array[result_array &lt; 0.5] = 0 
    result_array[result_array &gt;= 0.5] = 1
    &#47&#47 if result_array.dtype != int64:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/cbica/gandlf/commit/c7ddb8e057babeec6d2b360bbdb1a284a026a682#diff-e8e9d1aecc57d03523e91ca58b5b79b0c557a8abb59e324ba3a85e65db05a6d3L192' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76875114</div><div id='project'> Project Name: cbica/gandlf</div><div id='commit'> Commit Name: c7ddb8e057babeec6d2b360bbdb1a284a026a682</div><div id='time'> Time: 2021-06-26</div><div id='author'> Author: sarthak.pati@hotmail.com</div><div id='file'> File Name: GANDLF/metrics.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: hd95(3)</div><div id='n_method'> N Method Name: hd95(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: GANDLF/metrics.py</div><div id='n_file'> N File Name: GANDLF/metrics.py</div><div id='m_start'> M Start Line: 224</div><div id='m_end'> M End Line: 234</div><div id='n_start'> N Start Line: 225</div><div id='n_end'> N End Line: 230</div><BR>