<html><h3>Pattern ID :19313
</h3><img src='62895242.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
  def expand(self, shape, *args) -&gt; Tensor: return mlops.Expand.apply(self, shape=tuple(x if x != -1 else s for s,x in zip(self.shape, argfix(shape, *args))))
  def permute(self, order, *args) -&gt; Tensor: return mlops.Permute.apply(self, order=argfix(order, *args))
  def flip(self, axis, *args) -&gt; Tensor: return mlops.Flip.apply(self, axis=argfix(axis, *args))
  def slice(self, arg) -&gt; Tensor: return <a id="change">mlops.Slice.apply(</a>self<a id="change">, arg=tuple(a if a is not None else (0,s) for s,a in zip(self.shape, arg)))</a>

  &#47&#47 ***** movement hlops *****

  &#47&#47 Tensors mostly follow the normal python indexing / slicing behavior for sequences</code></pre><h3>After Change</h3><pre><code class='java'>
  &#47&#47 NOTE: using slice is discouraged and things should migrate to pad and shrink
  def slice(self, arg:Sequence[Optional[Tuple[int, int]]]) -&gt; Tensor:
    arg_ = tuple(a if a is not None else (0,s) for s,a in zip(self.shape, arg))
    padding<a id="change"> = </a>tuple((max(0, -p[0]), max(0, p[1]-self.shape[i])) for i,p in enumerate(arg_))
    <a id="change">return </a>self.pad(padding).shrink(tuple((p[0] + padding[i][0]<a id="change">, p[1] + padding[i][0]</a>) for i,p in enumerate(arg_)))

  &#47&#47 Tensors mostly follow the normal python indexing / slicing behavior for sequences
  &#47&#47 - Negative indices are taken relative to the end of the sequence, so X[-2] returns the 2nd-to-last element</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/geohot/tinygrad/commit/7ff92550bb2addf2f49a5f239c84adbab762265c#diff-7703e7b63c9844f019ae3609629fd9c9bab290d11ae6608ed2d09edd49bab2dbL198' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 62895242</div><div id='project'> Project Name: geohot/tinygrad</div><div id='commit'> Commit Name: 7ff92550bb2addf2f49a5f239c84adbab762265c</div><div id='time'> Time: 2023-02-28</div><div id='author'> Author: george@comma.ai</div><div id='file'> File Name: tinygrad/tensor.py</div><div id='m_class'> M Class Name: Tensor</div><div id='n_method'> N Class Name: Tensor</div><div id='m_method'> M Method Name: slice(2)</div><div id='n_method'> N Method Name: slice(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tinygrad/tensor.py</div><div id='n_file'> N File Name: tinygrad/tensor.py</div><div id='m_start'> M Start Line: 198</div><div id='m_end'> M End Line: 198</div><div id='n_start'> N Start Line: 203</div><div id='n_end'> N End Line: 206</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            attr = "NORM"
        matcher = PhraseMatcher(self.nlp.vocab, attr=attr)
        for name, df in dfs.items():
            df = df[<a id="change">df.apply(</a>(lambda x: self.entry_filter(x, lowercase=lowercase))<a id="change">, axis=1)</a>]
            terms = list([syn for syn in df[SYN]])
            iris = list(df[IDX])
            assert len(list(terms)) == len(list(iris))</code></pre><h3>After Change</h3><pre><code class='java'>

    def _create_phrasematcher(self, parsers: List[OntologyParser]):
        orth_matcher = PhraseMatcher(self.nlp.vocab, attr="ORTH")
        lower_matcher<a id="change"> = </a>PhraseMatcher(self.nlp.vocab, attr="NORM")
        for parser in parsers:
            &#47&#47 TODO: fix api call
            synonym_data = parser.collect_aggregate_synonym_data(False)
            generated_synonym_data = parser.generate_synonyms()
            generated_synonym_data.update(synonym_data)

            logging.info(f"generating {len(generated_synonym_data)} patterns for {parser.name}")
            patterns = list(self.nlp.tokenizer.pipe(generated_synonym_data.keys()))
            for i, (syn, syn_data_list) in enumerate(generated_synonym_data.items()):
                is_lower = syn.islower()
                for syn_data in syn_data_list:
                    for idx in syn_data.ids:
                        &#47&#47 if self.entry_filter(syn,syn_data,lowercase) and len(syn_data.generated_from)==0:
                        if self.entry_filter(syn, idx, is_lower):
                            try:
                                if is_lower:
                                    lower_matcher.add(str(idx), [patterns[i]])
                                else:
                                    orth_matcher.add(str(idx), [patterns[i]])
                            except KeyError as e:
                                logging.warning(
                                    f"failed to add &quot{syn}&quot. StringStore is {len(self.nlp.vocab.strings)} ",
                                    e,
                                )
        <a id="change">return </a>orth_matcher<a id="change">, lower_matcher</a>

    def _create_token_matchers(self):
        tp_matchers = {}
        fp_matchers = {}</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/astrazeneca/kazu/commit/e6b1e7e6235e8562c8164e4a5b1d6b4f946c3fab#diff-ec730aab051edf2ba7b89f163cda2f2499c14d8d87a4b422587f8edcaec3d078L340' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 62895239</div><div id='project'> Project Name: astrazeneca/kazu</div><div id='commit'> Commit Name: e6b1e7e6235e8562c8164e4a5b1d6b4f946c3fab</div><div id='time'> Time: 2022-11-30</div><div id='author'> Author: richard.jackson4@astrazeneca.com</div><div id='file'> File Name: kazu/modelling/ontology_matching/ontology_matcher.py</div><div id='m_class'> M Class Name: OntologyMatcher</div><div id='n_method'> N Class Name: OntologyMatcher</div><div id='m_method'> M Method Name: _create_phrasematcher(2)</div><div id='n_method'> N Method Name: _create_phrasematcher(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: kazu/modelling/ontology_matching/ontology_matcher.py</div><div id='n_file'> N File Name: kazu/modelling/ontology_matching/ontology_matcher.py</div><div id='m_start'> M Start Line: 340</div><div id='m_end'> M End Line: 356</div><div id='n_start'> N Start Line: 339</div><div id='n_end'> N End Line: 366</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                norm_w=None,
                norm_b=None,
                alibi=None):
        output = <a id="change">DeepSpeedSelfAttentionFunction.apply(
            </a>input,
            input_mask,
            head_mask,
            layer_past,
            get_present,
            encoder_hidden_states,
            encoder_attention_mask,
            output_attentions,
            norm_w,
            norm_b,
            self.config,
            self.attn_qkvw,
            self.attn_qkvb,
            self.num_attention_heads_per_partition,
            self.norm_factor,
            self.hidden_size_per_partition,
            self.attn_ow,
            self.attn_ob,
            self.mp_group,
            self.q_scales,
            self.q_groups,
            self.merge_count,
            self.qkv_merging,
            self.score_context_func,
            alibi<a id="change">)</a>

        return output
</code></pre><h3>After Change</h3><pre><code class='java'>

        output = self.vector_matmul_func(input=context_layer, weight=self.attn_ow)

        inp_norm<a id="change"> = </a>qkv_out[-1]

        if self.config.mlp_after_attn and self.mp_group is not None and dist.get_world_size(
                group=self.mp_group) &gt; 1:
            dist.all_reduce(output, group=self.mp_group)

        <a id="change">return </a>(output<a id="change">, key_layer, value_layer, context_layer, inp_norm</a>)


class BloomSelfAttention(DeepSpeedSelfAttention):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/bb68c526ad2c267dfb235db9c0d0fb1413d19a34#diff-88a3148746124b4093264a91ae8cac5be0bb592bfb2868d5df944836e55d93dbL446' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 62895235</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: bb68c526ad2c267dfb235db9c0d0fb1413d19a34</div><div id='time'> Time: 2022-12-22</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/ops/transformer/inference/ds_attention.py</div><div id='m_class'> M Class Name: DeepSpeedSelfAttention</div><div id='n_method'> N Class Name: DeepSpeedSelfAttention</div><div id='m_method'> M Method Name: forward(12)</div><div id='n_method'> N Method Name: forward(12)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: deepspeed/ops/transformer/inference/ds_attention.py</div><div id='n_file'> N File Name: deepspeed/ops/transformer/inference/ds_attention.py</div><div id='m_start'> M Start Line: 458</div><div id='m_end'> M End Line: 485</div><div id='n_start'> N Start Line: 120</div><div id='n_end'> N End Line: 151</div><BR>