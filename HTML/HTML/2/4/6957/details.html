<html><h3>Pattern ID :6957
</h3><img src='23289879.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        ax2.set_ylabel("Attention")
        ax2.plot(
            np.arange(
                -self.hparams.max_encoder_length, <a id="change">interpretation["attention"].size(1</a><a id="change">)</a> - self.hparams.max_encoder_length
            ),
            interpretation["attention"][idx].detach().cpu(),
            alpha=0.2,</code></pre><h3>After Change</h3><pre><code class='java'>
            ax = fig.axes[0]
            ax2 = ax.twinx()
            ax2.set_ylabel("Attention")
            max_encoder_length<a id="change"> = </a><a id="change">out["encoder_lengths"].max()</a>
            encoder_length = x["encoder_lengths"][idx]
            ax2.plot(
                np.arange(-encoder_length, 1),
                interpretation["attention"][idx, list(range(encoder_length)) + [max_encoder_length]].detach().cpu(),</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/jdb78/pytorch-forecasting/commit/786f72f02b958bee48909ffe9477a68e55de92e0#diff-76ca71ffaeab9ec5eca22b512d1ed2460e8173ce9feb6e881188098900f5f8d4L706' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23289879</div><div id='project'> Project Name: jdb78/pytorch-forecasting</div><div id='commit'> Commit Name: 786f72f02b958bee48909ffe9477a68e55de92e0</div><div id='time'> Time: 2020-08-22</div><div id='author'> Author: beitner.jan@bcg.com</div><div id='file'> File Name: pytorch_forecasting/models/temporal_fusion_transformer/__init__.py</div><div id='m_class'> M Class Name: TemporalFusionTransformer</div><div id='n_method'> N Class Name: TemporalFusionTransformer</div><div id='m_method'> M Method Name: plot_prediction(7)</div><div id='n_method'> N Method Name: plot_prediction(4)</div><div id='m_parent_class'> M Parent Class: BaseModel</div><div id='n_parent_class'> N Parent Class: BaseModel</div><div id='m_file'> M File Name: pytorch_forecasting/models/temporal_fusion_transformer/__init__.py</div><div id='n_file'> N File Name: pytorch_forecasting/models/temporal_fusion_transformer/__init__.py</div><div id='m_start'> M Start Line: 729</div><div id='m_end'> M End Line: 740</div><div id='n_start'> N Start Line: 706</div><div id='n_end'> N End Line: 742</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

                    if "whamr" in self.hparams.data_folder:
                        targets = self.hparams.reverb(
                            targets[0].t(), torch.ones(<a id="change">targets.size(-1</a><a id="change">)</a>)
                        )
                        targets = targets.t().unsqueeze(0)
                        mix = targets.sum(-1)</code></pre><h3>After Change</h3><pre><code class='java'>

                        &#47&#47 fix the levels
                        coef = (
                            <a id="change">targets.abs().max()</a>.item() / mix.abs().max().item()
                        )
                        mix<a id="change"> = </a>mix * coef

                        &#47&#47 torchaudio.save(&quotreverbtest.wav&quot, mix.cpu(), 8000)
                        &#47&#47 torchaudio.save(&quottarget.wav&quot, targets[:, :, 0].cpu(), 8000)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/59bc3bf412dc5c1c2e9baf687ede623cc1c4c588#diff-eb60f0baa9cae2dfcac548ade392e883ffc7b89290c90c680e1c9d6200f1c1a5L42' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23289878</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: 59bc3bf412dc5c1c2e9baf687ede623cc1c4c588</div><div id='time'> Time: 2021-03-19</div><div id='author'> Author: csubakan@gmail.com</div><div id='file'> File Name: recipes/WSJ0Mix/separation/train.py</div><div id='m_class'> M Class Name: Separation</div><div id='n_method'> N Class Name: Separation</div><div id='m_method'> M Method Name: compute_forward(6)</div><div id='n_method'> N Method Name: compute_forward(5)</div><div id='m_parent_class'> M Parent Class: sb.Brain</div><div id='n_parent_class'> N Parent Class: sb.Brain</div><div id='m_file'> M File Name: recipes/WSJ0Mix/separation/train.py</div><div id='n_file'> N File Name: recipes/WSJ0Mix/separation/train.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 65</div><div id='n_start'> N Start Line: 42</div><div id='n_end'> N End Line: 79</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        n_tasks = prod(Y_hat[0, 0, ...].shape)
        loss = loss / n_tasks  &#47&#47 takes an average over tasks

    batch_size = <a id="change">loss.size(0</a><a id="change">)</a>
    loss = loss.view(batch_size, -1).sum(keepdim=True, dim=-1)

    return loss
</code></pre><h3>After Change</h3><pre><code class='java'>
    if agg_over_tasks == "mean":
        loss = loss.mean(keepdim=True, dim=1)
    elif agg_over_tasks == "max":
        loss<a id="change"> = </a><a id="change">loss.max(keepdim=True, dim=1)</a>[0]
    elif agg_over_tasks == "sum":
        loss = loss.sum(keepdim=True, dim=1)
    elif agg_over_tasks == "std":</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/yanndubs/lossyless/commit/c8ef0b6b635ba0e212baf30a60596f78e08a56fa#diff-ba2db6a7ed79d2fb968c2737361a3e18fec7d218f75e89d30143679dc6744dfaL429' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23289882</div><div id='project'> Project Name: yanndubs/lossyless</div><div id='commit'> Commit Name: c8ef0b6b635ba0e212baf30a60596f78e08a56fa</div><div id='time'> Time: 2021-02-22</div><div id='author'> Author: yanndubois96@gmail.com</div><div id='file'> File Name: lossyless/helpers.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: mse_or_crossentropy_loss(4)</div><div id='n_method'> N Method Name: mse_or_crossentropy_loss(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: lossyless/helpers.py</div><div id='n_file'> N File Name: lossyless/helpers.py</div><div id='m_start'> M Start Line: 437</div><div id='m_end'> M End Line: 442</div><div id='n_start'> N Start Line: 444</div><div id='n_end'> N End Line: 465</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        input dimensions: n_samples x time x variables
        
        timesteps = <a id="change">x_cat.size(1</a><a id="change">)</a>  &#47&#47 encode + decode length
        max_encode_length = int(encode_lengths.max())
        embedding_vectors = {int(i): emb(x_cat[..., int(i)]) for i, emb in self.input_embeddings.items()}
        continuous_vectors = {</code></pre><h3>After Change</h3><pre><code class='java'>
        x_cat = torch.cat([x["encoder_cat"], x["decoder_cat"]], dim=1)  &#47&#47 concatenate in time dimension
        x_cont = torch.cat([x["encoder_cont"], x["decoder_cont"]], dim=1)  &#47&#47 concatenate in time dimension
        timesteps = x_cont.size(1)  &#47&#47 encode + decode length
        max_encoder_length<a id="change"> = </a>int(<a id="change">encoder_lengths.max()</a>)
        embedding_vectors = {int(i): emb(x_cat[..., int(i)]) for i, emb in self.input_embeddings.items()}
        continuous_vectors = {
            int(i): lin(x_cont[..., int(i)].view(x_cont.size(0), -1, 1)) for i, lin in self.input_linear.items()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jdb78/pytorch-forecasting/commit/bfd5feb8183d9ece59c1fd40054ef1ef7b8e789c#diff-76ca71ffaeab9ec5eca22b512d1ed2460e8173ce9feb6e881188098900f5f8d4L372' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 23289881</div><div id='project'> Project Name: jdb78/pytorch-forecasting</div><div id='commit'> Commit Name: bfd5feb8183d9ece59c1fd40054ef1ef7b8e789c</div><div id='time'> Time: 2020-07-14</div><div id='author'> Author: beitner.jan@bcg.com</div><div id='file'> File Name: pytorch_forecasting/models/temporal_fusion_transformer/__init__.py</div><div id='m_class'> M Class Name: TemporalFusionTransformer</div><div id='n_method'> N Class Name: TemporalFusionTransformer</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: BaseModel</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: pytorch_forecasting/models/temporal_fusion_transformer/__init__.py</div><div id='n_file'> N File Name: pytorch_forecasting/models/temporal_fusion_transformer/__init__.py</div><div id='m_start'> M Start Line: 373</div><div id='m_end'> M End Line: 383</div><div id='n_start'> N Start Line: 381</div><div id='n_end'> N End Line: 390</div><BR>