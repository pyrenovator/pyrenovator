<html><h3>Pattern ID :31543
</h3><img src='92220255.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    mask = tf.zeros([height, width]).numpy()  &#47&#47 need to assign values
    mask_value = 0  &#47&#47 value is ignored
    for hh_start, hh_end in zip(hh_split[:-1], hh_split[1:]):
        for ww_start, ww_end in zip(ww_split[:-1], <a id="change">ww_split[1:]</a>):
            mask[hh_start:hh_end, ww_start:ww_end] = mask_value
            mask_value += 1
    mask = tf.convert_to_tensor(mask)</code></pre><h3>After Change</h3><pre><code class='java'>
        rr = [tf.zeros([hh, ww_split[id + 1] - ww_split[id]]) + (id + mask_value) for id in range(total_ww)]
        mask.append(tf.concat(rr, axis=-1))
        mask_value += total_ww
    mask = <a id="change">tf.concat(</a>mask<a id="change">, axis=0)</a>
    &#47&#47 return mask

    mask = tf.reshape(mask, [height // window_height, window_height, width // window_width, window_width])
    mask = tf.transpose(mask, [0, 2, 1, 3])</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/bcd22fc3dc9889d71afdf773b78b74d3211754be#diff-24b1f385fb327a5f8149f07df27a49f3739c9d2de68a962cf49726311a2add9bL110' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 92220255</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: bcd22fc3dc9889d71afdf773b78b74d3211754be</div><div id='time'> Time: 2022-04-06</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/swin_transformer_v2/swin_transformer_v2.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: make_window_attention_mask(6)</div><div id='n_method'> N Method Name: make_window_attention_mask(6)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/swin_transformer_v2/swin_transformer_v2.py</div><div id='n_file'> N File Name: keras_cv_attention_models/swin_transformer_v2/swin_transformer_v2.py</div><div id='m_start'> M Start Line: 111</div><div id='m_end'> M End Line: 119</div><div id='n_start'> N Start Line: 110</div><div id='n_end'> N End Line: 118</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        anchors_hw = anchors[:, 2:] - anchors[:, :2]
        anchors_center = (anchors[:, :2] + anchors[:, 2:]) * 0.5

        bboxes_center = <a id="change">preds[:, :2]</a> * anchors_hw + anchors_center
        bboxes_hw = tf.math.exp(preds[:, 2:4]) * anchors_hw

    preds_top_left = bboxes_center - 0.5 * bboxes_hw</code></pre><h3>After Change</h3><pre><code class='java'>
    else:
        preds_top_left = bboxes_center - 0.5 * bboxes_hw
        pred_bottom_right = preds_top_left + bboxes_hw
        return <a id="change">tf.concat(</a>[preds_top_left, pred_bottom_right, preds_others]<a id="change">, axis=-1)</a>


def assign_anchor_classes_by_iou_with_bboxes(bbox_labels, anchors, ignore_threshold=0.4, overlap_threshold=0.5):
    num_anchors = anchors.shape[0]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/0105d064e05e7d2f4ce9d669ffeb8de9c40ef848#diff-0b4f97076caf9c1a827dc3bdff3c0c4eb77d00da49f17542a248e3a2920b42d4L159' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 92220252</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: 0105d064e05e7d2f4ce9d669ffeb8de9c40ef848</div><div id='time'> Time: 2022-03-29</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/coco/anchors_func.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: decode_bboxes(3)</div><div id='n_method'> N Method Name: decode_bboxes(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/coco/anchors_func.py</div><div id='n_file'> N File Name: keras_cv_attention_models/coco/anchors_func.py</div><div id='m_start'> M Start Line: 162</div><div id='m_end'> M End Line: 173</div><div id='n_start'> N Start Line: 159</div><div id='n_end'> N End Line: 179</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            source_pp = source_layer["positional_embedding:0"]  &#47&#47 weights
        else:
            source_pp = source_layer.pp  &#47&#47 layer
        self.pp.assign(tf.image.resize(source_pp, <a id="change">self.pp.shape[1:3]</a>, method=method))

    def show_pos_emb(self, rows=16, base_size=1):
        import matplotlib.pyplot as plt</code></pre><h3>After Change</h3><pre><code class='java'>
            tt = tf.image.resize(ss, [self.height, self.width], method=method)
            tt = tf.reshape(tt, [1, self.height * self.width, -1])

            tt = <a id="change">tf.concat(</a>[source_pp[:, :-hh * ww], tt]<a id="change">, axis=1)</a>  &#47&#47 If has cls_token
        else:
            tt = tf.image.resize(source_pp, [self.height, self.width], method=method)
        self.pp.assign(tt)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/8776edc81f38b435615eee79514c4b7b8b88fc67#diff-70a89c021ce6222b18ca0d8fb02d602b2b15343d3af62a18df1b7034f8955a29L203' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 92220259</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: 8776edc81f38b435615eee79514c4b7b8b88fc67</div><div id='time'> Time: 2023-01-10</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/volo/volo.py</div><div id='m_class'> M Class Name: PositionalEmbedding</div><div id='n_method'> N Class Name: PositionalEmbedding</div><div id='m_method'> M Method Name: load_resized_weights(3)</div><div id='n_method'> N Method Name: load_resized_weights(3)</div><div id='m_parent_class'> M Parent Class: keras.layers.Layer</div><div id='n_parent_class'> N Parent Class: keras.layers.Layer</div><div id='m_file'> M File Name: keras_cv_attention_models/volo/volo.py</div><div id='n_file'> N File Name: keras_cv_attention_models/volo/volo.py</div><div id='m_start'> M Start Line: 209</div><div id='m_end'> M End Line: 209</div><div id='n_start'> N Start Line: 216</div><div id='n_end'> N End Line: 226</div><BR>