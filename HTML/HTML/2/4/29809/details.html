<html><h3>Pattern ID :29809
</h3><img src='88272162.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
def visualize_4_way(cfg):

    &#47&#47 MODELS
    seg_model_path<a id="change">, pred_rgb_model_path, pred_mask_model_path, pred_colorized_mask_model_path</a> = model_paths
    seg_model = torch.load(cfg.seg)
    pred_rgb_model = torch.load(cfg.pred_rgb)
    pred_mask_model = torch.load(cfg.pred_mask)</code></pre><h3>After Change</h3><pre><code class='java'>
    test_data = SynpickVideoDataset(data_dir=data_dir, vid_type=("rgb", 3), num_frames=VIDEO_TOT_LENGTH,
                                    step=4, allow_overlap=VID_DATA_ALLOW_OVERLAP)
    test_loader = DataLoader(test_data, batch_size=1, shuffle=True, num_workers=4)
    iter_loader<a id="change"> = </a>iter(test_loader)

    with torch.no_grad():
        for i in tqdm(range(10)):

            frames = <a id="change">next(</a>iter_loader<a id="change">)</a>.to(DEVICE)  &#47&#47 [1, T, 3, h, w]
            frames_vis = postprocess_img(frames.squeeze(dim=0))  &#47&#47 [T, 3, h, w]
            input = frames[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, 3, h, w]

            pred_rgb = pred_rgb_model.pred_n(input, pred_length=VIDEO_PRED_LENGTH)
            pred_rgb = torch.cat([input, pred_rgb], dim=1)  &#47&#47 [1, T, 3, h, w]
            pred_rgb_vis = postprocess_img(pred_rgb.squeeze(dim=0))  &#47&#47 [T, 3, h, w]

            pred_rgb = torch.stack([seg_model(pred_rgb[:, i]) for i in range(pred_rgb.shape[1])], dim=1)
            pred_rgb = pred_rgb.argmax(dim=2).squeeze()  &#47&#47 [T, h, w]
            pred_then_colorized_vis = colorize_semseg(postprocess_mask(pred_rgb), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2) &#47&#47 [T, 3, h, w]

            frames_seg = torch.stack([seg_model(frames[:, i]) for i in range(frames.shape[1])], dim=1).argmax(dim=2)  &#47&#47 [1, T, 1, h, w]
            frames_seg_in = torch.stack([(frames_seg == i) for i in range(SYNPICK_CLASSES)], dim=2).float()  &#47&#47 [1, T, c, h, w] one-hot float
            input_seg = frames_seg_in[:, :VIDEO_IN_LENGTH]  &#47&#47 [1, t, c, h, w]
            pred_mask = pred_mask_model.pred_n(input_seg, pred_length=VIDEO_PRED_LENGTH).argmax(dim=2)  &#47&#47 [1, n, 1, h, w]
            pred_mask = torch.cat([input_seg.argmax(dim=2), pred_mask], dim=1).squeeze()  &#47&#47 [T, h, w]
            pred_mask_vis = colorize_semseg(postprocess_mask(pred_mask), num_classes=SYNPICK_CLASSES).transpose(0, 3, 1, 2)  &#47&#47 [T, 3, h, w]

            frames_colorized = colorize_semseg(postprocess_mask(frames_seg.squeeze()), num_classes=SYNPICK_CLASSES)
            frames_colorized_vis<a id="change"> = </a>frames_colorized.transpose(0, 3, 1, 2)  &#47&#47 [T, 3, h, w]

            input_colorized = preprocess_img(frames_colorized[:VIDEO_IN_LENGTH]).to(DEVICE).unsqueeze(dim=0)  &#47&#47 [b, t, 3, h, w]
            colorized_then_pred = pred_colorized_mask_model.pred_n(input_colorized, pred_length=VIDEO_PRED_LENGTH)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ais-bonn/vp-suite/commit/13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3#diff-e07d70acfca9139cbf2c37b7a0074bdfbb966d41dc6c7edcc2cef05e78c00af0L16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 88272162</div><div id='project'> Project Name: ais-bonn/vp-suite</div><div id='commit'> Commit Name: 13016d4ab8ba4f8e7ee087155a6c5171f4d00ba3</div><div id='time'> Time: 2021-08-02</div><div id='author'> Author: boltres@ais.uni-bonn.de</div><div id='file'> File Name: scripts/visualize_4_way.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: visualize_4_way(1)</div><div id='n_method'> N Method Name: visualize_4_way(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/visualize_4_way.py</div><div id='n_file'> N File Name: scripts/visualize_4_way.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 73</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 74</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
  def testCifar100CorruptedDatasetShape(self):
    super(Cifar100CorruptedDatasetTest, self)._testDatasetSize(
        ub.datasets.Cifar100CorruptedDataset,
        (32<a id="change">, 32, 3</a>),
        splits=[&quottest&quot],
        corruption_type=&quotbrightness&quot,
        severity=1)</code></pre><h3>After Change</h3><pre><code class='java'>
          split=split,
          corruption_type=&quotbrightness&quot,
          severity=1)
      dataset<a id="change"> = </a>dataset_builder.load(batch_size=bs).take(1)
      element = <a id="change">next(</a>iter(dataset)<a id="change">)</a>
      features = element[&quotfeatures&quot]
      labels = element[&quotlabels&quot]

      features_shape<a id="change"> = </a>features.shape
      labels_shape = labels.shape
      self.assertEqual(features_shape, (bs, 32, 32, 3))
      self.assertEqual(labels_shape, (bs,))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/google/uncertainty-baselines/commit/e71008f3b738c27c13f65a18058ce978d3dd596a#diff-3d7a796f372687a8ff0760f53a608377270c859b4c6fcb088debd7076ed6fd82L27' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 88272167</div><div id='project'> Project Name: google/uncertainty-baselines</div><div id='commit'> Commit Name: e71008f3b738c27c13f65a18058ce978d3dd596a</div><div id='time'> Time: 2021-06-15</div><div id='author'> Author: znado@google.com</div><div id='file'> File Name: uncertainty_baselines/datasets/cifar100_corrupted_test.py</div><div id='m_class'> M Class Name: Cifar100CorruptedDatasetTest</div><div id='n_method'> N Class Name: Cifar100CorruptedDatasetTest</div><div id='m_method'> M Method Name: testCifar100CorruptedDatasetShape(1)</div><div id='n_method'> N Method Name: testCifar100CorruptedDatasetShape(1)</div><div id='m_parent_class'> M Parent Class: parameterized.TestCase</div><div id='n_parent_class'> N Parent Class: parameterized.TestCase,ub.datasets.DatasetTest</div><div id='m_file'> M File Name: uncertainty_baselines/datasets/cifar100_corrupted_test.py</div><div id='n_file'> N File Name: uncertainty_baselines/datasets/cifar100_corrupted_test.py</div><div id='m_start'> M Start Line: 28</div><div id='m_end'> M End Line: 33</div><div id='n_start'> N Start Line: 27</div><div id='n_end'> N End Line: 43</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    assert not args.shuffle

    e<a id="change">, gmaker</a> = training._setup_example_provider_and_grid_maker(args)
    dims = gmaker.grid_dimensions(e.num_types())

    batch_size = 2</code></pre><h3>After Change</h3><pre><code class='java'>

    assert not args.shuffle

    e<a id="change"> = </a>training._setup_example_provider(args.trainfile, args)
    gmaker = training._setup_grid_maker(args)
    dims = gmaker.grid_dimensions(e.num_types())

    batch<a id="change"> = </a><a id="change">next(</a>e<a id="change">)</a>

    grid = torch.zeros((batch_size, *dims), device=device)
    assert not any(grid[grid &gt; 0.0])
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rmeli/gnina-torch/commit/7a941e0e04295d926f71dfa93c12b709aece14fb#diff-fd7aa2fbf7566ac44a21916e334388ecef8f76f037875774b84872b05642884eL108' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 88272151</div><div id='project'> Project Name: rmeli/gnina-torch</div><div id='commit'> Commit Name: 7a941e0e04295d926f71dfa93c12b709aece14fb</div><div id='time'> Time: 2021-11-03</div><div id='author'> Author: rocco.meli@biodtp.ox.ac.uk</div><div id='file'> File Name: gnina/tests/test_training.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_grid_maker(3)</div><div id='n_method'> N Method Name: test_grid_maker(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: gnina/tests/test_training.py</div><div id='n_file'> N File Name: gnina/tests/test_training.py</div><div id='m_start'> M Start Line: 111</div><div id='m_end'> M End Line: 122</div><div id='n_start'> N Start Line: 126</div><div id='n_end'> N End Line: 146</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    )

    &#47&#47 Extract xvectors from a validation sample
    valid_x<a id="change">, valid_y</a> = next(iter(valid_set.get_dataloader()))
    print("Extracting Xvector from a sample validation batch!")
    xvectors = ext_brain.extract(valid_x)
    print("Extracted Xvector.Shape: ", xvectors.shape)</code></pre><h3>After Change</h3><pre><code class='java'>
    )

    &#47&#47 Extract xvectors from a validation sample
    extraction_loader<a id="change"> = </a>sb.data_io.dataloader.make_dataloader(
        hparams["valid_data"], **hparams["loader_kwargs"]
    )
    batch<a id="change"> = </a><a id="change">next(</a>iter(extraction_loader)<a id="change">)</a>
    print("Extracting Xvector from a sample validation batch!")
    xvectors = ext_brain.extract(batch.wav.data, batch.wav.lengths)
    print("Extracted Xvector.Shape: ", xvectors.shape)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/speechbrain/speechbrain/commit/d656bc6618227a593465ff1a507ec955172eb4ac#diff-3e0d114fe5e2550449e8688e4a89f8ceeb73b27cd14c0b2edf1d764984691716L73' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 88272164</div><div id='project'> Project Name: speechbrain/speechbrain</div><div id='commit'> Commit Name: d656bc6618227a593465ff1a507ec955172eb4ac</div><div id='time'> Time: 2020-12-20</div><div id='author'> Author: aku.rouhe@aalto.fi</div><div id='file'> File Name: recipes/minimal_examples/neural_networks/Xvector/example_xvector_experiment.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(0)</div><div id='n_method'> N Method Name: main(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: recipes/minimal_examples/neural_networks/Xvector/example_xvector_experiment.py</div><div id='n_file'> N File Name: recipes/minimal_examples/neural_networks/Xvector/example_xvector_experiment.py</div><div id='m_start'> M Start Line: 91</div><div id='m_end'> M End Line: 106</div><div id='n_start'> N Start Line: 84</div><div id='n_end'> N End Line: 120</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    assert not args.shuffle

    e<a id="change">, gmaker</a> = training._setup_example_provider_and_grid_maker(args)

    batch_size = 2
</code></pre><h3>After Change</h3><pre><code class='java'>
def test_example_provider(trainfile, dataroot, device):
    &#47&#47 Do not shuffle examples randomly when loading the batch
    &#47&#47 This ensures reproducibility
    batch_size<a id="change"> = </a>2
    args = training.options(
        [
            trainfile,
            "-d",
            dataroot,
            "--no_shuffle",
            "--affinity_pos",
            "1",
            "-g",
            str(device),
            "--batch_size",
            str(batch_size),
        ]
    )

    assert not args.shuffle

    e = training._setup_example_provider(args.trainfile, args)

    batch_size = 2

    batch<a id="change"> = </a><a id="change">next(</a>e<a id="change">)</a>

    assert len(batch) == batch_size

    labels = torch.zeros(batch_size, device=device)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rmeli/gnina-torch/commit/7a941e0e04295d926f71dfa93c12b709aece14fb#diff-fd7aa2fbf7566ac44a21916e334388ecef8f76f037875774b84872b05642884eL66' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 88272152</div><div id='project'> Project Name: rmeli/gnina-torch</div><div id='commit'> Commit Name: 7a941e0e04295d926f71dfa93c12b709aece14fb</div><div id='time'> Time: 2021-11-03</div><div id='author'> Author: rocco.meli@biodtp.ox.ac.uk</div><div id='file'> File Name: gnina/tests/test_training.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_example_provider(3)</div><div id='n_method'> N Method Name: test_example_provider(3)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: gnina/tests/test_training.py</div><div id='n_file'> N File Name: gnina/tests/test_training.py</div><div id='m_start'> M Start Line: 69</div><div id='m_end'> M End Line: 88</div><div id='n_start'> N Start Line: 78</div><div id='n_end'> N End Line: 102</div><BR>