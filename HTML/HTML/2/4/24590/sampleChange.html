<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Use lpips_vgg loss as the euclidean distance between the feature representations of a reconstructed image and the reference image.
        lpips_loss = torch.nn.functional.l1_loss(self.features(source), self.features(target))

        <a id="change">return </a>lpips_loss


&#47&#47 Source code reference from `https://github.com/jxgu1016/Total_Variation_Loss.pytorch/blob/master/TVLoss.py`.</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 Keep all parameters in same device.
        self.mean = self.mean.cuda(source.device)
        self.std<a id="change"> = </a><a id="change">self.std.cuda(</a>source.device<a id="change">)</a>

        &#47&#47 Normalize the input image. Default: `ImageNet` dataset.
        source = (source - self.mean) / self.std
        target = (target - self.mean) / self.std

        &#47&#47 Use lpips_vgg loss as the euclidean distance between the feature representations of a reconstructed image and the reference image.
        loss = torch.nn.functional.l1_loss(self.features(source), self.features(target))

        <a id="change">return </a>loss
</code></pre>