<html><h3>Pattern ID :24590
</h3><img src='76304012.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Use lpips_vgg loss as the euclidean distance between the feature representations of a reconstructed image and the reference image.
        lpips_loss = torch.nn.functional.l1_loss(self.features(source), self.features(target))

        <a id="change">return </a>lpips_loss


&#47&#47 Source code reference from `https://github.com/jxgu1016/Total_Variation_Loss.pytorch/blob/master/TVLoss.py`.</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 Keep all parameters in same device.
        self.mean = self.mean.cuda(source.device)
        self.std<a id="change"> = </a><a id="change">self.std.cuda(</a>source.device<a id="change">)</a>

        &#47&#47 Normalize the input image. Default: `ImageNet` dataset.
        source = (source - self.mean) / self.std
        target = (target - self.mean) / self.std

        &#47&#47 Use lpips_vgg loss as the euclidean distance between the feature representations of a reconstructed image and the reference image.
        loss = torch.nn.functional.l1_loss(self.features(source), self.features(target))

        <a id="change">return </a>loss
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 7</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lornatang/srgan-pytorch/commit/cb7301a4fefd5880e7caba3ab7c368e2fe077b89#diff-59a5e918e0d1da40b0cd7d690a00a7179e24f98d00ee0f17844223a2ab450bf2L50' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76304012</div><div id='project'> Project Name: lornatang/srgan-pytorch</div><div id='commit'> Commit Name: cb7301a4fefd5880e7caba3ab7c368e2fe077b89</div><div id='time'> Time: 2021-05-27</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: srgan_pytorch/loss.py</div><div id='m_class'> M Class Name: LPIPSLoss</div><div id='n_method'> N Class Name: LPIPSLoss</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: srgan_pytorch/loss.py</div><div id='n_file'> N File Name: srgan_pytorch/loss.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 52</div><div id='n_start'> N Start Line: 208</div><div id='n_end'> N End Line: 222</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if (torch.sum(torch.isnan(cam_coords)) &gt; 0) or (torch.sum(torch.isinf(cam_coords)) &gt; 0):
            print(&quotWarning: Nan or Inf values in camera coordinate tensor.&quot)

        <a id="change">return </a>cam_coords, valid_points</code></pre><h3>After Change</h3><pre><code class='java'>
        if (torch.sum(torch.isnan(cam_coords)) &gt; 0) or (torch.sum(torch.isinf(cam_coords)) &gt; 0):
            print(&quotWarning: Nan or Inf values in camera coordinate tensor.&quot)

        T_c2_c0<a id="change"> = </a><a id="change">cam_calib[&quotT_c2_c0&quot].unsqueeze(0).expand(batch_size, 4, 4).cuda()</a>
        cam_coords = se3_inv(T_c2_c0).bmm(cam_coords)

        <a id="change">return </a>cam_coords[:, :3, :], valid_points</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/utiasasrl/hero_radar_odometry/commit/c612e851d17258f40a9dde6a641dc127c27fbe7a#diff-a87808e398bbe5556e0bcab7c9a1127424e926136cf458eacb604bb416eefb69L217' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76304013</div><div id='project'> Project Name: utiasasrl/hero_radar_odometry</div><div id='commit'> Commit Name: c612e851d17258f40a9dde6a641dc127c27fbe7a</div><div id='time'> Time: 2020-08-16</div><div id='author'> Author: mona.gridseth@robotics.utias.utoronto.ca</div><div id='file'> File Name: utils/stereo_camera_model.py</div><div id='m_class'> M Class Name: StereoCameraModel</div><div id='n_method'> N Class Name: StereoCameraModel</div><div id='m_method'> M Method Name: inverse_camera_model(4)</div><div id='n_method'> N Method Name: inverse_camera_model(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: utils/stereo_camera_model.py</div><div id='n_file'> N File Name: utils/stereo_camera_model.py</div><div id='m_start'> M Start Line: 239</div><div id='m_end'> M End Line: 239</div><div id='n_start'> N Start Line: 164</div><div id='n_end'> N End Line: 194</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

            mol_vecs = torch.stack(mol_vecs, dim=0)  &#47&#47 num_molecules x hidden

        <a id="change">return </a>mol_vecs  &#47&#47 num_molecules x hidden


class MPN(nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>
            mol_vecs = torch.stack(mol_vecs, dim=0)  &#47&#47 (num_molecules, hidden_size)
        
        semiF_features = np.stack(semiF_features).todense()
        semiF_features<a id="change"> = </a><a id="change">torch.from_numpy(semiF_features).cuda()</a>
        print(semiF_features.size())
        import pdb; pdb.set_trace()
        <a id="change">return </a>torch.cat(mol_vecs, semiF_features, dim=1)  &#47&#47 (num_molecules, hidden_size)


class MPN(nn.Module):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/aamini/chemprop/commit/6cf88ed5105a9529f637bb1e562c94c80e4947a3#diff-91b4e1ef89fbd915183928818e07287d60ba2d013478779025955bb686f6410dL104' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76304014</div><div id='project'> Project Name: aamini/chemprop</div><div id='commit'> Commit Name: 6cf88ed5105a9529f637bb1e562c94c80e4947a3</div><div id='time'> Time: 2018-10-16</div><div id='author'> Author: yangk@mit.edu</div><div id='file'> File Name: mpn.py</div><div id='m_class'> M Class Name: MPNEncoder</div><div id='n_method'> N Class Name: MPNEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: mpn.py</div><div id='n_file'> N File Name: mpn.py</div><div id='m_start'> M Start Line: 287</div><div id='m_end'> M End Line: 287</div><div id='n_start'> N Start Line: 114</div><div id='n_end'> N End Line: 292</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        d2 = 1 / torch.sqrt(d2 + 1e-10)
        D2 = torch.diag_embed(d2)
        L = torch.matmul(torch.matmul(D1, A), D2)
    <a id="change">return </a>L


def generate_adj(A, K,flag=2):</code></pre><h3>After Change</h3><pre><code class='java'>
    d = 1 / torch.sqrt((d + 1e-10))
    D = torch.diag_embed(d)
    L = torch.eye(N,N).cuda()-torch.matmul(torch.matmul(D, A), D)
    Lnorm<a id="change">=</a>(2*L/lmax)-<a id="change">torch.eye(N,N).cuda()</a>
    <a id="change">return </a>Lnorm


def generate_cheby_adj(L, K):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/xueyunlong12589/dgcnn/commit/89b96e07c348bcd980fa5333702ccab46cc46ccb#diff-09d0cbaf891d623ac245ccf84485a687b554217349ca55557c60b33234b969aeL7' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76304015</div><div id='project'> Project Name: xueyunlong12589/dgcnn</div><div id='commit'> Commit Name: 89b96e07c348bcd980fa5333702ccab46cc46ccb</div><div id='time'> Time: 2023-05-02</div><div id='author'> Author: 55629956+xueyunlong12589@users.noreply.github.com</div><div id='file'> File Name: utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: normalize_A(2)</div><div id='n_method'> N Method Name: normalize_A(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: utils.py</div><div id='n_file'> N File Name: utils.py</div><div id='m_start'> M Start Line: 10</div><div id='m_end'> M End Line: 25</div><div id='n_start'> N Start Line: 9</div><div id='n_end'> N End Line: 17</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Use lpips_vgg loss as the euclidean distance between the feature representations of a reconstructed image and the reference image.
        lpips_loss = torch.nn.functional.l1_loss(self.features(source), self.features(target))

        <a id="change">return </a>lpips_loss


&#47&#47 Source code reference from `https://github.com/jxgu1016/Total_Variation_Loss.pytorch/blob/master/TVLoss.py`.</code></pre><h3>After Change</h3><pre><code class='java'>
        target = (target + 1) / 2

        &#47&#47 Keep all parameters in same device.
        self.mean<a id="change"> = </a><a id="change">self.mean.cuda(</a>source.device<a id="change">)</a>
        self.std = self.std.cuda(source.device)

        &#47&#47 Normalize the input image. Default: `ImageNet` dataset.
        source = (source - self.mean) / self.std
        target = (target - self.mean) / self.std

        &#47&#47 Use lpips_vgg loss as the euclidean distance between the feature representations of a reconstructed image and the reference image.
        loss = torch.nn.functional.l1_loss(self.features(source), self.features(target))

        <a id="change">return </a>loss
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/srgan-pytorch/commit/59166c507cb98c3ee82813cc92e08a1f52b954ec#diff-59a5e918e0d1da40b0cd7d690a00a7179e24f98d00ee0f17844223a2ab450bf2L40' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76304011</div><div id='project'> Project Name: lornatang/srgan-pytorch</div><div id='commit'> Commit Name: 59166c507cb98c3ee82813cc92e08a1f52b954ec</div><div id='time'> Time: 2021-05-27</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: srgan_pytorch/loss.py</div><div id='m_class'> M Class Name: LPIPSLoss</div><div id='n_method'> N Class Name: LPIPSLoss</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: srgan_pytorch/loss.py</div><div id='n_file'> N File Name: srgan_pytorch/loss.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 52</div><div id='n_start'> N Start Line: 208</div><div id='n_end'> N End Line: 222</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    for parameter in list(model.parameters()):
        m_parameter = torch.cat((m_parameter, parameter.data.view(-1)))

    <a id="change">return </a>m_parameter[1:]


def unravel_model_params(model, parameter_update):</code></pre><h3>After Change</h3><pre><code class='java'>
    m_parameters = torch.cat(parameters)

    if cuda:
        m_parameters<a id="change"> = </a><a id="change">m_parameters.cuda()</a>

    <a id="change">return </a>m_parameters


def unravel_model_params(model, parameter_update):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/smilelab-fl/fedlab/commit/12925dd3ac83f8a9e1fbd4ed32fb3ec602217a77#diff-3f9658bd0898d77d8d23be9f67b244ede72a902b683904801797bba2c7b6793fL3' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76304018</div><div id='project'> Project Name: smilelab-fl/fedlab</div><div id='commit'> Commit Name: 12925dd3ac83f8a9e1fbd4ed32fb3ec602217a77</div><div id='time'> Time: 2021-04-09</div><div id='author'> Author: 928255708@qq.com</div><div id='file'> File Name: fedlab_core/utils/serialization.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: ravel_model_params(2)</div><div id='n_method'> N Method Name: ravel_model_params(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: fedlab_core/utils/serialization.py</div><div id='n_file'> N File Name: fedlab_core/utils/serialization.py</div><div id='m_start'> M Start Line: 10</div><div id='m_end'> M End Line: 19</div><div id='n_start'> N Start Line: 8</div><div id='n_end'> N End Line: 15</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    detokenizer = VQGanDetokenizer()
    detokenizer.load_state_dict(params)
    image = detokenizer.forward(image_tokens).to(torch.uint8)
    <a id="change">return </a>image.detach().numpy()
    </code></pre><h3>After Change</h3><pre><code class='java'>
    params = load_vqgan_torch_params(model_path)
    detokenizer = VQGanDetokenizer()
    detokenizer.load_state_dict(params)
    if torch.cuda.is_available(): detokenizer<a id="change"> = </a><a id="change">detokenizer.cuda()</a>
    image = detokenizer.forward(image_tokens).to(torch.uint8)
    del detokenizer, params
    <a id="change">return </a>image.to(&quotcpu&quot).detach().numpy()
    </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/kuprel/min-dalle/commit/17c96fe110fad3d48ea591dcd46475f521499770#diff-2097a3af63296c96464c411ba9e0d08e68b60588fb74d007cccb6b31d259c8efL105' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 76304019</div><div id='project'> Project Name: kuprel/min-dalle</div><div id='commit'> Commit Name: 17c96fe110fad3d48ea591dcd46475f521499770</div><div id='time'> Time: 2022-06-28</div><div id='author'> Author: brkuprel@gmail.com</div><div id='file'> File Name: min_dalle/min_dalle_torch.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: detokenize_torch(1)</div><div id='n_method'> N Method Name: detokenize_torch(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: min_dalle/min_dalle_torch.py</div><div id='n_file'> N File Name: min_dalle/min_dalle_torch.py</div><div id='m_start'> M Start Line: 111</div><div id='m_end'> M End Line: 112</div><div id='n_start'> N Start Line: 110</div><div id='n_end'> N End Line: 116</div><BR>