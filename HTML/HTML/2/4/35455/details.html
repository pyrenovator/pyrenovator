<html><h3>Pattern ID :35455
</h3><img src='100643598.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            ]))

    def forward(self, x):
        <a id="change">return </a>self.disc(x)

class Generator(nn.Module):
    def __init__(self, channels_noise, channels_img, features_g):</code></pre><h3>After Change</h3><pre><code class='java'>
        self.tanh = nn.Tanh()

    def forward(self, x):
        batch_size<a id="change"> = </a>x.size(0)
        x0 = self.lrelu(<a id="change">self.conv2d(</a>x<a id="change">)</a>)
        x3 = self.blocks(x0)
        &#47&#47 Flatten
        x3 = x3.view(batch_size, -1)

        &#47&#47 Returning logits to determine whether the images are real or fake
        x4 = self.linear1(x3)

        &#47&#47 Recognition network for latent variables has an additional layer
        encoder = self.lrelu(self.linear2(x3))
        z_prediction = self.tanh(self.linear3(encoder))

        <a id="change">return </a>x4, z_prediction

def truncated_normal_initializer(weight, mean=0, std=0.02):
    size = weight.shape</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ebartrum/lightning_gan_zoo/commit/ada6e3d1398560a9cbcae15a4c5eb1425a2067e0#diff-e937f082a8d32b3054bb1d157aa2b80c6a5063155266c7b79aa2a2ffd71b15cfL50' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 100643598</div><div id='project'> Project Name: ebartrum/lightning_gan_zoo</div><div id='commit'> Commit Name: ada6e3d1398560a9cbcae15a4c5eb1425a2067e0</div><div id='time'> Time: 2021-03-31</div><div id='author'> Author: edward.bartrum@gmail.com</div><div id='file'> File Name: core/models/hologan_discriminator.py</div><div id='m_class'> M Class Name: Discriminator</div><div id='n_method'> N Class Name: Discriminator</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: core/models/hologan_discriminator.py</div><div id='n_file'> N File Name: core/models/hologan_discriminator.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 50</div><div id='n_start'> N Start Line: 57</div><div id='n_end'> N End Line: 70</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        return weights * scale - shift
        
    def forward(self, x, eps=1e-4):
        weights<a id="change"> = </a>self.standardized_weights(eps)
        <a id="change">return </a>super()._conv_forward(x, weights)

class SqueezeExcite(nn.Module):
    def __init__(self, in_channels, out_channels, se_ratio=0.5):</code></pre><h3>After Change</h3><pre><code class='java'>
        return (self.weight - mean) * scale
        
    def forward(self, x):
        <a id="change">return </a><a id="change">F.conv2d(
            input=x,
            weight=self.standardized_weights(),
            bias=self.bias,
            stride=self.stride,
            padding=self.padding,
            dilation=self.dilation,
            groups=self.groups
        )</a>

class SqueezeExcite(nn.Module):
    def __init__(self, in_channels, out_channels, se_ratio=0.5):
        super(SqueezeExcite, self).__init__()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/benjs/nfnets_pytorch/commit/418101c197b12e698637507137b1fdcbde268d5d#diff-fada037ad086638e65c7ae77e3d223963e9afaa26326aab0ea718f4013176e43L213' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 100643594</div><div id='project'> Project Name: benjs/nfnets_pytorch</div><div id='commit'> Commit Name: 418101c197b12e698637507137b1fdcbde268d5d</div><div id='time'> Time: 2021-02-16</div><div id='author'> Author: benjs@benjs.de</div><div id='file'> File Name: model.py</div><div id='m_class'> M Class Name: WSConv2D</div><div id='n_method'> N Class Name: WSConv2D</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Conv2d</div><div id='n_parent_class'> N Parent Class: nn.Conv2d</div><div id='m_file'> M File Name: model.py</div><div id='n_file'> N File Name: model.py</div><div id='m_start'> M Start Line: 213</div><div id='m_end'> M End Line: 215</div><div id='n_start'> N Start Line: 214</div><div id='n_end'> N End Line: 222</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def forward(self, x):
        real, imag = x.unbind(dim = 1)
        new_real = self.conv_real(real) - self.conv_imag(imag)
        new_imag<a id="change"> = </a>self.conv_real(imag) + self.conv_imag(real)
        <a id="change">return </a>torch.stack((new_real, new_imag), dim = 1)

def complex_abs(t, dim = 1, eps = 1e-8):
    real, imag = t.unbind(dim = 1)</code></pre><h3>After Change</h3><pre><code class='java'>

    def forward(self, x):
        weight, bias = map(torch.view_as_complex, (self.weight, self.bias))
        <a id="change">return </a><a id="change">F.conv2d(</a>x, weight, bias<a id="change">, stride = self.stride, padding = self.padding)</a>

def ComplexSTFTResidualUnit(chan_in, chan_out, strides):
    kernel_sizes = tuple(map(lambda t: t + 2, strides))
    paddings = tuple(map(lambda t: t // 2, kernel_sizes))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/audiolm-pytorch/commit/cb442af8bf09890219f2fa6bf7081042a65c2710#diff-7e2ef88e24ccc344bf6eeeefc84a9daf25616a49d07c7bfd0473b3e039909de4L228' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 100643593</div><div id='project'> Project Name: lucidrains/audiolm-pytorch</div><div id='commit'> Commit Name: cb442af8bf09890219f2fa6bf7081042a65c2710</div><div id='time'> Time: 2023-02-07</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: audiolm_pytorch/soundstream.py</div><div id='m_class'> M Class Name: ComplexConv2d</div><div id='n_method'> N Class Name: ComplexConv2d</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: audiolm_pytorch/soundstream.py</div><div id='n_file'> N File Name: audiolm_pytorch/soundstream.py</div><div id='m_start'> M Start Line: 229</div><div id='m_end'> M End Line: 232</div><div id='n_start'> N Start Line: 151</div><div id='n_end'> N End Line: 152</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            exp_features.append(self.lambd_sp * sparse_feat + \
                                self.lambd_sm * smooth_feat + \
                                self.lambd_pe * persist_feat)
        <a id="change">return </a>torch.median(exp_features)</code></pre><h3>After Change</h3><pre><code class='java'>

    def cal_explanation_feature(self, saliency_maps: torch.Tensor) -&gt; float:
        sparse_feats = saliency_maps.flatten(start_dim=1).norm(p=1)    &#47&#47 (N)
        smooth_feats = <a id="change">self.conv2d(</a>saliency_maps<a id="change">)</a>.flatten(start_dim=1).norm(p=1)    &#47&#47 (N)
        persist_feats<a id="change"> = </a>0.0  &#47&#47 todo (N)

        exp_feats = self.lambd_sp * sparse_feats + self.lambd_sm * smooth_feats + self.lambd_pe * persist_feats
        <a id="change">return </a>exp_feats.median()
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ain-soph/trojanzoo/commit/afe7bbd2d2e9f901ee8cf56c3b9320b9272a81af#diff-5528b4636bddd4d9ccc9486227970324e4344e01059ddca8b9863336ce85d70cL67' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 100643605</div><div id='project'> Project Name: ain-soph/trojanzoo</div><div id='commit'> Commit Name: afe7bbd2d2e9f901ee8cf56c3b9320b9272a81af</div><div id='time'> Time: 2020-07-22</div><div id='author'> Author: ain-soph@live.com</div><div id='file'> File Name: trojanzoo/defense/backdoor/neuron_inspect.py</div><div id='m_class'> M Class Name: Neuron_Inspect</div><div id='n_method'> N Class Name: Neuron_Inspect</div><div id='m_method'> M Method Name: cal_explanation_feature(2)</div><div id='n_method'> N Method Name: cal_explanation_feature(2)</div><div id='m_parent_class'> M Parent Class: Defense_Backdoor</div><div id='n_parent_class'> N Parent Class: Defense_Backdoor</div><div id='m_file'> M File Name: trojanzoo/defense/backdoor/neuron_inspect.py</div><div id='n_file'> N File Name: trojanzoo/defense/backdoor/neuron_inspect.py</div><div id='m_start'> M Start Line: 68</div><div id='m_end'> M End Line: 84</div><div id='n_start'> N Start Line: 68</div><div id='n_end'> N End Line: 73</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            padding = self.padding
        )
        if self.use_bias:
            conv<a id="change"> = </a>torch.add(conv, self.b * self.b_mask)
        
        <a id="change">return </a>conv
</code></pre><h3>After Change</h3><pre><code class='java'>
    
    def forward(self, inputs):
        if not self.use_bias:
            <a id="change">return </a><a id="change">torch.nn.functional.conv2d(
                </a>inputs,
                self.w * self.w_mask,
                self.b * self.b_mask<a id="change">,
                stride = self.strides,
                padding = self.padding
            )</a>
        else:
            return torch.nn.functional.conv2d(
                inputs,
                self.w * self.w_mask,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/beyond-ml-labs/beyondml/commit/9408cec7f3cf593fe6a1a99aaaccd6cd964a1810#diff-3cdfe06b7d7afe91ca1fa3efe060af62a141aeb300fe3e29f316474de0d5bea6L70' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 100643603</div><div id='project'> Project Name: beyond-ml-labs/beyondml</div><div id='commit'> Commit Name: 9408cec7f3cf593fe6a1a99aaaccd6cd964a1810</div><div id='time'> Time: 2022-06-01</div><div id='author'> Author: 77127228+jacobrenn@users.noreply.github.com</div><div id='file'> File Name: mann/burning/layers/MaskedConv2D.py</div><div id='m_class'> M Class Name: MaskedConv2D</div><div id='n_method'> N Class Name: MaskedConv2D</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: mann/burning/layers/MaskedConv2D.py</div><div id='n_file'> N File Name: mann/burning/layers/MaskedConv2D.py</div><div id='m_start'> M Start Line: 71</div><div id='m_end'> M End Line: 80</div><div id='n_start'> N Start Line: 71</div><div id='n_end'> N End Line: 85</div><BR>