<html><h3>Pattern ID :29503
</h3><img src='87510481.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                    etree.HTML(resp.text).xpath("//div[@class=&quotresult&quot]/ul//li/a/text()"),
                )
            )
        _HS_SYMBOLS = sorted(<a id="change">list(</a>_res<a id="change">)</a>)
    return _HS_SYMBOLS

</code></pre><h3>After Change</h3><pre><code class='java'>

        symbol_cache_path = Path("~/.cache/hs_symbols_cache.pkl").expanduser().resolve()
        symbol_cache_path.parent.mkdir(parents=True, exist_ok=True)
        <a id="change">if </a>symbol_cache_path.exists():
            with symbol_cache_path.open("rb") as fp:
                cache_symbols = <a id="change">pickle.load(</a>fp<a id="change">)</a>
                symbols<a id="change"> |= </a>cache_symbols
        with symbol_cache_path.open("wb") as fp:
            pickle.dump(symbols, fp)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/microsoft/qlib/commit/5bca9d892aad7e59e44e4f4f522675c435b874c5#diff-5028716407720ea33d7e0fa3921ac328c29103dd0822f7102c648ff8edbf0481L57' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87510481</div><div id='project'> Project Name: microsoft/qlib</div><div id='commit'> Commit Name: 5bca9d892aad7e59e44e4f4f522675c435b874c5</div><div id='time'> Time: 2020-10-20</div><div id='author'> Author: zhu.pengrong@foxmail.com</div><div id='file'> File Name: scripts/data_collector/utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: get_hs_stock_symbols(0)</div><div id='n_method'> N Method Name: get_hs_stock_symbols(0)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/data_collector/utils.py</div><div id='n_file'> N File Name: scripts/data_collector/utils.py</div><div id='m_start'> M Start Line: 57</div><div id='m_end'> M End Line: 68</div><div id='n_start'> N Start Line: 80</div><div id='n_end'> N End Line: 99</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            process_list[-1].start()
        for process in process_list:
            process.join()
        self.list_of_eligible_wave_paths = <a id="change">list(</a>self.list_of_eligible_wave_paths<a id="change">)</a>
        self.waves = list()
        for path in tqdm(self.list_of_eligible_wave_paths):
            with open(path, "rb") as audio_file:
                wave_orig, _ = sf.read(audio_file)</code></pre><h3>After Change</h3><pre><code class='java'>
        self.desired_samplingrate = desired_samplingrate
        self.melspec_ap = AudioPreprocessor(input_sr=desired_samplingrate, output_sr=16000, melspec_buckets=80, hop_length=256, n_fft=1024, cut_silence=False)

        <a id="change">if </a>not os.path.exists(os.path.join(cache_dir, "waves.pt")):
            &#47&#47 hop length of spec loss must be same as the product of the upscale factors
            &#47&#47 samples per segment must be a multiple of hop length of spec loss
            _, self._orig_sr = sf.read(list_of_paths[0])
            &#47&#47  ^ this is the reason why we must create individual
            &#47&#47 datasets and then concat them. If we just did all
            &#47&#47 datasets at once, there could be multiple sampling
            &#47&#47 rates.
            resource_manager = Manager()
            self.waves = resource_manager.list()
            &#47&#47 make processes
            path_splits = list()
            process_list = list()
            for i in range(loading_processes):
                path_splits.append(list_of_paths[i * len(list_of_paths) // loading_processes:(i + 1) * len(list_of_paths) // loading_processes])
            for path_split in path_splits:
                process_list.append(Process(target=self.cache_builder_process, args=(path_split,), daemon=True))
                process_list[-1].start()
            for process in process_list:
                process.join()
            numpy_waves = list(self.waves)
            self.waves = list()
            for wave in numpy_waves:
                self.waves.append(torch.tensor(wave))
            torch.save(self.waves, os.path.join(cache_dir, "waves.pt"))
        else:
            self.waves<a id="change"> = </a><a id="change">torch.load(</a>os.path.join(cache_dir, "waves.pt")<a id="change">, map_location=&quotcpu&quot)</a>

        print("{} eligible audios found".format(len(self.waves)))

    def cache_builder_process(self, path_split):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/c762d97e04a62c8f3d839cc12c1f3c2b375bde9e#diff-56f51c307d53159c7cba2dab62c76f72ee2ed8cc56a0bbf8408982c5401993e5L15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87510478</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: c762d97e04a62c8f3d839cc12c1f3c2b375bde9e</div><div id='time'> Time: 2021-10-28</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Spectrogram_to_Wave/HiFIGAN/HiFiGANDataset.py</div><div id='m_class'> M Class Name: HiFiGANDataset</div><div id='n_method'> N Class Name: HiFiGANDataset</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TrainingInterfaces/Spectrogram_to_Wave/HiFIGAN/HiFiGANDataset.py</div><div id='n_file'> N File Name: TrainingInterfaces/Spectrogram_to_Wave/HiFIGAN/HiFiGANDataset.py</div><div id='m_start'> M Start Line: 23</div><div id='m_end'> M End Line: 49</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 54</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                os.makedirs(os.path.join(cache_dir, "durations_visualization"))
            resource_manager = Manager()
            self.path_to_transcript_dict = path_to_transcript_dict
            key_list = <a id="change">list(</a>self.path_to_transcript_dict.keys()<a id="change">)</a>
            &#47&#47 build cache
            print("... building dataset cache ...")
            self.datapoints = resource_manager.list()
            &#47&#47 make processes</code></pre><h3>After Change</h3><pre><code class='java'>
                                rebuild_cache=rebuild_cache)
            datapoints = torch.load(os.path.join(cache_dir, "taco_train_cache.pt"), map_location=&quotcpu&quot)
            &#47&#47 we use the tacotron dataset as basis and augment it to contain the additional information we need for fastspeech.
            <a id="change">if </a>not isinstance(self.datapoints, tuple):  &#47&#47 check for backwards compatibility
                TacotronDataset(path_to_transcript_dict=path_to_transcript_dict,
                                cache_dir=cache_dir,
                                lang=lang,
                                speaker_embedding=speaker_embedding,
                                loading_processes=loading_processes,
                                device=device,
                                min_len_in_seconds=min_len_in_seconds,
                                max_len_in_seconds=max_len_in_seconds,
                                cut_silences=cut_silence,
                                rebuild_cache=True)
                datapoints<a id="change"> = </a><a id="change">torch.load(</a>os.path.join(cache_dir, "taco_train_cache.pt")<a id="change">, map_location=&quotcpu&quot)</a>
            dataset = datapoints[0]
            norm_waves = datapoints[1]

            resource_manager = Manager()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/d75af2f091227a4695d4887a9a8f23dc5d22b12b#diff-528f1d1f9b65f826c6eec25f3934452fe1a81965d76a0070a71db9ef9ef36aa0L22' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 87510475</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: d75af2f091227a4695d4887a9a8f23dc5d22b12b</div><div id='time'> Time: 2021-09-15</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='m_class'> M Class Name: FastSpeechDataset</div><div id='n_method'> N Class Name: FastSpeechDataset</div><div id='m_method'> M Method Name: __init__(13)</div><div id='n_method'> N Method Name: __init__(13)</div><div id='m_parent_class'> M Parent Class: Dataset</div><div id='n_parent_class'> N Parent Class: Dataset</div><div id='m_file'> M File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='n_file'> N File Name: TrainingInterfaces/Text_to_Spectrogram/FastSpeech2/FastSpeechDataset.py</div><div id='m_start'> M Start Line: 36</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 36</div><div id='n_end'> N End Line: 109</div><BR>