<html><h3>Pattern ID :10231
</h3><img src='36013389.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        mask = torch.Tensor([[x is not None for x in lb] for lb in label_batch])
        labels = [[0 if x is None else x for x in lb] for lb in label_batch]
        <a id="change">if </a>scaler is not None:
            labels = scaler.transform(labels)  &#47&#47 subtract mean, divide by std
        labels = torch.Tensor(labels)
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 Log and/or add to tensorboard
        if (n_iter // args.batch_size) % args.log_frequency == 0 and (logger is not None or writer is not None):
            lr<a id="change"> = </a>scheduler.get_lr()[0]
            pnorm = compute_pnorm(model)
            gnorm = compute_gnorm(model)
            loss_avg = loss_sum / iter_count
            loss_sum, iter_count = 0, 0

            if logger is not None:
                logger.debug("Loss = {:.4e}, PNorm = {:.4f}, GNorm = {:.4f}, lr = {:.4f}".format(loss_avg, pnorm, gnorm, lr))

            if writer is not None:
                writer.add_scalar(&quottrain_loss&quot, loss_avg, n_iter)
                writer.add_scalar(&quotparam_norm&quot, pnorm, n_iter)
                writer.add_scalar(&quotgradient_norm&quot, gnorm, n_iter)
                <a id="change">writer.add_scalar(&quotlearning_rate&quot</a>, lr, n_iter<a id="change">)</a>

    return n_iter

</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/aamini/chemprop/commit/64f98d60d13bc4bd7131ea4453b03163503cce0c#diff-1ae5c6142982c466b6120408cea60c9e765c62ef258032b838fb5274077b166dL23' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 36013389</div><div id='project'> Project Name: aamini/chemprop</div><div id='commit'> Commit Name: 64f98d60d13bc4bd7131ea4453b03163503cce0c</div><div id='time'> Time: 2018-10-02</div><div id='author'> Author: swansonk.14@gmail.com</div><div id='file'> File Name: train_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(9)</div><div id='n_method'> N Method Name: train(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: train_utils.py</div><div id='n_file'> N File Name: train_utils.py</div><div id='m_start'> M Start Line: 24</div><div id='m_end'> M End Line: 54</div><div id='n_start'> N Start Line: 23</div><div id='n_end'> N End Line: 96</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    trainer.train()

    &#47&#47 TODO eval
    <a id="change">if </a>test_loader is not None and False:
        accuracy = 0

        if cfg.tensorboard:</code></pre><h3>After Change</h3><pre><code class='java'>
        evaluator = Evaluator(
            model=model, device=device, loader=test_loader, checkpoint_path=None
        )
        accuracy<a id="change"> = </a>evaluator.evaluate()

        if writer:
            <a id="change">writer.add_scalar("Eval/Accuracy/test"</a>, accuracy, -1<a id="change">)</a>

        if cfg.tensorboard:
            res_path = hydra.utils.to_absolute_path(f"results/{cfg.dataset.name}/")
            params = flatten(OmegaConf.to_container(cfg, resolve=True))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/dmizr/phuber/commit/80dbdb78ffe74a8f044fe89aa0ece1153514a0c4#diff-0486a3c469cb2619e864104b3bd3f8f59ba96a7e18629088c35e6a2b1e9e7389L18' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 36013388</div><div id='project'> Project Name: dmizr/phuber</div><div id='commit'> Commit Name: 80dbdb78ffe74a8f044fe89aa0ece1153514a0c4</div><div id='time'> Time: 2020-11-27</div><div id='author'> Author: david.mizrahi@epfl.ch</div><div id='file'> File Name: phuber/runner.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train(1)</div><div id='n_method'> N Method Name: train(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: phuber/runner.py</div><div id='n_file'> N File Name: phuber/runner.py</div><div id='m_start'> M Start Line: 71</div><div id='m_end'> M End Line: 80</div><div id='n_start'> N Start Line: 22</div><div id='n_end'> N End Line: 94</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            writer.add_scalar(&quot../record/Accuracy/train_ner_f1&quot, f1_ner_total/self.num_sample_total*self.config.batch_size, epoch)
            writer.add_scalar(&quot../record/Accuracy/train_rel_ps&quot, correct_score_total / len(self.train_dataset), epoch)
            
            <a id="change">if </a>(epoch+1) % 1 == 0:
                self.evaluate()
            if epoch &gt; 16 and f1_ner_total &gt; f1_ner_total_best:
                torch.save({</code></pre><h3>After Change</h3><pre><code class='java'>
            ner_loss_final_train = loss_ner_total/self.num_sample_total
            rel_loss_final_train = loss_rel_total/self.num_sample_total
            f1_ner_final_train = f1_ner_total/self.num_sample_total*self.config.batch_size
            precision_score_final_train<a id="change"> = </a>correct_score_total / len(self.train_dataset)
            print("train ner loss: {0}, rel loss: {1}, f1 score: {2}, precission score: {3}".format(ner_loss_final_train, rel_loss_final_train,
                    f1_ner_final_train, precision_score_final_train))
            &#47&#47 pbar.set_description(&quotTRAIN LOSS: {}&quot.format(loss_total/self.num_sample_total))
            
            &#47&#47 neptune 记录代码
            &#47&#47 neptune.log_metric("train ner loss", loss_ner_total/self.num_sample_total)
            &#47&#47 neptune.log_metric("train ner f1 score", f1_ner_total/self.num_sample_total*self.config.batch_size)
            &#47&#47 neptune.log_metric("train rel precission score", correct_score_total / len(self.train_dataset))

            &#47&#47 tensorboard 记录代码
            writer.add_scalar(&quotLoss/train_ner_loss&quot, ner_loss_final_train, epoch)
            writer.add_scalar(&quotAccuracy/train_rel_loss&quot, rel_loss_final_train, epoch)
            writer.add_scalar(&quotAccuracy/train_ner_f1&quot, f1_ner_final_train, epoch)
            <a id="change">writer.add_scalar(&quotAccuracy/train_rel_    ps&quot</a>, precision_score_final_train, epoch<a id="change">)</a>
            if (epoch+1) % 1 == 0:
                self.predict_sample()
            if (epoch+1) % 1 == 0:
                ner_loss_final_eval, rel_loss_final_eval, f1_ner_final_eval, precision_score_final_eval = self.evaluate()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mangonihao/multiheadjointentityrelationextraction_simple/commit/f3cd70fea333102bb4705e0b92cee42d8a1a6a41#diff-075d5e201e6fa33310a0829d04f69714642c915794e8b2dfaacd31c8d32e0a3fL82' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 36013385</div><div id='project'> Project Name: mangonihao/multiheadjointentityrelationextraction_simple</div><div id='commit'> Commit Name: f3cd70fea333102bb4705e0b92cee42d8a1a6a41</div><div id='time'> Time: 2021-04-07</div><div id='author'> Author: 2075419247@qq.com</div><div id='file'> File Name: mains/trainer.py</div><div id='m_class'> M Class Name: Trainer</div><div id='n_method'> N Class Name: Trainer</div><div id='m_method'> M Method Name: train(1)</div><div id='n_method'> N Method Name: train(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: mains/trainer.py</div><div id='n_file'> N File Name: mains/trainer.py</div><div id='m_start'> M Start Line: 84</div><div id='m_end'> M End Line: 127</div><div id='n_start'> N Start Line: 84</div><div id='n_end'> N End Line: 138</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def on_log(self, args, state, control, logs=None, **kwargs):
        if state.is_local_process_zero:
            if isinstance(logs, dict):
                <a id="change">if </a>self.mode == &quottrain&quot:
                    logs[&quotstep&quot] = state.global_step
                    logs[&quottrain_loss&quot] = logs.pop(&quotloss&quot, None)  &#47&#47 Trainer internal uses `loss`, instead of `train_loss`
                    logs = self.out_dict2str(logs)</code></pre><h3>After Change</h3><pre><code class='java'>
                    &#47&#47 Trainer internal uses `loss`, instead of `train_loss`
                    logs[&quottrain_loss&quot] = loss = logs.pop(&quotloss&quot, None)
                    assert loss is not None
                    lr<a id="change"> = </a>logs[&quotlearning_rate&quot]
                    self.writer.add_scalar(&quotTrain/loss&quot, loss, step)
                    <a id="change">self.writer.add_scalar(&quotTrain/learning_rate&quot</a>, lr, step<a id="change">)</a>
                    logs = self.out_dict2str(logs)
                else:
                    logs = log_dict(logs)
            self.logger.info(logs)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stefanheng/symbolic-music-generation/commit/c3c9ff076680751481754b5d0e5f5c5599ce1136#diff-3ed359f79d5eaf00ee67f5c9b85cc9e57797840c915865dda929f227d15dc7aeL78' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 36013384</div><div id='project'> Project Name: stefanheng/symbolic-music-generation</div><div id='commit'> Commit Name: c3c9ff076680751481754b5d0e5f5c5599ce1136</div><div id='time'> Time: 2022-02-26</div><div id='author'> Author: 43276957+SpongeBobBang@users.noreply.github.com</div><div id='file'> File Name: musicnlp/util/train.py</div><div id='m_class'> M Class Name: ColoredPrinterCallback</div><div id='n_method'> N Class Name: ColoredPrinterCallback</div><div id='m_method'> M Method Name: on_log(5)</div><div id='n_method'> N Method Name: on_log(5)</div><div id='m_parent_class'> M Parent Class: TrainerCallback</div><div id='n_parent_class'> N Parent Class: TrainerCallback</div><div id='m_file'> M File Name: musicnlp/util/train.py</div><div id='n_file'> N File Name: musicnlp/util/train.py</div><div id='m_start'> M Start Line: 81</div><div id='m_end'> M End Line: 87</div><div id='n_start'> N Start Line: 160</div><div id='n_end'> N End Line: 171</div><BR>