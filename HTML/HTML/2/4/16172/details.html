<html><h3>Pattern ID :16172
</h3><img src='54080121.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            mean_entity = mean_entity / (real_number)
            tensor_list.append(mean_entity.reshape(1, -1))
        tensor_mean = torch.cat(tensor_list, dim=0)
        <a id="change">print(&quottensor_mean:&quot</a>, tensor_mean<a id="change">)</a> if debug else None

        &#47&#47 print(&quotout.shape:&quot, out.shape) if debug else None
        &#47&#47 out = out[:, :self.real_entities_size, :]</code></pre><h3>After Change</h3><pre><code class='java'>
        print(&quotmask.shape:&quot, mask.shape) if debug else None

        &#47&#47 mask: [batch_size, max_entities]
        device = next(<a id="change">self.parameters()</a>).device
        mask = mask.to(device)

        &#47&#47 assert the input shape is : batch_seq_size x entities_size x embeding_size
        &#47&#47 note: because the feature size of entity is not equal to 256, so it can not fed into transformer directly.
        &#47&#47 thus, we add a embedding layer to transfer it to right size.
        &#47&#47 x is batch_entities_tensor (dim = 3). Shape: batch_seq_size x entities_size x embeding_size
        x = self.embedd(x)
        print(&quotx.shape:&quot, x.shape) if debug else None

        &#47&#47 mask for transformer need a special format
        mask_seq_len = mask.shape[-1]
        tran_mask<a id="change"> = </a>mask.unsqueeze(1)

        &#47&#47 tran_mask: [batch_seq_size x max_entities x max_entities]
        tran_mask = tran_mask.repeat(1, mask_seq_len, 1)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/liuruoze/mini-alphastar/commit/612d42a7bf5ef827e1e919198d839fce106155cd#diff-71869e70f9cb835282d541d2d3529d25b6ed6795c79bc770e860e9318619f6b1L716' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 54080121</div><div id='project'> Project Name: liuruoze/mini-alphastar</div><div id='commit'> Commit Name: 612d42a7bf5ef827e1e919198d839fce106155cd</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: liuruoze@163.com</div><div id='file'> File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_class'> M Class Name: EntityEncoder</div><div id='n_method'> N Class Name: EntityEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='n_file'> N File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_start'> M Start Line: 721</div><div id='m_end'> M End Line: 758</div><div id='n_start'> N Start Line: 716</div><div id='n_end'> N End Line: 778</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        pred_model = CopyLastFrameModel()
        cfg.no_train = True

    <a id="change">print(f"Model parameters: {sum(p.numel() for p in pred_model.parameters() if p.requires_grad)}"</a><a id="change">)</a>
    return pred_model.to(device)


def test():</code></pre><h3>After Change</h3><pre><code class='java'>
        pred_model = CopyLastFrameModel()
        cfg.no_train = True

    total_params<a id="change"> = </a>sum(p.numel() for p in <a id="change">pred_model.parameters()</a>)
    trainable_params = sum(p.numel() for p in pred_model.parameters() if p.requires_grad)
    print(f"Model parameters (total / trainable): {total_params} / {trainable_params}")
    return pred_model.to(device)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ais-bonn/vp-suite/commit/37a5c1ea6626a949bb3d67098723c1e14a8d15d7#diff-5452bb2a56a7b53674b2bf54da1e5c6a0efdf22153b1d64ca469e05e592148edL15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 54080139</div><div id='project'> Project Name: ais-bonn/vp-suite</div><div id='commit'> Commit Name: 37a5c1ea6626a949bb3d67098723c1e14a8d15d7</div><div id='time'> Time: 2021-09-13</div><div id='author'> Author: boltres@ais.uni-bonn.de</div><div id='file'> File Name: models/prediction/pred_model_factory.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: get_pred_model(4)</div><div id='n_method'> N Method Name: get_pred_model(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: models/prediction/pred_model_factory.py</div><div id='n_file'> N File Name: models/prediction/pred_model_factory.py</div><div id='m_start'> M Start Line: 44</div><div id='m_end'> M End Line: 44</div><div id='n_start'> N Start Line: 44</div><div id='n_end'> N End Line: 46</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
		r0 = ws_layer.r.clone()
		tau0 = ws_layer.tau.clone()
		ratio_sign_0 = np.mean(torch.sign(ws_layer.forward_sign).detach().cpu().numpy())
		<a id="change">print(f"ratio exec init: {(ratio_sign_0 + 1)/2 :.3f}"</a><a id="change">)</a>

	dataset = WSDataset(true_time_series.T)
	trainer = nt.trainers.RegressionTrainer(
		model,</code></pre><h3>After Change</h3><pre><code class='java'>
	regularisation = ExecRatioTargetRegularization(ws_layer.get_sign_parameters(), exec_target_ratio=0.8)

	optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, maximize=True, weight_decay=0.01)
	optimizer_reg<a id="change"> = </a>torch.optim.Adam(<a id="change">regularisation.parameters()</a>, lr=5e-3)
	criterion = nn.MSELoss()

	checkpoint_manager = nt.CheckpointManager(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/neurotorch/neurotorch/commit/a19976d80f57c54d66a936925f12b6f25f452bb8#diff-e31dfb803054ad8b9ad37669aa0e99a39f2b2c4ab68968f270d1eaa215976e96L21' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 54080138</div><div id='project'> Project Name: neurotorch/neurotorch</div><div id='commit'> Commit Name: a19976d80f57c54d66a936925f12b6f25f452bb8</div><div id='time'> Time: 2022-09-28</div><div id='author'> Author: 50332514+JeremieGince@users.noreply.github.com</div><div id='file'> File Name: tutorials/time_series_forecasting_wilson_cowan/main_dale.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: train_with_params(20)</div><div id='n_method'> N Method Name: train_with_params(20)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tutorials/time_series_forecasting_wilson_cowan/main_dale.py</div><div id='n_file'> N File Name: tutorials/time_series_forecasting_wilson_cowan/main_dale.py</div><div id='m_start'> M Start Line: 45</div><div id='m_end'> M End Line: 152</div><div id='n_start'> N Start Line: 51</div><div id='n_end'> N End Line: 168</div><BR>