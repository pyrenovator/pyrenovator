<html><h3>Pattern ID :10790
</h3><img src='37160647.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            Z = self.model(X)
            loss = F.mse_loss(Z, y)
            self.optimizer.zero_grad()
            <a id="change">loss.backward()</a>
            self.optimizer.step()
            total_loss += loss.item()
        self.model.eval()
        total_score = 0.0</code></pre><h3>After Change</h3><pre><code class='java'>
            Z = self.model(X)
            self.optimizer.zero_grad()
            device = Z.device
            loss_val<a id="change"> = </a>torch.tensor(
                0.0,
                dtype=torch.float32,
                device=device,
            )
            for (i, loss) in enumerate(self.losses):
                weight = self.weight_per_loss[i]
                loss_val += weight * loss(Z, y)
            loss_val.backward()
            self.optimizer.step()
            total_loss_val<a id="change"> += </a><a id="change">loss_val.item()</a>
        self.model.eval()
        total_score = 0.0
        for (X, y) in tqdm(self.val_dataloader):
            Z = self.model(X)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/takuyashintate/tsts/commit/f6b4e65e1ac0679b4951c401c8e2504e4fde4c4a#diff-38852a333fabc2d9fd8c03e25fb7cb67a9c31d255cc4c9f612c65b9ce2ed52e3L51' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 37160647</div><div id='project'> Project Name: takuyashintate/tsts</div><div id='commit'> Commit Name: f6b4e65e1ac0679b4951c401c8e2504e4fde4c4a</div><div id='time'> Time: 2021-08-17</div><div id='author'> Author: kmdbn2hs@gmail.com</div><div id='file'> File Name: tsts/trainers/trainer.py</div><div id='m_class'> M Class Name: SupervisedTrainer</div><div id='n_method'> N Class Name: SupervisedTrainer</div><div id='m_method'> M Method Name: step(1)</div><div id='n_method'> N Method Name: step(1)</div><div id='m_parent_class'> M Parent Class: Trainer</div><div id='n_parent_class'> N Parent Class: Trainer</div><div id='m_file'> M File Name: tsts/trainers/trainer.py</div><div id='n_file'> N File Name: tsts/trainers/trainer.py</div><div id='m_start'> M Start Line: 51</div><div id='m_end'> M End Line: 58</div><div id='n_start'> N Start Line: 61</div><div id='n_end'> N End Line: 76</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            loss = self.criterion(estimated_sources_amplitude, sources)

            self.optimizer.zero_grad()
            <a id="change">loss.backward()</a>
            
            if self.max_norm:
                nn.utils.clip_grad_norm_(self.model.parameters(), self.max_norm)
            </code></pre><h3>After Change</h3><pre><code class='java'>
                    s += " {:.5f}".format(mean_loss.item())
                else:
                    for idx, target in enumerate(self.sources):
                        loss_target<a id="change"> = </a>loss[idx]
                        s<a id="change"> += </a>" ({}) {:.5f}".format(target, <a id="change">loss_target.item()</a>)
                
                print(s, flush=True)
        </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tky823/dnn-based_source_separation/commit/84cad5184ccab316e3675dc3f6c07c11e5d09277#diff-04a083857f3626b899e7310e389ae175f37501c693f7b6a737bec85b9c9e0d4bL113' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 37160644</div><div id='project'> Project Name: tky823/dnn-based_source_separation</div><div id='commit'> Commit Name: 84cad5184ccab316e3675dc3f6c07c11e5d09277</div><div id='time'> Time: 2021-10-29</div><div id='author'> Author: delta9guitar97@gmail.com</div><div id='file'> File Name: egs/musdb18/x-umx/src/adhoc_driver.py</div><div id='m_class'> M Class Name: AdhocSchedulerTrainer</div><div id='n_method'> N Class Name: AdhocSchedulerTrainer</div><div id='m_method'> M Method Name: run_one_epoch_train(2)</div><div id='n_method'> N Method Name: run_one_epoch_train(2)</div><div id='m_parent_class'> M Parent Class: TrainerBase</div><div id='n_parent_class'> N Parent Class: TrainerBase</div><div id='m_file'> M File Name: egs/musdb18/x-umx/src/adhoc_driver.py</div><div id='n_file'> N File Name: egs/musdb18/x-umx/src/adhoc_driver.py</div><div id='m_start'> M Start Line: 120</div><div id='m_end'> M End Line: 148</div><div id='n_start'> N Start Line: 139</div><div id='n_end'> N End Line: 182</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            raise NotImplementedError
        policy_loss_value = policy_loss.detach().cpu().numpy()
        self.policy_optimizer.zero_grad()
        <a id="change">policy_loss.backward()</a>
        self.policy_optimizer.step()

        &#47&#47compute value loss
        v_loss = F.mse_loss(curr_state_v, future_return_batch)</code></pre><h3>After Change</h3><pre><code class='java'>
        

        &#47&#47entropy loss
        entropy_loss<a id="change"> = </a>-torch.mean(-new_log_pi) * self.entropy_coeff
        entropy_loss_value<a id="change"> = </a><a id="change">entropy_loss.item()</a>

        &#47&#47compute policy loss
        if self.policy_loss_type == "clipped_surrogate":
            surrogate1 = advantages * ratio_batch</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/x35f/unstable_baselines/commit/f41e2cf788d0214add3fb342aee698910c63e651#diff-52f03432c99c716ff4dd3aab99ae6fafde4ebca9abe1cdbec481a8fee78251bcL74' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 37160643</div><div id='project'> Project Name: x35f/unstable_baselines</div><div id='commit'> Commit Name: f41e2cf788d0214add3fb342aee698910c63e651</div><div id='time'> Time: 2021-04-01</div><div id='author'> Author: 1621322691@qq.com</div><div id='file'> File Name: ppo/model.py</div><div id='m_class'> M Class Name: PPOAgent</div><div id='n_method'> N Class Name: PPOAgent</div><div id='m_method'> M Method Name: update(2)</div><div id='n_method'> N Method Name: update(2)</div><div id='m_parent_class'> M Parent Class: BaseAgent,torch.nn.Module</div><div id='n_parent_class'> N Parent Class: BaseAgent,torch.nn.Module</div><div id='m_file'> M File Name: ppo/model.py</div><div id='n_file'> N File Name: ppo/model.py</div><div id='m_start'> M Start Line: 83</div><div id='m_end'> M End Line: 126</div><div id='n_start'> N Start Line: 79</div><div id='n_end'> N End Line: 137</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                              mix_data[x][&quotrdf_range&quot],
                              f&quot{model_path}/x_{x}_{str(i).zfill(3)}_rdf.pdf&quot)

        <a id="change">loss.backward()</a>
        optimizer.step()
        optimizer.zero_grad()

        print(loss.item())</code></pre><h3>After Change</h3><pre><code class='java'>
                _, _, sim_rdf12 = train_sys[x].rdf12(q_t)
                _, _, sim_rdf22 = train_sys[x].rdf22(q_t)

                loss_<a id="change"> = </a>(sim_rdf11 - torch.Tensor(train_sys[x].target_rdf11).to(device) ).pow(2).mean() + \
                        (sim_rdf12 - torch.Tensor(train_sys[x].target_rdf12).to(device) ).pow(2).mean() + \
                        (sim_rdf22 - torch.Tensor(train_sys[x].target_rdf22).to(device) ).pow(2).mean() 

                all_rdf11.append(sim_rdf11)
                all_rdf12.append(sim_rdf12)
                all_rdf22.append(sim_rdf22)

                loss_.backward()

                loss<a id="change"> += </a><a id="change">loss_.item()</a>
        
        optimizer.step()
        optimizer.zero_grad()
 </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/torchmd/mdgrad/commit/4a43676cd6950ce8bf34276d9c4fefcd081b35d7#diff-d331fc48ce4f2b9fd362780953537bd16aa4b7953175b6398d824bf57f626df7L137' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 37160649</div><div id='project'> Project Name: torchmd/mdgrad</div><div id='commit'> Commit Name: 4a43676cd6950ce8bf34276d9c4fefcd081b35d7</div><div id='time'> Time: 2022-01-28</div><div id='author'> Author: wwj@mit.edu</div><div id='file'> File Name: scripts/fit_mix.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: run_mix(1)</div><div id='n_method'> N Method Name: run_mix(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/fit_mix.py</div><div id='n_file'> N File Name: scripts/fit_mix.py</div><div id='m_start'> M Start Line: 199</div><div id='m_end'> M End Line: 230</div><div id='n_start'> N Start Line: 202</div><div id='n_end'> N End Line: 250</div><BR>