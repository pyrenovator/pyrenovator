<html><h3>Pattern ID :33907
</h3><img src='97153225.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 --- draw H_wisdom from H_desc with attention --- &#47&#47
        H_k_ = self.H_k(H_all)  &#47&#47 (N, L, H) -&gt; (N, K, H)
        H_k = torch.einsum("nkh-&gt;nhk", H_k_)
        H_wisdom<a id="change"> = </a><a id="change">self.pooler(H_k).squeeze()</a>  &#47&#47 (N, K, H) -pooling-&gt; (N, H, 1) -&gt; (N, H)
        &#47&#47 --- now compare H_wisdom with all the wisdoms --- &#47&#47
        S_wisdom_figurative = torch.einsum("nh,wh-&gt;nw", H_wisdom, wisdom_embeddings)  &#47&#47 (N, H) * (W, H) -&gt; (N, W)
        return S_wisdom_figurative</code></pre><h3>After Change</h3><pre><code class='java'>
        H_cls = H_all[:, 0]  &#47&#47 (N, H)
        H_desc = self.H_desc(H_all)  &#47&#47 (N, D, H)
        scores = torch.einsum("nh,ndh-&gt;nd", H_cls, H_desc)  &#47&#47 (N, D)
        attentions<a id="change"> = </a><a id="change">torch.softmax(</a>scores<a id="change">, dim=1)</a>  &#47&#47 over D
        H_wisdom = torch.einsum("nd,ndh-&gt;nh", attentions, H_desc)  &#47&#47 -&gt; (N, H)
        &#47&#47 --- now compare H_wisdom with all the wisdoms --- &#47&#47
        S_wisdom_figurative = torch.einsum("nh,wh-&gt;nw", H_wisdom, wisdom_embeddings)  &#47&#47 (N, H) * (W, H) -&gt; (N, W)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/eubinecto/wisdomify/commit/48be6381655aa90307f57ca68afe308c5214cddb#diff-5f23a84aa818c6cbad34ed97adf37af0767442ed5f4a4082158ba950c800d8a4L335' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 97153225</div><div id='project'> Project Name: eubinecto/wisdomify</div><div id='commit'> Commit Name: 48be6381655aa90307f57ca68afe308c5214cddb</div><div id='time'> Time: 2021-11-23</div><div id='author'> Author: eubinecto</div><div id='file'> File Name: wisdomify/models.py</div><div id='m_class'> M Class Name: RDGamma</div><div id='n_method'> N Class Name: RDGamma</div><div id='m_method'> M Method Name: S_wisdom_figurative(2)</div><div id='n_method'> N Method Name: S_wisdom_figurative(2)</div><div id='m_parent_class'> M Parent Class: RD</div><div id='n_parent_class'> N Parent Class: RD</div><div id='m_file'> M File Name: wisdomify/models.py</div><div id='n_file'> N File Name: wisdomify/models.py</div><div id='m_start'> M Start Line: 336</div><div id='m_end'> M End Line: 338</div><div id='n_start'> N Start Line: 335</div><div id='n_end'> N End Line: 339</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Compute biaffine attention matrix. This computes from the hidden
        &#47&#47 representations of the shape [batch_size, seq_len, hidden_size] the
        &#47&#47 attention matrices [batch_size, seq_len, seq_len].
        logits<a id="change"> = </a><a id="change">self.bilinear(head, dependent).squeeze(</a>-1<a id="change">)</a>

        &#47&#47 Mask out head candidates that are padding time steps. The logits mask
        &#47&#47 has shape [batch_size, seq_len], we reshape it to [batch_size, 1,
        &#47&#47 seq_len] to mask out the head predictions.</code></pre><h3>After Change</h3><pre><code class='java'>
        if self.training:
            &#47&#47 Compute head probability distribution.
            logits_arc = logits_arc.softmax(-1)
            logits_label<a id="change"> = </a><a id="change">logits_label.softmax(</a>-1<a id="change">)</a>

        return logits_arc, logits_label
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/explosion/spacy-experimental/commit/b683b4eb3ceef19f7437cf420d5aa133b5aa5b89#diff-510501f7cb2d459202a440b1750a360ccbcdc4c5f42a0298478a064ab610aad0L84' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 97153231</div><div id='project'> Project Name: explosion/spacy-experimental</div><div id='commit'> Commit Name: b683b4eb3ceef19f7437cf420d5aa133b5aa5b89</div><div id='time'> Time: 2021-10-22</div><div id='author'> Author: me@danieldk.eu</div><div id='file'> File Name: biaffine_parser/pytorch_biaffine_model.py</div><div id='m_class'> M Class Name: BiaffineModel</div><div id='n_method'> N Class Name: BiaffineModel</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: biaffine_parser/pytorch_biaffine_model.py</div><div id='n_file'> N File Name: biaffine_parser/pytorch_biaffine_model.py</div><div id='m_start'> M Start Line: 91</div><div id='m_end'> M End Line: 108</div><div id='n_start'> N Start Line: 95</div><div id='n_end'> N End Line: 121</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        x = self.norm(x)

        if self.seq_pool:
            x = <a id="change">torch.matmul(F.softmax(self.attention_pool(x), dim=1).transpose(-1, -2), x).squeeze(</a>-2<a id="change">)</a>
        else:
            x = x[:, 0]

        x<a id="change"> = </a>self.fc(x)
        return x

    @staticmethod</code></pre><h3>After Change</h3><pre><code class='java'>

        if self.seq_pool:
            attn_weights = rearrange(self.attention_pool(x), &quotb n 1 -&gt; b n&quot)
            x<a id="change"> = </a>einsum(&quotb n, b n d -&gt; b d&quot, <a id="change">attn_weights.softmax(dim = 1)</a>, x)
        else:
            x = x[:, 0]
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/vit-pytorch/commit/cb6d749821bbf3b0bd17c9e8e64eb343f40b3f69#diff-d9cf888a006662bd788cc31712f154ca4e86227d51998c7d5bca6e17d1197c07L258' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 97153223</div><div id='project'> Project Name: lucidrains/vit-pytorch</div><div id='commit'> Commit Name: cb6d749821bbf3b0bd17c9e8e64eb343f40b3f69</div><div id='time'> Time: 2022-10-29</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: vit_pytorch/cct.py</div><div id='m_class'> M Class Name: TransformerClassifier</div><div id='n_method'> N Class Name: TransformerClassifier</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: vit_pytorch/cct.py</div><div id='n_file'> N File Name: vit_pytorch/cct.py</div><div id='m_start'> M Start Line: 259</div><div id='m_end'> M End Line: 281</div><div id='n_start'> N Start Line: 267</div><div id='n_end'> N End Line: 292</div><BR>