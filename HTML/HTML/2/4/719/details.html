<html><h3>Pattern ID :719
</h3><img src='3457585.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            else:
                temp = self.mapping(paddle.randn(z.shape), c, skip_w_avg_update=True)[:, cutoff:]
                temp2 = ws[:, :cutoff]
                ws<a id="change"> = </a><a id="change">paddle.concat(</a>[temp2, temp], 1<a id="change">)</a>

        img = self.synthesis(ws)
        return img, ws
</code></pre><h3>After Change</h3><pre><code class='java'>
        if self.style_mixing_prob &gt; 0:
            cutoff = torch.empty([], dtype=torch.int64, device=ws.device).random_(1, ws.shape[1])
            cutoff = torch.where(torch.rand([], device=ws.device) &lt; self.style_mixing_prob, cutoff, torch.full_like(cutoff, ws.shape[1]))
            <a id="change">ws[:, cutoff:]</a> = self.mapping(torch.randn_like(z), c, skip_w_avg_update=True)[:, cutoff:]

        img = self.synthesis(ws)
        return img, ws</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/miemie2013/miemiegan/commit/0ad2483396ab17c9512db493c01be594f47431b0#diff-c3be3e49b4968a2ee433a8b0d38c7aa9f68d5116602220ff22567e41b765b44bL127' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3457585</div><div id='project'> Project Name: miemie2013/miemiegan</div><div id='commit'> Commit Name: 0ad2483396ab17c9512db493c01be594f47431b0</div><div id='time'> Time: 2022-02-23</div><div id='author'> Author: 53960695+miemie2013@users.noreply.github.com</div><div id='file'> File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_class'> M Class Name: StyleGANv2ADAModel</div><div id='n_method'> N Class Name: StyleGANv2ADAModel</div><div id='m_method'> M Method Name: run_G(4)</div><div id='n_method'> N Method Name: run_G(4)</div><div id='m_parent_class'> M Parent Class: torch.nn.Module</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='n_file'> N File Name: mmgan/models/architectures/styleganv2ada_model.py</div><div id='m_start'> M Start Line: 127</div><div id='m_end'> M End Line: 147</div><div id='n_start'> N Start Line: 128</div><div id='n_end'> N End Line: 133</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            n_data_sample = group_df.shape[0]
            num_ambiguous += n_data_sample
            if context.with_display:
                display<a id="change"> = </a><a id="change">pd.concat(</a>[display, sample]<a id="change">)</a>

        display = display.set_index(ambiguous_label_name)

        explanation = (&quotEach row in the table shows an example of a data sample &quot</code></pre><h3>After Change</h3><pre><code class='java'>

            n_data_sample = group_df.shape[0]
            num_ambiguous += n_data_sample
            samples.append(<a id="change">group_df.loc[:, [label_name, *features]]</a>.copy())

            if context.with_display is True:
                display_sample = dict(group_df[features].iloc[0])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/deepchecks/deepchecks/commit/b0bf20b9abb8067eac01dfc710851aac05ca4564#diff-f12b3d23a1ed0bbbd12a91115b30111a34beba1883c76c196032eb3cdd77a83fL51' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3457581</div><div id='project'> Project Name: deepchecks/deepchecks</div><div id='commit'> Commit Name: b0bf20b9abb8067eac01dfc710851aac05ca4564</div><div id='time'> Time: 2022-06-29</div><div id='author'> Author: 71635444+yromanyshyn@users.noreply.github.com</div><div id='file'> File Name: deepchecks/tabular/checks/data_integrity/conflicting_labels.py</div><div id='m_class'> M Class Name: ConflictingLabels</div><div id='n_method'> N Class Name: ConflictingLabels</div><div id='m_method'> M Method Name: run_logic(3)</div><div id='n_method'> N Method Name: run_logic(3)</div><div id='m_parent_class'> M Parent Class: SingleDatasetCheck</div><div id='n_parent_class'> N Parent Class: SingleDatasetCheck</div><div id='m_file'> M File Name: deepchecks/tabular/checks/data_integrity/conflicting_labels.py</div><div id='n_file'> N File Name: deepchecks/tabular/checks/data_integrity/conflicting_labels.py</div><div id='m_start'> M Start Line: 64</div><div id='m_end'> M End Line: 103</div><div id='n_start'> N Start Line: 71</div><div id='n_end'> N End Line: 123</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        sp = depthwise_conv2d_no_bias(sp, kernel_size=3, padding="SAME", use_bias=True, name=name + "spx_{}_".format(id + 1))
        gathered_result.append(sp)
    gathered_result.append(remainder)
    attn<a id="change"> = </a><a id="change">tf.concat(</a>gathered_result<a id="change">, axis=-1)</a>
    &#47&#47 print(f"{inputs.shape = }, {attn.shape = }")

    &#47&#47 XCA
    attn = PositionalEncodingFourier(name=name + "pos")(attn) if use_pos_emb else attn</code></pre><h3>After Change</h3><pre><code class='java'>
    if image_data_format() == "channels_last":
        spx, remainder = inputs[:, :, :, : (split - 1) * sub_channels], inputs[:, :, :, (split - 1) * sub_channels :]
    else:
        spx, remainder = <a id="change">inputs[:, : (split - 1) * sub_channels]</a>, inputs[:, (split - 1) * sub_channels :]
    spx = functional.split(spx, split - 1, axis=channel_axis)
    gathered_result = []
    for id, ii in enumerate(spx):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/leondgarse/keras_cv_attention_models/commit/7fe31da02f008f26eff018ec2199631227c94efc#diff-a119549323a000d7b33706b44fad5bc04a07d913bec886b503d88f2f13240579L104' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3457582</div><div id='project'> Project Name: leondgarse/keras_cv_attention_models</div><div id='commit'> Commit Name: 7fe31da02f008f26eff018ec2199631227c94efc</div><div id='time'> Time: 2023-02-10</div><div id='author'> Author: leondgarse@gmail.com</div><div id='file'> File Name: keras_cv_attention_models/edgenext/edgenext.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: split_depthwise_transpose_attention(9)</div><div id='n_method'> N Method Name: split_depthwise_transpose_attention(9)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: keras_cv_attention_models/edgenext/edgenext.py</div><div id='n_file'> N File Name: keras_cv_attention_models/edgenext/edgenext.py</div><div id='m_start'> M Start Line: 107</div><div id='m_end'> M End Line: 131</div><div id='n_start'> N Start Line: 113</div><div id='n_end'> N End Line: 143</div><BR>