<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        elif self.hparams[&quotloss_func&quot] == "cross_entropy_with_sync":
            loss = F.cross_entropy(S_wisdom, y).sum()  &#47&#47 (N, |W|), (N,) -&gt; (N,) -&gt; (1,)
            S_wisdom_literal = torch.log_softmax(S_wisdom_literal, dim=1)
            S_wisdom_figurative<a id="change"> = </a><a id="change">torch.log_softmax(</a>S_wisdom_figurative<a id="change">, dim=1)</a>
            &#47&#47 mse outperforms kl_div: https://arxiv.org/abs/2105.08919
            &#47&#47 KD library gets use of MSE:
            &#47&#47 https://github.com/SforAiDl/KD_Lib/blob/df4d9e5c0a494410cb2994e3a1d5902afdccf0d6/KD_Lib/KD/vision/vanilla/vanilla_kd.py&#47&#47L69-L71
            &#47&#47 you add this to the cross entropy loss</code></pre><h3>After Change</h3><pre><code class='java'>
        elif self.hparams[&quotloss_func&quot] == "cross_entropy_with_mtl":
            loss = F.cross_entropy(S_wisdom, y).sum()  &#47&#47 (N, |W|), (N,) -&gt; (N,) -&gt; (1,)
            loss += F.cross_entropy(S_wisdom_literal, y).sum()  &#47&#47 multi-task learning
            loss<a id="change"> += </a><a id="change">F.cross_entropy(</a>S_wisdom_figurative, y<a id="change">)</a>.sum()  &#47&#47 multi-task learning
            &#47&#47 S_wisdom_literal = torch.log_softmax(S_wisdom_literal, dim=1)
            &#47&#47 S_wisdom_figurative = torch.log_softmax(S_wisdom_figurative, dim=1)
            &#47&#47 &#47&#47 mse outperforms kl_div: https://arxiv.org/abs/2105.08919</code></pre>