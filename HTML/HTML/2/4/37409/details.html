<html><h3>Pattern ID :37409
</h3><img src='107781421.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
	else:
		model = RobertaModel.from_pretrained(&quotroberta-large&quot).cuda()

	if <a id="change">args[&quotparallel&quot]</a>:
		model = nn.DataParallel(model)
		
	classifier = FeedForward(args[&quotembed_size&quot],int(args[&quotembed_size&quot]/2),args[&quotnooflabels&quot]).cuda()</code></pre><h3>After Change</h3><pre><code class='java'>
    
    result_dir = args["save_dir"]+args["save_folder"]
    &#47&#47 Intialize model
    model = <a id="change">AutoModel.from_pretrained(</a>args[&quotmodel_type&quot]<a id="change">)</a>.cuda()
    args[&quotembed_size&quot]<a id="change"> = </a>model.config.hidden_size
    classifier = FeedForward(args[&quotembed_size&quot],int(args[&quotembed_size&quot]/2),args[&quotnooflabels&quot]).cuda()

    &#47&#47 Load pre-trained models</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/utahnlp/infotabs-code/commit/27cf8e2d7a767e0c5ee1a285797dd8d68090d707#diff-22b44a302a031db01b956acf4520f7dcbc49d0fad57ce247cdb5fe22b5267f18L170' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 107781421</div><div id='project'> Project Name: utahnlp/infotabs-code</div><div id='commit'> Commit Name: 27cf8e2d7a767e0c5ee1a285797dd8d68090d707</div><div id='time'> Time: 2021-11-22</div><div id='author'> Author: maitrey@redfish.cs.utah.edu</div><div id='file'> File Name: scripts/roberta/classifier.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_data(1)</div><div id='n_method'> N Method Name: test_data(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: scripts/roberta/classifier.py</div><div id='n_file'> N File Name: scripts/roberta/classifier.py</div><div id='m_start'> M Start Line: 170</div><div id='m_end'> M End Line: 177</div><div id='n_start'> N Start Line: 202</div><div id='n_end'> N End Line: 203</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        compressed_st[&quotstate_dict&quot][f&quot{name}&quot][&quotv&quot] = vt[:i].clone()

    if embed is not None:
        <a id="change">compressed_st[&quotstate_dict&quot][&quotembed&quot]</a> = embed.clone()

    name = delta_ckpt.replace(&quotdelta&quot, &quotcompressed_delta&quot)
    torch.save(compressed_st, f&quot{name}&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
        from diffusers import StableDiffusionPipeline
        compressed_key = &quotunet&quot
        compressed_st = {compressed_key: {}}
        pretrained_st = <a id="change">StableDiffusionPipeline.from_pretrained(</a>ckpt<a id="change">, torch_dtype=torch.float16)</a>.to("cuda")
        pretrained_st<a id="change"> = </a>pretrained_st.unet.state_dict()
        if &quotmodifier_token&quot in st:
            compressed_st[&quotmodifier_token&quot] = st[&quotmodifier_token&quot]
        st = st[&quotunet&quot]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/adobe-research/custom-diffusion/commit/5cd1e9c869b793d88573533a6a2adccd10aadcd0#diff-0f4293c247a4f4e8eab25c82da6ce7037c91175297d9dae021e3b167f28c1121L9' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 107781417</div><div id='project'> Project Name: adobe-research/custom-diffusion</div><div id='commit'> Commit Name: 5cd1e9c869b793d88573533a6a2adccd10aadcd0</div><div id='time'> Time: 2023-01-05</div><div id='author'> Author: nupurkumari@Nupurs-MacBook-Pro.local</div><div id='file'> File Name: src/compress.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: compress(5)</div><div id='n_method'> N Method Name: compress(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/compress.py</div><div id='n_file'> N File Name: src/compress.py</div><div id='m_start'> M Start Line: 10</div><div id='m_end'> M End Line: 48</div><div id='n_start'> N Start Line: 8</div><div id='n_end'> N End Line: 48</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def __init__(self, config=None, *inputs, **kwargs):
        super().__init__()
        assert &quotargs&quot in kwargs
        self.args = <a id="change">kwargs[&quotargs&quot]</a>
        self.bart = BartForConditionalGeneration.from_pretrained(self.args.seq2seq_decoder, cache_dir=self.args.embeddings)
        self.numericalizer = BartNumericalizer(self.args.seq2seq_decoder)

    def forward(self, *input, **kwargs):</code></pre><h3>After Change</h3><pre><code class='java'>
           
class Bart(GenieModel):
    def __init__(self, config=None, *inputs, args, tasks, vocab_sets, save_directory=None, **kwargs):
        config<a id="change"> = </a><a id="change">AutoConfig.from_pretrained(</a>args.seq2seq_decoder<a id="change">, cache_dir=self.args.embeddings)</a>
        super().__init__(config)
        self.args = args
        self.bart = BartForConditionalGeneration.from_pretrained(self.args.seq2seq_decoder, cache_dir=self.args.embeddings)
        self.numericalizer = TransformerNumericalizer(self.args.seq2seq_decoder, config, max_generative_vocab=None)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/6dd8f5b221db4adc2f120bf8b5f07f6de8a3f838#diff-bceffcc02e288dc2e7c5e76149fbb8822d24f0692d947a87423f72f40c70236bL306' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 107781414</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: 6dd8f5b221db4adc2f120bf8b5f07f6de8a3f838</div><div id='time'> Time: 2020-12-05</div><div id='author'> Author: gcampagn@cs.stanford.edu</div><div id='file'> File Name: genienlp/models/general_seq2seq.py</div><div id='m_class'> M Class Name: Bart</div><div id='n_method'> N Class Name: Bart</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(2)</div><div id='m_parent_class'> M Parent Class: GenieModel</div><div id='n_parent_class'> N Parent Class: torch.nn.Module</div><div id='m_file'> M File Name: genienlp/models/general_seq2seq.py</div><div id='n_file'> N File Name: genienlp/models/general_seq2seq.py</div><div id='m_start'> M Start Line: 308</div><div id='m_end'> M End Line: 309</div><div id='n_start'> N Start Line: 276</div><div id='n_end'> N End Line: 282</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    logger.info(f&quotInitializing Model&quot)
    Model = getattr(models, args.model)
    model = Model(numericalizer, args, context_embeddings, question_embeddings, decoder_embeddings)
    model_dict = <a id="change">save_dict[&quotmodel_state_dict&quot]</a>
    model.load_state_dict(model_dict)

    server = Server(args, numericalizer, context_embeddings + question_embeddings + decoder_embeddings,
                    model, devices[0])</code></pre><h3>After Change</h3><pre><code class='java'>
    device = devices[0] &#47&#47 server only runs on a single device

    Model = getattr(models, args.model)
    model<a id="change">, _ = </a><a id="change">Model.from_pretrained(</a>args.path<a id="change">,
                                     model_checkpoint_file=args.checkpoint_name,
                                     args=args,
                                     device=device
                                    )</a>

    
    model.to(device)
    model.eval()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stanford-oval/genienlp/commit/af978f49e201bdf942e18839ec49f168273f38f9#diff-4950f9e8f7246fc8ff6b4fb73bab7ac6f77ecaaa2e5c52d8b9a487d701c53159L161' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 107781415</div><div id='project'> Project Name: stanford-oval/genienlp</div><div id='commit'> Commit Name: af978f49e201bdf942e18839ec49f168273f38f9</div><div id='time'> Time: 2020-11-07</div><div id='author'> Author: s.j.semnani@gmail.com</div><div id='file'> File Name: genienlp/server.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: main(1)</div><div id='n_method'> N Method Name: main(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: genienlp/server.py</div><div id='n_file'> N File Name: genienlp/server.py</div><div id='m_start'> M Start Line: 168</div><div id='m_end'> M End Line: 185</div><div id='n_start'> N Start Line: 163</div><div id='n_end'> N End Line: 177</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

def get_encoded_dim(name):
    assert name in T5_CONFIGS, f&quot{name} model is not found in configuration&quot
    return <a id="change">T5_CONFIGS[name][&quotdim&quot]</a>

&#47&#47 encoding text

def t5_encode_text(texts, name = &quott5-small&quot):</code></pre><h3>After Change</h3><pre><code class='java'>
def get_encoded_dim(name):
    if name not in T5_CONFIGS:
        &#47&#47 avoids loading the model if we only want to get the dim
        config<a id="change"> = </a><a id="change">T5Config.from_pretrained(</a>name<a id="change">)</a>
        T5_CONFIGS[name] = dict(config=config)
    elif "config" in T5_CONFIGS:
        config = T5_CONFIGS[name]["config"]
    elif "model" in T5_CONFIGS:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/6d857854c25312dad6d379bb19d5b7e9fe0ccf68#diff-a18d52a4dbdaf0c9073663db34a3aabfa7f2e5eecce1597f937815e2ab4307b2L81' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 107781425</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: 6d857854c25312dad6d379bb19d5b7e9fe0ccf68</div><div id='time'> Time: 2022-05-26</div><div id='author'> Author: jorgemcgomes@gmail.com</div><div id='file'> File Name: imagen_pytorch/t5.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: get_encoded_dim(1)</div><div id='n_method'> N Method Name: get_encoded_dim(1)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: imagen_pytorch/t5.py</div><div id='n_file'> N File Name: imagen_pytorch/t5.py</div><div id='m_start'> M Start Line: 82</div><div id='m_end'> M End Line: 83</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 48</div><BR>