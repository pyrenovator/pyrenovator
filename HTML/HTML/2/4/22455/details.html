<html><h3>Pattern ID :22455
</h3><img src='71019625.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        working_window = deepcopy(sample_image.window)
        if "full" in self.psf_mode:
            working_window += self.target.psf_border 
            self.center_shift = <a id="change">self["center"].value.detach().numpy()</a> % 1. &#47&#47 fixme only move window
            working_window.shift_origin(self.center_shift)
            
        working_image = Model_Image(pixelscale = sample_image.pixelscale, window = working_window)</code></pre><h3>After Change</h3><pre><code class='java'>
        
        if sample_image is None:
            sample_image = self.model_image
        if <a id="change">self.is_sampled and sample_image is self.model_image</a>:
            return
        if sample_image is self.model_image:
            sample_image.clear_image()
            &#47&#47self.is_sampled = True

        &#47&#47 Check that psf and integrate modes line up
        if "window" in self.psf_mode:
            if "window" in self.integrate_mode:
                assert self.integrate_window_size &lt;= self.psf_window_size
            assert "full" not in self.integrate_mode
        working_window = deepcopy(sample_image.window)
        if "full" in self.psf_mode:
            working_window += self.target.psf_border 
            center = self["center"].value.detach().numpy()
            center_shift = center - np.floor(center/sample_image.pixelscale)*sample_image.pixelscale
            if center_shift[0] &lt; 0:
                sub_window.shift_origin((-working_image.pixelscale,0))
                center_shift[0] += working_image.pixelscale
            if center_shift[1] &lt; 0:
                sub_window.shift_origin((0,-working_image.pixelscale))
                center_shift[1] += working_image.pixelscale
            working_window.shift_origin(center_shift)
            
        working_image = Model_Image(pixelscale = sample_image.pixelscale, window = working_window)
        if "full" not in self.integrate_mode:
            working_image.data += self.evaluate_model(working_image)

        if "full" in self.psf_mode:
            self.integrate_model(working_image)
            working_image.data = conv2d(working_image.data.view(1,1,*working_image.data.shape), self.target.psf.view(1,1,*self.target.psf.shape), padding = "same")[0][0]
            working_image.shift_origin(-center_shift)
            working_image.crop(*self.target.psf_border_int)
        elif "window" in self.psf_mode:
            sub_window = self.psf_window.make_copy()
            sub_window += self.target.psf_border
            center_shift = self["center"].value.detach().numpy() - sub_window.center &#47&#47fixme, make center on a pixel, not necessarily central pixel ((0.5 + self["center"].value.detach().numpy()/self.target.pixelscale) % 1.)*self.target.pixelscale
            if center_shift[0] &lt; 0:
                sub_window.shift_origin((-working_image.pixelscale,0))
                center_shift[0] += working_image.pixelscale
            if center_shift[1] &lt; 0:
                sub_window.shift_origin((0,-working_image.pixelscale))
                center_shift[1] += working_image.pixelscale
            sub_window.shift_origin(center_shift)
            sub_image = Model_Image(pixelscale = sample_image.pixelscale, window = sub_window)
            sub_image.data = self.evaluate_model(sub_image)
            &#47&#47 plt.imshow(sub_image.data.detach().numpy(),origin = "lower")
            &#47&#47 plt.title("evaluate model")
            &#47&#47 plt.show()
            self.integrate_model(sub_image)
            &#47&#47 plt.imshow(sub_image.data.detach().numpy(),origin = "lower")
            &#47&#47 plt.title("integrate model")
            &#47&#47 plt.show()
            sub_image.data = conv2d(sub_image.data.view(1,1,*sub_image.data.shape), self.target.psf.view(1,1,*self.target.psf.shape), padding = "same")[0][0]
            &#47&#47 plt.imshow(sub_image.data.detach().numpy(),origin = "lower")
            &#47&#47 plt.title("convolve")
            &#47&#47 plt.show()
            sub_image.shift_origin(-center_shift)
            &#47&#47 plt.imshow(sub_image.data.detach().numpy(),origin = "lower")
            &#47&#47 plt.title("shift")
            &#47&#47 plt.show()
            center_shift = torch.zeros(2)
            sub_image.crop(*self.target.psf_border_int)
            &#47&#47 plt.imshow(sub_image.data.detach().numpy(),origin = "lower")
            &#47&#47 plt.title("crop")
            &#47&#47 plt.show()
            working_image.replace(sub_image)
            &#47&#47 plt.imshow(working_image.data.detach().numpy(),origin = "lower")
            &#47&#47 plt.title("working image")
            &#47&#47 plt.show()
        else:
            self.integrate_model(working_image)

        sample_image += working_image
        if sample_image is self.model_image:
            self.is_sampled<a id="change"> = </a>True
            
    def integrate_model(self, working_image):
        Sample the model at a higher resolution than the given image, then</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/connorstoneastro/autoprof/commit/084f9ab029cf4881c16a7d0a6a652ae00264aa04#diff-f48e7e4f4617c56a91cecf87400e1b8c67ec5491c53dceae61328526ff99ebfeL129' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 71019625</div><div id='project'> Project Name: connorstoneastro/autoprof</div><div id='commit'> Commit Name: 084f9ab029cf4881c16a7d0a6a652ae00264aa04</div><div id='time'> Time: 2022-11-03</div><div id='author'> Author: connorstone628@gmail.com</div><div id='file'> File Name: autoprof/models/model_object.py</div><div id='m_class'> M Class Name: BaseModel</div><div id='n_method'> N Class Name: BaseModel</div><div id='m_method'> M Method Name: sample(2)</div><div id='n_method'> N Method Name: sample(2)</div><div id='m_parent_class'> M Parent Class: AutoProf_Model</div><div id='n_parent_class'> N Parent Class: AutoProf_Model</div><div id='m_file'> M File Name: autoprof/models/model_object.py</div><div id='n_file'> N File Name: autoprof/models/model_object.py</div><div id='m_start'> M Start Line: 129</div><div id='m_end'> M End Line: 170</div><div id='n_start'> N Start Line: 129</div><div id='n_end'> N End Line: 208</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        y, feature = net(x)

    &#47&#47 make score and link map
    score_text = <a id="change">y[0,:,:,0].cpu().data.numpy()</a>
    score_link = y[0,:,:,1].cpu().data.numpy()

    &#47&#47 Post-processing
    boxes, polys, mapper = getDetBoxes(score_text, score_link, text_threshold, link_threshold, low_text, poly, estimate_num_chars)</code></pre><h3>After Change</h3><pre><code class='java'>
    return new_state_dict

def test_net(canvas_size, mag_ratio, net, image, text_threshold, link_threshold, low_text, poly, device, estimate_num_chars=False):
    if <a id="change">isinstance(image, np.ndarray) and len(image.shape) == 4</a>:  &#47&#47 image is batch of np arrays
        image_arrs = image
    else:                                                        &#47&#47 image is single numpy array
        image_arrs<a id="change"> = </a>[image]

    img_resized_list = []
    &#47&#47 resize</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jaidedai/easyocr/commit/78be56f87d091dfcea6d2289948fc86cc7188cf7#diff-d1923068b4a3834cfd4a66d8427816480985cf6c87ad09ce919ad9128500a255L24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 71019619</div><div id='project'> Project Name: jaidedai/easyocr</div><div id='commit'> Commit Name: 78be56f87d091dfcea6d2289948fc86cc7188cf7</div><div id='time'> Time: 2021-06-12</div><div id='author'> Author: samhunsadamant@gmail.com</div><div id='file'> File Name: easyocr/detection.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_net(10)</div><div id='n_method'> N Method Name: test_net(10)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: easyocr/detection.py</div><div id='n_file'> N File Name: easyocr/detection.py</div><div id='m_start'> M Start Line: 26</div><div id='m_end'> M End Line: 58</div><div id='n_start'> N Start Line: 25</div><div id='n_end'> N End Line: 71</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        original_predictions = self._original_predictions

        &#47&#47 handle only first image (batch=1)
        predictions_in_xyxy_format = <a id="change">original_predictions.xyxy[0].cpu().detach().numpy()</a>

        object_prediction_list = []

        &#47&#47 process predictions</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 compatilibty for sahi v0.8.15
        if isinstance(shift_amount_list[0], int):
            shift_amount_list = [shift_amount_list]
        if <a id="change">full_shape_list is not None and isinstance(full_shape_list[0], int)</a>:
            full_shape_list<a id="change"> = </a>[full_shape_list]

        &#47&#47 handle all predictions
        object_prediction_list_per_image = []</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/obss/sahi/commit/248cd2df7d3450eea48c0f03b75d1b7d0111dcf4#diff-34fb6fd3619110ee74df2d3aafa1b22f7cf122b36a43ec080f4dde16059022a3L455' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 71019618</div><div id='project'> Project Name: obss/sahi</div><div id='commit'> Commit Name: 248cd2df7d3450eea48c0f03b75d1b7d0111dcf4</div><div id='time'> Time: 2021-12-19</div><div id='author'> Author: 34196005+fcakyon@users.noreply.github.com</div><div id='file'> File Name: sahi/model.py</div><div id='m_class'> M Class Name: Yolov5DetectionModel</div><div id='n_method'> N Class Name: Yolov5DetectionModel</div><div id='m_method'> M Method Name: _create_object_prediction_list_from_original_predictions(3)</div><div id='n_method'> N Method Name: _create_object_prediction_list_from_original_predictions(3)</div><div id='m_parent_class'> M Parent Class: DetectionModel</div><div id='n_parent_class'> N Parent Class: DetectionModel</div><div id='m_file'> M File Name: sahi/model.py</div><div id='n_file'> N File Name: sahi/model.py</div><div id='m_start'> M Start Line: 470</div><div id='m_end'> M End Line: 509</div><div id='n_start'> N Start Line: 433</div><div id='n_end'> N End Line: 484</div><BR>