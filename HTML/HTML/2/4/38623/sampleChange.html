<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    bias_table[&quotexample_id&quot] = bias_table[&quotexample_id&quot].map(
        lambda x: eval(x).decode(&quotUTF-8&quot))  &#47&#47  pylint:disable=eval-used
    ids = np.concatenate(list(
        <a id="change">ds.map(</a>lambda example: example[&quotexample_id&quot]<a id="change">)</a>.batch(
            batch_size).as_numpy_iterator())).tolist()
    ids = list(map(lambda x: x.decode(&quotUTF-8&quot), ids))
    subgroup_labels = list(</code></pre><h3>After Change</h3><pre><code class='java'>
    num_subgroups: int,
    ) -&gt; pd.DataFrame:
  Evaluates model for subgroup representation vs number of rounds.
  round_idx<a id="change"> = []</a>
  subgroup_ids = []
  num_samples = []
  prob_representation = []
  for idx in range(num_rounds):
    ds = dataloader.train_ds
    bias_table = pd.read_csv(
        os.path.join(
            os.path.join(output_dir, f&quotround_{idx}&quot), &quotbias_table.csv&quot))
    predictions_merge = merge_subgroup_labels(ds, bias_table, batch_size)
    for subgroup_id in range(num_subgroups):
      prob_i = (predictions_merge[&quotsubgroup_label&quot]
                == subgroup_id).sum() / len(predictions_merge)
      <a id="change">round_idx.append(</a>idx<a id="change">)</a>
      subgroup_ids.append(subgroup_id)
      num_samples.append(len(predictions_merge))
      prob_representation.append(prob_i)
  return pd.DataFrame({</code></pre>