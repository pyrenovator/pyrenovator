<html><h3>Pattern ID :9177
</h3><img src='33271336.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                    best_free_pos = (x, layer)
            assert best_free_pos is not None
            selected_positions[node] = best_free_pos
            layers[best_free_pos[1]].remove(<a id="change">best_free_pos[0]</a>)
    return selected_positions

</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 Layers are just unique Y positions on the plot
    &#47&#47 Go through the highest layer to the lowest one
    for layer, nodes_in_layer in <a id="change">reversed(</a>sorted(layer_to_nodes.items())<a id="change">)</a>:
        n = len(nodes_in_layer)
        distances = np.zeros(shape=(n, n))

        &#47&#47 Extract available X positions in the layer
        avail_xs = layers[layer]

        for node_idx, node in enumerate(nodes_in_layer):
            related_nodes = list(graph.predecessors(node))
            related_nodes += list(graph.successors(node))

            for x_idx, x in enumerate(avail_xs):
                sum_distances = 0
                for related_node in related_nodes:
                    if related_node not in selected_positions:
                        continue
                    r_x, r_y = selected_positions[related_node]
                    sum_distances += (x - r_x) ** 2 + (layer - r_y) ** 2
                distances[node_idx, x_idx] = sum_distances

        &#47&#47 Minimize the sum of squared distances
        &#47&#47 This might work poorly when there are interconnections in the layer
        rows, cols = scipy.optimize.linear_sum_assignment(distances)
        for row, col in zip(rows, cols):
            <a id="change">selected_positions[nodes_in_layer[row]]</a> = (avail_xs[col], layer)

    return selected_positions
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/gahaalt/pytorch-functional/commit/2d43dd8b76fa3998291b3060ed7141de514bd990#diff-350b20189d86dc789c411daefc715628449daa9f0b2fc740e046888e4836edcdL75' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33271336</div><div id='project'> Project Name: gahaalt/pytorch-functional</div><div id='commit'> Commit Name: 2d43dd8b76fa3998291b3060ed7141de514bd990</div><div id='time'> Time: 2022-10-10</div><div id='author'> Author: sjmikler@gmail.com</div><div id='file'> File Name: pytorch_functional/tools.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: fix_positions_in_multipartite_layout(2)</div><div id='n_method'> N Method Name: fix_positions_in_multipartite_layout(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: pytorch_functional/tools.py</div><div id='n_file'> N File Name: pytorch_functional/tools.py</div><div id='m_start'> M Start Line: 75</div><div id='m_end'> M End Line: 107</div><div id='n_start'> N Start Line: 77</div><div id='n_end'> N End Line: 115</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            laterals[i-1] += F.interpolate(laterals[i], size=laterals[i-1].shape[2:], mode=&quotbilinear&quot, align_corners=False)
        
        fpn_outs = [self.fpn_convs[i](laterals[i]) for i in range(used_backbone_levels-1)]
        fpn_outs.append(<a id="change">laterals[-1]</a>)

        for i in range(used_backbone_levels-1, 0, -1):
            fpn_outs[i] = F.interpolate(fpn_outs[i], size=fpn_outs[0].shape[2:], mode=&quotbilinear&quot, align_corners=False)</code></pre><h3>After Change</h3><pre><code class='java'>
        f = self.ppm(features[-1])
        fpn_features = [f]

        for i in <a id="change">reversed(</a>range(len(features)-1)<a id="change">)</a>:
            feature = self.fpn_in[i](<a id="change">features[i]</a>)
            f = feature + F.interpolate(f, size=feature.shape[-2:], mode=&quotbilinear&quot, align_corners=False)
            fpn_features.append(self.fpn_out[i](f))
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sithu31296/semantic-segmentation/commit/af9bcfd5c4642c42b0fa9e1b2af46eb45ec9063d#diff-34cecd933382e1fd69f8eb47990fab2dfbe929c210f74c82718154d4c5a5428cL52' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33271326</div><div id='project'> Project Name: sithu31296/semantic-segmentation</div><div id='commit'> Commit Name: af9bcfd5c4642c42b0fa9e1b2af46eb45ec9063d</div><div id='time'> Time: 2021-08-27</div><div id='author'> Author: sithu31296@gmail.com</div><div id='file'> File Name: models/heads/upernet.py</div><div id='m_class'> M Class Name: UPerHead</div><div id='n_method'> N Class Name: UPerHead</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/heads/upernet.py</div><div id='n_file'> N File Name: models/heads/upernet.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 63</div><div id='n_start'> N Start Line: 44</div><div id='n_end'> N End Line: 53</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        tracer_kwargs={&quotleaf_modules&quot: list(_leaf_modules), &quotautowrap_functions&quot: list(_autowrap_functions)})

    inputs = torch.randn((batch_size, *input_size))
    outputs = model(inputs)[<a id="change">eval_nodes[-1]</a>]

    assert outputs.shape[0] == batch_size
    assert not torch.isnan(outputs).any(), &quotOutput included NaNs&quot</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 node. Then we use those indices to select from train_nodes returned by torchvision get_graph_node_names
    tracer = NodePathTracer(leaf_modules=list(_leaf_modules), autowrap_functions=list(_autowrap_functions))
    graph = tracer.trace(model)
    graph_nodes = list(<a id="change">reversed(</a>graph.nodes<a id="change">)</a>)
    output_node_names = [n.name for n in graph_nodes[0]._input_nodes.keys()]
    graph_node_names = [n.name for n in graph_nodes]
    output_node_indices = [-graph_node_names.index(node_name) for node_name in output_node_names]
    train_nodes, eval_nodes = get_graph_node_names(
        model, tracer_kwargs={&quotleaf_modules&quot: list(_leaf_modules), &quotautowrap_functions&quot: list(_autowrap_functions)})
    eval_return_nodes = [<a id="change">eval_nodes[ix]</a> for ix in output_node_indices]

    fx_model = create_feature_extractor(
        model, train_return_nodes=[train_nodes[-1]], eval_return_nodes=eval_return_nodes,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/feng-lab/pytorch-image-models/commit/0262a0e8e16c31a4e8157a44dafbe5f6b8c21495#diff-0adb667cd397bd56edce10eec11e1b10821740a10d72bd148b09645fc9108968L312' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 33271331</div><div id='project'> Project Name: feng-lab/pytorch-image-models</div><div id='commit'> Commit Name: 0262a0e8e16c31a4e8157a44dafbe5f6b8c21495</div><div id='time'> Time: 2021-11-12</div><div id='author'> Author: alexander.soare159@gmail.com</div><div id='file'> File Name: tests/test_models.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_model_forward_fx(2)</div><div id='n_method'> N Method Name: test_model_forward_fx(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: tests/test_models.py</div><div id='n_file'> N File Name: tests/test_models.py</div><div id='m_start'> M Start Line: 326</div><div id='m_end'> M End Line: 331</div><div id='n_start'> N Start Line: 320</div><div id='n_end'> N End Line: 352</div><BR>