<html><h3>Pattern ID :41024
</h3><img src='115693751.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            images_by_frame_group = torch.permute(images, (1, 0, 2, 3, 4))
            outputs = []
            for image_batch in images_by_frame_group:
                output<a id="change"> = </a><a id="change">self.backbone(</a>image_batch<a id="change">)</a>
                outputs.append(output.reshape(output.shape[0], output.shape[1], -1))
            outputs = torch.cat(outputs, dim=2)
            representations_concat = self.representation_fc(outputs)
            representations = output.reshape(representations_concat.shape[0], representations_concat.shape[1], representations_concat.shape[2]//8,</code></pre><h3>After Change</h3><pre><code class='java'>
            frames_batch_shape = images.shape[0] * images.shape[1]
            channels = images.shape[2]
            image_height = images.shape[3]
            image_width<a id="change"> = </a><a id="change">images.shape[4]</a>
            images_batch_frames: TensorType["batch*frames", "channels":3, "image_height", "image_width"] = images.reshape(frames_batch_shape, channels,
                                                                                                                          image_height, image_width)
            outputs: TensorType["batch*frames", "features", "rep_height", "rep_width"] = self.backbone(images_batch_frames)
            outputs: TensorType["batch", "frames", "features", "rep_height", "rep_width"] = outputs.reshape(images.shape[0], images.shape[1], outputs.shape[1],</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/danbider/lightning-pose/commit/e44a3ec9d6ba5f388281230fca8bcbc060ed9548#diff-99cc1aafbbd2d9185478090d049cb28431c41fdb606d1787b4e8c11baa8aa7ebL158' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 115693751</div><div id='project'> Project Name: danbider/lightning-pose</div><div id='commit'> Commit Name: e44a3ec9d6ba5f388281230fca8bcbc060ed9548</div><div id='time'> Time: 2022-05-16</div><div id='author'> Author: colehurwitz@gmail.com</div><div id='file'> File Name: lightning_pose/models/base.py</div><div id='m_class'> M Class Name: BaseFeatureExtractor</div><div id='n_method'> N Class Name: BaseFeatureExtractor</div><div id='m_method'> M Method Name: get_representations(3)</div><div id='n_method'> N Method Name: get_representations(3)</div><div id='m_parent_class'> M Parent Class: LightningModule</div><div id='n_parent_class'> N Parent Class: LightningModule</div><div id='m_file'> M File Name: lightning_pose/models/base.py</div><div id='n_file'> N File Name: lightning_pose/models/base.py</div><div id='m_start'> M Start Line: 158</div><div id='m_end'> M End Line: 170</div><div id='n_start'> N Start Line: 161</div><div id='n_end'> N End Line: 181</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        batch_size = X.size(0)

        with torch.no_grad():
            feat<a id="change"> = </a><a id="change">self.backbone(</a>X<a id="change">)</a>
        out = self.classifier(feat)

        loss = F.cross_entropy(out, target)
</code></pre><h3>After Change</h3><pre><code class='java'>
        X, target = batch
        batch_size = X.size(0)

        out<a id="change"> = </a><a id="change">self(X)["logits"]</a>

        loss = F.cross_entropy(out, target)

        acc1, acc5 = accuracy_at_k(out, target, top_k=(1, 5))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/vturrisi/solo-learn/commit/0aba1bed118e6a583941828d88374363e885bfd5#diff-306471ca72f10d091f7adabfddc03e702f662348314d589d172c5c700eae27abL143' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 115693758</div><div id='project'> Project Name: vturrisi/solo-learn</div><div id='commit'> Commit Name: 0aba1bed118e6a583941828d88374363e885bfd5</div><div id='time'> Time: 2021-06-18</div><div id='author'> Author: vt.turrisi@gmail.com</div><div id='file'> File Name: solo/methods/linear.py</div><div id='m_class'> M Class Name: LinearModel</div><div id='n_method'> N Class Name: LinearModel</div><div id='m_method'> M Method Name: shared_step(3)</div><div id='n_method'> N Method Name: shared_step(3)</div><div id='m_parent_class'> M Parent Class: pl.LightningModule</div><div id='n_parent_class'> N Parent Class: pl.LightningModule</div><div id='m_file'> M File Name: solo/methods/linear.py</div><div id='n_file'> N File Name: solo/methods/linear.py</div><div id='m_start'> M Start Line: 147</div><div id='m_end'> M End Line: 149</div><div id='n_start'> N Start Line: 149</div><div id='n_end'> N End Line: 149</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            images_by_frame_group = torch.permute(images, (1, 0, 2, 3, 4))
            outputs = []
            for image_batch in images_by_frame_group:
                output<a id="change"> = </a><a id="change">self.backbone(</a>image_batch<a id="change">)</a>
                outputs.append(output.reshape(output.shape[0], output.shape[1], -1))
            outputs = torch.cat(outputs, dim=2)
            representations_concat = self.representation_fc(outputs)
            representations = output.reshape(representations_concat.shape[0], representations_concat.shape[1], representations_concat.shape[2]//8,</code></pre><h3>After Change</h3><pre><code class='java'>
            frames_batch_shape = images.shape[0] * images.shape[1]
            channels = images.shape[2]
            image_height = images.shape[3]
            image_width<a id="change"> = </a><a id="change">images.shape[4]</a>
            images_batch_frames: TensorType["batch*frames", "channels":3, "image_height", "image_width"] = images.reshape(frames_batch_shape, channels,
                                                                                                                          image_height, image_width)
            outputs: TensorType["batch*frames", "features", "rep_height", "rep_width"] = self.backbone(images_batch_frames)
            outputs: TensorType["batch", "frames", "features", "rep_height", "rep_width"] = outputs.reshape(images.shape[0], images.shape[1], outputs.shape[1],</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/danbider/lightning-pose/commit/34b671290dd7e4b9a2cd4d3c9c8450c46ef7b274#diff-99cc1aafbbd2d9185478090d049cb28431c41fdb606d1787b4e8c11baa8aa7ebL138' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 115693755</div><div id='project'> Project Name: danbider/lightning-pose</div><div id='commit'> Commit Name: 34b671290dd7e4b9a2cd4d3c9c8450c46ef7b274</div><div id='time'> Time: 2022-05-16</div><div id='author'> Author: colehurwitz@gmail.com</div><div id='file'> File Name: lightning_pose/models/base.py</div><div id='m_class'> M Class Name: BaseFeatureExtractor</div><div id='n_method'> N Class Name: BaseFeatureExtractor</div><div id='m_method'> M Method Name: get_representations(3)</div><div id='n_method'> N Method Name: get_representations(3)</div><div id='m_parent_class'> M Parent Class: LightningModule</div><div id='n_parent_class'> N Parent Class: LightningModule</div><div id='m_file'> M File Name: lightning_pose/models/base.py</div><div id='n_file'> N File Name: lightning_pose/models/base.py</div><div id='m_start'> M Start Line: 158</div><div id='m_end'> M End Line: 170</div><div id='n_start'> N Start Line: 161</div><div id='n_end'> N End Line: 181</div><BR>