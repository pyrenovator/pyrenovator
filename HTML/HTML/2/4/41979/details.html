<html><h3>Pattern ID :41979
</h3><img src='117679249.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

                &#47&#47 averaging
                if state[&quotmu&quot] != 1:
                    state[&quotax&quot].add_(<a id="change">p.sub(</a>state[&quotax&quot]<a id="change">)</a>.mul(state[&quotmu&quot]))
                else:
                    state[&quotax&quot].copy_(p)
</code></pre><h3>After Change</h3><pre><code class='java'>
            with torch.enable_grad():
                loss = closure()

        <a id="change">for </a>group in self.param_groups<a id="change">:
            </a>params_with_grad = []
            grads = []
            mus = []
            axs = []
            etas = []
            state_steps = []

            for p in group[&quotparams&quot]:
                if p.grad is not None:
                    params_with_grad.append(p)
                    if p.grad.is_sparse:
                        raise RuntimeError(&quotASGD does not support sparse gradients&quot)
                    <a id="change">grads.append(</a>p.grad<a id="change">)</a>

                    state = self.state[p]
                    &#47&#47 State initialization
                    if len(state) == 0:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/9a622f4cd9318d69896462823891588ef0bf719c#diff-b5441178f7d0764941fd9b5dc89b596d57da114d4665b7b31138beac59e93c7dL48' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117679249</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 9a622f4cd9318d69896462823891588ef0bf719c</div><div id='time'> Time: 2021-05-19</div><div id='author'> Author: iramazanli@fb.com</div><div id='file'> File Name: torch/optim/asgd.py</div><div id='m_class'> M Class Name: ASGD</div><div id='n_method'> N Class Name: ASGD</div><div id='m_method'> M Method Name: step(2)</div><div id='n_method'> N Method Name: step(2)</div><div id='m_parent_class'> M Parent Class: Optimizer</div><div id='n_parent_class'> N Parent Class: Optimizer</div><div id='m_file'> M File Name: torch/optim/asgd.py</div><div id='n_file'> N File Name: torch/optim/asgd.py</div><div id='m_start'> M Start Line: 48</div><div id='m_end'> M End Line: 86</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 94</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

                &#47&#47 averaging
                if state[&quotmu&quot] != 1:
                    state[&quotax&quot].add_(<a id="change">p.sub(</a>state[&quotax&quot]<a id="change">)</a>.mul(state[&quotmu&quot]))
                else:
                    state[&quotax&quot].copy_(p)
</code></pre><h3>After Change</h3><pre><code class='java'>
            with torch.enable_grad():
                loss = closure()

        <a id="change">for </a><a id="change">group</a> in self.param_groups<a id="change">:
            </a>params_with_grad = []
            grads = []
            mus = []
            axs = []
            etas = []
            state_steps = []

            for p in group[&quotparams&quot]:
                if p.grad is not None:
                    params_with_grad.append(p)
                    if p.grad.is_sparse:
                        raise RuntimeError(&quotASGD does not support sparse gradients&quot)
                    grads.append(p.grad)

                    state = self.state[p]
                    &#47&#47 State initialization
                    if len(state) == 0:
                        state[&quotstep&quot] = 0
                        state[&quoteta&quot] = group[&quotlr&quot]
                        state[&quotmu&quot] = 1
                        state[&quotax&quot] = torch.zeros_like(p, memory_format=torch.preserve_format)

                    mus.append(state[&quotmu&quot])
                    axs.append(state[&quotax&quot])
                    etas.append(state[&quoteta&quot])

                    state[&quotstep&quot] += 1
                    <a id="change">state_steps.append(</a>state[&quotstep&quot]<a id="change">)</a>

            F.asgd(params_with_grad,
                   grads,
                   axs,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/9a622f4cd9318d69896462823891588ef0bf719c#diff-b5441178f7d0764941fd9b5dc89b596d57da114d4665b7b31138beac59e93c7dL36' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117679255</div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 9a622f4cd9318d69896462823891588ef0bf719c</div><div id='time'> Time: 2021-05-19</div><div id='author'> Author: iramazanli@fb.com</div><div id='file'> File Name: torch/optim/asgd.py</div><div id='m_class'> M Class Name: ASGD</div><div id='n_method'> N Class Name: ASGD</div><div id='m_method'> M Method Name: step(2)</div><div id='n_method'> N Method Name: step(2)</div><div id='m_parent_class'> M Parent Class: Optimizer</div><div id='n_parent_class'> N Parent Class: Optimizer</div><div id='m_file'> M File Name: torch/optim/asgd.py</div><div id='n_file'> N File Name: torch/optim/asgd.py</div><div id='m_start'> M Start Line: 48</div><div id='m_end'> M End Line: 86</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 94</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            phones = phones.replace(replacement[0], replacement[1])
        phones = re.sub("~+", "~", phones)
        phones = re.sub(r"\s+", " ", phones)
        phones = <a id="change">re.sub(</a>r"\s+", "", phones<a id="change">)</a>  &#47&#47 TODO remove this line, once word boundaries are properly implemented
        phones = phones.lstrip("~").rstrip("~")

        if self.add_silence_to_end:</code></pre><h3>After Change</h3><pre><code class='java'>
                                      &quot̃&quot, &quot̬&quot, &quot̽&quot, &quotʰ&quot, &quot|&quot, &quot̝&quot, &quot•&quot, &quotˠ&quot, &quot↘&quot,
                                      &quot‖&quot, &quot̰&quot, &quot‿&quot, &quotᷝ&quot, &quoẗ&quot, &quotᷠ&quot, &quot̜&quot, &quotʷ&quot, &quotʲ&quot,
                                      &quot̚&quot, &quot↗&quot, &quotꜛ&quot, &quot̻&quot, &quot̥&quot, &quotˁ&quot, &quot̘&quot, &quot͡&quot, &quot̺&quot}
        <a id="change">for </a><a id="change">char</a> in unsupported_ipa_characters<a id="change">:
            </a><a id="change">replacements.append(</a>(char, "")<a id="change">)</a>

        if not for_feature_extraction:
            &#47&#47 in case we want to plot etc, we only need the segmental units.
            replacements = replacements + [</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/digitalphonetics/ims-toucan/commit/7900ac1ea0b64b58b5de877cc1b95d3c5e1e47a9#diff-0eec6bd93f18520ead82255aad2d6db9e6b96603bb855499825a03a415ee480cL185' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117679243</div><div id='project'> Project Name: digitalphonetics/ims-toucan</div><div id='commit'> Commit Name: 7900ac1ea0b64b58b5de877cc1b95d3c5e1e47a9</div><div id='time'> Time: 2022-05-04</div><div id='author'> Author: florian.lux@ims.uni-stuttgart.de</div><div id='file'> File Name: Preprocessing/TextFrontend.py</div><div id='m_class'> M Class Name: ArticulatoryCombinedTextFrontend</div><div id='n_method'> N Class Name: ArticulatoryCombinedTextFrontend</div><div id='m_method'> M Method Name: get_phone_string(4)</div><div id='n_method'> N Method Name: get_phone_string(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: Preprocessing/TextFrontend.py</div><div id='n_file'> N File Name: Preprocessing/TextFrontend.py</div><div id='m_start'> M Start Line: 235</div><div id='m_end'> M End Line: 236</div><div id='n_start'> N Start Line: 200</div><div id='n_end'> N End Line: 246</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            new_name = "t"
        if name == "y":
            new_name = "y_scaled"
        df[new_name] = <a id="change">df[name].sub(</a>data_params[name].shift<a id="change">)</a>.div(data_params[name].scale)
    return df

</code></pre><h3>After Change</h3><pre><code class='java'>
                "Local normalization will be implemented in the future - list of data_params may break the code"
            )
            df_list_norm = list()
            <a id="change">for </a>df, <a id="change">df_data_params</a> in zip(df_list, data_params)<a id="change">:
                </a><a id="change">df_list_norm.append(</a>single_normalization(df, df_data_params)<a id="change">)</a>
            df = df_list_norm
        else:
            &#47&#47 Global Normalization
            df_joined, episodes = join_dataframes(df_list)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ourownstory/neural_prophet/commit/d07b79568ef37904de81ba00248764233fbaa8c8#diff-cb8ae2d50e5d5d245ed6fcc8cadf2baf7294fa9ac5c63e819fbfe34f0e4c2552L127' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 117679244</div><div id='project'> Project Name: ourownstory/neural_prophet</div><div id='commit'> Commit Name: d07b79568ef37904de81ba00248764233fbaa8c8</div><div id='time'> Time: 2021-10-07</div><div id='author'> Author: ourownstory@users.noreply.github.com</div><div id='file'> File Name: neuralprophet/df_utils.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: normalize(3)</div><div id='n_method'> N Method Name: normalize(2)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: neuralprophet/df_utils.py</div><div id='n_file'> N File Name: neuralprophet/df_utils.py</div><div id='m_start'> M Start Line: 139</div><div id='m_end'> M End Line: 148</div><div id='n_start'> N Start Line: 253</div><div id='n_end'> N End Line: 286</div><BR>