<html><h3>Pattern ID :17029
</h3><img src='57160568.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    real_feat_indices = np.random.permutation(total_instance)[:num_feats]
    real_feats = real_feats.detach().cpu().numpy()[real_feat_indices].astype(np.float64)
    real_labels = real_labels.detach().cpu().numpy()[real_feat_indices]
    return real_feats<a id="change">, real_feat_indices, real_labels</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
    real_labels = torch.cat(real_labels, dim=0)
    if DDP:
        real_feats = torch.cat(losses.GatherLayer.apply(real_feats), dim=0)
        real_probs<a id="change"> = </a>torch.cat(<a id="change">losses.GatherLayer.apply(</a>real_probs<a id="change">)</a>, dim=0)
        real_labels = torch.cat(losses.GatherLayer.apply(real_labels), dim=0)

    real_feat_indices = np.random.permutation(num_feats)
    real_feats = real_feats.detach().cpu().numpy()[real_feat_indices].astype(np.float64)
    real_probs = real_probs.detach().cpu().numpy()[real_feat_indices].astype(np.float64)
    real_labels = real_labels.detach().cpu().numpy()[real_feat_indices]
    <a id="change">return </a>real_feats, real_probs, real_feat_indices, real_labels
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/postech-cvlab/pytorch-studiogan/commit/e9b9424ea383996bb391e5c68e5c50071b818637#diff-ff672cec8523da9b4005f8c911359d38c08229474bee3c149b152a5dc3d49c81L106' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 57160568</div><div id='project'> Project Name: postech-cvlab/pytorch-studiogan</div><div id='commit'> Commit Name: e9b9424ea383996bb391e5c68e5c50071b818637</div><div id='time'> Time: 2022-03-30</div><div id='author'> Author: first287@naver.com</div><div id='file'> File Name: src/metrics/features.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: stack_features(8)</div><div id='n_method'> N Method Name: stack_features(8)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: src/metrics/features.py</div><div id='n_file'> N File Name: src/metrics/features.py</div><div id='m_start'> M Start Line: 106</div><div id='m_end'> M End Line: 134</div><div id='n_start'> N Start Line: 110</div><div id='n_end'> N End Line: 138</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        counterfactuals = []

        for i, row in instances.iterrows():
            _<a id="change">, counterfactual</a> = self.counterfactual_search(instances.values[i, :])
            counterfactuals.append(counterfactual)

        counterfactuals_df = check_counterfactuals(self._mlmodel, counterfactuals)</code></pre><h3>After Change</h3><pre><code class='java'>
        df_enc_norm_fact = df_enc_norm_fact.reset_index(drop=True)

        &#47&#47 find counterfactuals
        df_cfs<a id="change"> = </a><a id="change">df_enc_norm_fact.apply(
            </a>lambda x: self._counterfactual_search(x)<a id="change">, axis=1, raw=True
        )</a>
        df_cfs = check_counterfactuals(self._mlmodel, df_cfs)
        <a id="change">return </a>df_cfs
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/indyfree/carla/commit/ad6d72b67aba0a89b8f54c6c377f9e5b4b1366eb#diff-557a0282f4e4008a5663cab10fef6487b2711757903edb68ca8c91f1acd083fdL490' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 57160569</div><div id='project'> Project Name: indyfree/carla</div><div id='commit'> Commit Name: ad6d72b67aba0a89b8f54c6c377f9e5b4b1366eb</div><div id='time'> Time: 2021-06-30</div><div id='author'> Author: sbielawski@web.de</div><div id='file'> File Name: carla/recourse_methods/catalog/cem/model.py</div><div id='m_class'> M Class Name: CEM</div><div id='n_method'> N Class Name: CEM</div><div id='m_method'> M Method Name: get_counterfactuals(2)</div><div id='n_method'> N Method Name: get_counterfactuals(2)</div><div id='m_parent_class'> M Parent Class: RecourseMethod</div><div id='n_parent_class'> N Parent Class: RecourseMethod</div><div id='m_file'> M File Name: carla/recourse_methods/catalog/cem/model.py</div><div id='n_file'> N File Name: carla/recourse_methods/catalog/cem/model.py</div><div id='m_start'> M Start Line: 506</div><div id='m_end'> M End Line: 520</div><div id='n_start'> N Start Line: 523</div><div id='n_end'> N End Line: 531</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.blocks = nn.ModuleList([ReversibleBlock(f, g) for (f, g) in blocks])

    def forward(self, x, arg_route = (True, True), **kwargs):
        f_args<a id="change">, g_args</a> = map(lambda route: kwargs if route else {}, arg_route)
        block_kwargs = {&quotf_args&quot: f_args, &quotg_args&quot: g_args}
        return _ReversibleFunction.apply(x, self.blocks, block_kwargs)
</code></pre><h3>After Change</h3><pre><code class='java'>
            layers_and_args = layer_drop(layers_and_args, self.layer_dropout)
            blocks, args = map(lambda ind: list(map(itemgetter(ind), layers_and_args)), (0, 1))

        out<a id="change"> =  </a><a id="change">_ReversibleFunction.apply(</a>x, blocks, args<a id="change">)</a>
        <a id="change">return </a>torch.stack(out.chunk(2, dim=-1)).sum(dim=0)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/linear-attention-transformer/commit/fa23ce09a98a63d26116e3935ad5902cf705255d#diff-29d3c048298bdaa9a9670921a4026430e5b09b55bc1da20d65da18bd5c85f575L118' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 57160570</div><div id='project'> Project Name: lucidrains/linear-attention-transformer</div><div id='commit'> Commit Name: fa23ce09a98a63d26116e3935ad5902cf705255d</div><div id='time'> Time: 2020-06-04</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: linear_attention_transformer/reversible.py</div><div id='m_class'> M Class Name: ReversibleSequence</div><div id='n_method'> N Class Name: ReversibleSequence</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: linear_attention_transformer/reversible.py</div><div id='n_file'> N File Name: linear_attention_transformer/reversible.py</div><div id='m_start'> M Start Line: 118</div><div id='m_end'> M End Line: 121</div><div id='n_start'> N Start Line: 161</div><div id='n_end'> N End Line: 174</div><BR>