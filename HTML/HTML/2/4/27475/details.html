<html><h3>Pattern ID :27475
</h3><img src='81580617.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    

    def __init__(self, in_feature: int, hidden_size: int):
        <a id="change">super(DomainDiscriminator, self).__init__()</a>
        self.layer1 = nn.Linear(in_feature, hidden_size)
        self.bn1 = nn.BatchNorm1d(hidden_size)
        self.relu1 = nn.ReLU()
        self.layer2 = nn.Linear(hidden_size, hidden_size)</code></pre><h3>After Change</h3><pre><code class='java'>
        else:
            super(DomainDiscriminator, self).__init__(
                nn.Linear(in_feature, hidden_size),
                <a id="change">nn.ReLU(inplace=True)</a>,
                nn.Dropout(0.5),
                nn.Linear(hidden_size, hidden_size),
                nn.ReLU(inplace=True),
                nn.Dropout(0.5),
                <a id="change">nn.Linear(</a>hidden_size, 1<a id="change">)</a>,
                nn.Sigmoid()
            )
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/b572f553f392040359d3e98ded8c73f97fd042a0#diff-3997ad2b43bd4484d53a2ce660f64891cb07e29e2563f39e4ae28639baf6e6f3L25' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 81580617</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: b572f553f392040359d3e98ded8c73f97fd042a0</div><div id='time'> Time: 2021-02-08</div><div id='author'> Author: 13126830206@163.com</div><div id='file'> File Name: dalib/modules/domain_discriminator.py</div><div id='m_class'> M Class Name: DomainDiscriminator</div><div id='n_method'> N Class Name: DomainDiscriminator</div><div id='m_method'> M Method Name: __init__(4)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: nn.Sequential</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dalib/modules/domain_discriminator.py</div><div id='n_file'> N File Name: dalib/modules/domain_discriminator.py</div><div id='m_start'> M Start Line: 25</div><div id='m_end'> M End Line: 33</div><div id='n_start'> N Start Line: 26</div><div id='n_end'> N End Line: 50</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    

    def __init__(self, in_feature: int, hidden_size: int):
        <a id="change">super(DomainDiscriminator, self).__init__()</a>
        self.layer1 = nn.Linear(in_feature, hidden_size)
        self.bn1 = nn.BatchNorm1d(hidden_size)
        self.relu1 = nn.ReLU()
        self.layer2 = nn.Linear(hidden_size, hidden_size)</code></pre><h3>After Change</h3><pre><code class='java'>
            )
        else:
            super(DomainDiscriminator, self).__init__(
                <a id="change">nn.Linear(</a>in_feature, hidden_size<a id="change">)</a>,
                <a id="change">nn.ReLU(inplace=True)</a>,
                nn.Dropout(0.5),
                nn.Linear(hidden_size, hidden_size),
                nn.ReLU(inplace=True),</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuml/transfer-learning-library/commit/b572f553f392040359d3e98ded8c73f97fd042a0#diff-3997ad2b43bd4484d53a2ce660f64891cb07e29e2563f39e4ae28639baf6e6f3L24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 81580619</div><div id='project'> Project Name: thuml/transfer-learning-library</div><div id='commit'> Commit Name: b572f553f392040359d3e98ded8c73f97fd042a0</div><div id='time'> Time: 2021-02-08</div><div id='author'> Author: 13126830206@163.com</div><div id='file'> File Name: dalib/modules/domain_discriminator.py</div><div id='m_class'> M Class Name: DomainDiscriminator</div><div id='n_method'> N Class Name: DomainDiscriminator</div><div id='m_method'> M Method Name: __init__(4)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: nn.Sequential</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dalib/modules/domain_discriminator.py</div><div id='n_file'> N File Name: dalib/modules/domain_discriminator.py</div><div id='m_start'> M Start Line: 25</div><div id='m_end'> M End Line: 33</div><div id='n_start'> N Start Line: 26</div><div id='n_end'> N End Line: 50</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

class Model(ResNet):
    def __init__(self):
        <a id="change">super(Model, self).__init__(</a>BasicBlock,[2,2,2,2]<a id="change">)</a>

class Loss(nn.Module):
    def __init__(self):
        super(Loss, self).__init__()</code></pre><h3>After Change</h3><pre><code class='java'>
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(64),
            <a id="change">nn.ReLU(inplace=True)</a>)
        &#47&#47we use a different inputsize than the original paper
        &#47&#47so conv2_x&quots stride is 1
        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)
        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)
        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)
        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)
        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = <a id="change">nn.Linear(</a>512 * block.expansion, num_classes<a id="change">)</a>

    def _make_layer(self, block, out_channels, num_blocks, stride):
        make resnet layers(by layer i didnt mean this &quotlayer&quot was the
        same as a neuron netowork layer, ex. conv layer), one layer may</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/wwzzz/easyfl/commit/ddf7d4db52a22b726ed3c58c0d4f2638f9d22ed8#diff-0ccfc1fe340c1c377b71ad61cb577828def8c8dd26f612507360d5c44170168cL137' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 81580612</div><div id='project'> Project Name: wwzzz/easyfl</div><div id='commit'> Commit Name: ddf7d4db52a22b726ed3c58c0d4f2638f9d22ed8</div><div id='time'> Time: 2021-08-25</div><div id='author'> Author: zwang@stu.xmu.edu.cn</div><div id='file'> File Name: benchmark/cifar100/model/resnet18.py</div><div id='m_class'> M Class Name: Model</div><div id='n_method'> N Class Name: Model</div><div id='m_method'> M Method Name: __init__(4)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: FModule</div><div id='n_parent_class'> N Parent Class: ResNet</div><div id='m_file'> M File Name: benchmark/cifar100/model/resnet18.py</div><div id='n_file'> N File Name: benchmark/cifar100/model/resnet18.py</div><div id='m_start'> M Start Line: 137</div><div id='m_end'> M End Line: 138</div><div id='n_start'> N Start Line: 80</div><div id='n_end'> N End Line: 94</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

class Model(ResNet):
    def __init__(self):
        <a id="change">super(Model, self).__init__(</a>BasicBlock,[2,2,2,2]<a id="change">)</a>

class Loss(nn.Module):
    def __init__(self):
        super(Loss, self).__init__()</code></pre><h3>After Change</h3><pre><code class='java'>
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(64),
            <a id="change">nn.ReLU(inplace=True)</a>)
        &#47&#47we use a different inputsize than the original paper
        &#47&#47so conv2_x&quots stride is 1
        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)
        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)
        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)
        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)
        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = <a id="change">nn.Linear(</a>512 * block.expansion, num_classes<a id="change">)</a>

    def _make_layer(self, block, out_channels, num_blocks, stride):
        make resnet layers(by layer i didnt mean this &quotlayer&quot was the
        same as a neuron netowork layer, ex. conv layer), one layer may</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/wwzzz/easyfl/commit/ddf7d4db52a22b726ed3c58c0d4f2638f9d22ed8#diff-52eea8bf07e92c026d50c9ab8c8273f354b717a159053d14df333981119ec139L135' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 81580611</div><div id='project'> Project Name: wwzzz/easyfl</div><div id='commit'> Commit Name: ddf7d4db52a22b726ed3c58c0d4f2638f9d22ed8</div><div id='time'> Time: 2021-08-25</div><div id='author'> Author: zwang@stu.xmu.edu.cn</div><div id='file'> File Name: benchmark/cifar10/model/resnet18.py</div><div id='m_class'> M Class Name: Model</div><div id='n_method'> N Class Name: Model</div><div id='m_method'> M Method Name: __init__(4)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: FModule</div><div id='n_parent_class'> N Parent Class: ResNet</div><div id='m_file'> M File Name: benchmark/cifar10/model/resnet18.py</div><div id='n_file'> N File Name: benchmark/cifar10/model/resnet18.py</div><div id='m_start'> M Start Line: 135</div><div id='m_end'> M End Line: 136</div><div id='n_start'> N Start Line: 80</div><div id='n_end'> N End Line: 94</div><BR>