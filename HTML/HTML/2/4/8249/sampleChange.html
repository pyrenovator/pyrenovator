<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
  if FLAGS.use_gpu:
    strategy = tf.distribute.MirroredStrategy()
  else:
    <a id="change">logging.info(&quotUse TPU at %s&quot</a>,
                 FLAGS.tpu if FLAGS.tpu is not None else &quotlocal&quot<a id="change">)</a>
    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=FLAGS.tpu)
    tf.config.experimental_connect_to_cluster(resolver)
    tf.tpu.experimental.initialize_tpu_system(resolver)
    strategy = tf.distribute.TPUStrategy(resolver)</code></pre><h3>After Change</h3><pre><code class='java'>
        logging.info(
          &quotStarting to run eval step %s of epoch: %s&quot, step, epoch + 1)

      test_start_time = <a id="change">time.time()</a>
      test_step(test_iterator)
      ms_per_example = (time.time() - test_start_time)<a id="change"> * </a>1e6 / eval_batch_size
      metrics[&quottest/ms_per_example&quot].update_state(ms_per_example)

    logging.info(</code></pre>