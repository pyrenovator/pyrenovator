<html><h3>Pattern ID :28575
</h3><img src='84442617.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    dtype=st.sampled_from(ivy_np.valid_dtypes),
)
def test_to_scalar(object_in, dtype, device, call, fw):
    <a id="change">if fw == "torch" and (dtype in ["uint16", "uint32", "uint64"])</a>:
        &#47&#47 torch does not support those dtypes
        <a id="change">return</a>
    <a id="change">if call in [helpers.mx_call] and dtype == "int16"</a>:
        &#47&#47 mxnet does not support int16
        <a id="change">return</a>
    <a id="change">if call in [helpers.tf_graph_call]</a>:
        &#47&#47 to_scalar() requires eager execution
        <a id="change">return</a>
    &#47&#47 smoke test
    ret = ivy.to_scalar(ivy.array(object_in, dtype=dtype, device=device))
    true_val = ivy.to_numpy(ivy.array(object_in, dtype=dtype)).item()
    &#47&#47 type test
    assert isinstance(ret, type(true_val))
    &#47&#47 value test
    assert ivy.to_scalar(ivy.array(object_in, dtype=dtype, device=device)) == true_val
    &#47&#47 compilation test
    <a id="change">if call in [helpers.torch_call]</a>:
        &#47&#47 pytorch scripting does not support scalar conversion
        <a id="change">return</a>


&#47&#47 to_list
@given(x0_n_x1_n_res=helpers.dtype_and_values(available_dtypes=ivy_np.valid_dtypes))</code></pre><h3>After Change</h3><pre><code class='java'>
    dtype=st.sampled_from(ivy_np.valid_dtypes),
)
def test_to_scalar(object_in, dtype, device, call, fw):
    <a id="change">assume(not (fw == "torch" and (dtype in ["uint16", "uint32", "uint64"]))</a><a id="change">)</a>
    &#47&#47 torch does not support those dtypes
    <a id="change">assume(</a><a id="change">not (fw == "mxnet" and dtype == "int16"))</a>
    &#47&#47 mxnet does not support int16
    <a id="change">assume(</a><a id="change">not (fw == "tensorflow"))</a>
    &#47&#47 to_scalar() requires eager execution
    &#47&#47 smoke test
    ret = ivy.to_scalar(ivy.array(object_in, dtype=dtype, device=device))
    true_val = ivy.to_numpy(ivy.array(object_in, dtype=dtype)).item()
    &#47&#47 type test
    assert isinstance(ret, type(true_val))
    &#47&#47 value test
    assert ivy.to_scalar(ivy.array(object_in, dtype=dtype, device=device)) == true_val
    &#47&#47 compilation test
    &#47&#47 pytorch scripting does not support scalar conversion
    <a id="change">assume(</a><a id="change">not (fw == "torch"))</a>


&#47&#47 to_list
@given(x0_n_x1_n_res=helpers.dtype_and_values(available_dtypes=ivy_np.valid_dtypes))</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 35</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/unifyai/ivy/commit/003eeb7cfca5a81aef61a8756ffb8649520e01ac#diff-a13fff36fcac31f1f8fa76cb78fceb815348b58f0b03358bbf471bd355416ee8L251' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84442617</div><div id='project'> Project Name: unifyai/ivy</div><div id='commit'> Commit Name: 003eeb7cfca5a81aef61a8756ffb8649520e01ac</div><div id='time'> Time: 2022-07-30</div><div id='author'> Author: rushaligrandhe@gmail.com</div><div id='file'> File Name: ivy_tests/test_ivy/test_functional/test_core/test_general.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_to_scalar(5)</div><div id='n_method'> N Method Name: test_to_scalar(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: ivy_tests/test_ivy/test_functional/test_core/test_general.py</div><div id='n_file'> N File Name: ivy_tests/test_ivy/test_functional/test_core/test_general.py</div><div id='m_start'> M Start Line: 251</div><div id='m_end'> M End Line: 273</div><div id='n_start'> N Start Line: 261</div><div id='n_end'> N End Line: 276</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    dtype=st.sampled_from(ivy_np.valid_dtypes),
)
def test_to_scalar(object_in, dtype, device, call, fw):
    <a id="change">if fw == "torch" and (dtype in ["uint16", "uint32", "uint64"])</a>:
        &#47&#47 torch does not support those dtypes
        <a id="change">return</a>
    <a id="change">if call in [helpers.mx_call] and dtype == "int16"</a>:
        &#47&#47 mxnet does not support int16
        <a id="change">return</a>
    <a id="change">if call in [helpers.tf_graph_call]</a>:
        &#47&#47 to_scalar() requires eager execution
        <a id="change">return</a>
    &#47&#47 smoke test
    ret = ivy.to_scalar(ivy.array(object_in, dtype=dtype, device=device))
    true_val = ivy.to_numpy(ivy.array(object_in, dtype=dtype)).item()
    &#47&#47 type test
    assert isinstance(ret, type(true_val))
    &#47&#47 value test
    assert ivy.to_scalar(ivy.array(object_in, dtype=dtype, device=device)) == true_val
    &#47&#47 compilation test
    <a id="change">if call in [helpers.torch_call]</a>:
        &#47&#47 pytorch scripting does not support scalar conversion
        <a id="change">return</a>


&#47&#47 to_list
@given(x0_n_x1_n_res=helpers.dtype_and_values(available_dtypes=ivy_np.valid_dtypes))</code></pre><h3>After Change</h3><pre><code class='java'>
    dtype=st.sampled_from(ivy_np.valid_dtypes),
)
def test_to_scalar(object_in, dtype, device, call, fw):
    <a id="change">assume(not (fw == "torch" and (dtype in ["uint16", "uint32", "uint64"]))</a><a id="change">)</a>
    &#47&#47 torch does not support those dtypes
    <a id="change">assume(</a><a id="change">not (fw == "mxnet" and dtype == "int16"))</a>
    &#47&#47 mxnet does not support int16
    <a id="change">assume(</a><a id="change">not (fw == "tensorflow"))</a>
    &#47&#47 to_scalar() requires eager execution
    &#47&#47 smoke test
    ret = ivy.to_scalar(ivy.array(object_in, dtype=dtype, device=device))
    true_val = ivy.to_numpy(ivy.array(object_in, dtype=dtype)).item()
    &#47&#47 type test
    assert isinstance(ret, type(true_val))
    &#47&#47 value test
    assert ivy.to_scalar(ivy.array(object_in, dtype=dtype, device=device)) == true_val
    &#47&#47 compilation test
    &#47&#47 pytorch scripting does not support scalar conversion
    <a id="change">assume(</a><a id="change">not (fw == "torch"))</a>


&#47&#47 to_list
@given(x0_n_x1_n_res=helpers.dtype_and_values(available_dtypes=ivy_np.valid_dtypes))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ivy-dl/ivy/commit/003eeb7cfca5a81aef61a8756ffb8649520e01ac#diff-a13fff36fcac31f1f8fa76cb78fceb815348b58f0b03358bbf471bd355416ee8L250' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84442618</div><div id='project'> Project Name: ivy-dl/ivy</div><div id='commit'> Commit Name: 003eeb7cfca5a81aef61a8756ffb8649520e01ac</div><div id='time'> Time: 2022-07-30</div><div id='author'> Author: rushaligrandhe@gmail.com</div><div id='file'> File Name: ivy_tests/test_ivy/test_functional/test_core/test_general.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_to_scalar(5)</div><div id='n_method'> N Method Name: test_to_scalar(5)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: ivy_tests/test_ivy/test_functional/test_core/test_general.py</div><div id='n_file'> N File Name: ivy_tests/test_ivy/test_functional/test_core/test_general.py</div><div id='m_start'> M Start Line: 251</div><div id='m_end'> M End Line: 273</div><div id='n_start'> N Start Line: 261</div><div id='n_end'> N End Line: 276</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
@given(x0_n_x1_n_res=helpers.dtype_and_values(available_dtypes=ivy_np.valid_dtypes))
def test_to_numpy(x0_n_x1_n_res, device, call, fw):
    dtype, object_in = x0_n_x1_n_res
    <a id="change">if fw == "torch" and (dtype in ["uint16", "uint32", "uint64"])</a>:
        &#47&#47 torch does not support those dtypes
        <a id="change">return</a>
    <a id="change">if call in [helpers.mx_call] and dtype == "int16"</a>:
        &#47&#47 mxnet does not support int16
        <a id="change">return</a>
    <a id="change">if call in [helpers.tf_graph_call]</a>:
        &#47&#47 to_numpy() requires eager execution
        <a id="change">return</a>
    &#47&#47 smoke test
    ret = ivy.to_numpy(ivy.array(object_in, dtype=dtype, device=device))
    &#47&#47 type test
    assert isinstance(ret, np.ndarray)
    &#47&#47 cardinality test
    assert ret.shape == np.array(object_in).shape
    &#47&#47 value test
    helpers.assert_all_close(ret, np.array(object_in).astype(dtype))
    &#47&#47 compilation test
    <a id="change">if call in [helpers.torch_call]</a>:
        &#47&#47 pytorch scripting does not support numpy conversion
        <a id="change">return</a>


&#47&#47 to_scalar
@given(</code></pre><h3>After Change</h3><pre><code class='java'>
@given(x0_n_x1_n_res=helpers.dtype_and_values(available_dtypes=ivy_np.valid_dtypes))
def test_to_numpy(x0_n_x1_n_res, device, call, fw):
    dtype, object_in = x0_n_x1_n_res
    <a id="change">assume(not (fw == "torch" and (dtype in ["uint16", "uint32", "uint64"]))</a><a id="change">)</a>
    &#47&#47 torch does not support those dtypes
    <a id="change">assume(</a><a id="change">not (fw == "mxnet" and dtype == "int16"))</a>
    &#47&#47 mxnet does not support int16
    <a id="change">assume(</a><a id="change">not (fw == "tensorflow"))</a>
    &#47&#47 to_numpy() requires eager execution
    &#47&#47 smoke test
    ret = ivy.to_numpy(ivy.array(object_in, dtype=dtype, device=device))
    &#47&#47 type test
    assert isinstance(ret, np.ndarray)
    &#47&#47 cardinality test
    assert ret.shape == np.array(object_in).shape
    &#47&#47 value test
    helpers.assert_all_close(ret, np.array(object_in).astype(dtype))
    &#47&#47 compilation test
    &#47&#47 pytorch scripting does not support numpy conversion
    <a id="change">assume(</a><a id="change">not (fw == "torch"))</a>


&#47&#47 to_scalar
@given(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ivy-dl/ivy/commit/003eeb7cfca5a81aef61a8756ffb8649520e01ac#diff-a13fff36fcac31f1f8fa76cb78fceb815348b58f0b03358bbf471bd355416ee8L220' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 84442620</div><div id='project'> Project Name: ivy-dl/ivy</div><div id='commit'> Commit Name: 003eeb7cfca5a81aef61a8756ffb8649520e01ac</div><div id='time'> Time: 2022-07-30</div><div id='author'> Author: rushaligrandhe@gmail.com</div><div id='file'> File Name: ivy_tests/test_ivy/test_functional/test_core/test_general.py</div><div id='m_class'> M Class Name: AnonimousClass</div><div id='n_method'> N Class Name: AnonimousClass</div><div id='m_method'> M Method Name: test_to_numpy(4)</div><div id='n_method'> N Method Name: test_to_numpy(4)</div><div id='m_parent_class'> M Parent Class: </div><div id='n_parent_class'> N Parent Class: </div><div id='m_file'> M File Name: ivy_tests/test_ivy/test_functional/test_core/test_general.py</div><div id='n_file'> N File Name: ivy_tests/test_ivy/test_functional/test_core/test_general.py</div><div id='m_start'> M Start Line: 222</div><div id='m_end'> M End Line: 245</div><div id='n_start'> N Start Line: 236</div><div id='n_end'> N End Line: 252</div><BR>